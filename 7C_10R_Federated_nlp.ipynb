{"cells":[{"cell_type":"markdown","metadata":{"id":"S2h9vDxwy3mD"},"source":["# **Prerequesits**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10433,"status":"ok","timestamp":1678002953373,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"vRFsevaZ4D-h","outputId":"80ae3836-4443-4a8a-9e0e-1b8e92aa8a07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting vaderSentiment\n","  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from vaderSentiment) (2.25.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2.10)\n","Installing collected packages: vaderSentiment\n","Successfully installed vaderSentiment-3.3.2\n"]}],"source":["! pip install vaderSentiment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4450,"status":"ok","timestamp":1678002957819,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"T3bm5q5KVjUd","outputId":"4cb1990a-8561-4473-a08f-629f66ef9202"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting textstat\n","  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyphen\n","  Downloading pyphen-0.13.2-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyphen, textstat\n","Successfully installed pyphen-0.13.2 textstat-0.7.3\n"]}],"source":["! pip install textstat"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4884,"status":"ok","timestamp":1678002962694,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"iy90YTbjhQrF","outputId":"a799f935-2b73-4179-abfc-5e55f49f54b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyenchant\n","  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyenchant\n","Successfully installed pyenchant-3.2.2\n"]}],"source":["! pip install pyenchant"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9859,"status":"ok","timestamp":1678002972544,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"tHfdAJR-Vztu","outputId":"454e1af1-95e1-4f2a-d3c8-67dfcd201ef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  enchant\n","Suggested packages:\n","  libenchant-voikko\n","The following NEW packages will be installed:\n","  enchant libenchant1c2a\n","0 upgraded, 2 newly installed, 0 to remove and 22 not upgraded.\n","Need to get 77.1 kB of archives.\n","After this operation, 325 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libenchant1c2a amd64 1.6.0-11.3build1 [64.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 enchant amd64 1.6.0-11.3build1 [12.4 kB]\n","Fetched 77.1 kB in 0s (227 kB/s)\n","Selecting previously unselected package libenchant1c2a:amd64.\n","(Reading database ... 128215 files and directories currently installed.)\n","Preparing to unpack .../libenchant1c2a_1.6.0-11.3build1_amd64.deb ...\n","Unpacking libenchant1c2a:amd64 (1.6.0-11.3build1) ...\n","Selecting previously unselected package enchant.\n","Preparing to unpack .../enchant_1.6.0-11.3build1_amd64.deb ...\n","Unpacking enchant (1.6.0-11.3build1) ...\n","Setting up libenchant1c2a:amd64 (1.6.0-11.3build1) ...\n","Setting up enchant (1.6.0-11.3build1) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"]}],"source":["! apt install --yes libenchant1c2a"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11230,"status":"ok","timestamp":1678002983772,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"NsiIsfcVkXjP","outputId":"fec850fd-cce2-4849-c508-d8aee70289b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting splitter\n","  Downloading splitter-0.1.1.tar.gz (65 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pbr<1.0,>=0.6\n","  Downloading pbr-0.11.1-py2.py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from pbr<1.0,>=0.6->splitter) (22.0.4)\n","Building wheels for collected packages: splitter\n","  Building wheel for splitter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for splitter: filename=splitter-0.1.1-py3-none-any.whl size=63354 sha256=be78f0bd5cf3292dc9e35fed2754abd209e720c81204b956fab94935e0545164\n","  Stored in directory: /root/.cache/pip/wheels/72/4f/88/538c3f3da08b113a94345794d5f721034643cb5a4361b6f08c\n","Successfully built splitter\n","Installing collected packages: pbr, splitter\n","Successfully installed pbr-0.11.1 splitter-0.1.1\n"]}],"source":["! pip install splitter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJZbiziYGVE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678002987825,"user_tz":-120,"elapsed":4080,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"}},"outputId":"ea248fb7-bad4-4625-fbe1-ae70f4fea7ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Keras-Preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from Keras-Preprocessing) (1.22.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from Keras-Preprocessing) (1.15.0)\n","Installing collected packages: Keras-Preprocessing\n","Successfully installed Keras-Preprocessing-1.1.2\n"]}],"source":["!pip install Keras-Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"DxU0xKn2zh8F"},"source":["# **Call libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qmF8T8W05Am"},"outputs":[],"source":["import re\n","import enchant\n","import splitter\n","import pandas as pd\n","import numpy as np\n","import pickle\n","import sys\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","import string\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n","from textstat.textstat import *\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.metrics import classification_report\n","from sklearn.svm import LinearSVC\n","\n","from matplotlib import pyplot\n","import matplotlib.pyplot as plt\n","import seaborn\n","%matplotlib inline\n","\n","from numpy import array\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.preprocessing.text import one_hot, Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.models import Sequential, Model, load_model\n","from keras.layers import Input, LSTM, Embedding, Dropout, Flatten, GlobalMaxPooling1D, Dense, Conv1D, MaxPooling1D, Bidirectional, Concatenate, GRU, BatchNormalization\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.pipeline import Pipeline\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import class_weight\n","\n","from sklearn.model_selection import KFold\n","\n","# Importing libraries\n","from sklearn.metrics import auc\n","from sklearn.metrics import roc_curve\n","from keras import initializers\n","import hashlib\n","import time\n"]},{"cell_type":"markdown","metadata":{"id":"0nrfEIbE-VX-"},"source":["# **Federated Learning**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57540,"status":"ok","timestamp":1678003055075,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"m_JEg4GrUjiI","outputId":"b4f2c112-cd9d-49dd-c3b7-b586776b19dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GM1hUEziQGVf"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nn3ULCcUWjhX"},"outputs":[],"source":["# Importing libraries\n","import pandas as pd\n","import numpy as np\n","from tensorflow import keras\n","from keras import layers\n","from keras.layers import Input, Dense, Dropout\n","from keras.models import Model, load_model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras import backend as K\n","from sklearn.metrics import auc\n","from sklearn.metrics import roc_curve\n","from keras import initializers\n","import hashlib\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pEtS1aaZYNp4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678003055077,"user_tz":-120,"elapsed":14,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"}},"outputId":"b2856768-2dc4-4beb-d225-9b0a898cf04e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"]}],"source":["# Model configuration\n","no_of_rounds = 10\n","no_of_epochs = 10\n","no_of_folds = 10\n","clients_number = 7\n","batch_size = 100\n","verbosity = 1\n","\n","no_of_epochs_plt=[]\n","for i in range (1,no_of_epochs+1):\n","  no_of_epochs_plt.append(i)\n","print(no_of_epochs_plt)\n","\n","no_of_folds_plt=[]\n","for i in range (1,no_of_folds+1):\n","  no_of_folds_plt.append(i)\n","print(no_of_epochs_plt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HD6L6XB9-mrN"},"outputs":[],"source":["METRICS = [\n","      keras.metrics.BinaryAccuracy(name='accuracy'),\n","      keras.metrics.TruePositives(name='tp'),\n","      keras.metrics.FalsePositives(name='fp'),\n","      keras.metrics.TrueNegatives(name='tn'),\n","      keras.metrics.FalseNegatives(name='fn'),\n","      keras.metrics.Precision(name='precision'),\n","      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n","]"]},{"cell_type":"code","source":[],"metadata":{"id":"PBwhpg3aYw54"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFUSZRh4YD-o"},"outputs":[],"source":["class attention(Layer):\n","\n","    def __init__(self, return_sequences=True):\n","        self.return_sequences = return_sequences\n","        super(attention,self).__init__()\n","\n","    def build(self, input_shape):\n","\n","        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n","                               initializer=\"normal\")\n","        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n","                               initializer=\"zeros\")\n","\n","        super(attention,self).build(input_shape)\n","\n","    def call(self, x):\n","\n","        e = K.tanh(K.dot(x,self.W)+self.b)\n","        a = K.softmax(e, axis=1)\n","        output = x*a\n","\n","        if self.return_sequences:\n","            return output\n","\n","        return K.sum(output, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0L5CWXepX1SI"},"outputs":[],"source":["def ann(X_train, Y_train, random_seed, batch_size_specified=batch_size):\n","\n","    num_folds = no_of_folds\n","    inputs= X_train\n","    targets= Y_train\n","\n","    # Define per-fold score containers\n","    acc_per_fold = []\n","    loss_per_fold = []\n","\n","    # Define the model architecture\n","    input_shape = inputs.shape[1]\n","    # input layer\n","    input_layer = Input(shape=(input_shape,))\n","    # hidden layers\n","    hidden_layer1 = Embedding(input_dim=vocab_size, output_dim=300, input_length=100, trainable=False)(input_layer)\n","    hidden_layer2 = Conv1D(filters=512, kernel_size=4, activation='relu')(hidden_layer1)\n","    hidden_layer3 = BatchNormalization()(hidden_layer2)\n","    hidden_layer4 = MaxPooling1D(pool_size=4)(hidden_layer3)\n","    hidden_layer5 = attention(return_sequences=True)(hidden_layer4)\n","    hidden_layer6 = Bidirectional(LSTM(100, return_sequences=True))(hidden_layer5)\n","    #hidden_layer7 = Dropout(0.2)(hidden_layer6)\n","    hidden_layer8 = GlobalMaxPooling1D()(hidden_layer6)\n","    # output layer\n","    output_layer = Dense(3, activation = 'softmax')(hidden_layer8)\n","\n","    ann_model = Model(inputs=input_layer, outputs=output_layer)\n","\n","    # Compile the model\n","    ann_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics= METRICS)\n","\n","    # Define the K-fold Cross Validator\n","    kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","    # K-fold Cross Validation model evaluation\n","    fold_no = 1\n","    for train, test in kfold.split(inputs, targets):\n","\n","      # Generate a print\n","      print(\"------------------------------------------------------------------------\")\n","      print(f'Training for fold {fold_no} ...')\n","\n","      # Fit data to model\n","      history = ann_model.fit(inputs[train], targets[train],\n","                  batch_size=100,\n","                  epochs = no_of_epochs,\n","                  verbose=1)\n","\n","      # Generate generalization metrics\n","      scores = ann_model.evaluate(inputs[test], targets[test], verbose=0)\n","      print(f'Score for fold {fold_no}: {ann_model.metrics_names[0]} of {scores[0]}; {ann_model.metrics_names[1]} of {scores[1]*100}%')\n","      acc_per_fold.append(scores[1] * 100)\n","      loss_per_fold.append(scores[0])\n","\n","      # Increase fold number\n","      fold_no = fold_no + 1\n","\n","    # == Provide average scores ==\n","    print(f'------------------------------------------------------------------------')\n","    print(f'Score per fold')\n","    for i in range(0, len(acc_per_fold)):\n","      print(f'------------------------------------------------------------------------')\n","      print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n","    print(f'------------------------------------------------------------------------')\n","    print(f'Average scores for all folds:')\n","    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n","    loss = np.mean(loss_per_fold)\n","    print(f'> Loss: {np.mean(loss_per_fold)}')\n","    print(f'------------------------------------------------------------------------')\n","    return ann_model, loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9UvWwpLvt7By"},"outputs":[],"source":["def ann2(X_train, Y_train, initializers, batch_size_specified=batch_size):\n","\n","    num_folds = no_of_folds\n","    inputs= X_train\n","    targets= Y_train\n","\n","    # Define per-fold score containers\n","    acc_per_fold = []\n","    loss_per_fold = []\n","\n","    # Define the model architecture\n","    input_shape = inputs.shape[1]\n","    # input layer\n","    input_layer = Input(shape=(input_shape,))\n","    # hidden layers\n","    hidden_layer1 = Embedding(input_dim=vocab_size, output_dim=300, input_length=100, trainable=False)(input_layer)\n","    hidden_layer2 = Conv1D(filters=512, kernel_size=4, activation='relu')(hidden_layer1)\n","    hidden_layer3 = BatchNormalization()(hidden_layer2)\n","    hidden_layer4 = MaxPooling1D(pool_size=4)(hidden_layer3)\n","    hidden_layer5 = attention(return_sequences=True)(hidden_layer4)\n","    hidden_layer6 = Bidirectional(LSTM(100, return_sequences=True))(hidden_layer5)\n","    #hidden_layer7 = Dropout(0.2)(hidden_layer6)\n","    hidden_layer8 = GlobalMaxPooling1D()(hidden_layer6)\n","    # output layer\n","    output_layer = Dense(3, activation = 'softmax')(hidden_layer8)\n","\n","    ann_model = Model(inputs=input_layer, outputs=output_layer)\n","\n","    # Compile the model\n","    ann_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=METRICS)\n","\n","    #set weights\n","    ann_model.set_weights(initializers)\n","\n","    # Define the K-fold Cross Validator\n","    kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","    # K-fold Cross Validation model evaluation\n","    fold_no = 1\n","    for train, test in kfold.split(inputs, targets):\n","\n","      # Generate a print\n","      print(\"------------------------------------------------------------------------\")\n","      print(f'Training for fold {fold_no} ...')\n","\n","      # Fit data to model\n","      history = ann_model.fit(inputs[train], targets[train],\n","                  batch_size=100,\n","                  epochs = no_of_epochs,\n","                  verbose=1)\n","\n","      # Generate generalization metrics\n","      scores = ann_model.evaluate(inputs[test], targets[test], verbose=0)\n","      print(f'Score for fold {fold_no}: {ann_model.metrics_names[0]} of {scores[0]}; {ann_model.metrics_names[1]} of {scores[1]*100}%')\n","      acc_per_fold.append(scores[1] * 100)\n","      loss_per_fold.append(scores[0])\n","\n","      # Increase fold number\n","      fold_no = fold_no + 1\n","\n","    # == Provide average scores ==\n","    print(f'------------------------------------------------------------------------')\n","    print('Score per fold')\n","    for i in range(0, len(acc_per_fold)):\n","      print(f'------------------------------------------------------------------------')\n","      print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n","    print(f'------------------------------------------------------------------------')\n","    print(f'Average scores for all folds:')\n","    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n","    loss = np.mean(loss_per_fold)\n","    print(f'> Loss: {np.mean(loss_per_fold)}')\n","    print(f'------------------------------------------------------------------------')\n","    return ann_model, loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owYQWZt_t8su"},"outputs":[],"source":["def calculate_auc(model, X_test, Y_test):\n","    Y_preds = model.predict(X_test)\n","    Y_pred = np.argmax(Y_preds,axis=1)\n","    Y_test = np.argmax(Y_test,axis=1)\n","    fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)\n","    roc_auc = auc(fpr, tpr)\n","    return roc_auc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NiSZpV6hAnQA"},"outputs":[],"source":["def calculate_metrics(model, X_test, Y_test):\n","    scores = model.evaluate(X_test, Y_test, verbose=1)\n","    return scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3Xmp2PEgxCz"},"outputs":[],"source":["def calculate_training_metrics(model, X_train, Y_train):\n","    training_scores = model.evaluate(X_train, Y_train, verbose=1)\n","    #print(f'> Training Scores shape is : {np.shape(training_scores)}')\n","    return training_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tw5FJHdQuyEf"},"outputs":[],"source":["def average(round,models):\n","    weights_arrays = []\n","    for model in models:\n","        weights = model.get_weights()\n","        #print (f'> Weights shape of client {str(model)} is {str(np.array(weights).shape)}')\n","        weights_arrays.append(weights)\n","    average_weights = np.average(weights_arrays, 0)\n","    return average_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIImofzAuDay"},"outputs":[],"source":["def federated_learning(num_of_clients):\n","\n","    average_epoch_counts = []\n","    average_training_aucs = []\n","    end_of_loop_test_aucs = []\n","    previous_median_loss = 1\n","    clients_metrics=[]\n","    training_clients_metrics=[]\n","\n","    # Define all-rounds metrics\n","    final_loss_per_round = []\n","    final_tp_per_round = []\n","    final_fp_per_round = []\n","    final_tn_per_round = []\n","    final_fn_per_round = []\n","    final_acc_per_round = []\n","    final_precision_per_round = []\n","    final_recall_per_round = []\n","    final_auc_per_round = []\n","    final_prc_per_round = []\n","\n","    # Define all-rounds training metrics\n","    final_training_loss_per_round = []\n","    final_training_tp_per_round = []\n","    final_training_fp_per_round = []\n","    final_training_tn_per_round = []\n","    final_training_fn_per_round = []\n","    final_training_acc_per_round = []\n","    final_training_precision_per_round = []\n","    final_training_recall_per_round = []\n","    final_training_auc_per_round = []\n","    final_training_prc_per_round = []\n","\n","    X_train_clients = X_train_shares\n","    Y_train_clients = Y_train_shares\n","\n","    # global loops\n","    for t in range(no_of_rounds):\n","\n","        #np.random.seed(t+1)\n","        #indices =  np.random.choice(10, num_of_clients, replace=False)\n","\n","        #print indices\n","        print (\"\")\n","        print (\"##############################################################################################################\")\n","        print (\"\")\n","        print (f'> round {str(t+1)} start, random seed= {str(t+1)}')\n","        print (\"\")\n","\n","        #print (f'> training data indices {str(indices)}')\n","        #print (\"\")\n","        anns = []\n","        roc_aucs = []\n","        test_aucs = []\n","        losses = []\n","\n","        loss_per_round = []\n","        tp_per_round = []\n","        fp_per_round = []\n","        tn_per_round = []\n","        fn_per_round = []\n","        acc_per_round = []\n","        precision_per_round = []\n","        recall_per_round = []\n","        auc_per_round = []\n","        prc_per_round = []\n","\n","        training_loss_per_round = []\n","        training_tp_per_round = []\n","        training_fp_per_round = []\n","        training_tn_per_round = []\n","        training_fn_per_round = []\n","        training_acc_per_round = []\n","        training_precision_per_round = []\n","        training_recall_per_round = []\n","        training_auc_per_round = []\n","        training_prc_per_round = []\n","\n","        for i in range(num_of_clients):\n","\n","            print (f'> client {str(i+1)} started learning...........')\n","            print (\"\")\n","\n","            if t == 0:\n","                ann_model, loss = ann(np.array(X_train_clients[i]), np.array(Y_train_clients[i]), random_seed=t+1,\n","                                      batch_size_specified=batch_size)\n","            else:\n","                ann_model, loss = ann2(np.array(X_train_clients[i]), np.array(Y_train_clients[i]),\n","                                       initializers = weights, batch_size_specified=batch_size)\n","\n","            anns.append(ann_model)\n","\n","            # calculate auc for model trained with each client\n","            roc_auc = calculate_auc(ann_model, np.array(X_train_clients[i]), np.array(Y_train_clients[i]))\n","\n","            roc_aucs.append(roc_auc)\n","\n","            #loss\n","            losses.append(loss)\n","\n","            #test auc\n","            test_auc = calculate_auc(ann_model, X_test, Y_test)\n","            test_aucs.append(test_auc)\n","\n","            #evaluation training metrics for clients each round\n","            epoch_training_metrics = calculate_training_metrics(ann_model, X_train_clients[i], Y_train_clients[i])\n","            #print evaluation metrics for clients each round\n","            training_clients_metrics.append(epoch_training_metrics)\n","\n","            #evaluation metrics for clients each round\n","            epoch_metrics = calculate_metrics(ann_model, X_test, Y_test)\n","            #print evaluation metrics for clients each round\n","            clients_metrics.append(epoch_metrics)\n","\n","            print(\"\")\n","            print(f'>round {str(t+1)}  client {str(i+1)} evaluation training metrics:')\n","            print(epoch_training_metrics)\n","\n","            print(\"\")\n","            print(f'>round {str(t+1)}  client {str(i+1)} evaluation metrics:')\n","            print(epoch_metrics)\n","\n","            print(\"\")\n","            print(\"=============================================================\")\n","            print(\"\")\n","\n","        average_training_auc = np.average(roc_aucs)\n","        print (f'> round {str(t+1)} average training auc= {str(average_training_auc)}')\n","        average_training_aucs.append(average_training_auc)\n","\n","        print(f'> round {str(t+1)} average training loss= {str(np.average(losses))}')\n","\n","        # retrain\n","        anns, epoch_counts = loss_based_retrain(anns, losses, num_of_clients, X_train_clients, Y_train_clients, previous_median_loss, no_of_epochs)\n","        average_epoch_count = np.average(epoch_counts)\n","        average_epoch_counts.append(average_epoch_count)\n","        print (f'> round {str(t+1)} average epoch count= {str(average_epoch_count)}')\n","\n","        anns[0].set_weights(average(t,anns))\n","\n","        end_of_loop_test_auc = calculate_auc(anns[0], X_test, Y_test)\n","        print (f'> round {str(t+1)} test auc= {str(end_of_loop_test_auc)}')\n","        end_of_loop_test_aucs.append(end_of_loop_test_auc)\n","\n","        weights = anns[0].get_weights()\n","\n","        previous_median_loss = np.percentile(losses, 50)\n","\n","        #Round_Metrics\n","\n","        #evaluation training metrics for each round\n","        round_training_metrics = calculate_training_metrics(anns[0], X_train_clients[1], Y_train_clients[1])\n","\n","        training_loss_per_round.append(round_training_metrics[0])\n","        training_acc_per_round.append(round_training_metrics[1] * 100)\n","        training_tp_per_round.append(round_training_metrics[2])\n","        training_fp_per_round.append(round_training_metrics[3])\n","        training_tn_per_round.append(round_training_metrics[4])\n","        training_fn_per_round.append(round_training_metrics[5])\n","        training_precision_per_round.append(round_training_metrics[6] * 100)\n","        training_recall_per_round.append(round_training_metrics[7] * 100)\n","        training_auc_per_round.append(round_training_metrics[8])\n","        training_prc_per_round.append(round_training_metrics[9])\n","\n","        print(\"\")\n","        print (f'> round {str(t+1)} final model training loss_metric= {str(training_loss_per_round)}')\n","        final_training_loss_per_round.append(training_loss_per_round)\n","\n","        print (f'> round {str(t+1)} final model training TP_metric= {str(training_tp_per_round)}')\n","        final_training_tp_per_round.append(training_tp_per_round)\n","\n","        print (f'> round {str(t+1)} final model training FP_metric= {str(training_fp_per_round)}')\n","        final_training_fp_per_round.append(training_fp_per_round)\n","\n","        print (f'> round {str(t+1)} final model training TN_metric= {str(training_tn_per_round)}')\n","        final_training_tn_per_round.append(training_tn_per_round)\n","\n","        print (f'> round {str(t+1)} final model training FN_metric= {str(training_fn_per_round)}')\n","        final_training_fn_per_round.append(training_fn_per_round)\n","\n","        print (f'> round {str(t+1)} final model training accuracy_metric= {str(training_acc_per_round)}')\n","        final_training_acc_per_round.append(training_acc_per_round)\n","\n","        print (f'> round {str(t+1)} final model training precision_metric= {str(training_precision_per_round)}')\n","        final_training_precision_per_round.append(training_precision_per_round)\n","\n","        print (f'> round {str(t+1)} final model training recall_metric = {str(training_recall_per_round)}')\n","        final_training_recall_per_round.append(training_recall_per_round)\n","\n","        print (f'> round {str(t+1)} final model training auc_metric= {str(training_auc_per_round)}')\n","        final_training_auc_per_round.append(training_auc_per_round)\n","\n","        print (f'> round {str(t+1)} final model training prc_metric= {str(training_prc_per_round)}')\n","        final_training_prc_per_round.append(training_prc_per_round)\n","        print(\"\")\n","\n","        #evaluation metrics for each round\n","        round_metrics = calculate_metrics(anns[0], X_test, Y_test)\n","\n","        loss_per_round.append(round_metrics[0])\n","        acc_per_round.append(round_metrics[1] * 100)\n","        tp_per_round.append(round_metrics[2])\n","        fp_per_round.append(round_metrics[3])\n","        tn_per_round.append(round_metrics[4])\n","        fn_per_round.append(round_metrics[5])\n","        precision_per_round.append(round_metrics[6] * 100)\n","        recall_per_round.append(round_metrics[7] * 100)\n","        auc_per_round.append(round_metrics[8])\n","        prc_per_round.append(round_metrics[9])\n","\n","        print (f'> round {str(t+1)} final model loss_metric= {str(loss_per_round)}')\n","        final_loss_per_round.append(loss_per_round)\n","\n","        print (f'> round {str(t+1)} final model TP_metric= {str(tp_per_round)}')\n","        final_tp_per_round.append(tp_per_round)\n","\n","        print (f'> round {str(t+1)} final model FP_metric= {str(fp_per_round)}')\n","        final_fp_per_round.append(fp_per_round)\n","\n","        print (f'> round {str(t+1)} final model TN_metric= {str(tn_per_round)}')\n","        final_tn_per_round.append(tn_per_round)\n","\n","        print (f'> round {str(t+1)} final model FN_metric= {str(fn_per_round)}')\n","        final_fn_per_round.append(fn_per_round)\n","\n","        print (f'> round {str(t+1)} final model accuracy_metric= {str(acc_per_round)}')\n","        final_acc_per_round.append(acc_per_round)\n","\n","        print (f'> round {str(t+1)} final model precision_metric= {str(precision_per_round)}')\n","        final_precision_per_round.append(precision_per_round)\n","\n","        print (f'> round {str(t+1)} final model recall_metric = {str(recall_per_round)}')\n","        final_recall_per_round.append(recall_per_round)\n","\n","        print (f'> round {str(t+1)} final model auc_metric= {str(auc_per_round)}')\n","        final_auc_per_round.append(auc_per_round)\n","\n","        print (f'> round {str(t+1)} final model prc_metric= {str(prc_per_round)}')\n","        final_prc_per_round.append(prc_per_round)\n","\n","        print(np.shape(weights))\n","\n","    federated_ann = anns[0]\n","    federated_ann.summary()\n","\n","    average_epoch_count = np.average(average_epoch_counts)\n","    print (f'> average epoch count= {str(average_epoch_count)}')\n","\n","    return federated_ann, average_training_aucs, end_of_loop_test_aucs, average_epoch_counts, clients_metrics, final_loss_per_round, final_tp_per_round, final_fp_per_round, final_tn_per_round, final_fn_per_round, final_acc_per_round, final_precision_per_round, final_recall_per_round, final_auc_per_round, final_prc_per_round, training_clients_metrics, final_training_loss_per_round, final_training_tp_per_round, final_training_fp_per_round, final_training_tn_per_round, final_training_fn_per_round, final_training_acc_per_round, final_training_precision_per_round, final_training_recall_per_round, final_training_auc_per_round, final_training_prc_per_round"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1ybmsctLyy6"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xrBfcuKsl3zE"},"source":["# **Retarining and Evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNRjmQQIwOzV"},"outputs":[],"source":["def loss_based_retrain(anns, losses, num_of_clients, X_train_clients, Y_train_clients, previous_median_loss, starting_epochs):\n","    epoch_counts = starting_epochs * np.ones(num_of_clients)\n","    for i in range(num_of_clients):\n","        if losses[i] > previous_median_loss:\n","            retrain_count = 0\n","            epoch_count = starting_epochs\n","            original_loss = losses[i]\n","            new_loss = original_loss\n","            while new_loss > previous_median_loss:\n","                retrain_count += 1\n","                retrain_epochs = (starting_epochs - retrain_count+1) if starting_epochs > retrain_count else 1\n","                if epoch_count >= 3*starting_epochs:\n","                    break\n","                history = anns[i].fit(X_train_clients[i], Y_train_clients[i], epochs=retrain_epochs, batch_size = batch_size, shuffle=True, verbose=verbosity)\n","                new_loss = history.history[\"loss\"][-1]\n","                epoch_count += retrain_epochs\n","            epoch_counts[i] = epoch_count\n","\n","            ### average epoch count as teraining process causes increasing the number of epochs for rounds\n","            print (f'> model {str(i+1)} retrained, original loss= {str(original_loss)} , retrained loss= {str(new_loss)} epoch count {str(epoch_counts[i])}')\n","\n","    return anns, epoch_counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Ke4L4JpwUF1"},"outputs":[],"source":["def federated_learning_evaluation(num_of_clients):\n","    print (f'> {str(no_of_rounds)} ROUNDS {str(num_of_clients)} CLIENTS STARTED..........')\n","    federated_ann, average_training_aucs, end_of_loop_test_aucs, average_epoch_counts, clients_metrics, final_loss_per_round, final_tp_per_round, final_fp_per_round, final_tn_per_round, final_fn_per_round, final_acc_per_round, final_precision_per_round, final_recall_per_round, final_auc_per_round, final_prc_per_round, training_clients_metrics, final_training_loss_per_round, final_training_tp_per_round, final_training_fp_per_round, final_training_tn_per_round, final_training_fn_per_round, final_training_acc_per_round, final_training_precision_per_round, final_training_recall_per_round, final_training_auc_per_round, final_training_prc_per_round = federated_learning(num_of_clients)\n","    #pd.DataFrame(average_training_aucs).to_csv(\"./IID_evaluation/\"+ str(num_of_clients) + \"adaboost_training_aucs.csv\",\n","    #                                           header=False, index=False)\n","\n","    ## model training metrics saving\n","    #pd.DataFrame(training_clients_metrics).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"3- \"+ str(num_of_clients) + \"Clients_100Rounds_All_Training_Metrics.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_loss_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"4- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_loss_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_tp_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"5- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_tp_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_fp_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"6- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_fp_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_tn_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"7- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_tn_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_fn_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"8- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_fn_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_acc_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"9- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_acc_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_precision_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"10- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_precision_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_recall_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"11- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_recall_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_auc_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"12- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_auc_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_training_prc_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Training/\"+\"13- \"+ str(num_of_clients) + \"Clients_100Rounds_final_training_prc_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    ## model test metrics saving\n","    #pd.DataFrame(end_of_loop_test_aucs).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"1- \"+ str(num_of_clients) + \"Clients_100Rounds_test_aucs.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(average_epoch_counts).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"2- \"+ str(num_of_clients) + \"Clients_100Rounds_average_epoch_counts.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(clients_metrics).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"3- \"+ str(num_of_clients) + \"Clients_100Rounds_All_Metrics.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_loss_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"4- \"+ str(num_of_clients) + \"Clients_100Rounds_final_loss_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_tp_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"5- \"+ str(num_of_clients) + \"Clients_100Rounds_final_tp_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_fp_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"6- \"+ str(num_of_clients) + \"Clients_100Rounds_final_fp_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_tn_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"7- \"+ str(num_of_clients) + \"Clients_100Rounds_final_tn_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_fn_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"8- \"+ str(num_of_clients) + \"Clients_100Rounds_final_fn_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_acc_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"9- \"+ str(num_of_clients) + \"Clients_100Rounds_final_acc_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_precision_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"10- \"+ str(num_of_clients) + \"Clients_100Rounds_final_precision_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_recall_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"11- \"+ str(num_of_clients) + \"Clients_100Rounds_final_recall_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_auc_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"12- \"+ str(num_of_clients) + \"Clients_100Rounds_final_auc_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #pd.DataFrame(final_prc_per_round).to_csv(\"/content/drive/MyDrive/1- PhD/Experiment/Our code/Experiment2 - Federated Learning/Our_Code/3-last/results/2_Layers_10Clients_100Rounds/Test/\"+\"13- \"+ str(num_of_clients) + \"Clients_100Rounds_final_prc_all_rounds.csv\",\n","    #                                           header=False, index=False)\n","    #print(\"\")\n","    print (f'> {str(no_of_rounds)} ROUNDS {str(num_of_clients)} CLIENTS ENDED..........')\n","\n","#X_train_shares, Y_train_shares, X_test, Y_test = prepare_data()"]},{"cell_type":"markdown","metadata":{"id":"SR2FYm7W4Hxq"},"source":["# **Preprocess and Tokenize Data**"]},{"cell_type":"markdown","metadata":{"id":"qznaajl6JoYx"},"source":["**Columnskey:**\n","\n","count = number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF).\n","\n","\n","hate_speech = number of CF users who judged the tweet to be hate speech.\n","\n","\n","offensive_language = number of CF users who judged the tweet to be offensive.\n","\n","\n","neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n","\n","\n","class = class label for majority of CF users.\n","\n","    0 - hate speech\n","    1 - offensive  language\n","    2 - neither\n","\n","tweet = raw tweet text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPWKNMdWvte3"},"outputs":[],"source":["d = enchant.Dict('en_UK')\n","dus = enchant.Dict('en_US')\n","space_pattern = '\\s+'\n","giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n","        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n","mention_regex = '@[\\w\\-]+'\n","emoji_regex = '&#[0-9]{4,6};'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9GNfDn0vthw"},"outputs":[],"source":["#This is the original preprocess method from Davidson\n","def preprocess(text_string):\n","    \"\"\"\n","    Accepts a text string and replaces:\n","    1) urls with URLHERE\n","    2) lots of whitespace with one instance\n","    3) mentions with MENTIONHERE\n","    This allows us to get standardized counts of urls and mentions\n","    Without caring about specific people mentioned\n","    \"\"\"\n","    parsed_text = re.sub(space_pattern, ' ', text_string)\n","    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n","    parsed_text = re.sub(mention_regex, '', parsed_text)\n","    parsed_text = re.sub('RT','', parsed_text) #Some RTs have !!!!! in front of them\n","    parsed_text = re.sub(emoji_regex,'',parsed_text) #remove emojis from the text\n","    parsed_text = re.sub('…','',parsed_text) #Remove the special ending character is truncated\n","    #parsed_text = re.sub('#[\\w\\-]+', '',parsed_text)\n","    #parsed_text = parsed_text.code(\"utf-8\", errors='ignore')\n","    return parsed_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gJC-C-DvtlJ"},"outputs":[],"source":["def preprocess_clean(text_string, remove_hashtags=True, remove_special_chars=True):\n","    # Clean a string down to just text\n","    text_string=preprocess(text_string)\n","\n","    parsed_text = preprocess(text_string)\n","    parsed_text = parsed_text.lower()\n","    parsed_text = re.sub('\\'', '', parsed_text)\n","    parsed_text = re.sub('|', '', parsed_text)\n","    parsed_text = re.sub(':', '', parsed_text)\n","    parsed_text = re.sub(',', '', parsed_text)\n","    parsed_text = re.sub(';', '.', parsed_text)\n","    parsed_text = re.sub('&amp', '', parsed_text)\n","\n","    if remove_hashtags:\n","        parsed_text = re.sub('#[\\w\\-]+', '',parsed_text)\n","    if remove_special_chars:\n","        #parsed_text = re.sub('(\\!|\\?)+','.',parsed_text) #find one or more of special char in a row, replace with one '.'\n","        parsed_text = re.sub('(\\!|\\?)+','',parsed_text)\n","    return parsed_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LxC_NjvZv9VF"},"outputs":[],"source":["def strip_hashtags(text):\n","    text = preprocess_clean(text,False,True)\n","    hashtags = re.findall('#[\\w\\-]+', text)\n","    for tag in hashtags:\n","        cleantag = tag[1:]\n","        if d.check(cleantag) or dus.check(cleantag):\n","            text = re.sub(tag,cleantag,text)\n","            pass\n","        else:\n","            hashtagSplit = \"\"\n","            for word in splitter.split(cleantag.lower(),'en_US'):\n","                hashtagSplit = hashtagSplit + word + \" \"\n","            text = re.sub(tag,hashtagSplit,text)\n","    #print(text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6E-18Jps2Mx9"},"outputs":[],"source":["stemmer = PorterStemmer()\n","def stemming(text):\n","    \"\"\" Returns a list of stemmed tweets.\"\"\"\n","    stemmed_tweets = [stemmer.stem(t) for t in text.split()]\n","    return stemmed_tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwZK4cEH6VJ2"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/labeled_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QtrluqJ7y6m"},"outputs":[],"source":["tweets=df['tweet'].to_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OJfJss6a-fCG"},"outputs":[],"source":["#start_time = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxgATuHz8NaG"},"outputs":[],"source":["preprocessed_tweets = []\n","for t in tweets:\n","  preprocessed_tweets.append(preprocess(t))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0RDHHkeM8NdW"},"outputs":[],"source":["#preprocessed_tweets\n","clean_preprocessed_tweets = []\n","for t in preprocessed_tweets:\n","  clean_preprocessed_tweets.append(preprocess_clean(t))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6qMIi1uIeNx"},"outputs":[],"source":["#clean_preprocessed_tweets\n","stripped_hashtags_preprocessed_tweets = []\n","for t in clean_preprocessed_tweets:\n","  stripped_hashtags_preprocessed_tweets.append(strip_hashtags(t))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P61B-UWNaWwK"},"outputs":[],"source":["#stripped_hashtags_preprocessed_tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1678003227845,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"rw4mOIS7XjoG","outputId":"5ea52dc5-52b7-431e-941d-ea3f49428a84"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["24783"]},"metadata":{},"execution_count":40}],"source":["len(stripped_hashtags_preprocessed_tweets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ohmmF0FNmnE"},"outputs":[],"source":["stemmed_stripped_hashtags_preprocessed_tweets = []\n","for t in stripped_hashtags_preprocessed_tweets:\n","  stemmed_stripped_hashtags_preprocessed_tweets.append(stemming(t))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGdhFSmaTgYt"},"outputs":[],"source":["#stemmed_stripped_hashtags_preprocessed_tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1678003233809,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"jCuSqCdPTkWb","outputId":"da97c03d-fd74-4f38-af95-250dcf8aae25"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["24783"]},"metadata":{},"execution_count":43}],"source":["len(stemmed_stripped_hashtags_preprocessed_tweets)"]},{"cell_type":"markdown","metadata":{"id":"QX7dGeJI7Rvk"},"source":["**Tokenize data**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1678003234137,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"0Yevqg2FMgT0","outputId":"bcf61d00-dee6-4e2d-dcdf-a09bb16307d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["22853\n"]}],"source":["# get vocab size\n","t = Tokenizer()\n","#t.fit_on_texts(stripped_hashtags_preprocessed_tweets)\n","t.fit_on_texts(stemmed_stripped_hashtags_preprocessed_tweets)\n","vocab_size = len(t.word_index) + 1\n","print(vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2131,"status":"ok","timestamp":1678003236266,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"L39VJQyAM-6b","outputId":"e152c508-9bb0-4dd9-9df2-6d3ac67daf3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[73, 2, 414, 5, 982, 733, 59, 656, 35, 20, 1728, 26, 73, 2, 91, 5, 198, 156, 114, 4, 56, 3101], [177, 147, 8968, 6117, 89, 21, 2209, 147, 9, 11, 4, 841, 507], [797, 5, 182, 19, 2, 1, 8, 40, 192, 6, 345, 5, 14, 1075, 73, 45], [40, 65, 13, 2, 718], [4, 45, 5, 465, 59, 17, 318, 14, 573, 74, 15, 318, 14, 6118, 130, 4, 1, 69, 273, 15, 6, 97], [53, 4, 45, 33, 665, 8969, 5, 37, 1148, 8, 142, 21, 495, 34, 96, 19, 27, 9, 53], [53, 3, 63, 48, 33, 400, 35, 8, 90, 18, 246, 1, 233, 3, 41, 99, 209, 45, 61, 6119], [149, 23, 515, 16, 5, 180, 1, 107, 21, 263, 703, 77], [53, 26, 5, 318, 48, 28, 97, 1, 108, 26, 7, 7, 53], [53, 2371, 1581, 290, 8970, 1], [53, 8971, 12, 2, 1, 40, 1189, 416, 53, 55, 3, 294, 173, 2, 1514, 13, 1305, 251], [53, 3474, 1190, 1, 15, 1190, 1351, 53], [53, 37, 9, 7, 366, 49, 1818, 53, 447, 188, 61, 18, 798], [53, 89, 1, 12, 4, 101, 184, 7, 3, 13, 53], [53, 1, 28, 35, 102, 17, 53], [53, 1, 25, 346, 17, 27, 15, 53], [53, 1, 2054, 766, 53], [53, 1, 69, 58, 5, 64, 53], [53, 1, 28, 311, 102, 744, 340, 53], [53, 202, 1149, 26, 2, 89, 1, 53], [53, 291, 1, 75, 113, 17, 295, 53], [53, 2055, 7, 1, 13, 3475, 53], [53, 75, 5, 94, 39, 9, 266, 396, 53], [53, 19, 43, 7, 1, 29, 110, 249, 138, 53, 4, 4789, 496, 133, 6, 19, 798, 35], [53, 41, 97, 1, 1011, 1109, 18, 10, 8972, 1352, 53], [53, 50, 24, 767, 13, 2056, 676, 53], [53, 9, 57, 15, 167, 21, 53], [53, 3, 704, 7, 24, 18, 2372, 2813, 26, 3, 502, 7, 24, 2, 1515, 53], [53, 3, 87, 2, 4024, 1, 69, 19, 18, 8973, 53], [53, 3, 1049, 10, 169, 71, 3, 67, 1, 15, 10, 624, 53], [53, 3, 4025, 10, 206, 1, 10, 154, 1, 24, 4026, 53], [53, 278, 72, 23, 108, 6, 4, 206, 17, 34, 10, 206, 1, 118, 28, 1110, 53], [53, 31, 5, 46, 133, 7, 1012, 178, 24, 25, 242, 35, 53], [53, 31, 20, 1109, 46, 328, 5, 24, 1729, 53], [53, 23, 328, 27, 1150, 1, 15, 2, 1730, 21, 7, 26, 31, 5, 2, 1076, 95, 116, 2, 2565, 21, 7, 53], [53, 12, 7, 97, 1, 53], [53, 15, 46, 295, 6, 311, 2, 1, 102, 53], [53, 383, 563, 386, 92, 52, 97, 1151, 30, 1, 53], [53, 564, 345, 129, 9, 7, 1516, 16, 2, 1353, 53], [53, 13, 3476, 121, 11, 6120, 66, 29, 64, 39, 9, 53], [53, 734, 121, 43, 24, 534, 1077, 10, 8974, 53], [53, 247, 90, 34, 4, 9, 443, 53, 1517], [53, 417, 77, 89, 70, 17, 28, 8975, 89, 8976, 9, 112, 417, 6121, 142, 1658, 418, 13, 240, 112, 4790], [53, 1078, 35, 1078, 35, 9, 142, 53, 1152, 768], [53, 448, 2, 406, 16, 7, 24, 28, 4027, 13, 53], [53, 24, 12, 2, 863, 692, 53], [53, 705, 864, 16, 24, 79, 15, 2, 484, 123, 53], [53, 298, 657, 135, 13, 60, 2057, 154, 24, 7, 133, 6, 28, 19, 53], [53, 39, 1, 110, 884, 1930, 471, 76, 189, 21, 5, 53], [53, 39, 9, 13, 25, 7, 1049, 169, 48, 81, 133, 15, 53], [53, 66, 29, 302, 39, 25, 32, 39, 1, 53], [53, 78, 25, 340, 1354, 9, 149, 78, 46, 105, 44, 1, 53], [53, 5, 2210, 2, 1731, 53, 2211, 143, 1, 3, 311, 102, 554, 74, 2373, 6, 14, 8977, 274, 53], [53, 379, 1515, 6122, 39, 1, 64, 10, 451, 53], [53, 8978, 6123, 415, 6124, 130, 247, 16, 39, 186, 9, 8979], [53, 315, 25, 487, 304, 6, 208, 13, 1, 4028], [53, 8, 272, 719, 84, 534, 163, 2566, 15, 27, 2, 4791, 52, 2, 1, 5, 198, 58, 1732], [8980, 52, 223, 156, 14, 2, 917], [8981, 16, 2, 1, 424, 10, 8982, 8983, 3, 13, 22, 4792], [8984, 3, 131, 58, 12, 28, 169, 8, 19, 1263, 952, 160, 2567, 6125], [53, 3, 415, 452, 453, 261, 73, 209, 31, 66, 210, 44, 6, 799, 27, 1, 30, 8985, 800], [53, 23, 2, 19, 181, 36, 8986], [53, 275, 86, 438, 2, 24, 12, 342, 92, 53, 71, 277, 58, 22, 1216, 70, 170, 2, 24], [53, 8987, 53, 1659, 1659, 341, 1660, 1819], [53, 44, 97, 182, 191, 20, 1, 21, 166, 1, 160, 1264, 8988, 367], [53, 71, 42, 223, 316, 174, 234, 1, 6, 2, 178, 162, 5, 62, 97, 1661, 228, 51, 53, 3, 300], [53, 53, 1659, 1659, 8, 341, 508], [53, 8989, 119, 2, 354, 26, 58, 39, 8990, 68, 354, 55], [53, 1, 19, 42, 53, 485, 604, 28, 2058, 33], [53, 19, 355, 8991, 91, 1, 30, 8992, 222, 5, 333, 168, 983, 1355], [53, 85, 4, 2568, 1217, 8993, 52, 72, 40, 65, 13, 801, 128], [53, 4793, 8994, 2212, 53, 7, 68, 643, 1], [53, 170, 8995, 17, 24, 4026, 88, 2, 1306, 8996], [53, 8, 155, 87, 6, 94, 7, 327, 3, 33, 448, 140, 7, 1, 33, 121, 4, 247, 529, 1931], [53, 80, 19, 8997, 32, 78, 60, 1932, 842, 104, 91, 466, 12, 164, 53], [53, 260, 269, 8998, 53, 4029, 22, 12, 1933, 2814], [53, 3, 46, 45, 2374, 148, 4794, 55], [53, 42, 182, 204, 2, 3477, 18, 4, 6126, 8, 86, 148, 57, 31, 7, 25, 47, 18, 84, 193, 6, 28, 60, 8999, 1662, 456, 340, 9000], [53, 53, 984, 1013, 984, 3478, 984, 1, 55], [53, 574, 81, 89, 59, 4, 9001, 188, 34, 73, 2, 265, 632, 35, 2, 25, 124, 9002, 53], [53, 4, 488, 18, 9003, 53, 52, 2, 24, 27, 48, 1356, 76, 1357], [53, 1, 14, 67, 6, 208, 13, 25, 37, 89, 7, 45, 46, 9004, 34, 25, 208, 13, 1820], [53, 28, 4030, 1, 53, 1659, 1659], [53, 2375, 23, 3479, 49, 212, 9005, 1663, 53, 221, 40, 2, 9], [53, 422, 9006, 2213, 516, 14, 2, 291, 1, 4795, 1358, 44, 6, 113, 17, 71, 15, 197, 21, 50], [53, 3480, 9007], [53, 104, 509, 10, 175, 211, 147, 9008, 15, 407, 110, 356, 55], [53, 22, 1, 47, 37, 2376, 53, 1446, 2059, 9009], [53, 3, 132, 3102, 80, 368], [53, 9010, 52, 2, 918, 251, 5, 63, 113, 52, 2, 953], [53, 243, 457, 6127, 267, 80], [53, 38, 174, 826, 113, 42, 7, 42, 44, 2569, 53, 22, 1, 87, 6, 61], [53, 53, 7, 25, 47, 119, 7, 9, 1821, 286, 447, 55, 1050, 9011, 25, 121, 1050, 9012], [53, 57, 118, 78, 161, 183, 1582, 235, 1, 58, 31, 36, 139, 70, 4031, 26, 6128], [53, 4796, 165, 404, 22, 148, 178, 37, 3, 63, 61, 4797, 8, 45, 53, 5, 165, 192, 9013, 10, 312], [53, 61, 108, 6, 261, 249, 127, 138, 130, 4, 9, 69, 2377, 4798], [53, 18, 10, 193, 6, 19, 80, 1, 53, 17, 73, 2, 1079, 213, 206], [53, 71, 107, 5, 105, 316, 17, 4799, 3, 29, 44, 2, 347, 144], [53, 31, 9014, 317, 229, 35, 27, 625, 4800, 9, 23, 48, 84, 228, 6129, 497, 3, 1051, 13, 13, 885, 9015], [53, 71, 133, 76, 9016, 2815, 24], [53, 6130, 22, 25, 53, 9017, 67, 13, 21, 60, 2214, 9018], [53, 77, 5, 62, 3, 47, 1218, 7, 1080, 45, 6, 5, 26, 5, 47, 61, 9019, 2054], [53, 100, 17, 70, 2, 535, 175, 102, 9020, 1447, 37, 3, 266, 28, 11, 186, 9021, 1, 29, 843, 17, 361], [53, 3103, 1448, 12, 33, 98, 919, 6, 61, 392, 144, 21, 954, 9022], [53, 4801, 1518, 6131, 34, 40, 29, 87, 6, 208, 13, 2, 9, 33, 426, 40, 9023, 9024, 1449], [53, 44, 68, 334, 275, 12, 6132, 165, 130, 44, 9, 1153, 53], [53, 24, 735, 2570, 4032, 4032, 9025], [53, 536, 54, 305, 9026, 720, 53, 110, 27, 32, 212, 104, 2060, 408, 11, 4, 397], [53, 57, 582, 6, 76, 9027, 4802, 952, 36, 41, 920, 8, 1014, 6, 4, 234, 13, 2, 9028, 1], [53, 23, 4, 1, 550, 677, 2378, 53, 583], [53, 20, 19, 315, 9029, 917, 555, 54, 21, 769], [53, 4, 19, 14, 329, 27, 39, 952, 357, 62], [53, 78, 242, 9030, 70, 17, 1], [53, 3, 90, 2, 584, 9031, 409, 16, 1664], [53, 41, 1, 11, 4, 706, 34, 3, 29, 182, 9032, 678, 12, 693, 20, 503, 292], [53, 1519, 658, 21, 4, 2379, 53, 22, 12, 162, 4, 64, 192], [53, 141, 185, 73, 1, 3, 29, 19, 27, 9033], [53, 40, 109, 191, 17, 7, 544, 30, 686, 205, 32, 3, 222, 72, 47, 757, 9034, 55], [53, 23, 98, 570, 95, 8, 23, 2, 264, 6133, 37, 23, 2571, 8, 44, 9035], [53, 9036, 18, 4033, 692, 317, 372, 89, 6134, 3, 58, 7, 24, 45, 155, 921], [53, 2380, 1450, 4803, 73, 64, 1219, 2381, 4034, 26, 36, 9037, 1219, 2381, 6135], [53, 9038, 9039, 29, 175, 9040, 6, 17, 55], [53, 73, 358, 73, 4, 1583, 56, 82, 92, 18, 3, 222, 9041, 8, 7, 9042, 2816, 736], [53, 3, 210, 72, 393, 4035, 605, 17, 88, 104], [53, 22, 4, 296, 137, 1520, 359, 18, 77, 8, 255, 3104, 1934, 3481, 2572, 53, 2573], [53, 3, 222, 61, 21, 2, 203, 30, 1, 18, 10, 9043, 199], [53, 1584, 346, 79, 9044, 80, 9045, 1, 186, 556, 14, 9046], [53, 97, 234, 1, 146, 62, 15, 1585, 6, 22, 9047, 191, 5, 10, 1081, 82, 1586, 1265, 133, 9048, 9049], [53, 292, 335, 1733, 2061, 2215, 2374, 19, 221], [53, 39, 9, 14, 86, 1734, 266, 491, 36, 30, 53, 9050, 321], [53, 78, 1, 125, 43, 2817, 14, 58, 4, 247, 81, 53], [53, 78, 96, 61, 843, 74, 557, 22, 213, 74, 9051, 221, 272, 14, 143, 789, 9052, 9053, 719, 1, 558, 163, 45], [53, 3, 131, 44, 352, 27, 10, 306, 19, 50, 117, 11, 7, 24, 162, 3, 510, 9054, 148, 5, 41, 4036, 13, 19], [53, 31, 40, 605, 42, 27, 50, 387, 458, 194, 7, 9055], [53, 5, 2, 2062, 2063, 1521, 30, 9, 53], [53, 243, 1451, 1, 30, 25, 9056, 7, 1, 694, 35], [53, 168, 6, 471, 7, 1, 1452], [53, 183, 1, 14, 13, 23, 10, 373, 3105, 2574, 1, 5, 46, 357, 9057], [53, 25, 5, 62, 66, 9058, 2382, 6136, 9059, 3, 313, 43, 65, 433, 128], [53, 721, 23, 28, 459, 9060, 295, 34, 2, 666, 16, 25, 11, 26, 459, 865, 26, 171, 1, 27, 214, 265, 172, 9061], [53, 22, 427, 9062, 1220, 53, 23, 58, 22, 1153], [53, 3, 118, 436, 2, 9, 101, 218, 66, 452, 279, 7, 66, 359, 11, 922, 6137, 9063, 1453, 4, 575, 11, 4, 250, 507], [53, 14, 419, 427, 98, 919, 6, 14, 2, 3106], [53, 120, 177, 863, 368, 202, 863, 1], [53, 100, 28, 551, 28, 665, 1218, 45, 3482, 866, 26, 19, 894, 280, 120, 252, 44, 43, 4037], [53, 1, 162, 42, 9064, 224, 4, 360, 8, 895, 162, 5, 132], [53, 31, 3, 29, 28, 10, 138, 249, 51, 80, 460, 123, 2, 89, 1, 23, 1446, 223, 644, 15, 102, 53, 9065, 2064], [53, 12, 1933, 2383, 34, 52, 415, 136, 9, 18, 170, 2, 9066], [53, 11, 155, 3107, 126, 156, 2, 492, 39, 9, 1522, 53, 128, 148, 2216, 9067], [53, 69, 67, 6, 28, 116, 1359, 11, 39, 89, 1587, 88, 53, 341, 1111, 8, 645], [53, 3, 301, 3, 47, 2, 1, 13, 10, 646, 9068, 53, 6138, 3, 394, 5, 58], [53, 31, 5, 472, 35, 73, 2, 534, 21, 923, 5, 49, 9069, 9070, 2, 24], [53, 63, 6139, 33, 28, 2, 178, 3483, 2217, 37, 39, 171, 1, 63, 9071, 28, 18, 15, 9072], [53, 139, 14, 626, 6, 955, 50, 985, 352, 42, 1, 30, 956, 1358, 13, 9073, 72, 4, 189, 69, 167, 287, 54, 16, 2818, 1449], [53, 136, 219, 9074, 3, 70, 76, 9, 334, 9075, 1930, 105, 14, 334, 7, 693, 36, 9, 10, 312], [53, 241, 4038, 1360, 473, 195, 5, 102, 2, 1361, 236, 162, 4, 19, 97, 3484, 9076], [53, 20, 48, 2, 91, 31, 5, 1191, 6, 155, 77, 73, 2, 368], [53, 425, 22, 534, 192, 257, 4, 45, 54, 16, 986, 10, 25, 679, 41, 60, 24, 10, 25], [53, 4804, 35, 4804, 35, 316, 15, 108, 35, 9077, 108, 162, 23, 82, 36, 420, 6140, 82, 4, 6141, 6138, 69, 364, 121, 7, 56], [53, 2575, 2575, 3485, 1665, 236, 1454, 9078, 4805, 9079, 55, 9080, 281], [53, 576, 15, 10, 206, 6142, 154, 1112, 26, 10, 9081, 1523, 12, 53, 221, 23, 304, 18, 7, 9, 4039], [53, 802, 537, 1735, 30, 6143, 22, 47, 99, 356, 6, 307], [53, 7, 162, 3, 28, 10, 190, 1736, 21, 14, 1455, 53, 286, 221, 9082], [53, 29, 41, 106, 21, 1, 6, 14, 896, 9083], [53, 107, 18, 271, 1524, 3486, 6144, 22, 12, 96, 4, 570, 95, 3108], [53, 39, 9, 46, 334, 26, 43, 36, 46, 53, 1737, 26, 454, 85, 357, 2576, 67, 76], [53, 321, 5, 2577, 176, 86, 23, 1221, 73, 2384, 191, 97, 77, 71, 239, 106, 40, 801, 40, 47, 10, 83, 241, 2385, 9084, 680, 9], [53, 1015, 24, 1, 156, 924, 15, 18, 4, 9085], [53, 242, 80, 1, 30, 35, 53], [53, 1192, 1151, 11, 865, 8, 405, 1523, 155, 707, 8, 5, 9, 75, 110, 262, 4806], [53, 5, 64, 39, 9, 127, 88, 169, 827, 329, 39, 3487], [53, 2, 334, 1, 82, 4, 9086, 461, 803, 1222, 12, 13, 258, 2, 9087, 9088, 9089, 13, 17, 129, 116, 55], [53, 1016, 1266, 1016, 917, 7, 2, 488], [53, 159, 925, 12, 99, 112, 53, 1082, 19, 538, 21, 159, 4807], [53, 301, 3, 124, 2, 482, 53, 5, 41, 32, 4, 9, 205], [53, 19, 987, 1, 63, 5, 867, 53], [53, 1, 4808], [53, 53, 242, 35, 9090, 290, 17, 24, 21, 4040, 23, 93, 9091, 5, 49, 93, 9092, 420, 1738, 92], [53, 128, 19, 2218, 952, 410, 240], [53, 180, 517, 9, 1666, 4809, 53, 148], [53, 271, 4810, 6, 21, 98, 1588, 18, 4, 1193, 7, 6145, 103, 14, 54, 9093, 9094], [53, 296, 137, 1520, 359, 18, 77, 8, 255, 3104, 1934, 3481, 2572, 26, 367, 9095], [53, 4041, 955, 155, 213, 28, 102, 4, 1194, 56, 30, 9096, 6146], [53, 1589, 48, 1739, 55, 9097, 9098, 47, 4, 237, 1935, 26, 1739, 4811, 9099, 345, 13, 2, 1, 18, 886, 129, 2578], [53, 1667, 3, 90, 202, 111, 53, 22, 12, 85, 116, 202, 111, 8, 158], [53, 71, 222, 42, 58, 22, 6, 17, 368, 6147], [53, 53, 2, 633, 1819, 722, 897, 3, 118, 735, 84, 537, 508, 288, 52, 4812], [53, 53, 64, 4042, 177, 545, 1221, 358, 508], [53, 53, 643, 1819, 27, 341, 508, 8, 9100], [53, 336, 1154, 3, 146, 359, 27, 4, 894, 2579, 18, 4, 275, 3, 150], [53, 53, 3, 41, 1307, 55], [53, 22, 154, 186, 12, 1075, 4, 45, 54, 16, 4813, 61, 108, 6, 1658, 770, 1], [53, 6148, 196, 30, 74, 9101, 86, 24, 149, 6148, 9102, 12, 13, 530, 24], [53, 34, 57, 31, 52, 428, 277, 1668, 4, 183, 1, 129, 5, 4814, 30, 456, 14, 203], [53, 1, 487, 204, 10, 1822, 31, 97, 4815, 53, 325, 85, 3, 64, 1518, 2064], [53, 23, 515, 16, 1, 72, 3, 65, 9103, 53, 25, 5, 180, 483, 255, 926, 758, 8, 9104, 3109], [53, 546, 95, 20, 9105, 600, 105, 94, 267, 6, 4816, 396, 53], [53, 6149, 681, 5, 9106], [53, 523, 6150, 9107, 22, 3110, 47, 383, 868, 18, 4, 4817, 9, 53, 4818, 34, 11, 96, 45, 18, 667, 3110], [53, 169, 28, 2819, 8, 1, 28, 9108], [53, 3, 46, 105, 297, 2, 1, 37, 2065, 27, 36, 1590, 23, 2065, 27, 588], [53, 1362, 271, 81, 248, 34, 100, 48, 627, 53, 3, 1456, 6, 58, 22, 1155, 1936], [53, 9109, 577, 23, 48, 2, 3111, 53, 425], [53, 111, 156, 191, 17, 57, 23, 1223, 9110, 40, 2, 89, 668, 1, 55], [53, 9111, 12, 2, 2218, 8, 2, 9112, 34, 51, 577, 52, 427, 2, 1224, 13, 20, 2580, 3112, 695], [53, 4819, 337, 21, 3488, 56, 2581, 6151, 7, 229, 47, 474, 364], [53, 3, 195, 1267, 9113, 6152, 5, 515, 14, 2066, 8, 61, 6, 376, 9], [53, 139, 316, 804, 158, 173, 10, 844, 53], [53, 66, 29, 64, 39, 9, 53], [53, 31, 80, 77, 75, 44, 2067, 5, 2, 802, 669, 1, 30, 1590], [53, 3, 86, 884, 2068, 3, 502, 5, 47, 53, 29, 14, 2, 24, 8, 3113, 1452, 1821], [53, 1083, 22, 175, 27, 20, 443, 9114], [53, 3, 90, 38, 1740, 113, 5, 374, 9115, 9, 4820, 9116, 29, 429, 126, 24, 6, 9117, 5, 2, 9118], [53, 9119, 6153, 136, 957, 4043, 211, 201, 828, 6153, 188, 957, 24, 53, 251], [53, 38, 1, 987, 18, 4, 9120, 17, 3114, 97, 11, 97, 148, 2582], [53, 9121, 22, 12, 9122, 26, 357, 1823, 84, 1], [53, 9123, 16, 9124, 1457, 12, 708, 123, 120, 1225, 37, 78, 202, 4044, 12, 56, 9125], [53, 39, 1, 29, 279, 36, 33, 137, 7, 9126], [53, 15, 424, 2, 288, 21, 5, 6, 258, 17, 34, 3, 47, 869, 11, 4, 6154, 9127, 325, 1, 11, 143, 329, 1308, 1669], [53, 898, 154, 845, 7, 103, 14, 1525, 123, 9128, 367, 116, 9129, 18, 4, 845, 53, 9130, 2, 181], [53, 9131, 325, 4821, 5, 771, 695], [53, 9, 1670, 1226, 263, 9132, 1226, 42, 71, 6, 28, 1189, 7, 32, 3, 62], [53, 1, 75, 867, 34, 62, 71, 6, 249, 138, 9133, 1017, 6, 4, 68, 7, 63, 58, 398], [53, 203, 9, 28, 9134, 55], [53, 53, 219, 374, 9135, 68, 772, 76, 6, 14, 334], [53, 802, 1, 3115], [53, 321, 23, 515, 16, 25, 9136, 1518, 2069, 927, 7, 1, 46, 43, 409, 16, 9137, 805], [53, 33, 140, 1458, 2578, 51, 4, 9138, 178, 29, 196, 52, 96, 48, 2, 1, 4045, 1156, 76, 9139, 55, 1, 19, 5], [53, 1084, 45, 3489, 9140, 47, 11, 159, 8, 4, 1018, 9141, 17, 6155, 18, 4, 1352, 9142], [53, 296, 29, 67, 6, 44, 352, 27, 10, 1661, 140, 3, 150, 13, 23, 168, 9143, 160, 6156, 9144, 104], [53, 410, 68, 16, 20, 253, 27, 22, 53, 410, 495, 1, 31, 5, 29], [53, 31, 97, 1, 156, 1, 1113, 40, 9145, 74, 33, 98, 589, 1], [53, 39, 2070, 9, 1265, 36, 9146, 34, 25, 430, 18, 53], [53, 75, 475, 59, 2, 1, 7, 46, 475, 133, 986], [53, 234, 9, 49, 21, 1937, 25, 7, 75, 806, 2, 112, 6157], [53, 128, 22, 1, 107, 9147, 11, 4, 4822, 13, 40, 59, 6, 19, 60, 45, 1452], [53, 10, 1081, 121, 52, 958, 9, 27, 84, 4823, 52, 121, 958, 12, 279, 8, 52, 64, 84, 646, 53], [53, 23, 807, 34, 6158, 131, 1049, 10, 169, 18, 9148, 9, 437], [53, 1019, 9, 14, 2820, 6, 32, 16, 263, 1590], [53, 53, 241, 221, 19, 7, 1], [53, 3116, 91, 33, 1014, 84, 9149, 6159, 6160, 16, 4, 9150, 128, 56], [53, 6161, 1526, 4046, 3490, 524, 79, 235, 1309, 1824, 9151, 2, 529, 8, 559, 3117, 439, 53, 52, 2, 1], [53, 380, 57, 3, 560, 44, 1527, 106, 21, 20, 9152, 9153, 411, 24], [53, 497, 53, 643, 1660, 1819], [53, 3, 46, 958, 43, 1, 31, 5, 588, 5, 588, 53], [53, 169, 101, 1268, 4, 1310, 291, 952], [53, 103, 105, 14, 1311, 1, 36, 29, 100, 111, 829, 74, 396, 4824, 9154], [53, 4825, 236, 552, 1528, 1528, 6162], [53, 23, 48, 214, 1114, 9155, 9156, 4825, 236, 6163], [53, 39, 9, 12, 4826], [53, 5, 46, 182, 152, 14, 2, 2583, 1664, 2219, 9157, 647], [53, 1312, 37, 172, 595, 205, 9158, 410, 50, 29, 14, 43, 83], [53, 3, 454, 31, 4, 77, 7, 502, 235, 6, 899, 177, 21, 2, 467, 11, 9159, 136, 6164, 40, 9160, 471, 677, 21, 181], [53, 221, 1, 221, 1, 79, 17, 9161, 9162, 485, 9163, 9164, 9165, 790, 9166, 6165, 9167], [53, 9168, 11, 808, 50, 2821, 117, 123, 50, 24, 9169, 15, 101, 117], [53, 118, 5, 96, 64, 17, 38, 23, 43, 1363, 379, 8, 6166, 988, 183, 269, 809], [53, 78, 107, 539, 4, 9170, 3, 46, 107], [53, 104, 368], [53, 447, 23, 18, 10, 9171, 3, 29, 197, 22, 3491, 100, 466, 22, 104, 35, 296, 197, 9172], [53, 53, 22, 1660, 1819, 118, 28, 15], [53, 53, 923, 47, 1157, 185, 158], [53, 6167, 96, 9173, 4035, 9174, 35, 6, 826, 27, 959, 405, 959, 11, 7, 1, 9175], [53, 3, 64, 119, 24, 55, 3, 105, 28, 392, 55, 3, 63, 119, 7, 45, 1115, 1821, 8, 1269], [53, 53, 43, 6168, 9, 530, 769, 9176, 9, 578, 13, 9177], [53, 43, 6168, 9, 530, 769, 3118], [53, 1364, 9178, 14, 28, 17, 259, 73, 4827, 286, 447, 3, 137, 7, 9, 230, 10, 2386], [53, 80, 1, 12, 1192, 1151, 10, 1, 2, 3119, 53], [53, 3, 63, 498, 20, 1, 27, 43, 806, 9179], [53, 8, 31, 5, 46, 2, 9, 28, 35, 54, 10, 9180], [53, 1313, 611, 886, 2220, 989, 220, 96, 1150, 9181, 9182, 6169, 47, 4, 91], [53, 39, 4828, 1, 49, 32, 9183, 1195, 9184, 55, 32], [53, 887, 64, 15], [53, 9185, 496, 15, 107, 5, 141, 1, 4047, 6170, 3492, 53, 2822, 6171], [53, 18, 10, 193, 6, 19, 20, 1, 53, 425, 9186], [53, 2, 9187, 1365, 71, 52, 547, 1938, 1738, 4, 9188, 9189, 53], [53, 53, 3493, 126, 830, 65, 37, 342, 612, 53, 53, 58, 3, 146, 28, 2071, 830, 18, 22, 1], [53, 53, 15, 1310, 29, 14, 2, 6172, 475, 59, 14, 1459, 53, 290, 9190], [53, 85, 22, 1, 4829, 1227, 53, 50, 1366, 427, 1314, 4, 247, 4048, 205], [53, 394, 48, 14, 43, 1, 53, 960, 680], [53, 148, 1196, 146, 1367, 10, 6173, 4830, 14, 9191, 5, 41, 7, 961, 1270, 484, 39, 1, 4049], [53, 23, 70, 9192, 10, 504, 2374, 773, 340, 5, 4050, 9, 33, 13, 709, 1460, 5], [53, 3120, 181, 4831, 5, 64, 307], [53, 3, 456, 14, 2, 1, 5, 49, 3121, 9193, 22, 85, 66, 156, 990], [53, 142, 4051, 65, 6, 2221, 11, 4, 1529, 16, 4, 9194], [53, 29, 114, 4832, 16, 2, 417, 9195, 9196, 9197], [53, 243, 457, 1, 25, 53, 267, 3494], [53, 611, 62, 7, 247, 9, 266, 19, 27, 5, 426, 5, 46, 41, 9198, 304, 634, 928], [53, 4833, 45, 2222, 810, 9199, 34, 5, 810, 125, 613, 774, 218, 147, 97, 2067, 810, 153], [53, 2584, 3, 121, 7, 215, 9200, 11, 4, 215, 1461, 3, 47, 1271, 509, 15, 361, 6127], [53, 3, 101, 929, 112, 25, 11, 4, 231, 149, 2, 24, 25, 12, 152, 929, 17, 117, 4806, 870, 9201, 74, 9202], [53, 10, 24, 96, 9203, 4834, 256, 1116, 77, 3122], [53, 30, 491, 12, 68, 4, 2387, 2823, 3495, 53, 3, 491, 2, 77, 18, 4, 809, 26, 40, 41, 214, 3, 46, 28, 24, 21, 2, 449], [53, 221, 2585, 49, 37, 209, 165, 5, 19, 4835, 3, 94, 7, 20, 214, 59, 1305], [53, 579, 369, 12, 35, 27, 991, 1, 27, 9204, 333, 44, 1368, 930, 917, 9205, 13, 9206, 54, 135], [53, 116, 2, 3496, 60, 1, 87, 6, 271, 11, 53, 4, 440, 163, 28, 117, 4, 19, 459, 305, 231], [53, 3, 90, 38, 177, 2223, 7, 36, 44, 1, 53, 251], [53, 97, 312, 54, 116, 96, 72, 78, 29, 119, 4836, 27, 2, 344, 231], [53, 23, 2, 900, 30, 368, 6174, 87, 6, 400, 11, 2, 1825], [53, 52, 2, 9, 3, 4837], [53, 17, 8, 1939, 1265, 133, 525, 6175, 21, 143, 696, 9207, 45, 1, 1741, 271, 54, 143, 606], [53, 1, 555, 36, 25, 142, 38, 52, 28, 1020, 3123, 34, 31, 2, 25, 61, 6, 1197, 74, 4, 2388, 15, 2, 511, 4838, 53], [53, 85, 58, 10, 228, 90, 986, 140, 5, 2, 590, 2072], [53, 43, 64, 21, 39, 19, 3487, 6176], [53, 341, 1734, 53, 643, 73, 19, 1660, 6177, 3, 118, 64, 6, 563, 170, 8, 84, 9208], [53, 3497, 53, 9209, 35, 1660, 6177, 19, 1530], [53, 39, 1, 64, 9210], [53, 3, 2824, 194, 15, 21, 59, 954, 74, 1369, 710, 37, 200, 3, 4808, 2825, 149, 220, 144, 251], [53, 57, 198, 3, 226, 10, 534, 9211, 1826, 24], [53, 53, 1659, 9212, 643, 1021, 177, 6178], [53, 42, 94, 4, 148, 310, 1013, 53, 38, 5, 791, 1, 70, 2389, 5, 745, 79, 17], [53, 9213, 12, 10, 443, 4839, 3, 86, 52, 37, 6179, 52, 109, 1591, 695, 52, 2, 141, 9], [53, 546, 352, 1531, 6180, 22, 57, 42, 79, 19, 4, 931, 459, 1], [53, 12, 723, 614, 6, 14, 342, 5, 2826, 601], [53, 68, 91, 56, 12, 246, 91, 3124, 53], [53, 3, 29, 41, 43, 4840, 89, 1, 12, 4, 101, 184, 3, 3498, 9214], [53, 9215, 2816, 4, 1309, 67, 986, 3, 150, 15, 604, 28, 127, 10, 312, 43, 1592], [53, 274, 1022, 1052, 2827, 120, 1, 9216], [53, 15, 17, 9, 15, 17, 917, 9217], [53, 11, 9218, 66, 79, 76, 9219, 11, 6181, 66, 79, 76, 9220, 32, 1117, 770, 36, 44, 132, 1370, 73, 2, 282], [53, 23, 152, 346, 7, 1, 16, 2, 1195, 9221, 5, 9222, 29, 308], [53, 90, 38, 1, 122, 8, 157, 5, 11, 4, 9223, 1, 23, 1532, 6, 1228, 157, 17, 11, 4, 9224, 53, 962, 4841, 931], [53, 6182, 379, 136, 122, 6, 2223, 7, 95, 9225, 1351, 11, 84, 476, 4842, 53, 736], [53, 78, 398, 9226, 1452, 46, 1118, 2, 1, 932, 55], [53, 53, 114, 17, 21, 2, 498, 2582, 1659, 1659], [53, 241, 10, 274, 3, 64, 3499, 9227, 32, 10, 1, 64, 17], [53, 7, 358, 3125, 45, 963, 3, 724, 4, 1, 47, 9228, 1158, 241], [53, 52, 58, 15, 117, 53, 43, 1, 251], [53, 36, 1742, 147, 24, 21, 164, 26, 52, 146, 389, 9229, 9230, 831, 4843], [53, 1085, 49, 355, 8, 4052, 49, 759, 8, 158, 49, 202, 5, 62, 7, 9231], [53, 400, 18, 10, 1371, 6183, 1371, 458, 95, 122, 6, 635, 2073, 737, 254, 53], [53, 34, 2, 25, 276, 14, 2, 25, 14, 2, 6184, 5, 372, 172, 144], [53, 2, 496, 98, 1119, 871, 103, 13, 6185, 53, 3, 195, 270, 2, 3126], [53, 23, 48, 110, 933, 4053, 9232, 306, 84, 6186, 6186, 872, 9233, 353, 11, 9234], [53, 2586, 4844, 41, 311, 82, 155, 412, 52, 47, 18, 11, 4, 1593, 8, 52, 330, 41, 127, 9, 130, 17, 11, 9235, 9236], [53, 648, 12, 2, 1, 53, 9237, 9238], [53, 172, 341, 1198, 24, 53, 19, 221], [53, 377, 4054, 9239, 9240, 12, 1462, 51, 9241, 9242, 53], [53, 5, 63, 79, 17, 9243, 149, 3, 227, 4, 9, 9244], [53, 3, 222, 105, 44, 2, 4845, 123, 2, 161, 138, 1118, 693, 3, 41, 2, 2828, 123, 4, 215, 9245, 241, 10, 274], [53, 194, 287, 122, 6, 687, 27, 17, 13, 36, 44, 2, 138, 8, 428, 19, 60, 24, 6187, 3, 90, 38, 1, 58, 7], [53, 8, 366, 441, 11, 775, 19, 670, 91, 58, 57, 5, 131, 58, 36, 29, 373, 5, 298, 31, 36, 9246, 49, 5, 144], [53, 6188, 95, 205, 53], [53, 10, 24, 789, 13, 2829, 53, 9247], [53, 38, 186, 992, 706, 17, 126, 56, 1827, 53], [53, 1229, 1, 589, 986], [53, 6189, 155, 1, 227, 173, 7, 3106, 1517, 6190], [53, 53, 53, 3, 300, 31, 1312, 122, 81, 6, 17, 9248, 9249, 53, 24], [53, 5, 1, 14, 1463, 6, 14, 364, 9250, 5, 46, 105, 9251], [53, 888, 680, 917, 2074, 680, 233], [53, 3500, 2, 144, 53, 51, 577, 3, 63, 70, 2, 3127, 873], [53, 272, 176, 18, 134, 39, 24, 30, 25, 585, 540, 6, 90, 53], [53, 846, 53, 52, 12, 11, 508, 2056], [53, 9252, 6191, 1159, 53, 832, 1, 9253], [53, 234, 1, 1461, 53], [53, 488, 57, 6192, 1, 216, 22, 385, 53, 128], [53, 19, 125, 263, 8, 88, 66, 2587, 917, 4055], [53, 66, 896, 13, 15, 4, 2588, 115, 53, 1594], [53, 151, 421, 7, 161, 1, 833, 8, 266, 110, 150, 370, 59, 1732, 1828], [53, 22, 12, 37, 19, 341, 53, 64, 17, 60, 4846, 1660], [53, 78, 171, 30, 25, 14, 37, 1160, 6, 44, 319, 78, 669, 73, 19, 73, 4827, 9254, 129, 9, 354, 776], [53, 3, 63, 227, 80, 1, 173, 2, 9255], [53, 3, 29, 302, 1019, 9, 2830, 273, 9256, 162, 3, 271, 51, 32, 10, 408, 1464, 565, 9257, 66, 556, 107, 6, 6181, 8, 512, 2075], [53, 773, 78, 272, 6193, 21, 4, 1743, 412, 2224, 6193, 433, 4035, 43, 116, 268, 127, 144], [53, 92, 42, 41, 57, 42, 67, 1, 934, 15, 53, 92, 22, 12, 2, 284, 460, 3, 118, 64, 6, 9258], [53, 207, 1372, 11, 20, 387, 9259, 18, 4056, 149, 3, 75, 94, 5, 51, 9260, 128], [53, 488, 53, 101, 4, 252, 27, 9, 72, 36, 29, 41, 894], [53, 23, 6194, 192, 737, 1, 1230, 53, 9261, 51, 15, 237], [53, 164, 2, 1, 8, 88, 5, 309, 7, 85, 66, 28, 314, 149, 5, 1161, 62, 38, 20, 152, 4847, 10, 746, 12, 697, 647], [53, 68, 16, 263, 12, 18, 692, 8, 15, 17, 34, 20, 96, 329, 53, 6195, 23, 2, 1, 601, 647], [53, 23, 150, 322, 172, 4821, 251], [53, 53, 53, 53, 300, 23, 6196, 6197, 6197, 747, 9262, 628], [53, 22, 12, 2, 573, 498, 74, 309, 1, 53, 57, 4, 19, 9263], [53, 9264, 8, 159, 4057, 53], [53, 32, 3, 94, 12, 3120, 1, 30, 18, 10, 186, 615, 4808, 3120, 32, 7, 40, 94, 9265, 3128], [53, 23, 59, 6, 431, 104, 6151, 364, 12, 431, 25], [53, 23, 37, 362, 368, 2224, 364], [53, 186, 12, 48, 2, 2831, 16, 1199, 3129, 5, 19, 6198, 15, 12, 38, 3501, 6199, 4058, 1940, 2225, 49, 32, 176, 9266], [53, 41, 2, 535, 1, 72, 36, 62, 17, 34, 272, 100, 4, 169, 81, 21, 17, 53, 8, 23, 1671], [53, 6200, 49, 21, 9267, 1], [53, 3, 273, 9268, 6, 34, 2390, 21, 50, 9269, 5, 560, 79, 17, 56, 1315], [53, 348, 4028, 57, 698], [53, 43, 262, 108, 3, 29, 134, 2, 19, 151, 262, 246, 368, 148, 217, 12, 505, 55], [53, 9270, 550, 53, 5, 41, 9, 82, 440, 6, 117, 58, 1533, 1162], [53, 168, 9271, 6, 258, 4, 699, 16, 7, 3115], [53, 1023, 1819, 417, 3130, 53, 39, 1660, 1819, 163, 3502, 118, 28, 15], [53, 286, 221, 280, 53, 19, 221, 643, 1660, 1819, 11, 341, 3130], [53, 547, 54, 2, 2832, 53, 3, 64, 1660, 2833, 19, 221], [53, 1819, 14, 1819, 53, 19, 1530, 3, 64, 1660, 1819, 4848, 341, 3502, 776], [53, 244, 213, 1, 12, 152, 14, 13, 5, 146, 1373, 5, 266, 1459, 17, 53], [53, 37, 341, 735, 15, 1, 2374, 19, 1530, 119, 7, 3502, 42, 537, 1534], [53, 78, 86, 1120, 24, 511, 82, 4, 1595, 221, 9272, 93, 9273], [53, 296, 486, 98, 9274, 294, 54, 11, 4, 2589, 72, 583, 22, 12, 37, 56, 7, 3, 75, 110, 477, 6, 6201, 53, 695], [53, 87, 39, 1111, 53, 19, 1530, 3, 64, 2, 4846, 1660, 1819, 545, 3503, 1111, 8, 1465], [53, 3, 29, 182, 1459, 275, 13, 4059, 7, 9275, 1, 25, 9276], [53, 53, 6202, 9277, 154, 184, 27, 9278, 3504, 69, 58, 5, 9279], [53, 252, 375, 22, 1466, 496, 53, 526, 162, 200, 5, 258, 7], [53, 834, 1744, 19, 53, 148, 84, 91, 24, 12, 28, 2, 6203], [53, 9280, 9281, 643, 1374, 6178, 3, 64, 170, 53, 643, 1660, 1659, 1659], [53, 777, 11, 164, 12, 9282, 60, 16, 5, 1, 87, 6, 1053, 7, 18, 97, 9283], [53, 31, 68, 16, 5, 1, 67, 60, 16, 10, 4849, 42, 63, 430, 17, 51, 9284, 932, 281], [53, 25, 413, 9, 54, 135, 9285, 487, 124, 121, 15, 9286], [53, 3131, 193, 6, 119, 2391, 8, 873, 1121, 2590, 591, 1272, 6204, 873, 3132, 1375, 467, 2590, 591, 2591, 19, 952], [53, 31, 10, 1941, 12, 4850, 9287, 130, 9288, 7, 2, 112, 30, 1, 2592, 116], [53, 589, 1, 7, 3, 64, 53, 9289, 37, 322], [53, 53, 128, 1, 41, 18, 60, 9290], [53, 84, 1, 43, 1, 680, 368], [53, 277, 52, 65, 13, 2, 368], [53, 778, 169, 48, 9, 53], [53, 75, 397, 2, 296, 29, 62, 57, 3, 6205, 30, 25, 53, 3505], [53, 53, 53, 23, 18, 10, 193, 53, 64, 2, 9291, 643, 1660, 9292], [53, 39, 4060, 315, 1, 29, 636, 71, 45, 9293], [53, 38, 2, 1, 29, 67, 2, 112, 401, 36, 33, 671, 1740, 1821, 649], [53, 4851, 1734, 1734, 11, 84, 9294, 3133, 163, 10, 150, 1], [53, 3, 67, 2218, 1942, 10, 3506, 9295, 26, 2, 9296, 9, 9297, 4061], [53, 260, 1376, 53], [53, 39, 9, 46, 9298], [53, 9299, 748, 1745, 53, 1, 5, 33, 672, 1672, 5, 203, 19], [53, 3, 216, 7, 1, 4852, 53, 1, 64, 4852], [1829, 43, 9300, 34, 73, 738, 73, 22, 1, 28, 613, 11, 1086, 863, 50, 1535, 103, 396, 1086, 835, 26], [1829, 24, 2, 115, 176, 4, 1377, 4853, 160], [3507, 7, 59, 2, 6206, 57, 277, 7, 196], [2211, 39, 1, 67, 2, 260, 3, 29, 67, 43, 9301], [3508, 1, 5, 456, 14, 9302], [4854, 3, 13, 14, 18, 20, 440, 9303, 43, 1, 5, 75, 14, 116, 218, 4, 606, 18, 7, 234, 8, 186, 121, 3, 46, 112, 31, 5, 58], [3509, 372, 13, 270, 2, 179, 2392, 168, 256, 499], [9304, 4, 2076, 187, 9305, 693, 2393, 52, 19, 10, 500, 4062, 427, 6207, 4, 77, 289, 9306, 420, 9307, 14, 2, 24, 163, 58, 15, 9308], [9309, 54, 917, 9310], [9311, 11, 4, 6208, 125, 2, 607, 952], [9312, 21, 10, 9313, 3, 64, 22, 4792], [3134, 3, 87, 2, 89, 1, 7, 2394, 130, 986, 318, 14, 4, 4855, 45, 9314, 182, 4063, 7, 71, 3, 14, 1596, 744], [9315, 4, 193, 66, 58, 929, 4856], [9316, 12, 4857, 2834, 37, 209, 22, 1, 65, 2226, 100, 192, 27, 673, 1931], [6209, 9317, 66, 220, 2227, 9318, 42, 62, 134, 4, 9319, 1316, 4, 9320], [9321, 72, 84, 6, 10, 9322, 586, 53, 9323, 368], [2835, 5, 442, 39, 9, 49, 48, 11, 488, 2395, 296, 9324, 27, 7, 3, 58, 442, 36, 49, 11, 488, 4, 9325, 9326, 894], [1673, 62, 43, 183, 1, 29, 62, 43, 291, 9327], [1673, 70, 17, 70, 5, 616, 11, 259, 27, 2, 25, 13, 9328, 4, 95, 6210, 49, 10, 443, 323, 123, 2593], [1673, 475, 59, 4, 25, 5, 94, 475, 59, 4, 25, 5, 29, 6211, 147, 143, 25, 172, 80, 1664], [1673, 5, 182, 134, 10, 24, 3135, 5, 176, 15, 926, 9329], [6212, 2, 2396, 149, 1, 23, 9330, 160, 323, 79, 9331, 2077, 4, 1523, 135], [6213, 1, 58, 171, 9332], [3510, 4, 24, 13, 2, 112, 25, 6214], [9333, 254, 100, 61, 211, 4, 9334], [9335, 65, 165, 27, 2, 1, 244, 6, 1732], [9336, 69, 279, 31, 5, 2, 9, 38, 20, 30, 65, 13, 22, 53], [9337, 155, 89, 1, 116, 12, 2, 25, 515, 16, 19, 4064], [9338, 418, 43, 9339, 91, 7, 1, 6166], [9340, 25, 37, 5, 636, 3, 87, 2, 656, 836, 69, 636, 23, 197, 218, 3, 131, 94, 10, 412, 9341], [993, 9342, 3, 70, 10, 373, 9343, 249, 10, 2078, 466, 1, 79, 17, 6215], [9344, 6216, 874, 27, 9345, 32, 3, 94, 12, 4, 3136, 6, 316, 9346, 11, 9347, 527, 6216, 6217, 8, 95, 4858], [4859, 17, 7, 45, 1, 5, 12, 595, 6218], [4859, 20, 30, 108, 6, 2397, 97, 172, 9348], [3511, 7, 3, 438, 15, 550, 3, 46, 214, 80, 650, 5, 2836, 17, 11, 4, 548, 43, 64, 917], [2228, 58, 5, 62, 10, 186, 9349, 1, 333], [4065, 5, 297, 10, 229, 44, 5, 297, 10, 9, 31, 3, 407, 341, 118, 36, 14, 37, 4790], [2079, 2, 1, 21, 167, 7, 917], [2079, 791, 6, 2, 120, 6219, 811, 9350, 160, 674, 9351], [2079, 131, 14, 10, 25, 34, 23, 33, 4860, 14, 84, 492, 1024, 53, 526, 571, 356, 30, 1, 91, 34, 7, 112, 45], [4814, 434, 994, 2, 6220, 994, 2, 6220, 306, 8, 2, 9, 8, 40, 2, 9, 15, 2, 358, 493, 16, 894, 9352, 3137, 416], [2398, 61, 65, 51, 7, 496, 16, 4, 91, 7, 592, 4, 3102, 77, 11, 9353, 2, 3111, 160], [2398, 24, 5, 96, 4066], [2228, 59, 66, 1122, 32, 212, 6221, 617, 8, 471, 76, 6, 6222, 74, 166, 1317, 1674, 37, 36, 63, 229, 9354], [2228, 2394, 130, 12, 1732, 1829, 1664], [2228, 42, 81, 6, 9, 133, 280, 163, 6223, 85, 5, 81, 6, 9, 133, 280, 163, 4067], [2228, 5, 58, 284, 368, 12, 1943], [296, 62, 10, 845, 537, 73, 19, 766, 83, 5, 29, 44, 6, 9355, 13, 9356, 68, 16, 4, 250, 184, 36, 65, 51, 12, 845, 381], [296, 195, 2, 6224, 9357, 2, 837, 9358, 9359, 4861, 847, 3138], [296, 79, 170, 10, 368], [296, 75, 806, 43, 9360, 34, 39, 1, 75, 806, 9361, 160, 1830, 2399], [296, 29, 778, 211, 9362, 3, 778, 211, 4856, 160, 6225, 9363], [296, 29, 64, 39, 9, 260, 15, 17, 8, 5, 4862], [296, 29, 110, 87, 2, 406, 16, 9364, 7, 1, 12, 257, 11, 155, 9365], [296, 29, 44, 894], [296, 592, 2, 154, 193, 6, 901, 5, 44, 6, 458, 20, 476, 9366], [296, 19, 90, 7, 1, 37, 209, 3, 131, 737, 50, 11, 4, 231, 88, 1200, 605, 4064], [296, 41, 2, 1, 644, 15, 102, 13, 3512, 9367, 4863, 5, 498, 657, 27, 20, 4068, 1, 5, 9368], [296, 41, 2, 746, 40, 273, 17, 139, 79, 287, 6143], [296, 380, 22, 12, 4, 264, 1, 9369, 6226, 12, 7, 2400], [296, 124, 2, 1, 7, 124, 2, 1, 124, 4, 1, 119, 9370, 160], [296, 44, 22, 9371, 40, 791, 34, 3, 96, 131, 1467, 50, 40, 266, 44, 352, 27, 17, 57, 2, 368, 9372, 9373, 415], [296, 566, 5, 47, 65, 21, 1468, 91, 368], [296, 293, 5, 29, 28, 214, 4864, 3, 101, 79, 5, 1, 1, 426, 3, 29, 62, 20, 226, 9374, 9375, 2594], [296, 33, 41, 2, 518, 292, 23, 2, 1, 4831], [296, 62, 7, 45, 1831, 9376, 5, 519, 33, 19, 4, 77, 16, 20, 651, 74, 5, 1597, 2, 1832, 66, 62, 20, 2, 711, 6227, 5, 9377], [296, 101, 14, 27, 1944, 435, 149, 374, 127, 9378, 7, 614, 6, 902, 263, 1], [296, 700, 338, 35, 54, 22, 1, 27, 10, 1833, 11, 10, 402, 8, 80, 402, 11, 10, 166, 9379], [296, 121, 3, 29, 13, 15, 15, 578, 13, 3513, 887, 1378, 71, 58, 5, 110, 62, 57, 7, 578, 3498], [296, 1460, 531, 71, 6, 119, 24, 8, 311, 10, 373, 6228, 296, 1460, 531, 71, 6, 119, 24, 6228, 226, 4, 629], [296, 168, 6, 472, 35, 13, 2, 670, 9380, 2229, 6229, 9381, 211, 9382, 3514, 6230, 9383, 105, 9384], [296, 363, 6, 865, 21, 2, 2230, 26, 510, 337, 125, 2, 9385, 5, 363, 6, 865, 73, 2, 1, 510, 337, 73, 2, 9386], [296, 103, 19, 42, 162, 42, 9387, 2080, 6231, 4865, 268, 6232, 26, 3139, 4069, 3, 9388, 2, 6233, 72, 38, 3, 47, 6234], [296, 1025, 35, 13, 9389, 1, 61, 108, 6, 618], [296, 118, 516, 5, 79, 17, 1, 130, 9390, 9391, 2081], [4070, 257, 18, 7, 24, 37, 9392], [4070, 935, 20, 9393], [584, 2, 1746, 30, 9394, 160, 725, 1123, 54, 6, 390, 230, 9395], [584, 1945, 4071, 6, 4, 887], [584, 2077, 5, 2, 154, 395, 8, 748, 5, 2, 154, 231, 5, 812, 3, 64, 1834, 2082, 1732, 9396, 1085, 1087, 51, 84, 352, 9397], [584, 1596, 13, 9398, 11, 4, 848, 39, 1, 3140, 17, 36, 75, 346, 4067], [584, 152, 633, 18, 20, 9399, 139, 936, 4072, 18, 56, 412, 1821], [584, 415, 20, 455, 1, 1018, 1598, 2837, 9400], [584, 549, 16, 84, 45, 91, 400, 84, 1, 30, 23, 1599, 35, 280, 53, 4073, 1014, 478, 246, 479, 9401], [584, 370, 3, 19, 80, 836, 34, 40, 109, 2595, 2, 1590], [6235, 2083, 1, 6236], [1379, 5, 64, 50, 88, 869, 80, 1, 37, 604, 176, 9402], [1379, 5, 81, 108, 6, 17, 5, 46, 28, 43, 3514, 17], [1379, 20, 2, 89, 1, 157, 20, 402, 35, 4074, 155, 77, 11, 4, 712, 192, 1835, 116, 402, 3141], [4075, 1469, 7, 1, 35, 11, 4, 4076, 8, 9403, 50, 30, 21, 268, 449, 9404, 9405], [3114, 10, 9406, 146, 14, 4, 171, 9, 9407], [296, 7, 98, 1376, 9408, 1600, 586, 52, 9409], [1360, 114, 2, 573, 9410, 6, 1273, 9411, 5, 62, 57, 1, 15, 408, 13, 5, 7, 70, 4, 177, 4866], [1360, 9412, 220, 42, 11, 4, 4867, 200, 42, 94, 1732, 324, 16, 2, 6237, 26, 1380, 83, 66, 62, 174, 2401, 359, 18, 4077, 9413, 12, 171], [1360, 105, 99, 713, 6, 1318, 2, 9414], [1360, 4, 9415, 9416, 391, 27, 2, 391], [9417, 2838, 20, 2, 2402], [4078, 253, 4, 190, 2839, 9418], [9419, 31, 20, 24, 12, 93, 34, 10, 779, 29, 13, 5, 380, 69, 146, 9420, 6238], [4868, 6239, 160, 4079, 9421, 3142, 1601, 9422, 418, 6, 1470, 933, 4080], [2231, 58, 628, 6240, 8, 3143, 17, 9423], [2231, 204, 353, 9424, 369, 200, 3, 33, 465, 2375], [9425, 1675, 17, 31, 23, 329, 6241, 317, 3144, 4081, 4869, 1, 21, 2840], [6242, 1381, 1054, 65, 13, 24, 53], [6242, 4, 9426, 4870, 49, 3515, 130, 10, 310, 749, 45, 12, 4082], [9427, 9428, 9429, 11, 9430, 6243, 4083, 16, 6244, 9431, 12, 827, 12, 9432, 1536, 147, 6245, 9433, 6246, 2232, 4871, 9, 645, 1676, 309, 6247, 9434], [6248, 40, 67, 6, 14, 127, 130, 20, 228, 74, 485, 40, 2, 185, 83, 5, 105, 62, 444, 5, 70, 50, 9435], [9436, 137, 4872, 8, 2841, 4084, 251, 219, 10, 2233, 49, 179, 26, 36, 28, 35, 51, 13, 4873, 8, 257, 126, 9437], [1163, 994, 168, 6, 79, 17, 2, 2084, 269, 32, 4, 4085, 107, 6, 86, 16, 15, 40, 200, 1191, 6, 2, 2085, 1149, 73, 2, 158, 9438], [1163, 734, 273, 17, 6, 113, 5, 6, 453, 4874, 148, 4875, 172, 624, 5, 6249, 48, 4086, 57, 15, 12, 368], [1163, 628, 49, 9439, 7, 48, 550, 140, 374, 2583, 539, 10, 9440], [1163, 186, 47, 9441, 903, 23, 99, 24, 6, 1124, 7, 3, 121, 15, 8, 92, 3, 67, 6, 208, 13, 3, 105, 121, 254], [2403, 77, 3, 46, 276, 14, 2404, 6, 70, 15, 15, 132, 926, 371, 4876, 3516, 84, 4877, 5, 11, 4, 108, 13, 2596, 1, 6229], [2403, 15, 5, 80, 3, 299, 6250, 3517, 10, 231, 18, 7, 104, 9442, 90, 4878], [3145, 9443, 4, 323, 16, 4, 1164, 55, 7, 1, 889, 298, 13], [2597, 156, 1087, 993, 1, 28, 2840, 2842, 374, 291, 8, 96, 67, 4, 4856], [2597, 14, 1160, 21, 24, 9444, 4087], [1600, 1, 53, 160, 6251], [1600, 1602, 8, 9, 333, 4879, 160, 306], [9445, 26, 2598, 2599, 96, 56], [4088, 503, 16, 7, 40, 33, 2, 554, 30, 370, 282, 46, 105, 41, 43, 1946, 110, 50, 591, 9446, 160], [3518, 2, 535, 16, 355, 1111, 44, 2405, 722, 250, 9447, 23, 309, 4089, 485, 4, 1316, 87, 6, 1226, 76, 60, 1537], [4880, 9448, 92, 12, 4, 106, 21, 4, 6252, 849, 201, 397, 35, 8, 72, 1600, 9449, 230, 4, 9450, 227, 4, 360, 173, 2, 179, 9451, 9452], [9453, 792, 10, 9454, 512, 80, 1, 489, 9455, 601, 4090, 14, 9456, 8, 23, 550, 27, 760], [53, 15, 21, 307, 333, 8, 267, 200, 2, 1663, 24, 33, 107, 1117, 10, 1747, 53], [9457, 9458, 471, 565, 6, 97, 9459, 10, 1], [9460, 5, 49, 68, 530, 917], [6253, 6254, 9461, 1748, 107, 9462, 7, 12, 4, 503, 1088, 18, 2, 1748, 6255, 496, 27, 546, 937, 6256, 386, 16, 2, 19, 1], [9463, 4, 2234, 761, 16, 378, 120, 91, 6257, 6, 258, 4, 9464, 3146, 6, 70, 9465, 2600, 813, 11, 388, 1351], [9466, 10, 931, 21, 2601, 301, 1026, 347, 8, 952], [4881, 7, 1538, 188, 1274, 268, 388, 44, 352, 18, 2, 544, 6218], [9467, 3, 1945, 2843, 6, 2, 850, 115, 43, 2, 850, 115, 12, 48, 2, 1664], [1749, 146, 1471, 35, 50, 24, 767, 205, 413, 6258, 1947, 24, 53], [1749, 121, 1319, 91, 5, 9468, 4, 9469, 2235], [1749, 47, 2, 1, 4882], [1749, 82, 1382, 37, 814, 41, 6, 58, 4, 3497, 959, 11, 212, 9470, 9471], [6259, 4, 19, 142, 1, 3, 62, 162, 5, 6260, 1677, 379, 3519], [2236, 52, 2, 93, 1231, 9472, 52, 96, 208, 13, 2, 9473], [2406, 14, 2, 24, 386, 8, 1750, 7, 4883, 173, 20, 373, 9474], [2406, 65, 263, 8, 61, 119, 60, 24, 5, 9475, 9476], [9477, 15, 344, 6, 1751, 85, 714, 4, 24, 38, 3, 62, 3, 63, 157, 10, 138, 11, 1732], [1678, 46, 280, 420, 7, 9, 9478], [1678, 77, 12, 3520, 65, 6261, 183, 26, 9479, 403, 51, 577, 40, 41, 2, 417, 872, 26, 2, 434, 4884], [1320, 1377, 632, 1077, 4, 548, 16, 4, 1948, 8, 4885, 120, 524, 190, 8, 202, 207, 12, 48, 9480], [1320, 591, 427, 190, 23, 2, 4048, 9481], [2237, 9, 46, 2395], [2237, 9, 176, 1275, 34, 3, 46, 4091, 1452], [2237, 2844, 1232, 1150, 1, 23, 48, 172, 125, 4067], [3147, 104, 6262, 1949, 73, 9482, 4886, 35, 459, 22, 368], [3147, 44, 60, 179, 30, 9483, 2064, 28, 9484], [3147, 44, 1836, 7, 6263, 12, 56, 2602, 276, 404, 4, 4887, 9485], [1539, 12, 21, 32, 4, 408, 7, 304, 4, 1, 25, 7, 90, 964, 206, 9, 66, 438, 65, 779, 66], [1539, 12, 21, 10, 179, 9486, 9487, 9488], [1539, 4888, 79, 21, 2, 3521, 4889, 57, 4, 286, 12, 2, 3521, 348, 7, 33, 2, 348, 5, 745, 3148, 9489], [9490, 590, 1383, 29, 3149, 17, 34, 20, 120, 30, 75, 81, 56, 59, 76, 149, 5, 18, 529, 1931, 202], [9491, 9492, 1, 3, 29, 53], [9493, 12, 6164, 1, 186, 12, 164], [6264, 1540, 9494, 11, 2, 190, 1932, 8, 3, 2603, 4, 68, 6, 9495, 160, 2838, 4092, 1055], [2080, 41, 10, 9496, 1, 9497, 9498, 6, 4093, 9499], [9500, 57, 58, 66, 44, 20, 2845, 548, 10, 2845, 1149, 2, 190, 9501, 7, 5, 118, 13, 6, 430, 218, 80, 3150, 500, 216, 42, 9502], [4890, 6, 44, 2, 504, 92, 32, 3, 41, 12, 1541, 3, 47, 541, 21, 2, 93, 77, 34, 40, 47, 172, 18, 4, 9503], [9504, 24, 53, 6265, 53, 1321, 24, 53, 647, 513, 53, 1312, 24, 9505], [9506, 805, 7, 85, 3, 1950, 42, 203, 1, 218, 78, 41, 60, 180, 1384, 815, 8, 4094, 9507], [6266, 11, 7, 1, 13, 25, 66, 216, 1732], [2086, 90, 158, 66, 90, 104, 8, 66, 90, 9508, 2221], [4095, 54, 135, 8, 220, 3480, 53, 201, 445, 688, 4891, 66, 13, 15, 11, 305, 4836], [3522, 1, 4096, 9509], [1378, 3, 58, 146, 1193, 5, 73, 2238, 462, 31, 20, 235, 178, 165, 130, 20, 887], [3151, 23, 328, 27, 2, 9, 3, 433, 50, 6, 4, 9510, 1080], [1472, 4, 19, 5, 1275, 3523, 1590], [1542, 111, 86, 315, 1603, 12, 550, 12, 2239, 307, 370, 3, 29, 67, 10, 1152, 386, 94, 201, 181, 294, 142, 4, 606, 555, 402, 98], [1542, 42, 14, 270, 2, 141, 1, 890, 5, 46, 2604, 368, 160, 9511, 306], [1542, 118, 3, 67, 6, 137, 27, 60, 887, 160, 9512], [1542, 118, 5, 131, 14, 4, 875, 4097, 52, 9513, 2574, 1], [1542, 118, 5, 67, 24, 18, 20, 234, 9514, 7, 2, 93, 9515, 4861], [9516, 6267, 2, 1, 21, 9517], [9518, 160, 28, 17, 539, 212, 3524, 115, 736], [6268, 5, 49, 2, 368, 367, 7, 330, 132, 6269, 393, 499, 5, 44, 6, 72], [3525, 627, 52, 136, 84, 2057, 154, 260, 77, 51, 4857, 1, 4, 851, 49, 1276], [9519, 136, 121, 11, 84, 324, 7, 4, 9520, 49, 84, 111, 8, 6270, 12, 84, 9521, 8, 4, 9522], [9523, 9524, 2846, 53], [2605, 1, 18, 4, 6271, 238, 512, 2, 9525, 160, 7, 965, 758, 6272, 1458], [2605, 63, 3, 9526, 20, 887], [2605, 995, 532, 13, 10, 9527, 6273, 6274, 2847, 368, 526], [2605, 779, 1664, 57, 47, 4, 68, 1355, 7, 450, 20, 575], [463, 46, 1679, 58, 45, 2606, 9528], [463, 46, 10, 368, 12, 10, 443, 1680, 6, 358, 262], [463, 8, 80, 177, 60, 24, 9529], [463, 49, 2, 2607], [463, 63, 349, 127, 24, 27, 2, 2210, 8, 3526, 76, 1277, 9530, 9531, 8, 2407], [463, 63, 114, 217, 54, 16, 4, 179, 34, 5, 75, 114, 4, 179, 54, 16, 4824], [463, 29, 13, 263, 207, 617, 57, 4, 286, 20, 48, 207, 5, 120, 9532], [463, 41, 625, 894], [463, 167, 43, 480, 43, 493, 21, 9533, 2408, 51, 201, 11, 52, 561, 8, 6275, 108, 11, 50, 1728, 15, 2, 9534, 160, 159], [463, 65, 342, 225, 9535, 6230, 9536, 43, 3527, 9], [463, 65, 13, 141, 95, 547, 5, 28, 472, 11, 4, 9537], [463, 802, 6276, 476, 30, 368, 9538], [463, 81, 13, 2, 181, 8, 20, 45, 726, 34, 7, 431, 9539, 320, 16, 9540, 54, 116, 259, 966, 9541, 9542], [463, 424, 305, 1351, 37, 5, 222, 70, 922, 166, 144, 11, 4892, 9543, 305, 9544], [1322, 2, 3152, 1085, 8, 7, 1, 12, 2, 9545], [1322, 19, 1452, 43, 45, 5, 171, 30, 187, 92, 61, 448, 406, 31, 20, 1165, 30, 815, 18, 798, 659], [1322, 2, 9546], [1322, 2067, 65, 89, 8, 5, 134, 1278, 6, 76, 894], [1322, 1022, 49, 13, 4, 9547, 9548, 4879, 9549, 190, 8, 750, 423, 82, 922, 6137], [9550, 19, 240, 137, 13, 56, 4893, 29, 131, 137, 1821], [3507, 15, 106, 21, 5, 9, 6, 28, 54, 16, 4098, 55, 22, 12, 57, 3528, 306, 72, 6, 263], [3529, 66, 952, 160], [3530, 3, 110, 204, 2848, 8, 1224, 9551, 51, 10, 4099, 112, 637, 8, 604, 94, 2849, 9552], [757, 1125, 10, 1931], [757, 10, 2240, 12, 2, 141, 127, 6277, 130, 4894, 160], [3134, 3, 64, 4100, 336, 1, 7, 46, 2608], [3134, 24, 12, 4, 1752, 16, 32, 2087, 98, 9553, 157, 35, 11, 36, 235, 123, 36, 6238], [6278, 17, 9554, 2241, 149, 23, 4101, 6279, 917], [9555, 492, 2, 917, 12, 4, 247, 589, 4069], [9556, 16, 4895, 326, 152, 14, 65, 51, 4, 180, 4896, 194, 17, 19, 22, 9557, 6280, 368], [1673, 100, 20, 234, 1, 1385, 11, 3, 318, 44, 6, 9558, 5, 9559], [1673, 229, 17, 43, 1, 650, 40, 65, 13, 9560, 9561], [993, 5, 5, 24, 30, 1543, 61, 249, 2, 138, 8, 309, 4897, 160, 217, 6, 17, 11, 2088, 4898, 3, 86, 2242, 14, 93, 2243], [9562, 8, 9563, 12, 2, 9564, 9565, 7, 136, 2, 727, 2850, 9566], [3153, 249, 10, 138, 1027, 3, 65, 13, 1050, 9567, 167, 240, 125, 4, 4899, 3531, 3, 195, 20, 9568, 160], [1379, 3, 407, 11, 2, 197, 507, 278, 2609, 1323, 773, 19, 117, 278, 134, 5, 2, 6281, 445, 3532, 579, 450, 5, 27, 98, 9569, 242, 4, 19, 35, 1], [1379, 40, 63, 249, 20, 138, 27, 2, 1598, 11, 40, 48, 101, 2, 4102, 34, 2, 573, 388, 6282, 160, 960, 4900], [584, 152, 1028, 7, 1, 6283, 9570, 57, 6283, 6284], [1360, 3533, 368, 160, 4, 3534, 9571, 9572], [2597, 1, 1, 30, 25, 2610, 30, 9, 202, 30, 8, 2409, 30, 9, 181, 1318, 8, 1660, 9573], [1600, 24, 74, 48, 238, 61, 6, 4, 2851, 29, 79, 10, 4103, 967, 13, 7, 4104, 3154, 324, 35, 274, 3, 103, 4105, 80, 45, 274, 324, 1452], [2229, 97, 39, 9, 86, 36, 342, 11, 682, 926, 534, 2611, 1233, 7, 36, 481, 6, 6285, 6, 9574], [2612, 22, 1, 12, 19, 185, 3, 300, 1528, 1528, 6162, 9575, 449, 9576, 526, 9577, 482, 174, 10, 237, 228, 3, 300], [4088, 10, 193, 6, 19, 20, 1, 11, 4, 226, 16, 4, 9578, 160, 1753, 849], [9579, 6286], [9580, 27, 10, 280, 96, 29, 302, 39, 894], [1539, 696, 61, 6, 14, 9581, 3535, 91, 20, 94, 3155, 838, 31, 5, 58, 1930, 14, 4901, 11, 201, 710, 9582, 90, 4077], [9583, 5, 49, 14, 2, 93, 6157, 9584, 6287, 22, 1083, 12, 48, 21, 78, 9], [3151, 189, 72, 9585, 9586, 36, 196, 4, 960, 1754, 65, 77, 48, 5, 1, 7, 1471, 13, 2, 1951, 3536, 26, 532, 13, 9587], [3151, 992, 72, 816, 15, 70, 17, 150, 6288], [463, 165, 1952, 20, 24, 142, 129, 9588, 9589, 3537, 277, 7, 110, 196], [463, 19, 24, 5, 487, 110, 257, 20, 4902, 160, 1076, 2088, 1088], [1322, 14, 2, 187, 117, 6289, 160], [1517, 7, 386, 16, 2, 1, 1029, 38, 15, 1234, 8, 5, 627, 20, 347, 1371, 49, 142], [4106, 9, 590, 9, 2089, 9, 6290, 9, 171, 9, 65, 21, 64, 18, 1126, 1541], [28, 6, 167, 245, 1, 18, 2852, 52, 67, 6], [26, 996, 2613, 10, 3538, 35, 13, 2, 1, 3539, 515, 3156, 6291, 1235], [8, 49, 44, 37, 209, 501, 51, 22, 159, 2090, 6292, 26], [71, 24, 150], [12, 7, 32, 24, 1], [320, 16, 1234, 99, 89, 15, 407, 602, 6, 1089, 423, 4, 660, 529, 120, 56, 11, 4, 2853], [28, 2, 937, 800, 34, 75, 110, 28, 2, 1, 6, 262, 170, 4903], [124, 76, 1, 9590], [96, 79, 2, 2227, 1947, 2410, 26, 219, 40, 12, 96, 73, 2411, 37, 57], [24], [652, 5, 2091, 7, 159, 2244, 2614, 11, 20, 9591], [6293, 129, 1, 1, 18, 84, 138, 1127, 18, 4, 6294], [3540, 79, 6295, 1837, 849, 21, 159, 6296, 194, 259, 6297, 18, 9592, 3483, 4904], [97, 1, 5, 6298, 9593, 4107], [671, 2, 112, 1, 38, 5, 4, 49, 193, 193, 2819, 130, 4, 904, 47, 1953, 4905, 1084, 108, 9594], [1, 64, 2399], [47, 216, 123, 2, 315, 6299, 37, 367, 793, 2, 1755, 360, 4, 95, 118, 48, 44, 1838, 371, 15, 3541, 118, 14, 11, 865, 21, 9595], [4906, 1604, 3542, 676, 458, 410, 9596, 34, 66, 194, 4, 178, 11, 7, 1, 99], [1733, 4108, 160, 63, 268, 294, 612, 1030, 36, 14, 1279], [1733, 3543, 116, 49, 212, 69, 90, 4, 68, 69, 9597, 2854, 11, 1605, 8, 9598, 4, 68, 69, 113, 4, 3544], [4, 16, 84, 235, 6, 4, 508, 16, 84, 995], [6300, 9599, 65, 51, 4, 95, 16, 4, 9600, 8, 478, 20, 9601, 1544, 1090, 9602, 5, 48, 209, 127, 4907, 130, 36], [243, 9603, 647, 9604, 4908, 457, 9605, 2092, 1386, 9606], [4909, 88, 2, 4094, 236, 18, 2, 2093, 798], [9607, 512, 1324, 558, 657, 51, 4, 189, 160, 505, 13, 2, 1, 29, 36], [12, 392, 16, 120, 56], [12, 392, 16, 120, 56, 69, 420, 82], [9608, 92, 5, 62, 71, 15, 150, 62, 4, 12, 18, 32, 305, 9609, 559, 1545, 13, 26], [198, 14, 605, 30, 21, 84, 290, 27, 274, 2855, 66, 318, 32, 14, 19, 9610], [85, 9611, 37, 179], [49, 4051, 1, 246, 434, 404, 9612, 22, 412], [7, 792, 353], [12, 56, 140, 16, 9613, 49, 1166, 6, 259, 1271], [7, 140, 374, 1756, 3545, 2, 1757, 53, 22, 1, 41, 91, 1473, 2582], [116, 49, 2245, 193, 6, 28, 24, 6301, 6302, 20, 91, 9614, 16, 32, 36, 29, 1581, 468, 174, 653, 538], [46, 172, 224, 27, 715, 3, 41, 1236, 123, 847, 8, 5, 49, 48, 244, 5, 365, 30, 9615], [75, 58, 15, 32, 18, 9616, 23, 48, 2, 1374, 1387, 9617, 3, 29, 772, 74, 2389, 2, 1388, 6303, 2412, 218, 3, 41, 91, 9618], [427, 2, 1, 294, 108, 84, 6304, 427, 2, 4910, 69, 938, 2, 9619, 23, 2, 9620, 69, 3157, 20, 4911], [62, 6304, 2856, 6305, 9621, 408, 4109, 236, 4912, 6306, 735, 4913, 2246, 3546, 3158, 9622, 34, 5, 75, 465, 739, 63, 5], [3497, 9623, 466, 9624, 218, 2, 1219, 294, 4110, 1031, 32, 305, 939, 1237, 16, 837, 9625], [73, 2, 6307, 91, 3, 103, 346, 350], [9626, 49, 120, 248], [111, 69, 259, 619, 16, 49, 32, 120, 248], [410, 4111, 620], [434, 8, 3, 299, 4, 6308, 82, 95, 2094, 47, 1758, 3, 109, 46, 41, 106, 21, 760], [12, 2, 434, 6309, 21, 71, 3547, 119, 102, 16, 9627, 1947, 444, 4, 3548, 9628], [177, 27, 2, 269, 2615, 632, 35, 6, 4, 4, 6310, 16, 2, 9629, 478, 206, 1681], [1264, 12, 237, 38, 2, 93, 864, 16, 24, 19, 170, 129], [275, 7, 175, 32, 4, 3549, 115, 523, 9, 7, 87, 701], [12, 1128, 130, 4, 1280, 23, 2413], [85, 140, 3, 195, 44, 6, 1752, 21, 4, 2095, 11, 9630], [12, 1839, 85, 1027, 1374, 2616, 1, 30, 5, 19, 7, 86, 506, 692, 12, 431, 49, 4, 4914, 4915], [1, 15, 61, 292, 1091, 449], [8, 31, 5, 46, 2, 9, 28, 35, 54, 10, 9631], [9632, 306, 191, 17, 31, 3, 67, 2, 348, 3, 121, 43, 267, 40, 121, 57, 49, 1026], [933, 2414, 9633, 9634, 160, 351, 794, 1190], [31, 12, 407, 21, 9635, 118, 105, 44, 299, 16, 958, 27], [9636, 6, 372, 32, 9637, 8, 9638, 124, 15, 2, 320, 1128, 130, 4, 9639], [12, 68, 89, 1, 452, 131, 780, 27, 50, 4916], [243, 616, 2617, 3550, 354, 49, 135], [220, 135, 51, 4, 458, 1759, 351, 4112, 16, 9640, 4917, 9641, 348], [4918, 1682, 155, 507, 7, 4, 508, 16, 20, 1735, 2618, 4919, 2619, 7, 44, 3, 2096, 4920, 5, 73, 3, 121, 4920, 9642], [11, 848, 261, 9, 168, 6, 79, 17, 2, 6311, 3551], [590, 319], [7, 39, 9, 33, 258, 126, 373, 575, 661, 16, 1606, 166], [2571, 35, 4921, 24, 112, 3159, 13, 4922, 3552, 2097, 9643, 2415, 428, 6312, 290, 74, 61, 2247], [885, 344, 1129, 1520, 2098, 583], [198, 70, 17, 98, 9644, 1607, 278, 14, 193, 2857, 130, 4, 166, 1760, 9645, 3, 44, 10, 373, 1231, 1092], [278, 14, 4, 237, 4113, 8, 9646, 1269, 403, 31, 5, 41, 24, 5, 982, 14, 291, 117, 128, 1325], [3, 119, 143, 24, 165, 130, 2, 4923], [3, 47, 203, 73, 286, 8, 47, 2, 1130, 711, 267, 274, 3, 137, 1201, 211, 2248, 940, 8, 210, 271, 11, 1130], [9647, 140, 39, 124, 2, 320, 16, 117, 9648], [281, 5, 172, 144, 2620, 2621, 2858, 64, 6313, 7, 9649, 1219, 3553, 29, 52], [12, 392, 16, 120, 56], [3554, 4114, 220, 402, 2, 1368, 2249, 123, 51, 9650, 1546, 116, 6314, 16, 129, 2416, 2622, 514, 26, 377, 3555, 59, 15], [47, 9651, 7, 85, 4, 204, 1167, 715], [55, 593, 14, 13, 101, 434, 184, 39, 1, 63, 1761], [37, 3160, 153, 14, 2250, 81, 13, 17], [9, 1265, 36, 89, 110, 31, 36, 49, 3, 103, 113, 50, 757, 1954, 142, 42, 9652], [42, 165, 867, 8, 656, 21, 17, 83, 151, 134, 42, 32, 10, 169, 34, 3, 46, 9653, 43, 2417, 8, 1955, 10, 373, 4924], [12, 392, 16, 120, 56], [1840, 1, 249, 138, 123, 1474, 8, 44, 260, 123, 1313, 140, 374, 330, 595, 8, 472, 9654], [9655, 8, 1093, 3, 96, 29, 28, 85, 9656, 6315, 12, 37, 9657, 7, 111, 86, 40, 6316], [9658, 9659], [9660, 1120, 129, 378, 3556, 95, 989, 8, 924, 15, 18, 5, 172, 26], [2385, 23, 101, 61, 6, 72, 15, 4925, 3557, 3161, 9661], [3558, 6317, 4115, 1733, 160, 759, 2623, 9662, 9663, 18, 160], [434, 120, 160, 469, 6318, 1547, 933, 18, 160], [2859, 2621, 160, 469, 6318, 1547, 933, 18, 160], [4, 676, 160, 4, 2418, 9664, 2099, 8, 4, 180, 9665, 18, 160], [124, 7, 9666, 3, 636, 40, 24, 792, 7, 166, 25, 173, 157, 2, 1013, 18, 4116], [1, 12, 298, 2, 2860, 4926, 6191, 18, 22, 1956, 69, 428, 114, 84, 106, 294, 26, 42, 96, 28, 204], [12, 18, 4927, 9667, 28, 20, 570, 95, 1683, 82], [9668, 18, 4, 1540, 697, 193, 6, 1475, 211, 44, 1056], [4928, 6319, 37, 3, 829, 10, 6320, 6, 1, 491, 876], [10, 141, 646, 8, 3, 90, 6, 1124, 15, 34, 8, 52, 62, 6321, 34, 52, 96, 2, 161, 1, 1168, 19, 5], [71, 78, 1, 276, 2624, 1090, 125, 1357, 1013, 53], [85, 198, 3, 14, 491, 22, 9, 4929, 4117, 256, 272, 338, 15, 9669, 105, 1326, 477, 6, 531], [9670, 9671, 509, 1680, 26, 382, 6322, 4118, 18, 112, 1086, 4930, 18, 50, 6323, 6324], [12, 2, 83], [12, 96, 2, 83, 41, 22, 68, 2625, 287, 408, 198, 14, 9672], [31, 42, 47, 533, 6, 10, 312, 74, 1131, 143, 774], [20, 2, 282, 139, 4931, 18, 249, 138, 1841, 18, 28, 613], [9673, 59, 958, 715, 26, 15, 48, 59, 4119, 4, 13, 2, 172, 9674, 386, 16, 2, 3162], [9675, 168, 98, 428, 414, 73, 2, 4932, 6325, 3163, 21, 2211, 905, 9676, 74, 9677], [1841, 18, 4, 7, 762, 5, 54, 215, 213, 8, 48, 20, 4933, 16, 4, 21, 9678, 213, 55], [27, 9679, 9680, 148, 7, 1, 2, 9681, 7, 2, 180, 188], [6326, 6327, 542, 21, 740, 3164, 16, 4, 4934, 9682, 9683, 1030, 22, 2861], [6328, 100, 4120, 9684, 36, 301, 36, 4935, 149, 36, 9685, 59, 6329, 4, 189, 404, 74, 9686, 232, 739, 6330, 4120], [159, 9687], [1219, 6331, 9688, 3, 19, 1277, 9689], [6, 326, 7, 253, 2, 153], [6, 10, 153], [6, 10, 153], [6, 10, 3165, 6332, 153], [4936, 145, 113, 9, 23, 142, 81, 76, 33, 37, 3, 75, 28, 18], [12, 21, 248], [32, 158, 131, 58, 12, 19, 175, 8, 467, 2626, 3559, 32, 115], [49, 2419, 668, 202, 6333, 315, 144, 551], [12, 392, 16, 120, 56], [18, 5, 24, 6334, 3166, 3, 122, 6, 113, 6334], [1079, 1548, 16, 1684, 6335, 4121, 2627, 1193, 11, 1685, 2628, 22, 1608, 6336, 544, 95, 592, 1281, 4121], [64, 5, 1115, 2100, 2100], [51, 9690, 10, 153], [2862, 12, 4, 159, 524, 16], [386, 16, 2, 1, 1029, 38, 5, 679, 28, 11, 618, 8, 20, 6337, 1389, 15, 106, 6, 633], [386, 16, 2, 1, 1029, 38, 5, 227, 4, 2099, 18, 8, 20, 443, 323, 12, 18, 34, 15, 4, 450, 16, 4, 323], [386, 16, 2, 1, 1029, 38, 20, 294, 539, 20, 331, 11, 4, 991, 8, 9691, 20, 141, 1109, 18, 4, 1842], [38, 5, 338, 20, 347, 1371, 142, 8, 15, 1234, 11, 20, 347, 8, 65, 13, 3560, 4937, 920, 539, 7, 1], [111, 69, 49, 105, 243, 8, 9692, 1843, 16, 4, 817], [71, 6, 137, 1762, 25, 163, 1, 147, 14, 2218], [134, 50, 32, 143, 138, 42, 146, 470, 2863, 143, 24, 426, 31, 42, 1476, 138, 18, 147, 1, 40, 276, 671, 2420, 9693], [161, 1, 253, 17], [5, 63, 19, 384, 9, 34, 5, 165, 48, 64, 384, 319], [1191, 6, 2864, 73, 2, 6338, 30, 9694, 529, 4938], [439, 3, 58, 4, 9695, 9696, 25, 25, 25, 25, 1282, 1282, 1282, 1282, 25, 25, 25, 25], [296, 216, 54, 27, 292, 952], [810, 153], [63, 28, 2, 401, 51, 4, 9697, 74, 73, 4, 9698, 3, 465, 36, 13, 9699, 8, 9700, 73, 358, 73, 5, 46, 2, 353], [12, 392, 16, 120, 248], [2856, 4939, 3561, 9701, 9702, 9703], [12, 392, 16, 120, 248], [3167, 2101, 354, 2251], [4, 9, 3, 936, 106, 27], [15, 63, 70, 2, 1, 359, 35, 6, 1763, 446, 18, 4, 1844, 16, 378, 6, 546], [2621, 9704, 12, 37, 589, 52, 198, 14, 2, 355, 1111, 6339, 1390, 902, 8, 114, 20, 9705, 3168], [], [3, 29, 67, 4940, 895], [100, 170, 137, 4, 1119, 6340, 7, 6341], [4122, 2073, 189, 12, 6327, 4941, 4123], [292, 984, 6342, 9706, 9707, 11, 1957, 679], [9708, 4124, 344, 6343, 9709, 48, 20, 1477], [148, 5, 9710, 9711, 4, 232, 1537, 27, 2, 1125, 294, 102, 20, 204, 17, 6344, 9712], [2629, 219, 852, 7, 420, 6, 4, 6345, 109, 9713], [3, 46, 733, 59, 4, 2095, 404, 74, 468, 9714, 36, 229, 4942, 1057, 498, 74, 309, 43, 1764, 9715, 36, 1845, 15], [3, 363, 6, 1052, 27, 3552, 11, 4943, 38, 52, 47, 2, 6346, 43, 2630, 9716, 481, 9717, 4125, 92, 1369, 2102, 9718, 266, 72, 4, 725, 2392], [31, 2095, 44, 2, 739, 9719, 3, 67, 4, 413, 412, 338, 4126, 8, 9720, 4, 763, 63, 333, 2631, 1738, 27, 852, 8, 6347], [417, 1846, 108, 9721, 146, 176, 22, 61], [4127, 87, 7, 9722, 434, 137], [6348, 33, 41, 337, 8, 4, 1686, 49, 18, 9723, 679, 8, 36, 49, 404, 110, 2058, 106, 6, 28, 686, 9724, 79, 35, 106], [41, 9725, 123, 2, 1021], [114, 32, 1058, 178, 11, 6349, 23, 1275, 15], [936, 9726, 658], [9727, 1478, 37, 3562, 180, 36, 63, 204, 2, 413, 2230, 16, 95, 11, 68, 9728], [9729, 305, 1, 6, 6350, 73, 239, 435, 73, 1756, 6, 8, 14, 2, 715], [20, 818, 6, 14, 120, 56], [116, 49, 2, 607, 6351, 68, 34, 9730, 1, 12, 109, 162, 15, 51, 205], [819, 903, 4944, 1308, 8, 434, 1032, 245, 220, 499, 903, 1765, 1032, 8, 43, 1], [], [1], [11, 22, 1, 9731, 8, 2421, 3563, 9732], [338, 9, 596], [410, 4, 9733, 1766], [204, 715, 1687, 34, 3169, 61, 6352, 630, 173, 9734], [49, 9735, 2, 4945, 7, 256, 12, 9736, 58, 48, 1120, 73, 9737, 9738, 21, 36, 49, 715], [12, 2, 401, 21, 120, 56], [311, 423, 38, 2, 1033, 81, 8, 708, 6, 14, 1847, 8, 9739, 128, 1848, 392, 16, 8, 9740], [301], [66, 29, 64, 39, 9], [1], [408, 12, 4128, 9741, 6353, 21, 22, 213, 1122], [621, 82, 1586, 6354, 12, 6355, 3, 198, 61, 14, 2, 6356, 9742, 31, 15, 196, 169, 21, 10, 2865], [6357, 9743, 8, 84, 1, 9744, 93, 184, 9745, 9746], [96, 662, 2073, 66, 87, 22, 2379, 9747, 15, 48, 1461], [2611, 35, 361, 390], [22, 1, 136, 84, 1359, 1663], [29, 279, 41, 10, 1666, 23, 2, 23, 2, 23, 966, 392, 16], [101, 1391], [], [1392, 170, 329, 9748, 1132, 168, 488, 2632, 168, 1393, 6, 70, 6358, 488, 14, 148, 198, 14, 4, 660, 4946], [], [], [9749], [1, 28, 51, 17], [2866, 1, 24, 24, 6359, 689, 2422, 9750, 2633, 18, 15], [933, 2414, 160, 9751, 9752, 9753, 201, 9754, 26, 6360, 9755, 527, 26], [63, 28, 15, 34, 23, 497, 634, 143, 1, 167, 17, 35], [34, 25, 12, 1, 205, 177, 638, 340, 37, 1, 216, 42, 6361, 605, 240, 163, 143, 476], [165, 88, 174, 413, 412], [335, 335, 2867, 6362, 718, 137, 1277, 9756, 820], [335, 335, 6363, 2867, 6364, 1], [335, 335, 1958, 718, 30, 19], [335, 335, 3131, 2252, 494, 2867, 1381], [335, 335, 3564, 4947, 1059, 4948, 11, 24, 8, 30], [335, 335, 4129, 1059, 24], [335, 335, 906, 2, 77, 1849, 50, 24, 11, 677, 2868], [335, 335, 342, 9757, 659, 180, 1169, 137, 27, 9758, 24], [335, 35, 335, 246, 24, 637, 35], [335, 335, 3565, 24, 8, 714, 1034], [335, 335, 4130, 24, 781, 2869, 637, 35], [335, 335, 9759, 18, 681, 24, 9760], [335, 335, 24, 19, 637, 35], [335, 335, 379, 1688, 77, 1031, 187, 9761], [335, 335, 4131, 1767, 4132, 6365, 249, 98, 3566], [335, 335, 4132], [335, 335, 4132], [335, 335, 4129, 1094, 4947, 27, 180, 839, 24], [335, 335, 9762, 8, 1060, 1169, 8, 24, 19], [335, 335, 1958, 718, 835, 28, 2423, 8, 9763], [335, 335, 252, 2103, 84, 436, 180, 24], [335, 335, 127, 64, 372, 16, 2103, 2, 1394, 24], [335, 335, 792, 853, 2103], [335, 335, 1850, 213, 206, 1031, 24, 1266, 18, 714], [335, 335, 1031, 9764, 1750, 2, 3170, 11, 50, 1031, 355, 24], [335, 335, 1031, 24], [335, 335, 1031, 24], [335, 335, 402, 401, 8, 1266, 18, 4133, 24], [335, 335, 4130, 177, 19, 1, 9765], [335, 335, 2104, 24, 565, 82, 2, 9766, 1327], [335, 335, 337, 4949, 10, 436, 1849, 50, 24], [335, 335, 168, 10, 6366, 1, 9767, 337, 216, 4130], [335, 335, 10, 260, 24], [335, 335, 322, 379, 1688, 77, 341, 187, 19, 26, 1327, 335], [335, 335, 379, 1688, 77, 1031, 187, 6364], [335, 335, 9768, 504, 24], [335, 335, 1959, 418, 28, 50, 24, 2870], [335, 335, 1959, 2424, 180, 24], [335, 335, 1959, 27, 926, 24], [335, 335, 2425, 77, 119, 24], [335, 335, 1, 11, 2871, 28, 50, 631, 187, 1381], [335, 335, 2, 727, 341, 202, 718, 12, 9769], [335, 335, 206, 1, 333, 9770, 379, 2577], [335, 335, 4950, 2869, 28, 379, 8, 206, 968, 11, 50, 24], [335, 335, 969, 1169, 179, 835, 19, 27, 48, 50, 9771], [335, 335, 4951, 2425, 1328, 2105, 935], [335, 335, 1031, 9772, 3171, 26, 9773, 4952, 1031, 24, 335], [335, 335, 2426, 24, 119], [4, 2106, 68, 118, 14, 37, 209, 2857, 31, 36, 157, 2, 95, 18, 15], [29, 113, 17, 31, 10, 1661, 47, 2, 9, 230, 17, 31, 23, 3567], [31, 5, 2, 9, 98, 122, 6, 28, 686, 27, 217, 29, 772, 6, 14, 393, 127, 88, 2, 864, 16, 1734, 6, 76], [6367, 6368], [15, 4, 4953, 6369, 159, 524], [136, 2, 4954, 1851, 877, 1196, 6370, 8, 7, 85, 36, 44, 37, 239, 4955], [118, 215, 9774, 31, 36, 100, 4, 970, 81, 32, 7, 397, 35, 2427, 12, 21, 4, 95], [17, 14, 2, 89, 1], [10, 3568, 1479, 260], [6, 38, 3, 168, 6, 14, 93, 51, 9775, 272, 1], [38, 3, 424, 10, 9776, 269, 1960], [654, 13, 3569, 3172, 6, 4134, 2872, 1388, 4135, 997, 4136, 12, 9777, 9778, 197, 160, 322, 209, 26], [6, 14, 1, 26, 467, 1480, 426, 66, 249], [160, 3524, 382, 21, 4, 1095, 16, 57, 103, 6189, 14, 98, 9779, 410, 9780, 4956], [10, 1], [336, 66, 48, 152, 400, 142, 66, 152, 294, 15, 54, 83], [1, 28, 9781, 197, 546, 106, 54, 16, 546, 31, 40, 551, 513], [64, 4, 229, 22, 2428, 890, 12, 2634, 4, 1514, 9782, 70, 4, 660, 81], [], [1], [32, 4, 89, 1], [1], [9783, 3, 107, 11, 4, 2635, 5, 11, 4, 2635, 11, 4, 2082, 9784, 1831, 35, 32, 4, 24], [549, 16, 189, 69, 751, 13, 1549, 162, 49, 4, 728, 409, 435], [31, 42, 2, 112, 1], [4137, 3173, 6, 61, 18, 2, 438, 27, 6371, 9785, 241, 7, 9786, 386, 16, 2, 1], [9787, 1852, 9788, 8, 9789, 219, 565, 51, 4, 904, 9790, 1853, 23, 134, 423, 2, 840, 6, 819, 3570, 37, 31, 20, 48, 2, 187, 107, 1550, 17, 51, 9791, 1961], [6372, 9792, 142, 4, 4957, 149, 519, 3, 47, 6, 314, 8, 514, 15, 74, 68, 16, 10, 9793, 9794, 7, 9, 6373, 6374], [9795, 6141, 3571, 1609, 405, 2, 1854, 56, 81, 493, 18, 6375, 26], [2, 864, 16, 24], [3, 64, 2107, 769, 19, 5, 9, 119, 2, 6376], [1853, 4958, 1170], [155, 1, 163, 10, 6377, 930, 3, 4959, 19, 51, 577, 68, 106], [903, 15, 573, 7, 4, 570, 4138, 28, 4, 1329, 250], [537, 3174, 3, 64, 350, 34, 5, 2, 282, 34, 3, 64, 350, 847, 12, 9796], [22, 9, 41, 2, 261, 758, 18, 249, 138], [2, 2108, 1481, 25, 18, 22, 135, 1610, 109, 14, 81, 13, 283], [39, 1, 192, 512, 51, 10, 2429, 19, 154, 2253], [1, 134, 108, 1849], [105, 132, 2, 490, 2430, 35, 27, 6378, 490, 205, 34, 105, 47, 378, 3, 200, 60, 490, 45, 205], [25, 47, 1131, 84, 9, 124, 84, 9, 389, 21, 2, 4139, 8, 52, 96, 27, 50, 1962, 9797], [194, 158, 290, 18, 9798], [29, 13, 17, 44, 2, 27, 4, 763, 16, 4, 1, 304, 21, 17, 6, 134, 2, 19], [278, 516, 14, 79, 158, 130, 2, 674, 782, 74, 2, 2873], [394, 78, 1, 47, 6379, 6, 4140, 9799, 324, 59, 14, 557, 13, 2, 1235, 932], [9800], [9801, 78, 9802, 276, 450, 35, 544, 129, 2, 1464, 565, 9803, 7, 9804, 9805, 99, 239, 153, 276, 528, 51, 7, 340], [2254, 814, 227, 2, 9, 173, 2, 2255, 29, 28, 1096, 38, 20, 189, 192, 751, 36, 167, 15, 3572], [41, 174, 1, 1011, 1109, 18, 10, 6380, 9806], [160, 526, 33, 9807, 16, 5, 70, 17, 528, 66, 168, 6, 271, 81, 45, 11, 2636, 1230, 5, 342, 26, 5, 10, 1], [5, 1551, 139, 249, 138, 9], [2612, 161, 340, 253, 17, 9808, 1, 52, 253, 326, 242, 80, 30, 35], [907, 102, 282, 107, 18], [160, 128, 10, 25, 26, 100, 61, 470, 18, 2, 441, 348, 66, 103, 14, 528, 332, 73, 286, 11, 1526, 9809], [26, 31, 5, 46, 2, 236, 28, 35, 54, 10, 941, 9810], [160, 1035, 1, 3, 64, 5, 26, 7, 2, 725, 725, 20, 33, 2431, 6381, 3, 375, 38, 5, 342, 2, 9811, 16, 20, 343, 625, 752], [24, 498, 138, 13, 40, 2, 6382, 964, 3175, 964, 3175, 26, 9812, 9813, 9814, 26, 335, 715, 3175, 9815, 964, 3175, 26, 513, 4960], [18, 4, 24], [334, 24, 26], [10, 1], [12, 4, 247, 1768, 2432, 32, 22, 4141, 908, 8, 308, 12, 996, 4, 942, 204, 7], [529, 32, 707, 233, 19, 42, 2109], [1192, 340, 44, 17, 18, 10, 1395, 45, 55, 7, 48, 417, 53, 53, 7, 1, 46, 783, 2, 4142, 2582], [1963, 99, 206, 6, 14, 1112, 50, 815, 985, 352, 1, 5, 1133], [425, 31, 5, 194, 1202, 26, 257, 102, 26, 80, 774, 262, 42, 26, 15, 229, 84, 226, 11, 4, 9816, 20, 2, 104], [321, 39, 9, 146, 14, 3176], [495, 152, 309, 116, 2, 1, 18, 9817, 644, 35, 2, 2110, 73, 66, 175], [78, 44, 723, 2637, 9818, 3, 735, 4, 234, 16, 10, 1, 231, 38, 23, 2111, 15, 82, 4, 108], [16, 1134, 9819, 677, 49, 248, 40, 259, 11, 4, 4143, 57, 200, 5, 772, 26], [10, 1855, 11, 1964, 13, 2, 3177, 22, 4, 25, 7, 877, 1, 9820], [1, 28, 1216, 2433], [810, 153, 622, 1856, 6, 14, 4050, 35], [9821, 3, 293, 37, 200, 66, 28, 2256, 16, 1050, 2112, 65, 159, 4961], [1480, 79, 17, 9822], [25, 471, 4962, 16, 17, 6, 36, 1, 13, 53, 139, 262, 1114, 53], [22, 120, 1, 86, 40, 1518, 2069], [3, 297, 2, 593, 30, 1, 11, 60, 314, 503, 120], [153, 146, 412, 392, 16, 9823, 9], [22, 9, 33, 4963, 17, 854, 4144, 134, 35, 11, 20, 9824, 4964, 851, 30, 9, 19, 54, 10, 706], [38, 2, 391, 28, 554, 123, 2638, 3178], [757, 3, 62, 5, 41, 178, 18, 20, 6383], [1, 10, 4965], [1965, 24, 767], [3, 33, 121, 7, 10, 909, 146, 497, 27, 22, 322, 231, 1611, 4966, 78, 9, 9825], [336, 31, 5, 657, 17, 5, 58, 1361, 101, 1, 27, 43, 25, 58, 9826], [137, 7, 25, 251, 1, 49, 37, 6384, 241, 10, 274, 26], [43, 1, 61, 423, 53, 2874, 9827, 6385, 53], [1, 47, 214, 483], [3, 90, 5, 2069, 236, 12, 2, 4145, 2639, 28, 4, 1278, 211, 4, 438, 1171, 1171, 3573], [38, 20, 122, 6, 1769, 34, 20, 24, 12, 512, 54, 480, 6386], [3474, 54, 135, 249, 1], [1, 31, 20, 4, 4146, 5, 87, 6, 100, 17, 62, 117, 92], [39, 617, 37, 1758, 23, 33, 135, 6, 81, 248], [3574, 1, 42, 10, 381, 91], [251, 1, 3575, 50, 30], [53, 7, 24, 12, 9828, 571, 1233, 40, 33, 124, 2, 260, 9829, 115, 6187], [53, 5, 2, 104, 31, 5, 119, 4147, 9830], [6387, 124, 6388, 9831, 18, 4, 3127, 38, 84, 234, 9, 2434, 4, 6389, 178, 142], [953, 1, 1471, 13, 1482, 9832], [5, 2, 9, 31, 97, 994, 41, 2, 6390], [2113, 9833, 2113, 9834, 2113, 9835, 4148, 30, 141, 1], [76, 841, 3576, 4967, 4968, 153, 276, 9836, 224, 8, 1276, 1689, 16, 770, 1330, 142], [10, 19, 274, 321, 4, 95, 82, 9837, 49, 11, 580, 16, 10, 1728], [3, 44, 6, 9838, 4, 24, 54, 116], [425, 53, 369, 716, 24, 10, 306, 86, 3, 41, 303, 22, 385, 53], [689, 9, 64, 9839, 1231, 412], [1857, 56, 32, 5, 1, 12, 10, 386], [3, 90, 38, 111, 28, 18, 10, 89, 234, 149, 3, 1061, 29, 13, 6, 208, 13, 2, 1], [53, 18, 2, 4149, 33, 24, 53], [66, 1396, 1858, 21, 68, 264, 649, 34, 20, 2383, 1690, 17, 108, 312], [160, 20, 10, 9840, 3, 64, 5, 97, 9841, 1, 3, 363, 556, 14, 1941, 26, 1691, 18, 97, 1327, 115], [], [3, 380, 151, 33, 56, 22, 1552, 140, 16, 4150, 9842, 26], [9843, 171, 1], [96, 75, 94, 57, 158, 94, 11, 76, 120, 3179, 29, 58, 22, 9844], [10, 1203, 49, 14, 197, 2393, 16, 10, 269], [37, 239, 322, 1, 107, 6, 10, 457, 1283], [158, 230, 245, 420, 49, 9845, 10, 202, 30, 456, 114, 2, 1966], [155, 449, 76, 9, 460, 3, 94, 76, 9, 11, 155, 620, 460, 21, 98, 4969], [42, 1, 840, 251], [814, 132, 2, 93, 73, 228, 6, 17, 721, 3, 41, 20, 1391, 809, 100, 19, 45, 35, 22, 213], [3, 90, 97, 1, 30], [37, 4, 154, 1835, 12, 1, 255, 1951, 3577, 18, 126, 402], [187], [269, 214], [1, 36, 28, 2640, 74, 2075, 9846, 2114], [148, 3112, 41, 138, 163, 24, 6, 14, 58, 22, 55], [300, 6, 274, 1, 23, 1967, 998, 10, 186, 1024], [10, 2393, 3180, 81, 59, 57, 10, 186, 226, 241, 43, 9, 5, 222, 105, 1464, 565, 17, 6, 4, 900], [9847, 41, 384, 1, 932], [22, 19, 1, 4151, 87, 6, 309, 333], [183, 1, 28, 43, 64], [3, 14, 1265, 6391, 131, 134, 17, 60, 24], [2875, 1, 2875, 99, 738], [38, 5, 597, 35, 6, 482, 14, 2, 9, 18, 4, 909], [34, 304, 31, 52, 41, 2, 1384, 462, 8, 96, 9848, 80, 3578, 12, 52, 2, 4970, 591, 6392, 21, 9], [78, 14, 2587, 125, 7, 9849, 385, 46, 43, 193, 11, 286, 42, 13, 7, 1, 155, 419, 921], [4152, 4, 4153, 1, 1326, 468, 55, 22, 12, 4154], [638, 28, 351, 24, 102, 16, 1846, 257, 771], [1449, 93, 24, 29, 1161, 28, 515], [3, 300, 25, 168, 6, 795, 68, 1735, 102, 4, 1195, 8, 1, 118, 14, 13, 9850], [482, 61, 262, 20, 9, 17], [6393, 132, 56, 371, 6394], [51, 197, 571, 112, 674, 782], [1171, 1118, 48, 6395, 15, 72, 4971, 23, 48, 2, 282, 23, 2, 111, 395], [7, 1, 12, 82, 6396, 9851], [36, 4155, 9852, 181, 11, 9853, 9854, 12, 43, 507, 21, 76], [3, 86, 32, 384, 9, 18, 4972, 9855, 2393, 3180, 47, 780, 27, 6397, 3579], [39, 9, 1948], [153, 78, 87, 259, 169, 24, 2371, 74, 667, 6398, 188, 666, 16, 1949, 2257, 138, 163, 2, 517, 30, 177, 188], [155, 77, 41, 2, 8, 365, 315, 1062, 15, 106, 6, 119, 667, 285, 34, 23, 48, 17, 55], [241, 22, 1, 9856, 456, 14, 284], [219, 4973, 38, 97, 234, 9, 708, 5, 73, 50, 520], [63, 78, 275, 100, 22, 2258, 11, 21, 1204, 1029, 16, 2259, 6, 28, 78, 1, 86, 117], [22, 2876, 14, 44, 32, 4, 9, 4974, 129], [78, 1110, 59, 7, 1692, 1483, 14, 1484, 11, 9857, 8, 6399, 7, 1, 223, 14, 11, 9858], [53, 29, 58, 240, 27, 10, 77, 55, 37, 38, 78, 11, 3181, 277, 20, 77, 119, 4, 24, 3182], [112, 435, 119, 285], [3, 29, 67, 10, 91, 6400, 9859, 541, 478, 771, 6401, 6, 5, 319, 23, 48, 1937, 51, 1284, 78, 9, 75, 14, 302], [15, 1455, 17, 71, 25, 63, 19, 545, 155, 1, 34, 38, 2, 25, 122, 6, 81, 6, 84, 1, 52, 131, 345, 59, 15, 3, 87, 729], [160, 5, 2, 141, 3580, 91, 3, 87, 5, 21, 2, 521, 37, 42, 63, 547, 2, 312, 54, 34, 5, 431, 483, 91], [9860, 3581, 6402, 1968, 9861, 9862, 9863, 855, 4975, 9864, 9865, 2641, 6403, 2641], [6404, 855, 4156, 9866, 9867, 2615, 160, 3183, 931, 9868, 9869, 216, 27, 4, 9870, 1375, 9871], [6404, 855, 4156, 9872, 11, 4, 70, 2, 1969, 123, 8, 21, 494, 1607, 51, 3582, 4976, 4157], [1397, 27, 10, 774, 74, 57, 440, 16, 170, 2252, 992, 227, 1331, 377, 1856, 27, 1368, 235], [38, 111, 1191, 6, 126, 504, 73, 126, 1063, 749, 3, 62, 71, 15, 372, 34, 15, 71, 66, 196, 15, 55], [19, 1398, 1961, 1050, 8, 32, 36, 408, 730, 26, 228, 242, 80, 1, 30, 35], [124, 6, 753, 7, 1, 233, 593, 1, 41, 17, 739, 82, 9873, 4158, 175], [10, 646, 12, 2, 1, 24, 104, 2415, 5, 33, 13, 28, 257, 35, 29, 5], [31, 5, 41, 1135, 9874, 831, 6, 119, 2, 2877, 16, 45, 118, 42, 119, 15, 1131, 7, 1], [55, 1, 356, 3, 47, 129, 5, 82, 4, 1204, 3, 2878, 20, 30, 6, 4, 4159], [2, 1, 12, 32, 9875, 10, 779, 273, 17, 48, 6, 81, 6, 1, 9876], [89, 1238, 46, 342, 48, 110, 31, 5, 2, 37, 79, 89, 1, 8, 15, 1326, 149, 123, 2, 1096, 764, 4977, 46, 182, 308], [4978, 238, 9, 6405, 9877], [43, 127, 1485, 9878, 21, 5, 52, 317, 110, 1553, 15, 35, 13, 760], [773, 25, 69, 238, 4090, 5, 56, 464, 55], [486, 2, 1859, 91, 376, 11, 2, 874, 3140, 123, 2115, 9879, 456, 14, 84, 154, 3158, 2879, 5, 652, 110, 356, 1], [22, 1, 12, 65, 4160, 8, 4160, 123, 4, 9880, 9881], [110, 464, 4161, 47, 68, 16, 4, 455, 2220, 2078, 466, 2212, 47, 1267, 669, 669, 295, 1267, 59, 1770, 45, 47, 56], [526, 78, 198, 94, 22, 558, 16, 441, 381, 22, 1, 13, 2, 9882, 2435, 2642], [9883, 16, 287, 220, 659, 1554, 213, 16, 9884, 100, 39, 9, 14, 434], [9885, 7, 3184, 464, 9886, 99, 1097, 11, 7, 9], [910, 59, 245, 3125, 21, 32, 5, 64, 95, 54, 116, 26], [9887, 237, 178, 182, 101, 218, 5, 249, 51, 567, 95], [128, 6406, 33, 41, 79, 2, 24, 123, 1826, 709, 1399, 114, 1970], [37, 5, 96, 516, 44, 56, 30, 4073, 1609, 130, 1285, 5, 549, 91, 42, 96, 75, 113, 1285, 249, 5, 1380, 91], [9888, 12, 56, 1153, 52, 46, 132, 9889, 9890, 1609, 101, 4162, 54, 4163, 424, 84, 9891], [194, 9892, 122, 6, 167, 4164, 985, 421, 137, 26, 24, 3185, 123, 2, 24], [6407, 124, 17, 204, 268, 95, 27, 68, 1771, 26], [19, 24], [19, 4, 9893, 10, 457, 11, 268, 115, 9], [60, 16, 78, 9, 530, 78, 258, 54, 78, 958, 74, 958, 138, 27, 2, 537, 30, 275, 8, 96, 19, 4, 25], [22, 12, 2880, 42, 181, 26, 454, 69, 1772, 1686, 7, 12], [132, 194, 6408, 137, 155, 264, 751, 30, 1], [432, 131, 465, 15, 88, 9, 6118, 130, 734, 2643, 1022], [46, 7, 2, 1], [3, 67, 5, 6, 14, 24, 792, 23, 20], [369, 12, 567, 95, 49, 5, 265, 17], [280, 13, 3, 109, 934, 13, 119, 24, 82, 4, 3583, 15, 70, 15, 127, 530, 3, 13, 530, 281, 5, 13, 119, 30, 201], [72, 256, 12, 4, 68, 898, 323, 3, 44, 6, 477, 6, 38, 23, 11, 10, 9894], [155, 275, 373, 2, 4165, 31, 40, 255, 4165, 40, 2, 9, 55, 398, 488], [3, 75, 139, 14, 2, 161, 1], [246, 1586, 1332, 160, 57, 2, 187, 9895, 327, 9896, 6409, 384, 207, 14, 963], [1486, 4127, 11, 84, 244, 9897, 26], [12, 22, 567, 95, 45, 2, 675, 9898, 26, 18, 4, 112, 205], [200, 3, 33, 192, 345, 1], [3, 90, 77, 69, 28, 551, 26, 29, 227, 173, 9, 9899, 936, 16, 2116], [1123, 54, 6, 10, 734, 218, 40, 210, 878, 43, 9], [23, 2, 9900, 9901, 140, 3, 44, 202, 2243, 70, 697, 4166, 410], [98, 9902, 9903, 9904, 4167, 190, 9905, 4168, 6410, 6411, 6410], [367, 9906, 419, 3, 29, 780, 74, 81, 6, 621, 26, 43, 9, 33, 17], [33, 41, 2, 154, 1127, 15, 1376, 8, 3, 226, 170, 9907, 4979], [10, 2644, 29, 10, 2644, 29, 10, 2644, 29, 67, 553, 650, 5, 41, 1487, 1612, 251, 26, 120, 30, 145, 26], [3, 301, 3, 124, 10, 586, 11, 10, 164, 34, 4, 1, 30, 25, 96, 86, 23, 48, 84, 1388, 1667, 34, 148, 7, 611, 1114], [9, 109, 58, 340, 95, 91, 22, 154, 6, 5], [1, 28, 54, 384, 150, 8, 28, 60, 154, 138, 53], [10, 734, 46, 878, 43, 9], [26], [3584, 1935, 3585, 5, 2, 1, 403, 1055, 408, 4169, 3552, 12, 2260, 856, 6, 760, 403, 194, 15], [4980, 3, 65, 434, 1, 19, 5, 9908], [23, 614, 6, 119, 80, 517, 1, 9909], [53, 3, 75, 375, 32, 4, 77, 289, 1131, 18, 9910, 45, 48, 4170, 15, 114, 26], [3, 345, 13, 2, 1, 211, 10, 250, 9911, 105, 64, 361, 55], [1486, 4127, 869, 9912, 9913, 84, 833, 26, 488, 7, 4, 232, 359, 61, 355, 1111], [3586, 1488, 11, 22, 1, 23, 345], [994, 156, 340, 191, 5, 2835, 5, 44, 2, 6412, 9914, 41, 9, 364, 5, 196, 112, 385], [321, 23, 113, 5, 31, 40, 41, 1172, 2645, 618, 2646, 4981, 40, 2, 9], [3, 44, 43, 9, 140, 1533, 25, 46, 45], [1, 64, 313, 7, 1555, 1691, 61, 400, 161, 1, 26], [37, 36, 109, 998, 567, 95, 82, 4, 2565, 1333, 1027, 217, 204, 943, 129, 15, 2881, 2881], [99, 239, 6413, 3487, 18, 10, 3538, 26, 1971, 41, 9], [151, 257, 4, 24, 35, 7, 2, 1553, 117, 9915], [999, 9916, 5, 266, 3587, 4, 2647, 2261, 16, 39, 1219, 2381, 26, 91, 369], [4171, 174, 196, 964, 3, 121, 3588, 411, 9], [77, 49, 19, 144, 10, 108, 192, 3186, 35, 91, 15, 4, 957, 2882], [116, 2, 511, 808, 14, 428, 284, 26, 6414, 284, 112, 45, 26, 3, 75, 397, 6415, 4826, 1], [91, 3, 47, 1967, 262, 32, 4, 1, 7, 182, 273, 17, 7, 128, 5, 198], [31, 42, 191, 17, 155, 1, 9917, 9918], [250, 106, 27, 1375, 55, 26, 6416, 66, 167, 7, 9], [42, 87, 6, 14, 11, 217, 1860, 9919, 1064, 117, 34, 3, 197, 1461, 34, 96, 43, 4982], [1205, 33, 122, 6, 9920, 1065, 2, 9921, 6, 10, 312, 54, 135], [9922, 6417, 4172, 26, 3, 249, 147, 83, 29, 78, 2883, 442, 2, 207, 91, 29, 119, 43, 9923], [2425, 24, 578, 13, 6418, 6276], [9924, 8, 190, 1173, 12, 9925, 9926], [57, 4, 9927, 21, 1206, 10, 1855, 132, 505, 2436, 23, 9928, 5, 165, 48, 14, 66, 47, 467, 54, 199, 1149], [116, 3187, 1334, 11, 6419, 34, 22, 1, 168, 1972, 6, 4173, 50, 971, 1556, 251, 26, 369], [3, 33, 131, 58, 256, 21, 9929, 372, 1773, 130, 9, 71, 5, 133, 5, 192, 102, 8, 1165, 7, 1359, 16, 20], [90, 98, 6420, 689, 4983, 773, 1774, 66, 48, 477, 6, 3188, 32, 264, 3, 150, 5], [15, 99, 570, 29, 589, 17, 29, 107, 108, 82, 97, 501, 1207, 696, 8, 134, 17, 764, 9], [39, 9, 276, 107, 233, 61, 3, 150, 254], [38, 164, 762, 5, 142, 397, 4, 19, 35, 8, 72, 463, 167, 13, 2, 141, 1664], [175, 71, 5, 26, 26, 3, 972, 143, 207, 617, 309, 82, 325, 45, 522], [57, 61, 6, 14, 20, 479, 21, 26, 325, 70, 207, 617, 243], [281, 571, 430, 1206, 1174, 176, 531, 1097, 55, 2584, 1, 219, 271, 750, 423, 82, 17], [667, 329, 27, 4, 9930, 9931], [407, 7, 434, 6, 17, 519, 9932, 47, 56, 4984, 1239, 1089, 9933, 47, 1861], [5, 2884, 613, 774, 12, 56, 5, 148, 1196, 96, 477, 6, 161, 340, 583], [3, 28, 1135, 99, 4037, 958, 4, 4985, 161, 153], [18, 60, 112, 45, 31, 3, 430, 22, 1, 15, 178, 962], [78, 9, 1208, 18, 274, 2648], [53, 128, 4174, 6, 471, 22, 53, 9934, 917, 128], [3, 131, 61, 6, 22, 161, 45, 9935, 4, 193, 71, 1, 231, 14, 644, 35, 3589, 14, 3590, 6, 491, 240, 38, 3, 94, 76], [9936, 26, 9937, 60, 2649, 30, 1, 3, 90, 38, 5, 8, 9938, 192, 79, 263, 141, 481, 1, 11, 9939], [268, 16, 4, 237, 232, 1098, 891, 8, 852, 6421, 26], [68, 329, 420, 8, 1557, 20, 1, 588, 26], [1, 57, 42, 223, 72, 1, 4905, 220, 18, 4, 310, 83, 218, 6, 4, 100, 39, 663, 62], [3, 109, 90, 22, 1, 34, 40, 62, 17, 237], [3, 90, 2, 1, 7, 13, 6, 687, 163, 9940], [5, 4175, 141, 9, 53, 872, 21, 4, 921, 26, 22, 12, 356, 964], [9941, 7, 57, 582, 61, 28, 17, 2, 828, 1], [41, 4, 9942, 9943, 10, 9944, 14, 9945, 123, 10, 228, 188, 326, 41, 68, 3, 87, 378, 36, 63, 1478], [174, 944, 2, 9946, 90], [185, 1], [15, 2262, 1400, 2437, 52, 2, 1, 25], [9947, 4986, 33, 41, 50, 30, 9948, 26, 1335, 71, 25, 14, 36, 29, 182, 44, 36, 1, 108], [31, 2, 1, 175, 296, 468, 1489, 9949, 1099, 11, 50, 706, 149, 40, 2, 593, 93, 65], [122, 6, 298, 178, 18, 17, 42, 171, 1, 410, 50, 205], [296, 62, 3, 456, 70, 2, 320, 16, 78, 9, 549, 26, 32, 3, 63, 113, 5, 9, 28, 168, 6, 15, 368], [3, 452, 302, 2, 1693, 4987, 410, 32, 218, 26, 9950, 41, 68, 26, 52, 41, 6422, 4, 1], [23, 33, 2, 1, 21, 43, 2437, 3, 86, 23, 356, 601], [31, 123, 791, 50, 6, 2438, 389, 1388, 608, 12, 2, 404, 88, 221, 9951, 29, 94, 4, 9, 4, 199, 26, 7, 422], [68, 16, 20, 234, 418, 510, 35, 6423, 76, 1, 62, 162, 3, 259, 3, 14, 869, 82, 10, 218], [20, 117, 151, 114, 77, 18, 4, 117, 129, 960, 245, 115, 9952, 42, 608, 7, 9], [19, 32, 4, 1136, 3189, 6424, 66, 62, 69, 5, 49, 42, 372, 13, 4, 9, 214, 36, 91, 359, 27, 2, 203, 517, 1], [31, 1518, 109, 41, 762, 35, 123, 2263, 1137, 7, 45, 12, 9953, 210, 52, 72, 2080, 72, 43, 6, 590, 24, 2263, 1137, 4837], [31, 5, 44, 2, 511, 252, 155, 166, 449, 5, 318, 14, 2, 1774, 20, 48, 29, 477, 6, 170, 462], [26, 45, 13, 22, 12, 726], [9954, 41, 2, 341, 1, 6, 856, 18, 17, 510, 11, 10, 1286, 288, 40, 47, 1862, 18, 307, 514, 7, 9955], [7, 68, 500, 5, 75, 598, 6, 28, 9956, 98, 12, 2, 187], [23, 515, 16, 50, 1490, 1454, 183, 231, 8, 185, 768, 10, 25, 6425, 40, 643], [1667, 1, 29, 9957, 550, 1], [9958, 1, 1, 43, 68, 3190], [2885, 305, 3591, 827, 406, 1], [162, 4, 9, 51, 45, 42, 41, 240], [1, 7, 3191, 18, 50, 231, 26], [135, 6, 32, 4, 265, 69, 44, 105, 592, 126, 226, 18, 393, 11, 2, 9959, 1333, 267, 306, 21, 4, 179, 2439], [8, 7, 85, 382, 1122, 49, 2, 675, 10, 9960], [57, 6, 58, 211, 4, 9961, 771, 8, 295, 6, 9962, 107, 9963, 485, 61, 9964, 272, 58, 97, 1], [66, 9965, 58, 5, 26, 19, 367, 3, 58, 471, 212, 1775, 2264, 337], [1458, 2578, 11, 10, 1], [3, 33, 1863, 119, 60, 4988, 467, 60, 9966, 61, 6, 22, 2429, 8, 44, 2, 89, 1, 6426, 18, 2, 25, 38, 3, 9967], [354, 851, 6427], [202, 1, 227, 1973, 303, 2, 1100, 8, 208, 13, 847, 911, 36, 47, 19, 25, 11, 4, 731, 9968], [19, 484, 741, 15, 315, 73, 19, 45, 24, 72], [782, 1974, 2265, 671, 1089, 9969, 84, 4176, 33, 56], [31, 5, 46, 41, 45, 784, 21, 97, 653, 57, 1, 223, 67, 5], [78, 1240, 9, 78, 1138, 279, 133, 3, 2266, 10, 4989, 11, 2, 1060, 689], [23, 1491, 16, 1694, 6428, 9], [574, 69, 86, 6429, 1741, 88, 1971, 383, 144], [1311, 7, 28, 1695, 344, 35, 21, 2262, 3486, 12, 56], [6397, 802, 77, 545, 22, 1864, 30, 1822, 3, 90, 779, 13, 50, 9, 87, 6, 14], [3, 13, 71, 86, 23, 81, 6, 9970, 336, 55, 10, 89, 3, 911, 5, 46, 41, 9, 13, 6430, 58], [3, 301, 5, 220, 3192, 139, 345, 1, 23, 9971, 108, 330, 281], [194, 18, 280, 5, 2, 6431, 21, 719, 10, 175, 1, 30, 25], [1287, 186, 26, 1287, 1], [3, 46, 41, 43, 409, 120, 1, 12, 4, 101, 184, 7, 3, 13], [10, 381, 13, 2650, 51, 4, 1352, 230, 52, 973, 4177, 52, 804, 1492, 1975, 20, 804, 1], [57, 103, 4, 1583, 14, 211, 1362, 56], [39, 9, 46, 334, 26], [286, 97, 36, 198, 70, 127, 9972, 2267, 1401, 13, 1305, 26, 160, 325, 14, 2056, 972, 2, 207, 91], [85, 7, 9, 345, 11, 50, 6432, 321], [32, 39, 9, 132, 433, 224, 6, 2, 2886, 145], [26, 4178, 4178, 9, 120, 617, 14, 32, 9973, 657, 207], [5, 29, 477, 38, 3, 81, 485, 604, 477, 38, 3, 4990, 7, 1, 96, 266, 477], [6433, 1, 340, 3193, 2117], [1492, 692, 4, 413, 1036, 128, 93, 188, 1037, 30, 9, 90, 76, 2060, 9974, 99], [26, 92, 22, 9, 89], [4991, 134, 17, 4992, 10, 145], [211, 5, 28, 328, 298, 1036, 18, 2, 1, 7, 18, 50, 1230, 26, 43, 7, 530], [23, 18, 10, 9975, 45, 168, 6434, 51, 197, 340, 1558, 558, 76, 9976, 9, 55], [71, 1, 71, 1241], [4993, 18, 2, 9977, 34, 11, 166, 1199, 40, 196, 3592, 9, 8, 48, 110, 480, 9978, 26, 736], [1481, 5, 158, 55, 1325, 1865], [3194, 2887, 182, 1, 9979, 225, 32, 15, 114, 12, 2, 161, 1402, 8, 39, 1, 67, 5], [55, 93, 92, 3, 41, 76, 530, 388, 102, 10, 108, 3, 63, 114, 279, 16, 624, 52, 686], [2651, 654, 3593, 11, 9980, 49, 1745, 6435, 26, 6435, 377, 374, 48, 33, 2, 9981, 9982], [272, 1866, 22, 177, 15, 295, 5, 1324, 235, 30, 1], [286, 6436, 3, 131, 94, 22, 26, 367, 9983, 73, 286], [3, 486, 2, 77, 2650, 50, 2440, 3195, 57, 7, 196, 29, 19, 50, 117, 11, 4, 24], [1976, 11, 9984, 688, 308, 5, 56], [3, 67, 6, 14, 2065, 27, 217, 8, 3, 67, 217, 6, 14, 2065, 27, 9985, 42, 318, 44, 6, 204, 4, 1], [35, 70, 137, 63, 3, 44, 10, 659, 1, 504, 42, 156, 742, 59, 108, 478], [23, 19, 9986, 450, 4, 264, 27, 60, 1028, 37, 209, 21, 167, 17, 35, 1], [31, 80, 24, 1116, 26, 42, 407, 878, 9987], [4094, 24, 4994, 65, 13, 2, 9988], [326, 6437, 6, 36, 373, 1242, 1000, 48, 7, 1, 40, 87, 6, 242, 35, 26, 400, 4, 19, 142], [1139, 628, 939, 17, 36, 939, 17, 99], [1288, 9989, 11, 2118, 1094, 9990, 26, 198, 3, 61, 258, 22, 9], [1289, 558, 2, 83, 6438], [31, 3, 448, 327, 16, 474, 3, 58, 11, 10, 164, 78, 9, 118, 616, 11, 64, 29, 204, 240, 4179], [9991, 4027, 4180, 46, 834, 1, 5, 2, 19, 9992], [5, 203, 1, 1551, 139, 1942, 20, 767, 38, 5, 114, 3591, 78, 65, 807, 48, 4181], [71, 1, 14, 65, 4, 250, 115, 16, 2119, 26], [1613, 663, 1614, 2888, 120, 1, 55], [8, 243, 6, 14, 9, 776, 9993, 130, 14, 11, 3594], [993, 120, 4182, 26, 1, 4183], [32, 4, 1526, 379, 234, 9, 152, 14, 51, 1851, 13, 26], [4855, 1, 6, 182, 795, 1735, 18, 2, 1520, 1194, 26, 155, 412, 136, 2, 1, 13, 22], [38, 4, 25, 27, 4, 3196, 2652, 868, 60, 56, 45, 26], [1, 11, 4, 848, 65, 13, 2, 803, 358, 645, 26], [71, 202, 1, 484, 38, 36, 323, 107, 18, 26], [32, 78, 60, 19, 490], [46, 10, 1661, 5, 161, 399, 411, 3595, 14, 6, 274, 88, 3596], [57, 39, 1, 67, 82, 585, 25], [31, 3597, 26, 960, 1754, 44, 43, 437, 249, 126, 91, 138, 88, 5, 1696, 65, 291, 1, 982, 1776], [31, 42, 72, 174, 2, 3598, 15, 2441, 196, 174, 24, 12, 9994], [23, 2653, 2, 1, 205], [241, 10, 381, 24, 12, 37, 926, 106, 6, 6439, 15, 2374], [38, 5, 61, 142, 6, 119, 4, 24, 8, 15, 532, 6440, 26], [272, 33, 572, 5, 9, 9995, 572, 240, 519, 68, 55], [15, 10, 381, 457, 5, 198, 28, 15, 2, 89, 1], [258, 2, 334, 236], [1583, 109, 248], [181, 34, 1458, 647], [53, 723, 73, 9996, 1521, 729, 10, 310, 79, 1, 3, 516, 14, 9997], [5, 13, 6441, 5, 87, 9998, 5, 2, 282, 1272, 23, 9999, 10000, 10, 1270], [5, 146, 19, 155, 849, 33, 6, 94, 678, 10001, 5, 13, 4, 4184, 593], [3, 487, 167, 2, 414, 27, 2, 1757, 8, 24, 3, 29, 279, 71, 643, 74, 613, 40, 12], [45, 162, 5, 82, 10002, 91, 76, 9, 595, 26, 284], [366, 93, 441, 27, 2, 89, 1], [226, 256, 56, 3599], [75, 2, 1, 259, 72, 3, 1051, 50, 1486, 6442, 66, 87, 127, 189, 13, 5], [21, 32, 4, 89, 1, 54, 116, 10003, 61, 44, 60, 501], [3, 293, 10, 1152, 436, 69, 182, 40, 318, 14, 12, 376, 74, 1470, 661, 31, 14, 2, 9, 117, 92, 25, 4995, 4996, 35], [23, 370, 3, 1001, 5, 38, 3, 79, 5, 2, 1, 3, 1061, 299, 5, 10004], [128, 6443, 270, 2, 9, 1614], [119, 50, 24, 579, 65, 51, 50, 13, 22, 26], [3197, 10, 1230, 18, 75, 429, 7, 24, 92, 932], [3198, 3600, 11, 201, 115, 4997, 26, 394, 42, 210, 110, 44, 2, 438, 1, 3, 33, 363, 8, 72, 11, 4, 1825], [36, 14, 90, 18, 10, 77, 205, 34, 36, 301, 36, 47, 4, 1, 36, 90, 22, 323, 61], [133, 6, 28, 2, 2624, 6444, 39, 1, 14, 11, 4, 10005, 686], [63, 3, 316, 4998, 1, 74, 336], [2889, 354, 1321, 354, 367], [354, 49, 339, 1751, 2120, 27, 3601, 3602], [148, 22, 1, 156, 28, 167, 18, 123, 4, 6445, 189, 163, 70, 76, 150, 185, 3, 41, 79, 98, 2121, 204], [128, 3, 453, 219, 14, 2, 9, 21, 32, 7, 3, 46, 196, 13, 7, 77, 55], [128, 857, 48, 3, 47, 133, 6, 72, 29, 580, 1, 7, 45, 2, 4999], [43, 1, 1867, 35, 10006, 37, 807, 3, 75, 1841], [6446, 367, 1, 10007, 542, 965], [1025, 35, 8, 1, 47, 48, 135, 10008, 407, 1076, 125, 10, 9], [272, 229, 10, 30, 390, 3, 63, 150, 15, 10009, 3, 47, 86, 4, 199, 45, 1], [2, 320, 16, 287, 69, 708, 36, 49, 190, 49, 428, 355, 207, 1380, 639, 6447, 23, 190, 205], [1137, 2890, 12, 248, 289, 132, 72, 22, 21, 2654, 19, 170, 649], [162, 195, 3, 18, 22, 877, 1844, 10010, 5, 96, 255, 76, 207, 1372, 74, 576], [133, 6, 498, 10, 1766, 6, 107, 19, 80, 10011, 410, 240, 205], [38, 78, 9, 61, 6, 683, 71, 6, 1175], [5000, 10, 312, 647, 3128, 10012, 647, 10013], [221, 5, 137, 17, 221, 5, 41, 57, 5, 10014, 34, 675, 18, 5, 5, 59, 6, 14, 2, 803, 83, 6427], [6448, 12, 32, 3, 191, 21, 5, 183, 88, 2, 9, 88], [1967, 100, 10015, 636, 23, 784, 14, 2, 10016, 1], [38, 9, 150, 13, 126, 846, 210, 28, 602, 443, 26, 7, 17, 640, 30], [328, 3199, 32, 39, 19, 25, 4185, 4185, 9, 411], [6449, 7, 79, 4, 77, 2, 10017, 5001, 23, 398, 16, 76, 205], [583, 157, 2, 413, 10018, 35, 168, 10019, 8, 123, 2, 10020, 403, 10021, 239, 103, 5, 3200], [5002, 5003, 2122, 26, 10022], [321, 5004, 424, 4, 190, 6450, 26], [140, 3, 299, 1615, 2268, 118, 167, 50, 221, 52, 12, 1370, 21, 6451, 2, 1, 74, 201], [53, 93, 24, 44, 2, 25, 13, 53, 2123, 184, 289, 182, 297, 18, 10, 909], [78, 37, 172, 56, 80, 91, 76, 25, 152, 404, 4, 682, 56], [3, 198, 14, 4, 6452, 10023, 16, 256, 3, 157, 574, 18, 855, 879, 9, 3603, 25], [2891, 294, 54, 18, 39, 9], [26, 39, 1, 2373, 6, 28, 505, 149, 2, 2108, 39, 25, 14, 10024, 221], [55, 57, 499, 58, 66, 44, 11, 2269, 25, 90, 376, 11, 4, 1136, 850, 12, 21, 4, 95], [10025, 321, 36, 398, 1524, 7, 6431, 1, 69, 309, 241, 219, 10026], [22, 9, 304, 444, 40, 41, 2655, 6, 70, 2, 6453, 10027, 26, 241, 10, 1403], [584, 10028, 10029, 4186, 3128, 821, 6454, 10030, 72, 1, 5, 24], [1, 28, 459, 135, 171, 30, 128], [10031, 1, 26, 267, 5], [13, 32, 10, 406, 6, 28, 2, 253, 30, 1, 53], [3, 87, 127, 10032, 748, 268, 573, 4187, 68, 55], [3, 318, 19, 224, 8, 19, 80, 1, 119, 50, 30, 38, 20, 719, 50, 37, 604, 14, 2, 112, 30, 25], [22, 1032, 87, 6, 48, 1736, 225, 66, 122, 6, 1243, 4188, 2, 1, 390, 10033], [4, 115, 5, 5005, 17, 5, 103, 671, 2, 91, 1404, 34, 7, 266, 582, 37, 5, 33, 2, 83, 55], [10034, 10035, 2442, 394, 5, 10036, 741, 147, 9], [376, 129, 27, 189, 317, 196, 66, 152, 1066, 302, 17, 20, 2, 1, 21, 2223, 76, 24], [5, 4, 112, 3478, 7, 827, 97, 1, 121, 38, 3, 1056], [1965, 24, 767, 160, 26, 4189, 11, 4, 759, 313, 15], [4, 89, 1, 49, 101, 89, 444, 36, 192, 81, 2656, 52, 2892], [674, 159, 33, 41, 785, 767, 10037], [38, 186, 992, 706, 17, 126, 56, 1827, 26], [5006, 10038, 223, 338, 4190, 52, 56, 769], [10039, 27, 954, 9, 18, 10, 138, 5, 44, 683, 82, 4, 237], [2, 320, 16, 76, 49, 1168, 764, 14, 1604, 56], [400, 11, 116, 8, 45, 1138, 751, 9, 26, 10040], [693, 464, 26, 109, 9, 109, 42, 4, 5007, 114, 2, 327], [38, 23, 11, 7, 24, 2443, 23, 337], [643, 1, 293, 40, 133, 15], [162, 58, 32, 4, 6455, 61, 38, 36, 10041, 2, 189, 4, 6455, 1219, 114, 76, 211, 5, 157, 76, 793, 20, 2270], [78, 49, 37, 1075, 39, 2124, 26, 495, 157, 7, 9, 11, 2, 472], [2, 1082, 16, 10, 1199, 1090, 12, 111, 687, 59, 57, 15, 196, 6, 14, 2, 388], [5, 63, 14, 2, 9, 461, 44, 352, 191, 245, 16, 4, 77, 262, 3201, 25, 51, 4, 199, 817], [23, 2, 2657, 51, 468, 5008, 60, 111, 33, 75, 806, 10, 5009, 168, 16, 4, 197, 10042, 588, 149, 3, 72, 19], [10043, 26, 26, 10044, 866, 10045, 2, 1310, 453, 236, 216, 22, 327, 3, 394], [31, 3, 487, 302, 60, 16, 4, 774, 71, 222, 3, 302, 39, 10046, 75, 55], [2893, 1336, 359, 26, 40, 124, 343, 13, 2, 10047, 10048, 2574], [39, 9, 54, 16, 829, 10049], [31, 3202, 5010, 2894, 103, 2894, 290, 108, 29, 44, 6, 41, 5011, 95, 8, 4191], [23, 551, 23, 133, 6, 10050, 2, 498], [4192, 4192, 3, 81, 45, 18, 186, 8, 37, 7, 1, 572, 17], [10051, 405, 76, 1, 13, 2, 6456, 2658], [4193, 504, 49, 4, 237, 26, 139, 308, 6, 39, 9, 5012, 7, 45, 589], [10052, 47, 2, 285, 10053], [10, 1, 89, 40, 2, 5013, 4194, 57, 323, 12, 7], [322, 177, 231, 2895, 267, 104], [98, 4195, 8, 2, 470, 423, 82, 1285, 5014, 14, 10054, 6, 2833, 33, 2, 6457, 6458, 150, 98, 10055], [66, 54, 2444, 2373, 125, 22, 1946, 1596, 13, 1290, 4196, 11, 22, 1, 26, 1140], [26, 1, 272, 1448, 1062, 3, 75, 4197], [19, 5, 183, 55, 229, 76, 1022, 1, 19, 42], [55, 14, 431, 2896, 5, 62, 20, 994, 1582, 10056, 41, 32, 50, 1022, 9], [1091, 1, 4, 1101, 4198, 10057, 82, 10058, 6459], [36, 75, 1023, 18, 7, 969, 30, 606, 10059, 5, 62, 57, 582, 215, 106, 66, 47, 10060, 1961], [61, 171, 18, 22, 2897, 1, 5, 4199], [3, 19, 35, 11, 4, 2248, 10061, 1, 5, 67, 6, 290, 17, 27, 80, 797, 30], [78, 18, 10, 909, 87, 6, 14, 376, 78, 41, 261, 740, 1, 3, 41, 344, 73, 432, 87, 6, 61], [3, 29, 2445, 238, 14, 974, 38, 3, 72, 83, 15, 33, 2, 1067, 13, 321, 74, 386], [5, 48, 223, 338, 9], [4, 244, 106, 3, 94, 22, 1, 23, 257, 50, 809, 401, 74, 1591, 55], [19, 35, 1, 28, 54, 2125, 331], [89, 1, 12, 4, 101, 184, 7, 3, 13], [15, 46, 5015, 1933, 10062, 12, 1, 40, 243, 3548], [43, 622, 75, 28, 43, 169, 622, 1482, 1774], [39, 638, 1, 869, 747, 1190, 36, 46, 11], [29, 72, 45, 499, 33, 411, 1, 66, 63, 58, 2, 320, 127, 102, 22, 186, 45, 5, 63, 107, 94, 17], [25, 81, 127, 88, 1, 39, 115], [5, 141, 185, 30, 1, 3, 46, 172, 27, 5], [3, 46, 223, 308, 26, 206, 235, 72, 36, 94, 15, 11, 17, 37, 3, 1244, 336, 5, 33, 144], [128, 26, 6460, 372, 379, 483, 81, 133, 9, 163, 441, 163, 45, 2893, 5, 146, 477, 6, 22, 45], [25, 129, 5016, 27, 358, 30, 269, 1291, 70, 4, 237, 2126, 10063, 3, 566, 3203, 2, 275, 273, 17, 22, 469], [601, 3, 90, 3204, 26, 601, 3, 64, 254, 2579, 18, 4, 106, 16, 213, 3, 3604, 26, 4, 171, 1, 7, 259, 135], [252, 1390, 461, 15, 14, 21, 98, 3605, 1405, 12, 315, 483, 20, 726], [74, 52, 119, 15, 218, 52, 27, 2, 287, 69, 33, 75, 867, 88, 42, 146, 28, 2256, 16, 7, 9], [23, 61, 6, 346, 39, 1, 37, 209, 26, 750, 117, 40, 763, 18, 802, 77, 517, 78, 356, 73, 45], [5, 47, 27, 4, 1, 27, 4, 203, 30, 101, 193, 6, 259, 38, 42, 379, 7, 45, 152, 28, 206, 205, 8, 44, 2, 320, 16, 6461, 11, 15], [3606, 1, 30, 46, 334, 51, 32, 412, 907, 30], [9, 5017, 903, 409, 80, 1, 518, 11, 2898, 6, 94, 31, 15, 429, 35, 18, 108, 1447, 267], [3, 47, 273, 105, 4200, 26, 105, 506, 10, 10064, 198, 44, 273, 622, 271, 11, 261, 10065, 2659, 236, 17], [1, 42, 122, 15, 26, 42, 655, 155, 2446, 324, 7, 510, 54, 890, 476, 680, 9], [68, 215, 565, 51, 22, 64, 45, 88, 23, 381, 5, 9], [664, 5, 255, 2, 1366, 10066, 11, 2, 10067, 51, 2, 688, 92, 96, 632], [57, 93, 10068, 4, 1198, 65, 51, 9, 167, 42, 790], [38, 5, 458, 20, 3205, 1468, 8, 28, 201, 190, 26, 128, 321], [457, 696, 192, 225, 242, 80, 9, 30, 35], [1, 25, 389, 21, 9, 33, 6, 973, 27, 9, 1769, 68, 264, 604, 389, 6, 271, 27, 9], [31, 20, 4201, 2447, 16, 2448, 645, 5, 2, 9, 2899], [11, 4, 1483, 27, 80, 1, 8, 80, 169, 23, 28, 17, 1406], [119, 2, 320, 16, 10069, 119, 2, 320, 16, 24, 119, 4, 413, 30], [23, 2407, 1], [38, 5, 259, 22, 315, 5, 75, 14, 1491, 16, 268, 202, 138, 11, 20, 4836, 5, 19, 494], [2, 320, 16, 5, 1693, 87, 6, 472, 35, 73, 112, 435, 21, 923, 371, 78, 14, 208, 13, 1, 32, 1608], [5, 67, 6, 14, 2, 141, 1, 130, 272, 557, 5, 13, 2, 141, 83], [591, 3607, 12, 37, 19, 332, 221, 31, 20, 2, 24], [10070, 200, 6462, 52, 5018, 1, 2127], [69, 4, 206, 1, 6463], [3, 64, 4, 323, 10071, 10072, 104], [3, 90, 38, 1, 58, 7, 1472, 49, 5, 81, 3608, 45, 13, 1113, 10073, 14, 13, 757, 125, 143, 355, 676, 917], [33, 41, 328, 27, 10, 215, 679, 8, 23, 2900, 224, 2852, 13, 3, 373, 22, 507, 3206], [219, 23, 61, 6, 376, 181], [10074, 1697, 12, 54, 761, 527, 12, 11, 26, 1950, 4, 10075], [36, 48, 10076, 9, 11, 2259, 10077, 16, 15, 749, 88, 67, 538], [38, 5, 19, 50, 93, 40, 840, 110, 127, 93, 138, 70, 2, 1, 61, 284], [37, 239, 9, 7, 10078], [31, 2, 4803, 317, 44, 2, 108, 761, 18, 71, 52, 192, 52, 200, 15, 21, 24], [289, 372, 13, 2, 181, 4, 215, 607, 115, 20, 1393, 49, 2660], [77, 596, 203, 24, 3207, 3609, 203, 30, 163, 2901, 872, 10079], [5, 63, 14, 10080, 34, 48, 786, 10081, 10082, 41, 98, 6464, 27, 10083, 389, 76, 6, 168, 4, 226], [69, 7, 24, 631, 21], [5, 10084, 441, 6465, 49, 589, 483, 18, 186, 441, 8, 1616, 49, 4, 199, 184, 104], [53, 23, 651, 53, 10085, 5, 456, 14, 19, 35], [128, 10, 1, 47, 477, 6, 4202, 451, 3199, 2267, 11, 50, 402, 10086, 3, 47, 345], [85, 3208, 1, 30, 2883, 359, 18, 3610, 595, 30, 432, 10087, 116, 127, 6, 2, 25, 130, 84, 10088, 299, 78, 724, 147], [26, 5, 198, 150, 974, 31, 2, 1, 122, 6, 249, 5, 35, 27, 1015, 6466], [78, 1, 1868, 2, 6467, 25, 69, 4, 286], [69, 12, 40, 78, 1617, 7, 1407, 2887, 418, 35, 34, 23, 2, 497, 2, 391, 992], [1739, 404, 178, 985, 4, 1321, 658, 34, 38, 36, 28, 6, 4, 1408, 7, 56, 483, 55, 90, 30, 25], [44, 984, 1, 109, 4, 10089, 5, 41, 32, 4, 9], [25, 67, 2, 93, 77, 34, 96, 131, 19, 27, 9, 34, 7, 46, 223, 1869, 146, 479, 68, 177, 411], [3209, 4203, 1, 4204, 740], [76, 148, 10090, 300, 128], [306, 29, 79, 2, 77, 2, 83, 7, 495, 10091, 17, 8, 495, 1, 99], [120, 265, 443, 2271, 1121, 79, 111, 6468, 18, 2106, 10092, 126, 1245, 1375, 512, 35, 126, 261], [251, 1, 49, 270, 1543, 71, 1038, 36, 58, 22, 6, 50, 26, 5019, 10093], [313, 6469, 51, 1, 69, 87, 6, 6470, 562, 573, 147], [168, 693, 903, 10094, 1002, 340, 6, 10095, 4, 699, 16, 7, 30, 2449], [18, 10, 193, 6, 19, 174, 1, 26], [18, 10, 193, 6, 19, 174, 1, 26], [10, 646, 2, 10096], [1138, 924, 25, 38, 2, 275, 94, 97, 9, 30, 6471, 61, 477, 6, 60, 10097, 169, 10098], [60, 16, 78, 1618, 49, 248, 588, 322, 93], [133, 106, 60, 16, 39, 418, 29, 67, 2, 91, 36, 33, 67, 4205, 113, 7, 1, 6, 28, 2, 1865], [38, 4, 24, 1116, 26], [375, 22, 280, 6425, 29, 229, 111, 22], [10099, 5, 41, 4, 9, 55, 78, 3, 592, 22, 3210, 18, 10, 1832, 26, 10100], [31, 40, 471, 5, 677, 18, 1396, 1858, 34, 20, 48, 68, 16, 4, 292, 189, 18, 50, 443, 40, 2, 282], [49, 2, 413, 320, 165, 38, 20, 484, 2, 5020, 26, 1678, 120, 24, 4206, 28, 10101], [43, 1363, 2, 234, 1, 26], [1218, 18, 111, 33, 229, 5, 2128, 878, 1777, 11, 246, 324, 15, 2, 1, 25, 10102], [3611, 54, 135, 257, 1, 35, 26], [2, 575, 12, 101, 216, 21, 10103, 34, 60, 1, 29, 62, 71, 6, 10104, 6, 7], [85, 12, 416, 69, 86, 20, 98, 6472, 10105, 10106, 1870, 2, 1977, 8, 52, 90, 207, 617], [6473, 77, 5021, 10107, 30, 1], [11, 4, 1698, 360, 6474, 196, 6475, 82, 202, 4182, 15, 179, 18, 263, 8, 4207, 18, 76, 281, 26], [15, 13, 38, 2, 1, 146, 322, 24, 34, 15, 1394, 26], [10108, 4, 120, 77, 42, 198, 2661, 51, 34, 4208, 3211, 61, 21, 4, 2272, 89, 1484, 9, 182], [26, 71, 379, 12, 22, 9, 27, 2, 6476, 2270], [3, 2273, 10109, 2094, 95, 2094, 1684, 6335, 8, 4, 10110, 10111, 151, 14, 10112, 2828, 10113, 75, 6477, 7], [10114, 26, 10, 443, 409, 16, 283], [10, 175, 56], [969, 815, 1, 1663, 1357, 65, 13, 10115, 128], [542, 665, 22, 1, 142, 10116, 17, 292, 10117], [3, 487, 258, 393, 6, 555, 10, 343, 35, 100, 771, 157, 2, 3612, 10118, 1, 3, 121, 448, 2, 912, 327], [10, 338, 54, 12, 56, 42, 549], [1409, 41, 43, 6478, 1, 12, 4, 101, 184, 7, 3, 13, 773, 23, 33, 259, 164], [171, 918], [3, 122, 6, 176, 32, 10, 1, 18, 973, 423, 199, 193, 3, 150], [302, 39, 1, 336], [12, 15, 329, 31, 3, 28, 18, 22, 1, 8, 192, 81, 45, 367], [46, 295, 165, 11, 164, 130, 563, 2, 9, 27, 2, 392, 106, 10119, 100, 50, 44, 50, 373, 5022, 25, 57], [4175, 73, 45, 117, 3, 297, 240, 294, 142, 4, 606, 1335, 3, 47, 11, 4, 967, 205, 52, 2, 811, 5023], [3, 566, 2821, 3212, 12, 2, 193, 16, 113, 31, 2, 1, 24, 12, 10120, 57], [53, 3, 1014, 76, 9, 4853, 5, 560, 33, 1014, 80, 164, 10121], [55, 281, 10122, 1762, 879, 1], [90, 484, 11, 4, 10123, 2129, 5, 63, 484, 1762, 879, 11, 20, 6479, 476, 9], [20, 1242, 12, 1555, 140, 20, 2, 838], [573, 295, 242, 35, 10124, 1, 69, 13, 6, 4209, 51, 393, 7, 10125, 4, 910], [19, 50, 117, 11, 4, 24, 26, 3, 301, 22, 252, 47, 10, 2902], [38, 5, 94, 4, 1, 7, 132, 81, 737, 59, 5, 11, 4, 6480, 26], [3, 33, 67, 5024, 2130, 10126, 180, 517, 10127], [652, 36, 32, 205, 280, 3, 90, 2, 3613, 10128, 127, 130, 166], [3, 41, 169, 743, 1052, 1, 579, 2396, 25, 19, 22, 4083, 990, 44, 10, 6481, 28, 51, 25, 2, 316, 147, 928, 913], [31, 2, 1, 107, 21, 17, 3, 293, 40, 133, 32, 7, 2274, 45, 40, 6482, 59, 5025], [23, 556, 119, 60, 24, 128], [38, 77, 114, 10, 1396, 108, 8, 1493, 55, 7, 2903, 831, 2, 1100, 8, 1369, 21, 4, 10129, 1493, 3, 29, 100, 76, 114, 15], [2, 154, 1871, 16, 120, 4983, 26, 40, 2131, 7, 1], [2, 1, 487, 389, 17, 6, 28, 384, 554, 361, 1446, 1154, 432, 94, 71, 153, 54, 135, 1872, 265, 54], [25, 67, 285, 3, 46, 134, 245, 897, 135, 12, 162, 308, 305, 10130, 7, 431], [1292, 58, 15, 1, 70, 50, 616, 11, 64, 198, 3], [31, 40, 303, 5, 2, 1356, 436, 7, 77, 22, 1], [1, 72, 1410, 1173, 41, 57, 52, 655, 34, 33, 2, 707, 892, 67, 22, 91, 351, 10131], [1, 14, 13, 1208, 10132, 26], [38, 40, 191, 71, 571, 119, 50, 24, 26], [77, 5, 119, 1091, 24, 130, 17, 77, 5, 1521, 132, 2, 25, 7, 7, 1873], [338, 32, 4, 2450, 6, 1], [215, 264, 47, 6483, 501, 128, 5, 41, 60, 24, 210, 97, 10133, 3213, 43, 55], [78, 275, 64, 78, 2, 1699, 25, 74, 2, 865, 4138], [5, 811, 10134, 31, 5, 41, 4, 1619, 5, 67, 233, 2, 145, 33, 238, 176, 50], [29, 28, 18, 280, 26, 38, 482, 3214, 246, 158], [3, 33, 3215, 672, 2, 1616, 4889, 3, 380, 116, 568, 10, 5026, 16, 14, 692, 351, 21, 164, 26, 3614, 26, 128], [69, 499, 86, 767, 1942, 12, 19, 643, 444, 7, 1, 1942, 99, 332, 157, 2, 9, 54, 469, 21, 7], [39, 4, 265, 7, 79, 5, 158, 18, 2106, 26], [71, 3, 150, 38, 23, 313, 56, 5027, 26, 744, 11, 2119], [38, 52, 70, 42, 84, 3105, 26, 84, 9, 443, 15, 26], [275, 7, 62, 36, 49, 9, 109, 4, 3615, 10135, 352, 10136], [36, 178, 12, 129, 19, 78, 1, 26, 78, 764, 26], [15, 318, 14, 60, 16, 78, 275, 24, 631, 149, 52, 345, 251], [3, 72, 1, 89, 414, 93, 462, 165, 6484], [354, 8, 1778], [485, 218, 20, 157, 302, 11, 2, 53, 1, 53, 48, 2, 3519, 74, 485, 140, 22, 2, 19, 323], [242, 4, 19, 35, 5, 19, 56, 25, 197, 18, 246, 1013], [10137, 11, 4, 190, 12, 728, 332], [326, 64, 3194, 2887, 149, 7, 1039, 19, 102, 6485, 147, 10, 83], [3, 259, 11, 4210, 1293, 16, 14, 45, 18, 123, 2, 95, 219, 22, 428, 19, 582, 6, 17, 230, 10138], [3, 3140, 10, 89, 1, 3, 75, 176, 76, 54, 10, 231], [2813, 10139, 216, 4211, 1494, 6, 2275, 143, 360, 143, 667, 1, 25, 45, 3, 118, 4212, 2, 77, 4211, 6, 2451, 667, 833, 1978], [171, 1, 2276, 568, 99, 749, 26, 7, 32, 5, 674, 1620], [3, 100, 10, 77, 10140, 17, 6, 4, 618, 1265, 40, 276, 58, 256, 2452, 22, 1, 363, 539, 10, 310], [57, 31, 24, 557, 2904, 13, 347, 557, 10141, 8, 1874, 10142, 444, 42, 157, 15, 18], [15, 603, 132, 546, 10143, 5, 745, 124, 68, 1661, 371, 42, 33, 132, 3616, 9, 5028], [20, 575, 450, 48, 20, 1068, 139, 14, 2, 1779, 1], [5, 1481, 13, 2, 9, 37, 43, 267, 5, 26, 272, 14, 1677, 38, 3, 58, 15, 1, 23, 544], [3, 90, 71, 60, 16, 5, 1, 107, 6, 261, 6486, 26, 13, 71, 364, 5, 294, 54, 20, 331, 1116, 20, 779, 46, 45], [1176, 1, 14, 13, 749, 29, 1411, 17, 9], [78, 180, 5029, 10144, 260, 343, 1412, 1, 65, 13, 10145, 82, 29, 14, 2, 6487, 188, 22, 12, 48, 35, 21, 2277], [53, 6488, 31, 5, 2, 9, 5, 2662, 18, 4, 1352, 8, 48, 10, 148, 10146, 34, 20, 457, 12, 11, 5030, 74, 3535, 1171], [23, 37, 544, 85, 5, 9, 17, 26, 552, 3, 33, 1559, 13, 3216, 5, 55], [26, 61, 6, 376, 10147], [3, 109, 101, 13, 13, 292, 111, 11, 22, 975, 416, 499, 12, 2, 104, 17, 17, 17], [165, 48, 44, 245, 1, 30, 111, 11, 10, 521, 740], [148, 36, 41, 1039, 616, 108, 25, 233, 3, 29, 958, 10, 9], [38, 5, 430, 20, 77, 58, 60, 9, 45, 747, 20, 108, 26], [3, 258, 531, 67, 6, 2898, 1320, 190, 10148, 43, 265, 57, 12, 61, 18], [76, 631, 72, 10149, 94, 31, 36, 41, 76, 9, 11, 2663, 3, 103, 471, 5, 10, 169], [22, 1, 1133, 483, 26, 68, 16, 10, 746, 1560, 124, 6, 1780, 50], [10150, 5, 29, 86, 52, 62, 57, 52, 200, 47, 171, 71, 1220, 49, 5, 242, 20, 1, 30, 35], [19, 20, 1, 8, 440, 50, 1671, 26], [2664, 38, 2, 1, 28, 1135, 205, 73, 358, 73, 40, 1138, 208, 284], [470, 78, 9, 96, 41, 879, 11, 78, 260, 343, 242, 35], [357, 67, 6, 14, 27, 2, 1699, 1030, 1699, 1], [174, 500, 504, 12, 2, 659, 1446, 1561, 147, 9], [462, 31, 2, 25, 156, 131, 61, 54, 8, 460, 155, 696, 26, 52, 339, 234, 9, 1495], [3151, 5, 152, 114, 17, 3217, 60, 9, 48, 152, 100, 5, 107, 129, 444, 5, 1049, 169, 18, 10151], [990, 12, 38, 2, 1, 815, 65, 13, 36, 10152, 57, 10153], [225, 47, 2, 358, 2905, 1, 43, 15, 407], [522, 715, 24, 34, 24, 903, 522, 37, 522, 285], [3, 300, 31, 3, 94, 245, 1979, 10154, 26, 6489, 5, 372, 13, 2, 339, 120, 1], [1413, 9, 1980, 1121, 534, 1272, 3218, 1375, 2132, 2591, 1205, 1294, 3219, 943], [1158, 919, 17, 1, 5, 29, 87, 6, 10155], [355, 833, 684, 1857, 1611, 26, 52, 456, 14, 82, 4, 6490], [366, 4213, 10156, 6491, 10157], [3, 90, 22, 45, 13, 85, 78, 1, 86, 7, 342, 10158, 754, 4939], [346, 5, 24], [3, 366, 13, 787, 10159, 2, 115, 670, 384, 1, 123, 143, 874, 10160], [2453, 2906, 6492, 232, 92, 1337, 10161, 12, 2, 6493], [330, 61, 26, 71, 3, 65, 51, 234, 9, 38, 803, 294, 11, 4, 3220], [42, 523, 10162, 3617, 34, 20, 10, 177, 23, 721, 23, 637, 27, 350, 5, 171, 1, 71, 189, 72, 296, 64, 1323], [75, 397, 2, 868, 30, 10163], [70, 441, 348, 390, 784, 1099, 17, 2, 4961, 10164], [4, 9, 6494, 55], [2907, 10165, 206, 1], [10166, 47, 58, 4820, 11, 4, 848, 16, 4, 606, 215, 264, 8, 976, 1, 15, 407, 4820], [3, 67, 24, 21, 1283], [38, 50, 677, 56, 5, 146, 1552, 754, 108, 18, 50, 8, 471, 240, 108, 26], [9, 14, 13, 2612, 3, 64, 10, 154, 3557, 53, 26, 299, 22, 47, 6495], [1981, 10167, 30], [659, 10168, 835], [3, 150, 13, 987, 22, 12, 85, 80, 24, 1116], [1264, 318, 14, 4, 250, 25, 6, 1875, 492, 2, 10169, 22, 2, 2647, 26, 175], [546, 793, 11, 2133, 12, 2, 10170, 332, 6, 258, 76, 9, 33, 13, 6, 1209, 3618], [1083, 22, 27, 2, 3619, 10171, 23, 2, 2454, 11, 4, 3524, 13, 2, 260, 11, 4, 56], [1083, 22, 27, 2, 3619, 2665, 20, 13, 2, 1, 27, 43, 30, 5, 46, 41, 45], [5, 33, 183, 483, 741, 6, 68, 945, 53, 22, 154, 830, 56, 74, 6496], [5, 2666, 101, 2666, 25, 6497, 129, 418, 27, 2227, 1982, 69, 49, 5], [156, 238, 6498, 10172, 38, 10173, 12, 603, 32, 78, 86, 59, 37, 10174, 10175, 26, 601], [6499, 15, 23, 105, 255, 10, 6500, 361, 519, 34, 5, 29, 2667, 13, 2, 161, 1, 5031], [7, 46, 10, 282], [22, 419, 45, 37, 723, 249, 15, 1], [10176, 10177, 12, 4, 6501, 837, 3, 44, 182, 297], [5032, 6502, 404, 52, 96, 56], [345, 129, 2, 189, 18, 2908, 336, 1, 479, 20, 235, 35, 5, 70, 4, 4214, 10178, 267, 10179, 10180, 4214, 10181], [93, 24, 14, 70, 2, 25, 44, 6, 10182, 349, 54, 8, 28, 20, 299, 612], [3, 672, 1312, 24, 410, 50], [432, 279, 59, 553, 16, 39, 1], [105, 297, 37, 239, 697, 1, 1062, 3, 216, 2, 186, 34], [23, 2, 900, 30, 1, 10183], [1279, 119, 24, 12, 37, 209, 10184, 398, 530], [19, 2, 147, 10, 1, 48, 10, 1562], [32, 3, 67, 12, 1, 180, 10185, 1], [26, 71, 12, 22, 2455], [3, 29, 13, 2, 179, 275], [31, 5033, 10186, 63, 468, 1414, 1311, 63, 5, 203, 30, 9], [139, 134, 2, 25, 24, 52, 139, 896, 13, 52, 279, 43, 573, 966, 188], [32, 3, 131, 58, 12, 61, 2386, 88, 107, 108, 337, 8, 973, 11, 618, 2600, 102, 204, 268, 95, 27, 68, 4215], [98, 10187, 469, 122, 6, 44, 352, 27, 4216, 4217, 10188, 269], [182, 704, 2, 1, 7, 19, 27, 20, 25, 34, 47, 6, 24, 6, 1124, 15, 2, 1, 21, 2, 83], [151, 258, 2, 342, 10189, 6, 438, 244, 213], [3, 33, 216, 7, 1876, 10, 83, 10190, 15, 932, 55], [66, 29, 64, 39, 9, 26], [19, 2, 1983, 368, 278, 516, 44, 2, 93, 77, 69, 2, 1125, 33, 21, 17, 10191, 106], [419, 483, 66, 29, 279, 20, 183, 769, 410, 17, 24], [3, 29, 64, 39, 9, 10192], [38, 5, 122, 6, 1131, 34, 7, 24, 1116, 26], [8, 355, 1111, 49, 10193, 73, 66, 137, 11, 4, 1700, 6340, 4, 6503, 12, 194], [5034, 10194, 11, 6, 4218, 135, 11, 4, 10195, 52, 87, 6, 61, 423, 1069, 63], [3599, 2278, 1136, 2278, 10196, 146, 70, 1695], [23, 48, 2, 1, 13, 55, 370, 48, 370, 122, 6, 134, 170, 2, 6504, 7, 3, 210, 67, 6, 569, 6, 170, 37, 1153], [26, 242, 35, 10197, 1399, 35], [354, 684, 853, 1054, 26], [53, 3, 41, 2, 905, 196, 3620, 296, 14, 1412, 196, 5035, 8, 432, 110, 14, 10198, 1, 242, 4, 19, 10199], [32, 3, 67, 21, 10, 457, 12, 2, 275, 27, 2, 2850, 10200, 180, 517, 9], [10, 746, 4219, 18, 5, 236, 469, 361, 53, 6505, 133, 147, 1781, 53], [805, 3, 258, 22, 45, 37, 356, 78, 9, 46, 6506, 27, 197, 15, 54, 27, 68, 25, 4994, 723], [42, 65, 13, 2, 1984, 4220, 205, 59, 6, 157, 11, 1194, 197, 148, 2643, 41, 32, 4, 675], [10201, 5, 459, 748], [22, 1, 308, 6, 17, 1208, 4221], [6507, 5, 609, 17, 1, 34, 5, 165, 262, 17, 108, 149, 23, 686, 19, 42, 10202], [23, 59, 99, 157, 2668, 209, 879, 11, 10, 19, 476, 8, 2212, 2224, 1, 622, 530], [23, 37, 6508, 26, 1], [4, 177, 273, 6509, 70, 76, 4222, 367, 1, 8, 3, 87, 240], [39, 9, 14, 137, 545, 17, 13, 3, 266, 471, 260, 10203, 51, 36, 145, 4223, 6510], [512, 7, 25, 8, 84, 2279, 1], [4224, 43, 446, 11, 14, 1176, 218, 2643, 9, 21, 326, 1517], [1312, 2, 9, 5036], [57, 184, 58, 5, 64, 531, 10204, 441, 24, 164], [1312, 2, 365, 1, 30, 25, 446, 3221, 5037, 251, 4029, 10205], [71, 3, 468, 22, 6511, 46, 468, 15, 5, 869, 15, 425, 6512, 238, 366, 7, 9, 6, 84, 653, 6513], [10206, 1026, 130, 2, 1, 27, 4, 466, 65, 13, 5, 54, 116, 10207, 3, 301], [736, 40, 6, 209, 16, 2, 3222, 21, 5, 105, 1293, 2216, 10208, 12, 135, 6, 492, 7, 9], [243, 457, 141, 83, 10209, 22, 216, 17, 528, 38, 3, 509, 15], [1396, 1858, 226, 333, 101, 1, 5, 63, 10210, 12, 17], [39, 9, 46, 334, 43, 36, 46], [162, 4, 1, 51, 221, 162, 36, 51, 3, 29, 62, 36, 415, 51, 7, 460], [3, 41, 4, 3621, 140, 23, 2, 181, 3, 46, 276, 308, 55], [5, 2, 10211, 87, 6, 1020, 80, 30, 35, 21, 854, 60, 185, 45, 13, 7], [43, 68, 13, 3, 163, 717, 3, 523, 1701, 1327, 965, 30, 283], [10, 1583, 49, 61, 6, 14, 37, 56, 22, 658, 3, 75, 304, 647], [520, 3622, 119, 80, 24, 32, 115, 358, 174, 143, 112, 3478], [71, 5, 70, 2, 2107, 8, 44, 43, 3223, 18, 4, 1, 134, 17, 2, 6514, 1295, 2107], [23, 37, 243, 11, 4, 561, 211, 3, 1390, 10, 24, 342, 156, 644, 17, 35, 21, 2, 93, 6515, 87, 60, 138], [3, 14, 528, 38, 10, 500, 14, 238, 1985, 1, 5, 911, 3, 363, 27, 5, 3, 62, 57, 5, 41, 26, 29, 41], [301, 390, 47, 2669, 37, 3, 63, 28, 6, 2280, 242, 80, 9, 30, 35], [57, 31, 3, 113, 78, 23, 122, 6, 227, 35, 21, 10212, 1621, 1, 5, 41, 4, 6516], [55, 3, 10213, 1085, 132, 147, 153, 205, 105, 10214, 6517, 3, 47, 1070], [65, 51, 628, 1013, 3, 75, 304, 444, 3, 63, 396, 588, 128], [243, 154, 213, 536, 80, 2670, 1612, 66, 41, 246, 755, 10215, 33, 200, 4, 161, 914, 142, 184], [1, 146, 197, 32, 332, 6, 656, 7, 45, 461, 1028, 50, 682, 10216], [10, 228, 49, 60, 10217, 1], [23, 238, 28, 60, 1979, 115, 138, 276, 70, 2, 153, 44, 2, 2909, 54, 116, 2250, 349, 35, 18, 97], [13, 85, 364, 12, 22, 1, 253, 17], [218, 5, 2, 9, 55, 218, 5, 363, 18, 20, 161, 2910, 18, 17, 91], [7, 407, 17, 9, 2671, 1587, 23, 6518, 3497, 513, 370, 6518, 10218], [57, 42, 200, 1826, 1, 139, 79, 17, 7, 34, 3, 466], [432, 119, 534, 26, 1, 57, 5, 315, 21, 88], [1409, 41, 48, 409, 188, 89, 1, 12, 4, 101, 184, 7, 3, 13, 5038, 313, 7, 30, 11, 2, 6519], [25, 12, 9, 91, 3, 300], [22, 9, 1963, 121, 296, 505, 10, 10219, 1, 50, 977], [325, 9, 5039, 103, 19, 35, 2, 631, 651, 429, 35, 11, 4, 651, 13], [42, 2, 9, 6405, 42, 146, 65, 51, 147, 45], [161, 2456, 1, 3623], [1619, 131, 1338, 21, 24, 34, 23, 13, 2581, 92, 2281, 50, 18, 6, 1278, 40, 168, 6, 19, 21, 351], [4169, 26, 4225, 645, 29, 505, 36, 2457, 155, 148, 264], [55, 217, 273, 17, 3, 124, 9, 37, 3, 1415, 76, 22, 26], [1, 23, 6520, 4226], [19, 4, 77, 1702, 71, 52, 396, 38, 2, 25, 1986, 35, 641, 170, 26, 1, 30], [357, 279, 59, 2841, 6521, 6522, 279, 133, 10, 1081, 9], [435, 907, 11, 36, 150, 209, 6523, 130, 2282, 48, 17, 3, 907, 11, 97, 1], [1, 23, 18, 1, 23, 18, 10, 10220, 1021, 10221], [10, 310, 1338, 3224, 144], [3, 67, 60, 24], [2283, 9, 10222, 244, 106, 14, 3624, 26, 425], [117, 552, 678, 68, 47, 506, 24, 21, 6524, 34, 7, 193, 99, 314, 21, 76, 10223], [3625, 5, 62, 69, 37, 1220, 6525, 34, 367, 2875, 23, 721, 5, 569, 20, 453, 6, 39, 10224, 9], [502, 7, 1, 2, 10225, 371, 40, 131, 208, 1208], [23, 127, 1110, 59, 1971, 28, 54, 130, 1987, 10226, 28, 6526, 24, 5040, 10227, 24, 8, 10228, 10229], [3, 29, 13, 6527, 4131, 813, 76, 1, 14, 18, 546, 3626, 5, 3225], [3, 454, 31, 3, 410, 1312, 3, 14, 13, 3, 67, 19, 118, 3, 14, 329, 74, 5, 2, 14, 68, 4227, 73, 10230, 115], [15, 37, 454, 38, 5, 563, 2, 252, 7, 48, 2, 1, 30, 25, 39, 115], [221, 52, 1267, 64, 17, 52, 62, 52, 581, 25, 66, 29, 64, 39, 9], [23, 201, 209, 21, 39, 25, 8, 292, 209, 21, 39, 9], [10231, 271, 70, 501, 16, 71, 3, 119, 13, 2, 141, 368], [52, 200, 61, 11, 3, 47, 428, 1003, 52, 38, 7, 332, 163, 4, 967, 477, 201, 10, 312, 10232, 1877, 10, 774], [5, 46, 1101, 2284, 38, 23, 497, 125, 3627, 574, 294, 35, 6, 17, 6, 191, 17, 6, 114, 10233], [146, 303, 212, 10234, 845, 37, 39, 9, 266, 430, 17, 1878], [10235, 20, 109, 431, 20, 93, 51, 10236, 8, 20, 2, 1172, 12, 22], [632, 35, 1, 36, 47, 342], [3628, 156, 18, 4, 6528, 27, 625, 9, 112, 25, 128], [31, 52, 136, 2, 504, 29, 14, 2, 9, 8, 262, 170, 10237, 69, 42, 523], [29, 109, 44, 621, 6, 81, 6, 38, 184, 192, 61, 10238, 4228, 9, 30, 25], [6529, 10, 443, 40, 2, 158, 34, 3, 64, 50], [2214, 34, 3, 41, 9, 199], [10239, 5, 96, 10240, 97, 10241, 7, 1, 1490], [59, 6, 61, 114, 129, 4, 2, 22, 6530, 10242, 6531, 4, 635, 1, 6, 1236, 3226, 267, 5], [3, 105, 28, 18, 186, 34, 38, 3, 58, 3, 28, 11, 1, 290, 27, 956, 48, 110, 275, 4229], [233, 162, 4, 19, 12, 20, 503, 767, 26, 11, 10, 24], [1151, 4, 703, 1, 47, 868, 55, 3, 124, 99, 114, 10, 1414, 521, 99, 246, 822], [1416, 258, 54, 5, 638, 100, 1, 45, 18, 80, 231, 25, 12, 6532], [10243, 49, 37, 10244, 10245, 4, 1, 7, 366, 2390], [3, 90, 38, 3, 3185, 6, 70, 4, 190, 480, 34, 4, 347, 5041, 16, 17, 139, 51, 4, 480, 3, 14, 67, 6, 290], [3, 13, 142, 1], [25, 81, 127, 88, 1, 39, 115], [92, 1, 5, 4230, 805], [19, 76, 262, 15, 2, 5042, 805, 1605, 262, 1849, 102, 18, 17, 40, 168, 6, 14, 1, 133, 15, 205], [3, 87, 6, 258, 12, 398, 2, 148, 3629, 87, 6, 258, 2, 1, 2, 10246], [3, 29, 19, 6533, 42, 161, 185, 30, 1, 3, 46, 172, 125, 5, 42, 161, 1496, 1, 3, 46, 172, 125, 5], [1563, 350, 5043, 307, 1777, 615, 26, 151, 737, 2, 9], [23, 33, 2, 3227, 161, 1, 69, 64, 6, 376, 8, 119], [39, 9, 46, 334, 10247, 118, 62, 149, 23, 2, 10248, 34, 10, 408, 148, 362, 49, 160, 112], [221, 15, 109, 750, 8, 15, 1417, 31, 5, 13, 259, 123, 2, 413, 320, 16, 1307, 281], [23, 33, 2, 1, 30, 10249], [3, 29, 302, 77, 75, 302, 39, 9], [219, 66, 32, 62, 3499, 1564, 615, 447, 8, 66, 32, 4, 6534, 3228, 95, 19], [1622, 4231, 129, 5044, 1, 1622, 17, 13, 68, 16, 20, 1374, 77], [145, 5, 10250, 10251], [4171, 12, 37, 19, 196, 6, 17, 13, 148, 1, 55, 19, 5], [1, 23, 108, 51, 337, 615], [26, 7, 1772, 10252], [243, 755, 106, 237, 106, 16, 143, 115, 25, 29, 62, 133, 76, 243, 755, 9], [10, 443, 106, 16, 143, 115, 243, 755, 4, 89, 1, 107, 54, 8, 4, 422, 9, 51, 337, 58, 4031], [10253, 6535, 5, 183, 30, 180, 95, 65, 1, 242, 4, 19, 562, 10254, 322, 209, 11, 20, 231, 10255], [85, 42, 75, 33, 64, 140, 66, 29, 64, 39, 9], [3147, 137, 2, 434, 4877, 69, 4, 144, 92], [78, 1, 14, 429, 260, 54, 13, 15, 2, 10256, 57, 55], [714, 2, 1, 545, 10, 3229, 714, 25, 242, 35], [10257, 26, 50, 1879, 3230, 3630, 40, 119, 13, 2, 1339, 9], [139, 14, 270, 2, 1], [33, 10258, 22, 1139, 1, 10259, 12, 279], [33, 86, 31, 1285, 1159, 60, 178, 7, 370, 386, 16, 2, 1, 103, 105, 10260, 263, 2, 178], [1, 37, 713, 432, 1459], [3, 150, 370, 21, 1703, 168, 6507, 518, 6, 137, 310, 178, 171, 30, 9, 69, 46, 41, 2, 164], [151, 14, 2, 1, 38, 3, 44, 6, 14, 2, 1, 513, 2892], [1, 14, 644, 6536, 13, 1, 28, 20, 164, 21, 42, 28, 257, 35, 128], [7, 24, 37, 631, 40, 146, 1015, 6537, 113, 10, 624], [38, 3600, 236, 659, 4, 6538], [668, 44, 752, 618, 10, 995, 49, 662, 102, 4, 2817, 16, 4, 618, 2126, 17, 1, 23, 117, 1782, 5], [42, 2, 1321, 312, 42, 137, 54, 340, 55, 272, 340, 798, 10261, 115, 7, 914, 21, 1406], [2254, 6, 960, 888, 6539, 2, 434, 115, 21, 9, 1666], [55, 485, 3, 198, 134, 11, 579, 438, 39, 9, 18, 10262, 17, 62, 71, 7, 197, 55], [571, 349, 35, 18, 5, 119, 18, 7, 24, 8, 1598], [31, 5, 75, 28, 24, 461, 308, 6, 2, 77, 5, 963, 29, 4232, 10263], [10, 1246, 70, 17, 27, 3, 407, 2, 9, 82, 1247, 10264, 42, 18, 2, 694, 390], [24, 700, 578, 13, 2056], [92, 5045, 188, 155, 10265, 18, 135, 132, 238, 44, 36, 24, 670, 2, 150, 18, 29, 10266], [5, 62, 1004, 59, 2, 414, 2871, 1141, 38, 3, 64, 1031, 24, 37, 209], [85, 5, 100, 39, 9, 1516, 57, 66, 124, 117, 1880], [3, 33, 67, 4, 832, 1, 11, 4, 360, 117, 135, 18, 10, 3231], [2626, 18, 1881, 51, 10267, 18, 1881, 10268, 2458], [3, 87, 920, 6540, 8, 6540, 774, 728, 4, 431, 3, 87, 60, 351, 45, 74, 60, 9], [96, 28, 43, 10269, 26, 52, 383, 14, 10270, 2, 181], [57, 521, 5, 11, 117, 92, 3, 87, 10, 5046, 21, 10271, 1230, 23, 686, 1, 10272], [1210, 526, 22, 229, 216, 17, 345, 23, 270, 2, 24, 10273, 109, 49], [2911, 411, 15, 186, 3, 222, 800, 10274, 70, 17, 1, 491, 5, 361], [3, 62, 42, 210, 167, 7, 3631, 27, 10, 1988, 5047, 233, 10275, 497], [19, 659, 2881, 19, 147, 83], [318, 61, 6, 10276, 10277, 69, 5, 223, 61, 27], [23, 2, 2826, 3, 1279], [3, 47, 6541, 2459, 10278, 1989, 128, 281, 576, 497, 5, 4, 68, 528, 51, 6430], [70, 4, 247, 16, 57, 5, 2912, 29, 113, 17, 57, 6, 58, 1], [232, 103, 105, 44, 217, 255, 2, 419, 3632, 2134, 361, 211, 22, 658, 2375, 229, 7, 12, 98, 3232, 1947], [85, 58, 1, 397, 13, 22, 26, 40, 67, 6, 14, 11, 3233, 4233, 5048, 496, 37, 5049], [15, 29, 690, 162, 66, 51, 22, 25, 156, 238, 2661, 51, 2, 1, 6542, 3633, 51], [22, 1, 6543, 5, 932, 932, 55], [108, 88, 9, 210, 67, 17, 92, 23, 341, 36, 32, 18, 307], [296, 63, 442, 7, 1336, 6544, 8, 7, 68, 1582, 1, 49, 28, 2285, 53], [549, 16, 32, 4, 56, 81, 8, 2913, 10279, 2286, 44, 6, 114, 829, 38, 87], [2287, 2, 1142, 27, 480, 207, 387, 26], [419, 306, 41, 7, 2914, 24, 55, 6545, 35, 34, 6190], [90, 38, 2, 418, 72, 61, 6546, 38, 42, 330, 10280, 54, 32, 42, 41], [1, 131, 438, 4, 5050, 25, 88, 14, 2135, 38, 52, 136, 9, 55], [462, 57, 31, 2, 252, 157, 268, 402, 11, 20, 24, 8, 192, 2427, 695], [42, 28, 57, 42, 157, 2073, 31, 32, 42, 1761, 12, 24, 29, 14, 214, 38, 32, 42, 3634, 12, 138], [184, 9, 4234, 26], [7, 10, 1988, 820, 18, 114, 10281, 1623, 56], [43, 68, 67, 98, 183, 25, 37, 814, 41, 170, 32, 6, 2915, 43, 127, 1040, 129, 9, 6547, 308], [78, 3635, 11, 2672, 7, 10, 1, 40, 75, 498, 2288], [42, 41, 9, 205, 6548, 162], [32, 3, 94, 11, 155, 10282, 26, 325, 14, 13, 143, 207, 1974, 666], [43, 87, 6, 267, 17, 204, 158, 12, 15, 373, 5051, 325, 10, 3494, 82, 305, 1851, 38, 66, 47, 5052], [43, 5, 2460, 370, 3, 75, 14, 344, 13, 5, 8, 349, 214, 1], [17, 292, 5, 29, 110, 2916, 24], [470, 4174, 6, 61, 619, 8, 298, 10, 310, 129, 27, 10, 347, 140, 15, 270, 2, 864, 16, 385, 58, 15, 24], [12, 15, 99, 570, 6, 157, 20, 231, 11, 60, 24, 10283, 105, 6, 570, 21, 1418], [57, 59, 4, 3234, 52, 2, 285, 52, 46, 61, 6549], [3, 67, 10, 1340, 6, 65, 13, 22, 26, 3, 33, 67, 22, 1, 1340, 55], [3, 29, 114, 111, 25, 1, 29, 137, 59, 36, 25, 1101, 36, 260, 803, 43, 1662], [3, 168, 6, 14, 7, 203, 1, 326, 216, 501, 16, 65, 51, 17, 92, 3, 47, 216, 501, 16, 21, 14, 183], [9], [31, 24, 12, 33, 24, 6, 5, 5, 2, 530, 30, 2461, 293, 5, 28, 1457, 1102, 10284, 6550, 7, 2917], [19, 17, 88, 1, 242, 35, 8, 694, 1014], [23, 48, 72, 23, 21, 22, 34, 233, 2577, 103, 19, 718, 34, 266, 100, 36, 1, 1882, 76, 142, 5, 5053, 1133, 55], [1, 3, 47, 10285, 10286, 34, 19, 5, 25, 1986, 35, 8, 23, 19, 27, 5], [62, 3, 63, 406, 7, 9, 11, 10, 235, 52, 93, 92, 762, 4, 2136, 54, 7, 177], [10287, 25, 23, 2462, 133, 10288, 8, 1402, 17, 99, 432, 9, 240], [1935, 408, 29, 1030, 4, 488, 7, 10289, 132, 56, 22, 213, 8, 7, 326, 1244, 54, 7, 1624, 1248], [593, 1, 131, 14, 2289, 26, 6551, 13, 2, 436, 34, 29, 62, 71, 6, 1845, 15], [42, 625, 315, 42, 105, 200, 559, 1341, 181], [281, 1], [3, 86, 22, 9, 1160, 74, 60, 45, 6552, 71, 239, 106, 66, 191, 162, 36, 10290], [9, 58, 9, 1162], [7, 154, 6553, 323, 6275, 12, 219, 2290, 219, 328, 10291, 1625, 142, 1], [180, 10292, 848, 714, 83], [38, 111, 733, 6, 17, 59, 1990, 23, 33, 13, 1, 58, 3, 65, 13, 3, 70, 4, 1585], [3, 90, 7, 1, 26, 4, 488, 7, 1312, 13, 4235, 33, 43, 10293, 10294], [52, 2, 9, 425, 652, 36, 32, 6554, 128], [189, 49, 9, 39, 115, 128, 29, 19, 6555, 17, 149, 3, 63, 157, 5, 18, 1626, 69, 6556], [6557, 6, 28, 2434, 3121, 23, 10295, 1, 14, 13], [2137, 562, 26, 21, 42, 9, 25, 37, 77, 7, 114, 426, 49, 9], [3636, 14, 723, 88, 2, 10296, 177, 5, 194, 17, 127, 130, 39, 9, 58], [3636, 392, 16, 10297, 16, 169, 9], [435, 49, 4, 796, 9, 128], [116, 427, 68, 323, 18, 5054, 1991, 3, 10298, 1030, 4, 323, 27, 1704, 1992, 140, 7, 10299, 1, 249], [447, 10300], [22, 1, 107, 117, 11, 26, 28, 10301, 3235, 26, 3, 105, 486, 22, 80, 10, 2138, 32, 54, 3, 90, 42], [1, 30, 25, 19, 5, 6558, 39, 9, 46, 41, 43, 3230], [5055, 300, 36, 1217], [10302, 2, 302, 6272, 1], [15, 342, 483, 1, 3, 442, 42, 15, 383, 28, 433, 302, 42, 125, 2, 4883, 6, 217, 235], [805, 3637, 10303, 422], [10, 226, 12, 6559, 188, 10304, 42, 9], [22, 1, 122, 4, 329, 68, 1627, 32, 61, 142, 3638, 82, 92], [32, 111, 182, 58, 18, 186, 12, 83, 28, 2, 639, 172, 10305], [3, 222, 1053, 2, 1177, 18, 4, 184, 9, 10306, 193, 4171], [99, 89, 4, 10307, 3, 44, 21, 4, 2095, 5, 29, 44, 21, 4, 1883, 114, 212, 10308, 207, 1178, 102], [23, 484, 531, 10309], [275, 28, 2083, 1026, 19, 76, 9], [1, 3, 79, 622, 108, 4, 308], [219, 14, 10310, 2212, 2, 401, 282], [52, 99, 613, 6, 100, 7, 1, 28, 170, 214, 13, 7, 25, 29, 86, 51, 32], [6560, 10311, 5056, 10312, 32, 7, 568, 54, 4, 1371, 38, 2, 1, 137, 27, 307], [12, 15, 17, 74, 277, 960, 1754, 46, 65, 73, 93, 43, 10313, 65, 165, 88, 39, 37, 79, 89, 1], [410, 2, 77, 69, 2, 9, 18, 186], [71, 58, 5, 44, 2, 681, 275, 8, 96, 258, 2, 193, 6, 19, 545, 590, 1541, 3, 29, 28, 15], [118, 64, 4, 10314, 1201, 77, 472, 13, 1362, 32, 115, 744, 100, 17, 94, 378, 16, 76, 9], [22, 189, 121, 52, 1705, 27, 2416, 10315, 241, 422, 100, 17, 6561, 10316, 62, 2, 77, 7, 124, 2673, 252, 10317, 48, 9], [155, 1, 113, 17, 3, 208, 13, 2, 2461, 766, 4, 19, 7, 196], [55, 4, 1, 48, 10318, 15, 431, 571, 28, 68, 3, 383, 302, 7, 127], [23, 48, 637, 6, 14, 20, 252, 2291, 4179, 7, 117, 1, 1625, 142, 6, 20, 2291], [3, 41, 625, 319], [2, 25, 69, 28, 1628, 16, 1, 12, 48, 152, 1884, 5, 13, 217, 499, 118, 20, 33, 10319, 2918, 649, 311, 7, 54], [10320, 42, 10321, 551, 1, 55], [31, 20, 61, 6, 81, 45, 59, 10, 6562, 29, 137, 43, 24, 385, 72, 15, 6, 50, 231, 80], [7, 68, 228, 69, 5, 3639, 27, 98, 6563, 158], [1993, 262, 20, 166, 894, 17, 26], [18, 2, 1844, 16, 6564, 22, 1, 12, 599, 2, 688, 10322], [22, 252, 2, 19, 2112, 321, 19, 50, 117, 11, 4, 24, 128, 26, 573, 10323, 50, 117, 11, 4, 24], [33, 297, 201, 554, 1, 290, 200, 4, 65, 13, 10324, 4236], [15, 10, 457, 6565, 2441, 357, 279, 1], [6525, 2, 9, 371, 10325], [23, 1174, 258, 2, 1, 27, 2, 203, 30], [6566, 3, 1279, 4, 247, 19, 35, 229, 3, 182, 194, 47, 6567, 1497, 5057, 436, 7, 9, 47, 4, 10326], [33, 486, 6411, 2674, 621, 10327, 304, 21, 2139, 369, 1, 278, 14, 32, 35, 11, 5058, 3127, 5, 150], [38, 9, 150, 13, 126, 846, 210, 28, 602, 443, 26], [3, 94, 37, 239, 214, 9, 18, 4, 3538, 1118, 45, 198, 14, 10328], [2279, 226, 12, 53, 10329, 8, 78, 1003, 40, 2, 282], [1039, 196, 4, 24, 93, 117, 92, 34, 5, 146, 61, 11, 201, 10330], [280, 10, 95, 271, 44, 352, 15, 18, 2, 1697, 6329, 121, 2919, 581, 43, 10331], [1318, 2, 228, 7, 249, 51, 567, 95], [31, 5, 168, 4, 5059, 2920, 5, 198, 857, 396, 20, 5060, 26, 10332, 7, 611], [69, 754, 11, 4, 3640, 23, 238, 1015, 10, 10333, 76, 9, 54], [128, 3236, 7, 117, 1, 61, 467, 60, 1097, 1778, 8, 61, 6, 618], [1, 121, 3, 308, 99, 209, 1, 5, 46, 783, 113, 4, 910, 99], [542, 21, 246, 2292, 10334, 26, 123, 17, 117, 9], [1143, 1858, 1, 66, 79, 78, 3641, 1599, 194, 326], [251, 36, 146, 632, 35, 51, 577, 5, 62, 39, 1, 67, 6, 14, 5, 3, 300], [38, 20, 500, 167, 5, 27, 7, 296, 346, 1323, 908, 5061, 1, 309], [7, 9, 223, 1873, 194, 31, 5, 46, 313, 30, 1, 993, 54, 4, 460, 53], [80, 779, 47, 1075, 38, 40, 124, 42, 55, 233, 39, 9, 46, 41, 43, 3230], [199, 9, 12, 96, 51, 15, 3, 1419, 1370], [19, 3, 65, 13, 236, 3, 65, 13, 367, 8, 97, 65, 13, 43], [66, 6568, 1704, 2675, 3237, 21, 4, 850, 89, 4189, 33, 131, 44, 501, 26, 22, 1, 136, 4, 2, 1203, 251], [29, 616, 11, 64, 27, 2, 1], [78, 25, 86, 3, 33, 662, 224, 20, 967, 58, 295, 1, 3, 14, 28, 1407, 99, 26], [4, 10335, 761, 12, 123, 750, 4, 10336, 761, 289, 182, 566, 24], [53, 31, 3238, 11, 80, 6569, 5, 2, 2826], [365, 1, 3, 29, 67, 20, 1420], [1994, 18, 76, 9, 26, 65, 51, 10, 260, 803], [3, 109, 90, 4237, 283, 5, 8, 17, 398, 91], [3, 41, 378, 6570, 3, 41, 1], [296, 195, 48, 2, 1, 3, 195, 4, 83, 37, 7, 12, 4238, 1, 6, 1323], [1843, 16, 4, 275, 5062, 87, 6, 139, 14, 270, 2, 1], [97, 25, 137, 6, 19, 10, 25, 137, 21, 10337, 1, 75, 19, 125, 17], [1539, 47, 4239, 11, 4, 177, 10338, 160, 2921, 5063, 26, 1482, 283], [31, 5, 29, 44, 20, 509, 3642, 18, 5, 2, 1, 4, 10339, 1, 182], [147, 95, 10340, 10341, 1, 10342, 1], [773, 8, 38, 4, 9, 192, 107, 29, 627, 69, 157, 5, 18, 3, 266], [5, 266, 44, 6, 4240, 21, 9, 43, 127, 55, 128, 3, 293, 48, 22, 45, 10343], [12, 3153, 123, 10344, 2, 112, 184, 2140], [78, 14, 2922, 53, 3, 67, 2, 64, 13, 5064, 26, 154, 10345, 45, 78, 330, 41, 1155, 308, 59, 69, 5, 49, 30, 9, 128], [3, 75, 81, 117, 92, 3, 41, 24, 18, 10, 1200], [66, 419, 218, 101, 9, 49, 10346, 32, 4, 93, 68, 1041, 10347, 275, 18, 4, 909, 7, 10348, 2, 10349], [23, 101, 108, 149, 3, 29, 131, 94, 4, 177, 468, 6, 56], [11, 2, 575, 27, 4, 1179, 16, 5, 160, 77, 27, 56, 64, 259], [10, 10350, 29, 67, 553, 650, 42, 656, 212, 1096, 5065, 1612], [1096, 24], [174, 24, 532, 13, 3239, 1402, 583], [5, 196, 4, 638, 3, 565, 151, 134, 5, 4241, 31, 42, 100, 245, 25, 532, 20, 24, 8, 15, 29, 532, 13, 385], [888, 1995, 24, 532, 13, 45], [], [4, 2463, 16, 4, 5066, 232, 3240, 2879, 26, 6571, 4, 6572], [203, 1180, 604, 182, 430, 17, 467, 2, 828, 199, 1], [23, 619, 20, 331, 22, 1], [2642, 42, 1, 23, 168, 7, 45, 82, 92, 962], [369, 10351, 85, 3, 46, 107, 6, 2905], [105, 475, 59, 4, 244, 83, 156, 5067, 59, 4, 244, 6573, 23, 238, 172, 119, 19, 57, 5, 533, 133], [148, 3, 156, 14, 175, 5, 10352, 175, 3, 1456, 6, 72, 9, 96, 29, 70, 10353], [26, 10354, 10, 2092, 121, 23, 3643, 19, 5, 10355], [3, 2464, 6, 44, 127, 1237, 7, 1, 1944, 130, 307, 7, 4199], [58, 22, 9, 131, 290, 117], [57, 9, 58, 3, 44, 1249, 18, 4, 3644, 16, 1250, 199], [85, 85, 85, 85, 85, 10356, 5, 46, 605, 245, 1, 3241, 738], [21, 4, 480, 1414, 10357], [31, 5, 41, 2676, 194, 1241, 7, 9, 259, 82, 92, 18, 10, 226, 12, 2677, 1701, 23, 48, 10358, 43, 127], [10359, 3645, 621, 151, 14, 116, 18, 4, 455, 1706, 201, 795, 27, 674, 159], [709, 42, 753, 17, 37, 3, 75, 706, 42, 37, 151, 72, 15, 135, 20, 2, 1395, 187, 128, 5, 63, 706, 17], [3, 81, 6, 245, 77, 69, 1135, 129, 10360, 21, 50, 6574, 11, 229, 17, 42, 1996, 41, 60, 409, 16, 900, 1, 11, 5, 55, 3537], [342, 262, 10361, 1, 107, 129, 21, 60, 1421], [43, 68, 67, 6, 94, 10362, 287, 160, 6575, 10363, 52, 144], [5032, 10364, 78, 169, 10365, 10366, 66, 47, 33, 142, 899], [22, 12, 17, 37, 6576, 4242, 526, 78, 60, 24], [55, 10367, 31, 80, 1, 29, 509, 1177, 74, 119, 10368, 40, 2, 282], [159, 870, 103, 44, 1094, 108, 73, 2, 863, 165, 863, 16, 180, 1296, 12, 1311, 92], [941, 176, 17, 635, 7, 85, 3, 64, 170, 26, 6577, 5, 41, 7, 9, 51, 1115, 1850, 932], [32, 39, 1, 28, 3646, 169, 25, 776], [7, 688, 274, 123, 898, 12, 37, 56, 4243, 267, 5, 30, 591], [31, 5, 330, 54, 16, 261, 19, 5, 3, 90, 5, 8, 3, 293, 5, 840, 18, 4, 1706, 51, 1851, 9], [3, 67, 3242, 1978, 34, 3, 560, 67, 6, 14, 440, 771, 10369, 58, 5, 94, 4, 1222, 10370], [229, 2, 2108, 64, 6, 10, 746, 205, 34, 39, 1, 37, 10371, 23, 11, 1885], [25, 300, 36, 64, 2, 2293, 1, 205, 26, 52, 2141, 3579], [336, 1416, 497, 3, 64, 4, 1, 13, 843, 64, 4, 265, 26, 5, 62, 22], [530, 389, 4, 1005, 1], [52, 273, 4, 1, 2406, 262, 10, 310, 10, 1619, 4826, 721, 52, 62], [200, 7, 1, 82, 2923, 182, 100, 15, 61], [37, 7, 2142, 959, 216, 17, 15, 1, 281], [3, 33, 929, 11, 4, 1359, 18, 2465, 140, 40, 33, 2135, 4, 2678, 54, 16, 17, 1, 7, 505], [347, 907, 12, 2, 511, 360, 39, 179, 189, 122, 191, 21, 10, 518, 55, 200, 36, 44, 6, 14, 179, 205], [31, 5, 58, 1997, 6578, 5, 394, 48, 1038, 175, 59, 946, 10372, 16, 76, 175, 36, 29, 58, 1086], [76, 1422, 3647, 8, 1998, 72, 6579, 920, 10373, 36, 72, 45, 13, 494, 464], [85, 78, 86, 15, 422, 6, 14, 104, 8, 67, 263, 6, 14, 431, 27, 76], [252, 54, 135, 103, 122, 8, 19, 97, 1, 747, 97, 108, 8, 113, 5, 40, 46, 93, 21, 97, 15, 6580], [18, 4, 1398, 2679, 116, 207, 343, 3648, 22, 456, 14, 4, 2466, 1835, 1269], [340, 354, 2, 10374, 785], [48, 68, 419, 1006, 11, 10, 481, 134, 2, 19, 59, 57, 4, 244, 1, 10375], [53, 3, 86, 31, 10, 504, 220, 6, 28, 1020, 35, 2213, 14, 4, 250, 68, 10376, 10377, 3527], [171, 30, 1, 410, 17, 244, 106], [71, 58, 111, 110, 28, 1562, 18, 307, 23, 13, 2, 966, 83], [65, 51, 10, 2680, 1, 289, 132, 4, 45, 10378], [431, 761, 1, 92, 433, 4, 866, 1], [22, 77, 1040, 17, 54, 432, 110, 44, 43, 9, 26, 45, 3, 14, 72, 55], [3, 150, 370, 21, 621, 69, 1135, 21, 10379, 140, 10380, 12, 56, 451], [1235, 4863, 4, 101, 391, 278, 10381, 6581, 10382], [55, 64, 5, 1707, 141, 1], [38, 42, 67, 2, 5068, 34, 174, 10383, 1661, 266, 61, 28, 76, 1707, 4244, 840, 620, 161, 1], [1695, 11, 10, 1783, 21, 2, 154, 10384, 3, 380, 15, 1498, 6, 72, 52, 1597, 508, 21, 84, 154, 164, 188, 10385], [116, 12, 2, 106, 26, 2, 507, 445, 6582, 6583, 105, 26, 11, 4, 6584, 26, 4245, 527, 26], [237, 668, 1007, 18, 4, 2444, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 2444, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 2444, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 2444, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 2444, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [237, 668, 1007, 18, 4, 731, 699, 1423, 877, 1424, 1425, 160, 899], [1629, 1630, 458, 1629, 503, 521, 1767, 1007, 697], [1629, 1630, 458, 1629, 503, 521, 1767, 1007, 697], [1629, 1630, 458, 1629, 503, 521, 1767, 1007, 697], [1629, 1630, 458, 1629, 503, 521, 1767, 1007, 697], [1629, 1630, 458, 1629, 503, 521, 1767, 1007, 697], [1629, 1630, 458, 1629, 503, 521, 1767, 1007, 697, 964], [1629, 1630, 458, 1629, 503, 521, 1767, 1007, 697, 964], [1629, 1630, 458, 1629, 503, 521, 1767, 1007, 697, 964], [85, 308, 20, 10, 399], [54, 1, 23, 404], [26, 3, 247, 4246, 103, 48, 100, 43, 1, 69, 1181, 2, 25, 3, 330, 124, 28, 4, 237, 54, 16, 17, 4247, 125, 10, 10386, 26, 45], [26, 3, 176, 7, 1, 18, 17, 15, 820, 16, 10, 1698, 37, 25, 94, 17, 38, 5, 94, 17, 430, 17, 11, 2924], [26, 39, 1, 2373, 6, 28, 505, 149, 2, 320, 16, 39, 25, 14, 137], [26, 19, 20, 1], [26, 432, 44, 2, 83, 37, 1530, 57, 2467, 29, 87, 6, 14, 10387], [26, 10, 746, 12, 109, 61, 6, 2143, 2223, 15, 34, 478, 1999, 4, 712, 27, 10388, 13, 109, 1, 85, 49, 5, 61, 6, 2223, 15], [26, 22, 1, 191, 17, 85, 10, 1708, 6585, 218, 36, 238, 555, 10, 6586, 35], [26, 593, 49, 255, 3649, 664, 49, 349, 54, 126, 10389], [233, 60, 16, 5, 9, 5069], [233, 38, 794, 1, 192, 90, 7, 1497, 2, 1, 514, 17], [233, 9, 657, 135, 33, 458, 645, 13, 2000, 676], [10390, 36, 72, 170, 36, 196, 391, 2925], [10391, 60, 6587, 30, 9, 405, 60, 6588, 74, 5070, 1216, 18, 685, 871], [10392, 4248, 269, 466], [10393, 1, 14, 58, 99, 209, 18, 186], [10394, 15, 190, 619], [10395, 677, 49, 56], [32, 675, 3243, 23, 784, 785, 15, 2, 145, 548, 505, 251, 26, 439, 26], [32, 4, 9, 334, 2641], [8, 5, 62, 7, 3, 442, 15, 149, 50, 24, 6, 6589, 880, 8, 40, 29, 19, 27, 239, 145, 40, 29, 19, 27, 245, 145, 439, 26], [10396, 72, 19, 7, 145, 52, 1709, 669, 439, 52, 75, 113, 7, 5, 2, 1125, 439, 7, 5, 46, 541, 21, 64, 749], [2294, 3650, 655, 7, 2144, 10, 145, 26], [260, 10397, 41, 17, 6590, 3, 67, 22, 1, 244, 99, 3651, 24, 13, 4249, 880, 26], [10398, 10399, 880, 41, 17, 10400, 3, 67, 22, 1, 244, 6, 17, 24, 13, 4249, 439, 26], [257, 4, 24, 35, 634, 15, 355, 13, 4150, 8, 211, 3, 19, 3, 28, 6, 10401, 13, 4, 10402, 439, 26], [14, 11, 64, 1040, 581, 145, 26], [1, 906, 2, 481, 59, 2, 449, 892, 19, 27, 263, 8, 66, 28, 6, 5071, 9, 298, 35, 18, 7, 145, 28, 5072], [291, 364, 459, 22, 145, 51, 899, 2144, 52, 139, 5073, 2145, 8, 32], [149, 39, 9, 46, 334, 8, 145, 46, 519, 38, 15, 61, 142, 5, 1275, 21, 10403, 7, 5, 10404], [149, 39, 9, 46, 334, 39, 25, 46, 519, 439, 38, 15, 61, 142, 5, 1275, 21, 6591, 7, 2419], [489, 2288, 378, 839, 19, 2, 10405, 149, 3, 731, 18, 4, 606, 10406, 62, 439, 5, 75, 302, 39, 9, 188], [29, 191, 17, 31, 23, 11, 10, 53, 150, 53, 149, 3, 46, 43, 1, 3, 29, 41, 212, 364, 26, 23, 611, 48, 11, 43, 19, 150, 26], [29, 376, 18, 581, 145, 10407], [10408, 6592, 2906, 47, 10409, 8, 6593, 215, 264, 55, 66, 47, 2874, 22, 581, 145], [1182, 2, 6594, 30, 145, 31, 5, 67, 99, 7, 276, 14, 80, 145, 1565, 30, 26], [82, 1554, 213, 6, 1526, 213, 22, 109, 10, 145, 192, 14, 646, 445, 213, 892, 225, 26, 15, 10410], [10411, 7, 47, 581, 145, 82, 2663, 1008, 880, 4250, 10412, 26], [19, 50, 117, 11, 4, 24, 2641], [19, 18, 4, 250, 264, 29, 70, 5, 2, 9, 26], [28, 60, 235, 102, 186, 92, 145, 7, 10413, 880, 272, 260, 734, 3244, 80, 1, 40, 63, 28, 15, 439, 2419], [41, 145, 2141, 51, 6595, 149, 80, 651, 1, 12, 581, 455, 1099, 2144], [10414, 10415, 2144, 55, 26, 145, 12, 109, 1850, 11, 22, 1, 880, 26], [243, 457, 6, 10, 455, 145, 117, 135, 6596, 66, 132, 51, 15, 21, 2, 691, 199, 651, 16, 1426, 613, 8, 10416], [90, 2, 275, 7, 41, 4, 1288, 16, 2, 145, 26], [44, 5, 182, 124, 352, 1427, 4251, 355, 2001, 6597, 203, 941, 145, 176, 7, 24, 1428, 631, 2144, 26], [9, 18, 10, 453, 3, 19, 9, 32, 4, 106, 26], [3, 46, 3225, 149, 3, 13, 50, 769, 40, 41, 2, 145, 8, 3, 41, 2, 77, 34, 769, 447, 769, 439], [3, 46, 3225, 102, 5, 43, 1091, 439, 3, 328, 405, 5, 439, 762, 10417, 439, 3, 222, 1161, 14, 2, 5074, 21, 2, 9, 880, 3, 10418], [3, 29, 13, 38, 145, 14, 13, 53, 162, 80, 1, 51, 53, 1710, 151, 536, 5, 18, 7, 1153, 69, 5, 12, 588, 2419], [3, 1181, 39, 145, 744, 1161, 396, 35, 156, 132, 4, 199, 6, 2, 145, 26, 132, 785, 45, 27, 581, 145, 26], [3, 380, 2, 145, 33, 442, 11, 97, 7, 2146, 21, 97, 63, 226, 2, 320, 16, 184, 245, 166, 91, 266, 58, 21, 10419], [3, 90, 2, 53, 10420, 69, 33, 122, 6, 81, 6, 5075, 53, 30, 1, 439], [3, 33, 150, 13, 10, 10421, 37, 587, 439, 151, 134, 3245, 6, 155, 145, 7, 182, 41, 227, 142, 21, 4, 702, 2926, 16, 10422, 439, 2147, 26], [3, 62, 3, 62, 3, 62, 26, 76, 606, 36, 19, 27, 17, 870, 8, 76, 1, 276, 19, 33, 140, 5076], [3, 516, 1429, 102, 88, 19, 9, 1249, 7, 45, 723, 134, 17, 2, 436, 26], [3, 109, 29, 134, 2, 19, 26, 469, 5, 192, 7, 53, 5, 41, 9, 5, 19, 27, 1, 53, 45, 23, 998, 6598], [3, 96, 29, 41, 4, 106, 21, 2, 1, 6, 14, 896, 4252, 439, 26], [3, 10423, 10424, 62, 59, 10425, 10426, 1, 439, 26], [3, 273, 22, 145, 6599, 10427, 10428, 22, 145, 276, 191, 17, 53, 12, 7, 4, 355, 3652, 2681, 2144, 369, 26], [3, 424, 4, 1, 142, 11, 4, 644, 80, 1, 28, 224, 11, 4, 644, 3, 138, 4, 1, 142, 11, 4, 644, 6598], [3, 103, 105, 438, 2, 275, 27, 246, 145, 226, 18, 50, 55, 26, 369, 26], [3, 454, 31, 5, 275, 54, 135, 182, 33, 400, 224, 8, 86, 133, 71, 78, 9, 74, 71, 4970, 78, 109, 12, 26], [3, 452, 316, 10, 77, 224, 357, 34, 2927, 880, 52, 4, 101, 145, 3, 62, 7, 452, 780, 27, 245, 16, 4157], [23, 332, 6, 204, 439, 23, 5077, 1054, 35, 27, 581, 5078, 1, 880, 26, 114, 102, 50, 1631, 8, 40, 96, 65, 13, 2, 10429, 880, 26], [23, 48, 276, 182, 14, 7, 145, 7, 167, 2416, 13, 18, 155, 406, 34, 3, 28, 1703, 3, 67, 1230, 26, 10430], [23, 7, 145, 5, 63, 229, 54, 11, 775, 10431, 880, 55], [278, 516, 400, 51, 4, 331, 32, 115, 8, 1429, 102, 88, 912, 2, 3653, 6, 599, 101, 497, 27, 2, 1, 10432], [552, 85, 145, 134, 2, 275, 235, 88, 313, 2, 2904, 18, 805, 145, 5, 330, 672, 4, 413, 3654, 880], [31, 3, 182, 157, 581, 302, 1427, 1, 151, 156, 14, 505, 880], [31, 3, 182, 157, 10, 302, 1427, 1, 151, 156, 14, 505, 880, 26], [31, 22, 183, 30, 145, 63, 14, 27, 50, 3, 63, 99, 26, 364, 40, 27, 10433, 10434, 21, 769, 22, 145, 65, 13, 6600], [31, 80, 154, 145, 75, 472, 165, 88, 17, 74, 110, 637, 6, 65, 165, 88, 17, 1138, 122, 6, 70, 1566], [31, 5, 28, 80, 77, 424, 29, 14, 214, 51, 4, 145, 69, 200, 15, 439, 14, 214, 51, 50, 149, 52, 29, 1632, 5, 2928, 40, 277, 26], [272, 204, 7, 24, 344, 1012, 7, 45, 8, 272, 119, 15, 119, 15, 119, 15, 880, 8, 735, 15, 634, 15, 491, 26, 773, 880, 26], [272, 349, 35, 119, 18, 7, 24, 8, 1598, 439], [272, 112, 379, 145, 6597, 6601, 764, 439, 294, 35, 23, 80, 1251, 5, 118, 86, 2, 145, 214, 51, 5, 26], [272, 379, 613, 145, 238, 19, 2, 145, 1, 10, 500, 2, 2682, 4, 10435, 14, 172, 18, 7, 1, 880, 4253], [4190, 145, 5, 63, 113, 82, 581, 6601, 4254, 3, 300, 3, 41, 292, 9, 27, 17, 33, 13, 23, 4255, 880, 26], [12, 22, 6602, 4, 145, 7, 41, 581, 1567, 554, 4, 145, 7, 75, 114, 1680, 73, 6600], [15, 33, 17, 74, 58, 5, 48, 67, 357, 499, 10436, 80, 77, 74, 145], [33, 47, 206, 6, 17, 2, 161, 10437, 150, 17, 60, 1, 7, 276, 150, 17, 60, 145, 7, 266, 204, 17, 26], [1416, 258, 54, 5, 210, 729, 10, 79, 149, 5, 6603, 27, 7, 145, 439], [2927, 10438, 65, 22, 145, 200, 2, 484, 123, 18, 4, 2295], [65, 51, 10, 500, 2296, 8, 40, 1784, 27, 7, 669, 30, 145, 439, 274, 12, 93, 880], [581, 145, 3650, 14, 1042, 84, 1162, 26], [70, 2, 145, 303, 2, 1013, 21, 97, 714, 439, 1960, 21, 97, 995, 439, 1708, 21, 7, 108, 439, 2871, 21, 4157], [2683, 39, 9, 28, 777, 439, 34, 60, 138, 8, 5079, 439, 31, 40, 27, 5075, 40, 10439, 3, 121, 4253], [10440, 597, 78, 1, 30, 35, 1009], [10, 4256, 41, 10, 19, 35, 880, 556, 1730, 4, 2652, 364, 224, 10, 310, 22, 1, 556, 1338, 225, 5080, 2641, 26], [10, 260, 779, 3225, 8, 7, 1, 63, 512, 880, 26], [336, 3, 46, 43, 9, 145, 43, 1, 145, 613, 145, 27, 4, 45, 145, 10441, 1499, 145, 26], [145, 121, 53, 10, 77, 102, 2148, 640, 145, 271, 54, 50, 3655, 53, 34, 4, 1, 65, 13, 10442, 10443], [145, 271, 1265, 3, 67, 36, 77, 2641, 48, 10444, 145, 26], [43, 1596, 21, 2, 9, 7, 46, 581, 455, 1162, 581, 145, 18, 4, 199, 1162, 439, 32, 581, 145, 5081, 188], [709, 3656, 1080, 5, 13, 139, 10445, 17, 23, 13, 1, 19, 5, 299, 40, 13, 145, 19, 5, 196], [422, 581, 1094, 1, 176, 3214, 17, 1275, 3246, 3247, 17, 439, 133, 162, 3, 132, 34, 3, 132, 27, 246, 1, 5082, 880, 26], [422, 10, 1094, 1, 176, 3214, 17, 1275, 3246, 3247, 17, 3248, 17, 59, 162, 3, 132, 34, 3, 132, 27, 246, 1, 5082, 439, 26], [18, 186, 72, 40, 3249, 21, 2, 145, 880, 26, 7, 85, 3, 109, 19, 27, 50, 40, 142, 6, 349, 4, 3229, 880, 26], [4250, 6604, 439, 26, 3, 29, 62, 170, 34, 3, 62, 2, 2297, 145, 11, 4, 689, 226, 6604, 28, 565, 390, 26], [920, 2, 93, 178, 27, 10, 2095, 145, 2144], [121, 3, 46, 1161, 64, 43, 10446, 34, 39, 1, 2298, 1886, 18, 17, 18, 17, 5083, 26, 37, 57, 195, 4253], [94, 3, 146, 28, 22, 169, 581, 4944, 6605, 145, 2468, 13, 9, 247, 16, 76, 1, 26], [1619, 131, 113, 17, 1564, 18, 71, 6, 742, 145, 3, 113, 7, 1, 15, 127, 1252, 38, 5, 555, 15, 142, 880, 26], [40, 10447, 10448, 40, 62, 23, 4, 24, 10449, 880, 26], [40, 4240, 3, 47, 2, 961, 177, 3, 4240, 40, 47, 2, 1052, 5084, 439, 32, 3, 62, 12, 40, 2, 112, 1, 37, 3, 19, 50, 13, 2, 112, 145, 26], [40, 64, 15, 38, 3, 81, 6, 50, 284, 880, 249, 2, 145, 138, 27, 2, 413, 2108, 1218, 439, 100, 15, 3657, 439, 447, 10450], [40, 47, 214, 21, 13, 473, 1204, 41, 129, 15, 8, 167, 170, 117, 108, 35, 55, 40, 279, 59, 7, 145, 26], [495, 107, 65, 51, 22, 145, 117, 135, 2064, 2219, 3658, 768, 2064, 55], [217, 100, 17, 62, 85, 898, 37, 587, 6606, 52, 10, 443, 992, 22, 145, 332, 26], [1658, 4257, 145, 109, 29, 14, 1886, 39, 9, 39, 9, 29, 14, 1886, 39, 145, 439, 26, 66, 33, 6607], [7, 2283, 2296, 10451, 184, 365, 88, 2, 663, 3, 33, 1401, 60, 1, 1157, 8, 15, 124, 17, 18, 4, 503, 26, 19, 1446], [7, 68, 145, 7, 1071, 4, 3196, 2652, 8, 192, 5073, 669, 30, 451, 2641], [4, 9, 556, 14, 13, 53, 6608, 2684, 2294, 8, 890, 524, 63, 44, 10, 260, 51, 4, 199, 106, 439, 53, 3596, 9, 46, 334, 26], [39, 145, 1, 79, 36, 734, 113, 50, 107, 8, 10452, 15, 519, 7, 15, 512, 170, 74, 512, 1703, 27, 170, 26], [22, 145, 2219, 3658, 487, 400, 142, 10453, 10, 145, 10, 145, 6596], [22, 14, 17, 2144, 1114, 363, 82, 53, 15, 106, 6, 1385, 142, 53, 6, 53, 162, 4, 9, 51, 53, 2144, 26], [22, 145, 10454, 13, 3659, 35, 18, 145, 11, 3660, 1355, 880, 26], [22, 145, 10455, 74, 766, 22, 145, 226, 12, 29, 655, 45, 21, 7, 120, 30, 315, 323, 26], [35, 2685, 39, 2686, 1941, 27, 581, 145, 10456, 880, 2927, 5085, 1558], [10457, 145, 10458, 39, 145, 107, 6, 975, 192, 10459, 10, 206, 659, 6606, 26], [597, 35, 23, 1236, 439, 10460, 3250, 43, 1040, 439, 6609, 274, 21, 581, 1875, 880, 581, 1, 72, 23, 4, 237, 880, 26], [27, 10, 5086, 10461, 5087, 8, 581, 455, 145, 3661, 2929, 4258, 6610, 880, 629, 2373, 211, 66, 479, 35, 4, 774], [78, 733, 59, 1887, 941, 1446, 126, 1263, 7, 472, 33, 13, 7, 30, 54, 8, 32, 411, 26, 29, 70, 5, 2, 9, 369, 26], [78, 9, 28, 227, 18, 21, 43, 540, 880, 14, 13, 53, 6608, 52, 41, 2292, 52, 1467, 3251, 27, 43, 5060, 439, 10462], [78, 13, 854, 169, 29, 303, 243, 34, 226, 2, 145, 400, 11, 2, 6611, 345], [5, 655, 2299, 2294, 3650, 880, 23, 3662, 7, 6, 32, 10, 206, 234, 9, 10463, 26], [5, 10464, 14, 2, 214, 2, 6612, 145, 2144, 854, 581, 226, 3, 4158, 41, 5, 10465, 145, 10466], [5, 4259, 27, 291, 145, 5, 276, 14, 291, 145, 2641], [5, 145, 896, 13, 9, 3, 63, 1881, 212, 2144], [5, 1888, 1308, 30, 275, 14, 1973, 533, 133, 53, 430, 150, 53, 1, 5, 87, 6, 430, 22, 10467], [38, 15, 107, 6, 24, 3, 44, 43, 19, 228, 160, 10468, 6610, 12, 109, 57, 220, 194, 117, 92], [201, 93, 891, 2580, 21, 232, 11, 10469, 527], [149, 36, 46, 50, 3, 46, 5088, 2687, 4, 2276, 478, 34, 85, 9, 1500, 18, 960, 888], [148, 5, 1430, 604, 28, 2, 543, 54, 16, 4, 5089, 2300, 16, 120, 2930], [5090, 15, 100, 61, 211, 4, 1224, 5, 44, 6, 94, 4079, 2301, 154, 1183, 1401, 10470], [155, 1, 41, 2, 203, 30, 74, 40, 10471, 82, 15], [627, 6, 2002, 56, 4, 166, 189, 21, 4, 89, 1317, 10472, 10473, 10474, 5091, 545, 10475, 315, 505, 10476, 267, 1065], [3663, 352, 2149, 1211, 18, 6199, 117, 211, 15, 4, 434, 2617, 159, 524, 70, 915, 1076], [1535, 82, 4, 688, 276, 14, 610, 406, 2003, 21, 2, 10477, 5092, 10, 312], [3, 2150, 11, 174, 24, 37, 3, 6613, 10478, 10479, 2004, 4, 247, 6614, 1253, 1415, 18, 2106, 4260], [10480, 18, 5093, 10481, 10482, 10483, 10484, 10485, 647, 480, 114, 99, 358, 70, 17, 10486, 513], [2688, 560, 5094, 207, 5095, 6, 507, 18, 4, 10487, 37, 7, 2005, 63, 4945, 126, 2689, 10488], [10489, 129, 51, 10490, 277, 1463, 6, 44, 43, 1, 109, 197, 74, 336], [3252, 513, 159, 6615, 12, 471, 216, 11, 3253, 3664, 1736, 4261, 108, 6, 2302], [10491, 10492, 5096, 10493, 368], [5097, 10494, 10495, 5, 25, 1868, 35, 20, 1242, 13, 104], [10496, 57, 2, 180, 711, 6616, 133, 6, 10497], [10498, 3254, 10499, 3193, 1564, 10500, 15, 72, 135, 1297, 5098, 47, 2, 1779, 141, 1], [10501, 10, 190, 1447, 2565, 21, 4, 10502, 1429, 11, 4, 10503], [10504, 3, 204, 7, 24, 40, 309, 27, 50, 387, 458], [10505, 79, 5, 2, 24, 21, 48, 58, 1526, 2931, 6617], [10506, 10507, 321, 55, 3, 2690, 211, 10508, 140, 474, 47, 56, 6618], [3504, 10509, 17, 222, 5, 48], [10510, 5097, 95, 79, 6619, 10511], [3665, 6, 5099, 10512, 6620, 173, 2, 5100, 53, 3665, 202, 928, 10513, 6620, 173, 2, 10514], [10515, 10516, 96, 2, 95, 30, 1], [10517, 188, 55, 57, 329, 27, 39, 1, 91], [10518, 6382, 10519, 88, 85, 42, 96, 419, 78, 258, 4, 2272, 9, 3666], [10520, 2, 2571, 2469, 59, 4, 10521, 10522, 5101, 16, 1120, 11, 4, 4262, 16, 10523, 10524, 1328, 382, 10, 206, 10525, 10526], [6621, 7, 24, 21, 10527], [10528, 284, 1, 2151, 4, 729, 66, 220, 65, 6622], [5102, 10529, 231, 10530], [10531, 402, 13, 95, 91], [10532, 539, 10533, 60, 9, 72, 6557, 2, 91, 201, 2126, 11, 4, 587, 6623, 1, 357, 131, 881, 20, 30], [10534, 6624, 6624, 10535, 17, 95, 242, 35, 10536, 1285, 7, 47, 98, 208, 16, 10537], [6625, 21, 10538, 6, 167, 17, 27, 4, 6626], [1002, 378, 852, 5103, 70, 111, 998, 126, 186, 1024, 10539, 52, 24, 205, 52, 572, 986], [6627, 10540, 5104, 92, 27, 57, 23, 61, 6, 10541, 1191, 6, 73, 10, 10542, 10543], [17, 6628, 10544, 13, 2, 144, 6, 70, 4, 166, 395, 65, 4160, 123, 1463, 6, 1279, 27, 6629, 10545], [85, 48, 978, 3255, 3, 67, 978, 353, 1471, 13, 2291, 1830, 8, 1977, 8, 743, 8, 45, 5105, 6630], [10546, 2303, 1568, 11, 979, 49, 21, 4, 104, 280], [10547, 10548, 71, 239, 9, 58, 5, 109, 44], [10549, 3, 547, 5, 10550, 5, 146, 1092, 21, 370, 7, 718, 309, 11, 20, 6631, 3220, 92, 20, 436, 6632, 135, 98, 6633, 2006, 1092], [26, 3667, 6634, 1827, 8, 3668, 283, 52, 318, 100, 5, 137, 84, 460, 2932], [188, 3, 33, 150, 89, 21, 4, 287, 7, 1475, 2230, 6, 270, 10551, 1021, 81, 4, 180, 81, 6, 1310, 453, 9, 8, 6, 126, 6635], [188, 34, 1, 430, 150, 211, 32, 4, 148, 817], [188, 55, 336, 9, 66, 6636, 27, 15, 37, 103, 78], [10552, 357, 506, 2304, 8, 207, 12, 7, 20, 172, 437, 19, 254, 23, 61, 92], [10553, 92, 175, 82, 2, 10554, 1], [10555, 15, 10556, 19, 158, 7, 32, 4263, 12, 8, 182, 103, 14], [6637, 23, 784, 108, 6, 6638, 101, 21, 4, 9, 8, 2, 521, 74, 268], [10557, 31, 2, 229, 59, 47, 79, 10558, 1400, 118, 345, 13, 161, 283], [6152, 2007, 1085, 63, 728, 2, 1582, 235, 8, 2, 1582, 24, 88, 1400, 37, 63, 6639], [10559, 120, 652, 5, 6155, 10560, 1028, 6, 10, 25, 6640, 2, 2933, 2606, 3669], [26, 367, 5106, 2691, 5107, 8, 1172, 10561, 10562], [26, 64, 1670, 6641, 270, 2, 2934, 21, 26], [26, 109, 277, 81, 13, 2, 1889, 158], [26, 12, 298, 224, 975, 2470, 522, 6, 1225, 31, 52, 114, 54, 4, 56, 99, 52, 12, 4, 697, 6642], [26, 222, 5, 33, 137, 201, 691, 16, 4, 159, 524, 10563, 10564, 10565, 2008, 372, 2471, 661], [26, 317, 15, 156, 150, 13, 66, 61, 173, 4, 658, 27, 1248, 10566, 7, 66, 6643, 56, 8, 88, 66, 28, 93], [26, 583, 10567, 65, 51, 5, 168, 20, 10568, 6644, 10569, 380, 66, 220, 101, 470, 329, 59, 5, 14, 2, 171, 838], [26, 10570, 10571, 1859, 111, 186, 11, 6645, 527], [26, 403, 5, 849, 2692, 6322, 3256, 1, 162, 20, 1043, 30, 569, 21, 2854, 18, 22], [26, 122, 1550, 51, 264, 21, 2, 112, 1594], [26, 267, 5, 10572, 3, 94, 305, 654, 95, 6646, 20, 10573], [26, 10574, 112, 10575, 401, 12, 6, 10576, 142, 4, 5108, 89, 5109, 8, 1086, 10577, 235, 173, 6647, 6648], [26, 222, 14, 255, 2, 56, 558, 8, 2213, 96, 14, 4, 4264, 8, 3615, 1044, 3, 62], [26, 1057, 3670, 3257, 958, 12, 405, 2693, 130, 10578, 26, 10579, 11, 4, 377, 2935, 3257], [26, 725, 64, 16, 642, 12, 10580, 10581, 642, 12, 1113, 4265, 83], [26, 27, 4265, 842, 21, 1351, 8, 3253, 983, 10582, 126, 1291, 1453, 20, 2, 19, 1633, 271, 54, 10, 3671], [378, 260, 734, 43, 1, 43, 436, 13, 4266, 42, 87, 2, 1021, 11, 97, 164], [378, 93, 77, 12, 783, 2472, 9], [378, 334, 77, 715, 10583, 9], [378, 127, 115, 1], [378, 127, 178, 16, 2686, 88, 23, 1056, 10, 154, 1177, 188, 1050, 10584, 587, 88, 2, 9], [378, 1162, 3, 62, 39, 1, 107, 163, 61, 37, 176, 240, 54, 20, 6649], [378, 106, 21, 4, 1045, 9, 194, 2410, 298], [2694, 43, 23, 48, 1501, 387, 23, 6650, 75, 829, 7], [2694, 6651, 12, 2, 10585, 48, 2, 10586, 6652, 2936, 6651, 12, 560, 2, 1779, 83, 3258, 6653, 12, 1400, 10587], [378, 201, 292, 445, 473, 23, 99, 551, 6, 294, 100, 6654, 3, 41, 1, 27, 17, 32, 264, 8, 4, 460, 29, 192, 1062, 4, 692, 5110], [10588, 5, 49, 2, 10589, 269, 7, 12, 1773, 1785, 21, 6655, 8, 196, 11, 1068, 10590, 1502, 14, 422, 27, 3672, 10591], [10592], [1121, 322, 637, 984, 56, 30, 25, 1083, 22, 8, 151, 380, 20, 481, 914], [546, 6656, 18, 1696, 1272, 34, 3, 63, 14, 98, 885, 38, 87, 2305, 53, 18, 2, 1844, 16, 6564, 71, 179, 49, 6657], [947, 115, 1062, 1503, 1], [947, 1634, 544, 1674, 6658, 224, 10593, 61, 6, 2060, 74, 2152, 4, 122, 654, 87, 165, 1], [947, 1243, 787, 447, 3, 13, 10, 169, 11, 748, 89, 668, 1, 447, 40, 65, 33, 13, 6659], [10594, 3673, 8, 15, 149, 16, 2578, 1, 30, 2695, 26, 10595, 48, 119], [10596, 545, 160, 4, 5111, 10597, 160, 2, 10598, 10599, 10600, 9, 9, 1400, 4255, 6660, 12, 107, 6, 10601], [1296, 4267, 2696, 56], [1296, 47, 13, 10602, 368, 29, 192, 53, 36, 49, 572, 263, 11, 53], [10603, 933, 6661, 1, 10604, 5112], [10605, 21, 4, 1711, 5113, 234, 153, 233], [10606, 200, 186, 182, 28, 5, 10607], [1494, 213, 206, 24, 578, 13, 6662], [1494, 1164, 5114, 82, 54, 135, 318, 28, 164, 11, 3259, 21, 10608, 2, 10609, 25, 123, 1968, 1635, 4049, 102, 16, 761, 10610], [6663, 71, 23, 1976, 39, 9], [4268, 8, 6664, 360, 1957, 10611], [5115, 160, 4, 190, 6665, 123, 5116, 10612], [841, 178, 16, 616, 10613, 556, 204, 60, 9], [10614, 107, 28, 821, 1, 66, 653, 10615], [201, 178, 38, 23, 11, 71, 93, 12, 7], [201, 2008, 1044, 4269, 592, 11, 56], [201, 89, 1, 292, 6666, 445, 4899], [201, 828, 494], [201, 231, 1], [201, 9, 378, 391], [201, 74, 292, 9, 21, 474], [201, 1162, 10, 1, 75, 72, 584, 10616, 163, 6667, 1230, 10617], [201, 213, 192, 18, 17, 18, 4, 10618, 37, 3, 157, 2, 181, 54, 18, 1167], [6249, 48, 62, 369, 15, 12, 1], [10619, 1526, 220, 497, 73, 1066, 22, 213, 1526, 49, 339, 30, 1], [4270, 175, 9, 278, 13, 6, 267, 32, 10, 608, 408, 127, 175, 6, 6668], [10620, 5, 2, 1, 34, 5, 10, 1, 37, 66, 625, 10621, 560, 267, 21, 3674, 17, 8, 14, 10, 3675], [5117, 3260, 2153, 3, 195, 109, 721, 116, 745, 132, 245, 10622, 34, 85, 745, 116, 132, 245, 190], [10623, 214, 218, 10624, 19, 84, 1], [10625, 18, 567, 95, 249, 10, 138, 8, 735, 10, 466], [6669, 47, 112, 483, 18, 10626, 7, 1314, 71, 15, 14, 21, 25, 28, 169, 8, 1], [10627, 439, 37, 69, 168, 10, 2697, 1636, 21, 22, 1858, 493, 32, 39, 1, 2111, 17, 35, 439], [2686, 1309, 49, 144, 69, 118, 157, 2, 3543, 446, 2698, 51, 4, 292, 1000], [292, 6670, 33, 294, 11, 85, 5, 840, 1, 5, 1135, 21, 4, 290, 128], [292, 184, 3, 75, 397, 288, 799, 27, 2, 1, 2929, 167, 995, 2436, 1116, 30, 1238, 6671, 2937, 30, 193], [292, 213, 225, 3, 47, 2, 19, 144, 8, 976, 11, 2608, 85, 47, 3, 37, 185, 301, 3, 47, 10628], [10629, 1, 19, 2938, 17], [954, 1204, 21, 163, 6, 479, 54, 2, 56, 63, 410, 10630, 58, 42, 189, 594, 85, 3, 424, 292, 565, 230, 22, 840], [2416, 1, 66, 341, 66, 328, 424, 1861], [10631, 3676, 27, 10632, 18, 4, 6672, 3677, 60, 319], [10633, 43, 3, 29, 13, 9], [445, 203, 9, 1427, 10634, 42, 63, 113, 36, 383, 514, 765, 6673, 347, 498, 2699, 99, 243, 128], [445, 206, 9, 2, 6674, 8, 2, 391, 2473, 44, 3511, 6675], [445, 2396, 21, 4, 3261, 18, 10, 1, 995, 347, 930, 96, 4271, 13, 546, 10635, 113, 4, 4173, 7, 23, 541, 21, 2, 10636], [5118, 4272, 35], [1369, 4273, 444, 7, 1, 405], [10637, 66, 62, 97, 1], [2700, 257, 10, 24, 35, 13, 3, 1431, 18, 5, 8, 5, 124, 6, 1759, 106, 11, 2, 654, 1675, 10638, 21, 473, 2654], [2700, 8, 358, 1], [473, 558, 16, 1499, 292, 1173, 5119, 292, 3484, 292, 5120, 2, 429, 10639, 60, 353, 292, 10640, 8, 2, 591, 6676, 23, 93, 55], [6677, 120, 435, 11, 479, 35, 2474, 801, 158, 8, 10, 1309, 41, 4, 1203, 6, 28, 214, 3, 346, 4, 351, 313], [10641, 10642, 8, 96, 3262, 2939, 106, 6, 901, 1637, 8, 355, 1450, 21, 4, 10643, 1152, 8, 293, 48, 433, 54, 747, 4, 2701], [3263, 12, 56], [4873, 10644, 353, 10, 534, 41, 173, 4, 26, 49, 92, 137, 2702, 27, 980, 649], [6678, 49, 183, 593, 1, 845], [3263, 14, 13, 107, 662, 54, 27, 263, 34, 48, 31, 42, 5121, 241, 8, 234, 9, 6, 4, 440, 10645], [10646, 10647, 253, 88, 753, 17, 57, 2, 2703, 30, 9], [688, 10648, 18, 39, 319, 3, 195, 48, 4274, 23, 180, 10649, 10650], [10651, 195, 233, 133, 6, 1141, 35, 125, 325, 153], [1212, 1381, 105, 1332, 6, 70, 17, 4866, 23, 48, 1, 3, 33, 1342, 6, 15], [1212, 213, 790, 8, 22, 1, 96, 210, 683, 50, 10652, 55, 3, 375, 40, 47, 4, 250, 1082, 677, 3264, 16, 22, 979], [10653, 87, 6, 1867, 35, 26, 15, 5122, 11, 22, 1], [10654, 16, 4, 77, 42, 363, 6, 2940, 27, 65, 1765, 92, 34, 29, 131, 442, 10655, 133, 6, 633, 76, 1126, 9, 102, 27, 22], [10656, 1091, 100, 204, 60, 353, 204, 126, 5123, 154, 202, 5124, 10657, 84, 10658], [5125, 2475, 16, 95, 1193, 11, 6679, 21, 4, 434, 6680, 95, 5126, 71, 239, 11, 20, 1890], [5125, 2475, 16, 95, 1193, 11, 6679, 21, 4, 434, 6680, 95, 5126, 71, 239, 11, 20, 1890], [1638, 3265, 80, 1, 27, 17, 947, 3265, 7, 5114, 27, 17], [4275, 16, 25, 2666, 8, 208, 13, 1], [10659, 2217, 347, 378, 16, 10660, 190, 8, 202, 2217, 1832, 1889, 1318, 12, 18, 4, 10661, 4205, 10662, 10663], [10664, 10665, 3, 41, 2, 346, 79, 82, 80, 1], [4276, 16, 4, 1786, 3260, 111, 289, 107, 1117, 49, 144, 10666, 4276, 16, 4, 1210, 10667, 111, 49, 18, 446, 8, 10668], [1569, 3265, 16, 4, 56, 66, 1476, 11, 4, 3678, 12, 6681, 22, 12, 48, 2, 93, 184], [1569, 437, 34, 2, 1, 46, 378], [1569, 437, 34, 2, 1, 46, 68], [513, 53, 51, 60, 446, 66, 87, 6, 2277, 71, 4277, 4, 4917, 348, 82, 18, 42, 2921, 10669], [964, 219, 7, 249, 7, 1362, 12, 54, 2704, 52, 96, 2009, 5, 63, 90, 170, 32, 42, 67, 34, 31, 5, 29, 44, 538, 21, 170, 174, 144], [10670, 32, 93, 24, 107, 27, 2, 1990, 1318], [410, 17, 1], [410, 17, 205, 22, 1, 67, 6, 14, 1581, 37, 172, 10671, 321], [410, 4, 418, 69, 12, 2476, 8, 37, 595, 34, 50, 24, 1729], [410, 4, 395, 69, 5127, 166, 2, 9, 8, 5, 4, 1017, 359], [43, 1, 3, 124, 6, 168, 10, 10672], [1307, 367], [188, 7, 57, 582, 38, 20, 28, 285, 24, 74, 186, 598, 13, 2, 1891, 311, 2154, 6, 307, 1292], [159, 925, 222, 1309, 165, 130, 3679, 10673, 221, 36, 2010, 4278, 1990, 4, 4279, 1309], [3, 394, 52, 2, 2941, 494], [1, 5, 3680, 73, 19, 5128, 76, 6682, 815], [3, 222, 19, 2, 1743, 16, 2155, 353, 6683], [1, 906, 2, 481, 59, 2, 449, 1712, 326, 430, 1731, 10674], [332, 6, 10675, 106, 12, 560, 2, 1964, 6, 382, 54, 11, 2942, 10676], [1], [295, 13, 304, 634, 4, 215, 178, 16, 4, 658, 6, 10677, 15, 45, 2920], [2943, 1394, 9], [10678, 881, 4, 508, 16, 4, 1044, 27, 3266, 8, 1268, 7, 101, 338, 15, 10679], [10680, 6684, 3, 560, 103, 528, 51, 20, 10681, 3, 103, 382, 38, 20, 1293, 10682], [274, 96, 958, 84, 1733, 10683, 1236], [10684, 10685, 54, 16, 4, 2306, 4, 1403, 274, 2300, 155, 2944, 16, 4, 1194, 8, 155, 16, 4, 2623], [1, 5, 19, 273, 17, 6, 400, 11, 7, 930, 8, 80, 1496, 107, 361, 72, 1542, 5, 400, 4066, 1], [181], [1, 103, 14, 283], [948, 50, 8, 50, 24, 530], [485, 48, 34, 5, 1170, 59, 642, 8, 1033, 37, 5, 49, 2, 10686, 73, 219, 14, 2, 6685], [26, 57, 66, 58, 27, 305, 4966, 818, 10687, 694, 305, 387, 1463, 7, 66, 29, 94, 382, 74, 4280, 51, 76, 4281, 764], [8, 52, 792, 3646, 27, 4, 6686, 36, 44, 48, 1462, 22, 202, 414, 112, 158, 4282, 40, 41, 57, 40, 10688, 989], [52, 46, 2, 112, 158, 241, 10, 89, 2, 112, 25, 34, 3267, 4, 10689, 3183, 21, 44, 48, 2, 10690, 10691, 23, 90], [43, 454, 5, 298, 1359, 250, 21, 80, 112, 158, 26, 120, 1377, 6687, 74, 245, 91, 446, 51, 246, 6, 2413, 42, 52, 12, 882], [10692, 345, 129, 514, 24, 127, 1393, 130, 2, 10693, 36, 28, 54, 26, 580, 18, 9, 1310, 453, 26, 446, 3211, 13, 17, 54], [76, 1, 87, 2, 2011], [15, 47, 206, 590, 9, 321], [24], [622, 585, 9], [26, 3, 454, 57, 159, 524, 118, 44, 6, 72, 59, 39, 2124], [93, 602, 181], [141, 1, 20, 30, 12, 28, 10694, 38, 3, 28, 337], [281, 96, 2, 141, 1, 464], [426, 40, 2, 187, 9, 558], [40, 65, 13, 2, 2633, 269, 2945], [128, 919, 17, 2822, 195, 48, 6634], [61, 14, 187, 1504, 499], [411, 9, 8, 19, 729, 17, 230, 3, 737, 4, 45, 459, 5, 8, 20, 104, 10695], [37, 721, 5, 200, 22, 23, 96, 122, 6, 1244, 54, 10696, 18, 22, 148, 10697, 6, 134, 7, 1, 4, 10698], [31, 15, 56, 23, 4283, 80, 30], [1093, 17, 16, 354, 128], [32, 76, 1, 750, 73, 19, 82, 2012, 66, 41, 1968, 10699, 1635, 35, 22, 193, 8, 15, 1759, 263, 2411], [10700, 3, 75, 28, 245, 197, 328, 31, 5, 176, 3681, 102, 20, 283], [272, 208, 13, 3, 167, 7, 9, 88, 433, 15, 13, 3, 47, 3682], [181, 3683, 27, 10701], [19, 5, 10702, 10703, 864, 16, 10704], [42, 121, 10705, 17, 917, 37, 3, 10706], [9], [31, 40, 58, 88, 40, 223, 309, 99, 3, 46, 868, 797, 1, 223, 14, 6688, 88, 3, 103, 14, 99], [842, 17, 18, 4, 1842, 2265, 114, 10, 1277, 142, 8, 1053, 6689, 27, 174, 1200, 18, 10, 926, 24], [15, 817, 3268, 4284, 3268, 15, 47, 2290, 6, 1367, 4060, 6690, 500, 6691, 15, 259, 15, 5129, 106, 6, 450, 2705, 260, 10707], [3, 528, 354, 8, 462, 3684, 18, 2, 1461, 115], [221, 3, 298, 129, 5130, 8, 490], [1, 49, 9, 29, 14, 1003], [104], [403, 3, 29, 156, 61, 1271, 601, 39, 1058, 284, 1, 8, 68, 10708, 6692, 843, 17, 173, 61, 27, 76], [33, 194, 4, 10709, 2301, 10710, 1097, 858, 10711], [57, 5, 528, 51, 9], [681, 10712, 113, 5131, 2254, 31, 40, 375, 2, 6693], [4045, 10713, 21, 4, 312, 69, 75, 28, 401, 2706], [10714, 1121, 48, 2, 83, 23, 2, 2013, 683, 4, 5132, 1272, 3, 62, 23, 4274, 1375, 15, 79, 2, 5133, 6694], [3685, 2707, 23, 44, 1885, 1244, 54, 57, 10, 203, 30, 67, 6, 119, 162, 49, 4, 467, 8, 4, 1], [44, 566, 837, 6695, 7, 2946, 209, 1128, 11, 4, 10715, 371, 2947, 242, 2014], [8, 3, 33, 656, 4, 1119, 19, 1414, 3220, 65, 13, 2, 4285, 363, 539, 22, 10716, 4084], [7, 48, 2307, 7, 789, 8, 2, 629, 6696, 122, 361], [36, 49, 141, 1, 38, 36, 49, 2914, 2625], [242, 35, 1], [321, 23, 793, 201, 2708, 13, 2, 1, 117, 92], [20, 48, 179, 1000, 5, 63, 259, 11, 4, 689, 8, 48, 14, 179], [43, 1], [91, 99, 209, 148, 3621, 47, 6697, 52, 47, 1761, 10717, 1011, 8, 385, 55, 86, 3, 110, 566, 4, 1, 1218, 2, 535, 106], [268, 56, 30, 433, 5, 62, 148, 219, 5, 486, 15, 776, 18, 1700, 8, 2636, 2014, 230, 10718, 1159, 4, 1537], [1530, 75, 308, 205, 1218, 18, 2, 670, 347, 117, 27, 126, 1, 30, 11, 15, 150, 148, 1639], [20, 2, 19, 24], [3679, 9], [957, 35, 18, 22, 178, 1], [1, 238, 114, 32, 10, 169, 3686], [85, 5, 81, 6, 17, 51, 473, 603, 10719, 66, 46, 228, 285], [3, 13, 10, 3680, 190, 1136, 10720, 85], [2948, 4815, 922, 106, 66, 61, 52, 33, 400, 116, 11, 2259, 8, 3, 345, 13, 2, 1, 8, 10721], [949, 6, 14, 2, 3687, 10722], [109, 280, 7, 144, 110, 346, 4, 446, 16, 10723, 15, 196, 29, 762, 15, 1062, 97, 122, 15], [221, 1118, 2, 1, 66, 46, 315, 6698, 497], [3, 600, 44, 33, 345, 2, 6699, 3688], [1690, 41, 4036, 32, 16, 5, 9, 59, 6, 44, 60, 1365, 6, 58], [289, 297, 2, 518, 16, 1, 18, 135, 72, 116, 43, 270, 184, 73, 1394, 24, 649, 422], [43, 179, 226], [2308], [571, 1, 3, 62, 338, 17, 771], [3, 29, 14, 18, 4, 9, 34, 39, 9, 18, 10, 1690], [286, 221, 3, 41, 6378, 9, 38, 3, 124, 10, 3269], [180, 2254, 6, 32, 3, 772, 170, 6, 14, 3689, 18, 3690, 1858, 11, 2, 607, 115, 92, 28, 60, 376, 5, 103, 87, 15], [10724, 317, 168, 2709, 310, 74, 4, 1213, 583, 5, 49, 185], [1, 74, 827], [281, 45, 145, 3, 301], [55, 1, 82, 10725, 6, 819, 5134], [336, 3, 299, 42, 124, 6, 1, 55, 210, 62, 1892, 77, 47, 68, 16, 76, 128], [145, 55, 3, 124, 688, 828, 230, 3, 363, 6, 4, 904, 88, 124, 445, 828, 51, 4, 904, 88, 41, 2, 10726, 18, 4, 193, 337, 6566], [1, 69, 58, 42, 64], [3, 47, 262, 2, 1], [23, 18, 22, 9, 13, 22, 155, 264, 33, 14, 175, 908], [55, 149, 39, 9, 64, 17], [37, 78, 638, 46, 105, 477, 6, 43, 981, 45, 27, 2, 1], [1140, 286, 576, 280, 3, 14, 35, 3, 745, 297, 7, 9], [55, 3, 47, 133, 6, 3122, 45, 4286, 1997, 11, 23, 238, 258, 17, 2, 1, 21, 2, 535, 449], [333, 271, 1498, 5, 189, 3, 64, 5, 37, 209, 3, 9, 6, 68, 115, 563, 5, 189, 243, 923, 513], [7, 1893, 386, 16, 2, 1, 655, 474, 7, 107, 6, 170], [10727, 10, 25, 10728, 4050, 9], [89, 1, 27, 17, 454, 162, 10, 3230, 61], [648, 12, 2, 1], [1, 139, 19, 868, 27, 17, 5, 62, 369, 23, 533, 59], [22, 145, 14, 308], [297, 2, 327, 16, 312, 1505, 2, 10729, 1787, 10730, 61, 18, 11, 10731, 649, 3, 29, 13, 1072, 519, 34, 369], [34, 3, 259, 11, 4, 5135, 320, 127, 1184, 10, 429, 259, 11, 10732, 6700, 2674, 43, 158, 1271], [37, 339, 5, 13, 4, 2015, 451, 1298], [76, 9, 47, 56], [5, 1070, 1], [112, 742, 19, 7, 1, 973, 35, 21, 4, 115, 7, 109, 974, 13, 1, 42, 487, 150, 4, 313, 35, 107], [13, 2, 9, 525, 138, 32, 115, 8, 88, 390, 40, 525, 127], [139, 14, 196, 1, 10733], [12, 10, 455, 83], [3, 13, 76, 991, 480, 10734, 120, 355, 2011, 190, 759, 2016, 5136, 15, 317, 690, 57, 207, 36, 49], [33, 375, 6, 176, 4, 3691, 991, 4287, 15, 10735, 32, 7, 2477, 10736, 5137], [1320, 9, 14, 123, 10, 10737, 66, 14, 51, 1458, 1251, 663], [52, 121, 52, 41, 5, 11, 2386, 24], [29, 79, 10, 1492, 10738, 144, 91, 1936, 7, 6701], [34, 63, 66, 32, 51, 577, 1279, 7, 5, 1545, 13, 2, 141, 1, 140, 217, 1014, 20, 310, 12, 1064, 1943], [281, 72, 4, 141, 1, 69, 100, 217, 114, 84, 3692, 2, 112, 91, 452, 44, 100, 7, 3693, 2, 141, 1, 3694], [37, 2, 91, 69, 12, 2, 24, 8, 2, 1894, 6702, 5, 8, 2004, 424, 57, 47, 20, 5, 49, 1113, 209, 882, 130, 2, 91, 88], [20, 10739, 1545, 5138, 2, 2933, 141, 6703, 12, 4, 2123, 184, 7, 136, 582, 32, 3270, 5, 49, 48, 2, 720], [447, 7, 156, 65, 10740, 4, 269, 231, 287, 2, 94, 224, 4255, 10741, 65, 165, 130, 905, 10742], [394, 7, 60, 93, 24], [29, 150, 13, 509, 117, 92, 3, 131, 134, 2, 643, 10743, 77, 60, 1788, 527, 262, 1253, 5139], [85, 5, 131, 2451, 2, 260, 5, 65, 10744, 318, 222, 197, 55], [23, 4, 56], [20, 4288, 83, 48, 11, 4, 2156, 21, 5140, 22, 2428], [4, 670, 47, 1, 491, 123, 22, 131, 340, 2921, 4938, 8, 52, 41, 57, 10745, 41, 544, 94, 5, 29, 491, 670, 36, 523, 997], [3, 90, 7, 2157], [212, 158, 1570, 307, 36, 198, 44, 6636, 27, 947, 213, 892, 66, 452, 14, 44, 39, 437, 615], [1, 118, 516, 19, 2, 6704, 5141, 7, 5142], [10746, 12, 2, 9, 21, 7], [55, 7, 9, 200, 518], [117, 107, 88, 57, 304, 246, 1079, 707, 10747, 3, 222, 14, 3144, 39, 9, 55], [2254, 1733, 513], [22, 12, 144], [10748, 411, 40, 86, 20, 183, 8, 332, 6, 65, 51, 28, 4, 19, 54, 16, 1858, 104, 230, 3, 572, 5, 6705, 6706, 5143], [75, 304, 21, 127, 6454, 12, 7, 15, 5144, 4289, 104], [6707, 1], [242, 4, 19, 35, 9, 30, 1, 19, 10749, 30, 187, 9], [3695, 1], [2460, 30, 353], [3, 118, 34, 3, 41, 147, 154, 6708, 125, 143, 10750, 555, 15, 35, 163, 94, 31, 2, 9, 103, 100, 2, 25, 6709, 18, 1789], [7, 2, 417, 207, 3532, 99, 64, 4, 759, 8, 1343], [345, 260, 1], [4, 10751, 901, 51, 4, 450, 16, 1015, 3123, 2614, 6, 14, 60, 16, 4, 247, 3271, 4033, 4290, 182, 10752], [3, 210, 79, 5, 2, 1, 3, 33, 10753, 83], [21, 60, 1594, 45], [46, 357, 1001, 42, 172, 2710, 3, 5145, 16, 2, 43, 93, 120, 2376, 2109], [3580, 4, 1086, 1675, 1067, 118, 14, 10754, 10755, 15, 2711, 1248, 6, 168, 4, 324, 726], [290, 17, 378, 18, 378, 174, 2154, 16, 178, 104, 94, 57, 582], [128, 26, 4, 234, 236, 28, 32, 4, 112, 1781, 769, 26], [40, 47, 4, 5146, 21, 2, 179, 2949, 261, 3, 1592, 254, 34, 714, 1501], [36, 49, 329, 5, 49, 2, 158, 156, 10756, 10757, 4291, 174, 373, 111], [811, 269], [118, 22, 104, 2273, 11, 6710], [5, 14, 966, 1675, 10758, 75, 14, 2478, 657, 384, 207, 3696, 115, 14, 6711, 142, 143, 689, 8, 384, 10759, 1884], [403, 10760, 5, 569, 207, 93], [934, 10761, 243, 21, 10762, 3, 90, 4, 10763, 367, 4, 1111, 200, 955], [33, 29, 1, 38, 20, 863, 568, 54, 13, 215, 106], [24], [1, 1449], [4, 1322, 61, 10764, 201, 204, 353, 26, 126, 260, 154, 202, 5124], [219, 5, 41, 6, 94, 10765, 5147], [57, 3584, 246, 1], [19, 42, 183, 30, 1], [336, 42, 33, 2, 181], [69, 1713, 22, 181], [3, 44, 521, 312], [189, 48, 614, 6, 28, 126, 30, 249, 494], [326, 382, 642, 6712, 98, 2091, 6, 4, 6713], [221, 39, 1, 46, 45, 205], [1, 94, 5, 88, 88, 83, 8, 93, 1640, 6, 350], [1, 5, 35, 8, 1344, 4, 19, 1714, 8, 212, 16, 263, 224, 22, 1, 47, 13, 3697, 4, 19, 1505, 61, 6, 4, 172, 10766], [55, 1710, 1, 13, 284, 31, 4, 717, 93], [22, 1], [311, 2, 1], [162, 10, 1, 125, 10, 6714, 88], [1, 3, 41, 4, 10767], [444, 4, 360, 94, 201, 104, 2309, 2132, 49, 19, 8, 68, 41, 554], [8, 18, 7, 1895, 23, 54, 325, 1], [1, 29, 62, 31, 36, 131, 137, 1641, 74, 65, 643, 280], [280, 5, 62, 3, 75, 48, 1088, 18, 185, 45, 13, 10768, 610, 2, 548, 1183, 18, 2, 5148], [1073, 6, 4, 5042, 621, 69, 28, 110, 3698, 775, 12, 2, 494, 1599, 74, 1422, 10769, 2950, 6, 4, 10770], [321, 321, 7, 1, 46, 334], [319], [369, 3, 4963, 5, 1], [3699, 10771, 12, 6, 924, 21, 4, 4292, 48, 665, 54, 4, 355, 1111, 8, 232, 10772], [336, 23, 1896, 398, 16, 78, 24, 532, 13, 60, 1015, 35, 3679, 1127, 2138], [336, 7, 1, 1116], [673, 19, 42, 291, 30, 529], [19, 42, 1], [39, 9, 46, 334], [15, 2, 10773, 10774, 12, 10775, 339, 4, 1172, 3700, 10776, 49, 10777], [519, 193, 398, 261, 49, 56], [24, 30, 2951], [3, 58, 48, 13, 81, 6, 5, 104, 8, 3, 200, 34, 11, 2, 417, 193, 181], [729, 10, 1690, 104], [61, 6, 376, 104], [20, 4, 68, 176, 17, 35, 104], [3, 63, 48, 304, 6, 94, 22, 19, 838, 50, 30, 12, 4056], [2017, 1231, 12, 56, 720, 248, 649], [3, 346, 5, 5149, 73, 66, 10778, 3, 346, 5, 355, 1006, 8, 7, 867], [1, 1299, 17], [296, 222, 44, 10779, 296, 79, 10, 306, 2, 368, 128], [321, 200, 61, 54, 13, 2, 1, 5150, 55, 7, 198, 48, 14, 84, 679, 1141], [128, 3272, 5, 94, 4, 1, 238, 208, 13, 40, 46, 150, 15, 3203], [55, 84, 1141, 82, 4, 570, 1638, 38, 52, 47, 6715, 2098, 4, 1, 109, 118, 61, 3191], [37, 574, 49, 633, 102, 339, 72, 31, 66, 44, 6, 3701, 5, 103, 776, 10780, 1118, 1], [20, 305, 1, 464], [33, 107, 139, 11, 22, 1, 149, 23, 133, 6, 28, 102], [25, 14, 18, 24, 45], [149, 20, 2, 643, 1], [58, 3, 599, 119, 1034, 21, 2, 259, 12, 7, 57, 3, 428, 58, 104, 5, 598, 2, 141, 10781], [1, 162, 5, 132], [43, 3, 1, 8, 1897, 48, 1516], [10782, 37, 7, 4, 1582, 10783], [31, 42, 75, 81, 461, 81, 59, 174, 187, 779, 23, 785, 81], [37, 174, 104, 6716, 167, 217, 713, 13, 7, 8, 42, 72, 52, 6482, 8, 1087, 42, 189, 1589, 6717, 11, 4, 712], [91, 242, 80, 10784, 30, 35, 67, 60, 9, 3702, 271, 10785, 2938, 17, 18, 135, 2683], [52, 19, 56], [1667, 7, 60, 181, 45, 720], [17, 99, 10786, 138, 8, 24, 12, 99, 3568, 6, 134, 35, 8, 14, 1606, 123, 60, 908, 7, 47, 328, 6, 307], [714, 10, 2479, 24, 2265, 73, 3, 1266, 18, 174, 231], [22, 1024, 12, 37, 2234, 726], [106, 21, 4097, 5151, 6, 235, 54, 8, 194, 60, 232, 10787], [20, 2, 391], [10788, 10789, 162, 22, 1, 35], [93, 1138, 14, 2, 2952, 21, 39, 611, 214, 1], [33, 253, 307, 18, 2712, 1403, 147, 10790, 3, 132, 477, 6, 22, 25, 371, 10791, 5152, 18, 5, 9], [6558, 41, 32, 4, 9], [7, 1456, 2018, 10, 586, 1661, 40, 2, 1, 252], [559, 1426, 2, 141, 1, 340], [9, 987, 4033, 6, 7], [21, 268, 213, 206, 10792], [19, 43, 10, 261, 723, 8, 179], [3, 157, 22, 1, 6, 1898], [1, 57], [9, 2713, 10793], [23, 6603, 1, 555, 18], [28, 22, 399, 16, 22, 606], [5153, 10794, 7, 32, 45, 29, 139, 827, 93, 2866, 2310, 1, 5, 132, 3703, 99], [5, 330, 62, 272, 176, 15, 10795, 1451, 5154, 1, 3, 64, 622, 25], [117, 11, 4, 24], [471, 76, 148, 918, 108, 162, 36, 1642, 163, 4, 263, 46, 15], [2480, 5, 10796, 1, 43, 68, 279, 57, 5, 86, 61, 19, 5155, 49, 5, 11, 3253, 769], [2858, 47, 2, 3273, 215, 264, 447, 117, 13, 159, 925, 109, 47, 2, 2, 3273, 5156, 55], [721, 5, 1051, 7, 265, 337, 34, 52, 19, 35, 8, 198, 231, 4, 10797, 29, 279, 59, 2953, 24, 3704], [1432, 946, 8, 608, 42, 8, 42, 349, 4, 3705, 54, 82, 793, 263, 2, 1129, 8, 1128, 218, 220, 48, 11, 1322, 5157, 220, 248], [70, 441, 1899, 5, 24, 5, 62, 5, 366, 7, 45], [583, 8, 116, 49, 120, 111, 8, 116, 49, 3255, 380, 678, 68, 42, 1563], [2, 1029, 16, 2259, 21, 4, 1, 69, 396, 50, 226, 744, 10798], [353, 1429, 242, 4, 19, 35], [195, 48, 152, 242, 45, 35, 1, 34, 42, 63, 28, 80, 1043, 30, 54, 116, 9, 30, 25], [241, 109, 8, 7, 324, 162, 42, 14, 51, 88, 3, 131, 94, 57, 133, 88, 3, 29, 131, 465, 57, 42, 152, 58, 3, 67, 94, 15, 1], [26, 42, 564, 88, 2, 1, 28, 4, 19, 27, 7, 315, 45], [26, 1319, 1319, 1319, 1319, 1319], [10799, 1697, 3706, 5, 10800, 3707, 16, 10801], [6718, 12, 12, 2677, 392, 16, 4293, 1132, 144], [25, 121, 296, 1025, 35, 11, 2, 618, 6719, 1, 7, 3, 46, 2445, 3562, 34, 1153, 84, 45, 133, 6, 14, 5158, 2222], [10, 2902, 136, 165, 3274, 8, 52, 544, 5, 104, 61, 619, 8, 100, 61, 16, 20, 141, 30, 138, 21, 2, 691], [1703, 216, 22, 186, 317, 13, 4, 10802, 36, 523, 70, 2, 3274, 34, 22, 10803, 96, 1475, 6, 56, 81, 240], [171, 1, 411], [23, 5159, 34, 3, 28, 2714, 130, 2, 10804, 204, 39, 381, 30, 9, 124, 6, 471, 240, 6, 4, 2001, 5160, 123], [8, 33, 57, 12, 7, 1, 152, 58, 21, 287], [3, 195, 68, 818, 5161], [642, 1], [158, 55, 1118, 1248, 10805, 8, 10, 5162, 47, 6720, 124, 2, 535, 16, 467, 37, 3, 47, 595, 3652, 5162, 5061], [147, 534, 152, 2650, 32, 35, 18, 147, 207, 177, 8, 52, 152, 450, 35, 11, 143, 5163, 6721], [6722, 3, 195, 10806, 11, 10807, 10, 1970, 49, 2148, 6, 3275, 3708, 6723, 1002, 56, 2481], [58, 22, 25, 86, 52, 5164, 4294], [3, 33, 29, 67, 68, 39, 154, 1, 7, 5165, 11, 6, 2, 889, 4295, 140, 40, 94, 71, 4, 360, 12], [1602, 8, 9], [219, 65, 13, 151, 14, 303, 5, 268, 2, 180, 1, 874, 16, 6724, 1710], [145, 253, 17, 108], [1558, 622, 185, 5154, 1, 3, 132, 62, 5, 21, 59, 10808, 5, 105, 124, 2, 10809], [48, 6, 78, 2310, 10810, 19, 721, 558, 56], [113, 7, 177, 52, 2, 9, 3, 33, 79, 170], [78, 19, 56, 6725], [1, 10, 306, 210, 79, 5], [1614, 241, 219, 19, 7, 1], [40, 33, 246, 10811, 10812, 10813, 5166, 5048, 248], [1502, 13, 7, 452, 5, 181], [10, 1, 4296], [52, 65, 13, 2, 181, 8, 84, 106, 493, 12, 723, 10814], [655, 4297, 6726, 20, 10815, 47, 43, 2158, 151, 14, 108, 244, 106], [99, 89, 52, 2, 104], [5, 750, 2117, 99, 399], [321, 7, 266, 582, 218, 3, 63, 94, 7, 180, 1, 74, 15, 230, 15, 10816], [200, 5, 28, 20, 10817, 478, 104], [40, 700, 41, 60, 859, 24, 776, 55, 3, 293, 281], [1], [243, 457, 5, 537, 141, 95, 1516, 15, 35], [40, 223, 119, 7, 1], [3, 394, 52, 118, 44, 223, 673, 45, 8, 204, 76, 32, 31, 36, 1183, 6727], [57, 4, 1084, 19, 286, 12, 61, 18, 51, 4, 10818, 212, 10819, 187, 3, 75, 304, 21, 5167], [74, 73, 3, 13, 6, 157, 15, 65, 539, 849, 207, 1178], [471, 32, 4, 19, 1433, 337, 92, 10820, 107, 8, 28, 17, 1400], [507, 24, 18, 6728, 100, 24, 114, 498], [20, 57, 329, 27, 4, 120, 849, 5, 172, 490, 1300, 864, 16, 2715, 333, 309, 771], [773, 220, 143, 5168, 5169, 16, 5168, 1235, 8, 5168, 10821], [2159, 10, 175, 361, 5, 5169], [100, 1665, 2, 323, 1, 117, 10822], [55, 37, 144], [128, 1, 242, 35], [57, 35, 10, 1, 1123, 54, 82, 20, 10823, 11, 2663, 176, 1042, 57, 42, 2019], [4, 101, 68, 16, 1386, 228, 3, 13, 37, 5, 166, 1, 29, 1838], [58, 39, 1, 109, 64, 6729, 464], [1038, 14, 101, 68, 558, 147, 617, 14, 2482, 18, 57, 3, 107, 6, 80, 10824, 32, 143, 3276, 14, 3590, 6, 498, 11, 10, 10825], [147, 196, 28, 4, 19, 54, 9, 3, 14, 1265], [78, 14, 60, 284, 120, 283, 3, 67, 6, 973, 142, 125, 5, 10826], [48, 5170, 3, 86, 247, 287, 44, 653, 90, 10827, 3526, 10828, 49, 952, 671, 126, 2483, 8, 435, 253], [2140, 85, 2311, 59, 10829, 88, 61, 117, 337, 8, 2020, 21, 2, 189, 6, 257, 20, 24, 35, 23, 514, 51, 106], [280, 7, 9, 259], [417, 830, 161, 158], [219, 7, 60, 353, 1429, 1564, 2312, 197, 1271, 10830, 621], [6730, 446, 353, 47, 2, 1067, 21, 4, 2716, 1385, 11, 4, 1932, 16, 4, 10831, 2674, 6731], [20, 1976, 17, 91, 2251, 48, 32, 2302, 49, 529, 33, 13, 48, 32, 10832, 90, 5171], [497, 218, 604, 3709, 15, 280, 20, 167, 7, 9, 1315, 85, 559], [3710, 31, 111, 49, 4298, 6, 86, 16, 5, 73, 2, 6732, 1, 15, 126, 6733], [136, 1, 23, 4091, 35, 2868, 1059, 440, 163, 117, 18, 4, 1684, 2679], [6734, 10833, 36, 79, 17, 1900, 56, 21, 255, 10, 161, 823, 6735], [425, 61, 6, 618, 1430], [813, 860, 2717, 15, 12, 177, 3711, 1295, 6736, 875, 1324, 1901, 98, 684, 853, 98, 348, 21, 211], [3277, 6737, 1, 542, 6, 665, 542, 644, 61], [267, 1612, 281], [1, 41, 4, 1790, 1617, 98, 96, 41, 50, 30, 257, 390, 198, 44, 1051, 170, 6, 263], [156, 1831, 93, 125, 10, 145, 8, 93, 541, 18, 4, 3712, 10, 177, 41, 60, 1136, 92, 3, 63, 1571, 60, 5172], [10834, 10, 145, 6738, 14, 129, 116, 33, 132, 112, 624, 713], [221, 7, 145, 137, 93, 1267, 3, 67, 2484, 6, 404], [92, 7, 174, 2160, 129, 107, 543, 15, 27, 97, 312, 11, 4, 10835], [4, 3278, 8, 4918, 479, 44, 132, 727, 6739, 73, 4, 64, 21, 104, 10836, 73, 219], [433, 4, 4819, 104], [10837, 200, 15, 58, 21, 6740, 15, 216, 170, 2, 3279, 104, 5173, 1996, 6741, 12, 10838], [10839], [6742, 211, 7, 250, 1514, 18, 20, 2161, 52, 2283, 1253, 17, 79, 17, 2, 181, 3280], [52, 1373, 6, 397, 27, 4, 1433, 5174], [19, 102, 83], [174, 804, 529, 83], [43, 42, 119, 15, 4299, 1900, 248], [100, 4, 9, 113, 15, 4038], [3245, 1296, 29, 433, 54, 51, 230, 1296, 13, 2, 161, 1], [491, 2, 1672, 11, 1118, 9, 231], [3, 44, 105, 469, 11, 10, 164, 132, 6, 2, 1637, 1495, 13, 10840, 3, 195, 2, 1307, 1168], [128, 6743, 5, 65, 13, 2, 148, 1295, 1, 176, 533], [5175, 1873, 190, 10841], [116, 2, 540, 85, 4, 232, 29, 67, 6744, 245, 6745], [289, 124, 565, 61, 102, 162, 190, 366], [10842, 4, 310, 24], [36, 56], [7, 179, 21, 889, 10843, 15, 4, 1254, 979, 237, 10844], [349, 10, 1277, 142, 27, 174, 1022, 8, 1053, 4, 6689, 596, 174, 1200, 18, 10, 2479, 24], [3, 840, 18, 4300, 48, 283], [447, 42, 185, 711, 23, 48, 338, 634, 13, 10845, 67, 2, 498], [105, 253, 170, 609, 269], [805, 576, 25, 571, 271, 117, 11, 20, 844, 9], [25, 3, 210, 44, 43, 10846, 60, 9, 21, 238, 512, 62, 78, 75, 512], [597, 20, 30, 35, 9], [290, 7, 45, 72, 20, 18, 351, 1255, 8, 36, 456, 44, 4, 178, 19, 35, 149, 20, 207, 13, 4, 763, 16, 76], [7, 45, 276, 14, 4, 989, 16, 39, 10847, 13, 2021], [805, 5176, 12, 341, 56, 280, 42, 62, 15], [28, 7, 2718, 250, 1], [151, 72, 15, 21, 1834, 58, 97, 414, 67, 5, 18, 4, 2022, 11, 3520, 3281, 74, 2473, 27, 39, 1, 10848], [2162, 154, 24, 13, 2, 2719, 64, 184, 54, 22, 83], [40, 12, 2, 1, 22, 780, 12, 32, 2856, 1791, 32, 16, 15], [6746, 16, 2, 10849, 3, 121, 15, 21, 5, 5177, 5, 1282], [3, 62, 3, 47, 137, 7, 9, 192, 18, 4, 787, 205], [20, 2, 530, 158, 835], [5, 41, 60, 9, 135, 478], [51, 577, 52, 363, 35, 8, 407, 2, 1], [3, 623, 15, 4, 68, 18, 1827, 6323, 99, 37, 5, 204, 268, 95, 27, 68, 4215, 650, 20, 28, 4, 2136, 1127, 776], [10850, 59, 212, 232, 22, 213, 57, 2, 10851], [23, 48, 953, 602, 21, 4, 112, 918, 478, 99, 953, 21, 4, 732, 918, 647], [7, 5, 41, 9, 148], [88, 57, 4, 286, 49, 4, 5178, 16, 14, 20, 9, 22, 12, 60, 908], [1035, 20, 27, 4844, 20, 1239, 2, 181, 92, 8, 11, 10852], [36, 121, 60, 3282, 148, 158], [583, 49, 5, 1506, 108, 35, 135, 36, 60, 1, 25], [63, 3, 257, 22, 1, 35, 10853, 2, 1], [148, 5, 1, 5, 105, 729, 17, 6747, 128, 1325, 3588, 769, 721, 16, 20, 250, 229, 14, 1498, 38, 61, 6, 4, 244, 68], [10854, 12, 2, 19, 836, 45, 2163, 16, 90, 18, 116, 38, 3, 200, 10, 250, 3129], [278, 13, 6, 999, 4, 1, 7, 448, 760], [10, 843, 12, 3, 304, 21, 4, 95, 6, 28, 637, 6, 4, 1952, 8, 88, 4301, 4, 1464, 37, 5, 105, 167, 20, 1643], [6748, 10855, 1536, 10856, 3283, 10857, 1060, 6749, 10858, 5179, 6750, 10859, 6751, 10860, 9, 888, 3284, 10861], [19, 5, 711], [3, 146, 94, 7, 9, 11, 395, 149, 23, 376, 18, 7, 9, 21, 92], [143, 19, 7, 9, 65, 611], [55, 52, 96, 2, 161, 1], [39, 154, 25, 1792, 10862, 64, 32, 39, 104, 30, 2409, 207, 8, 1783, 176, 134, 76, 57, 36, 67, 251], [9, 48, 287, 13, 6, 14, 4, 2485, 16, 701], [66, 25, 13, 172, 10863, 100, 68, 11, 8, 5, 341, 1301, 10864, 5, 2, 284, 83, 3, 2595, 80, 30], [39, 265, 49, 1549, 66, 41, 2, 120, 56, 265, 26, 2, 10865, 131, 14, 35, 11, 135], [114, 20, 494, 30, 6752, 54, 16, 135], [66, 124, 2, 6753, 11, 4, 2673, 26, 3, 2005, 64, 38, 10866, 16, 4, 10867, 510, 18, 4, 10868, 10869, 37, 3, 222, 72, 10870], [128, 42, 46, 2, 1828, 39, 9, 21, 326], [3226, 5180, 5181, 5182, 4, 10871, 10872, 644, 15, 102, 6754, 10, 64, 6755, 6756, 1793, 10873, 2225], [66, 1679, 4280, 51, 10874, 918, 608, 11, 2, 1204], [3, 210, 1794, 393, 26, 5, 198, 44, 132, 194, 15, 158, 312, 1902], [4, 2954, 67, 6, 1338, 5, 6757, 21, 4, 983, 2261], [2955, 158, 920, 129, 60, 6758], [3, 29, 13, 4, 2955, 158, 34, 15, 1182, 13, 688, 10875], [852, 10876, 12, 4, 2023, 104, 7, 290, 1392, 15], [32, 3, 375, 47, 4, 203, 1, 719, 4, 4071, 1857, 26, 10877, 30], [32, 263, 918, 220, 633, 13, 2838, 38, 4, 1422, 2286, 139, 15], [448, 4, 3173, 162, 5, 113, 7, 312, 6, 168, 4, 10878], [573, 2955, 158, 26, 1699, 10879, 708, 52, 2, 6759, 3713, 16, 3285, 2112, 251], [10880, 4, 154, 68, 74, 4, 10881, 16, 2, 1, 811, 1707], [289, 1389, 7, 49, 726], [10882, 546, 10883, 10884, 10885, 10886, 36, 514, 126, 237, 10887, 333, 1365, 20, 6760], [372, 13, 36, 49, 555, 108, 10888, 6761], [2956, 49, 156, 10889, 67, 6, 14, 27, 2, 1], [7, 178, 404, 167, 11, 1903, 2486, 2, 434, 5183, 4, 189, 12, 2, 841, 4302, 10890, 74, 3714], [24], [119, 2, 2313, 1295, 8, 872, 634, 10, 2487, 49, 10891, 4, 1170, 10892, 11, 22, 6762, 5184, 49, 10893], [2459, 56, 5, 62, 1885, 596, 10894, 12, 11, 1755, 3554, 654, 34, 13, 5, 1193, 308, 769], [2459, 56, 20, 229, 47, 2, 2158, 22, 195, 2957, 596, 974, 4, 970], [529, 2459, 56, 934, 20, 314, 1738, 27, 1755, 404, 2, 10895, 21, 529, 3516], [529, 2459, 56, 529, 85, 6763, 42, 6764, 163, 191, 529, 938, 10896, 37, 974], [116, 427, 2, 875, 68, 2164, 116, 355, 8, 190, 11, 7, 10897], [3, 383, 131, 100, 5, 62, 5185, 56, 10898, 46, 45, 78, 46, 784, 2488, 461, 4303], [4304, 1, 7, 4, 412, 5, 29, 67, 43, 437], [403, 2958, 331, 158, 674, 782, 652, 5, 82, 1630, 1384, 3569, 3, 763, 10, 1548], [5, 87, 20, 30, 792, 27, 2, 792, 1826, 331, 158, 375, 42, 103, 156, 340, 2, 158, 6, 76], [1, 453, 20, 624], [241, 5, 196, 13, 71, 5, 192, 6, 14, 2, 187, 6, 6765, 59, 256, 7, 136, 295, 6, 58, 27, 5], [20, 91, 65, 6766, 11, 7, 6767, 58, 5, 257, 170, 74, 33, 557, 170, 13, 2, 1321, 1], [92, 5186, 29, 131, 1049, 2, 5187, 125, 2165, 700, 54, 135, 1087, 169, 129, 283], [3, 33, 109, 346, 5, 8, 3, 62, 66, 63, 467, 15, 102, 8, 81, 59, 32, 16, 305, 437, 13, 339, 1], [4305, 277, 161, 153], [1043, 30, 83], [3, 131, 14, 7, 120, 25, 1397, 11, 10, 1951, 6768, 33, 5188, 169, 51, 1], [1160, 192, 1], [2, 19, 2665, 82, 2314, 840, 1, 139, 1233, 45], [69, 182, 121, 22, 12, 37, 4306, 10, 306, 2, 670, 26, 151, 44, 50, 1345, 5, 142, 21, 14, 2, 161, 83, 5189, 10899], [7, 25, 47, 119, 7, 9, 55], [5, 143, 2166, 1, 54, 135, 2007], [9, 30, 916], [6451, 1, 11, 36, 2959], [179, 30, 10900, 26], [10, 89, 1, 23, 2489, 11, 18, 326, 45], [3286, 1], [1, 23, 99, 214, 23, 556, 313, 22, 1, 619], [1, 42, 378], [1, 42, 1662, 71, 1481, 1533], [1301, 1], [3286, 1], [143, 154, 482, 10, 1, 89, 74, 576, 128], [1, 46, 45], [3, 75, 1], [1, 3, 62, 411], [43, 2, 429, 1466], [429, 1466, 8, 405, 15, 205], [6, 973, 35, 596, 10, 1], [4307, 1, 1687, 3, 47, 48, 1524, 37, 3, 1113, 10901, 44, 15], [66, 11, 22, 1, 556, 28, 10902, 1256, 18, 957, 10903], [5, 29, 62, 57, 3, 1507, 226, 495, 6769, 5, 269, 231, 5190], [12, 2, 181], [4308, 12, 270, 2, 365, 187], [7, 162, 3, 486, 4, 10904, 52, 273, 17, 6, 1276, 2823], [32, 9, 751, 15, 99], [148, 7, 9, 33, 510, 54, 34, 65, 51, 71, 239, 9, 121, 84, 45, 1873, 18, 10, 45], [805, 3, 67, 76, 9, 40, 47, 614, 6, 555, 240], [805, 25, 46, 34, 9, 12, 3, 86, 23, 404], [1140, 4309, 28, 39, 9, 631, 180, 280, 23, 238, 113, 5], [17, 519, 34, 31, 4, 1, 13, 157, 18, 7, 1904, 25, 46, 223, 5191], [766, 227, 76, 9, 18, 10905, 46, 223, 28, 4, 1, 631], [3, 19, 27, 10906, 25, 28, 18, 4, 1, 8, 33, 1396], [55, 7, 9, 21, 10907, 206], [576, 162, 63, 3, 94, 7, 9, 51], [1336, 124, 2, 10908, 13, 2, 1], [447, 52, 107, 108, 170, 180, 6770, 58, 256, 21, 7, 9], [10909, 5, 1, 6, 1572], [23, 48, 1991, 51, 32, 10, 312, 42, 1051, 17, 6, 186, 163, 1846], [2, 379, 25, 227, 173, 1753, 10910, 11, 143, 1194, 10, 312], [52, 2, 112, 25, 205, 7, 1, 62, 50, 507], [2593, 29, 492, 9, 340, 10911, 133, 898], [2593, 70, 10912, 21, 4, 9, 340, 23, 238, 563, 39, 287, 52, 14, 533, 133], [5, 10913, 146, 28, 384, 175, 102, 10, 312], [57, 63, 3, 72, 23, 2, 5192, 386, 16, 2, 83], [26, 1057, 2232, 129, 10914, 175, 10915, 3715, 10916, 6771, 1905, 10917, 26, 10918, 2232, 10919, 10920, 9, 16, 10921], [1, 23, 1584, 8, 3, 210, 253, 1834, 736], [281, 3, 29, 375, 253, 5, 34, 422, 28, 20, 10922, 54, 16, 16, 666, 187], [10923, 8, 1548, 12, 96, 11, 4, 56, 2960, 1004, 1046], [148, 3, 67, 6, 303, 7, 1, 7, 45, 47, 1715], [3, 62, 280, 25, 297, 2, 10924, 1644, 137, 2698, 8, 47, 806, 4, 9], [1103, 1051, 4, 1, 142, 6, 84, 1981, 497], [69, 32, 11, 7, 9], [7, 118, 1224, 305, 2388, 513], [1], [1, 23, 48, 107, 43, 127, 5, 121, 20, 70, 893], [1, 23, 2462, 133, 51, 13, 546], [1, 432, 41, 43, 764, 370, 9, 23, 1691, 1315], [1, 5, 48, 519, 680], [1, 5, 96, 1411, 34, 48, 1257, 464], [241, 1, 34, 5, 487, 729, 588, 38, 3, 87, 2, 10925, 2470, 6, 20, 331, 37, 810, 102], [526, 1, 61, 6, 376, 15, 47, 33, 2, 10926, 932], [3, 210, 86, 5, 724, 16, 2, 95, 7, 487, 14, 10927], [1749, 255, 4, 199, 758, 57, 2, 1664], [241, 43, 370, 6772, 7, 5193, 293, 5, 5194, 3287], [653, 702, 142, 202, 1], [664, 10928, 41, 2, 401, 92, 128], [1521, 273, 50, 221, 31, 3, 63, 114, 5, 337, 21, 24, 55], [1, 680, 5, 75, 28, 15], [1, 12, 5, 551, 74, 336], [15, 603, 97, 19, 6773, 37, 208, 117, 2284], [43, 15, 190, 10929, 15, 11, 10930], [190, 5195], [118, 3, 14, 2, 1, 31, 3, 121, 447, 34, 105, 273, 5, 162, 3, 271, 51], [10931, 50, 628, 49, 1589, 127, 697, 130, 7], [10932, 1051, 15, 35, 250, 27, 4, 10933, 7, 40, 2, 282], [262, 17, 145], [367, 140, 3, 99, 67, 6, 14, 203, 8, 44, 2, 203, 1, 436], [109, 49, 10, 677, 56], [19, 459, 135, 8, 61, 157, 60, 127, 56, 30, 6774, 18, 20, 104, 30, 653, 24], [271, 81, 2024, 20, 4310, 30, 520, 74, 57, 61, 249, 170, 102, 288, 20, 51, 15, 104], [576, 4278, 121, 15, 47, 56, 3716, 37, 220, 271, 1504, 499], [5, 87, 6, 1273, 4, 488, 7, 20, 398, 1792, 1716], [193, 6, 998, 20, 175, 5, 10934, 1], [24], [20, 315, 411, 171, 269], [241, 3, 10935, 40, 431, 464, 318, 102, 50, 2, 348, 55], [39, 1, 87, 6775], [84, 159], [84, 159, 44, 2, 434, 115], [107, 18, 159, 305, 2315, 47, 33, 122, 6, 1367, 4, 1019, 10936, 1996, 7, 57, 6776, 642, 10937], [10938, 181], [3, 47, 4027, 1], [778, 5, 274, 148, 104], [5, 671, 144], [14, 223, 10, 399], [272, 28, 22, 37, 155, 106, 3, 313, 56, 423, 15, 162, 15, 109, 1642], [10939, 569, 27, 4, 1958, 343, 8, 1075, 20, 2, 2490, 218, 20, 2, 104], [5196, 2, 889, 9, 2932, 34, 52, 200, 1795, 10940, 35, 256, 6777, 985, 6280, 10941, 583], [149, 52, 2, 104], [10942, 10, 353, 30, 1391], [31, 6502, 407, 56, 7, 2, 3717], [810, 6778, 323, 38, 622, 276, 405, 2, 1523, 153], [148, 593, 3, 572, 174, 858, 6779, 44, 615], [1346, 7, 165, 88, 44, 4, 3705, 2682, 298, 224, 1533, 967, 77, 934, 164, 55], [242, 35, 5197], [422, 5, 5198, 2167, 343, 837], [5, 121, 93, 680, 171, 1, 4311, 3, 121, 10943, 12, 15, 27, 5, 120, 10944, 44, 295, 21, 5, 3288, 2907, 16, 1009], [5, 3289, 908, 6780, 386, 16, 2, 835, 5, 2158, 32, 2001, 27, 174, 5199, 92, 61, 102, 6, 24, 1351, 162, 42, 1642], [29, 14, 2, 83], [24, 30, 916], [6781, 8, 1704, 10945, 998, 4, 365, 1024, 8, 8, 139, 14, 1], [117, 11, 4, 24], [743, 1881, 44, 10946, 743, 2672, 136, 6782, 10947, 245, 708, 6, 4, 6783, 12, 168, 858, 10948], [118, 5, 516, 467, 5130, 2168, 74, 2017, 10949, 2675, 11, 159, 8, 4, 1018, 5200], [5, 79, 217, 2, 104, 8, 88, 72, 6, 204, 943, 5, 49, 2, 2169, 1044, 6784, 2, 19, 6785], [5, 29, 62, 57, 20, 81, 59, 144, 104], [2943, 1, 1050, 103, 1476, 174, 590, 30], [183, 1165, 2170, 2703, 30, 120, 1], [37, 3, 380, 7, 70, 263, 202, 957, 158, 932], [576, 42, 33, 144, 10950, 55], [200, 5, 33, 79, 10, 789, 10951, 2, 236], [8, 1906, 29, 182, 316, 35, 722, 9, 125, 80, 802, 462, 3, 424, 7, 1432, 11, 2940, 238, 14, 10952, 2293, 251], [85, 40, 2, 9, 66, 62, 59, 473, 252, 7, 167, 960, 473, 39, 9, 54, 135, 58, 7, 11, 2, 449], [160, 375, 38, 66, 137, 10953, 26, 36, 1874, 79, 305, 413, 412, 315, 26, 10954, 121, 4070, 227, 32, 5, 9, 54, 10955], [40, 407, 72, 40, 200, 34, 367, 17, 8, 10956, 44, 398, 132, 11, 4, 179, 8, 62, 57, 15, 13, 37, 42, 65, 4306], [3, 118, 544, 2630, 311, 7, 1], [6786, 3598, 8, 10957, 24], [10, 25, 57, 50, 24, 532, 13], [4, 154, 628, 405, 225, 10958], [3718, 24], [573, 3, 346, 78, 91, 78, 49, 10, 4823, 12, 4312, 192, 8, 57, 59, 4, 1346, 425], [10959, 298, 4, 5117, 11, 10960, 15, 1343, 116, 2, 5201, 330, 1271], [84, 2145, 12, 56, 8, 52, 132, 728, 123, 847, 6787, 10961, 8, 3719, 10962], [23, 11, 22, 1, 18, 60, 10963, 385, 132, 11, 618, 371, 6788], [10964, 12, 179, 4313, 304, 1062, 66, 61, 479, 35, 5202, 11, 1670, 740], [217, 1415, 22, 6, 17, 707, 892, 1], [805, 10965, 33, 10966, 170, 1299, 22, 6, 15, 10967, 1], [1, 147, 47, 2, 702, 665], [1, 147, 80, 10968, 4314, 30], [1, 58, 3, 65, 120, 6, 42], [1, 204, 80, 653], [1, 139, 1823, 10, 45, 5203, 3, 90, 42, 42, 171, 1], [1, 194, 364, 54, 42, 18, 4315, 1734, 92], [210, 3, 33, 72, 3, 299, 42, 273, 17, 6, 998, 76, 37, 3, 998, 76, 1], [19, 42, 42, 171, 30, 1, 9], [55, 1, 42, 6789, 15, 44, 2, 1178, 16, 591, 1, 42, 2, 161, 640, 21, 4, 4316, 1162], [10, 89, 1, 5038], [367, 1, 3, 58, 623, 147], [148, 386, 485, 52, 210, 62, 15, 47, 97, 10969, 52, 47, 33, 238, 28, 60, 24, 3290], [25, 4317, 425, 151, 14, 1301, 31, 2, 181, 1796, 10, 77], [3, 210, 62, 220, 759, 8, 190], [8, 2, 1082, 2025, 1, 99], [147, 12, 68, 183, 978, 34, 143, 269, 12, 6790], [23, 784, 92, 37, 14, 772, 6, 28, 1705, 104], [736, 267, 1], [6791, 9], [1, 10, 310, 152, 309, 11, 686, 3, 41, 341, 1434], [6463], [148, 5012, 5204, 56, 55], [33, 592, 42, 8, 19, 12, 10, 968, 332, 64, 20, 3657, 24], [274, 2171, 240, 92, 86, 361, 490], [286, 552, 69, 200, 34, 7, 24, 165, 14, 2889], [1140, 773, 111, 395, 37, 5, 62, 161, 3636, 41, 9, 736], [3, 299, 1502, 28, 4, 6504, 7, 66, 62, 20, 2, 365, 187, 8, 998, 20, 365, 4318], [140, 20, 2, 181], [39, 9, 109, 54, 135], [4, 199, 189, 69, 86, 52, 63, 4109, 224, 1063, 461, 15, 14, 1248, 4319], [29, 70, 17, 1552, 5, 13, 68, 16, 10, 10970, 1, 10971], [3, 346, 2316, 742, 102, 837], [149, 16, 4, 2163, 16, 24, 5, 28, 117], [65, 51, 5, 27, 190, 10972], [218, 111, 51, 197, 49, 1, 36, 45, 3291, 8, 221, 252, 3, 87, 2, 77, 264, 54, 10973], [281, 367, 145, 34, 1157, 264, 552, 91, 15, 167, 17, 51, 264, 13, 224, 201, 11, 4, 561, 210, 61, 6, 376, 634, 13, 10974], [94, 280, 24, 396, 5], [2264], [221, 1, 167, 17, 35, 38, 5, 28, 228, 1674, 10975], [221, 117, 24], [52, 2, 359, 2264], [52, 79, 4, 6758, 2, 24, 74, 256], [3, 487, 258, 4, 1321, 68, 104], [3, 13, 80, 6792, 3, 67, 6, 70, 143, 1886, 6, 2, 120, 77, 125, 2, 207, 91, 2687, 8, 4050, 84, 4167], [3702, 1, 5, 860], [70, 5, 2, 285, 70, 185, 1213, 10976, 20, 2, 1388, 8, 31, 15, 12, 59, 5, 678, 552, 31, 15, 12, 15, 415, 10977], [61, 303, 76, 1], [10978, 2, 2649, 5205, 5, 171, 19, 187], [2491, 1717, 52, 12, 2, 104], [10, 10979, 162, 364, 5, 132, 51, 664], [5, 542, 6, 70, 22, 3708, 959, 305, 1], [3, 298, 10980, 11, 305, 10981, 1595, 670, 557, 574, 13, 56, 21, 760, 3, 90, 254, 70, 574, 86, 15, 2, 936], [85, 49, 5, 229, 232, 178, 11, 2696, 38, 5, 6171, 2421, 6793, 178, 3, 394, 118, 67, 10, 624], [60, 111, 58, 45, 6, 28, 565, 51, 8, 88, 14, 13, 5206, 90, 17, 3, 2210, 10982, 648, 12, 83], [1151, 78, 153, 284, 483, 1336, 206, 45, 41, 153, 10983, 84, 1907, 163, 10984], [10985, 153, 64, 1042, 147, 2893], [55, 286, 97, 765, 86, 2, 153, 142, 10986], [1, 622, 48, 1498], [3, 1535, 10987, 18, 4, 199, 822, 73, 10988, 160, 1, 491, 173, 4, 2720, 8, 3292, 444, 10989, 6794, 34, 1530, 4232], [3, 394, 3, 63, 349, 51, 6795, 292, 1, 27, 76], [65, 51, 174, 830, 42, 181], [5, 2, 1, 6796], [1, 29, 340, 2, 2490], [218, 3, 47, 1679, 366, 42, 54, 1185, 42, 2, 1, 205], [94, 7, 32, 10990, 8, 875, 1, 30, 36, 210, 547, 17, 28, 10, 261, 2164, 78, 96, 11, 4, 10991], [5, 10, 145, 464, 1908, 55], [5, 2, 6797, 647, 94, 23, 61, 32, 179, 2481, 369], [23, 556, 706, 5, 4, 327, 321, 39, 9, 356], [10, 153], [78, 153, 3482, 35], [52, 407, 1036, 1479, 177, 277], [4, 312, 12, 501, 6, 194, 41, 6, 1124, 1206, 177, 63, 569, 2085, 1840, 99, 55], [350, 2, 1, 99], [23, 135, 92, 9], [3, 380, 7, 171, 1, 34, 66, 32, 87, 6, 467, 60, 106, 10, 507, 98, 19, 217, 35, 281], [973, 11, 618, 133, 6, 433, 54, 10992, 12, 152, 14, 2, 1], [281, 33, 10993, 34, 97, 66, 198, 8, 28, 7, 181, 6, 107, 8, 219, 61, 6798, 74, 60, 45], [20, 82, 2, 56, 63], [349, 35, 11, 7, 10994, 5, 62, 23, 133, 6, 70, 80, 77, 24, 3293], [1, 3, 41, 60, 1009, 147, 662, 11, 819], [19, 102, 161, 1, 700, 146, 161, 138], [146, 176, 20, 1, 11, 536], [15, 1718, 1242, 13, 22, 7, 70, 2961, 882, 130, 248, 2961, 2128, 2, 437, 38, 111, 27, 10995, 220, 5207], [5, 65, 13, 19, 5208, 1], [955, 18, 1407, 1], [97, 77, 12, 2, 10996, 30, 282, 28, 50, 793, 829, 8, 113, 50, 6, 139, 1999, 908, 54, 50, 476, 32, 115], [286, 1710, 52, 2, 1391, 2893], [28, 18, 187], [24], [43, 3, 6799, 33, 70, 2, 979, 4320, 289, 105, 79, 42, 2, 1], [52, 96, 2, 10997, 464], [10998, 2492, 738, 3, 210, 44, 602, 6, 28, 15, 211, 10, 10999, 11000, 15, 2, 353, 3, 87, 254, 63, 11001], [3, 62, 39, 9, 46, 117], [1, 242, 4, 19, 35, 11002, 20, 2, 659, 1, 835, 25], [1325, 278, 19, 2, 381, 230, 3, 19, 5, 1127, 24], [97, 34, 5, 75, 140, 15, 2, 112, 1024, 171, 1, 3, 61, 6, 11003, 19, 1], [25, 632, 60, 466, 8, 6800, 24], [15, 229, 1219, 572, 17], [516, 130, 442, 7, 116, 47, 2, 91, 69, 47, 4, 727, 857, 16, 93, 42, 382, 254], [252, 3, 47, 633, 34, 88, 65, 51, 15, 3, 19, 309, 51, 577, 23, 4, 247, 11004, 673], [278, 506, 393, 31, 111, 49, 103, 6, 303, 15, 71, 2711, 58, 4113, 86, 16, 126, 24, 6, 506, 7], [140, 31, 5, 608, 2425, 5, 44, 6, 608, 104, 116, 43, 5132], [1, 30, 25, 3636], [2895, 177, 20, 758, 926, 130, 2, 1, 11, 7, 830, 3607, 91, 2281, 173, 2, 4236, 203, 30, 161, 177], [177, 65, 13, 2, 2172, 18, 7, 9], [1140, 848, 261, 762, 142, 32, 4, 24, 27, 4, 1340, 18, 10, 758, 8, 43, 1374, 5209], [43, 437, 375, 32, 212, 11005, 63, 14, 2, 112, 83], [4, 1055, 49, 11006, 106, 12, 2260], [107, 129, 9], [697, 366, 1032, 281, 280, 3, 46, 110, 11, 10, 689, 478, 8, 3, 330, 41, 9, 122, 6, 72, 47, 35, 82, 166, 975], [7, 9, 18, 60, 166, 45, 280, 945, 8, 11007, 165, 1315, 7, 2, 25, 314], [219, 11008, 4321, 222, 14, 33, 2, 848, 714, 371, 15, 4, 11009, 6801, 4, 6802, 48, 5210, 2, 11010], [32, 1, 6803, 4322], [3, 33, 75, 397, 71, 111, 28, 32, 19, 6804, 59, 15, 1047, 1779, 1, 7, 110, 28, 626, 51, 15], [2598, 12, 48, 165, 130, 4323, 74, 898], [25, 19, 350, 60, 2173, 261, 61, 332, 88, 2, 1, 193, 165, 130, 11011], [1523, 506, 508, 41, 60, 5172], [3, 47, 811, 6, 14, 11012, 8, 289, 105, 124, 2, 181, 74, 2, 6805, 23, 333, 59, 7, 11013, 367, 3, 44, 2, 828, 34, 7, 1284], [75, 110, 1175, 1777, 5, 44, 4, 1209, 16, 98, 673], [246, 202, 91, 57, 277, 7, 44, 6, 58, 27, 393, 469, 2, 269, 156, 2, 269, 2962, 1718], [552, 3, 146, 86, 59, 15, 149, 76, 1, 969, 73, 45], [7, 183, 30, 406, 8, 267, 1], [40, 318, 14, 4, 68, 29, 14, 2, 1], [3, 487, 279, 882, 59, 39, 1], [4, 1481, 384, 1, 156, 41, 667, 45, 125, 11014], [160, 24, 26, 11015], [403, 1, 31, 20, 152, 81, 45, 1318, 17, 8, 559, 14, 270, 2, 1, 71, 200, 3, 19, 35, 4, 347, 149, 15, 266, 555, 1211, 1496], [278, 90, 150, 13, 2, 104, 99, 1043, 30, 9], [71, 59, 5, 1089, 10, 11016, 54, 27, 20, 1200, 5, 141, 104], [242, 20, 476, 5, 141, 172, 1], [5, 537, 141, 1], [766, 19, 32, 212, 4324, 374, 158, 36, 32, 65, 3720, 6, 307], [212, 141, 104, 1326, 44, 558, 129, 126, 235, 2656, 70, 1731, 11017, 1489, 785, 2, 11018], [55, 113, 147, 120, 1, 3, 121, 403], [23, 107, 283], [42, 2493, 17, 774, 229, 4, 1, 43, 64], [11019, 5065, 5211, 2, 11020, 11021, 678, 12, 560, 168, 6, 70, 3294, 6806, 26, 508, 16, 845], [181], [174, 306, 24, 309, 2, 981, 989, 37, 219, 44, 93, 2494], [2016, 26, 11022, 4, 104, 69, 67, 6, 14, 11023, 4, 1205, 661, 16, 1538, 1291, 31, 87, 14], [1, 14, 2922, 1360, 196, 256, 6, 986], [146, 14, 1996, 3543, 6, 79, 17, 2, 1, 55], [11024], [242, 35, 181], [3295, 7, 52, 2, 11025, 140, 52, 555, 56, 2026, 5, 268, 2126, 11026], [55, 7, 25, 2, 112, 144], [40, 2, 89, 1], [200, 5, 872, 13, 2, 144, 38, 5, 220, 2, 265, 15, 424, 17, 634, 13, 2317, 940, 230, 3, 683, 71, 6, 905, 872], [1004, 91, 19, 76, 9, 188, 36, 417, 6, 65, 51, 34, 36, 46, 21, 17], [151, 229, 35, 8, 901, 2, 828, 74, 885], [40, 4, 101, 1, 7, 271, 334, 40, 2, 4102, 280], [26, 812, 57], [805, 410, 3296, 11027, 85, 200, 3, 11028, 4325, 23, 572, 5], [267, 141, 181], [128, 1157, 76, 9, 47, 342, 483, 55], [176, 39, 9, 243], [1, 30], [29, 1087, 51, 17, 3, 64, 398, 16, 4, 11029, 5212, 5145, 4, 56, 11030], [4, 931, 136, 4326, 82, 4, 11031, 43, 127, 931, 11, 11032, 4327, 21, 11033, 8, 6807], [252, 559, 14, 2, 11034, 83, 5, 920, 5213, 11035, 17, 48, 6, 113, 3721], [695, 10, 310, 2659, 13, 2, 812], [52, 64, 11036, 15, 32, 224, 2021, 52, 64, 4, 1026, 164, 23, 362, 52, 330, 1862, 18, 11037, 9, 73, 219], [9, 9, 9, 2721, 1503], [642, 12, 2, 1, 84, 2963, 47, 1604, 1086, 21, 3660, 5214, 101, 193, 66, 2275, 1331, 12, 27, 4114, 18, 4, 11038], [403, 92, 29, 1877, 10, 1641, 282], [4851, 325, 3722, 399, 96, 4328], [274, 1210, 8, 7, 252, 12, 11039, 964, 2568, 4329], [91, 398, 76, 28, 224, 2, 320, 666, 16, 319], [2581, 79, 17, 2, 187], [22, 13, 2, 144, 6808, 4330], [51, 10, 489, 236, 5215], [160, 2664, 1, 11040, 5, 655, 254, 11041, 2114], [136, 11042, 136, 7, 186, 136], [1324, 42, 918], [5, 452, 62, 181], [78, 41, 1741, 11043, 972, 6809, 6810, 14, 179], [128, 289, 156, 67, 6, 11044, 10, 30, 74, 48, 23, 6491, 9, 1023, 8, 1284], [241, 11045, 1589, 48, 7, 2495, 5, 600, 48, 62, 2174, 442, 22, 34, 23, 4331, 21, 1189, 1982, 55, 2899, 6811], [42, 398, 370, 6, 134, 529, 2, 11046, 596, 84, 56, 2318, 4332, 174, 6764, 47, 3297, 6812, 822], [98, 11047, 11048, 11049, 4180, 1480, 524, 5216, 4176, 18, 11050, 4933, 445, 4, 1205, 26, 1430, 1401, 6813, 201, 84, 5217], [55, 4333, 69, 41, 68, 177, 10, 30, 1045, 73, 2, 83, 5, 1354, 35, 46, 97], [1287, 24], [425, 157, 18, 21, 186, 3, 94, 203, 1], [33, 194, 1, 25, 42, 152, 67, 4, 413, 412, 544], [403, 5, 1, 5, 198, 28, 4, 18, 20, 3723, 3298, 14, 697, 21, 15, 23, 265, 59, 4, 1, 5218], [11051, 52, 124, 214, 1], [10, 11052, 241, 304, 15, 10, 19, 457, 1], [57, 49, 5, 58, 390, 24], [3, 13, 15, 108, 11053, 15, 351, 972, 17, 149, 1430, 389, 143, 4334], [69, 12, 143, 6814, 1430], [267, 5, 21, 4, 1788, 39, 1, 37, 4335, 98, 376, 18, 20, 451, 36, 33, 14, 13, 1210, 42, 37, 789, 100, 17, 249, 174, 138], [329, 485, 5, 132, 799, 27, 24, 34, 3, 29, 157, 35, 27, 7, 5199, 31, 3, 11054, 35, 113, 17, 3, 11055, 562, 176, 15, 112], [1], [312, 1902], [55, 161, 1], [7, 148, 1309, 46, 105, 79, 108, 1, 30], [1, 11056], [3, 62, 117, 37, 209, 144], [3, 33, 683, 71, 239, 144, 5, 63, 258, 38, 5, 1785, 1839, 11057], [7, 48, 11058, 15, 98, 4336, 488, 7, 3299, 408, 49, 3300], [4337, 1, 4337], [15, 152, 316, 15, 142, 464, 650, 15, 227, 173, 2, 11059, 330, 13, 2, 2115, 125, 285, 146, 429, 15, 98, 1627, 14, 223], [1099, 35, 18, 2, 89, 11060, 1, 65, 93], [177, 42, 65, 13, 180, 95, 102, 16, 6815, 606], [1, 3, 29, 110, 65, 13, 7, 176, 81, 8, 66, 61, 6, 290], [1, 23, 112, 25, 4, 19, 42, 196, 669, 30, 25, 3, 58, 17, 3, 29, 1463, 6, 14, 217, 23, 48, 37, 42, 63, 242, 7, 45, 35, 1156, 177], [1, 20, 5219, 42, 29, 44, 2, 1523, 8, 5, 148, 362, 75, 742, 42, 487, 742, 31, 20, 164, 2579, 18, 15], [576, 42, 176, 15, 1843, 365, 28, 80, 564, 30, 18, 5220, 1319, 286, 43, 28, 18, 5220], [241, 286, 43, 42, 44, 43, 1008, 57, 37, 182, 48, 110, 2, 141, 1102, 27, 384, 2113, 30, 11061, 8, 85, 37, 44, 2, 4338, 18, 1, 42, 48, 202], [447, 7, 57, 3, 299, 24, 177, 42, 523, 2, 19, 593], [7, 2, 404, 117, 1271, 245, 25, 69, 317, 5221, 11, 7, 12, 2, 711, 110, 31, 36, 29, 11062], [40, 11063, 75, 110, 1463, 6816], [198, 14, 55, 161, 1], [20, 1073, 3, 346, 5, 99, 312, 1902], [198, 14, 61, 6, 351, 95, 769], [244, 1588, 118, 14, 11064, 31, 268, 1120, 220, 6817, 378, 758, 102, 647, 219, 114, 4, 5093, 8, 201, 4, 6818], [23, 1233, 15, 118, 65, 256, 13, 2, 1, 491, 8, 2, 11065], [5, 58, 41, 6819, 143, 1541], [7, 1, 67, 326, 54, 5222, 7, 4, 199, 45, 40, 200, 6, 17, 51, 68, 446], [29, 1332, 1], [7, 1, 167, 4, 418, 38, 40, 266, 11066, 7, 45, 669, 483], [932, 3, 132, 27, 5223, 21, 445, 213, 83], [262, 17, 66, 29, 6820, 9, 194], [25, 5, 328, 1571, 80, 1643, 5224, 11067, 739, 34, 1362, 1079, 3724, 1052, 49, 56], [3, 452, 958, 2, 1835, 27, 212, 56, 63], [7, 47, 112, 153, 45, 205, 55], [5, 196, 1, 30, 24], [588, 24], [55, 221, 280, 93, 11068, 34, 1, 58, 64, 1797, 792, 37, 15, 2, 395, 2496], [285], [5, 46, 688, 995, 793, 15, 48, 129, 24], [20, 2, 1, 31, 5, 167, 2, 77], [5, 2, 1, 6225], [20, 2, 1043, 24, 30, 1, 252, 5, 29, 44, 4, 466, 6, 290, 32, 5, 131, 58, 12, 131, 167, 77, 20, 2, 172, 1], [7, 11069], [148, 1, 18, 2, 25, 453, 281], [102, 6, 4, 1398, 16, 20, 1254, 3301, 18, 98, 11070, 699, 11071, 234, 16, 2, 1015, 11072], [11073, 3504], [629, 29, 690, 73, 358, 73, 5, 58, 490, 45, 27, 490, 20, 2, 25], [1865, 23, 133, 6, 6821, 22, 1], [26, 49, 283], [66, 58, 15, 6822, 650, 5, 6823, 263, 283], [83], [3, 2212, 4211, 11074, 636, 57, 11, 7, 874, 10, 312], [281, 40, 2, 185, 9], [621, 316, 11, 2, 2319], [167, 4, 949, 11075, 21, 4, 301, 8, 4, 1092], [2913, 386, 16, 1], [11076, 35, 11, 7, 9], [3493, 91, 66, 124, 2, 3725, 969, 161, 11077, 644, 7, 1, 54], [372, 13, 2, 93, 11078, 34, 3, 67, 10, 324, 6, 14, 11079, 1422, 158, 8, 2620, 11080], [66, 44, 2, 1969, 7, 222, 1337, 173, 2, 2388, 4212, 34, 3667, 2, 392, 2175, 382, 35, 21, 959], [20, 2, 6824], [1, 3, 197, 899, 755, 2, 115, 6, 1367, 20, 2964, 19, 5], [1, 23, 328, 27, 261], [104], [446, 7, 11081, 1, 54], [22, 9, 407, 334], [23, 1569, 1300, 1, 23, 2722, 6208, 4339, 149, 23, 37, 613, 3, 41, 10, 11082, 11083, 8, 10, 792, 11084], [5, 398, 362, 58, 5, 67, 6, 134, 2, 351, 433, 6, 155, 1909, 3302, 11, 22, 823, 5, 268, 49, 57, 329, 135], [1, 333], [140, 40, 2, 158], [36, 63, 94, 22, 1496, 158], [57, 49, 5, 58, 1], [5, 44, 2, 388, 2497, 4, 199, 111, 7, 86, 11085, 12, 112, 86, 1940, 365, 6825, 12, 1798, 20, 68], [3, 63, 101, 293, 159, 5225], [109, 7, 85, 66, 41, 234, 9], [693, 195, 3, 48, 1003, 183, 1480, 6826, 136, 6, 303, 24], [3, 509, 2, 202, 91, 175, 341, 1645, 12, 56, 26, 2829, 12, 11086, 3, 75, 799], [242, 35, 1, 8, 1841, 18, 7, 1432, 11087], [55, 573, 3, 33, 67, 860, 354], [95, 16, 2, 1508, 2230, 612], [73, 358, 73, 15, 48, 68, 16, 212, 11088, 11089, 117], [5, 67, 10, 24, 37, 89], [569, 2965, 2703, 30, 120, 1], [640, 339, 30, 1], [11090, 140, 84, 2024, 47, 11091, 84, 3303, 220, 4340, 579, 52, 200, 236, 401, 3271, 11, 398, 645], [5019, 3, 47, 86, 133, 7, 4, 166, 115, 2706, 5, 101, 109, 569, 16, 68, 395, 10, 145], [422, 42, 4341, 6827, 3, 64, 5, 8, 5, 49, 10, 4342, 51, 290, 178, 8, 5, 415, 28, 127, 1, 776, 1258], [22, 12, 11092, 1479, 6, 17, 140, 3, 29, 44, 4, 178], [11093, 5, 1053, 108, 1, 55], [1, 55], [43, 1, 55, 23, 48, 59, 7, 164, 1046], [3, 87, 60, 355, 875, 26, 190, 1286, 26, 11094, 758, 2130], [11095, 3, 75, 94, 20, 6828, 1217, 23, 2, 339, 1, 1185], [252, 113, 17, 85, 7, 37, 573, 10, 306, 136, 22, 228, 82, 1094, 122, 6, 1617, 786, 1231, 8, 45], [6829, 43, 91, 198, 1120, 84, 1451, 51, 2, 11096], [417, 1024, 104], [24], [219, 11097, 12, 13, 698, 16, 2, 1476, 92, 7, 4, 179, 420, 135, 371, 15, 3726, 6, 259, 135, 6830], [69, 63, 11098, 21, 97, 24, 205, 888], [44, 42, 2266, 5127, 106, 11, 245, 179, 74, 125, 4, 213, 16, 3304, 1694, 123, 1205, 11, 4, 202, 2227], [57, 98, 3213, 754, 11099, 9, 27, 4, 2966, 2723, 11100, 983, 4, 6213, 2967, 11101, 3271], [78, 153, 133, 6, 665, 902, 55, 75, 304, 21, 4, 360, 6, 94, 22, 2397, 45, 153], [559, 14, 2, 24], [6748, 6831, 4871, 11102, 5179, 965, 4343, 129, 11103, 11104, 26, 2232, 11105, 6751, 11106, 9, 2232, 11107, 2724, 11108, 11109, 3727, 11110, 1536, 11111], [5226, 136, 132, 231, 295, 34, 56, 371, 84, 1432, 6, 11112], [1, 29, 110, 86, 59, 868, 125, 17], [9, 29, 70, 17, 157, 35, 4962, 16, 20, 262, 6, 17, 9], [242, 35, 172, 918], [33, 14, 2, 9, 88], [23, 2275, 22, 1, 797], [3, 560, 13, 71, 23, 79, 4, 9, 38, 289, 132, 72, 2498], [24, 30, 1], [29, 14, 2, 1, 251], [61, 108, 6, 3728, 11113, 3, 11114, 16, 1134, 7, 118, 11115, 298, 129, 2, 381, 8, 3200, 254], [7, 57, 3, 79, 2, 1780, 5007, 9], [11116, 11117, 5, 70, 7, 45, 11118], [4, 2418, 16, 1076, 6832, 257, 15, 173, 2, 11119, 11120], [383, 67, 6, 100, 11121, 62, 293, 4, 3560, 204, 20, 11122, 1461, 56], [55, 5, 113, 7, 1], [177, 3, 124, 43, 1179, 7, 47, 3305, 15, 79, 2, 11123, 20, 1765, 51, 56, 81], [1667, 31, 7, 1, 210, 396, 84, 410, 37, 209, 3, 222, 258, 127], [11124, 997, 766, 5, 490], [1, 139, 1500, 149, 36, 46, 70, 240, 11, 6833, 6834, 5, 198, 14, 243, 36, 70, 240, 11, 3729, 92], [2320, 494, 120, 640, 1], [2943, 494, 120, 56], [526, 2499, 120, 104], [183, 120, 1], [29, 14, 2, 1, 91, 35, 55, 513], [7, 12, 4344, 171, 3126, 285], [148, 52, 47, 10, 1, 21, 3730, 2241, 412, 215, 213], [55, 156, 27, 4, 733, 8, 3731, 33, 13, 38, 4196, 291, 35, 27, 5, 149, 20, 2, 1897, 206, 83], [590, 65, 158], [5, 594, 5, 65, 13, 2, 112, 164, 391, 117, 13, 5, 65, 13, 2, 3732, 391, 1669, 2, 1201, 1865, 26, 6835, 752, 255, 391], [11125, 797, 3, 46, 41, 43, 1, 3733, 3, 702, 1250, 41, 2, 418, 34, 3, 75, 72, 15, 18, 1610, 5, 62, 71, 39, 6836, 12], [25, 65, 10, 1366, 1853, 15, 28, 167, 11, 4, 30, 98, 65, 13, 15, 132, 290, 32, 15, 11126, 151, 1465, 147, 1, 98, 298], [512, 7, 158, 1, 11, 4, 11127], [367, 92, 28, 102, 186, 5, 564, 664, 198, 44, 105, 683, 71, 6, 168, 4, 1213], [3, 297, 667, 16, 15, 34, 23, 1532, 94, 11128, 163, 2321], [1292, 6837, 19, 2322], [56], [1457, 19, 3584, 42, 1043, 83], [3603, 3, 94, 23, 96, 2, 11129, 59, 4, 2968, 16, 4, 282, 34, 23, 11130], [20, 2, 141, 1, 6838], [11131, 5, 918, 4835], [3, 46, 480, 682, 25, 23, 110, 207, 128], [25, 3, 81, 45, 1230, 22, 46, 1573, 154, 120, 1, 66, 61, 1014, 22, 155, 148, 115], [42, 2, 1, 11, 25, 754, 242, 80, 30, 35], [2710], [52, 2, 6824], [21, 4, 1665, 34, 29, 279, 69, 12, 650, 3, 146, 94, 1770, 199, 27, 155, 1719, 110, 95, 11132, 57, 1591], [3, 13, 17, 384, 953, 319, 115, 249, 17, 102, 21, 473, 2969], [3, 47, 133, 6, 737, 2, 83], [280, 22, 1, 109, 2970, 116, 8, 47, 13, 5, 152, 134, 17, 10, 4345], [1030, 21, 11133, 11134, 7, 1, 47, 356], [20, 96, 2, 1], [76, 139, 14, 2, 1, 8, 58, 15], [375, 6120, 63, 14, 2, 1, 139, 6, 467, 31, 5, 28, 11135, 2068], [174, 68, 6, 81, 1], [221, 15, 19, 7, 11136, 1, 744, 2436], [267, 171, 1], [5, 220, 116, 1, 55], [20, 14, 2, 1, 55, 34, 3535, 11137, 11138], [33, 121, 11139, 392, 16, 11140, 11141, 299, 66, 220, 11142, 11143], [7, 573, 11, 60, 6471, 178, 12, 727, 1383, 92, 2, 115, 1000, 416, 12, 2, 11144, 27, 1468, 1562, 8, 1076, 95], [241, 304, 11145, 3, 28, 7, 846, 16, 17, 868, 27, 11146, 234, 1969, 123, 11147, 10, 1758, 221, 1793, 12, 2091], [3, 633, 3201, 574, 102, 18, 2283, 3, 47, 2971, 4, 11148, 244, 2176, 76, 9, 30, 2585], [55, 15, 152, 14, 37, 501, 41, 268, 2284, 18, 4, 193], [153, 1138, 636, 133, 143, 2725, 16, 11149], [8, 2, 3734, 11150, 118, 56, 247, 16, 39, 11151, 252, 225], [766, 1910, 5, 9], [1910, 85, 49, 5, 37, 179], [3, 195, 156, 116, 1], [11152, 11, 143, 108], [212, 677, 220, 56], [11153, 181, 177, 195, 3, 152, 194, 5, 137], [72, 4, 206, 91, 647, 3, 293, 5, 63, 2273, 246, 546, 213, 5, 1482, 3631, 1567, 269], [55, 7, 24, 41, 613, 25, 468, 126, 453, 776, 41, 5227, 26, 4346, 11154, 54, 7, 4316, 12, 4, 1377, 11155], [5, 54, 80, 3306, 1085, 6769, 130, 960, 26, 193, 127, 142, 6, 4347, 1264, 1, 134, 170, 127, 437, 130, 1336, 4348], [3, 12, 207, 3307, 8, 60, 11156, 38, 3, 420, 11, 3, 29, 1606, 4, 2323, 3, 2726, 15, 54], [3, 465, 97, 9], [3, 47, 376, 9, 162, 5, 51], [1746, 9, 5, 223, 2288], [55, 3, 103, 14, 116, 11, 4, 561, 9], [576, 9, 100, 17, 94, 31, 5, 41, 6839], [5, 1632, 268, 9, 3, 29, 131, 465, 45, 38, 3, 11157], [11158, 11159, 6840, 49, 2, 83], [1, 57, 582, 6, 1506, 785], [250, 102, 69, 5, 79, 2, 9, 29, 70, 17, 61, 6841, 422, 5, 1567, 1567], [241, 5, 3308, 386, 16, 2, 1, 5], [11160, 15, 4, 299, 7, 11161, 5, 2, 11162], [32, 3, 200, 47, 1, 59, 6842, 96, 64, 5, 769], [913, 5, 934, 143, 4349, 125, 2, 207, 720, 66, 58, 15, 361, 11, 201, 5228, 100, 17, 43, 31, 3, 87, 2177, 316, 143, 6843], [10, 45, 13, 98, 2568, 2727, 202, 8, 180, 602, 37, 147, 32, 143, 287, 28, 384, 2, 864], [3, 67, 6, 79, 133, 10, 11163, 34, 3, 46, 5229, 31, 5, 2, 1998, 972, 143, 207, 617], [32, 384, 207, 177, 14, 854, 3, 1038, 260, 5230, 3, 41, 6, 1367, 10, 11164, 793, 143, 1020, 8, 11165, 8, 3, 1730, 6844], [277, 143, 163, 196, 664], [1019, 1, 163, 10, 565, 25], [3, 266, 272, 107, 633, 11, 20, 1], [55, 3309, 1, 29, 157, 80, 164, 18, 17, 1384, 75, 467, 591, 211, 885, 30, 25], [43, 15, 3133, 1], [242, 35, 1], [66, 29, 64, 22, 9], [42, 67, 17, 6, 70, 42, 68, 16, 10, 179, 11166, 36, 107, 11, 419, 8, 11167], [29, 28, 7, 2500, 2178, 4350, 205, 15, 56], [9, 29, 175, 17], [339, 1, 3274, 772], [11168, 3, 346, 5, 1], [4351, 353, 427, 7, 89, 140, 38, 5, 72, 7, 6, 2, 120, 395, 20, 72, 126, 68, 16, 4, 2172], [293, 5, 189, 58, 28, 1183, 21, 608, 11169, 666, 16, 537, 2218, 1716], [26, 5231, 5, 83], [5, 1711, 2238, 1], [61, 1646, 11, 2, 1860, 74, 256, 181, 43, 68, 279, 59, 20, 5070, 3282], [296, 67, 6, 119, 20, 887], [7, 1130, 12, 120, 56, 8, 101, 120, 56, 118, 303, 7, 6845], [1776, 277, 20, 19, 534, 285], [128, 112, 45, 464, 76, 1, 14, 171, 73, 19, 251], [9, 273, 17, 40, 47, 152, 3310, 10, 138, 102, 188, 40, 47, 82, 2719], [3, 194, 4, 841, 658, 426, 3, 67, 6, 94, 4, 5232, 234, 16, 11170, 48, 6, 94, 2, 11171, 9, 69, 168, 11172, 343, 6846], [40, 47, 156, 2, 2169, 3728, 1773, 5233, 701, 26, 2, 5129, 43, 690, 57, 6765, 1053, 7, 103, 105, 396], [91, 28, 80, 1, 30, 54, 10, 663, 844, 91, 27, 32, 1118, 1662, 42, 1070], [1, 1481, 32, 973, 827, 5, 131, 58], [290, 74, 336, 171, 1], [2888, 1, 272, 94, 42], [107, 37, 5, 63, 1665, 170, 72, 52, 10, 1], [19, 20, 813, 1799, 236], [5234, 113, 76, 3126, 202, 6, 28, 217, 5235, 8, 472, 76, 35, 120, 11173, 156, 1545], [4352, 8, 3735, 36, 103, 105, 11174, 56], [2728, 4, 141, 2084, 269], [4, 490, 163, 490, 131, 340, 41, 57, 36, 198, 44, 1030, 198, 44, 132, 127, 106, 11, 865], [36, 49, 32, 1718, 1030, 11175, 4, 763, 49, 33, 2972, 30, 1], [693, 29, 398, 16, 212, 203, 1, 309], [42, 198, 33, 349, 54, 26, 100, 11176, 21, 4353, 15, 136, 132, 2, 2501, 936, 11177, 247, 523, 33, 701, 236], [3, 41, 7, 9, 11178, 281, 31, 5, 131, 2324, 15], [11179, 7, 9, 65, 697, 281, 34, 5236], [60, 287, 28, 11, 2, 575, 705, 37, 36, 266, 150, 13, 2, 9, 21, 44, 2637], [28, 15, 426, 5, 79, 630, 2, 2502, 3, 79, 5, 2, 282, 426, 9, 49, 2502, 1292, 23, 37, 356], [154, 11180, 27, 11181, 3129, 82, 4, 2179, 15, 216, 16, 1485, 759, 873, 5, 62], [1709, 57, 5, 157, 18, 212, 353, 6847], [668, 24], [23, 18, 7, 344, 2663, 3250, 1, 29, 204, 10, 1822], [1, 3, 41, 893, 6, 19, 390, 3, 121, 928, 25], [1, 3, 70, 4, 893, 48, 5, 24, 2729, 23, 11, 1338, 253, 17, 74, 2223, 17, 23, 1042, 928, 8, 220, 290], [19, 5, 321, 5, 210, 229, 35, 19, 24], [281, 2888, 312, 1954, 4354], [281, 5, 868, 25, 3, 19, 1, 70, 169, 8, 366, 7, 344, 2730, 3250], [2888, 22, 928, 312], [22, 928, 51, 4, 1327, 6848, 1483, 5, 525, 792, 13, 4, 1, 3, 19], [252, 19, 5, 104, 15, 928, 74, 43, 61, 1, 3, 644, 4, 1911, 5, 70, 74, 421, 76, 1], [19, 572, 20, 120, 30, 140, 5, 122, 6, 192, 45, 13, 2, 19, 494, 37, 19, 5, 25], [2888, 25, 281, 19, 494, 136, 6, 1891, 84, 2951], [2888, 25, 390, 51, 6849, 1327, 6848, 1483, 1], [5144, 3736, 209, 104], [85, 5, 345, 88, 260, 108, 1], [344, 35, 20, 9, 63, 304], [11182, 717, 11183, 563, 11184, 6247, 11185, 11186, 3283, 4355, 11187, 11188, 1676, 3737, 278], [43, 7, 25, 784, 6, 1869, 559, 1532, 6, 204, 2, 25, 1822, 5, 291, 1], [221, 37, 559, 14, 2, 1, 8, 11189], [28, 173, 1377, 250, 1, 11190], [2824, 144], [3, 105, 109, 728, 27, 4, 120, 11191, 3, 150, 97, 1669, 34, 39, 10, 443, 3311, 16, 32, 817], [289, 124, 6, 58, 15, 11, 3312, 11192, 46, 109, 7, 11193, 560, 29, 79, 20, 826, 2, 1, 18, 1610], [267, 312], [40, 47, 2, 537, 1, 156, 6290, 21, 3313, 8, 11194, 8, 45, 37, 3177, 156, 14, 13, 11195, 11196], [426, 12, 56, 85, 118, 52, 308, 59, 7, 3, 273, 5, 52, 112], [5, 428, 86, 286, 58, 7, 161, 1, 75, 929, 2, 1295], [398, 16, 78, 24, 3626], [3, 454, 31, 4, 6850, 210, 11197, 379, 202, 435, 6, 4, 179, 6, 176, 76, 423, 82, 2139, 5237, 11198], [11199, 5, 131, 14, 68, 16, 10, 2731], [63, 3, 1, 59, 48, 44, 366], [19, 20, 786, 1], [45, 113, 7, 24, 6, 107, 54, 16, 2690, 8, 229, 35, 11200, 4258, 88, 52, 63, 28, 538], [48, 73, 549, 73, 5, 1433, 56], [735, 10, 24, 8, 581, 1144], [151, 714, 174, 926, 24, 37, 2265, 604, 14, 1897, 10, 226, 4845], [1, 42, 697], [1489], [321, 109, 728, 2, 6851, 18, 84, 231, 1140, 52, 700, 41, 984, 1, 99, 720], [5, 2493, 162, 3, 195, 24, 3, 90, 38, 42, 191, 17, 1118], [56], [5238, 965, 11201, 4871, 9, 11202, 1536, 11203, 9, 11204, 3738, 6852, 11205, 11206, 1676, 2724, 11207, 11208], [3, 47, 528, 51, 2, 675, 59, 3314, 180, 511, 83], [36, 67, 57, 3, 41, 3, 67, 57, 36, 41, 11209, 41, 4, 324, 158, 3, 67, 15, 6], [11210, 1532, 201, 349, 2, 4356, 11211, 30, 386, 16, 2, 1], [11212, 6831, 11213, 9, 11214, 435, 3739, 11215, 11216, 11217, 11218, 2268, 11219], [40, 294, 423, 57, 2, 285], [151, 191, 5, 199, 938, 58, 5, 608, 1909, 3302, 58, 5, 608, 1775], [12, 7, 32, 42, 63, 72, 816], [8, 1853, 15, 56, 2481, 5, 198, 62, 7, 1047, 27, 1384, 11220], [3, 61, 21, 4, 247, 2634, 1861, 88, 123, 6853, 129, 8, 328, 27, 11221, 635, 12, 2, 1, 3740], [23, 383, 238, 11222, 423, 82, 4, 158, 1669], [1700, 8, 215, 106, 151, 182, 79, 5, 7, 104], [1936, 42, 37, 726, 55], [55, 7, 11223, 6854, 1281, 292, 6198], [37, 63, 66, 33, 100, 22, 104, 11, 330, 230, 52, 345, 1399, 6, 376], [6855, 5, 181, 1042], [30, 354, 8, 84, 226, 12, 11224, 11225], [11226, 12, 2, 711, 727, 5239, 6856, 11227, 8, 11228, 84, 6856, 49, 96, 322, 5239, 52, 33, 2, 1686, 295, 1101, 5240, 11229, 1002], [2147, 38, 20, 93, 6, 61, 1], [526, 3, 29, 110, 62, 162, 11230, 6857, 11231, 118, 132, 11232, 2, 4321, 88, 920, 21, 4, 3638, 55], [1, 85, 200, 5, 48, 1988, 74, 800, 22], [1416, 380, 5, 2503, 4, 11233, 1307, 11234], [369, 9, 729, 10, 938], [20, 702, 2973, 388, 1496, 946, 21, 39, 5241, 6761, 7, 1718, 13, 5, 442], [420, 54, 16, 305, 823, 660], [52, 195, 136, 43, 2732], [206, 27, 2, 206, 3513, 24, 7, 12], [2480, 74, 4, 166, 327, 16, 4, 718, 128], [55, 19, 39, 161, 1, 46, 45, 6, 1702, 1287, 545, 5, 205], [20, 2, 1], [3, 90, 212, 2504, 30, 2945, 7, 79, 5, 6858, 23, 13, 757, 3, 46, 80, 6859], [1416, 258, 54, 5, 186, 6860, 27, 9], [1, 87, 6861], [24, 1872, 18, 2, 11235, 288, 174, 119, 2829], [1710, 2, 379, 1, 41, 261], [1733, 4108, 63, 268, 294, 612, 650, 36, 49, 1279], [212, 274, 148, 11236], [324, 261, 2325, 18, 2, 171, 1774], [199, 1184, 19, 90, 7, 83], [273, 5, 76, 1, 47, 214, 110, 3686], [23, 238, 44, 22, 1, 11, 54, 738], [128, 286, 6862, 3, 64, 834, 1, 26, 834, 1, 64, 203, 956], [1, 5, 62, 5, 266, 22], [219, 52, 11237, 137, 4, 1977, 6863, 16, 11238, 4357, 4, 154, 1219, 409, 51, 11239], [4801, 18, 22, 2974, 6336, 6864, 3315, 82, 4169, 159, 338, 2, 215, 11240], [3, 592, 50, 117, 135, 93, 401, 753, 17, 1906, 104], [3, 2505, 3741, 744, 47, 383, 854, 3, 124, 32, 4, 9, 13, 201, 115, 892, 43, 23, 11241, 244, 3, 146, 260, 18, 4, 193], [576, 25, 3, 41, 80, 1, 1011, 1109, 18, 10, 6865, 1352], [8, 144], [3742, 92, 23, 4, 101, 68, 27, 2, 19, 35, 6866], [43, 471, 4, 19, 1611, 559, 14, 2, 24], [563, 17, 790, 21, 2, 1912, 224, 159, 824], [], [11242], [422, 827, 182, 42, 72, 3743, 42, 700, 105, 110, 297, 6867], [242, 35, 6868, 104, 158, 187], [7, 727, 2326, 140, 1, 64, 168, 10, 231, 73, 2, 3316], [57, 59, 190, 1251], [97, 3, 62, 32, 4, 4109, 23, 529, 3, 6869, 2084, 11243], [20, 1245, 5242, 11244], [1, 242, 35, 8, 402, 17, 60, 16, 212, 2847, 5, 506, 4, 480, 12, 59, 6, 6870], [31, 4, 104, 63, 44, 2, 1447, 693, 75, 11245, 1001, 17, 127, 130, 76], [23, 732, 29, 134, 201, 45, 59, 4, 918, 4358, 76, 918, 108], [65, 13, 245, 166, 141, 2084, 269, 6, 17], [4, 141, 187, 63, 33, 309, 21, 32, 3, 279], [693, 29, 7, 1, 33, 512, 1227, 37, 549, 16, 32, 212, 835], [505, 9, 14, 13], [1, 43, 127, 18, 10, 1024], [3, 44, 98, 458, 453, 8, 7, 1, 1904, 12, 284], [3, 47, 417, 6, 4, 171, 1, 88, 40, 157, 50, 1359, 32, 35, 11, 10, 624, 119, 45, 120, 56, 9], [4231, 100, 33, 609, 4, 1482, 282, 40, 554, 625, 11246, 238, 19, 27, 166, 111], [7, 47, 37, 2506, 8, 3, 47, 2011, 83, 11247, 216, 17, 120], [1, 65, 13, 3611], [6871, 20, 24, 12, 257, 35], [32, 16, 39, 1, 308], [133, 6, 14, 11, 2071, 2, 535, 755], [551, 1, 168, 6, 119, 10, 30, 15, 1769], [714, 10, 24, 2265, 27, 11248, 5243], [714, 10, 2479, 24], [714, 10, 631, 2479, 24, 2265, 73, 3, 1266, 18, 174, 714], [19, 10, 2479, 24, 2265], [19, 10, 631, 24, 27, 174, 1139, 968], [243, 218, 3, 1025, 35, 120, 8, 48, 2, 158], [286, 221, 172, 549, 30, 1], [10, 24, 12, 11249, 21, 174, 253, 482], [158], [101, 2, 590, 1, 118], [37, 277, 10, 2263, 24], [3, 454, 31, 3, 44, 10, 727, 373, 11250, 1594, 253, 17, 123, 92], [417, 1340, 1, 5, 65, 13, 2, 274, 148, 11251], [23, 48, 2470, 6, 7, 1, 177, 2027], [2570, 3, 46, 124, 2, 5244, 371, 3, 47, 1913], [8, 5, 65, 13, 4359, 2, 158], [1, 18, 10, 138, 34, 65, 51, 17, 23, 19, 681], [3, 29, 290, 74, 67, 6, 290, 1, 69, 29, 62, 69, 4, 19, 3, 2975, 19, 3, 65, 13, 58, 7, 25, 333], [336, 278, 105, 191, 2, 189, 6, 498, 142, 18, 2, 6872, 57, 4, 168, 16, 28, 170, 11, 1885, 21, 2, 11252, 1], [11253, 6735, 839, 2417, 6873, 1223, 11254, 11255, 190, 668, 2094, 11256, 11257, 151, 1711, 274], [3, 454, 85, 1038, 46, 43, 207, 617, 35, 1038], [219, 236, 325, 5245, 267, 5], [1, 1048, 50, 386, 60, 81, 133, 3, 124, 6, 28, 240, 230, 36, 1597, 54], [55, 25, 33, 294, 11, 7, 9, 65, 21, 77, 29, 110, 131, 303, 295], [7, 9, 54, 92], [63, 5, 569, 68, 11258, 1355, 461, 372, 13, 2, 312, 6874], [15, 47, 2, 675, 5, 2943, 1, 14, 243, 674, 3476, 110, 3317, 20, 530, 30, 128], [5, 19, 24], [3, 46, 6, 229, 133, 384, 207, 2454, 5, 81, 59, 18, 143, 11259, 245, 2454, 5, 28, 82, 2, 207, 14, 3318], [155, 106, 3, 257, 5, 23, 3744, 2, 2826, 485, 23, 33, 14, 165, 130, 5, 128], [37, 239, 1, 5, 276, 87, 6, 396, 97, 226, 82, 11260, 6, 283], [336, 34, 3, 47, 783, 7, 11261, 2220, 83], [4296, 23, 11262, 29, 429, 4161, 18, 17, 23, 33, 2, 1, 30, 11263], [1, 30], [140, 20, 4, 11264, 16, 76, 32, 1], [5, 58, 623, 97, 24, 1116, 117], [403, 42, 33, 253, 17, 48, 358, 1712, 152, 628, 7, 11, 143, 5246, 13, 174, 1618, 1000, 42, 62, 4, 120, 1377, 1796, 305, 305], [243, 457, 285, 44, 2, 93, 68], [3625, 185, 1], [3, 64, 3581, 154, 68, 149, 3, 492, 76, 8, 88, 11265, 76, 1, 425], [3, 11266, 69, 11267, 4224, 34, 272, 133, 6, 28, 120, 11268, 179, 18, 116, 30, 38, 3, 258, 5247], [422, 42, 203, 3568, 541, 30, 1, 42, 180, 203, 108, 51, 4, 11269, 541, 30, 83, 3, 63, 1720, 10, 4254, 34, 42, 96, 203], [2895, 177, 5, 532, 13, 269, 352], [52, 124, 4, 9, 99], [5, 65, 13, 567, 95], [52, 456, 86, 5, 1571, 285, 3, 43, 3306, 151, 119, 20, 8, 70, 5, 13, 4, 26], [36, 79, 17, 190, 1006], [7, 48, 110, 2, 112, 324, 456, 44, 167, 2, 866, 8, 192, 70, 35, 45, 27, 20, 158, 30, 55], [1, 66, 565, 2, 451, 496], [76, 1, 14, 4869], [127, 13, 65, 51, 32, 212, 1], [19, 50, 117, 11, 4, 24], [60, 16, 76, 1, 134, 5, 127, 130, 2, 4121], [278, 429, 147, 3745, 21, 60, 112, 285], [278, 421, 7, 141, 1, 714], [328, 7, 1175, 536, 66, 62, 5, 1456, 203, 1132, 391, 3746, 4360, 1], [117, 11, 4, 24], [2954, 20, 2, 1221, 25], [57, 15, 4234, 3, 94, 95, 11, 2021, 128], [12, 10, 180, 358, 514, 646, 3, 5248, 3, 29, 62, 57, 278, 58, 461, 22, 11270], [5, 2, 1, 25], [11271, 7, 6875, 68, 21, 17, 280, 149, 5, 62, 7, 1, 165, 665, 4361], [38, 1, 28, 1435, 36, 14, 2226], [37, 57, 174, 854, 12, 32, 3, 780, 125, 12, 9], [6876, 743, 178, 24], [181], [380, 69, 119, 353, 340, 461, 5], [1232, 886, 41, 4, 1593, 3747, 18, 7, 1, 23, 322, 362, 374, 32, 18, 1271, 289, 194, 2, 6299], [5249, 3, 103, 5250, 7, 1, 1048, 173, 4, 11272, 1, 6, 2507, 53, 1000], [1, 3, 41, 2, 1013, 92, 236, 3, 46, 6877, 43, 127, 151, 290, 350], [1, 5, 11273, 73, 19, 6878, 82, 1514, 2619, 690, 16, 4, 848, 3319], [477, 11274, 835, 1, 45, 14, 3320, 73, 19, 720, 66, 124, 6, 58, 5109, 250, 7, 68, 213, 22, 213, 47, 4, 2242, 2028], [2820, 30, 1], [5, 2, 6877, 3748, 1281, 30, 496, 178, 137, 30, 664, 11275, 5, 4362, 43, 193, 5, 63, 1800, 6, 438, 2, 26], [1407, 11, 979, 46, 99, 93, 21, 11276, 1391, 1407, 4, 11277], [3, 64, 3749, 11278, 559, 1426, 2, 104, 8, 249, 7, 138], [3, 47, 152, 555, 10, 1200, 444, 3, 222, 28, 173, 246, 412, 34, 3, 487, 58, 15, 1046, 374, 172, 726], [11279, 2, 711, 23, 721, 20, 1499, 1167], [6879, 49, 181], [37, 5, 276, 79, 17, 2, 158, 140, 16, 7, 19, 329, 27, 5], [33, 172, 2313, 22, 104], [2896, 66, 4, 6714, 730, 54, 22, 83, 40, 62, 3321, 64, 11280], [45, 46, 276, 14, 356, 38, 5, 87, 17, 6, 28, 5, 459, 2, 6880, 347, 1780, 83], [20, 1207, 27, 1078, 8, 319, 219, 33, 81, 59, 212, 3, 6632], [286, 43, 149, 4363, 96, 294, 423, 13, 53, 221, 3, 19, 7, 25, 1, 53], [66, 198, 662, 54, 11281, 44, 2, 320, 11, 6881, 111, 936, 106, 18, 11282, 1422, 523, 523, 2029], [36, 96, 19, 248, 3, 75, 119, 212, 6, 492, 10, 1068], [11283, 248, 114, 16, 4, 1458, 3750, 11284, 8, 137, 11285, 7, 48, 57, 5251, 49, 21], [7, 198, 509, 249, 18, 10, 2500, 11286, 848, 714, 1387, 816], [11287, 1433, 1534, 293, 15, 47, 644, 6, 61, 392, 16, 2500, 8, 4147, 11288], [11289, 96, 1419, 294, 129, 8, 121, 256, 24], [3, 41, 42, 1], [3, 687, 7, 11290, 12, 1776, 1893, 2174, 2, 83, 40, 3279, 1773, 6, 1367, 50, 1334, 8, 6, 14, 1884, 11, 2, 360], [470, 4364, 16, 6882, 1390, 269, 6883, 1730, 1951, 11291, 134, 20, 237, 11292], [134, 17, 1789, 161, 1], [32, 56, 6, 17], [2294, 12, 56], [10, 172, 108, 96, 505, 34, 15, 47, 783, 254, 8, 23, 96, 214, 59, 4, 9, 11293, 3495], [42, 86, 7, 651, 136, 393, 6, 58, 27, 212, 268, 171, 1, 11, 1914, 3719, 55], [3477, 12, 2, 24, 91, 29, 70, 17, 349, 35, 4, 327], [23, 2, 900, 30, 1], [55, 814, 175, 1063, 98, 5009, 3751, 11294, 6884, 1185, 5, 422], [11295, 11296, 303, 2, 5252], [65, 13, 5, 424, 2, 355, 6885, 8, 207, 18, 20, 645], [267, 321, 29, 182, 627, 66, 96, 18, 4, 65, 54, 21, 39, 104, 11297], [372, 13, 116, 49, 60, 1082, 1, 11, 20, 11298], [12, 5, 362, 5, 46, 207], [1457, 46, 32, 147, 1758, 5, 63, 671, 143, 9, 8, 58, 143, 1144, 8, 46, 152, 70, 43, 511, 11299], [5, 1532, 6, 72, 3276], [5, 63, 156, 28, 143, 207, 617, 108, 11, 143, 3254, 125, 143, 4071], [3752, 92, 11300, 7, 48, 573], [128, 22, 399], [151, 122, 740, 152, 122, 8, 3753, 4, 324, 1063, 54, 16, 10, 11301, 3, 87, 6, 192, 165, 531], [40, 2, 117, 816, 278, 113, 5, 1061, 2623, 1061], [70, 17, 120, 56, 1081, 1534], [777, 209, 1081, 881, 120, 56, 2322, 5253, 1, 177, 138, 249, 19, 315, 1], [5, 2, 19, 2322, 37, 411], [6886, 202, 1, 896, 13, 36, 99, 93, 21, 98, 1696, 25, 13, 36, 33, 41, 3160, 1789, 8, 24], [2074, 43, 7, 101, 2, 19, 5, 1, 8, 328, 5231, 103, 293, 538, 77, 426, 3, 195, 58, 15, 771, 8, 3, 29, 67, 7], [3, 105, 121, 5, 47, 2, 9, 2899, 11302, 30, 77], [181], [5, 165, 150, 4, 6494, 3, 29, 110, 229, 39, 9, 64, 55], [128, 11303, 41, 2, 1, 135, 117, 92, 34, 52, 64, 50], [3, 67, 15, 6, 14, 11304, 16, 2, 11305, 233, 169, 11306, 6887, 2225, 233, 383, 141, 45, 6, 100, 153, 62, 66, 96, 135], [2, 153, 11307, 6, 465, 7, 45, 10, 1080], [10, 153], [5, 189, 131, 4269, 19, 60, 6888, 95, 22, 2593], [11308, 451, 477, 109, 49, 1307, 8, 2116], [180, 517, 9], [241, 5, 196, 6889, 2864, 342, 30, 26, 3, 196, 52, 198, 52, 81, 6, 84, 9, 32, 115, 744, 26, 26, 84, 77, 11309, 1428], [65, 3734, 21, 60, 56, 479, 35], [8, 19, 5, 99, 97, 141, 1, 5, 65, 13, 2, 953, 249, 2, 968, 11, 174, 2296], [11310, 41, 32, 4, 1], [42, 63, 33, 191, 170, 6, 249, 84, 138, 48, 7, 332, 120, 56], [11311], [45, 327, 2291, 9, 1367, 30, 1625, 1469, 25], [23, 5254, 11312, 11313, 2162, 4, 199, 549, 1717, 1034, 54, 1271], [6890, 33, 429, 1117, 10, 909, 37, 3, 11314, 34, 417, 122, 104], [660, 49, 2733, 11315, 71, 15, 150, 6, 90, 20, 823], [3, 29, 86, 36, 442, 11, 126, 2227, 3136, 6, 2508, 6301, 3743, 36, 1668, 6, 14, 2734, 123, 180, 11316], [57, 58, 5, 67, 181], [20, 2, 181], [58, 15, 88, 24], [151, 19, 5, 1062, 5, 64, 17, 104], [242, 35, 5, 185, 1], [51, 577, 211, 3754, 268, 11317, 16, 983, 56, 36, 157, 54, 11318, 6, 6891, 4353], [39, 25, 456, 14, 11319, 38, 4, 215, 106, 5, 566, 2, 1752, 323, 18, 4, 2099, 6257, 29, 28, 1], [3, 424, 15, 2222, 38, 3755, 11320, 23, 48, 2, 232, 408, 34, 3, 44, 2, 320, 16, 64, 8, 538, 21, 2165, 1047, 4, 4365, 445], [10, 429, 12, 82, 154, 6892, 10, 730, 12, 232, 11321, 10, 746, 599, 345, 38, 40, 566, 52, 47, 152], [221, 3756, 5255, 1527, 1], [74, 20, 11, 4, 179], [140, 15, 1943, 71, 15, 70, 660, 1125, 897, 151, 58, 15, 361, 776], [413, 9, 11322], [3, 47, 3659, 18, 76, 1825, 713, 1434, 407, 344, 1, 3, 46, 276, 70, 15, 51, 22, 877, 11323, 62, 57, 23, 854], [3, 118, 44, 64, 6, 194, 11324, 1, 491, 2241, 278, 389, 6, 94, 7], [326, 62, 7, 1, 64, 3757], [66, 87, 6, 632, 3757, 612, 37, 66, 63, 28, 32, 4, 1, 8, 63, 90, 18, 263], [560, 12, 1785, 16, 537, 120, 56, 2956, 21, 4, 696], [4851, 45, 55, 3, 67, 10, 169, 99, 83, 69, 499, 3, 134, 68, 6], [241, 5, 141, 1, 350, 5, 238, 167, 4, 1847, 205, 225, 74, 601, 22, 449, 45, 318, 14, 501, 551], [1, 165, 108, 35, 3322, 588], [43, 11325, 6893, 12, 2, 9, 8, 2, 4366], [38, 2, 1, 65, 84, 193], [8, 5, 62, 237, 59, 4, 95, 11326], [85, 118, 2, 120, 91, 110, 61, 6, 2, 158, 286, 1556, 16, 2397, 98, 289, 197, 11, 2, 975, 11327, 78, 93, 158], [243, 246, 1143, 16, 11328, 115, 5, 804, 30, 386, 16, 2, 83, 7, 85, 66, 32, 64, 5, 1168, 293, 116, 49, 4797, 11, 6894], [605, 39, 879, 1], [2976, 427, 45, 104, 61, 477, 6, 60, 112, 451], [181], [104], [5, 29, 62, 45, 59, 17, 104, 1], [1064, 144, 4367], [195, 3, 109, 2, 181, 31, 23, 13, 7, 496], [181], [104], [48, 356, 42, 104], [183, 11329, 187, 42, 415, 44, 98, 11330, 1757, 104], [174, 646, 65, 37, 494, 8, 183], [43, 4368, 9], [9, 72, 11331, 18, 6895, 233, 1785, 15, 18, 186], [1297, 357, 11332, 2, 535, 3758, 4299, 660, 11333, 134, 2, 635, 19, 59, 20, 11334], [11335, 226, 18, 186, 182, 11336, 11337, 237, 226, 18, 186], [148, 20, 1, 109, 11338, 21, 4, 1561], [7, 11339, 4, 620, 12, 11340, 146, 61, 6, 232, 1330, 38, 36, 49, 6508, 15, 12, 1786, 11341], [158, 5, 49, 1104, 130, 3, 2975, 58, 5, 110], [734, 210, 878, 43, 11342, 1], [168, 269, 5256, 5, 6896], [3, 90, 7, 385, 13, 1, 29, 191, 17, 21, 45, 1955, 17, 936, 10, 106, 8, 20, 171, 30, 46, 110, 168, 254], [3, 375, 84, 2509, 11343, 345, 8, 4369, 72, 11344, 14, 270, 2, 24, 8, 632, 2, 11345, 74, 2180, 4369, 37, 2181], [6897, 1094, 12, 388, 6898], [281, 5257, 7, 9, 47, 356], [1116, 30, 9, 281], [3504], [19, 5, 1, 55], [242, 35, 1], [249, 2, 138, 9], [20, 315, 1], [43, 1, 55], [128, 20, 18, 10, 1747, 15, 46, 2735, 9, 55], [1, 5, 257, 211, 468, 1547, 55, 8, 66, 1159, 1474, 5, 33, 2, 1543], [1, 729, 17, 55], [1, 5, 75, 110, 72, 43, 55], [128, 20, 2, 1, 177], [55, 267, 1, 4322, 2977, 46, 542, 21, 263, 55], [242, 35, 1], [7, 29, 196, 20, 48, 466, 55, 242, 35, 9, 55], [7, 196, 20, 466, 31, 20, 5258, 55, 3, 29, 64, 9, 55], [20, 2, 1, 55], [43, 323, 289, 566, 47, 93, 12, 57, 3, 196, 123, 52, 56], [333, 113, 212, 11346, 670, 7, 36, 49, 2, 666, 16, 1894, 141, 1, 8, 198, 48, 14, 1166, 1196, 6899, 6900], [374, 398, 180, 1, 205, 55], [93, 338, 5, 185, 104], [932, 55, 214, 158, 12, 214], [5, 46, 41, 43, 9, 161, 6165, 20, 2, 161, 189], [69, 200, 5, 1505, 76, 9, 13, 445, 2492], [1, 30, 11347], [3, 72, 15, 32, 4, 106, 199, 27, 181, 8, 494, 15, 32, 59, 4, 6901, 3, 614, 60, 111, 49, 33, 65, 6, 28, 1001], [4, 488, 22, 95, 30, 25, 424, 10, 310, 8, 200, 2, 480, 682, 1856, 11, 261, 251, 55], [106, 6, 79, 9], [150, 13, 15, 132, 2, 213, 371, 3, 297, 97, 494, 4370], [3637, 2007, 614, 6, 204, 17, 181], [200, 5, 72, 1999, 2011, 11348, 824, 1868, 108, 6, 11349], [29, 100, 1718, 7, 75, 110, 1175, 144, 28, 5, 2014], [3493, 3, 64, 5, 99, 4371, 20, 37, 148, 11350, 26, 48, 2030, 944, 325, 1, 456, 14, 1380], [15, 560, 2, 95, 2, 620, 8, 2, 1436, 11351, 3, 70, 43, 6902], [3, 63, 941, 2978, 3, 131, 33, 140, 3, 46, 2, 1, 163, 11, 2510, 6903], [61, 18, 6904, 1, 14, 18, 116], [10, 1640, 4, 1, 152, 692, 17, 98, 3, 266, 110, 636, 57, 582, 128], [40, 63, 249, 138, 205, 7, 165, 130, 348], [174, 830, 700, 512, 3553, 54, 20, 310, 218, 7, 45, 37, 206, 42, 534, 1127, 4, 1, 18, 135, 128], [20, 2, 1], [3, 75, 14, 1859, 11, 11352, 34, 76, 1, 165, 48, 1878, 11, 3168], [1, 3, 318, 14], [1, 5, 33, 98, 1435, 2819, 130, 17, 26, 66, 1975, 3759, 11353, 8, 11354, 49, 33, 60, 752, 1], [128, 5259, 451, 249, 221, 20, 19, 185, 31, 5, 86, 3684, 12, 2058, 144], [115, 12, 13, 207, 147, 1730, 115, 9, 13, 11355], [2979, 3, 90, 6, 11356, 34, 63, 3, 44, 80, 3632, 3, 13, 2322, 147, 131, 14, 19, 123, 207], [243, 457, 104], [49, 5, 2, 849, 2736, 74, 33, 2, 1496], [403, 2511, 604, 64, 22], [33, 13, 6905, 418, 87, 64, 3182, 3, 3604, 60, 11357, 11358, 409, 118, 14, 32, 129, 7, 1339, 1989], [8, 71, 195, 3, 1233, 45, 4125, 218, 42, 29, 62, 57, 19, 42, 81, 59, 353, 39, 2124], [718], [43, 2460, 280, 64, 97, 6, 100, 28, 60, 11359, 98, 60, 4993, 6906, 5260, 1079, 22, 1, 281], [98, 33, 29, 14, 2, 9, 59, 15, 281], [1, 5, 206, 30, 5108, 30, 1, 65, 13, 2, 11360, 30, 1109, 5261, 6907, 30, 2240, 231, 680], [20, 270, 2, 1, 11361, 20, 811, 20, 1544, 2, 11362], [5, 87, 6, 11363, 2, 497, 1515, 35, 20, 809, 1547, 2, 115, 444, 20, 1, 30, 568, 3135, 31, 4, 437, 11364, 94, 2, 11365], [12, 270, 2, 144, 2858, 79, 1399, 120, 177, 11, 563, 27, 202, 4372, 26], [3, 380, 11366, 6, 20, 5262, 12, 422, 31, 20, 2980, 1433, 932], [400, 142, 8, 411, 6908], [242, 35, 104], [34, 7, 1, 222, 279, 882, 59, 3760, 3323], [381, 2315, 401, 12, 4, 385, 3, 328, 41, 10, 215, 607, 102, 7, 83], [789, 3274, 42, 172, 6909, 3, 1138, 194, 1520, 34, 278, 96, 5263, 20, 1, 30, 11, 15, 61, 3761, 4, 355, 1111, 265, 174, 82, 2327, 181], [20, 270, 2, 24], [12, 180, 534, 2, 6905, 887, 675], [61, 119, 1538, 45, 5, 172, 2981], [29, 81, 6, 20, 9, 7, 193], [55, 6910, 1], [56, 46, 15], [13, 126, 781, 109, 132, 81, 56, 59, 11367], [5, 372, 13, 20, 24, 11368], [20, 2, 2512, 24, 1866, 43, 1237, 16, 4245, 11369, 4373, 11370, 11371, 92, 400, 20, 30, 32, 4, 193, 2014], [43, 93, 3762, 440, 6911, 22, 970, 70, 1960, 3324, 65, 13, 2, 11372, 37, 4199], [573, 34, 88, 361, 23, 10, 1242, 2, 9, 12, 217, 69, 568, 8, 376, 27, 326], [52, 857, 248, 34, 31, 1005, 11373, 74, 11374, 725, 235, 1309, 67, 4, 401, 278, 2010, 980, 27, 2, 154, 2982, 16, 1134], [24], [52, 533, 133, 66, 131, 14, 1044, 8, 23, 33, 13, 749, 1, 11375], [23, 2, 161, 25, 304, 634, 5, 94, 916, 5, 46, 4374, 23, 82, 2962, 177, 3, 46, 43, 24, 82, 4, 11376, 33, 304], [19, 43, 104], [11377, 359, 81, 56, 69, 58, 7, 1782, 3763, 8, 427, 579, 11, 4, 848, 16, 359, 1222], [3, 210, 109, 44, 68, 47, 3764, 16, 232, 34, 156, 64, 6912, 2134], [6897, 11378, 3, 41, 10, 293, 35, 38, 2, 535, 16, 4, 1129, 189, 6913, 7, 11379, 11380, 124, 170, 11381], [5, 452, 215, 2, 115, 116, 282], [40, 868, 24, 1556, 11382, 40, 1552, 4, 244, 518], [148, 424, 22, 171, 1282, 3754, 201, 115, 6, 2182, 6799, 109, 93, 205, 918], [242, 80, 918, 30, 35, 1282, 8, 907, 20, 104, 30, 108, 1117, 4, 1909, 141, 25, 61, 477, 6, 60, 4791], [15, 156, 65, 37, 417, 3, 47, 152, 303, 22, 190, 68], [242, 35, 24], [104], [3, 62, 133, 80, 963, 30, 2328, 158], [336, 20, 2, 158], [2737, 12, 21, 11383, 519, 223, 45, 74, 28, 102, 4, 11384], [46, 43, 64, 445, 39, 9], [45, 52, 700, 12, 166, 130, 7, 326, 499, 56], [1739, 408, 49, 187, 139, 4, 1160], [49, 66, 96, 81, 59, 978, 3, 62, 60, 668, 617, 7, 118, 64, 6, 94, 71, 5, 2513, 20, 24, 230, 119, 254], [23, 48, 2, 83, 114, 15, 895], [3, 966, 86, 4, 256, 38, 1, 107, 1117, 588, 72, 66, 49, 6739, 1158, 43], [1, 2721, 1503], [4801, 141, 11385, 693, 277, 22, 206, 2738, 823, 1, 13, 5, 37, 209, 3, 29, 1507, 34, 3, 58], [572, 74, 3765, 4, 187], [4308, 118, 79, 17, 56, 4375, 2415], [28, 2, 63, 16, 2418, 11386, 15, 512, 54, 787, 995, 8, 3726, 130, 1538, 11387, 74, 6914, 197, 33, 73, 93], [74, 2, 2738, 1, 13, 17, 69, 103, 665, 2, 395, 548, 54, 16, 126, 108, 11388, 565], [267, 274, 23, 33, 98, 53, 206, 388, 368, 82, 6915, 5264, 8, 48, 2, 1977], [19, 42, 158], [383, 11389, 9, 18, 2, 413, 511, 822], [3, 67, 11390, 37, 148, 515, 16, 14, 11, 4, 19, 2635, 2, 1, 12, 341, 8, 87, 2, 1178, 16, 2289, 8, 2, 108, 1849], [1, 597, 35], [3680, 151, 741, 27, 10, 5265, 15, 103, 96, 3634, 212, 628], [48, 2329, 235, 9, 464], [31, 52, 67, 1, 1011, 11391, 18, 84, 6380, 1352, 52, 103], [46, 357, 191, 80, 104, 30, 21, 2, 1088, 3, 62, 5, 1702, 330, 5, 315, 7, 57, 42, 58, 21, 2, 259], [1115, 1850, 9], [18, 1881, 30, 9], [180, 815, 1, 128, 19, 15, 93, 460], [162, 4, 19, 220, 5, 22, 850, 1], [680, 9], [1138, 168, 10, 45, 641, 17, 9], [664, 333], [367, 42, 9], [1522, 15, 6916, 2071, 7, 2330], [29, 443, 17, 5, 104], [66, 87, 127, 1242, 283], [242, 4, 19, 35, 104, 30, 4376, 968, 2952, 20, 1242, 12, 1555, 181], [660, 49, 2420, 6917], [467, 423, 22, 11392, 5, 41, 60, 154, 9, 21, 263], [322, 362, 5, 1456, 1861, 8, 48, 11393, 171, 30, 5266], [3, 210, 62, 5, 47, 253, 17, 9], [241, 34, 212, 215, 607, 7, 11394, 159, 11395, 11396], [1086, 427, 186, 490, 55], [955, 18, 256, 9], [128, 187], [19, 102, 10, 24, 1587, 1], [17, 1, 23, 238, 176, 2, 656, 1345, 1665, 4, 19, 321], [66, 29, 64, 39, 9], [12, 98, 1893, 90, 1430, 529, 69, 86, 11397, 11398, 655, 254], [552, 12, 40, 428, 82, 116, 55, 66, 253, 2, 11399, 34, 66, 704, 2, 607, 11400, 22, 1, 124, 13, 445, 1022, 3, 300, 55], [23, 675, 54, 1, 5, 185], [11401, 227, 35, 97, 11402, 97, 797, 91], [364, 1, 5, 124, 1209, 3766, 8, 46, 113, 17], [70, 7, 6402, 20, 1], [83], [100, 28, 2, 1143, 612, 26, 58, 256, 664, 23, 337], [183, 158], [15, 356, 71, 22, 1447, 1083, 10, 175, 59, 4, 1067, 11403, 11404, 426, 3, 195, 2, 19, 2983, 5, 1496], [267, 11405, 3, 538, 350, 48, 5, 6918, 20, 2, 83], [3, 192, 528, 11406, 11407, 2739, 3, 86, 15, 356, 7, 5, 11408, 4357, 310, 11, 56, 129, 11409, 1411], [1, 25], [3588, 9, 1801, 35, 322], [55, 113, 7, 9, 632, 35, 3203], [19, 1], [3, 62, 312], [80, 1, 3, 346, 5, 776], [128, 11410, 3, 29, 13, 240, 1485, 2027], [29, 28, 15, 1717, 121, 46, 868, 2060, 654, 16, 453, 38, 1, 12, 224, 11411, 11412], [3, 2062, 383, 273, 5267, 68, 264, 403, 3, 41, 2, 1861, 11, 4, 11413, 125, 15, 74, 336, 288, 3214, 10, 3564, 1], [55, 22, 12, 85, 42, 10, 312], [52, 383, 87, 6, 61, 6, 2484, 28, 1399, 2, 89, 3564, 1, 8, 383, 1769], [31, 80, 77, 100, 76, 11, 40, 2, 11414, 1642, 6, 4, 360, 85, 42, 1354, 50], [85, 12, 52, 3247, 1399, 22, 312, 63, 14, 2478, 6919, 6920, 230, 52, 363, 6, 3259], [20, 1073, 10, 312], [1, 20, 6921], [146, 64, 15, 38, 4, 11415, 5268, 122, 6, 70, 2, 11416, 59, 1247, 1413, 1433, 11417], [23, 18, 7, 9, 92], [805, 286, 576, 25, 5, 456, 47, 137, 261, 16, 1380, 8, 1224], [3, 150, 4, 199, 193, 59, 4, 4377, 8, 2331, 16, 168, 4, 324, 11418], [242, 35, 1, 15, 3133, 983, 5269, 169, 11419, 163, 15], [190, 758, 1100, 2281, 6, 143, 234], [1738, 27, 4, 1374, 759, 8, 11420, 2132, 11421, 8, 4, 354, 11422], [333, 3317, 10, 1838, 5, 1455, 386, 16, 2, 1], [58, 42, 96, 44, 174, 5235, 2332], [94, 1, 22, 12, 85, 5, 44, 43, 228], [65, 135, 1, 31, 3, 67, 6, 14, 11423, 1675, 3, 118, 44], [23, 81, 59, 4, 11424, 16, 4, 24, 534, 5, 6922, 11425], [170, 73, 219, 36, 13, 126, 860, 11426, 4, 2606, 11427], [52, 92, 4378, 18, 4, 6923, 11428], [11429, 48, 4, 11430], [91, 620, 8, 4, 232, 44, 41, 612, 6, 2300, 4, 11431, 11432, 11433, 2589, 137, 11, 11434], [11435, 778, 17, 159, 16, 84, 11436, 129, 11437, 3, 11438, 20, 11439], [48, 114, 5270, 2068, 8, 52, 672, 4, 190, 11440], [7, 816, 5271, 11441, 118, 598, 6, 14, 32, 59, 116, 47, 43, 3762, 21, 412, 6, 958, 4, 11442], [4, 2606, 3669, 49, 2971, 173, 5272, 5273], [232, 257, 88, 11, 4, 11443, 2025, 4, 166, 921], [232, 137, 390, 11, 4, 11444, 178, 16, 4, 1254, 1957, 641, 4, 11445], [5, 11446, 168, 6, 14, 356, 1934, 6924], [3309, 766, 5, 49, 1594, 74, 1282, 3, 96, 29, 13, 5, 26, 93, 115], [757, 46, 45, 34, 9, 27, 11447], [58, 15, 3, 19, 1038, 5, 104], [5, 75, 79, 217, 2, 181, 31, 20, 6925, 35, 27, 189], [37, 31, 20, 1584, 8, 11, 314, 261, 5, 29, 44, 20, 373, 331, 5, 19, 104], [104], [1320, 11448, 368, 6926, 345, 52, 79, 17, 185], [2984, 1826, 23, 32, 1715, 149, 3, 259, 11, 2, 144, 620, 86, 52, 3767, 111, 13, 5, 198, 14, 3577, 10, 1979, 291, 6927], [3768, 6, 3769, 6928, 1], [65, 135, 23, 2, 640, 30, 4379, 30, 1, 30, 1584, 213, 206, 11449, 26, 3, 383, 67, 6, 62, 31, 3, 63, 28, 2, 253, 108, 333], [38, 394, 92, 3, 70, 362, 7, 1, 12, 48, 4081, 7, 378, 184, 2985, 8, 4266, 63, 1279, 18, 40, 2728, 240, 398], [3, 13, 170, 34, 3, 109, 1592, 52, 110, 137, 66, 330, 41, 2, 320, 11, 4, 180, 91, 4380, 1694, 6, 2894, 95, 5011, 26, 4225], [1056, 4, 2897, 8, 4, 6929, 1], [422, 3, 33, 67, 6, 62, 1, 51, 11450, 31, 20, 48, 135, 23, 54], [140, 2859, 144], [55, 25, 76, 65, 13, 2, 3532, 16, 56, 11, 20, 331, 26, 56, 51, 4, 1476], [18, 274, 5274, 14, 238, 72, 1457, 132, 54, 1363, 8, 45, 13, 43, 1, 1206, 132, 54, 135], [4, 89, 1, 27, 76, 183, 30, 1783], [55, 23, 48, 5, 33, 75, 14, 611, 59, 184, 5, 75, 11451, 34, 38, 5, 294, 7, 1706, 10, 2308, 151, 14, 243, 513], [695, 3, 86, 3, 67, 22, 1, 97, 17, 11452, 11453, 34, 267, 304, 555, 35, 188, 69, 42, 290], [42, 185, 1156, 235, 1], [8, 4, 2633, 3766, 16, 2, 2986], [559, 14, 2, 260, 3325, 167, 7, 11454, 24], [37, 40, 144], [3, 86, 3, 200, 10, 401, 135, 6930, 6, 5, 1], [569, 16, 141, 1, 5, 210, 110, 58, 32, 20, 11455, 5, 141, 1, 1874, 81, 6, 6931, 416, 499, 11456], [11457, 55, 11458, 6440, 281, 2, 4825, 236, 11459, 11460, 11461, 236, 6932, 11462, 11463, 11464], [31, 3, 63, 28, 22, 1, 6, 61, 11465], [1, 5, 62, 4, 3623, 9, 55], [55, 4381, 35, 24], [7, 9, 1970], [66, 146, 258, 22, 9], [323, 3770], [1587, 139, 46, 43, 9, 11, 4, 11466, 11467, 44, 132, 519, 7, 85, 357, 724, 162, 305, 689, 11468, 43, 9], [3, 41, 2, 391, 125, 2, 1388, 73, 11469, 11470, 8, 40, 383, 2010, 246, 11471, 325, 11472], [12, 270, 2, 9, 26, 255, 20, 845, 97, 180, 1, 6933, 346, 4, 2022, 565, 1410, 3771, 3772, 5, 54, 11473], [523, 42, 2, 104], [7, 45, 1485, 55], [5275, 11474, 6934, 3326, 11475, 11476, 11477, 6935, 8, 2, 2107, 27, 6936], [5276, 31, 2, 11478, 1, 146, 643, 768, 40, 63, 2004, 28, 45, 784], [24], [139, 14, 2, 285], [136, 136, 65, 57, 22, 181, 121, 55], [42, 11479, 494, 45, 73, 11480, 73, 42, 157, 43, 2460, 55], [1962, 1522, 15, 132, 2, 11481, 607, 5228, 4305, 236], [61, 232], [11482, 267, 5, 181, 177], [1314, 37, 175, 60, 166, 45, 19, 32, 7, 29, 14, 13, 326, 22, 46, 269, 94, 269, 58, 11483], [1435, 7, 1, 54, 8, 3546, 15, 125, 10, 1200, 13, 2, 148, 11484], [29, 389, 384, 1, 8, 36, 537, 30, 2677, 43, 453, 280], [66, 146, 28, 13, 787, 235, 6, 2631, 416, 316, 1308, 60, 316, 522, 1, 8, 2267, 16, 5277], [2426, 1647, 522, 190, 1054, 27, 11485, 1018, 4092, 1377, 522, 6, 309, 21, 6937, 2215], [3, 47, 223, 469, 381, 920, 2, 490, 35, 4, 3773, 3327, 40, 479, 15, 102, 27, 68, 11486, 96, 124, 5278], [12, 44, 2, 457, 37, 70, 362, 5, 113, 7, 1, 14, 3567, 26, 1120, 461, 692], [85, 220, 116, 4080, 8, 2, 95, 11, 4, 4382, 1743], [55, 2629, 33, 299, 278, 100, 5, 1507, 10, 586, 47, 61, 889, 3774, 673, 385], [3637, 3, 11487, 8, 29, 1, 17, 97, 1], [3, 3775, 6, 14, 1802, 1072, 8, 547, 959, 15, 54], [11488, 81, 13, 52, 558, 1], [3, 44, 105, 297, 270, 609, 3758, 864, 16, 45, 11, 10, 1068, 316, 11, 6938, 2698, 26, 5279, 22, 248], [219, 2168, 12, 11489, 1343], [72, 4, 5280, 2157], [6939, 158], [281, 1417, 219, 5, 146, 28, 135, 8, 94, 22, 1, 281, 604, 626, 4, 45, 459, 170, 3, 330, 44], [281, 43, 34, 3, 47, 542, 6, 491, 7, 1, 361, 52, 510, 2900, 11, 10, 712, 6, 72, 84, 288, 3, 47, 868, 2602, 11, 10, 11490, 2129], [1], [19, 5, 1], [32, 1, 32, 115, 32, 4, 106], [19, 1818, 2264], [26, 10, 30, 33, 266, 14, 18, 7, 9], [26, 37, 5, 59, 6, 1405, 6, 159], [584, 2, 537, 30, 25, 27, 2, 656, 1270, 19, 2, 1, 11, 50, 30, 88, 40, 249, 10, 4902, 526, 161, 340, 66, 652, 4374], [50, 231, 183, 6, 17, 26, 50, 677, 220, 248], [22, 9], [10, 1791, 15, 372, 13, 15, 810, 153], [57, 5, 72, 1], [1240, 15, 83, 94, 57, 3, 200, 116], [176, 76, 224, 37, 154, 1, 62, 36, 222, 14, 4, 244, 500, 31, 36, 29, 271, 11, 2658], [220, 81, 59, 19, 5, 117, 11, 4, 24], [3161, 537, 24], [58, 15, 24], [43, 414, 655, 6, 14, 508, 3776, 13, 760, 52, 12, 2, 1, 8, 37, 12, 416, 194, 58, 11491], [2917, 16, 4, 115, 574, 69, 49, 110, 4160, 130, 52, 1437, 4, 1384, 95, 16, 2, 1508, 409, 16, 11492], [305, 11493, 66, 168, 21, 6940, 11494, 47, 98, 1772, 348, 446, 6, 71, 219, 1484, 36, 1563, 247, 2420, 4383], [159, 115], [5, 549, 1, 210, 110, 1713, 17], [242, 35, 1], [145, 14, 13, 23, 11495, 10, 6941, 11, 201, 2718, 1032, 54, 11496, 4384, 13, 2, 1], [37, 20, 2, 171, 1], [174, 37, 2867, 411, 21, 469, 42, 1], [339, 66, 46, 41, 712, 21, 339, 283], [4385, 40, 41, 76, 1, 197, 18], [1, 3, 62, 5, 297, 17, 175, 133, 5], [1, 11497], [1, 69, 12, 5], [1417, 336, 1, 5, 67, 137, 18, 1610], [26, 5, 41, 2031, 9], [1, 5, 210, 1090, 307, 5, 191, 10, 6, 303, 5, 2, 2183], [1, 357, 67, 5], [1, 7, 85, 23, 1967, 61, 6, 3328], [1, 5, 48, 107], [92, 66, 44, 2, 11498, 1548, 11, 6942, 31, 66, 204, 32, 4, 158, 66, 318, 14, 6943], [3, 509, 7, 11, 84, 768, 13, 2, 9], [3197, 398, 74, 470, 1871, 500, 51, 4, 6944, 1035], [417, 285], [552, 5, 173, 11499, 1282, 18, 3329, 27, 688, 265, 8, 292, 260, 803], [20, 2, 180, 11500, 6, 14, 44, 935, 11, 20, 6945, 10, 11501, 55, 405, 15, 54], [281, 5281, 1, 92, 139, 137, 178, 9], [8, 4, 232, 502, 5, 2, 2379, 513, 243, 457], [160, 23, 5282, 3616, 545, 350, 289, 156, 67, 6, 2457, 625, 93, 776, 66, 5282, 48, 1060, 602, 6, 14, 11, 4, 2120, 11502], [3, 29, 3777, 7, 193, 3206, 267, 21, 4, 1761, 15, 11503], [61, 108, 6, 11504, 104], [590, 120, 56], [60, 120, 1, 18, 1126, 55], [28, 2, 112, 343, 311, 711, 3, 1759, 10, 823, 11, 4, 5283, 21, 885, 2654, 57, 44, 42, 2433], [174, 2, 19, 470, 1871, 6946, 139, 11505], [78, 137, 29, 107, 171, 9], [289, 101, 13, 59, 292, 11506, 6947, 56, 233], [11507, 23, 2455, 176, 97, 2740, 11508], [517, 1466, 234, 73, 286], [268, 95, 27, 68, 1771, 11509], [24], [403, 4, 184, 12, 2, 5284, 1682, 3760, 793, 2514, 43, 11510, 127, 18, 3760, 130, 112, 5285, 1183], [36, 133, 6, 122, 8, 9, 5, 244], [57, 49, 5, 58, 35, 117, 92, 11511, 4283, 10, 1, 6, 4159, 21, 14, 99, 3778, 361], [540, 21, 85, 52, 101, 742, 59, 2741, 53, 57, 195, 3, 614, 6, 81, 11512, 251, 71, 133, 5, 70, 451, 7, 46, 1864], [20, 2, 490], [23, 1302, 4, 2987, 1640, 11513, 16, 283, 2032], [78, 398, 56], [3, 67, 60, 949, 18, 4, 470, 1358, 2988], [5, 438, 207, 435], [135, 10, 1242, 18, 4, 11514, 40, 2, 838], [219, 452, 2679, 5, 7, 209, 34, 3, 29, 94, 5, 61, 6293, 1127, 27, 2, 666, 16, 613, 388, 2164], [5, 9, 46, 334], [25, 6762, 21, 4, 1, 13, 66, 745, 32, 297, 50, 677, 6948, 57, 277, 52, 67, 364], [24, 792], [40, 1042, 2569, 5, 11515, 100, 50, 14], [25, 3779, 11516, 461, 2, 1097, 35, 8, 5, 2742, 13, 2, 1], [741, 6, 4, 1605, 9], [1, 253, 17], [3, 293, 37, 4, 1, 47, 589, 3, 86, 40, 299, 40, 47, 1220, 74, 256], [55, 7, 47, 2, 6949, 1, 491, 21, 362], [4997, 162, 5, 61, 180, 476, 1, 624, 955, 18, 7, 968, 3, 273, 5, 6, 258], [29, 56, 11517, 11518, 452, 215, 546, 691, 224, 135, 61, 108, 6, 194, 6950], [11519, 3, 33, 955, 18, 98, 354, 851, 23, 1244, 22, 600, 44, 256, 6, 58, 27, 15], [1871, 2, 1129, 16, 24, 92, 71, 4, 286, 12, 2, 91, 2, 11520, 52, 2, 24, 23, 2515, 66, 44, 24, 26, 3330], [221, 3, 297, 5, 175, 59, 1, 26, 6951, 3, 168, 11521, 1023], [11522, 122, 48, 6, 253, 76, 11523, 65, 283, 1165, 54, 43, 193, 3, 168, 10, 2646, 18, 10, 618, 48, 10, 235], [55, 15, 98, 11524, 21, 7, 9, 129, 1271], [15, 726, 609, 4, 3103, 1448, 5286, 8, 293, 15, 568, 423, 5287], [37, 326, 2493, 3, 11525, 45, 188, 432, 2146, 509, 45, 100, 585, 1, 79, 17, 171, 272, 108, 765, 30, 35], [221, 17, 776, 10, 111, 4, 287, 4280, 51, 4, 644, 1880, 11526, 36, 64, 4, 112, 25, 74, 2989], [34, 1, 357, 47, 67, 20, 809, 42, 1233, 7, 218, 42, 100, 381, 298, 35, 11, 80, 5288, 26, 42, 86, 3, 67, 60, 16, 11527], [36, 44, 1223, 48, 32, 49, 4386, 6952, 12, 11528, 11529, 8, 5289, 144], [34, 725, 52, 41, 2, 24, 92, 678, 70, 170, 2, 876, 8, 40, 1758, 6830], [3780, 11530, 4387, 25, 146, 4037, 23, 45, 18, 5, 319], [411, 399, 289, 132, 509, 4, 11531, 21, 4, 6953, 8, 5, 62, 7], [950, 950, 4388, 136, 11532, 11533, 201, 1, 59, 43, 378, 118, 110, 62, 52, 47, 224, 2, 6954], [147, 1, 2, 5290], [2, 874, 392, 16, 190, 11534], [3, 146, 176, 10, 2731, 18, 11535], [403, 11536, 23, 114, 54, 4, 202, 179, 248, 20, 572, 158], [3, 299, 5, 47, 2462, 133, 4, 261, 3251, 3, 47, 276, 72, 32, 5, 124, 6, 58, 47, 191, 2, 1], [91, 78, 25, 497, 91, 23, 314, 483, 205, 26, 78, 25, 46, 110, 113, 17, 69, 4, 9, 12], [57, 200, 3, 1392, 21, 5, 7, 20, 6955, 609, 1143, 6956, 1086, 11537, 8, 849, 2736], [190, 1006, 14, 241, 37, 1016, 125, 143, 226, 1275, 340], [2408, 1], [5, 363, 11538, 18, 22, 9, 280], [526, 10, 306, 200, 15, 18, 1503, 469, 31, 3, 4935, 132, 4, 5291, 7, 213, 3, 1560, 935, 50, 977], [5, 8, 198, 226, 2, 1143, 79, 2990, 160, 1897, 206, 1], [242, 4, 19, 35, 5, 345, 260, 32, 5, 58, 12, 1, 8, 1545, 59, 164, 45, 726], [1158, 241, 15, 3314, 57, 5, 152, 2892, 8, 345, 59, 225, 711], [181], [3, 33, 67, 348, 91], [151, 1695, 5, 68, 347, 6593, 21, 2122], [365, 145, 36, 365], [45, 525, 169, 172, 9, 2743, 71, 147, 61, 2516], [317, 436, 39, 1], [34, 944, 15, 4, 101, 540, 3, 168, 2, 6957, 6958, 1604, 11539, 560, 212, 789, 858, 5292], [52, 598, 13, 2, 669, 104, 37, 415, 447], [3, 603, 44, 602, 3503, 6, 303, 60, 1216, 82, 4, 2016, 83, 57, 198, 3, 303, 82, 4, 3331, 189], [1889, 918, 26, 3332, 192, 842, 170, 26, 7, 11540, 104, 224], [2972, 30, 391], [55, 3, 330, 216, 254, 23, 304, 18, 10, 348, 6, 1056], [25, 367, 5, 58, 114, 17, 18, 2, 498, 11, 7, 1, 11541], [351, 360, 1], [2423, 49, 21, 181], [5, 29, 67, 6, 2333, 5, 5293, 149, 46, 43, 270, 184, 73, 470, 193, 2966, 6959], [20, 96, 2, 351, 360, 1, 29, 655, 20, 11542, 1890, 1803], [221, 3, 13, 76, 99, 34, 23, 48, 589, 30, 1, 59, 254, 608, 76, 34, 29, 1], [23, 152, 113, 10, 228, 48, 6, 303, 20, 11543, 92, 171, 1346, 11544, 24], [168, 3333, 2334, 104], [22, 45, 370, 130, 2, 9], [15, 614, 6, 14, 4389, 27, 11545, 759, 6960, 8, 4, 508, 49, 127, 190, 130, 3334, 37, 433], [3, 29, 249, 205, 20, 33, 214, 140, 20, 56, 8, 3, 1281, 350, 5, 156, 124, 984, 446], [4, 4910, 424, 76, 9], [3236, 299, 66, 220, 81, 5294, 370, 3335, 20, 48, 56, 51, 4390], [15, 41, 93, 11546, 21, 5170, 1915, 2, 1], [20, 72, 1172, 49, 4391], [417, 285], [23, 48, 122, 6, 14, 2991, 34, 5295, 599, 65, 13, 52, 33, 672, 2, 1616, 348, 41, 102, 2, 2022, 8, 157, 18, 84, 4392], [346, 5, 97, 1534, 471, 17, 2, 4025, 155, 92, 8, 361, 13, 97, 168, 6, 32, 151, 58, 4, 199, 97, 816, 1145], [2140, 881, 10, 1, 28, 97, 45, 762], [811, 73, 1, 6961, 2263, 1137], [3, 293, 5, 28, 165, 738, 587, 49, 21, 4, 95], [42, 46, 133, 15, 1466], [139, 79, 50, 2, 1, 11547, 2114], [367, 83], [57, 698, 16, 9, 49, 5, 472, 35, 73], [1073, 108, 6962, 461, 20, 1697, 2910, 10, 909, 47, 56, 483], [11548, 5, 41, 4, 9], [14, 10, 11549, 3, 67, 6, 14, 2, 95, 3, 86], [13, 4, 2992, 106, 38, 42, 242, 143, 19, 35, 82, 525, 11, 166, 617, 5296, 13, 2, 161, 1], [66, 572, 263, 88, 8, 94, 57, 3781, 5, 86, 66, 18, 97, 314, 190, 30, 615, 33, 194], [6963, 47, 2, 104, 3126], [411, 9], [1, 19, 5, 28, 54, 10, 844, 11550], [118, 14, 5297, 31, 770, 8, 48, 24, 11551], [3, 872, 250, 8, 88, 5, 5035, 26, 37, 16, 1134, 272, 11552, 895, 75, 1, 54, 55], [267, 5, 21, 1392, 10, 1, 30, 329, 1146], [97, 473, 178, 49, 5, 2, 144], [805, 2335, 3336, 2744, 23, 33, 2, 2993], [195, 48, 142, 27, 315, 45, 42, 165, 191, 10, 1], [1, 5, 63, 28, 1836], [316, 80, 1, 30, 11553, 240, 756, 11, 67, 6, 8, 28, 80, 30, 257, 35], [9, 23, 51, 197, 1062, 13, 885], [139, 65, 1202, 181], [1, 3, 273, 5, 6, 167, 17, 38, 5, 41, 108], [218, 1, 64, 3782], [5, 2, 181, 340], [139, 14, 2822, 1], [11554, 3337, 2232, 3739, 1057, 3283, 827, 3727, 11555, 2232, 11556, 2232, 965, 3337, 12, 965, 1172, 16, 2445, 6952], [136, 4, 2745, 25, 113, 9, 201, 236, 131, 14, 11557], [253, 17, 1, 55, 42, 99, 93, 6, 253, 108, 136, 136], [75, 4, 232, 70, 60, 215, 449, 420], [393, 6, 56, 22, 202, 970], [33, 41, 84, 24, 543, 52, 54, 328, 404, 3783, 1940, 11558], [11, 239, 1890, 136, 7, 65, 34, 87, 6, 94, 1324, 11559, 15, 230, 1324, 49, 2, 11560, 6, 58, 57, 5, 29, 772], [47, 13, 124, 60, 1069, 149, 3, 167, 7, 1, 68, 106, 8, 450, 35, 533, 45, 32, 264, 1, 47, 860], [3, 195, 524, 288, 5, 49, 202, 8, 609, 20, 185, 70, 17, 549, 1413, 1021, 65, 2157], [7, 85, 4, 9, 64, 11561, 63, 1342, 6, 14, 1045, 26, 2214, 55], [15, 725, 443, 19, 1873, 3, 745, 297, 15, 34, 1105, 123, 116, 14, 2, 141, 77, 11, 15, 15, 415, 56], [5, 238, 72, 23, 2, 24, 16, 1134, 23, 238, 11562, 3, 46, 43, 24, 11563], [176, 97, 1552, 18, 9], [5, 196, 4, 68, 3, 207, 27, 4393, 427, 11564], [160, 5, 62, 57, 5, 200, 5, 711, 116, 49, 599, 1721, 16, 111, 7, 44, 5, 18, 126, 11565, 2460], [84, 58, 48, 444, 5298, 34, 5299, 22, 196, 7, 245, 1152, 265, 103, 857, 1752, 21, 4, 6964], [11566, 164, 104], [336, 15, 426, 23, 2, 89, 1], [24], [24, 45], [135, 15, 2, 5300, 252, 49, 5, 19, 4082], [5301, 9], [20, 2, 537, 187, 2832, 55], [31, 15, 220, 637, 130, 66, 222, 1, 34, 7, 47, 61, 18, 546, 6, 4188, 18, 11567, 188, 117, 6965, 11568], [447, 15, 65, 11569], [249, 10, 138, 5, 187], [93, 1], [20, 2, 187], [4, 2994, 12, 11570, 18, 4, 166, 234, 16, 4, 6966, 16, 1134, 15, 560, 2, 6967, 3784, 1194], [1320, 232, 16, 11571, 47, 4, 2123, 820, 16, 20, 3150, 5302, 5303, 32, 16, 11572], [540, 3, 210, 748, 2, 758, 11573, 103, 62, 162, 3, 259, 8, 52, 118, 415, 258, 17, 8, 2836, 307], [196, 56, 55], [5304, 113, 7, 1, 11, 20, 830, 40, 87, 1720, 2, 1165, 21, 147, 1165, 30], [242, 20, 645, 9], [11574, 33, 67, 6, 94, 2, 165, 327, 16, 4, 508], [1, 19, 5, 5, 311, 102, 444, 3, 28, 10, 1795, 82, 203, 177], [1, 139, 2995, 17], [5, 204, 7, 9], [1, 23, 156, 54], [148, 1955, 1, 1176, 11, 2127, 26, 11575, 700, 214, 426, 31, 50, 327, 47, 448, 15, 452, 14, 1041, 73, 2, 675], [10, 172, 306, 12, 2, 83, 13, 40, 46, 110, 5305, 21, 254, 6406, 12, 8, 52, 121, 15, 4394], [42, 109, 41, 39, 490, 54, 135, 651], [71, 12, 15, 19, 35, 5, 19, 144, 6968, 1410, 1173, 478, 608, 890, 524, 69, 2, 287, 11576, 7, 2326], [1886, 32, 4, 24, 327], [45, 20, 30, 8, 11577, 20, 306, 24, 42, 1422, 6969, 174, 106, 3305, 11578, 4395], [3, 299, 3, 47, 4, 179, 324, 21, 1059], [6970, 1], [241, 1, 5, 11579, 750], [1, 65, 1859, 8, 42, 72, 4396, 48, 441, 174, 2, 19, 5306, 6, 732, 34, 602, 16, 4, 1450, 45, 57, 35, 1156, 177], [281, 104], [141, 1], [101, 31, 20, 2, 816, 73, 2411, 14, 48, 2, 816, 10, 2896], [325, 1, 41, 11580], [24], [15, 4, 11581, 66, 29, 64, 39, 9], [35, 20, 30, 5, 141, 11582], [69, 12, 22, 11583, 3, 29, 64, 9], [267, 5, 361, 5164], [1240, 2, 3683, 171, 1], [1], [42, 65, 13, 7, 203, 265, 18, 159, 6971, 4, 7, 41, 861, 15, 4, 1018, 11584], [1319, 85, 4, 19, 523, 42, 11, 22, 1514, 27, 80, 1509, 30], [1, 3, 29, 67, 80, 203, 30, 253, 17, 9], [1, 195, 171, 1, 195, 3785, 130, 80, 203, 1892, 4397, 65, 30], [1, 38, 523, 42, 61, 6, 28, 174, 657, 3, 33, 19, 121, 22, 33, 1392, 10, 446], [1, 13, 42, 14, 1392, 10, 446, 42, 569, 18, 45, 42, 62, 295, 59, 3, 41, 2, 19, 51, 2851, 629, 3127, 33, 411], [92, 19, 7, 411, 45, 71, 2, 133, 42, 139, 14, 2, 141, 1, 8, 28, 15, 657, 218, 42, 2438, 938, 42, 19, 6972], [42, 79, 17, 2, 24, 34, 42, 48, 133, 45, 19, 32, 22, 81, 100, 429, 45, 102, 88], [583, 20, 19, 564, 66, 32, 528, 51, 5307, 403, 203, 30, 42, 67, 1347, 8, 57, 42, 121, 216, 43, 1237, 61, 119, 74, 256], [128, 23, 1426, 2881, 19, 32, 76, 1, 13, 7], [44, 50, 683, 4, 250, 954, 710, 16, 4398, 8, 4, 863, 15, 11585, 4399, 7, 4400, 118, 14, 431, 21, 2, 95, 6, 58, 55], [109, 113, 17, 6, 79, 170, 11586, 4206, 576, 5, 4, 145, 26, 7, 7], [3, 29, 1181, 7, 25, 52, 24], [219, 3, 21, 148, 362, 46, 157, 18, 43, 24, 30, 2578, 1586], [32, 3, 566, 47, 23, 2, 1, 25], [20, 270, 2, 1], [118, 14, 697, 11587, 2155, 353, 2304, 5065, 74, 2, 5308, 11588, 6973], [10, 310, 47, 544, 181, 91], [241, 17, 99, 1964, 6974, 33, 216, 10, 1209, 858, 8, 464, 6975, 11589, 21, 2, 11590], [243, 457, 3, 293, 4, 1, 41, 5, 256, 93], [913, 4, 203, 207, 77, 778, 17, 142, 115, 606, 288, 40, 6976, 143, 1879, 125, 68, 11591, 3, 67, 10, 389], [37, 12, 10, 24], [881, 10, 2479, 24], [32, 7, 56, 81, 8, 66, 404, 6977, 20, 723, 17, 252], [281, 1121, 3, 118, 61, 21, 4, 725, 1272, 212, 181, 207, 49, 3338, 21], [242, 35, 2993], [136, 3773, 6, 2, 89, 83, 40, 63, 28, 4, 717], [3, 67, 6, 249, 20, 24], [491, 2, 1], [7, 57, 582, 38, 5, 44, 24, 21, 970, 8, 979, 5, 44, 6, 290, 4, 199, 1317, 129, 8, 129, 1404], [267, 21, 4, 253, 189, 23, 934, 2, 587, 190, 2723, 117, 615], [3, 29, 253, 5, 140, 474, 59, 20, 2494, 12, 120, 248], [5, 109, 598, 6, 64, 11592, 11593, 174, 2, 2504, 30, 353], [139, 1977, 17, 42, 2504, 30, 353], [4997, 3237, 1433], [183, 1, 3702], [20, 453, 12, 351, 8, 20, 4401, 3183, 103, 2336, 6, 42, 11, 84, 6978, 4, 184, 7, 382, 4077, 271, 870, 11, 11594], [1687, 1038, 11595, 3, 229, 721, 147, 42, 253, 307, 42, 11596, 3786, 341, 11, 384, 11597, 5, 2883, 340, 125, 207, 435], [40, 14, 57, 66, 72, 11, 143, 689, 120, 56], [78, 1430, 41, 6, 389, 972, 143, 2513], [10, 11598, 11599, 1106, 6979, 11, 147, 1], [15, 249, 4151, 746, 12, 270, 2, 6980, 1, 163, 11600, 12, 37, 11601, 397, 4308, 37, 11602], [2517, 2329, 235, 9, 5, 41, 2066], [192, 70, 269, 231, 747, 5], [7, 327, 27, 4, 355, 1006, 11, 5029, 8, 7, 3339, 11, 4, 108, 21, 1881], [660, 6981, 522, 8, 11603, 6982, 12, 6983, 127, 939, 8, 5216, 130, 11604], [65, 51, 4, 2095, 8, 454, 57, 222, 44, 132, 31, 66, 210, 11605, 4, 232, 3240, 2879], [242, 35, 5, 2329, 235, 9], [243, 457, 1], [3787, 7, 1, 148, 1574, 50, 142], [5, 65, 13, 2, 269], [7, 1890, 12, 2, 1, 1804, 37, 3, 63, 2337], [3, 46, 43, 462, 1], [11606, 2, 190, 1006], [57, 7, 24, 58, 205], [55, 289, 2405, 173, 27, 144, 18, 135, 69, 428, 86, 3, 195, 10, 830, 2129, 289, 2405, 79, 183, 202, 83, 6984], [15, 12, 66, 14, 1021, 18, 39, 1, 99, 332, 92, 115], [1, 284], [3, 195, 197, 181], [595, 294, 1], [165, 6703], [3, 407, 686, 1, 1, 76, 25, 3, 226, 46, 948, 6985, 30, 66, 32, 33, 70, 45, 35], [1, 432, 81, 6, 292, 45, 432, 110, 81, 6, 378, 63, 5, 110, 226, 378, 55], [1583, 49, 56], [3, 300, 6, 274, 158, 5, 165, 96, 662, 27, 17, 230, 1869, 5, 41, 10, 1617], [58, 5, 197, 225, 2284], [736, 2895, 447, 41, 2, 438, 27, 4, 832, 1, 224], [3, 41, 1169, 73, 180, 73, 2, 9, 37, 15, 110, 54], [1, 5, 121, 5, 29, 110, 13, 11607, 172, 4915], [52, 2, 141, 1, 11, 979, 11608, 3788], [11609, 3, 532, 2, 1611, 26, 3561, 1259, 3561, 244, 106, 3, 94, 97, 1, 30], [1258, 10, 664], [3213, 5, 49, 1675, 2958, 96, 119, 45, 8, 309, 464, 6959, 513], [198, 44, 19, 7, 1, 35], [31, 3501, 136, 1575, 5, 6, 14, 2, 6986, 21, 3501, 36, 49, 11, 2, 320, 16, 11610, 3, 8, 228, 103, 43, 1363, 194, 3501, 56, 378], [454, 71, 239, 263, 4402, 44, 1344, 1331, 211, 477, 6, 852, 11611, 56, 22, 3296, 11612, 93, 401, 852], [5, 1, 8, 733, 59, 71, 89, 305, 2001, 49, 14, 557, 478, 5, 49, 96, 103, 6, 471, 76, 102, 6, 1317, 549, 1718], [7, 2, 2082, 2996, 675, 5, 11613, 541, 1], [5, 330, 62, 36, 61, 6, 1599, 21, 17, 585, 1, 14, 542, 6, 294, 54, 4, 676], [11614, 6987, 42, 328, 216, 2, 356, 25, 107, 715, 3, 41, 11615, 718, 6369, 5309, 107, 51, 11616], [73, 11617, 715, 381, 29, 119, 922, 166, 73, 209, 73, 95, 2019, 48, 474, 12, 73, 15, 598, 11, 1044, 5214], [262, 17, 1], [23, 2, 818, 5310, 95, 71, 133, 5], [1916, 6988, 28, 5, 1], [940, 2, 285], [1, 23, 818, 6, 14, 202, 174, 2, 11618], [183, 315, 25, 1, 19, 1258, 16, 45], [78, 12, 490, 163, 674, 782], [25, 3, 297, 80, 30, 51, 143, 3329, 2485, 1043, 1, 46, 783, 10, 106], [197, 12, 256, 2008, 58, 21, 169, 48, 2324, 82, 5076, 291, 1], [19, 5, 185, 30, 1894, 30, 1043, 1, 104, 30, 529, 864, 16, 385, 6989, 1, 46, 783, 10, 106], [999, 16, 11619, 4, 101, 193, 5, 222, 28, 285, 251], [613, 281, 42, 291, 83, 43, 287, 118, 182, 19, 350, 649], [241, 286, 43, 19, 5, 674, 782, 1, 3, 375, 80, 1043, 291, 30], [576, 76, 177, 56, 66, 192, 2679], [128, 1973, 34, 23, 625, 703, 37, 1, 29, 13, 17], [22, 327, 12, 248, 11620, 12, 1015, 3617], [29, 14, 2, 83], [3, 471, 76, 9, 140, 46, 357, 223, 137, 17, 34, 6990, 128, 48, 38, 36, 191, 21, 76], [2984, 6991, 52, 67, 5311, 6, 14, 84, 6992, 1109, 37, 52, 63, 1467, 15, 18, 4, 1637, 11621, 57, 2, 816, 55], [473, 16, 263, 1389, 6, 467, 11622, 8, 61, 6, 2, 232, 11623, 101, 268, 216, 15, 6, 126, 930], [3, 19, 90, 5, 128, 34, 267, 5, 141, 138, 1536, 391], [38, 1386, 191, 170, 59, 15, 121, 1320, 820, 5, 119, 12, 11624, 313, 4, 190, 4853], [162, 20, 120, 9, 51, 280, 55], [597, 8, 2338, 230, 261, 9], [6993, 3, 200, 145, 6993, 7, 2745, 961, 302, 17, 1154, 233], [1962, 76, 1, 49, 171, 11625, 34, 171, 55], [23, 37, 11626, 3, 33, 122, 6, 1342, 9, 6, 6994, 1645, 8, 70, 15, 3789, 55], [3, 86, 3, 87, 6, 94, 121, 1, 11, 938], [221, 57, 2, 1, 2997, 164, 5193, 416, 198, 44, 4, 1805, 2746, 6, 468, 126, 758, 11, 2285, 6995], [583, 3, 63, 157, 935, 3340, 641, 42, 11, 212], [3, 300, 3, 299, 5, 220, 2162, 2, 285, 3589, 146, 61, 6, 2818], [3166, 399, 37, 38, 97, 107, 108], [3, 29, 62, 23, 11627, 37, 3, 29, 62, 162, 36, 11628], [1], [60, 6996, 9, 40, 46, 11629], [101, 68, 437, 116, 2, 1600, 24, 11630, 370, 188], [1, 23, 549, 26], [2033, 1], [11631, 1, 29, 137, 27, 20, 164], [128, 367, 1], [1, 2034], [1, 2034, 29, 28, 565, 11632], [1107, 299, 160, 31, 2, 95, 1501, 4, 6450, 16, 2, 11633, 122, 220, 4916, 123, 466, 149, 15, 6, 6997, 102, 5277, 11634, 74, 346], [640, 1055, 49, 156, 13, 5312, 236, 2402], [66, 220, 70, 212, 348, 51, 445, 195, 515, 73, 2, 83, 793, 4, 6998, 374, 322, 93], [1676, 52, 1559, 13, 2, 89, 83, 114, 15, 142, 2, 3790, 5313], [12, 143, 207, 617, 1166, 6, 1344, 218, 11, 10, 689, 617, 475, 59, 143, 2829, 48, 6999, 8, 143, 813, 99, 969], [122, 14, 538, 661, 16, 208, 13, 2, 19, 1633], [128, 25, 1521, 121, 3, 118, 14, 11635, 426, 147, 587, 1, 266, 139, 2613, 17], [11636, 31, 621, 86, 22, 1353, 363, 6, 6, 303, 354, 12, 73, 185, 73, 32, 16, 76, 65], [1035, 157, 68, 5118, 544, 2485, 102, 170], [147, 148, 381, 119, 1741, 913, 247, 207, 617, 2019], [147, 797, 259, 1741, 913, 247, 207, 617, 11, 10, 689], [3, 14, 7000, 5, 47, 11637, 3, 114, 5, 6, 143, 232, 178, 8, 1794, 5], [3, 41, 6, 14, 1426, 207, 8, 32], [221, 720, 52, 110, 626, 17, 8, 3, 12, 2, 158], [5, 105, 2273, 11, 143, 207, 689], [147, 207, 189, 14, 11638], [403, 181, 3, 121, 22, 47, 20, 11639, 11640, 121, 15, 47, 350], [3, 13, 143, 232], [15, 5314, 10, 1209, 1501, 7001, 74, 256, 3, 29, 62, 85, 3, 510, 35, 27, 11641, 4, 179, 68], [11642, 143, 207, 3724, 563, 6, 119], [267, 21, 79, 17, 2, 19, 1298], [7, 11643, 47, 13, 22, 1, 12, 1772, 63, 3, 61, 337, 27, 5], [5, 2, 161, 1, 11644, 10, 226, 54, 6, 2747, 7, 32, 272, 3122], [188, 52, 12, 2, 388, 1066, 22, 3791, 11645, 12, 4, 11646, 16, 3792, 8, 84, 11647, 12, 216, 35, 16, 11648, 11649], [5, 249, 15, 2620, 1], [110, 22, 633, 207, 864, 16, 45, 1048, 2, 1155, 251, 3, 90, 5, 92], [5, 600, 48, 13, 10, 7002, 18, 670, 34, 3, 210, 5315, 118, 11650, 79, 5, 2, 838, 333, 139, 2159, 17, 18, 39, 2518], [7, 13, 57, 60, 1900, 56, 418, 118, 226, 126, 534, 11651], [336, 7, 45, 28, 17, 11652, 3, 44, 4, 11653, 476, 8, 62, 57, 23, 58, 8, 28, 79, 2, 1633, 23, 328, 137, 178], [2016, 269], [156, 142, 3793, 105, 132, 2, 24], [249, 18, 10, 2479, 24], [249, 15, 35, 24], [1422, 8, 120, 849, 2736, 44, 6, 14, 4886, 656, 37, 4, 6252, 849, 63, 11654], [23, 330, 2, 341, 120, 1, 8, 341, 1959, 28, 18, 10, 822], [1, 17, 99], [39, 1, 5316, 1645], [678, 68, 1364, 1, 74, 341, 25], [3, 150, 4059, 3, 94, 295, 329, 27, 4, 3794, 204, 426, 15, 48, 4, 508, 1405, 16, 4, 178], [42, 96, 2, 3728, 205, 55], [693, 42, 48, 18, 4, 269, 904, 99, 55], [23, 330, 54, 7, 1, 736], [23, 821, 35, 8, 15, 179, 73, 19, 695], [3, 302, 5, 494, 1054, 162, 4, 3542, 40, 216, 17, 58, 15, 3742], [7, 265, 2, 181], [2334, 69, 121, 5317, 133, 2334, 1, 5, 11655], [11656, 111, 506, 2725, 48, 431, 2385], [1417, 285], [69, 4, 286, 87, 4403, 21, 393, 82, 7, 11657, 179, 835], [180, 19, 11658, 260, 158], [19, 50, 117, 11, 4, 24], [25, 3, 96, 349, 205, 8, 19, 5, 1, 42, 411], [1, 69, 6972, 195, 48, 108, 142, 82, 43, 19, 25, 4, 19, 5, 81, 133, 9, 30, 25, 139, 147, 81, 8, 349, 35], [19, 57, 2, 25, 152, 58, 3, 131, 94, 15, 8, 113, 7, 25, 6, 139, 208, 13, 2, 1, 88], [1, 3, 167, 5, 27, 4, 706, 8, 2, 25, 46, 706, 108], [901, 2168], [1292, 5318, 1, 28, 54, 4, 11659], [281, 24, 3280], [57, 200, 5, 1785, 315, 388, 1510, 378, 137], [2, 1, 41, 885, 26, 23, 4860, 396, 201], [33, 11660, 12, 2], [811, 1], [1, 5, 625, 713, 3, 363, 1157, 55], [628, 23, 238, 303, 2, 2159, 16, 34, 20, 2920, 12, 4177, 100, 17, 62, 256], [1965, 205, 233, 383, 13, 2, 153], [20, 270, 2, 1, 55], [104], [104, 30, 19, 1431], [3, 75, 304, 21, 4, 115, 36, 114, 76, 14, 2, 2934, 21, 4, 1119, 1129], [92, 7003, 19, 102, 13, 5, 121, 5, 11661, 5, 372, 13, 2, 141, 11662, 172, 4830], [12, 37, 1110, 59, 84, 355, 7004, 4889], [31, 36, 56, 11, 1164, 292, 74, 445, 286, 4404, 15, 55], [159, 524, 2, 1503, 761, 11663, 34, 101, 140, 16, 4, 2339, 16, 6567, 11664], [3, 79, 170, 2, 24, 8, 41, 572, 112, 705, 123, 170, 8, 1364, 11665, 3, 75, 72, 3, 1917, 59, 254], [43, 5319, 4, 11666, 49, 2, 666, 16, 187, 34, 4, 1130, 7, 690, 4, 247, 12, 4, 231, 5320, 1771, 11667], [2417, 1094, 56, 81, 3795, 27, 529, 485, 31, 11668, 124, 1918, 21, 32, 84, 2998, 52, 452, 14, 869], [52, 1453, 15, 55, 214, 1, 510, 6, 10, 453, 785, 155, 904], [95, 16, 2, 1508, 2230, 612, 78], [5321, 17, 158], [293, 48, 3, 64, 147, 1], [86, 15, 149, 40, 486, 17, 58, 5322, 128, 1325, 23, 96, 2, 1], [19, 185, 353], [19, 2504, 30, 399, 128], [20, 28, 572, 104], [3, 13, 348], [1709, 38, 66, 662, 54, 8, 1955, 348], [339, 220, 214, 51, 76, 21, 14, 9], [695, 20, 4, 24, 69, 103, 79, 4, 5323, 560, 31, 3, 67, 6, 258, 622, 3, 3694, 34, 23, 48, 152, 936, 10, 106, 27, 5], [5, 2282, 8, 38, 5, 28, 169, 4, 9, 223, 107, 37, 71, 277, 7, 372, 315, 516, 70, 169, 11669], [221, 76, 9, 344, 272, 1071, 7, 480, 759, 2035], [48, 391, 74, 393], [33, 13, 2, 312, 6, 107, 337, 38, 182, 36, 67], [43, 68, 279, 158], [6, 713, 158, 309, 250], [57, 35, 158], [552, 69, 502, 7, 1, 10, 226], [22, 1, 48, 1806, 17], [120, 1], [1, 28, 80, 1438, 30, 102, 10, 45], [1416, 33, 313, 2, 11670, 11, 15, 71, 4, 718], [65, 51, 22, 158, 30, 158, 45, 117, 135], [973, 11, 15, 646, 23, 2, 1391], [232, 3796, 12, 19, 1772, 97, 6969], [100, 2, 1391, 62, 91, 55], [339, 56], [403, 9], [272, 79, 84, 144, 30], [7, 57, 3, 79, 15, 99, 55, 15, 2239, 179, 251, 34, 91, 42, 1551, 559, 868, 8, 107, 108], [33, 62, 2, 11671, 206, 1, 11, 5264, 136, 174, 108], [267, 21, 4, 1713, 205, 1], [11672], [20, 33, 1478, 4, 24, 35, 128], [281, 140, 23, 99, 431, 21, 76, 9, 128, 1325, 3, 41, 1193, 7005, 7, 3, 47, 2, 365, 1024], [4, 1, 7, 424, 10, 310], [1962, 678, 12, 11673, 11674, 11675, 130, 126, 144, 154, 11676], [11677, 143, 186, 95], [29, 113, 17, 57, 6, 2019, 19, 466, 2954, 158, 187, 1169, 4366, 1346, 1282, 633, 1, 3797, 24, 711], [204, 630, 183, 30, 269, 65, 45], [5, 152, 14, 4108, 213, 206, 27, 43, 1, 11678], [57, 2, 3341, 1543, 1], [135, 107, 4, 1773, 9], [7, 690], [5, 198, 536, 15, 3101, 15, 46, 978, 8, 136, 159, 3138, 11, 15], [367, 23, 120, 1089, 140, 3, 29, 61, 224, 2999, 10, 689, 8, 72, 2, 666, 16, 609, 312, 5214], [34, 43, 675, 3, 103, 72, 43, 15, 12, 48, 98, 11679, 8, 436, 103, 72, 386, 16, 2, 812, 2925, 367, 4, 286, 15, 12, 28, 54, 20, 1177], [1954, 142, 5, 141, 668, 55, 33, 61, 788, 2, 1], [22, 236, 11680, 12, 11681], [19, 5, 1], [200, 5, 114, 2, 406, 16, 20, 24, 3, 293, 5, 889, 1366, 15, 140, 15, 1139, 1630, 7006, 1366], [177, 81, 59, 11682, 698, 16, 185, 750, 440, 12, 2, 793, 2917, 142, 144], [246, 7007, 6893, 11, 112, 164, 5, 869, 13, 2, 141, 1], [1673, 28, 235, 82, 9, 27, 11683], [15, 2, 1130, 664], [3331, 1, 58, 3331, 184, 39, 9, 46, 334], [588, 103, 72, 1320, 11684, 149, 1, 75, 806, 254], [11685, 3792, 182, 11686, 660, 5324, 13, 5325], [31, 42, 4373, 11, 5, 63, 94, 84, 1031, 1357], [11, 4, 56], [376, 145, 55], [151, 1, 491, 5, 6, 4, 4405, 11687], [107, 1552, 8, 1622, 27, 17, 145], [19, 5, 181], [19, 5, 145, 5, 2506, 55], [61, 6, 376, 5, 181], [11, 1914, 3719, 145], [145, 5, 315], [48, 1847, 20, 96, 2, 104, 2032], [5, 301, 145], [2737, 17, 42, 2308, 3, 87, 6, 62, 38, 66, 54, 6, 4, 2340], [262, 17, 42, 2308], [162, 277, 7, 19, 1433, 11688, 107, 82, 1599, 74, 7008, 3798], [98, 450, 6, 4, 7009, 16, 287, 8, 104, 3000, 101, 4406, 12, 6, 6981, 8, 3001, 305, 11689], [11690, 3, 293, 5, 46, 14, 3659, 125, 325, 2322, 177], [68, 4967, 1333, 34, 16, 1134, 36, 49, 104], [1, 132, 18, 116, 21, 585, 11691, 11692], [6947, 983, 248, 48, 110, 11693], [1, 25], [1, 1169], [3, 62, 5, 49, 2, 24, 30, 1894, 7, 12, 7010, 8, 5326, 13, 5327], [66, 29, 471, 24, 30, 1894, 6, 206, 11694], [221, 140, 1576, 2864, 12, 2, 24, 30, 11695], [3, 87, 60, 949, 18, 4, 470, 1358, 11696, 142, 135, 32, 5, 63, 28, 12, 839, 860, 949, 11697], [40, 2, 9, 48, 2, 2255], [15, 47, 1939, 11698, 104], [833, 815, 88, 24], [571, 512, 7, 1], [221, 263, 353, 49, 4, 11699], [3, 121, 256, 6, 5, 3342, 139, 477, 6, 269, 451], [221, 38, 5, 94, 170, 11700, 386, 16, 2, 1, 1632, 17, 169, 113, 170, 3, 132, 65, 21, 170], [117, 39, 9, 46, 334], [22, 1, 12, 48, 101, 98, 1718, 34, 2, 1977, 37, 176, 5328, 174, 45], [157, 20, 169, 35, 24], [5, 8, 17, 44, 186, 95, 1471, 2519, 7, 118, 33, 14, 2, 192], [1417, 88, 219, 11, 79, 5, 2, 24, 560], [172, 1433, 187, 198, 32, 14, 4407, 1828], [3729, 35, 236, 142, 11701, 3, 196, 1113, 52, 13, 6, 2429], [2728, 4, 11702], [3, 79, 20, 1, 30], [241, 15, 107, 35, 141, 1, 8, 4, 4408, 136, 43, 11703, 129, 254, 1627, 14, 2, 6224, 6, 7011], [5, 172, 232, 151, 14, 116, 11, 201, 707, 151, 563, 5, 24], [336, 60, 2109, 541, 252, 51, 11704], [3640, 88, 76, 89, 30, 387, 16, 20, 181], [2573, 52, 200, 13, 2, 344, 1], [4, 11705, 12, 28, 19, 117, 11, 4, 24], [22, 65, 127, 13, 20, 141, 260, 386, 16, 2, 83], [117, 11, 4, 24], [1314, 123, 617, 69, 75, 3002, 6, 28, 173, 7, 64, 206, 4409], [3, 346, 2327, 7012, 87, 2, 2657, 1057, 3117, 4, 4410, 12, 7013, 74, 11706, 7, 322, 1758, 4, 1658, 12, 11707], [3, 346, 4, 1421, 4, 11708], [241, 1530, 8, 4, 589, 148, 1438, 79, 36, 459, 14, 11709, 1438, 5329], [33, 28, 11, 3, 293, 2028, 149, 36, 7014, 15, 35, 215, 1477], [11710, 413, 666, 16, 4, 56, 87, 201, 383, 61, 3135, 36, 523, 383, 56], [11711, 574, 152, 836], [736, 7015, 11712, 70, 2, 492, 27, 84, 11713], [3, 2689, 1172, 11714, 210, 62, 59, 5330, 11715], [64, 11716, 168, 6, 1090, 76, 38, 3, 259, 11, 47, 2853, 5331, 76, 18, 11717, 11, 11718], [217, 502, 17, 2, 628, 16, 7016, 2716, 853, 1637, 57, 63, 3, 168, 15, 11719], [3, 29, 594, 71, 15, 669, 6, 134, 393, 6, 891, 38, 4, 4292, 1240, 44, 245, 2142, 27, 4, 232], [3, 29, 64, 39, 9], [7, 2983, 21, 463, 68, 24, 525, 4875, 11720], [11721, 410, 314, 73, 4411, 24], [99, 70, 35, 21, 20, 190, 11722], [3, 299, 15, 47, 2239, 144, 3325, 48, 939, 51, 32], [17, 25, 5, 4, 285, 3, 41, 402, 21, 5, 797], [403, 58, 5, 44, 7, 1464, 565, 16, 11723, 11724, 1447, 14, 1588, 3343, 4, 56, 63, 4412], [63, 66, 2054, 61, 6, 2941, 8, 58, 760, 1206, 372, 13, 2, 109, 179, 689, 226, 7017], [242, 35, 1, 25], [108, 35, 104], [286, 43, 91, 23, 144, 93, 51, 11725, 7, 298, 47, 669, 205], [58, 3, 65, 13, 1480, 3799, 1], [4367, 12, 11726, 424, 10, 250, 11727, 27, 11728, 47, 219, 2433, 110, 124, 201, 179, 4189, 27, 2, 11729, 11730, 1079, 34, 219, 328], [1290, 11731, 3800, 710, 1447, 11732, 11733, 1710, 600, 637, 450, 938, 2415, 11734, 11735, 3800, 3003, 190, 7018], [1], [5, 13, 435, 711], [154, 1648, 25, 705, 6, 114, 102, 18, 2, 1, 11, 775, 177, 55], [1419, 906, 15, 4, 250, 106, 158], [114, 102, 13, 2, 1, 1865], [1004, 9], [153, 42, 509, 57, 3, 409, 42, 46, 11736, 123, 2, 358, 565, 29, 137, 171, 92, 11737, 55], [1413, 11738, 409, 11739, 8, 47, 194, 2, 3234, 18, 71, 1991, 90, 274, 542, 6, 382, 254], [85, 555, 108, 33, 72, 374, 73, 144, 73, 126, 1169, 49, 365, 116, 43, 11, 11740], [22, 295, 6, 58, 27, 10, 845, 5, 609, 3004], [148, 5, 33, 79, 630, 2, 1, 321, 55], [19, 490], [23, 533, 133, 659, 8, 9, 11, 979], [118, 48, 1049, 10, 169, 18, 56, 13, 7], [19, 20, 639, 104], [3, 29, 90, 7, 52, 1807, 35, 82, 11741, 13, 2, 1792, 34, 3, 90, 4, 104, 69, 72, 36, 64, 84, 451, 1095, 102, 84, 884, 1002], [3, 6448, 86, 4, 1213, 12, 33, 392, 16, 4386], [230, 3, 363, 102, 6, 1197, 3, 67, 6, 28, 2, 11742, 34, 5332, 7019, 278, 14, 2, 1104, 181, 130, 4, 4290, 265, 11, 4, 11743], [236, 988, 461, 174, 946, 66, 514, 4, 6648, 11744, 12, 114, 7020, 73, 2748, 1185, 2988], [3, 62, 117, 34, 135, 3, 195, 936, 106, 86, 11745, 2102, 634, 3, 192, 4, 4413, 23, 144], [11746, 29, 86, 15, 59, 26, 3, 86, 12, 59, 8, 11, 2059], [10, 1254, 443, 493, 12, 11747, 11748, 15, 51, 2176, 8, 11749, 434, 21, 1015, 4414, 4415, 207, 4416], [766, 9], [22, 189, 118, 37, 28, 2, 229, 18, 3787, 31, 36, 222, 4417, 11750, 4, 386, 16, 2, 83, 278, 7011], [5, 144, 321, 55], [5333, 11751, 2396, 27, 792, 853, 190, 11752, 26, 2583, 11753, 479, 82, 4, 3240, 545, 10, 2749], [33, 137, 641, 2, 11754, 4205, 796, 104, 1269, 185, 873, 11755], [31, 3, 28, 572, 151, 14, 18, 7, 1, 2084, 551, 8, 11756, 1084, 11757, 47, 11758, 195, 1264], [10, 1, 41, 4, 961, 11, 50, 1277, 11759, 5, 6, 3778], [42, 62, 71, 3344, 14, 1823, 32, 4, 401, 39, 158, 266, 221, 1406, 13, 2, 3344], [425, 3, 407, 7021, 11760, 203, 9, 47, 2111, 17, 35], [71, 5, 152, 1945, 7022, 6, 24, 205, 116, 46, 43, 138, 61, 11, 20, 7022], [576, 3, 2520, 13, 70, 5, 2, 161, 214, 3, 44, 132, 223, 21, 99, 358, 205, 3, 90, 4, 7023], [3345, 51, 10, 11761, 43, 1, 22, 318, 14, 2, 1803, 11762], [71, 59, 3, 33, 19, 5, 117, 11, 4, 24], [52, 2, 308, 711, 52, 168, 7024, 3801, 6, 396, 4, 518, 16, 831, 11, 84, 4318], [367, 3, 13, 138, 8, 3, 90, 283, 69, 195, 3, 92], [773, 11763, 3005, 11764, 11765, 391], [1302, 48, 239, 1, 44, 297, 7], [75, 110, 902, 2, 207, 91, 125, 325, 908], [7, 1, 47, 61, 74, 3802], [1, 30, 768, 11, 84, 235, 281], [1, 30, 5334, 281, 46, 5, 51, 197, 25], [23, 551, 7, 9, 123, 531, 280, 2288, 4418], [11766, 29, 192, 27, 22, 361, 281, 10, 11767, 994, 107, 129, 9, 31, 97, 67, 151, 122, 6, 7025, 97, 35, 225, 31, 97], [242, 35, 104], [19, 5, 1], [24, 11768], [28, 60, 376, 285], [160, 5, 566, 307, 100, 111, 62, 5, 44, 575, 437, 26, 687, 18, 135, 7, 57, 76, 9, 13, 37, 2498], [221, 52, 857, 407, 4, 199, 189, 69, 3006, 11769, 34, 52, 311, 4, 1013, 102, 219, 678, 198, 14, 2, 1139, 2934, 6, 11770], [171, 7026, 365, 202, 1716, 61, 6, 11771, 8, 833, 2915], [695, 57, 2, 181], [3, 429, 2, 1361, 155, 115, 215, 213], [19, 5, 1043, 30, 529, 161, 138, 83, 289, 1193, 5, 5335], [2392, 58, 245, 16, 174, 2496, 1581, 2705, 1508, 11772, 821, 95], [11, 7, 406, 367, 3, 745, 124, 98, 1588, 327, 1401, 4, 1647, 1919, 12, 207, 92, 99, 8, 267, 3149, 57, 3, 195, 1707], [7027, 57, 24, 32, 3, 94, 12, 2, 789, 2293, 414, 34, 944, 5, 222, 70, 22, 1509, 184, 37, 209, 2245], [243, 457, 1], [3, 75, 85, 5, 35, 9], [474, 34, 23, 619, 107, 28, 22, 1], [91, 148, 252, 107, 28, 22, 1, 3346], [4, 101, 184, 165, 130, 2, 11773, 12, 2, 232, 11774], [128, 7, 25, 47, 59, 6, 61, 11775, 18, 7, 1], [96, 2, 1, 464], [39, 9, 46, 334], [28, 60, 169, 8, 139, 137, 7, 206, 248], [172, 11776, 515, 202, 30, 25, 11777, 2, 120, 177, 758, 18, 34, 10, 25, 200, 6439, 35, 2, 161, 5336], [281, 221, 36, 58, 72, 23, 2, 141, 1], [27, 479, 35, 493, 13, 5, 11778, 394, 5, 28, 37, 209, 24, 4, 518, 49, 11, 4, 11779], [26, 4, 2621, 3803, 568, 11780, 5137, 66, 103, 61, 84, 236, 4, 6291, 709, 1057, 5137, 66, 103, 4847], [1], [1497, 52, 236, 6117, 143, 1540], [43, 454, 20, 2184, 12, 11, 4, 1476, 7, 162, 56, 13, 5, 11781, 267, 6, 21, 446, 54, 20, 573, 207], [11782, 506, 2, 1, 24, 1062, 15, 3657, 405, 631, 4, 2001, 48, 4, 1245, 403, 1], [12, 2, 141, 1, 7, 85], [281, 71, 209, 49, 5, 389, 6, 1577, 48, 62, 57, 20, 81, 59, 171, 30, 11783, 12, 56], [91, 57, 59, 2090, 14, 4, 1700, 202, 3347, 6, 404, 2, 1499, 3348, 59, 56, 2481, 43, 1994, 21, 11784], [16, 1134, 42, 118, 5, 5337, 11785, 33, 72, 4, 324, 11786, 166, 136, 32, 4, 4419, 6, 5338, 11787, 18, 5339], [4238, 7028, 172, 27, 4, 1224, 265], [2646, 3, 75, 58, 7, 99, 2, 1224], [66, 11, 147, 1, 10, 252], [14, 2, 24, 73, 11, 534], [14, 2, 24], [1100, 18, 263, 48, 56, 205, 55], [19, 212, 104], [10, 25, 62, 52, 2, 1], [3, 1279, 10, 3007, 5266], [1576, 210, 44, 2, 186, 79, 1600, 2148, 1590, 162, 52, 81, 59, 290, 692, 743, 8, 1, 8, 319], [16, 5277, 3, 47, 14, 83, 683, 82, 10, 306, 71, 6, 70, 2, 189, 150, 13, 52, 378, 1735, 7029], [68, 106, 51, 1130, 2521, 3, 861, 2, 11788, 11, 10, 24, 11789, 2750], [5, 49, 392, 16, 15, 39, 37, 79, 1334, 49, 48, 11790, 36, 49, 1775, 1909, 3302, 11791, 1190, 7030], [8, 4, 101, 1130, 7, 249, 1128, 259, 12, 212, 181, 743, 26, 11792], [1, 967, 288, 40, 867, 17, 873, 1711], [31, 66, 556, 2667, 1077, 74, 54, 19, 144, 7, 57, 23, 72, 100, 17, 62, 5340, 2522, 767, 30, 25], [66, 60, 9, 4296, 55], [97, 1, 967], [52, 1094, 56, 280], [3, 86, 247, 11793, 49, 21, 4, 942, 3, 46, 43, 95, 1209, 80], [144, 24, 178], [3, 13, 147, 2439, 384, 2955, 158, 87, 6, 62, 1038, 507, 11, 143, 5341, 748], [847, 3, 118, 64, 6, 58, 7, 8, 127, 6, 212, 1433, 7031, 19, 978, 1828], [1521, 510, 6, 95, 91, 7, 45, 47, 37, 1722], [40, 63, 271, 73, 637, 73, 40, 333, 399], [72, 71, 5, 58, 7, 3, 41, 22, 161, 1, 69, 46, 28, 4, 11794], [7032, 1365, 2075, 6, 855, 379, 177, 54, 135, 92, 11795, 29, 62, 827, 2, 573, 1078, 12, 3, 14, 3144, 855, 9, 3804, 1558], [11796, 1416, 380, 36, 44, 190, 1054, 99, 566, 22, 761, 11797], [23, 48, 2, 1298, 2499], [48, 332, 11798, 698, 16, 2, 282], [1, 194, 97, 3008, 230, 3, 3009, 5, 6, 4, 3805, 3806, 5, 1, 30, 916, 5, 276, 450, 35, 13, 11799, 802, 11800, 30, 25], [242, 4, 19, 562, 5, 189, 2, 11801, 1089, 11802, 7033, 400, 142, 8, 404, 637, 178, 641, 3349, 8, 2523, 104], [2176, 41, 76, 314, 521, 9], [5, 1, 2032], [241, 5, 342, 5, 2751, 1], [28, 173, 111, 231, 55, 478, 42, 523, 4, 660, 32, 129, 10, 186, 11803, 242, 4, 19, 35, 3807], [3, 222, 44, 7, 418, 116, 1473, 11, 10, 231, 8, 1228, 4, 290, 165, 130, 4, 1, 7, 216, 15, 7034], [7, 1, 198, 14, 11, 865, 21, 7, 7034], [425, 3, 375, 32, 4, 388, 11, 10, 261, 27, 7, 45, 55], [3, 124, 351, 1683, 8, 487, 61, 140, 3, 124, 7035, 46, 7, 2, 1], [3, 724, 11804, 2, 104], [11805, 965, 8, 367, 152, 44, 6, 1053, 4, 413, 1], [37, 20, 2, 3808, 1938, 932], [11806, 11807, 179, 30, 226], [2511, 5342, 2628, 2, 1751, 950, 1033, 2110, 11808, 11809, 12, 15, 7036, 132, 116, 15, 2, 1196, 179], [762, 7, 1, 931, 54, 50, 481, 55], [43, 174, 329, 185, 158], [18, 274, 10, 1, 89], [267, 92, 61, 656, 7, 56, 63, 97, 161, 530, 55], [544, 260, 3707, 35, 13, 56, 51, 2, 1476, 256, 6, 14, 818, 16], [136, 55, 13, 51, 7037, 1808, 1, 55], [2835, 5, 62, 71, 93, 11810, 49, 51, 11811, 729, 463, 745, 2096, 35, 32, 20, 11812, 11813], [212, 274, 148, 1, 251, 298, 423], [898, 12, 1, 216, 21, 7, 13, 11814, 37, 209, 8, 266, 58, 2, 1345, 129, 7038], [336, 386, 66, 2036, 61, 470, 31, 15, 47, 10, 77, 1, 14, 67, 6, 1049, 5343, 8, 35, 18, 60, 365, 343], [13, 69, 100, 240, 316, 143, 1136, 11, 325, 1, 233, 280], [12, 68, 16, 4, 11815, 153, 1042, 325, 45], [1446, 1296, 47, 556, 7039, 2, 153, 52, 121, 622, 811, 3, 383, 41, 2, 11816, 79], [280, 58, 5, 2103, 1, 27, 7, 45], [15, 2, 323, 9], [221, 66, 62, 59, 5344, 11817], [48, 33, 502, 2686, 2, 56, 11818, 5345, 78, 96, 44, 437, 27, 7040], [797, 5, 37, 56, 20, 734, 41, 1338, 27, 4420, 38, 40, 405, 5, 102, 21, 261], [773, 83], [34, 48, 6940, 285, 7, 184, 12, 2, 11819], [104, 34, 5, 1415, 17, 625, 5346, 7041], [128, 1221, 30, 25, 122, 6, 208, 32, 1715, 5, 2, 141, 83, 400, 142, 8, 194, 82, 4, 2089, 285], [242, 4, 19, 35, 20, 963, 73, 1066, 1439, 11820, 44, 104, 139, 70, 451, 8, 3577, 10, 1979, 11821], [11822, 17, 175, 59, 119, 24, 82, 4, 108, 27, 10, 1200, 11, 7, 216, 7, 11823], [101, 292, 3003, 1164, 634, 244, 11824, 1, 133, 57, 11825, 440, 11826], [147, 47, 159], [1686, 2, 320, 1038, 1753, 11827, 3, 64, 10, 674, 782, 513], [5, 177, 362, 107, 35, 125, 60, 284, 7042, 11, 10, 115, 66, 105, 81, 59, 43, 104], [37, 72, 4, 68, 69, 1207, 98, 2845, 1556, 1077, 1227, 123, 4030, 2, 11828, 69, 445, 32, 42, 636, 600, 14, 2, 3736, 7043, 1], [875, 1972, 49, 165, 88, 190, 68, 776], [100, 48, 627, 4, 488, 7, 416, 8, 126, 639, 136, 190, 4421], [11829, 124, 6, 114, 4, 2151, 11830, 11831, 4, 1122, 47, 614, 6, 14, 21, 470, 1871, 13, 17, 8], [272, 70, 5, 2, 549, 11832, 323, 10, 312], [5, 100, 17, 62, 88, 55, 151, 61, 129, 8, 204, 32, 76, 9], [104, 2382], [3, 195, 33, 11833, 3, 118, 257, 5, 142, 13, 4, 1, 7, 5, 4422, 88, 157, 10, 1735, 18, 20, 833, 8, 512, 5], [55, 7044, 3, 301, 36, 11834, 3, 41, 2, 11835, 7, 118, 70, 2, 24, 13, 5, 345, 21, 4, 4423], [1, 177], [83], [43, 540, 6, 167, 27, 5, 38, 3, 62, 5, 24, 3, 266, 28, 43, 431, 446], [3, 308, 15, 505, 13, 2, 1, 8, 15, 2752, 20, 11836, 3, 118, 3809, 5, 29, 58, 15, 55], [140, 76, 25, 7, 273, 5, 1, 216, 26, 36, 48, 112, 25, 74, 245, 698, 16, 112], [422, 497, 64, 95, 55], [11837, 11838, 19, 50, 649, 40, 2520, 2, 1], [321, 66, 63, 679, 694, 13, 388, 647, 11839, 11840], [552, 100, 58, 60, 388, 385, 191, 11841], [31, 66, 29, 662, 54, 444, 4, 2341, 251, 272, 204, 2, 1], [219, 52, 2, 187, 8, 52, 63, 249, 10, 30], [5, 19, 816, 33, 192, 81], [24, 1587], [5, 46, 45, 24, 55, 61, 28, 167, 5, 46, 132, 881, 11, 546, 1164, 425], [858, 3010, 318, 14, 4, 7045, 184, 5, 222, 157, 11, 20, 347, 55], [56, 251, 178, 4424, 11842, 424, 5144], [8, 3, 1257, 9], [146, 64, 11843, 823, 9, 26, 11844], [267, 4, 1, 7, 7046, 10, 175, 18, 7047, 22, 7048], [20, 270, 2, 104], [353, 1429, 197, 7049, 160, 200, 97, 86, 16, 536, 4, 2185, 392, 16, 111], [85, 174, 2296, 2, 68, 1291, 158], [950, 3263, 136, 589, 30, 187, 73, 3585, 36, 29, 279, 59, 5, 51, 32, 5, 1507], [3, 146, 192, 7050, 39, 183, 9, 13, 11845, 230, 36, 28, 595, 18, 10, 30], [5, 94, 4, 1, 27, 4, 365, 645, 7, 133, 6, 107, 18, 128, 40, 716, 89, 277, 11, 4, 3327], [50, 24, 532, 13, 2590, 341, 381, 591, 8, 6868, 1270], [11846, 122, 6, 119, 20, 95], [5, 113, 17, 2993], [34, 12, 48, 110, 2, 11847, 52, 317, 44, 4, 11848, 74, 5347, 6, 58, 393, 123, 1399, 8, 1601, 2, 11849], [11850, 9], [243, 457, 153, 58, 490, 45, 11, 2, 1680, 3810], [55, 33, 13, 11851, 8, 61, 54, 13, 2, 669, 1, 8, 2753, 4, 244, 213, 8, 404, 292, 178], [3, 33, 1649, 5, 189, 79, 17, 2, 3523], [25, 3, 103, 28, 138, 873, 8, 1453, 5, 6, 119, 15, 1], [69, 62, 720, 7, 674, 782, 1288, 103, 105, 2754, 802, 1920, 1186, 11852], [3, 195, 156, 1455, 51, 20, 6277, 6, 176, 18, 61, 173, 4, 264, 11853, 12, 15, 109, 165, 130, 4, 6963, 179], [1458, 467, 11854, 8, 72, 57, 3, 187, 465, 5, 1240, 30, 17, 361], [293, 48, 108, 11, 143, 179], [55, 258, 2, 5348, 82, 11855, 6, 114, 5], [3, 63, 113, 82, 22, 175, 7, 20, 2, 3004], [5045, 11856, 5, 1891, 7, 175, 27, 4, 279, 36, 600, 2057, 5, 11857, 11858, 21, 4, 1203, 16, 86], [20, 1242, 11859, 38, 1575, 129, 103, 116, 14, 245, 5349, 74, 103, 2856, 96, 14, 1166, 6, 56, 770], [11860, 158], [11, 22, 360, 66, 29, 3143, 4, 269, 4, 269, 3143, 2012], [3, 41, 9, 11, 511, 1890, 1803], [3, 694, 35, 6, 2, 1, 98, 765, 13], [2586, 2, 24], [403, 312], [28, 17, 2, 558, 16, 212, 1106, 163, 120, 1934, 1536, 789, 2034, 267, 252, 2988], [7, 57, 3, 299, 1982], [57, 20, 2088, 3747, 88, 104], [20, 48, 19, 11861, 5, 28, 253, 82, 253, 1036, 8, 88, 753, 111, 140, 20, 2, 11862], [11863], [1, 491, 7, 11864, 2, 11865], [33, 486, 20, 202, 7051, 11866, 15, 47, 11867, 20, 48, 2181, 47, 2, 408, 16, 20, 48, 2027], [550, 34, 23, 4, 45, 282], [78, 41, 6, 114, 143, 207, 11868, 4263, 860, 813, 34, 101, 143, 120, 1734], [3, 452, 14, 818, 7, 11869, 12, 11, 20, 2865, 52, 1765, 21, 68, 8, 268, 52, 183, 1900, 2455], [7, 1, 12, 37, 185, 15, 4, 3735, 11870, 48, 4, 1578, 11871, 161, 960, 47, 4, 1235, 340, 3735, 12, 1235, 340], [43, 1], [112, 45, 7, 480, 4339, 12, 2, 1, 6, 258, 205], [22, 1, 12, 7052, 625, 873, 175, 117, 211, 3, 121, 3, 47, 7053, 7054, 85, 5, 146, 58, 7, 6, 17, 5350], [8, 367, 3, 121, 1218, 1], [5, 2, 1, 21], [9, 4, 851, 7055, 670, 12, 18, 4, 11872], [85, 5, 146, 310, 11, 20, 830, 262, 34, 5, 41, 1864, 1], [8, 3, 29, 44, 2, 306, 1, 30, 25, 42, 165, 242, 20, 19, 476, 230, 3, 58, 15, 21, 5, 27, 1438, 30], [31, 20, 61, 6, 81, 45, 51, 577, 108, 15, 35, 8, 290, 1, 30, 25, 3, 300, 42, 25, 82, 49, 365, 24, 177], [425, 8, 23, 96, 349, 9, 37, 71, 12, 7, 614, 6, 2471, 17, 12, 15, 614, 6, 505, 10, 976, 19, 177], [241, 2062, 2063, 1521, 30, 25, 1, 30, 25, 57, 42, 133, 241, 1742, 11873, 30, 25, 430, 20, 3011], [5, 11874, 16, 45, 34, 5, 75, 108, 384, 324, 35, 205, 1, 30, 25, 42, 48, 81, 59, 290], [221, 8, 20, 152, 137, 27, 144, 69, 131, 58, 692, 32, 115, 34], [1, 87, 6775, 55], [11875, 31, 5, 11876, 13, 27, 11877, 661, 16, 11878, 3, 318, 14, 11879], [846, 7056, 5272, 1801, 18, 4, 232, 51, 215, 264, 178], [3, 86, 52, 144, 74, 1406], [107, 6, 4, 2301, 229, 8, 1120, 27, 17, 5, 144], [387, 125, 7057, 12, 2, 104], [221, 9], [29, 86, 621, 12, 382, 4, 720, 289, 297, 111, 382, 4, 11880, 16, 685, 871, 11881, 2755, 11882, 16], [3, 64, 50, 99, 1572, 485, 68, 16, 10, 11883, 4425], [5, 28, 154, 24, 8, 48, 958], [3, 94, 574, 72, 298, 2, 1036, 18, 2, 95, 8, 2, 7058, 12, 4, 199, 184, 34, 143, 48, 57, 3, 11884, 65, 21, 11885], [3, 299, 52, 118, 86, 15, 47, 11886, 62, 13, 38, 5, 242, 20, 949, 35, 21, 473, 691], [7059, 1], [23, 388, 284], [8, 3, 442, 66, 32, 3157, 74, 11887, 34, 3, 258, 15, 332, 6, 442, 7, 66, 32, 510, 82, 673], [33, 349, 54, 84, 1434, 3350, 316, 15, 91, 33, 382, 7060, 7061, 1088, 736], [839, 11, 10, 24, 220, 20, 1200, 198, 2305, 5351, 7062, 31, 5, 87, 11888], [104], [5, 220, 614, 6, 662, 596, 17, 22, 449, 158], [1592, 15, 149, 2, 1, 46, 295, 34, 2, 25, 7063], [101, 434, 184, 39, 1, 63, 1761], [40, 121, 40, 46, 843, 102, 18, 76, 11889], [89, 1, 27, 98, 458, 476], [122, 6, 28, 2, 401, 211, 1247, 1243, 12, 2, 112, 1, 100, 771, 2, 154, 5183, 54, 16, 197, 6656, 2654, 59, 6, 14, 11890], [187, 158, 19, 466, 1169, 4366, 633, 138, 5352, 31, 5, 75, 114, 300, 29, 61, 18, 4, 274, 148, 7064], [23, 556, 28, 10, 645, 11891, 26, 10, 402, 430, 35, 9], [93, 68, 181, 2756], [550, 3237, 181], [3, 375, 2, 106, 38, 11892, 2151, 297, 73, 14, 2037, 11893, 52, 121, 52, 46, 3012, 158, 255, 84, 11894], [187], [1, 42, 564, 73, 1156, 55], [447, 432, 58, 7065, 7066, 233, 3, 1240, 58, 11895, 11896, 34, 3, 67, 6, 122, 256, 5353, 233, 3, 28, 515, 16, 158, 522], [3351, 37, 21, 57, 540, 200, 274, 70, 4426, 1329, 3000, 508, 1405, 12, 6, 11897, 173, 4, 387, 16, 2, 969, 1644, 1388], [55, 42, 2493, 384, 1969, 1, 14, 44, 384, 480, 524, 3112, 66, 79, 384, 591, 2946], [128, 252, 5, 121, 66, 118, 28, 43, 1694, 82, 5354, 4427, 74, 1488, 71, 277, 1170, 578, 127, 2146, 5, 49, 392, 16, 15], [5, 362, 26, 26, 26, 8, 128, 24], [11898, 325, 11899, 12, 356, 31, 15, 143, 77], [3586, 7067, 2, 181, 52, 2, 2317, 716, 189], [97, 181], [2, 2409, 7068, 190, 7069], [5, 14, 19, 27, 6, 239, 9, 26], [7070, 8, 144, 4312, 21, 1101, 3352, 874], [55, 7, 339, 13, 4, 463, 41, 99, 239, 894, 1189], [27, 20, 3759, 1530, 1485, 1], [33, 79, 17, 2, 339, 1, 8, 23, 48, 362, 71, 3, 150, 59, 15], [8, 726, 64, 12, 156, 726], [57, 2, 141, 1], [253, 17, 42, 643, 1], [1103, 12, 2, 1], [212, 189, 49, 24], [116, 12, 2, 95, 135, 18, 4, 2306, 8, 15, 96, 1524, 3, 75, 442, 15], [8, 277, 52, 62, 20, 79, 170, 2, 181], [11900, 1299, 17, 3, 2, 227, 7, 1, 35, 128], [3, 103, 599, 3013, 60, 1, 30, 972, 11901, 11902], [143, 11903, 11904, 80, 1209, 144, 693, 118, 3, 1866, 80, 30, 163, 580, 16, 143, 1205], [3, 63, 3014, 2, 607, 184, 20, 4428, 814, 105, 132, 2978, 1196, 2, 112, 2307, 5, 74, 2, 6233, 12, 2, 7071, 1843], [3517, 10, 312], [11905], [49, 4, 743, 21, 14, 2, 89, 1], [148, 3, 33, 41, 79, 2, 9], [61, 28, 7, 667, 1], [375, 7, 1644, 1, 66, 168, 6, 197, 27, 51, 11906], [117, 39, 1, 14, 13, 2596, 3, 293, 3, 28, 22, 401, 51, 11907, 1, 58, 165, 96, 2478, 27, 97, 734, 30, 9], [403, 1612], [5198, 2167, 837, 5, 249, 26, 7072, 5, 2158, 11908, 231, 11909, 1072], [237, 442, 66, 46, 43, 2524, 2172, 7073, 202, 1594, 346, 120, 91, 2186, 4354, 40, 1377], [51, 4, 450, 16, 4, 115, 36, 79, 80, 171, 30, 269, 11910, 282, 34, 42, 1950, 76, 120, 1377], [11, 166, 324, 5, 49, 11911, 6, 158, 37, 11912, 5152, 68, 63, 14, 244, 6, 42, 34, 80, 158], [103, 2413, 42, 7, 12, 2, 564, 5, 2, 158, 7074, 442, 15, 218, 5, 2, 158, 835], [3, 29, 134, 2, 635, 19, 57, 2, 660, 864, 16, 1044, 1439, 13, 5, 86, 11913], [5, 49, 2, 660, 2757, 69, 67, 6, 2187, 111, 27, 84, 1757, 11914, 5, 49, 2, 2744, 6, 22, 3671], [4242, 21, 112, 52, 47, 13, 22, 1, 284, 55], [12, 7075, 54, 16, 7076, 1809, 2, 308, 3307, 11, 1700, 11915, 2448, 11916, 35, 123, 1775, 2525, 545, 2705, 260], [5, 5355, 5, 1562, 84, 296, 41, 17, 98, 3331, 368, 7077], [31, 101, 116, 47, 2, 11917, 21, 7, 2086, 90, 181, 34, 66, 266, 204, 6629, 11918, 267, 42, 21, 4, 2930, 6, 100, 181, 4260], [609, 370, 3, 79, 5, 2, 1, 5356, 21], [146, 227, 4, 9, 173, 2255], [1782, 174, 11919, 4429, 65, 295, 13, 4, 324, 16, 274, 2162, 4, 11920, 16, 3015, 11, 11921, 11922, 1], [7, 47, 10, 382, 328, 18, 2, 7078, 536, 15, 54, 479, 20, 412, 71, 239, 657, 8, 61, 21, 15], [40, 207, 48, 11923], [1898, 16, 5, 11924, 5352, 66, 1422, 49, 11925, 5357, 1225], [5, 79, 331, 158, 8, 40, 4, 529, 11926, 4, 3016, 11, 7, 4320], [31, 4, 1, 29, 13, 15, 40, 75, 14, 10, 1], [488, 188, 1153, 1409, 44, 43, 1, 37, 23, 93, 55], [49, 5, 362, 59, 7, 1650, 374, 11927, 8, 5, 44, 43, 1179, 69, 3, 2975], [3589, 172, 67, 11928, 23, 515, 16, 22, 908, 104, 30, 3237, 529, 11929, 11930], [11931, 7, 162, 23, 4, 247, 144, 8, 12, 85, 861, 73, 2526, 293, 21, 2, 1847, 11932, 11933], [57, 42, 58, 1, 177], [3, 262, 42, 181], [7, 10, 161, 25, 11, 4, 848, 26, 3, 47, 1020, 2938, 1], [22, 47, 10, 25, 11, 7, 1, 91], [36, 216, 35, 11934, 226, 21, 263, 13, 158, 1594, 26, 269], [5203, 11935, 349, 1], [5, 89, 141, 1], [7079, 175, 95], [1522, 100, 5358, 22, 696, 9], [43, 23, 1078, 54, 5, 8, 212, 189, 51, 4, 731, 137, 1, 11936], [103, 105, 582, 711, 41, 11937, 18, 15, 225, 51, 3811, 123, 1368, 3017, 1707], [711], [11938, 1298, 513], [12, 4, 796, 104, 11, 4, 360], [162, 44, 5, 132, 9], [33, 13, 38, 3, 79, 217, 2, 158, 15, 48, 140, 374, 202, 15, 59, 71, 36, 11939, 13, 2, 158], [279, 36, 318, 122, 6, 494, 97], [241, 3, 5359, 820, 16, 2, 1055, 3798, 114, 129, 6803, 5325, 5, 49, 2, 675, 16, 2, 11940, 660], [11941, 380, 4, 950, 44, 32, 4, 11942, 169, 11943, 51, 199, 877, 73, 197, 11944, 660, 49, 2736], [210, 5, 3812, 4, 7080, 1179, 16, 1197, 1607, 1440, 1136, 5, 49, 2, 11945, 660], [52, 33, 2, 4430, 1718, 7, 63, 72, 393, 8, 84, 388, 660, 11946, 303, 254, 36, 64, 185, 111], [403, 3791, 11947, 175, 11948, 45, 8, 58, 20, 11949, 660], [5325, 42, 198, 2481, 42, 175, 308, 8, 1133, 45, 59, 11950, 727, 11951, 5, 101, 7081, 6, 171, 388], [5, 660, 11952, 67, 6, 3753, 2342, 32, 612, 37, 5, 63, 11953, 127, 11954, 11955, 649], [11956, 49, 2, 1810, 4431, 28, 108, 6, 197, 11957, 271, 102, 186, 27, 20, 308, 11958], [11959, 209, 5360, 58, 5, 5361, 11, 68, 115, 20, 11, 129, 20, 1643, 57, 2, 6996, 5, 1563], [11960, 32, 59, 5, 8, 120, 2302, 4432, 5, 32, 70, 4, 360, 61, 11961, 333, 14, 305, 11962], [11963, 732, 1108, 8, 660, 139, 1453, 174, 4187, 18, 4, 763, 16, 2012, 11964, 42, 29, 11965], [5362, 11966, 55, 55, 55, 55, 526, 55, 55, 55, 55, 55, 5, 49, 2, 356, 30, 11967, 55, 55, 55], [4430, 355, 654, 24, 6685, 4, 915, 99], [7082, 11968, 8, 586, 2343, 386, 5, 2820, 5363, 11969, 19, 200, 15, 91, 35, 8, 373, 15, 97, 813, 45, 24, 1108], [11970, 382, 350], [2514, 424, 292, 106, 73, 239, 11971, 1108, 660, 49, 11972], [389, 20, 1997, 660], [5, 745, 3157, 73, 2, 1044, 6784, 1413, 11973, 4431, 3, 2740, 350, 5, 29, 62, 57, 2964, 12, 11974], [2571, 11975, 11976, 456, 14, 2, 117, 11977], [364, 28, 17, 18, 7, 1, 3708], [680, 20, 2, 494], [10, 2137, 28, 17, 1, 37], [57, 2, 144], [32, 52, 182, 277, 12, 1988, 172, 187], [111, 1, 140, 36, 468, 98, 755, 16, 376, 225, 34, 15, 110, 54, 8, 66, 28, 127, 11978], [22, 12, 2, 675, 117, 20, 18, 135, 13, 1035, 3, 301, 3, 47, 2, 5364, 8, 175, 11, 1479, 8, 45, 8, 7083, 6, 11979], [65, 13, 2, 11980, 6, 307, 11981], [20, 639, 65, 13, 2, 11982, 11983, 94, 162, 5, 41, 3003, 16, 7, 5365, 417, 522, 99], [1193, 17, 21, 57, 1, 5, 87, 6, 509, 4, 186, 1585, 8, 11984, 22, 46, 1126, 838], [119, 10, 24], [126, 11985, 49, 56, 1168], [367, 282, 5, 156, 124, 4, 1651], [1, 5, 65, 13, 2, 11986, 61, 108, 6, 11987], [3, 119, 147, 813, 54, 20, 64, 874, 2727, 1886, 2, 120, 414, 288, 1831, 4433, 2, 207, 91, 651], [384, 9, 11988, 117, 11989, 765, 87, 1158, 729], [712, 11990, 1027, 3, 44, 2512, 1, 5366, 647, 11991], [2088, 1538, 1259, 269, 2295, 849], [1, 122, 6, 227, 22, 45, 13, 1126], [11992, 28, 170, 60, 4393, 8, 978, 353, 211, 11993], [23, 2711, 1917, 147, 855, 1, 7032, 1353, 17, 18, 2, 871, 3281, 1, 3, 46, 61], [584, 61, 6, 229, 39, 1, 71, 15, 11994], [374, 37, 11995, 3, 33, 67, 13, 2, 11996, 2141, 3782, 353], [11997, 2, 351, 5255, 11998, 505, 5, 1633, 8, 15, 11999], [447, 3, 477, 6, 7, 9, 38, 3, 597, 35], [107, 94, 307, 621, 226, 12000, 12, 2441, 2, 24], [267, 97, 19, 4434], [7084, 243, 7085, 7085, 2581, 241, 2581, 2402], [162, 49, 4, 95, 51, 407, 15, 7086, 162, 95, 220, 32, 129], [42, 94, 2, 564, 11, 7, 327, 12001, 3353, 6, 20, 12002, 27, 2989, 23, 7087, 3, 7088, 4, 1334, 16, 3183, 11, 4, 606], [43, 1, 7089, 129, 5085], [19, 1518, 718, 65, 92, 148, 30, 25], [72, 7, 9, 136, 3482, 2, 239, 2, 866, 371, 5, 440, 15], [77, 7, 32, 39, 236, 87, 36, 29, 279], [7, 57, 3, 299, 24], [], [43, 174, 4, 1380, 83, 252, 11, 4, 496, 12, 193, 12003], [23, 48, 2, 1132, 26, 3, 608, 396, 4, 2439, 15, 12004, 1911, 1086, 12005], [88, 471, 22, 68, 6, 20, 660, 228, 8, 194, 126, 235, 4435], [68, 882, 141, 158, 7, 118, 632, 35, 173, 2, 180, 2157], [1, 729, 10, 79], [1, 3695], [212, 353, 103, 338, 5, 7090, 2117], [2038, 3018, 1340, 12006, 2615, 21, 7, 3813], [150, 199, 193, 59, 154, 5367, 5368, 26, 154, 1648, 2527, 34, 2186, 42, 289, 197, 11, 3814, 26, 12007, 1094, 3259, 12, 4436], [12008], [37, 56], [219, 371, 5, 12, 1009, 5, 28, 2, 1080, 433, 34, 101, 22, 106, 8, 3, 266, 113, 1466, 59, 7, 1788, 3019], [7, 1, 1967, 14, 12009], [23, 5000, 5, 62, 17, 199, 1384, 45, 511, 115, 10, 312], [128, 24], [100, 61, 117, 92, 1, 8, 3, 762, 5, 215, 106, 100, 290, 117, 92], [5165, 173, 159, 5369, 103, 105, 4437, 6, 14, 12010], [52, 204, 7, 9, 464], [1140, 3, 62, 2528, 11, 2484, 119, 7, 12011, 24], [2516, 280, 5, 96, 41, 7, 45, 5, 49, 2, 9, 66, 874, 38, 5, 107, 108, 25], [5, 2, 9, 21, 7, 23, 694], [5, 41, 60, 127, 9], [48, 101, 4059, 211, 52, 842, 170, 52, 795, 108, 12012, 7, 47, 60, 24, 45], [37, 47, 3, 187, 1073, 6, 186], [5, 315, 12013, 89, 73, 1066, 110, 464, 4, 166, 1, 89, 5, 75, 359, 18, 2, 12014, 55], [7, 48, 71, 5, 2344, 5, 2933, 1633, 58, 5, 87, 2, 5252], [34, 2, 5253, 179, 120, 77, 103, 799, 27, 98, 12015, 202, 91, 21, 127, 130, 2637], [3, 62, 7, 1, 29, 61, 4197], [4, 910, 505, 3815], [289, 132, 62, 181], [31, 5, 1389, 6, 58, 12016, 5, 198, 70, 50, 2, 12017, 66, 44, 2476, 12018, 68, 107, 35, 129, 1184], [7091, 3, 63, 96, 28, 254, 7, 10, 24], [55, 571, 65, 51, 2, 1, 30, 31, 3, 131], [46, 72, 15, 329, 34, 15, 33, 73, 185, 73, 9, 229, 35, 6, 28, 701, 82, 12019, 68, 12, 1104, 130, 4, 1537], [40, 13, 4075, 139, 81, 6, 5, 140, 5, 1822, 11, 76, 12020, 6, 17, 8, 107, 28, 22, 24, 11, 166, 324], [218, 4, 413, 412, 56], [12021, 1, 29, 44, 245, 538, 21, 943, 37, 23, 27, 5, 18, 4, 45, 533, 55], [104], [5, 44, 20, 628, 1663, 99], [19, 240, 117, 11, 4, 24], [52, 56], [171, 158], [190, 11, 7092, 7093, 4438, 82, 8, 12022, 33, 4, 215, 1706, 35, 21, 1071, 53], [9, 103, 14, 9, 295, 34, 256, 189, 33, 4934], [85, 200, 36, 1299, 20, 226, 32, 179, 13, 7, 65, 13, 36, 168, 3354, 5256, 55], [85, 2128, 5, 37, 12023, 236, 38, 5, 41, 1122, 661, 16, 45, 630, 5, 598, 13, 246, 12024, 813, 12025], [8, 23, 681, 1], [6176, 49, 127, 501], [3, 46, 45, 5, 46, 12026, 66, 1456, 21, 5370], [336, 1, 5, 13, 12027, 82, 154, 1429, 620], [242, 35, 1], [45, 56], [85, 161, 4439, 1796, 3233, 2827, 8, 122, 6, 1764, 27, 4, 1, 11, 84, 830], [1171, 857, 726], [4, 3020, 168, 6, 134, 265, 351, 1255, 11, 4, 4440, 38, 3, 47, 2, 4441, 721, 6, 94, 36, 49, 96, 58, 1639], [467, 2, 1, 828, 459, 2, 2188, 12028], [55, 576, 7, 1, 47, 33, 2, 12029], [5, 63, 394, 4928, 12030, 136, 50, 402, 32, 129, 22, 12031, 12032, 3, 210, 946, 21, 7, 2620, 83], [41, 15, 267, 1612, 272, 262, 42], [66, 11, 325, 282, 571, 28, 50, 99, 1667], [43, 68, 191, 1], [702, 665, 12033, 71, 239, 106, 4, 1316, 257, 263, 11, 4, 1408, 39, 215, 885, 74, 37, 213], [1, 2034, 48, 152, 3693, 3573], [19, 76, 1, 3, 293, 12034, 257, 240, 22, 2501], [19, 5, 283], [267, 350, 3, 90, 350, 119, 12035, 616, 2014, 298, 231, 250, 173, 2, 12036, 232, 346, 4, 5298], [7, 33, 582, 6, 14, 4, 213, 66, 514, 2, 68, 178, 1408, 6, 76, 1, 82, 4, 1, 30, 1883, 283, 811, 21, 350], [52, 415, 424, 102, 2, 446, 140, 12037, 427, 82, 4, 1398, 2679, 8, 72, 7094], [11, 7, 3, 28, 127, 1, 130, 5, 31, 37, 5, 117], [1, 30, 25, 135, 2, 154, 2758, 21, 5], [1723, 2015, 10, 158], [550, 8, 3021, 1], [344, 24], [172, 24, 281], [5, 210, 110, 430, 15, 24], [5361, 855, 1479], [3, 64, 5, 9, 12038], [56], [12039, 69, 4, 19, 194, 7, 56], [267, 141, 1], [330, 62, 2520, 748, 60, 16, 22, 21, 4, 696, 21, 794, 120, 9], [1, 191, 2, 115, 102], [1, 212, 49, 4, 199, 3762], [316, 1], [55, 20, 144], [87, 6, 28, 459, 7, 1, 12040, 32, 89, 92, 34, 73, 358, 73, 5, 28, 7, 1010, 5, 1639], [23, 12041, 6, 4, 629, 117, 92, 8, 23, 599, 152, 491, 2, 1, 31, 36, 801, 74, 60, 385], [3, 29, 86, 52, 63, 257, 3816, 34, 52, 750, 82, 248, 2186, 2985, 52, 428, 157, 6740, 2014], [10, 1544, 47, 1348, 11, 12042, 8, 2377, 12043, 23, 2, 7095, 232, 34, 64, 4, 7096, 7097, 867, 2988], [79, 17, 1, 361, 8, 94, 31, 3, 29, 491, 4, 643, 54, 16, 20, 306, 8, 44, 1748, 6255, 316, 15, 895], [2581, 370, 21, 4, 1175, 536, 4442, 15, 48, 236, 15, 47, 403, 37, 370], [66, 2473, 1], [4443, 83], [84, 513, 221, 1977, 49, 589, 34, 29, 2515, 630, 27, 980, 374, 32, 816, 26, 44, 43, 164, 649, 33, 609, 980, 2299], [58, 95, 44, 2, 7075, 54, 16, 7076, 877, 12, 15, 120, 1544, 7, 49, 298, 423], [29, 13, 6, 56, 81, 519, 3810, 34, 6, 14, 1847, 7, 33, 18, 1610, 23, 44, 2, 466, 18, 12044], [219, 88, 27, 32, 3022, 12045, 28, 143, 12046, 54, 97, 161, 1], [104, 12047, 5, 131, 466], [411, 56], [349, 4, 3229, 1], [20, 2, 141, 83], [3, 13, 4, 115, 2, 95, 41, 11, 20, 12048], [245, 127, 95, 11, 261], [5, 12049, 244, 604, 14, 1028, 5371, 1318, 1724, 15, 2, 2529, 5372], [149, 15, 118, 126, 1011, 402, 661, 36, 1545, 13, 141, 12050], [1171, 1906, 5, 2, 9, 55], [241, 219, 227, 54, 7, 260, 46, 588, 5097, 6626], [1157, 186, 47, 113, 76, 199, 252, 7, 7098, 24, 47, 4, 237, 37, 44, 1148], [44, 5, 65, 630, 22, 12, 2181, 22, 12, 13, 642, 72, 52, 12, 93, 21, 4, 12051, 1792, 711, 356, 464], [52, 2, 24], [32, 292, 513, 3495, 140, 23, 8, 20, 12052, 1], [3493, 693, 42, 37, 214, 205, 2, 1875, 91, 425, 4891, 1420, 73, 711], [31, 5, 146, 1123, 42, 2, 89, 836, 42, 46, 2, 89, 1], [12053, 7, 47, 56], [58, 630, 2, 3002, 8, 466, 7, 35, 8, 313, 11, 4, 248], [766, 55, 10, 2011, 493, 12, 726, 55, 47, 7, 166, 175, 2, 1411], [5, 112, 2066, 386, 216, 159, 12, 45, 8, 3355, 99, 5173], [3, 13, 162, 174, 3817, 51], [136, 6, 14, 2261], [4279, 1499, 8, 1099, 174, 138, 11, 926, 949, 64, 15], [4, 570, 2189, 91, 28, 4, 949], [281, 4, 141, 45, 12054, 1051, 84, 166, 1], [1, 61, 512, 60, 466, 16, 12055, 1384, 2371, 258, 30], [55, 2659, 12, 2, 1, 34, 768, 12056, 12, 209, 2693, 130, 12057], [63, 19, 2, 203, 1, 14, 1557, 2, 3181], [34, 31, 66, 64, 361, 3, 300, 278, 64, 5, 1777, 1906, 1, 5, 165, 48, 14, 2898, 39, 1788, 588, 12, 82, 4, 2251], [22, 12, 3602, 7, 1, 136, 268, 1024], [3, 560, 13, 788, 2, 1, 678, 12, 12058], [3, 62, 282], [43, 52, 98, 1034, 26, 12, 13, 3, 44, 833, 437, 26, 75, 376, 7, 193, 42, 161, 1], [76, 1, 12059, 73, 19, 99], [5, 2, 9, 30, 1828, 22, 45, 316, 35, 2530, 37, 867, 18, 10, 3686], [180, 95, 180, 12060, 36, 156, 214, 149, 36, 101, 28, 2434, 469, 8, 7, 123, 126, 5373], [485, 52, 63, 79, 12061, 108, 35, 52, 29, 729, 17, 1046, 34, 96, 44, 4444], [146, 28, 10, 7099, 758, 51, 4, 6124, 88, 66, 167, 4, 180, 1187], [92, 918, 484, 2165], [36, 237, 48, 5374, 59, 22, 4076, 1, 12, 13, 2, 4213, 12062], [8, 49, 1716, 12063], [32, 4, 640, 319, 55], [23, 4, 409, 6, 157, 7, 1, 11, 2, 2190, 37, 5, 63, 3356, 54, 10, 3301, 55], [8, 15, 111, 13, 5, 7, 134, 263, 32, 2, 89, 226, 5, 49, 2, 1570, 864, 16, 45, 16, 2, 395, 2, 158, 12, 57, 5, 49], [252, 19, 12064, 249, 8, 10, 618, 12, 56], [7, 5375, 1496, 66, 32, 33, 382, 170], [12065, 12066, 12, 2, 1043, 30, 1], [5, 58, 15, 6, 263, 37, 1915, 12, 2, 83, 736, 2251, 243, 1987, 115, 1168], [93, 68, 5, 19, 1, 30], [57, 49, 5, 152, 58, 272, 778, 5, 54, 4, 489, 13, 12067, 839, 200, 6, 5, 285], [7, 1365, 5, 149, 32, 5, 58, 12, 1, 8, 12068], [128, 20, 33, 2, 171, 9, 7, 5103, 216, 3357, 333, 139, 20, 1555, 8, 43, 68, 279, 59, 5, 2639], [1616, 16, 1052, 30, 399], [5, 49, 48, 2, 12069, 49, 2, 24, 202, 723, 265, 204, 2, 670, 123, 192, 2, 12070, 12, 4, 4445, 5, 5376], [324, 95], [3, 86, 5, 198, 7100, 52, 2, 141, 1, 6, 4, 68, 573, 274, 5152, 12071, 21, 20, 931, 12072], [559, 14, 14, 2, 24, 630, 8, 79, 76, 54, 123, 250, 8, 215, 226, 1853, 12073, 97, 7101], [1411, 8, 168, 2039, 1312, 57, 4, 511, 1145, 1325, 33, 7083, 80, 138, 97, 158, 711], [118, 547, 21, 60, 166, 75, 806, 2630, 8, 1224, 76, 1853, 31, 5377, 427, 1041, 173, 7102, 1627, 14, 89], [76, 9, 49, 656], [74, 2, 12074, 950, 1], [2345, 2692], [5378, 52, 46, 1073, 11, 2421, 654, 74, 12075, 12076, 12, 344, 248], [10, 437, 12, 7, 3, 64, 89, 283], [8, 20, 2, 12077, 24], [52, 2, 1, 5, 198, 58, 15], [1, 80, 12078, 30, 3818, 102, 7, 12079, 275, 175, 26, 29, 43, 4, 6901, 50, 171, 30, 29, 1776], [72, 7, 45, 6, 10, 231, 7103, 5, 2, 1, 21, 525, 11, 2, 91, 42, 29, 62, 3023, 806, 80, 373, 45], [8, 139, 1112, 80, 2082, 231, 13, 4, 12080, 80, 1290, 1482, 30, 2393, 821, 21, 285], [43, 45, 5, 49, 57, 12081, 118, 79, 2, 1413, 732, 203, 73, 19, 8, 568, 6, 119, 1026, 522, 32, 4, 106, 171, 83], [24], [19, 35, 24], [278, 516, 191, 20, 12, 40, 2, 2329, 235, 9, 99, 8, 12, 20, 994, 73, 219, 278, 14, 1811, 6, 14, 11, 20, 2865], [2329, 235, 9, 75, 79, 621, 183, 139, 2091, 630, 3358], [37, 19, 589, 38, 2, 9, 12, 13, 2612, 575, 7104, 13, 637, 20, 645, 28, 472, 8, 58, 256, 59, 254], [5, 49, 2, 24, 461, 20, 743, 1, 73, 12082, 20, 803, 317, 110, 538, 4, 5379, 52, 405, 11, 20, 306, 1116, 24], [232, 13, 1382, 2853, 48, 12083], [2875, 1, 2875], [10, 734, 486, 71, 4, 77, 856, 8, 47, 13, 994, 47, 13, 4881, 7, 30, 917], [241, 42, 63, 381, 50, 54, 34, 29, 229, 7, 9, 43, 64, 31, 42, 58, 15, 27, 97, 802, 462], [37, 60, 16, 2346, 1, 87, 6, 2935, 35, 18, 12084, 6, 1720, 2346, 291, 35, 30, 395], [1028, 5148, 348, 2850, 1289, 860, 1324, 1295, 2107, 12085], [15, 4348, 5, 8, 32, 20, 1792, 228, 49, 183, 73, 7105, 8, 80, 24, 32, 1116], [344, 102, 4, 3819], [107, 6, 4, 3820, 16, 60, 144, 735, 537, 12086, 18, 4, 12087, 5, 189, 49, 5140], [516, 14, 98, 12088, 12089, 130, 28, 98, 1494, 18, 10, 208, 8, 61, 6, 12090], [141, 1043, 66, 198, 471, 84, 30, 6, 4446, 21, 2, 607, 449, 141, 1, 118, 107, 337, 26, 605, 4, 2306], [2528, 963, 30, 1, 25], [5196, 12, 2, 141, 1], [5, 12, 2, 9], [71, 49, 232, 178, 18, 4, 2099, 93, 2347], [71, 58, 232, 408, 65, 108, 18, 4447, 12091, 106, 27, 4, 412], [60, 704, 408, 122, 113, 17, 3755, 427, 16, 4, 237, 232, 16, 32, 106, 140, 52, 12, 33, 2, 12092, 369], [3, 721, 325, 207, 91, 63, 14, 16, 12093, 972, 143, 120, 91], [23, 48, 190, 23, 370], [2939, 23, 2, 1430, 292], [12094, 12095, 36, 41, 444, 7106, 15, 4, 7107, 5380, 100, 61, 6964], [52, 132, 467, 99, 209, 16, 7, 1096, 3664, 4434, 828], [7108, 118, 772, 295, 882, 82, 20, 12096, 241, 123, 4, 193, 4941, 1], [1060, 1902, 110, 12097, 2175, 186, 9, 3738, 12098, 3715, 124, 12099, 12100, 12101, 3283, 12102, 12103, 12104, 26, 12105, 12106], [151, 801, 82, 5381, 21, 5, 782], [57, 92, 1], [1079, 16, 1313, 426, 2003, 12107, 3673, 11, 12108, 15, 434, 14, 11, 2, 388, 12109, 8, 48, 11, 12110], [107, 129, 494], [403, 181, 5382, 18, 10, 12111], [12112, 929, 3341, 2681, 24], [1, 55], [19, 3, 65, 13, 1495, 51, 7, 56, 30, 1333], [24, 24, 24, 12113, 12114], [55, 3, 150, 13, 2, 1043, 1, 2662, 11, 135, 27, 32, 4, 480, 18], [1108, 660, 198, 14, 865, 21, 12115], [104, 12, 2, 775, 12116, 247, 315, 49, 48, 2191, 775, 7109, 28, 775, 7110], [1, 46, 45, 34, 9, 8, 843], [221, 4, 1213, 1589, 1460, 17, 2, 1, 75, 987, 31, 40, 533, 133, 5207], [7, 428, 12117, 140, 49, 2009, 120, 56, 69, 49, 32, 7111], [3, 210, 70, 6, 245, 178, 215, 3359, 33, 65, 15, 562, 4292, 458, 35, 27, 4, 232, 841, 16, 5383], [3, 299, 5, 118, 13, 170, 149, 16, 4, 5384, 34, 221, 52, 2, 104], [469, 12118, 5, 41, 1160, 6, 4, 2306, 12119, 35, 20, 5385, 163, 105, 157, 76, 108, 18, 74, 86, 59, 15], [5, 753, 17, 140, 5, 86, 20, 4, 45, 8, 168, 253, 1036, 6, 2759, 8, 88, 33, 753, 149, 20, 2, 24], [22, 1, 136, 1209, 3360], [1], [1, 151, 19, 5, 35], [128, 114, 102, 785, 12120, 75, 58, 45, 34, 70, 1553, 7112, 143, 101, 378, 2531, 34, 3, 636, 153, 132, 1806, 170, 147], [7, 9, 12, 13, 12121], [1, 5, 63, 175, 34, 48, 729], [12122, 10, 25, 108, 11, 4, 1], [12123, 167, 4, 7113, 3, 62, 2709, 3606, 8, 5386, 223, 122, 6, 167, 7, 9], [487, 547, 15, 720, 25, 24, 21, 1505, 2, 418, 8, 7114, 876], [4, 193, 52, 742, 59, 19, 10, 1, 26, 12124, 59, 44, 127, 169, 130, 17, 12, 37, 1182, 15, 284], [3, 300, 855, 9, 33, 70, 35, 1611, 92], [3, 122, 68, 16, 76, 2332, 12125, 1402, 163, 3, 300, 15, 578, 13, 2304, 12126, 191, 55], [242, 80, 9, 30, 35], [55, 947, 15, 124, 6, 14, 68, 16, 10, 206, 1], [36, 48, 5387, 1088, 149, 36, 11, 4, 3237, 9, 55, 55], [4228, 394, 66, 11, 7, 1, 99], [295, 72, 1698, 13, 2, 187, 12127], [15, 12, 1], [65, 13, 20, 152, 665, 217, 181], [6791, 9], [2573, 8, 92, 66, 4091, 5, 120, 1, 1240, 13, 2, 813, 645], [7, 47, 43, 2465, 425, 39, 9, 1174, 14, 1267, 12128], [5388, 5, 44, 4, 1067, 388, 12129, 4, 3541, 12, 48, 12130, 93, 21, 12131, 12132, 1246], [15, 4, 1119, 2378, 12133, 374, 104], [3, 273, 42, 183, 25, 28, 1, 379, 3, 1373, 42, 197, 97, 1579, 55], [93, 401, 390, 5, 87, 6, 119, 60, 353, 12134, 139, 313, 35], [8, 20, 2, 19, 12135, 609, 388, 1066, 5, 96, 1532, 6, 249, 20, 373, 138, 5, 75, 5, 12136, 99, 7115], [3, 41, 2, 1, 226, 1972, 24, 1972, 300, 3, 146, 72, 15, 361, 24, 1972, 10, 161, 431, 2671, 1, 40, 82, 143, 3821], [19, 5, 24, 2032, 3, 216, 2, 2638, 8, 192, 4448, 12137, 129, 890, 7116, 22, 449, 2032, 19], [12138, 242, 35, 1, 26, 3, 12139, 70, 5, 39], [394, 9], [432, 1465, 1877, 18, 291, 1], [5, 585, 5389, 30, 9], [403, 151, 338, 12140, 99, 241, 31, 3, 28, 2, 401, 18, 4, 699, 3, 318, 420, 108, 149, 278, 468, 54, 18, 320, 16, 169, 303, 1683], [32, 1740, 8, 643, 9, 253, 10, 91], [15, 51, 20, 331, 1], [119, 80, 4449, 1], [1470, 229, 7, 20, 2, 104], [3573, 889, 12141, 12142, 2122], [57, 2, 12143, 427, 7, 1, 11, 12144], [5390, 12145, 165, 316, 17, 32, 4, 348, 182], [29, 609, 17, 104, 5350], [29, 5, 44, 2, 56, 63], [1898, 7, 20, 779, 210, 1226, 5, 48, 6, 79, 287, 12146, 219, 66, 32, 46, 7, 4964, 3, 3604], [242, 35, 104, 5, 8, 4450, 87, 6, 70, 98, 1623, 612, 219, 4450, 976, 102, 5, 210, 2688], [91, 60, 16, 39, 1, 49, 11, 3594, 59, 254], [57, 633, 17, 102, 12, 73, 1693, 66, 1105, 275, 285, 71, 5, 223, 1105, 20, 373, 28, 214, 8, 2223, 15, 1394, 140, 5, 44, 2, 3212], [39, 12147, 2954, 2040, 7117, 123, 1601, 22, 2348, 57, 47, 126, 12148, 36, 33, 2040, 126, 12149], [379, 1095, 274, 11, 3352, 271, 172, 1], [20, 1588, 21, 10, 12150, 322, 209, 291, 12151, 8, 216, 15, 1064, 589, 8, 726], [5391, 29, 70, 2, 9, 2, 2255], [1, 766, 25, 42, 220, 6, 626, 6, 137], [5, 33, 75, 134, 837, 98, 7118, 1930, 12152, 15, 155, 817], [101, 104, 484, 741], [55, 1, 80, 7109, 226], [61, 2600, 102, 6, 12153, 711], [251, 57, 329, 125, 42, 236], [6862, 5, 29, 259, 142, 135, 3, 3604, 66, 96, 41, 4451, 7, 652, 1720, 82, 159, 8, 12154], [43, 3, 29, 19, 27, 212, 9, 191, 12155, 52, 277], [36, 210, 67, 6, 19, 1824, 7, 1, 128], [12156, 12157, 29, 3813, 96, 762, 1, 54], [12158, 12159, 13, 12160, 445, 12161, 49, 1579, 18, 2, 12162, 4233, 155, 12163, 8, 12164, 16, 926, 12165], [40, 2, 187], [12166, 57, 12, 4, 979, 150, 16, 4, 3822, 7, 5, 62, 11, 3343, 6, 4, 1067, 7119, 1248, 6, 76, 74, 48], [204, 4, 490], [4, 187, 87, 50, 402, 311, 102], [29, 878, 174, 402, 6, 17, 145], [10, 145, 10, 145, 55], [43, 437, 10, 145], [47, 93, 10, 145, 55], [1287, 145], [92, 12167, 95, 12, 68, 16, 274, 4034, 2988], [79, 54, 1], [119, 385, 69, 49, 5, 197, 21, 5, 2329, 83], [66, 318, 44, 2760, 75, 109, 14, 5170, 34, 60, 804, 141, 95, 121, 7, 318, 14, 2, 12168, 271, 12169, 7120], [95, 16, 2, 7121, 5, 397, 27, 12170, 3, 397, 27, 12171], [474, 4352, 1053, 12, 248], [1975, 3, 118, 72, 40, 456, 44, 2, 434, 24, 34, 371, 289, 297, 15, 7, 48, 573, 37, 552, 57, 15, 1437], [4452, 103, 70, 7122, 15, 1], [221, 37, 5, 165, 137, 27, 17, 97, 158], [278, 1346, 5, 31, 5, 440, 17, 27, 759, 466], [22, 587, 66, 44, 61, 224, 305, 141, 1307, 975, 124, 59, 416, 3, 62, 1020, 11, 126, 331, 21, 165, 130, 2, 2501, 271, 219], [509, 4453, 1650, 20, 12172, 2917, 121, 474, 66, 12173, 12, 4, 101, 2420, 1088, 216], [20, 48, 37, 12174, 211, 32, 42, 172, 388, 12175], [12176, 15, 1437, 5, 49, 12177, 35, 10, 1747, 5392], [19, 20, 1333, 1], [5, 12178, 52, 122, 6, 236, 6, 7123, 52, 200, 1591, 52, 2210, 254, 52, 12, 43, 434, 12179], [51, 4, 12180, 16, 4, 1317, 596, 1344, 4, 1094, 6938, 2698, 6, 28, 459, 7123, 488, 49, 2, 83], [55, 1, 25, 272, 28, 10, 315, 774, 18, 5], [1063], [7, 56, 15, 7124], [1906, 2511, 1170, 997, 220, 608, 123, 1033, 48, 1108, 8, 3361, 47, 2, 1108], [367, 143, 1589, 143, 12181, 12182, 47, 2, 2606, 3669, 52, 2062, 2212, 398, 7125, 2592], [37, 5, 608, 12183, 107, 135, 8, 1624, 3024, 4291, 732, 651, 7, 1], [2, 1105, 7, 47, 4454, 123, 642, 69, 135, 317, 94, 4, 7126, 19, 2966, 1], [403, 12184, 277, 20, 3170, 114, 54, 4, 56, 21, 5, 12185], [4455, 4, 199, 12186, 69, 121, 572, 1861, 82, 6419, 12, 529, 447, 117, 43, 278, 43, 946, 1, 1052, 5084], [20, 954, 710, 1299, 33, 1606, 254, 2, 154, 702, 479, 18, 2, 1224], [72, 4, 7127, 2040, 12187, 128], [104], [6227, 4, 1895, 72, 2406, 14, 2, 1, 135, 60, 12188, 5393, 28, 240, 2026], [169, 347, 8, 5394, 8, 4, 319, 649, 52, 33, 67, 14, 1875, 55], [22, 60, 908, 83, 229, 4047, 12189], [65, 51, 22, 45, 571, 1, 1896], [33, 6, 1093, 78, 218, 9, 14, 208, 13, 36, 29, 62], [37, 209, 9], [3, 47, 947, 719, 7, 1], [667, 1, 7, 65, 93, 162, 277, 2, 91, 270, 73, 531, 479, 35, 68, 16, 212], [2694, 52, 2, 104, 8, 3, 29, 13, 1167, 2936, 23, 18, 4, 166, 234, 16, 4, 2853], [7, 25, 12190, 224, 11, 4, 285], [10, 1288, 14, 2, 3216, 181, 12, 2, 686, 1288, 1222], [290, 17, 83], [3, 150, 4, 1097, 12191], [2950, 6, 5, 10, 507, 12, 11, 7128, 919, 17, 288, 3, 114, 54, 4, 56], [123, 56, 3, 1456, 42, 805], [112, 45, 280, 80, 9, 273, 17, 31, 12192, 1065, 124, 12193, 3, 2036, 19], [622, 911, 66, 257, 78, 7, 13, 2, 1439, 91, 79, 2, 12194, 56], [1, 66, 2063, 132, 51, 4, 1333, 65], [718, 2078, 2997, 3, 62, 60, 111, 7, 103, 64, 22], [3823, 1042, 225, 312], [12195, 35, 312, 3, 146, 154, 518, 12196, 262, 17], [5, 63, 3362, 22, 138, 104], [20, 1, 79, 40, 47, 346, 22, 138], [19, 459, 135, 104, 7, 452, 110, 14, 2, 1847], [695, 1413, 312, 1902, 859, 1419, 41, 327], [1, 333], [63, 66, 48, 168, 4, 324, 104], [1, 5, 41, 17, 19, 35], [1, 5, 156, 1500, 128], [12197, 3, 299, 3, 41, 2, 436, 34, 3, 479, 2, 3106, 23, 1886, 39, 323, 720, 176, 15, 107], [411, 1], [222, 28, 470, 2, 1130, 102, 17, 12198, 410, 20, 961, 275, 253, 8, 654, 71, 209, 1502, 389, 21, 126, 24], [12199, 144], [465, 7, 5, 171, 1, 52, 121, 43, 68, 13, 5], [1, 3, 67, 15, 32], [721, 5, 222, 28, 20, 1697, 7125, 16, 3621, 104], [403, 104, 1175, 104, 117, 5, 12200], [242, 4, 19, 35, 181, 151, 257, 4, 45, 459, 5], [221, 25, 3, 28, 1, 8, 3335, 19, 315, 73, 45], [23, 48, 365, 1, 563, 17, 211, 261, 88, 25], [149, 272, 12201, 4, 45, 459, 5, 145], [19, 5, 1, 3695], [281, 1], [1937, 209, 157, 32, 5, 2532, 11, 68, 2974, 19, 1496, 252, 278, 2909, 5, 5, 104], [33, 1921, 7, 2663, 366, 8, 172, 20, 1, 7129], [242, 35, 2284], [2192, 253, 17, 5, 445, 1, 5, 75, 58, 45, 37, 411, 104], [88, 683, 6, 509, 1], [69, 58, 5, 86, 3, 195, 1], [59, 4, 1493, 34, 719, 10, 7130, 34, 42, 652, 2141, 74, 365], [55, 5, 415, 1777, 19, 5, 1, 7131, 12202], [3, 156, 67, 6, 569, 6, 574, 3, 1514, 27, 18, 186, 34, 36, 156, 65, 51, 17, 13, 757, 552, 5, 11, 112, 12203, 251], [40, 375, 4, 138, 55, 8, 67, 15, 1404, 3, 3824, 5, 512, 2, 1, 31, 40, 229, 562, 40, 318, 1396], [3025, 1], [3, 90, 95, 36, 33, 633, 17, 102, 59, 4, 488, 7, 3, 75, 635], [3, 13, 175, 5, 13, 1305, 233, 1497, 622, 46, 81, 6, 32, 80, 9, 3, 14, 6984, 151, 2761], [23, 515, 16, 147, 1, 3825], [32, 4, 434, 3347, 4200, 793, 4368, 12204, 31, 42, 12205, 2533, 30, 52, 276, 1479, 54], [15, 156, 2, 120, 1, 58, 256, 2175, 55, 13, 36, 134, 1527, 19, 38, 15, 107, 6, 138], [7, 120, 1, 12, 2, 1080, 21, 12206, 7, 413, 493, 16, 25], [272, 346, 3826, 8, 2155, 8, 1908, 205, 36, 220, 322, 431, 6, 17, 38, 3, 47, 116, 272, 257, 4456, 1, 30, 155, 115], [281, 3, 47, 59, 6, 4234, 148, 3, 33, 79, 5, 2, 89, 1, 3, 196, 196, 1, 425], [559, 168, 323, 1788, 494], [12207, 12, 165, 130, 80, 24, 30], [1, 15, 48, 1062, 1903], [12208, 15, 1883, 543, 15, 35, 2, 12209, 106, 6, 257, 4, 12210], [101, 93, 184, 59, 22, 3359, 26], [1228, 29, 690, 11, 2750, 1036, 91], [8, 66, 32, 976, 1922], [61, 423, 330], [427, 7, 698, 16, 72, 4, 266, 70, 15, 6, 4, 360, 1957, 55], [415, 106, 6, 157, 22, 186, 1090, 6, 618], [412, 249], [1035], [24, 194, 15, 4457, 2125, 1161, 12211, 12212, 12213], [193, 166, 9, 1567], [766, 4458, 56], [3, 90, 7, 104, 52, 37, 1490], [3825, 953, 11, 1652, 64, 126, 314, 261, 1554, 9], [221, 111, 62, 52, 48, 56, 34, 84, 178, 12, 2148, 8, 15, 229, 713, 11, 178, 641, 7132], [193, 6, 114, 748, 13, 2, 141, 1, 1], [337, 490], [1, 165, 194, 54, 140, 220, 298, 4, 1879, 390], [403, 471, 17, 20, 323, 3, 87, 6, 157, 76, 9, 18, 2, 3712, 8, 1467, 240, 38, 3, 498, 224], [3, 67, 10, 2332, 108, 425], [3, 47, 1348, 190], [3, 5395, 5, 105, 62, 40, 600, 44, 132, 2020, 6, 28, 405, 70, 50, 24, 631, 12214, 40, 791, 170, 117, 211], [736, 216, 97, 119, 12215], [23, 284, 8, 1441, 63, 742, 59, 24, 292, 323, 11, 2, 3363], [55, 12216, 39, 1, 12217], [41, 17, 1596, 13, 46, 1923, 41, 17, 542, 6, 79, 4, 143, 910], [3309, 1, 622, 156, 12218, 622, 603, 41, 50, 150, 505], [4, 19, 143, 827, 1, 125, 1158, 7133, 35, 2959, 58], [3, 301, 5, 1932, 13, 2, 1308, 11, 22, 83], [3, 301, 5, 1932, 13, 2, 1308, 11, 22, 1], [315, 181], [13, 2, 1308, 11, 22, 1, 12219], [1002, 7, 1, 330, 41, 722, 3364, 11, 12220, 50, 35, 33, 223, 7134, 2760], [153, 810, 622], [55, 471, 147, 153, 656, 54, 2041, 60, 163, 57, 31, 52, 109, 12], [3, 121, 24, 147, 30, 57, 14, 18, 80, 1200, 177], [55, 143, 101, 540, 3, 75, 81, 133, 143, 2336, 12, 218, 10, 153, 505, 163, 46, 137, 32, 1164], [87, 6, 192, 5011, 140, 2594, 101, 512, 100, 170, 137, 27, 95], [326, 11, 5396, 12221, 12222, 38, 5, 2333, 2193, 52, 2503, 60, 5397, 12223, 7135, 45, 1002, 201, 511, 207, 12224], [10, 5398, 1744, 381, 68, 6843, 103, 157, 2, 5399, 11, 4, 1556, 8, 7, 47, 7136, 54, 16, 4, 24, 767], [9, 4926, 363, 102], [45, 151, 389, 4, 12225, 6, 28, 423, 82, 39, 393, 30, 9], [1], [300, 6, 274, 2489, 18, 3026, 23, 448, 4, 1228, 18, 155, 685, 1848, 5, 1, 30, 25], [336, 52, 24, 52, 266], [2517, 203, 1], [217, 273, 17, 218, 60, 574, 13, 6, 168, 15, 73, 1, 60, 275, 29, 13, 14, 79, 275, 34, 5239, 4795], [68, 549, 1], [4, 141, 77, 782, 12226, 28, 941, 11, 4, 5400, 1738, 27, 3827, 852, 8, 603, 2754, 3827, 852, 309, 8, 36, 258, 84, 3124], [66, 114, 20, 1, 88, 12227, 235, 82, 20, 306], [2435, 2435, 233, 1867, 97, 30, 35, 153], [2375, 3, 64, 71, 5, 79, 630, 2, 659, 34, 43, 3704, 5, 452, 182, 359, 18, 2, 77, 1, 49, 37, 4306], [640, 9], [36, 41, 60, 587, 120, 9, 11, 12228, 205, 29, 36, 117, 116, 18, 4, 1692, 12229], [3, 79, 111, 2954, 8, 2, 320, 16, 19], [640, 9], [5, 24], [55, 353], [43, 3, 13, 24, 85, 118, 3, 14, 1811, 16, 7], [3517, 157, 10, 235, 18, 181, 12, 48, 12230], [4, 19, 523, 42, 81, 59, 3, 273, 42, 469, 8, 195, 61, 6, 113, 42, 641, 25, 3, 64, 120, 1, 3356, 280], [66, 146, 58, 51, 577, 292, 8, 405, 76, 1, 11, 13, 201, 707, 12231, 74, 60, 45], [23, 383, 2250, 1244, 54, 38, 32, 384, 153, 47, 612, 13, 147], [714, 10, 2479, 24, 6619], [1, 238, 28, 11, 21, 351, 2040, 163, 45, 805, 3, 94, 5, 11, 794, 311], [119, 1], [563, 35, 119, 1], [563, 35, 37, 3, 63, 1361, 1866, 80, 1, 30], [576, 25, 57, 35, 27, 240, 402, 57, 582, 6, 4, 45, 5, 47, 81, 2, 535, 2, 707, 892, 119, 1], [3322, 8, 1891, 2720, 9], [71, 12, 52, 614, 6, 1252, 1, 11, 2, 5401, 464], [5, 103, 8, 52, 152, 28, 32, 384, 1], [181], [1621, 551, 3324, 262, 105, 12232, 403, 411, 23, 107, 2260, 3828, 23, 135, 107, 4, 19, 619, 1], [181], [71, 59, 5, 410, 17, 1], [55, 1, 23, 5402, 5, 2175], [219, 51, 577, 31, 20, 61, 6, 58, 12233, 5, 58, 1770, 8, 29, 1, 3829, 110, 38, 15, 4, 329, 184], [1210, 898, 12, 58, 5, 400, 11, 4, 1825, 8, 345, 38, 5, 477, 6, 170, 425, 24, 138, 3027, 71, 898, 968, 578, 711], [431, 431, 19, 125, 42, 99, 153], [640, 30, 9, 61, 6, 376], [280, 42, 56, 51, 7, 4390], [57, 582, 6, 61, 1127, 1], [31, 15, 12234, 3, 227, 24, 55], [43, 9], [446, 2, 12235, 98, 1], [1, 3, 309, 38, 3, 509, 760], [1, 7137, 5, 6697], [425, 1, 47, 3, 81, 6, 5], [4221, 83, 12236], [836, 37, 36, 75, 555, 2, 112, 25, 142, 996, 7138, 321, 191, 779, 6, 389, 22, 1683, 996, 17], [5, 37, 19, 3365, 5, 41, 3292, 6, 4, 329, 285, 23, 113, 5, 394, 48, 182, 605, 17, 361, 23, 421, 35, 4459, 42], [4213, 201, 56, 7139, 4213, 292, 124, 2167, 12237], [3603, 23, 99, 209, 16, 2, 1, 6, 259, 102, 12238, 3, 28, 1810, 8, 452, 67, 6, 484, 337, 513], [20, 406, 70, 5, 65, 13, 2, 686, 1298, 55], [160, 55, 15, 1756, 7, 2, 9, 63, 557, 5, 4, 117, 193, 34, 103, 40, 64, 5, 4, 117, 193, 988, 2, 9, 103, 14, 2, 282], [160, 55, 33, 86, 59, 15, 116, 12, 2, 117, 193, 26, 2, 329, 193, 6, 64, 4460, 2, 9, 600, 33, 64, 5, 21, 57, 5, 4461], [78, 49, 32, 141, 1043, 30, 1, 277], [364, 58, 3, 65, 13, 5403, 1, 74, 57, 3203], [52, 198, 3, 41, 515, 16, 465, 71, 52, 63, 119, 24, 5404, 193, 13, 148], [289, 4815, 3, 156, 167, 12239, 8, 119, 6957, 2178, 354, 140, 3, 75, 1244, 54, 212, 12240, 55], [12241, 85, 1118, 10, 5405, 482, 205, 5406, 85, 42, 19, 35, 9], [65, 51, 57, 5, 33, 121, 2042, 154, 4262, 77, 680, 204, 1, 596, 698, 233, 6395, 1081], [48, 57, 3, 121, 26, 3, 67, 2, 2335, 6, 1223, 4, 1345, 1804, 21, 126, 373, 168, 4, 496, 276, 14, 171, 144, 27, 4, 7140, 12242], [3507, 357, 41, 43, 106, 972, 12243, 12244, 202, 462, 3128], [7, 85, 66, 124, 885, 1321, 658, 12245], [19, 32, 5, 319, 55], [15, 1008, 1, 2534], [104, 206, 111, 111, 69, 75, 484, 551, 111], [19, 5407, 12246, 388, 30, 52, 12247, 52, 29, 134, 2, 148, 55, 52, 14, 18, 2852, 208, 13, 52, 4, 45], [604, 70, 4, 412, 76, 25, 248, 55], [48, 110, 362, 280, 23, 609, 39, 505, 1, 12248], [15, 2, 323, 432, 636, 693, 52, 1191, 6, 84, 1152, 436, 73, 2, 1], [1, 64, 60, 1285, 82, 2176], [495, 65, 13, 4, 309, 18, 4, 250, 6217, 18, 567, 95, 55], [108, 102, 97, 494, 558], [3, 146, 258, 76, 3, 62, 2663, 41, 76, 9], [805, 177, 299, 52, 7141, 32, 409, 16, 117, 1175, 7, 9], [4, 95, 223, 298, 82, 20, 30], [7142, 3366, 12, 2, 611, 12249, 107, 18, 122, 361, 2507, 3202, 12, 4, 247, 12250, 185, 2319], [145, 23, 48, 80, 161, 280, 4, 19], [57, 145], [23, 4287, 46, 614, 6, 14, 43, 93, 3028], [17, 1], [12251, 7, 10, 1], [12252, 841, 16, 32, 50, 323, 49, 428, 93, 1945, 6, 4, 166, 56, 12253, 40, 270, 2, 12254, 526], [7, 9, 129, 7], [411, 27, 7, 57, 23, 152, 58, 8, 33, 19, 241, 24, 1401, 25], [195, 4, 1, 34, 42, 4, 68, 2298, 81, 411, 8, 14, 133, 45, 9, 30, 25], [3, 121, 3, 47, 82, 162, 139, 157, 324, 11, 10, 476, 7, 256, 2, 1, 118, 58], [3, 29, 41, 245, 990, 27, 5, 34, 113, 80, 177, 1285, 6, 139, 208, 13, 1, 8, 316, 84, 1438, 30, 35, 1184], [69, 422, 12255, 660, 743, 879, 5138, 12256, 286, 110, 19, 5323], [158], [346, 5, 1], [4371, 72, 20, 98, 1893, 83], [181], [3, 716, 1244, 2, 161, 1102, 38, 42, 121, 1, 42, 342], [309, 241, 83, 3165, 10, 7143, 50, 215, 4262, 47, 12257, 6845, 7144, 2889, 7145, 2688], [1, 32, 39, 834, 1, 27, 36, 30, 54, 18, 886, 58, 57, 5, 67], [52, 87, 6, 438, 2, 994, 23, 99, 2281, 35, 21, 84, 161, 24, 30, 280, 8, 3, 79, 170, 161, 260, 226, 13, 564, 26, 7146], [12, 4, 2166, 1, 54, 135, 945], [29, 471, 17, 212, 874, 66, 5408, 35, 18, 143, 1634, 10, 916, 41, 143, 7147, 5408, 1710, 4913, 972, 2, 24, 177, 12258, 17], [28, 4, 12259, 7148, 54, 147, 1, 31, 42, 3029], [25, 139, 1500, 1, 14, 1596, 12260, 2436, 163, 268, 31, 42, 86, 384, 1, 216, 25, 41, 80, 108, 42, 1921, 180, 1329, 45], [24], [9, 622, 7149, 1], [61, 6, 376, 145, 55], [55, 497, 24], [358, 761, 55, 34, 289, 346, 5, 104], [26, 128, 26, 9, 1037, 2512, 527, 7150, 36, 300, 36, 465, 20, 3008, 11, 155, 12261, 3, 192, 168, 12262, 26], [3, 29, 44, 245, 437, 27, 12263, 34, 5, 598, 13, 2, 104], [492, 5, 2, 5409], [29, 113, 4, 171, 9, 7], [3, 195, 1064, 12264, 1, 12, 2349], [23, 128, 996, 112, 218, 3, 109, 486, 50, 313, 147, 1, 11, 2, 2120, 55], [1, 23, 6324, 4462, 3, 58, 57, 3, 67], [5406, 181], [1], [52, 2, 104], [158, 1687], [7, 573, 552, 85, 20, 110, 11, 22, 2535, 5, 171, 158, 701, 835], [3, 63, 532, 20, 860, 813, 30, 2, 1634, 423, 1587, 8, 656, 20, 530, 30, 1340, 590, 1], [128, 5, 185, 158], [5257, 23, 556, 167, 7, 9], [71, 239, 106, 200, 5, 477, 6, 7, 24, 323, 225], [60, 9, 45], [5, 456, 44, 1415, 2, 95, 79, 140, 3, 210, 28, 45], [286, 576, 19, 76, 1, 1759, 76, 117], [109, 2310, 23, 65, 13, 5410, 7151, 11, 22, 1], [34, 88, 36, 121, 2229, 336, 174, 12265, 34, 252, 23, 28, 6, 14, 2, 2536, 1, 44, 5, 48, 704, 17], [1, 42, 62, 57, 3, 196, 1175, 4463, 39, 879], [447, 3, 911, 3, 47, 533, 6, 2, 7152, 104], [20, 1246, 63, 438, 22, 141, 181, 558], [7, 9, 75, 867], [1, 139, 90, 18, 270, 98, 12266, 12267], [10, 457, 12268, 330, 433, 27, 141, 6, 43, 12269, 2028, 934, 20, 115, 8, 14, 1236, 83], [5, 2, 112, 1, 21, 7], [5, 2058, 8, 272, 100, 7, 1, 1099, 117, 92, 33, 14, 18, 12270], [24], [114, 13, 12271, 1, 756, 6, 688, 211, 257, 3830, 678, 46, 7, 7153], [55, 10, 280, 121, 15, 59, 2, 1, 34, 15, 63, 14, 59, 42], [104], [3, 87, 201, 16, 4, 1], [1676, 5, 220, 24], [12272, 1, 105, 58, 66, 279, 2817, 96, 5411], [20, 2, 104], [23, 3248, 5, 664, 55], [43, 3, 29, 345, 23, 48, 2, 12273, 3, 47, 33, 633, 140, 4, 670, 47, 122, 6, 1338, 17, 27, 2, 1556, 666, 16, 908, 1145], [403, 181, 3, 2251, 5], [24], [1667, 5019, 3, 514, 10, 3367, 433, 92, 3, 75, 110, 958, 15, 7154, 67, 17, 6, 61, 28, 246, 68, 110, 205, 40, 62, 17], [199, 13, 1, 15, 4, 1784, 6, 168, 4, 2458, 100, 574, 28, 18], [91, 1, 195, 48, 152, 58, 2, 148, 1162, 31, 42, 29, 13, 57, 3, 41, 6, 72, 88, 753, 17], [191, 20, 177, 3030, 12274, 12, 52, 96, 238, 6, 28, 84, 68, 18, 68, 8, 693, 52, 572, 17, 177], [370, 3, 119, 24], [19, 1, 28, 169], [3, 62, 2028, 57, 12275, 121, 407, 2, 308, 720, 22, 189, 86, 12, 2, 2944, 11, 12276, 12277, 84, 451, 12, 56, 48, 4, 7155, 16, 230], [1325, 3, 118, 14, 2, 1, 31, 3, 41, 76, 328], [1171, 48, 51, 32, 34, 23, 861, 11, 2, 331, 392, 16, 19, 158, 547, 17, 5412], [101, 38, 174, 224, 17, 146, 176, 147, 7156, 6, 176, 2009, 158, 423], [74, 5, 62, 5, 222, 33, 61, 467, 4464, 1], [281, 10, 25, 5413, 513, 3, 75, 304, 6, 5414, 13, 2, 12278, 9, 22, 850, 281, 1325], [945, 17, 6, 12279, 3, 363, 6, 4, 401, 1876, 314, 88, 2, 1, 344, 1116, 13, 12280, 281, 387, 355, 88, 2, 9], [26, 1, 29, 81, 51, 17, 13, 7, 1669], [177, 96, 41, 95, 11, 4, 3254, 55], [471, 7, 9], [52, 132, 114, 76, 9, 55], [242, 35, 158], [55, 3169, 220, 2191], [52, 672, 10, 24, 3, 7157], [3, 33, 486, 2, 89, 1, 18, 135, 82, 663, 12281, 8, 150, 11, 64], [9, 2064], [3, 1456, 1, 3, 195, 2757], [58, 5, 1, 177], [43, 1, 596, 10, 138], [410, 7, 1], [417, 3368, 104], [2161, 1193, 70, 2, 2380, 139, 11, 5415, 6, 999, 1], [52, 13, 7, 9], [57, 7, 9, 47, 13], [29, 14, 2, 83, 28, 12282], [281, 3831, 200, 97, 167, 7, 9], [91, 316, 80, 1, 30, 135, 432, 134, 2, 1301, 133, 80, 663, 764], [42, 165, 400, 80, 30, 11, 7, 1, 1062, 12283], [190, 1173, 202, 1324, 8, 4147, 3310, 2537], [48, 12284], [211, 5, 1624, 7, 5288, 16, 174, 6, 7, 120, 381, 52, 26, 4, 93, 802, 177, 220, 12285, 18, 172, 2, 269], [42, 201, 514, 4382, 29, 62, 385, 338, 76, 158, 771, 42, 63, 683, 256, 1782, 71, 36, 13], [100, 68, 16, 76, 5416, 112, 158, 381, 430, 254, 346, 12286, 29, 67, 7, 593, 45], [1, 28, 7, 401, 3572], [1, 33, 14, 65, 21, 10, 385], [83], [177, 3, 47, 656, 11, 76, 283], [101, 31, 15, 356, 175, 59, 4465, 158], [836, 23, 214, 51, 5, 21, 491, 17], [1, 103, 434, 4907, 24, 156, 70, 5, 168, 12287, 99, 239, 530, 138, 25, 54, 135], [60, 25, 210, 12288, 6, 44, 7, 1, 11, 4, 250, 507], [2140, 64, 6, 70, 240, 3832, 6, 10, 768, 1, 64, 2738, 3369], [164, 46, 45, 34, 1, 8, 169, 3, 433, 7, 441, 13, 3, 1470], [15, 56, 1676, 33, 67, 6, 19, 27, 12289], [725, 285], [100, 19, 12290, 1, 51, 3311, 8, 4466], [12291, 154, 202, 7158, 353, 5123, 5124, 6, 4, 3820], [3808], [3, 195, 505, 12292, 11, 15, 369, 19, 1908, 7, 1], [1, 28, 929, 364, 54, 55], [1, 42, 41, 17, 19, 35], [1, 114, 147, 45, 142, 12293], [1, 42, 6789, 15, 533, 59, 10, 730, 8, 45, 194, 54], [1, 42, 41, 17, 19, 35, 61, 249, 161, 1781, 12294, 13, 42, 156, 58, 18, 1903, 8, 928, 210, 86, 1676, 200, 42], [1675, 1, 80, 3758, 30, 131, 119, 10, 24, 8, 3, 41, 60, 2485, 606, 177, 147, 42, 63, 249, 35, 1573, 1082], [576, 19, 42, 1, 8, 61, 249, 35, 6887], [422, 1, 148, 3, 103, 23, 48, 110, 12295, 10, 310, 33, 309], [281, 7, 9, 61, 332, 945], [4, 1, 11, 4, 2016, 752, 8, 12296, 257], [243, 457, 89, 1], [3, 7159, 12297, 3, 29, 110, 62, 71, 6, 168, 22, 385, 71, 3, 1588, 10, 2161, 18, 22, 9], [23, 1973, 163, 3, 90, 4308, 2, 365, 30, 187], [241, 242, 20, 476, 3, 47, 533, 59, 4, 561, 5, 181], [43, 7, 19, 144, 49, 5, 467, 390, 74, 48], [3, 33, 1866, 20, 30, 85, 5, 5417, 24], [281, 5, 220, 7, 1, 18, 305, 412], [19, 2, 12298, 44, 501, 27, 7, 38, 4, 718, 1332, 18, 5, 211, 12299, 1634], [107, 82, 2, 189, 3000, 508, 12300, 6, 14, 12301, 12, 14, 4, 811, 5379, 2988], [650, 1, 12, 2, 324, 21, 1772, 36, 49, 329], [23, 428, 27, 10, 177, 117, 615, 20, 12302, 30, 12, 27, 20, 306, 26, 586, 194, 12303, 70, 5, 84, 1], [1652, 47, 503, 2043, 11, 12304, 2377, 288, 6460, 220, 1184, 4, 12305, 1979, 95, 118, 64, 2, 3117], [91, 19, 22, 1], [117, 550, 1], [12, 141, 1, 98, 1393, 218, 23, 150, 1770], [160, 66, 58, 48, 67, 5, 135, 519, 249, 10, 1072, 5418, 5, 1433, 12306, 28, 4, 7160, 54, 8, 61, 108, 6, 20, 12307, 164], [3, 47, 13, 1539, 1, 165, 12308, 241, 403, 5177], [45, 3, 301, 15, 47, 685, 1273, 21, 17, 6, 257, 60, 16, 39, 1, 7161, 128], [11, 7162, 295, 61, 18, 295, 6, 58, 295, 6, 1, 59, 607, 997], [12309, 1989, 219, 58, 15, 180], [5, 330, 62, 1151, 371, 2248, 940, 289, 132, 1976, 9], [105, 3693, 99, 209, 1108, 388, 2334, 1946, 611, 971, 3602], [1171, 15, 2, 1067, 168, 6, 382, 660, 2757, 13, 32, 1058, 16, 350, 165, 1640, 244, 106, 12310], [11, 27, 4, 61, 6, 1211, 54, 27, 4, 89, 1211, 8, 162, 10, 244, 348], [1, 415, 655, 15, 55], [3007, 12311, 559, 14, 2240, 1145, 13, 3833, 314, 35, 11, 22, 1], [969, 91, 7163, 1326, 839, 142, 374, 1139, 24, 37, 36, 1344, 4, 7164, 6, 12312, 126, 669, 2121], [24], [85, 49, 5, 528, 26, 7, 5, 9], [536, 1278, 18, 4, 1825, 16, 1968, 12313, 8, 12314, 15, 1117, 4, 12315, 21, 1635, 4049], [576, 252, 3, 301, 374, 120, 56], [827, 2, 104], [127, 130, 5, 298, 24], [299, 6, 531, 12316, 41, 10, 30, 541, 13, 2, 1172], [97, 148, 117, 2308, 717], [338, 391], [411, 20, 2, 24, 400, 20, 30, 142, 27, 32, 7, 3370], [989, 6, 701, 9], [151, 134, 5, 2, 1011, 5419, 16, 4, 183, 95, 69, 869, 747, 4467, 7165, 5113], [583, 20, 13, 292, 213, 713, 1], [24], [80, 181, 12317], [400, 135, 81, 59, 57, 42, 118, 58, 74, 152, 58, 7, 256, 10, 1, 277], [1, 57], [552, 3, 363, 6, 6, 4, 261, 13, 2, 449, 892, 8, 4, 1, 502, 17, 2, 1010, 8, 45, 113, 17, 10, 521, 1135, 21, 8], [7, 1287, 71, 42, 41, 1, 471, 5, 517, 327, 205, 55], [70, 80, 1, 458, 50, 5420], [175, 34, 29, 262, 108, 422, 181], [71, 32, 16, 4, 3347, 66, 124, 230, 22, 658, 220, 248, 36, 1051, 11, 2, 5421, 37, 36, 222, 44, 217, 6, 137], [599, 726, 5, 220, 405, 18, 20, 1643], [5, 72, 936, 2, 1122, 479, 18, 3031, 38, 66, 44, 12318, 7, 85, 23, 113, 5, 6, 998, 20, 4318, 20, 144], [3, 47, 2, 181, 108, 88], [415, 1530, 123, 247, 1024, 52, 136, 4, 395, 6, 806, 15, 1168, 8, 52, 63, 255, 2, 190, 2611, 31, 52, 157, 35, 7166], [4239, 27, 32, 252, 8, 407, 172, 43, 1, 2028], [19, 32, 5323, 8, 19, 5, 99, 12319, 1, 20, 12320, 1359, 12, 1471, 13, 2, 1766, 1270], [345, 59, 254, 5, 96, 75, 110, 81, 6, 17, 110, 464, 23, 7005, 4, 2762, 1, 7, 266, 3013, 5, 55], [104], [3, 63, 134, 5, 60, 16, 10, 754, 37, 5, 63, 65, 13, 2, 342, 391], [1346, 387], [12321, 34, 3, 75, 304, 1062, 4, 115, 2, 1, 122, 17], [8, 140, 15, 372, 13, 116, 12, 43, 12322, 52, 152, 1278, 11, 48, 876, 52, 1302, 136, 179, 5422, 12323, 7], [2524, 176, 528, 8, 17, 8, 170, 103, 19, 42, 35, 661, 24, 1], [52, 47, 1584, 48, 1913, 26, 52, 122, 6, 257, 35, 2, 209, 7010, 6338, 30, 12324, 7, 12, 85, 52, 12, 1923, 31, 2864, 47, 2, 6219], [356, 6, 509, 144, 1132, 2518, 34, 12325, 42, 210, 998, 12326, 2974, 769, 72, 84, 6], [23, 37, 549, 16, 653, 1759, 4468, 397, 123, 288, 2856, 56, 4469], [367, 370, 4351, 23, 2, 1, 37, 23, 61, 6, 609, 5, 13, 247, 12327, 609, 4, 1082, 12328], [23, 96, 152, 737, 4, 19, 54, 980, 36, 122, 6, 208, 332, 129, 1610, 281, 24, 30, 25], [101, 540, 3, 452, 134, 15, 35, 12, 3, 12329, 2, 19, 7167, 18, 22, 83, 12330, 178, 220, 12331], [78, 46, 276, 28, 2, 12332, 16, 2570], [241, 447, 12333, 1274, 1826, 1, 128], [55, 92, 32, 97, 87, 12, 667, 12334, 12335, 2763, 24, 177], [28, 102, 10, 186, 181], [183, 120, 1], [3, 1279, 12336, 43, 905, 12337, 43, 2705, 260, 12338, 32, 61, 6, 915, 823, 16, 12339], [146, 176, 290, 280, 12340, 9, 33, 122, 6, 316, 17, 2014], [600, 3, 756, 11, 42, 12341, 12342, 73, 2, 2302, 3746, 7168, 2001, 1, 3, 301, 42, 1640, 27, 2, 3834, 12343], [15, 550, 151, 28, 1, 18, 22, 138, 769, 34, 267, 21, 4, 1011], [3, 29, 134, 2, 635, 19, 57, 5, 86, 59, 10, 175, 2933, 660, 7169], [15, 5423, 10, 161, 190, 1006], [7, 85, 12344, 2, 190, 1006], [218, 5, 62, 3, 47, 137, 7170, 3, 46, 79, 80, 779, 2, 1, 74, 72, 80, 646, 183, 483, 200, 3], [251, 1409, 594, 15, 34, 19, 15, 127, 9, 21, 17], [19, 240, 31, 36, 75, 114, 2, 675, 1132, 24, 101, 86, 675, 59, 4470, 5424, 26, 1246, 49, 2181], [1064, 1279, 27, 7, 4320, 15, 33, 37, 5425, 71, 1076, 15, 70, 32, 39, 660, 12345, 7, 771, 12, 783, 254], [43, 48, 390, 20, 152, 9, 740], [1], [243, 457, 494], [207, 1372], [1140, 23, 79, 50, 2, 9, 8, 23, 214, 4995, 12346, 35], [549, 1], [31, 23, 56, 174, 56, 371, 66, 482, 92], [1417, 1, 3, 293, 217, 998, 20, 164, 249, 954, 138, 8, 28, 167, 123, 201, 7171], [336, 3, 1257, 6, 5, 13, 3, 200, 6, 599, 416, 499, 69, 79, 15, 2455, 61, 8, 536, 31, 5, 29, 442, 17], [241, 988, 36, 1122, 7, 315, 30, 7, 107, 54, 18, 886, 219, 42, 1073, 6, 786, 12347, 43, 494, 33, 2, 320, 16, 2989], [2378, 3835, 12, 2, 5352], [27, 1515, 7, 312, 103, 215, 445, 2654, 13, 1579, 1137, 4994, 312, 198, 4341, 309, 213, 1712, 78, 4, 250, 412, 6, 1122, 2506], [270, 2, 9], [447, 1175, 536, 12, 2, 836, 100, 271, 18, 3371], [55, 7, 2764, 197, 219, 21, 202, 617, 11, 4, 12348, 36, 165, 316, 2, 607, 353, 27, 12349], [20, 1272, 8, 1375, 25, 76, 9, 249, 7172, 646, 49, 48, 356, 51, 32, 12350, 4471, 198, 14, 518, 201], [1968, 664], [221, 193, 6, 572, 17, 181, 20, 626, 5, 61, 8, 167, 77, 71, 1715, 277, 7, 70, 5, 1715, 602, 6, 62, 278, 12351], [20, 2, 19, 494, 104, 1], [1, 7, 369, 3, 33, 121, 8, 15, 48, 12352, 15, 890, 663], [49, 5, 2, 1072, 74, 49, 5, 2, 95], [33, 257, 4, 24, 35], [61, 6, 376, 1], [128, 5, 301, 1], [33, 672, 2, 2076, 348, 8, 12, 94, 1107, 534], [128, 36, 62, 69, 4, 2538, 2291, 12, 29, 90, 1], [100, 33, 72, 12353, 12354, 70, 165, 348], [2002, 2, 89, 1], [369, 5, 1, 297, 22, 461, 17], [1266, 785, 1], [19, 102, 1], [19, 5, 1], [67, 17, 6, 100, 416, 62, 52, 2077, 4, 413, 7173, 1748, 3032, 1623], [57, 93, 24], [5, 308, 1], [10, 145], [12355, 57, 893, 262, 17, 145], [7174, 1], [1218, 12356, 18, 5, 145, 27, 80, 1220, 30, 476, 5, 655, 254, 26, 219, 411, 55], [398, 5, 177, 87, 60, 24, 2629], [96, 924, 2514, 19, 144], [135, 97, 61, 2264, 119, 7175], [7, 161, 312], [20, 2, 308, 2382, 16, 45, 140, 3, 62, 5, 64, 17], [55, 181], [174, 3494, 12357, 12358, 12359, 12360, 311, 174, 833, 12361, 16, 2651, 12362, 42, 7176, 13, 2, 1, 13, 1908, 12363], [20, 4, 508, 540, 3, 107, 6, 7, 2765, 7177, 5, 210, 1507, 176, 35, 4, 93, 197, 1059], [1739, 12364], [56], [336, 15, 33, 4472, 14, 2, 1, 25], [55, 15, 2, 1790, 48, 428, 9], [38, 5, 28, 1303, 23, 7178, 80, 2725, 37, 17, 8, 10, 1, 63, 44, 147, 45, 32, 11, 143, 967], [12365, 411, 559, 1426, 2, 1, 3, 47, 1806, 12366, 6, 139, 4104], [29, 14, 2, 1, 88], [71, 2647, 5, 104], [1, 29, 1257], [367, 155, 189, 12, 2, 1, 12367], [12, 152, 258, 1399, 2, 388, 77, 68, 16, 39, 115], [104], [225, 47, 81, 13, 2, 3836, 115, 8, 1064, 357, 724, 278, 132, 58, 2, 159, 12368, 7179, 32, 921], [34, 7, 57, 5, 79, 120, 56, 27, 169], [43, 4191, 96, 14, 2, 181, 31, 3, 47, 3614], [174, 2, 181], [33, 127, 12369, 39, 49, 4, 199, 19, 7, 3832, 6, 160, 36, 33, 90, 15, 38, 315, 523, 7180], [36, 156, 157, 5426, 11, 355, 190, 74, 4473, 12370], [526, 174, 679, 468, 174, 12371, 4980, 174, 2, 917, 3, 64, 254, 75, 139, 4089], [43, 2717, 135, 2164, 43, 1867, 18, 2122, 33, 7, 406, 42, 448, 216, 17, 32, 34, 7181, 18, 10, 3692, 513], [7, 120, 414, 24], [1531, 299, 312, 1902], [128, 381, 33, 409, 76, 54, 8, 100, 76, 104, 122, 6, 5427, 254], [241, 654, 33, 934, 20, 1900, 56, 8, 20, 1341, 12372, 4474], [333, 14, 2, 141, 2214, 1, 4, 1119, 106], [76, 9, 65, 93], [3, 745, 297, 7, 9], [447, 6710, 11, 22, 9, 3837, 474, 5428, 167, 565, 8, 7182, 806, 4, 1], [5429, 1585, 282], [12373, 12, 11, 1338, 16, 7183, 1548, 8, 4, 1108, 266, 3033, 2, 7184, 6, 1337, 4, 7185], [371, 103, 14, 2, 12374, 7186], [293, 40, 7187, 130, 2, 1187], [1, 29, 204, 10, 1822], [221, 1266, 4475, 10, 935, 260, 1054], [20, 2, 19, 158], [12375, 235, 1, 11, 7188, 55], [13, 4, 154, 7189, 10, 186, 12, 144, 8, 229, 5, 11, 4, 3838, 1100, 34, 38, 3, 1509, 20, 2296, 15, 229, 4, 154, 68], [20, 2, 1, 12376], [851, 372, 12377], [22, 12, 85, 3, 253, 8, 64, 5, 7190, 3, 600, 1, 51, 5, 34, 151, 105, 559, 350], [71, 358, 211, 4, 226, 396, 103, 1057, 7191, 12378, 226, 14, 7192, 529, 8, 12379, 1775], [55, 6, 28, 4, 190, 4464, 3266, 54, 168, 2, 2338, 3559, 12380, 12381, 722, 18, 4, 3266, 8, 313, 11, 4, 12382], [23, 107, 21, 5, 1, 177], [11, 20, 651, 141, 3839, 12383], [5, 196, 248], [1, 12384], [66, 49, 14, 12385, 123, 12386, 140, 7193, 74, 4, 1422, 7, 298, 305, 823, 67, 4, 120, 91, 6, 12387], [2516, 3232, 95, 12388], [47, 59, 6, 635, 6, 12389, 26, 458, 2, 63, 16, 12390, 371, 36, 192, 6, 4373, 54, 985, 12391, 298, 22, 368], [583, 57, 2, 104], [336, 1, 42, 1812, 6, 12392, 2435, 948, 1361, 1118, 45, 6580, 378, 106, 8, 2110, 12393, 37, 411, 9, 30, 61, 5430, 18, 667, 593], [371, 115, 378, 42, 375, 794, 1, 11, 3372, 1558], [71, 42, 636, 23, 533, 133, 5, 1, 425], [281, 1, 272, 1552, 2, 7194, 11, 1731, 657, 80, 12394, 7195, 1, 3, 62, 162, 5, 4378], [336, 40, 121, 5, 2, 181], [42, 1921, 7, 12395, 1], [447, 1114, 2, 1, 948, 5431, 3840, 233, 5080, 3144, 205], [706, 17, 20, 518, 9], [15, 197, 1], [22, 159, 2268, 109, 277, 87, 1288, 547, 536, 22, 54], [3841, 103, 14, 11, 839, 839, 591, 51, 12396, 99, 239, 2188, 386, 16, 1, 35, 116], [357, 12, 182, 152, 114, 22, 30, 1353, 686, 361, 57, 2, 161, 1], [29, 72, 45, 13, 7, 161, 312, 233, 74, 151, 134, 5, 2, 4476], [4, 101, 5432, 3, 96, 44, 82, 76, 49, 33, 4, 1469, 6846, 68, 269, 4477, 202, 8, 3171, 8, 4, 5089, 68], [76, 46, 4, 1, 23, 533, 133, 46, 43, 2309, 4421, 129, 116, 55], [1, 25, 29, 28, 32, 34, 505], [773, 773, 15, 10, 1979, 1956, 233, 15, 21, 10, 1, 6, 1099, 6, 10, 967], [3, 41, 76, 1, 7196, 6, 17], [5134, 497, 10, 1, 65, 165], [370, 7197, 12, 2, 1], [12397, 10, 310, 12, 60, 56, 34, 5, 724, 7], [3, 5, 1], [274, 317, 471, 144, 6, 286], [24], [5, 2, 551, 1], [424, 3373, 5433, 7198, 73, 7199, 2979, 2060, 3842, 34, 47, 428, 2, 190, 3842, 51, 199, 6853], [133, 106, 1], [48, 7, 15, 690, 34, 23, 818, 16, 174, 141, 30, 23, 163, 206, 2738, 83, 662, 163, 116, 260], [23, 2, 12398], [29, 924, 17, 3034, 23, 2901], [2, 451, 3809, 12, 6413, 12399], [80, 1, 271, 541, 13, 2, 1353], [111, 146, 1, 59, 2180], [32, 16, 78, 411, 20, 32, 24, 8, 266, 58, 45], [640, 9], [22, 25, 233, 62, 148, 219, 5, 2, 490], [391, 2925], [4, 252, 424, 102, 298, 13, 2, 1], [12400, 12401, 422, 20, 4, 180, 106, 45, 3291, 18, 186, 43, 226, 43, 231, 43, 2973], [3, 566, 875, 1289, 70, 5, 468, 12402, 8, 571, 490, 37, 7, 1365, 4, 2829], [33, 5321, 5434, 1, 30], [12403, 12, 56, 1737, 3, 1560, 299, 52, 118, 44, 223, 211, 5226, 34, 57, 5, 121, 70, 1237], [23, 380, 2028, 4, 781, 49, 81, 248], [19, 367, 66, 49, 2849, 12404, 399], [23, 48, 362, 23, 2, 291, 312], [220, 973, 728, 224, 305, 12405, 20, 1073, 6, 1344, 2, 388, 6203], [149, 20, 2, 148, 1909, 2132, 5, 627, 330], [318, 12406, 134, 5, 2, 12407, 22, 187, 427, 61, 6, 44, 2, 730, 38, 23, 2433], [15, 46, 726, 52, 10, 12408, 1522], [40, 1175, 104, 27, 98, 1701, 20, 37, 431, 55], [1, 242, 4, 19, 8, 253, 57, 42, 72, 25], [49, 42, 19, 96, 81, 1, 3, 131, 94, 7, 3, 29, 134, 2, 19, 59, 20, 183, 30, 504, 386], [1, 8, 4, 19, 42, 131, 58, 59, 88, 25, 411, 81, 8, 58, 256], [7, 2, 342, 8, 858, 12409, 1707], [7200, 5435, 12410, 49, 12411, 43, 508, 255, 74, 12412, 1366, 12413, 4251, 1296, 2882, 1366, 12414], [56], [33, 262, 447, 494, 2692], [212, 220, 12415], [48, 31, 20, 397, 11, 1906, 4, 190, 493], [497, 20, 586, 28, 127, 1, 51, 261, 130, 5, 58, 5436], [58, 15, 24], [3, 44, 969, 24, 1366, 4173], [57, 12, 7, 269, 58, 6, 212, 950, 1149], [42, 189, 49, 2191], [149, 416, 33, 64, 80, 1, 30, 2592, 447, 12416], [19, 4, 232], [73, 42, 198, 7, 383, 2, 3374, 30, 1251, 1, 66, 11, 116, 21, 4, 227, 35], [1, 12417, 526, 3, 383, 486, 68, 16, 240, 1157, 23, 11, 12418, 3, 12419, 123, 13, 241, 7, 1605, 280, 92, 23, 514], [202, 77, 49, 37, 356, 85, 75, 5, 81, 599, 15, 2169, 138, 498, 309, 332, 408, 7201, 5, 1570, 17, 1633], [680, 183, 9, 333, 58, 256, 59, 7, 530, 1766, 343, 7202], [112, 686, 11, 7095, 666, 16, 4478, 187], [8, 36, 1, 149, 1205, 229, 11, 12420, 220, 4, 101, 184, 3035, 76, 82, 28, 227, 12421, 1540, 204], [2350, 415, 101, 395, 11, 360, 1489, 11, 10, 950, 202, 12422, 120, 12423, 1179], [372, 13, 5, 133, 6, 737, 2, 9], [25, 5, 818, 16, 3843, 3, 47, 11, 7, 1, 12424, 4, 12425, 12, 82, 17, 61, 6, 28, 4, 441, 54, 4, 347], [], [3, 484, 1775, 144], [23, 1411, 10, 746, 9], [218, 174, 2, 95, 1], [19, 80, 1, 30, 88], [7, 158, 451], [219, 20, 2, 250, 521, 83, 37, 61, 18, 27, 20, 1, 164, 1], [422, 185, 1], [529, 1094, 56, 7203, 510, 6, 3375, 12426, 375, 52, 8, 1108, 1796, 4, 1575], [529, 2459, 56, 116, 43, 5319, 12427, 4479, 642, 163, 7203, 945, 2961, 103, 229, 52, 608, 1843], [159, 333, 2498, 82, 378, 1384, 2729, 201, 12428], [159, 23, 98, 206, 3519, 29, 182, 72, 183, 184, 59, 174, 1334, 12429, 3, 28, 15, 383, 29, 180, 1420], [151, 901, 10, 1888, 63, 26, 34, 3036, 266, 3844, 55], [9, 5, 49, 58, 93, 99], [1, 23, 6426, 18, 10, 813, 2877], [55, 56, 3, 118, 16, 1874, 15, 31, 40, 47, 342], [5, 122, 6, 1102, 10, 1529, 767, 102, 13, 15, 47, 2, 1795, 1], [22, 1, 65, 13, 2, 19, 120, 56, 1900, 731, 1235, 541, 91, 1538, 7071], [48, 73, 89, 73, 2, 3376, 12430, 158, 7, 13, 978], [12431, 3, 64, 5, 1], [2691, 5107, 8, 1172, 94, 5, 51, 4, 849], [24], [3, 67, 15, 3, 64, 50, 1479, 40, 12, 1772, 162, 200, 5, 28, 15], [31, 123, 12432, 5, 196, 5437, 5, 345, 13, 2, 368, 88, 221, 278, 5395], [3, 1279, 4, 203, 1, 4, 101, 77, 440, 48, 525, 433, 224], [36, 14, 238, 340, 18, 4, 702, 34, 68, 115, 39, 1, 152, 623, 60, 25, 81, 127, 88, 76, 1432], [252, 47, 2, 1, 25, 8, 424, 102, 298], [281, 23, 2135, 12433, 41, 127, 190, 1092, 22, 106], [52, 47, 294, 26, 292, 141, 95, 4279, 123, 84, 12434, 751, 789, 323, 16, 12435, 1604, 26, 3602, 72, 188], [13, 7204, 121, 2086, 32, 179, 12436, 55], [25, 58, 4, 12437, 18, 384, 544, 9, 55], [28, 60, 1685, 9], [2147, 664], [342, 34, 3, 64, 50, 190, 12438, 4, 247, 4, 12439, 27, 12440, 343, 65, 37, 342, 1145, 3, 64, 50, 231, 11, 20, 7205], [321, 42, 270, 2, 24, 33, 81], [236, 236, 1989], [1], [151, 491, 2, 9], [770, 225, 4, 1585, 16, 3845, 12, 38, 11, 1592, 924, 7206], [76, 1702, 69, 1], [100, 17, 380, 36, 44, 190, 1054, 99, 199, 2678, 511, 970], [85, 58, 5, 1, 59, 474], [410, 17, 83, 38, 8, 162], [5, 124, 6, 313, 11, 4, 104, 324, 251, 251, 251], [174, 4, 2502, 21, 448, 2, 5438, 16, 2, 252, 7207, 1047, 38, 42, 220, 99, 24, 6, 2348, 84, 231], [5, 49, 2, 1], [160, 94, 7, 85, 97, 30, 105, 87, 6, 61, 897, 238, 61, 673, 385], [1530, 434, 3037, 33, 194, 4, 12441, 2341, 16, 12442, 232, 1330, 12443], [85, 6763, 42, 131, 14, 2, 104, 252, 7, 104, 13], [3, 299, 5, 124, 60, 19, 35, 1809, 12444, 7, 216, 20, 628, 548, 1471, 1522], [15, 48, 117, 34, 15, 4, 6630, 4, 1593, 136, 2, 3846, 3547, 21, 692, 8, 3571, 5439, 12, 144], [12445, 10, 56, 30, 653, 12, 33, 7, 1949], [12446, 389, 108, 12, 2, 1], [2664, 1, 2664, 3, 454, 31, 4345, 433], [23, 515, 1], [20, 529, 641, 120, 111, 7208, 12447, 12, 2, 7209, 21, 12448, 12449, 12, 2, 7209, 21, 12450], [7, 47, 21, 166, 1, 55, 5, 342, 205, 1287, 12451, 80, 7210, 571, 905, 99, 1558], [52, 747, 4, 5148, 21, 4, 178, 390, 135, 11, 7211, 23, 65, 6, 303, 2, 12452, 12453, 758, 3, 63, 1516, 102, 1271], [555, 15, 5, 19, 1], [286, 43, 162, 12, 4, 24, 2645, 1447], [241, 52, 96, 81, 6, 166, 1, 3, 4480, 553, 16, 10, 5296, 205], [13, 57, 42, 1, 12454, 12455, 3128], [1, 3, 108, 45, 35, 19, 25], [1, 195, 48, 152, 242, 45, 35, 150, 351, 6, 1344, 76], [25, 5, 257, 69, 30, 1, 2948, 105, 110, 3006, 37, 42, 87, 6, 139, 70, 35, 45, 8, 316, 80, 30, 27, 76], [583, 3, 47, 13, 1296, 74, 1682, 290, 111, 11, 314, 261, 88, 1, 753, 17, 19, 25], [1, 693, 42, 46, 107, 6, 261], [2517, 10, 2461, 12456, 337, 12457, 57, 97, 62, 7, 233, 12458, 627, 1770, 403, 6, 5307], [745, 5, 182, 566, 4, 761, 16, 4, 95, 8, 4, 1578], [89, 1, 596, 2328, 3847], [14, 362, 6, 253, 15, 35, 27, 2, 5440, 1, 231], [77, 7, 67, 6, 555, 18, 6, 36, 9, 8, 208, 13, 36, 75, 229, 102, 36, 520], [485, 12459, 3377, 7212, 3848, 3218, 12460, 159, 12461, 26, 779, 4481, 198, 14, 126, 373, 412, 244, 106, 11, 12462], [267, 5, 1095, 2168, 935], [97, 24, 100, 61, 12463], [145, 22, 45, 686, 46, 43, 68, 528], [52, 4, 993, 50, 117, 11, 4, 887, 189], [3, 105, 200, 212, 178, 34, 3, 47, 2065, 27, 1076, 942, 678, 12, 85, 15, 424, 17, 37, 358, 6, 58, 12464, 3, 47, 12465, 55], [12466, 15, 56, 464], [750, 73, 3, 63, 113, 490, 1345, 18, 4, 12467, 676, 1371, 160, 7213, 47, 731, 123, 60, 1308, 423, 82, 337], [19, 43, 40, 29, 100, 357, 167, 7, 24, 519, 3, 62, 15, 12468], [2096, 4, 12469, 1650, 16, 7, 4451, 278, 72, 127, 13, 1421, 7214], [4221, 1, 311, 207, 8, 2194, 136, 12470], [71, 222, 5, 72, 270, 2, 184, 414, 5, 44, 268, 2508, 2170, 1879, 6, 555, 20, 3167, 2101, 8, 353], [10, 1981, 266, 100, 17, 12471, 224, 209, 37, 3, 33, 70, 2, 607, 840, 8, 65, 51, 4, 203, 12472, 388, 12473], [5, 6, 1], [48, 129, 43, 186, 385, 1853, 20, 2, 5441, 5, 100, 2, 171, 1339, 481, 609, 1, 569, 21, 12474, 111], [8, 374, 144, 73, 19, 11, 979, 27, 126, 12475, 293, 36, 616, 102, 27, 1210, 34, 4, 4443, 2149, 12, 632, 37, 7215], [40, 61, 392, 144, 117, 92, 251], [116, 47, 560, 43, 87, 21, 50, 6, 14, 2, 187, 8, 208, 13, 40, 256, 3108, 15, 407, 12476], [9], [60, 804, 1595, 179, 261, 281], [29, 14, 2, 285, 560, 116, 12, 828, 8, 351, 1421, 1184, 3, 300], [140, 15, 19, 144], [12477, 174, 2, 181], [285, 15, 12478, 12479, 527, 4151, 1175, 4442], [911, 217, 2284], [19, 5, 104], [5, 203, 2716, 19, 187, 3, 1061, 293, 5, 955, 6, 989, 11, 2, 2340, 16, 20, 373, 12480, 12481, 4482], [66, 29, 64, 39, 9], [3, 741, 35, 21, 10, 3849, 29, 974, 4, 7216, 10, 3815, 8, 2895, 12482], [52, 94, 4, 1280], [8, 114, 4, 56, 54, 8, 3139, 4, 3805], [367, 5, 58, 1633], [1044, 109, 87, 6, 28, 722, 22, 413, 6259, 142, 8, 1442, 51, 4, 2149, 16, 98, 12483, 673, 1288, 66, 44, 5442], [37, 89, 1, 7027, 5, 11, 166, 324], [10, 310, 1042, 143, 24, 117, 92, 55], [128, 2873, 12, 4, 101, 189, 440, 116, 52, 59, 6, 28, 60, 24], [367, 37, 5, 222, 338, 181], [1292, 1210, 12484, 66, 198, 122, 8, 5443, 7, 187], [71, 239, 172, 181, 200, 2, 110, 28, 982, 14, 1166, 173, 10, 3748, 4483, 793, 4, 3028, 281], [52, 67, 24, 579, 2, 5444, 196, 2, 534], [4484, 24, 534], [24, 5, 75, 290], [29, 1448, 20, 235, 51, 307, 3, 33, 64, 6, 56, 2481], [127, 13, 12485, 12, 2, 141, 816], [40, 63, 33, 172, 79, 4, 12486, 59, 15, 8, 1930, 2055, 4, 514, 1683, 8, 12487, 154, 68, 57, 2, 171, 1], [692, 1492, 24, 169, 1, 441], [2, 104, 7, 87, 6, 632, 35], [632, 2, 2035, 24], [802, 6587, 30, 1], [5, 200, 2, 93, 401, 58, 7, 6, 17, 8, 48, 262, 108, 104], [3, 742, 7, 8, 50, 820, 16, 437, 1978, 149, 23, 2, 89, 1], [219, 23, 362, 23, 48, 3850, 144, 647], [573, 147, 312], [20, 509, 5, 490], [247, 16, 39, 111, 49, 253, 16, 253, 16, 910, 34, 36, 943, 49, 96, 7217, 126, 5445, 453, 26, 1284], [140, 20, 2, 669, 83, 477, 6, 7218, 402, 140, 4, 3851, 976, 18, 231, 215, 1477], [45, 37, 7057, 363, 102, 8, 3741, 51, 4, 265, 8, 4, 265, 47, 2, 19, 1431, 25, 24, 8, 2682, 18, 170, 26, 41, 170, 160], [267, 21, 609, 10, 262, 181], [7, 2, 2078, 5, 144], [38, 5, 623, 20, 56], [810, 4, 1037, 45, 23, 94, 7, 9, 22, 696], [3, 41, 2, 12488, 6804, 6, 34, 15, 415, 179, 117], [15, 48, 179, 5, 5335], [5, 41, 2, 12489, 5, 9], [5, 146, 14, 13, 17, 163, 4, 1883, 33, 901, 15, 32, 230, 416], [5, 63, 14, 2, 89, 1, 99, 5313, 15, 550], [2862, 572, 7, 1], [372, 13, 4, 7219, 129, 95, 2094, 2, 607, 213, 895, 15, 124, 2, 7220, 7221, 877, 130, 4, 1321, 12490], [155, 1, 708], [1, 57, 3, 29, 134, 2, 19, 57, 5, 72, 34, 29, 172, 308, 18, 17, 5, 1031, 1], [12, 54, 16, 84, 2082, 95, 122, 6, 72, 12491, 12, 165, 130, 473, 189], [1417, 4130, 3852, 269, 229, 17, 71, 15, 2433, 304, 7, 372, 12492], [3, 293, 10, 858, 235, 317, 12493, 99, 1572], [31, 5, 72, 68, 7222, 324, 59, 4, 159, 524, 5162, 1101, 3, 103, 7223, 4, 515, 18, 20, 1832], [47, 33, 454, 31, 80, 12494, 6, 1299, 1091, 207, 886, 2539, 5446, 3, 7224, 325], [3351, 3, 380, 5, 46, 207, 37, 37, 29, 62, 143, 3747], [5, 41, 143, 394, 8, 143, 4455, 125, 147, 207, 12495, 69, 101, 477, 6, 12496, 57, 499, 3, 346], [4029, 29, 14, 2, 24, 151, 229, 42, 47, 93, 27, 7, 12497, 55], [806, 55, 7, 45, 101, 7225, 12498, 92, 20, 1, 12, 741, 1709, 3, 62, 47, 93, 27, 76, 957, 4485, 2534], [1, 33, 563, 17, 35, 135, 55], [487, 70, 15, 25, 47, 51, 4, 12499, 10, 89, 88, 10, 4256, 21, 10, 310, 1028, 37, 3, 63, 262, 23, 18, 10, 7226, 32, 179], [128, 221, 1, 7, 161, 45, 1028, 26], [249, 10, 138, 1672, 1968, 664, 165], [221, 1, 200, 15, 578, 93, 1534, 7227], [19, 5, 1], [7228, 7, 236], [15, 716, 2728, 35, 7, 36, 220, 10, 1802, 1072, 34, 3, 47, 101, 1924, 18, 578, 661, 3, 41, 127, 1489, 12500], [659, 12501, 1047, 12502, 52, 2, 282], [1171, 105, 1041, 2233, 428, 5447, 33, 7229, 12503, 2973, 11, 126, 56, 63, 51, 7230, 889, 2495], [101, 68, 1254, 232, 506, 101, 68, 1254, 12504, 506, 101, 68, 781, 18, 922, 12505, 412, 506, 247, 412, 44, 984, 1530], [5, 29, 44, 245, 265, 57, 49, 5, 68, 16, 76, 494], [57, 3, 299, 1], [1, 46, 616, 142, 74, 2766, 394, 40, 63, 114, 127, 735, 130, 350, 43], [7, 9, 229, 35, 4486, 68, 115, 20, 30, 266, 107, 619, 205], [603, 214, 2, 399, 430, 60, 2396, 51, 1255, 637, 68], [124, 143, 1, 2351, 11, 143, 489, 125, 10, 177, 12506], [7, 399, 249], [24], [139, 800, 12507, 23, 515, 16, 94, 7, 1, 18, 10, 909], [398, 5, 1, 61, 6, 376], [490, 8, 269, 13, 5, 1570, 17, 5, 12508, 229, 5392, 345, 59, 45, 32, 4, 106, 20, 2, 2158, 1666], [128, 76, 1, 47, 4, 910], [88, 4, 265, 52, 1597, 15, 6, 1051, 15, 108, 6, 170, 867, 11, 2, 348], [78, 2010, 207, 617, 101, 197, 470, 143, 115, 8, 313, 143, 3706, 11, 143, 12509, 31, 66, 46, 328], [169, 63, 28, 5, 93, 441, 34, 48, 156, 4, 237, 16, 285, 370, 10, 228, 647, 380], [24], [5, 49, 2, 83], [36, 5331, 2163, 16, 12510, 18, 4, 508, 16, 980, 36, 118, 150, 93, 18, 174, 1270], [64, 5, 99, 1], [1, 3, 47, 54, 4061, 8, 20, 30, 47, 376], [12511], [1488, 49, 56], [2026, 2657, 412, 58, 7231, 12512, 7, 28, 12513, 23, 48, 4487, 23, 33, 72, 3, 29, 86, 42, 198, 72, 374, 248], [212, 5448, 4311, 883, 118, 12514, 174, 412, 11, 4311, 8, 247, 2657, 7232], [250, 710, 98, 2540, 12515, 3, 132, 465, 15, 2151, 56, 12516, 3012, 134, 15, 2, 477, 716, 29], [77, 3, 132, 67, 76, 45, 3, 132, 632, 76, 9, 21, 133, 7233], [628], [22, 1, 94, 7, 73, 48, 98, 1183, 140, 1387, 49, 101, 12517, 7234, 1179, 162, 52, 12518], [431, 7235], [431, 7235, 3, 33, 41, 2247, 542, 6, 176, 10, 2022, 82, 3853, 3135, 55], [1, 14, 896, 13, 23, 2, 1120], [241, 583, 4, 1, 12, 1, 361], [3, 62, 71, 5, 12519, 3, 3854, 697, 449, 21, 17, 118, 14, 1316, 48, 28, 2097], [705, 178, 21, 1111, 12520, 5, 28, 337, 738], [370, 133, 20, 1316, 12521, 12522, 13, 11, 4, 7141], [7, 118, 14, 20, 232, 12523, 32, 62, 36, 198, 404, 32, 7236], [34, 5, 220, 99, 624, 14, 2, 3736, 1, 8, 48, 279, 7, 20, 12524, 12525, 47, 61, 539, 286, 37, 116, 10, 929], [179, 484, 2, 417, 347, 8, 48, 44, 6, 389, 2, 320, 21, 7237, 3, 484, 2, 7238, 8, 389, 141, 7237, 33, 7239], [4, 758, 56, 8, 23, 338, 20, 712, 2, 780], [12526, 195, 48, 12527, 7240, 174, 9, 1138, 471, 2125, 327], [1226, 7, 1463, 386, 6, 340, 2, 24, 84, 386, 118, 44, 3855, 18, 84, 12528, 1882], [76, 5449, 1274, 12529, 87, 6, 28, 572], [221, 370, 269, 412, 33, 176, 543, 574, 304, 21, 5450, 1421], [12530, 12531, 664], [12532, 12533, 664, 17, 4369, 12534], [57, 4, 511, 808, 4, 1058, 16, 4, 312, 1902], [69, 279, 1249, 68, 2, 1096, 537, 12535, 26, 4, 166, 12, 2, 1508, 2103, 158], [267, 5, 3856, 160, 243, 12536, 457, 99, 9], [23, 1233, 2038, 2115], [372, 13, 12537, 6, 17, 160, 36, 168, 6, 58, 22, 32, 4, 106, 162, 3, 259], [20, 359, 18, 2038, 2115, 709], [20, 3683, 12, 179], [1479], [2418, 1711], [5, 372, 13, 2, 112, 187], [3549, 12538, 12539, 3566, 12540, 12541], [12542, 9], [7241, 269], [2448, 420, 97, 171, 1, 281], [1753, 8, 1826, 56], [40, 65, 13, 2, 112, 391, 92], [1, 12543, 15, 763, 18, 10, 815, 8, 12544, 31, 42, 47, 389, 701, 1502, 44, 297, 38, 3, 121, 3, 694, 173, 15], [128, 29, 290, 17, 5, 29, 62, 10, 179, 30, 261, 252, 3, 2711, 1592, 7, 371, 3, 29, 134, 2, 19, 59, 15], [5, 75, 28, 2256, 16, 17, 7, 2004, 1], [1195, 3, 2019, 3, 58, 90, 4, 12545, 8, 4, 2527, 31, 3, 90, 4, 232, 21, 126, 7242, 3, 44, 6, 90, 4, 12546], [31, 3, 44, 6, 194, 1519, 3, 428, 61, 21, 4, 704, 140, 4488, 12547, 8, 19, 4, 2527], [66, 90, 4, 232, 464, 117, 3, 150, 13, 23, 109, 93, 51, 90, 980], [66, 90, 76, 127, 130, 4, 1739, 8, 2527], [403, 85, 29, 42, 28, 12548, 11, 202, 18, 202, 12549, 149, 90, 1430, 340, 2293, 92], [85, 357, 105, 1713, 17, 6, 43, 2425, 2429, 513, 283], [3, 62, 571, 291, 30, 1], [1, 333, 49, 5, 122, 6, 72, 3, 47, 3857, 6, 3299, 130, 5], [24, 24, 24], [20, 2, 1], [139, 665, 4, 4304, 24], [99, 239, 141, 4478, 1, 11, 4469, 217, 6, 345, 59, 393, 5391, 265, 456, 255, 12550, 4489], [259, 27, 10, 1], [24], [151, 107, 999, 20, 436, 1, 177], [1, 43], [149, 3, 210, 131, 94, 20, 1, 30], [20, 68, 16, 10, 1, 5, 70, 169, 21, 17], [403, 4, 997, 216, 15, 2, 6570, 6, 176, 8, 3526, 4, 12551, 28, 20, 488, 344], [12552, 123, 5451, 3783, 4, 2315, 4, 1470, 12, 93, 8, 12553, 389, 20, 1005, 12554, 660, 8, 1108], [1614, 71, 239, 12555, 136, 22, 104, 2405], [1139, 232, 12556], [95, 16, 2, 7121, 61, 423], [267, 9], [2, 24, 11, 174, 476, 12, 2, 109, 93, 1040, 4218, 1998, 3824], [3, 86, 42, 87, 2, 1007, 74, 2, 24, 11, 20, 476, 6, 70, 42, 150, 882, 1040, 54, 29, 42, 86], [5, 63, 14, 766, 5, 67, 371, 5, 652, 2, 308, 30, 1, 30, 1133, 30, 639, 1534], [221, 52, 249, 33, 13, 4, 166, 181, 69, 4422, 241, 5452, 116, 49, 43, 181, 11, 4], [814, 41, 43, 508], [151, 58, 15, 11, 4, 2743, 12557, 196, 2390, 8, 2, 5453, 12, 2, 5015, 16, 741, 5, 12558], [33, 1124, 5, 192, 4, 45, 123, 79, 50, 54, 8, 7, 20, 14, 2, 1, 8, 219, 32, 420, 18], [1], [2898, 2, 1, 1322, 1785, 160, 3377, 2436, 2301, 12559, 200, 48, 1141, 245, 3378, 12560], [3, 121, 23, 2, 2240, 34, 48, 2, 1298, 69, 2764, 297, 7, 629], [38, 200, 66, 671, 2, 1129, 16, 1055, 3657, 1779, 24, 769, 70, 22, 252, 970, 16, 4446, 7243, 52, 4, 91], [12561, 96, 2, 141, 83], [318, 87, 5, 6, 5454, 2, 1], [80, 253, 17, 108, 399], [12562, 628, 12563, 330, 44, 12564, 68, 37, 3, 86, 1627, 65, 625, 342], [560, 3, 157, 3, 881, 531, 18, 2, 12565, 12566], [24], [5, 96, 183, 88, 2, 9, 8, 5, 96, 65, 13, 12567, 102, 12568], [7244, 12, 2, 837, 3038, 4490, 91, 69, 136, 12569, 120, 4491, 4492], [19, 102, 5270, 5, 24], [3, 486, 4, 428, 175, 288, 7021, 377, 7245, 36, 157, 2, 1464, 565, 16, 15, 27, 32, 1457, 3180, 523, 2735], [242, 35, 104, 43, 68, 279], [757, 81, 45, 5, 41, 4, 117, 6, 12570, 274, 7246, 5, 49, 143, 12571], [162, 305, 51, 399], [3, 79, 212, 10, 179, 12572, 540, 3, 363, 201, 865, 73, 219, 647], [128, 52, 2820, 2537, 84, 1, 273, 17, 31, 245, 480, 12573, 11, 4, 413, 2044, 360, 480, 35, 225, 3, 2036, 19], [19, 5, 2606, 3669], [128, 1, 12, 171, 491, 50, 35], [17, 99, 2976, 15, 33, 70, 17, 86, 7, 374, 161, 158, 260, 12574], [10, 172, 226, 9], [8, 88, 416, 1, 3379, 4, 189, 75, 404, 27, 4, 408, 66, 2912, 66, 118, 298, 7247, 54, 16, 135, 11, 84, 3734], [945, 256, 499, 82, 246, 1, 11, 1277, 59, 64, 3, 300], [36, 118, 70, 2, 434, 260, 95, 327, 321], [262, 17, 181], [290, 17, 9], [281, 97, 167, 7, 9, 117, 116], [55, 10, 89, 3, 911, 7, 9, 216, 97, 611], [945, 604, 94, 194, 52, 556, 167, 7, 9, 8, 157, 60], [1, 3, 407, 253, 42, 11, 4, 250, 507, 28, 4, 19, 102, 10, 3538], [1, 44, 5, 182, 297, 17, 290, 85, 5, 110, 81, 45], [1, 242, 80, 141, 30, 35, 19, 43, 207, 5455, 5456, 1401, 25, 42, 79, 17, 171, 34, 42, 29, 62, 45], [83, 57, 3, 13, 24, 61, 423, 42, 58, 6, 209, 81, 99, 209, 3, 81, 27, 10, 2103, 8, 42, 63, 28, 8, 80, 586, 141, 948], [74, 68, 16, 76, 1, 33, 14, 81, 45, 34, 48, 133, 45], [45, 57, 35, 27, 88, 9, 151, 58, 398, 9, 195, 322, 362, 42, 48, 18, 10, 822], [583, 42, 9, 12, 4, 1067, 21, 287], [3, 29, 90, 4, 12575, 34, 3, 46, 627, 525, 5364, 2164], [174, 2143, 564, 1], [7, 593, 24], [766, 9, 1, 76, 7248, 257, 78, 611, 30, 99], [2191], [3, 599, 33, 273, 6, 84, 231, 71, 56, 52, 12, 51, 4, 1495, 11, 2667], [20, 1169, 600, 14, 165, 65, 34, 50, 231, 70, 5, 13, 2, 668, 74, 1959, 718], [5, 65, 13, 2, 3329, 1, 1945, 6, 1959, 3, 438, 8, 1066, 5, 87, 1698, 8, 1631, 1011, 1249], [84, 401, 73, 263, 5457, 6, 1367, 263, 12, 313, 11, 12576, 1905, 51, 305, 2926, 1908, 398, 169, 26, 259, 381], [55, 22, 104, 7249, 82, 4, 2179, 900, 66, 3, 47, 547, 170], [34, 105, 6, 4315, 55, 2489, 102, 104, 20, 1056], [196, 280, 19, 104], [5, 83, 107, 18, 5, 83, 5, 626, 1894, 5, 48, 91, 602, 6, 19, 27, 307, 5, 75, 215, 268, 691, 11, 10, 360, 83], [309, 11, 2, 347, 2465, 88, 104], [5, 1679, 100, 7, 1, 58, 5, 13, 7], [3858, 296, 13, 71, 3, 29, 109, 44, 6, 86, 59, 1732, 74, 296, 29, 86, 494, 655, 2, 243, 12577], [172, 12578], [52, 4, 857, 16, 141, 12579, 1], [3252, 513], [12580, 90, 38, 52, 12581, 14, 2, 180, 24, 32, 4, 817], [162, 5, 51, 1], [23, 98, 1384, 1, 11, 7250, 8, 3, 86, 42, 728, 560], [85, 58, 5, 189, 345, 8, 1545, 2767, 217, 72, 104, 15, 12582], [58, 5, 86, 4, 1802, 1072, 47, 550, 647], [2, 755, 20, 337, 8, 1397, 8, 23, 197, 24], [805, 181], [104], [1, 24], [5458, 13, 2314, 103, 2768, 8, 1115, 1224, 305, 111, 3136, 6, 12583, 2, 12584, 8, 1086, 7251], [23, 1191, 6, 4, 710, 142, 157, 3799, 11, 7252, 137], [274, 12585, 40, 428, 946, 6, 134, 111, 1800, 3380, 12586, 7, 1], [4, 884, 2769, 49, 1108, 12587], [22, 189, 2494, 124, 237, 213, 12588, 12589, 660, 49, 2757], [174, 48, 5459, 120, 56, 396, 174, 12590], [888, 1], [422, 104], [8, 2352, 3, 210, 62, 42, 222, 2352, 129, 4, 1213, 8, 4, 1, 510, 51, 17, 37, 552, 85, 42, 11, 10, 844, 321], [367, 573, 4952, 47, 4, 12591, 12592, 288, 970, 8, 52, 47, 5460, 5461, 12593], [3, 29, 594, 15, 116, 56, 12594, 1666, 8, 31, 116, 48, 33, 304, 634, 5, 61, 1504, 27, 1155], [80, 77, 57, 1164, 4419, 3, 131, 144, 15], [43, 1, 55], [1906, 243, 457, 159, 28, 165, 738], [271, 1498, 54, 116, 3039], [4, 101, 507, 21, 2, 236, 11, 4, 3152], [3848, 15, 117, 11, 50, 24], [117, 11, 4, 19, 24], [7253, 743, 997, 174, 726, 116, 1012, 116, 7254, 43, 68, 63, 2024, 4353, 101, 2966, 44, 743, 116], [403, 23, 96, 18, 12595, 5315, 15, 109, 12, 2845, 357, 6, 81, 6, 1030, 7, 1034, 12596], [150, 13, 2, 496, 2, 1130, 118, 24, 54, 18, 12597, 267, 274, 3381, 12, 96, 224, 6, 70, 35, 21, 15, 1284], [683, 71, 6, 409, 97, 837], [112, 77, 13, 12598, 17, 368], [7016, 12, 525, 24], [1044, 49, 1893, 720, 311, 12599, 16, 39, 681, 978, 37, 1346, 86, 4, 28, 2, 332, 962], [23, 18, 10, 193, 6, 4, 1198, 330, 34, 5301, 1], [37, 38, 2, 2045, 658, 107, 224, 15, 106, 6, 14, 2, 9], [890, 139, 20, 1076, 95, 1218, 163, 4332, 61, 7255, 174, 3382, 12600, 42, 210, 12601, 3324, 945, 163, 42, 105, 81, 2353, 170], [92, 1960, 67, 6, 81, 56, 1560, 1419, 2505, 92, 890, 139, 81, 8, 1218], [8, 20, 2, 9], [1, 162, 5, 784], [1, 162, 5, 61], [917], [888, 1, 25], [14, 2, 185, 1, 4319], [5106, 3, 200, 25, 12, 99, 129, 168, 37, 3, 168, 158], [12602, 28, 2, 433, 123, 12603, 16, 2448, 14, 2, 1187], [215, 213, 3, 124, 6, 1365, 85, 12604, 12605, 12, 4, 1273, 12606, 1067], [12607, 221, 15, 47, 3040, 906, 17, 355, 402, 370], [2721, 1503, 1612], [19, 5099, 7, 1], [1, 65, 13, 40, 276, 665, 423, 1446], [579, 5, 636, 71, 209, 3, 64, 949, 55], [5, 636, 3, 64, 2178, 949, 12608], [29, 139, 92, 470, 1871, 23, 33, 192, 6, 683, 59, 57, 70, 5, 2, 171, 30], [36, 330, 2912, 49, 5, 144], [284, 1, 85], [49, 5, 362, 5, 46, 207], [55, 3, 29, 41, 777, 641, 357, 12609, 720, 23, 33, 854, 12610, 39, 9, 14, 12611], [158], [4493, 318, 73, 219, 5462, 203, 9, 29, 110, 13, 2763, 4197, 36, 13, 12612, 2723], [1, 43, 42, 48, 42, 65, 13, 2, 392, 1407, 353], [447, 3822, 8, 202, 818, 88, 2, 1], [8, 71, 12, 7, 57, 23, 614, 6, 61, 21, 4, 412, 69, 257, 263, 7, 144], [109, 42, 168, 11, 246, 25, 226, 8, 42, 253, 2, 25, 69, 317, 19, 13, 5, 20, 2, 104, 7256, 387, 639, 1534], [88, 1, 71, 59, 42, 61, 509, 369, 3, 157, 88], [3, 105, 137, 7257, 99, 624, 1300, 1], [2825, 7, 181, 12613], [5463, 9], [58, 3, 44, 6, 3383, 531, 42, 120, 56], [3, 452, 62, 149, 3, 29, 19, 27, 39, 9], [55, 15, 1, 30], [1678, 9, 129, 4066], [12614, 7, 12615, 21, 39, 9], [], [101, 31, 15, 190, 1054, 26, 1018, 4092], [52, 65, 13, 2, 322, 391], [1874, 4, 1909, 458, 6, 3024, 82, 4257, 770, 7258, 12616, 5218, 5464, 371, 3324, 1962, 2, 112, 2934, 6, 12617], [32, 42, 63, 349, 12, 4, 19, 144], [10, 1, 317, 110, 62, 5, 37, 369, 523, 42, 81, 59, 25, 139, 19, 651], [80, 203, 183, 30, 487, 110, 349, 4, 183, 1, 11, 4, 261], [495, 69, 7, 209, 16, 2, 2541, 8, 2, 24, 317, 1642, 18, 4, 12618], [200, 5, 70, 98, 978, 353, 1672], [12, 15, 392, 16, 158], [1140, 7, 9, 65, 13], [576, 52, 198, 405, 7, 1, 102, 11, 1658, 2118, 27, 4, 763, 16, 4, 1859, 381], [113, 17, 22, 25, 46, 2016, 88, 2, 1, 25, 48, 202], [7259, 842, 5, 54, 8, 124, 2, 120, 260, 13, 2, 1], [180, 280, 299, 52, 47, 18, 331, 460, 7260, 1873, 13, 2, 1], [13, 1, 8, 2, 2046], [55, 3, 1560, 257, 7, 9, 35], [221, 91, 32, 10, 25, 1598, 6, 4, 347, 8, 440, 8, 3, 47, 11, 2, 7261, 28, 778, 123, 4, 179, 95], [379, 1021, 46, 1845, 84, 1692, 478, 55, 33, 2, 607, 7262, 7263, 1336, 63, 58, 147, 218, 52, 48, 2, 161, 399, 16, 4, 742, 178, 55], [3, 33, 29, 131, 28, 65, 51, 356, 38, 3, 72, 158, 11, 7264], [339, 245, 3311, 129, 2, 885, 12619, 32, 384, 1, 65, 180, 358, 98, 4494, 12620], [4, 1203, 16, 39, 9], [1186, 3041, 98, 12621, 11, 7, 83, 38, 120, 189, 480, 4, 12622], [269, 26, 84, 12623, 52, 544, 686], [37, 5, 47, 11, 2, 275, 706, 81, 6, 246, 2400, 20, 2, 104, 340], [113, 17, 71, 7, 372, 185, 5, 220, 1463, 6, 14, 2, 275, 8, 81, 6, 2, 3042, 5, 2, 104], [57, 58, 5, 196, 417, 122, 23, 117, 916, 5, 2, 711, 31, 5, 131, 687, 133, 393, 499, 1475], [20, 1, 11, 1652], [10, 177, 121, 22, 215, 1477, 151, 14, 11, 4, 1198, 426, 3, 1813, 6, 14, 1339, 13, 39, 89, 1484, 1, 55], [241, 1, 188, 3, 33, 486, 20, 610, 448, 8, 3, 801], [12624, 10, 917], [7, 9, 249], [3, 683, 82, 4, 434, 12625, 6421, 114, 1895, 1], [12626, 1, 28, 54, 16, 10, 12627], [94, 325, 57, 582, 38, 2, 207, 91, 420, 173, 439, 12628, 52, 46, 132, 549, 972, 546, 115], [15, 2, 417, 193, 16, 1275, 78, 1391], [8, 3, 109, 14, 5025, 369, 3, 65, 13, 662, 224, 60, 161, 2765, 12629, 1402, 30, 1, 13], [12, 52, 1485], [5, 49, 1031, 13, 2, 2319, 1145], [337, 16, 7, 68, 9, 4937], [12630, 9], [432, 44, 2, 2283, 25, 18, 186, 46, 475, 59, 17, 26, 76, 798, 25, 3859, 326, 37, 122, 361, 10, 4495, 41, 4, 9], [172, 1, 533, 45, 133, 6, 28, 7265], [1521, 510, 6, 10, 730, 1283, 12631, 81, 59, 45, 8, 12632], [3, 46, 105, 12633, 82, 43, 207, 1421, 7266], [3, 94, 143, 12634, 970, 7267, 10, 1, 8, 9, 14, 1955, 169, 115, 193], [23, 61, 6, 346, 7, 180, 312], [55, 410, 32, 4, 265, 7, 208, 5348, 11, 12635], [1], [12636, 65, 33, 13, 5], [89, 30, 1], [23, 56], [1391, 5465, 12637, 12638], [695, 177, 71, 5, 86, 5466, 566, 15, 55, 3, 47, 1626, 7, 1], [447, 272, 5467, 18, 80, 9, 51, 59, 1313, 211, 1296], [1, 5, 459, 493], [523, 42, 96, 81, 251, 1, 1004, 57, 42, 12, 411, 81, 6, 42, 33, 61, 224, 2120], [19, 35, 9, 196, 411, 9, 55], [19, 35, 9], [243, 457, 711], [503, 3790, 1], [31, 20, 2515, 59, 71, 209, 20, 462, 70, 88, 7, 60, 1, 45, 6, 17, 8, 5, 87, 20, 2121, 2863], [3, 5359, 37, 5, 150, 3860, 20, 2331, 107, 897, 2135, 5, 210, 79, 170, 674, 782, 5, 1150, 1818], [104], [422, 9], [97, 1, 26, 29, 44, 99, 209, 501], [7268], [20, 48, 356, 56], [123, 48, 14, 98, 2770, 144], [7, 4434, 2997, 6, 350], [3823, 276, 58, 133, 15, 1], [3, 300, 22, 12, 33, 2158, 13, 2, 1, 493, 2, 109, 14, 1015, 32, 115, 151, 101, 28, 2697, 82, 12639], [63, 605, 10, 30, 8, 367, 7269, 47, 2, 1, 33, 13, 7270, 12640], [23, 61, 6, 924, 4, 202, 91, 371, 36, 156, 924, 7206, 23, 98, 1805, 2746, 5468], [10, 226, 12, 12641, 1], [4496, 633, 17, 102, 13, 5469, 633, 102, 1450, 7271, 201, 1221, 104], [6125, 208, 13, 2, 1, 38, 3234, 440, 21, 12642], [4, 215, 1260, 16, 4, 673, 27, 10, 12643, 15, 132, 2, 691], [15, 7272, 7, 57, 617, 4497, 199, 617, 14, 214, 38, 217, 79, 76, 2, 158, 18, 4971], [417, 308, 26, 33, 140, 5, 67, 6, 94, 15, 317, 70, 15, 1798, 13, 4952, 47, 2, 2302, 246, 1139, 308], [6, 4936, 28, 722, 2137, 2521, 8, 61, 2271, 2, 607, 213, 94, 57, 66, 109, 58, 1697, 5, 1132, 24], [3, 560, 3824, 12644, 16, 3688, 12645, 8, 1296, 755, 16, 6388, 3384, 51, 1320, 12646, 1090, 5470, 6737], [267, 5, 37, 1572, 15, 47, 2, 1, 420, 16, 50, 6, 12647, 34, 267, 5], [19, 10, 926, 24, 444, 23, 3657, 631], [281, 5, 1, 109, 205, 15, 103, 14, 93, 6, 430, 35, 80, 15, 47, 322, 501, 215, 106, 66, 497], [80, 312, 20, 2, 12648], [12649, 5, 103, 94, 24], [648, 2, 1, 6489], [3, 29, 290, 12650, 36, 1, 985, 15, 6, 1572], [119, 45, 25, 1, 3791, 558, 138, 12651], [48, 2, 1, 7, 21, 362], [174, 2, 187, 579, 2, 301, 2, 47, 2, 104], [43, 432, 146, 58, 2, 1, 30, 1162, 31, 5, 29, 13, 369, 23, 72, 753, 17], [144, 3847], [4295, 19, 35, 99, 128, 34, 7, 13, 18, 56, 1896, 5, 2, 284, 68, 3, 94], [7, 2606, 3669, 286, 988], [3, 572, 7, 589, 30, 2955, 158, 708, 6, 48, 14, 12652, 34, 478, 43, 68, 63, 72, 393, 59, 5226], [66, 198, 137, 612, 738, 289, 132, 137, 27, 1107, 104, 34, 15, 501], [51, 577, 157, 2, 1787, 38, 719, 4, 327, 181, 55], [65, 179, 73, 19], [26, 2700, 10, 1802, 1072, 103, 7273, 5], [23, 48, 2, 56, 3291, 6698, 23, 1086, 8, 7274, 18, 8, 102, 4, 6995], [52, 12, 2, 24, 98, 452, 229, 35, 280], [58, 15, 5, 24], [242, 562, 8, 346, 5, 99, 181], [5, 75, 94, 15, 34, 23, 788, 5, 4, 95], [2394, 130, 2, 24, 11, 2, 2771, 12653, 70, 22, 45, 35, 12654], [1416, 1801, 5, 35, 1], [100, 662, 54, 158], [74, 31, 66, 479, 5, 35, 11, 3830, 8, 114, 5, 27, 263, 628, 6, 12655], [804, 6, 94, 2, 1595, 2981, 12656, 28, 197, 35, 602, 6, 114, 270, 2, 446, 234, 1168, 299, 36, 220, 12657], [3, 29, 279, 31, 15, 2, 12658, 79, 217, 2, 1, 12, 96, 79, 217, 2, 2439], [422, 151, 2258, 6, 20, 12659, 20, 2, 1101, 698, 16, 1, 652, 5], [1121, 724, 52, 47, 525, 24, 790, 1272, 52, 12660, 1375, 5, 65, 1771, 73, 286], [19, 1], [128, 19, 1, 272, 1866, 5, 13, 2, 200, 1157, 34, 23, 122, 6, 1588, 4, 4150, 5, 142], [15, 7, 3228, 433, 15, 1202, 35, 18, 4, 12661, 298, 35, 6, 1, 27, 12662, 12663, 300, 7, 23, 4498], [25, 69, 1, 42, 19, 353, 28, 20, 315, 30, 54, 10, 7143], [89, 1, 101], [32, 4, 112, 3043, 3385, 5375, 46, 105, 64, 43, 9], [269, 5471], [1, 5, 1411, 170], [19, 221, 8, 341, 180, 7275, 7276, 22, 1660, 1819, 118, 28, 254], [18, 7, 2700, 142, 7277, 398, 4, 1650, 65, 13, 165, 12664, 1898, 34, 116, 2, 4499, 26, 3044, 16, 302, 61, 962], [23, 171, 88, 2, 9, 281, 3, 330, 514, 7, 184, 97, 502, 17, 225], [281, 76, 9, 101, 61, 332, 38, 2, 25, 12665, 55], [76, 1, 532, 13, 10, 2729, 3, 132, 5472, 11, 371, 2317, 940], [99, 89, 1, 5, 11, 22, 45, 1115], [5473, 43, 1, 3, 105, 12666, 12667], [221, 60, 25, 49, 344, 283], [12668, 20, 4, 68, 69, 67, 12669, 146, 197, 15, 1], [12, 2, 181], [12, 2, 181], [391, 652, 110, 1044, 1249, 13, 57, 5474, 76, 6, 472, 13, 2, 91, 34, 13, 1, 60, 2525, 45], [31, 1, 238, 795, 6, 263], [7, 85, 23, 5254, 721, 7, 3, 44, 6, 72, 5475, 236, 4789, 4, 7278, 4098, 6, 1878, 173, 10, 4789, 768, 2411], [12670, 1, 4996, 55], [78, 238, 19, 10, 1, 211, 4, 178, 74, 336], [32, 529, 12671, 56, 596, 32, 90, 6, 94, 22, 5476, 91, 11, 3375, 163, 48, 4, 12672], [221, 31, 5, 28, 11, 1885, 15, 882, 130, 2, 7279, 3265, 1180, 7, 15, 2, 7280, 37, 20, 2, 19, 1633], [403, 12673, 121, 52, 41, 12674, 16, 57, 52, 12675, 11, 12676, 5, 372, 13, 2, 2541, 38, 416, 62, 5, 49, 308], [36, 2019, 85, 499, 58, 826, 1577, 1, 59, 389], [5, 41, 32, 4, 1, 1168], [40, 121, 15, 422, 31, 42, 100, 174, 91, 929, 42, 11, 174, 24, 73, 358, 73, 52, 70, 42, 1266], [52, 626, 16, 24], [417, 2296, 327, 181], [23, 156, 2, 79, 423, 31, 97, 87, 17, 312], [140, 15, 726, 55, 1325, 220, 4, 199], [5477, 15, 47, 1715, 34, 1530, 55, 1325, 16, 1134, 2284], [37, 1067, 13, 2109, 353, 2710, 8, 7281, 16, 120, 111, 19, 126, 265, 8, 746, 427, 529, 789], [24, 157, 80, 30, 6, 376, 92, 23, 79, 5, 12677], [43, 193, 23, 18, 2, 12678, 5, 49, 7282, 2093, 1347, 49, 4, 1377, 37, 49, 1418, 7283, 3, 346, 1418, 1672], [29, 14, 2, 24, 33, 81, 6, 50, 127, 8, 14, 127, 16, 2, 228, 37, 15, 317, 598, 73, 4500], [1240, 30, 17, 361, 3, 187, 465, 5], [773, 9], [5090, 384, 12679], [15, 966, 4348, 532, 13, 348, 155, 115, 3, 294, 6, 1869], [95, 1100, 715, 155, 166, 1100], [4, 95, 136, 2, 7284, 37, 15, 1100, 18, 1100, 69, 63, 257, 7], [258, 2, 154, 837], [7285, 488, 220, 3, 6, 192, 2, 12680, 1814, 22, 118, 14, 4, 508, 3667, 21, 1851], [136, 23, 428, 61, 6, 94, 2, 232, 178, 73, 804, 73, 15, 12681, 10, 674, 331, 11, 7286, 12, 98, 755, 3135], [66, 222, 28, 1141, 7287, 310, 8, 14, 179, 7288, 21, 2, 607, 707], [4501, 23, 48, 1491, 6, 935, 20, 977, 740], [4, 172, 24, 70, 501, 16, 111, 32, 115, 18, 4, 2099, 217, 79, 170, 2, 3386, 8, 52, 572, 980], [12682, 12, 5384, 1111, 1422, 1298], [13, 3, 121, 1549], [83], [358, 815, 43, 1357, 1412, 30, 1], [51, 577, 7, 68, 252, 124, 4, 2138, 6, 410, 307, 31, 5, 29, 13, 10, 1242, 12683, 14, 2, 1, 8, 176, 3861], [181], [272, 79, 5, 16, 2, 511, 518, 218, 306, 96, 18, 667, 9, 45], [3321, 523, 42, 2, 144, 15, 59, 4, 2145, 8, 66, 101, 1166, 98, 12684, 16, 13, 546, 446, 37, 42, 109, 87, 6], [7, 33, 17, 1752, 641, 2, 412, 3, 90, 48, 12685, 42, 144, 42, 44, 2, 511, 443], [151, 19, 7289, 2, 1, 252, 29, 19, 27, 17], [174, 1073, 42, 1], [4, 691, 212, 355, 163, 190, 21, 2354, 821, 61, 35, 4, 5478, 574, 192, 506, 163, 420], [3, 64, 2331, 12686, 6286, 21, 474, 92, 7, 5, 844, 15, 3, 394, 4, 120, 91, 157, 4, 4314, 12687, 18], [19, 15, 9, 103, 14, 319], [333, 43, 127, 13, 7, 7290, 12688, 613, 1, 249], [5, 165, 16, 79, 7, 265, 2, 24], [], [1], [71, 49, 5, 12689], [1, 57, 932, 25, 195, 48, 152, 58, 148, 184, 2958, 22, 10, 1447, 241, 57, 42, 911], [242, 80, 353, 1429, 1889, 1022, 30, 195, 2, 3822, 8, 2, 25, 4, 237, 698], [17, 74, 5202, 1589, 48, 17, 27, 7, 3688], [44, 566, 60, 837, 12690, 7, 2946, 1128, 11, 1815, 213, 140, 16, 2947, 12691], [2106, 259, 181], [20, 560, 2, 165, 141, 1], [759, 873, 353, 12692, 8, 12693, 17, 51, 4, 199, 817], [241, 242, 35, 104, 28, 2, 3024, 5479, 18, 186], [7, 10, 312, 1902], [1, 23, 3187], [1, 6565, 3, 70, 77, 214], [5, 487, 806, 7291, 24, 160, 135, 2538, 2538, 2538, 3630], [12694, 12695, 13, 2, 2218, 12696, 372, 13, 2, 12697, 13, 2, 1501, 808, 2, 7292, 8, 98, 3387], [100, 39, 9, 14, 434], [1667, 23, 238, 94, 71, 239, 9, 3, 63, 5480, 11], [10, 189, 12, 2, 455, 490, 8, 2, 966, 2126, 6927, 155, 68, 7, 289, 182, 704, 136, 132, 889, 7293], [181, 55], [4502, 28, 84, 30, 1381, 26, 64, 15, 23, 328, 27, 22, 315, 4478, 83, 12698], [21, 1798, 161, 83], [3, 594, 85, 416, 64, 24], [63, 2, 1083, 22, 8, 1318, 2, 1], [101, 89, 1, 11, 12699, 523, 42, 26], [15, 144], [560, 12700, 678, 2659, 396, 37, 23, 157, 10, 310, 11, 4, 56, 8, 61, 6, 376], [1061, 19, 1703, 1279, 27, 22, 1, 30, 25, 20, 105, 61, 6, 28, 6, 2316, 822], [1298], [3, 594, 34, 139, 7294, 18, 22, 1, 5, 134, 6, 209, 12701, 11, 6, 20, 164, 26, 39, 111, 29, 655, 7], [8, 85, 118, 3, 67, 10, 77, 6, 397, 35, 21, 17, 31, 23, 4, 91, 5, 49, 2, 1, 21, 100, 50, 58, 7], [3, 300, 5, 344, 35, 1], [8, 20, 98, 589, 30, 19, 177, 52, 222, 16, 96, 563, 35, 8, 290, 5220, 499, 42, 63, 242, 7, 1, 45, 35, 19, 177], [1, 162, 42, 14, 19, 25], [1, 5, 65, 13, 68, 16, 4, 2220, 102, 16, 6815, 606, 678, 80, 183, 809], [25, 57, 1, 23, 81, 133, 874, 63, 42, 509], [37, 369, 42, 238, 58, 1], [7, 25, 46, 43, 19, 4463, 52, 2, 344, 35, 1, 69, 48, 133, 45, 1517, 1, 216], [20, 779, 878, 5, 73, 1, 117], [20, 37, 19, 609, 42, 81, 2, 320, 45, 21, 217, 69, 29, 131, 290, 20, 779, 878, 42, 73, 1, 932], [20, 2, 185, 141, 4503, 3, 299, 5, 487, 28, 245, 7295, 34, 71, 1038, 5, 1218, 18, 111, 18, 20, 373, 19, 12702], [44, 501, 28, 4407, 5, 19, 104], [417, 2322, 6728], [241, 3, 911, 5, 144, 55, 1416, 421, 15, 142, 21, 5, 162, 4, 5481, 9, 51, 128], [274, 1236, 5, 3743, 3, 14, 7296, 11, 740], [559, 14, 2, 1], [241, 57, 9, 12, 40, 1070, 133, 88], [3, 157, 5482, 18, 1, 30, 25], [66, 41, 2, 404, 10, 153, 128], [422, 36, 44, 201, 158, 11, 1744], [55, 88, 36, 44, 68, 127, 2304, 3, 86, 15, 190, 7297, 34, 447, 116, 7298], [58, 15, 24], [52, 12703, 149, 2087, 808, 111, 52, 121, 7, 5, 79, 17, 2, 1, 8, 3, 62, 5, 210, 7299], [], [221, 68, 79, 17, 2, 849, 2736, 55], [219, 3, 62, 5, 13, 15, 38, 1334, 49, 1012, 698, 16, 804, 5, 118, 14, 270, 2, 141, 1, 59, 2, 186, 1304], [52, 121, 12704, 1, 12705, 4504, 37, 328], [113, 80, 1, 6, 139, 79, 17, 1154], [88, 471, 76, 1, 539, 2130, 3706, 7300, 5403], [2534, 20, 1073, 145], [29, 110, 840, 10, 145, 3, 41, 5, 55], [33, 65, 21, 4, 2166, 145, 18, 12706, 7, 14, 17, 55], [10, 145, 10, 145, 55], [145, 5, 29, 62, 17, 55, 5, 29, 62, 10, 164, 2534], [3, 75, 547, 34, 1649, 5, 3185, 6, 2438, 3317, 20, 727, 1031, 2570], [241, 43, 43, 988, 20, 4850, 11, 4, 12707, 20, 1031, 24, 3862, 511, 4838], [20, 24, 48, 588, 58, 5], [1274, 52, 131, 176, 5, 1097, 1521, 33, 3388, 1399], [100, 4, 490, 14, 434, 15, 11, 4, 651], [42, 146, 981, 142, 39, 490, 2102, 32, 36, 62, 12, 64, 163, 1443, 907, 1103, 26, 365, 64, 1083], [24, 45, 12708], [29, 1105, 17, 269], [23, 48, 2, 5023], [1994, 2409, 13, 2, 89, 1], [9, 276, 14, 9, 37, 37, 3, 487, 924, 4986], [1729, 198, 242, 84, 1556, 26, 33, 3045, 84, 843, 13, 2, 93, 1036, 269], [16, 4, 2421, 448, 6, 79, 4, 970, 609, 3, 191, 5, 529, 1076, 1150, 1, 65, 11, 4, 2772], [1, 333, 151, 61, 6, 12709, 519, 12710, 38, 3, 107, 35, 3, 63, 316, 60, 560], [336, 22, 1, 12711], [3, 62, 32, 4, 1, 64, 17], [136, 1, 3, 62], [31, 5, 75, 397, 4, 1136, 28, 54, 16, 4, 7128, 12712, 1008, 1], [1084, 19, 267, 350, 3, 90, 1, 7, 33, 19, 126, 500, 88, 126, 520, 88, 108, 6, 108, 13, 148, 79, 5, 1258, 1952], [302, 17, 211, 3, 175, 7, 3, 47, 1671, 148, 23, 2, 181], [1, 108, 35, 23, 1041], [43, 34, 31, 5, 1038, 151, 1300, 20, 809, 5, 12713, 12714, 2986], [15, 356, 8, 15, 136, 7, 1958, 1, 18, 15], [403, 92, 116, 43, 87, 21, 2446, 2318, 5, 2954], [403, 1156, 76, 9, 36, 700, 330, 44, 15], [88, 69, 49, 5, 6, 79, 17, 56], [1962, 23, 98, 12715, 219, 52, 982, 14, 270, 2, 141, 7301, 362, 52, 465, 1128, 18, 2, 1697, 5483], [249, 30, 1699, 30, 232, 1449], [950, 12716, 139, 12717, 31, 4, 2136, 118, 15, 318, 14, 417, 12718, 21, 1444], [281, 24], [3, 62, 1], [1, 26, 31, 36, 407], [1, 22, 45, 12, 1933, 356], [1, 5, 65, 1003, 2117, 2605, 779, 100, 5, 484, 50, 1931], [13, 60, 16, 4, 12719, 1788, 36, 448, 49, 681, 34, 33, 140, 36, 29, 62, 57, 374, 81, 59, 15, 5448], [29, 627, 2329, 235, 971, 183, 1, 69, 791, 6, 2, 1387], [7, 4, 681, 16, 76, 348, 3, 156, 12720, 59, 57, 278, 58, 31, 3, 167, 4, 12721, 55, 12722, 34, 12723], [101, 171, 1, 523, 11, 3389], [316, 15, 83], [336, 252, 2448, 33, 372, 13, 2, 104], [1498, 12724, 12725, 6, 186, 10, 12726], [329, 12727, 77, 49, 21, 189, 7, 67, 341, 352, 7, 65, 93, 776, 155, 203, 1, 62, 7], [427, 116, 2, 997, 7, 32, 949, 12728, 456, 14, 1759, 23, 1407, 1743, 281], [12729, 4105, 80, 1], [2574, 20, 10, 455, 1, 513], [15, 322, 1016, 7302, 23, 33, 4, 12730, 117, 92, 23, 119, 212, 978, 353, 4370, 513], [57, 106, 12, 20, 12731, 1445, 9], [403, 7, 189, 136, 4, 199, 250, 226, 7, 3, 58, 57, 2, 1298], [181], [5377, 67, 6, 1, 491, 4505, 37, 332], [41, 1, 7, 65, 13, 7303, 661, 55], [559, 97, 90, 5, 5484, 541, 30, 83], [1171, 160, 41, 811, 160, 60, 1089, 18, 4, 699, 152, 70, 15, 2, 141, 3524, 4506, 34, 150, 727, 4964, 225], [933, 2414], [3, 62, 23, 37, 5043, 60, 16, 394, 12, 2181, 3, 64, 38, 202, 79, 5370, 609, 8, 2989, 70, 17, 48, 44, 6], [1, 57, 106], [25, 139, 14, 2, 1, 8, 107, 6, 4, 314, 261, 5, 330, 121, 367], [26, 43, 4, 19, 15, 317, 15, 2, 19, 323, 369, 523, 42, 81, 2195, 367, 4, 19, 3, 63, 1], [2054, 107, 142, 135, 23, 109, 549, 16, 20, 1, 30, 81, 45, 2054, 107, 142, 135, 15, 61, 6, 14, 378, 18, 378], [43, 195, 33, 100, 5, 57, 61, 6, 582, 195, 48, 13, 42, 24, 30, 25, 82, 2173], [1, 3, 132, 11, 2173, 155, 19, 696, 8, 5, 70, 919, 411, 8, 290], [1, 71, 364, 195, 171, 20, 61, 102, 57, 217, 499, 273, 5, 37, 42, 63, 242, 7, 45, 35], [1, 7, 244, 213, 107, 18, 4, 696], [34, 80, 939, 30, 29, 67, 6, 94, 17, 205, 411, 81, 195, 42, 62, 162, 3, 14, 51, 24, 177], [42, 19, 1900, 56], [576, 109, 1, 3, 196, 80, 1636], [1, 176, 81], [1, 57, 162, 78, 14, 51, 107, 6, 975, 1398, 1483, 42, 8, 20, 1, 19, 177], [88, 316, 80, 1, 30, 6, 975, 1398, 1483, 100, 17, 62, 38, 42, 116, 1], [88, 316, 20, 1, 30, 6, 975, 1398, 1], [42, 79, 17, 171, 34, 42, 569, 18, 45, 42, 29, 62, 295, 59, 447, 65, 69, 19, 81, 144], [162, 78, 14, 51, 241, 66, 61, 290, 107, 6, 975, 1398, 1], [447, 15, 727, 573, 1], [37, 85, 4, 19, 49, 96, 81, 385, 5, 208, 13, 2, 24, 30, 25], [71, 42, 61, 6, 81, 45, 82, 246, 654, 7, 147, 24, 45], [3, 566, 20, 779, 878, 5, 13, 1], [3, 121, 20, 226, 1, 37, 367, 5, 19, 177], [425, 8, 23, 70, 127, 169, 88, 80, 1438, 30, 1, 3, 82, 2118, 2459, 1348, 8, 878, 8, 66, 108, 305, 45, 35, 32, 115, 25], [43, 195, 112, 34, 5, 2, 24, 30, 25, 37, 85, 118, 3, 134, 2, 19, 57, 42, 86, 128, 33, 411], [43, 7, 57, 42, 86, 3, 33, 29, 13, 24, 177, 69, 298, 36, 476, 34, 36, 75, 108, 36, 324, 562], [43, 4, 19, 15, 48, 1, 57, 4, 112, 19, 1636, 28, 7, 1, 54, 80, 1009, 8, 113, 17, 4, 1636], [195, 328, 49, 208, 13, 2, 141, 83, 10, 473, 213, 206, 2509, 7304, 88, 20, 939, 30, 7305, 12, 48, 2, 106, 42, 171, 19], [195, 61, 6, 505, 127, 88, 20, 1, 30, 150], [8, 139, 14, 2, 1, 216, 25, 8, 91, 35, 8, 229, 35, 21, 7, 30, 1866], [8, 69, 121, 3, 210, 13, 531, 162, 4, 19, 42, 41, 45, 82, 42, 216, 7, 35, 411, 8, 139, 1233, 8, 1, 195, 48, 2030], [8, 85, 118, 3, 279, 57, 2, 1, 30, 25, 86, 8, 42, 29, 594, 71, 19, 939, 42, 65], [8, 5, 41, 7, 24, 11, 20, 12732], [1, 3, 29, 131, 81, 3, 131, 290, 20, 24, 30], [1, 3, 44, 2, 310, 411, 81, 29, 475, 59, 17, 33, 70, 362, 5, 229, 35], [1, 195, 48, 3, 109, 29, 19, 13, 350, 85, 4, 19, 49, 5, 110, 81, 6, 17], [1, 195, 48, 20, 1154, 8, 369, 12, 12733, 69, 72, 45, 13, 7, 28, 20, 963, 30, 102, 10, 1447, 12734], [1, 149, 42, 67, 6, 290, 8, 5, 210, 229, 35, 8, 238, 70, 2, 394, 8, 45, 28, 80, 1565, 30, 102, 10, 186], [1, 210, 66, 33, 2277, 22, 45, 1157, 57, 106, 5456], [1, 28, 4, 19, 102, 10, 909, 57, 42, 196], [1, 61, 28, 2, 164, 230, 3, 572, 20, 564, 30], [1, 100, 290, 225, 162, 5, 51, 74, 49, 5, 61, 6, 1, 35, 1404, 3, 86, 20, 61, 6, 1, 35, 361], [1, 563, 35], [1, 7, 72, 2924, 139, 1, 139, 70, 919], [1, 42, 2, 593, 241, 365, 30, 25, 874, 35, 9, 42, 48, 133, 295], [1, 42, 2162, 398, 16, 212, 1067], [1, 47, 3, 81, 6, 42, 411, 8, 28, 102, 10, 1447, 241, 1, 25, 42, 133, 7, 164], [1, 57, 3, 200, 229, 35, 88, 3, 12735, 262, 88, 79, 42, 8, 3, 191, 42, 220, 238, 563, 35, 1, 174, 19, 7306], [1, 57, 43, 15, 456, 16, 4507, 129, 42, 235, 218, 42, 210, 229, 35, 51, 2173, 1526, 314, 261, 11, 2173, 2459, 19, 177], [1, 69, 19, 137, 34, 5, 8, 71, 118, 42, 62, 57, 3, 366, 3, 29, 19, 27, 1565, 30, 25], [1, 69, 137, 195, 48, 475, 59, 5, 74, 20, 141, 5456, 30, 228, 51, 1454, 3, 62, 25, 51, 1454, 6, 37, 369, 42, 72], [1, 369, 523, 42, 81, 59, 8, 85, 364, 523, 42, 96, 81, 45, 34, 48, 58, 43, 1781, 43, 267, 21, 1392, 10, 446, 24, 177], [1, 5, 49, 48, 356, 411, 81, 6, 17, 57, 820, 16, 7, 58, 5, 48, 594], [680, 1], [430, 76, 9, 12736, 563, 17, 51, 2173, 1526, 314], [136, 1, 69, 1076, 1, 195, 2819, 8, 1944, 88, 20, 365, 30, 177, 411, 20, 70, 630, 65, 13, 2, 1496, 24, 6725], [135, 100, 17, 72, 15, 127, 1113, 371, 20, 144, 30, 29, 594], [71, 118, 42, 62, 31, 3, 29, 19, 27, 5, 1314, 5, 29, 369, 3, 41, 242, 20, 144, 30, 35], [3, 300, 42, 2, 19, 25, 42, 2, 939, 141, 1, 42, 86, 22, 2, 178, 932], [1004, 57, 20, 226, 12, 939, 30, 134, 17, 2, 112, 1636, 9], [12, 7, 32, 5, 44, 6, 72, 5, 372, 13, 2, 141, 1, 3390, 8, 45, 162, 42, 14, 51], [176, 81, 23, 61, 6, 70, 38, 42, 75, 81, 42, 61, 6, 14, 81, 13, 2, 144], [100, 1385, 22, 8, 290, 139, 14, 2, 24], [128, 85, 174, 586, 878, 42, 6, 14, 2, 1, 216, 25], [563, 35, 88, 8, 139, 7307, 54, 8, 108, 20, 324, 35, 24], [7308, 57, 422, 1, 66, 61, 6, 5359, 20, 2, 356, 639, 1534], [576, 10, 1154, 46, 43, 1, 216, 25, 3356, 102, 10, 45, 19, 25, 23, 48, 20, 1154, 241, 1565, 30, 25], [25, 3, 47, 116, 51, 12737, 3, 363, 6, 61, 28, 10, 2067, 8, 3, 262, 42, 51, 12738, 576, 42, 2, 1], [25, 3, 109, 29, 134, 2, 635, 19, 34, 31, 42, 131, 81, 45, 88, 108, 20, 324, 35, 8, 2650, 139, 14, 2, 141, 1], [25, 42, 33, 79, 17, 2, 1, 215, 106, 3, 536, 23, 2, 19, 25, 28, 54, 116, 8, 151, 229, 42, 57, 2, 112, 290, 13], [25, 57, 3, 47, 81, 133, 211, 2119, 74, 38, 182, 20, 2154, 1], [241, 195, 3, 564, 34, 80, 24, 30, 210, 229, 35, 4, 19, 42, 81, 133, 241, 939, 30, 120, 177], [241, 34, 3, 195, 8, 10, 940, 72, 166, 2571, 37, 42, 63, 411, 8, 28, 102, 10, 186, 74, 42, 63, 874, 1310, 30, 7, 24, 177], [24], [24, 25, 15, 4, 199, 1067], [12739, 1080, 196, 20, 4508, 132, 12740, 139, 70, 919, 5, 2, 344, 35, 1], [370, 29, 62, 57, 6, 113, 5, 34, 6, 28, 20, 24, 30, 102, 10, 186], [42, 63, 316, 7, 1, 1836], [42, 63, 44, 2, 2502, 394, 42, 67, 512, 15, 205, 24, 30, 25, 34, 42, 75, 539, 384, 402, 205], [42, 150, 13, 171, 30, 29, 42, 24, 177], [42, 61, 6, 28, 405, 1, 23, 2, 19, 25, 69, 41, 2, 19, 138], [42, 216, 17, 484, 32, 4, 193, 6, 2173, 88, 131, 1, 54], [42, 67, 17, 6, 5024, 2130, 37, 4460, 63, 421, 35, 4, 13, 19, 741, 6, 893, 8, 61, 6, 2173, 28, 7, 1, 54, 20, 1009], [42, 103, 94, 15, 18, 1445, 8, 31, 42, 29, 229, 35, 88, 20, 2, 1, 216, 25, 24, 30, 25], [4307, 5, 362, 4, 9, 3, 81, 6, 652, 183], [369, 523, 42, 81, 59, 3, 47, 11, 2173, 2459, 57, 523, 42, 81, 59, 24, 177], [369, 42, 86, 42, 1384, 24, 30, 25], [367, 1, 20, 2, 19, 1986], [5, 171, 19, 7, 48, 2, 19, 392, 1636, 5, 1496, 3, 29, 259, 11, 2173, 37, 71, 4, 19, 118, 3, 62, 144], [20, 37, 19, 12741, 15, 48, 110, 356, 1, 23, 61, 6, 376, 42], [1417, 181, 57, 59, 22], [337, 1298, 210, 150, 13, 4509, 35, 27, 20, 45, 225], [3, 7309, 11, 20, 706, 37, 729, 17, 1], [29, 5, 196, 1816, 48, 1170], [23, 322, 362, 40, 2, 89, 83, 11, 166, 324, 1619, 2, 12742], [3, 47, 12743, 5, 220, 4, 280, 26, 76, 268, 46, 777, 34, 161, 12744, 92, 3, 74, 5, 960], [1, 1551, 114, 1895], [25, 14, 1498, 9], [19, 5, 1], [2516, 66, 75, 1089, 7, 260, 30, 5485, 5, 41, 149, 7, 9, 29, 2926, 127, 130, 12745], [805, 33, 79, 10, 310, 31, 5, 67, 76, 95, 12746, 2114], [29, 194, 17, 194, 886, 9], [25, 5098, 137, 60, 1, 30, 120, 177, 7, 61, 6, 3582, 18, 997, 12747, 137, 284], [242, 35, 1, 21, 3, 1218, 18, 5], [5, 1632, 17, 769, 9, 3, 87, 7, 27, 1489, 74, 512, 20, 45, 35], [5, 297, 15, 9, 157, 7, 1278, 35, 1, 571, 114, 20, 169, 8, 1218, 18, 20, 203, 30], [3, 150, 13, 3, 33, 41, 791, 321, 40, 2, 89, 1], [29, 14, 2, 1], [5, 33, 200, 1, 55], [23, 2, 900, 30, 1, 1, 1, 1, 1], [55, 17, 8, 33, 400, 116, 8, 70, 501, 16, 1167, 3, 75, 397, 7, 181], [2838, 12, 2, 172, 181, 737, 4, 45, 459, 170], [1, 451], [19, 5, 83], [104], [139, 7310, 17, 44, 5, 566, 16, 351, 2963, 139, 1750, 20, 5398, 142, 10, 977, 841, 3268], [1, 20, 4, 183, 68, 7, 85, 416, 338, 5, 12748], [411, 391, 65, 282], [51, 577, 23, 48, 202, 1, 20, 915, 440, 5, 11, 4, 1653, 731, 320, 211, 5, 220, 1348], [5, 220, 4, 68, 7, 756, 11, 22, 1514, 5, 3341, 30, 836, 33, 19, 102, 8, 7, 1770], [1, 3, 46, 687, 27, 5, 233, 1156, 18, 5, 121, 60, 2274, 45, 163, 3, 1636, 15, 233], [3, 2711, 1592, 20, 2, 112, 2013, 20, 700, 2, 203, 30, 720, 69, 172, 279, 100, 17, 58, 17, 236], [1, 5, 844, 17, 250, 364, 329, 125, 80, 7311, 809], [52, 600, 14, 7312, 34, 52, 1470, 2991, 12749, 3863, 8, 10, 111, 3391, 12, 28, 84, 12750, 36, 90, 3743], [217, 18, 1126, 216, 2, 2161, 2024, 170, 37, 3, 405, 2, 859, 392, 16, 2968, 18, 7, 1, 8, 12751], [55, 113, 4930, 553, 16, 50, 1326, 388, 837, 507, 98, 553, 16, 174, 202, 12752, 507, 519], [2320, 5, 65, 13, 2, 2113, 718, 2956], [60, 3663, 9, 88, 128], [3, 293, 325, 46, 149, 52, 207, 149, 3, 62, 52, 14, 896, 32, 25, 13], [2451, 68, 27, 84, 476, 637, 3, 75, 1552, 1022, 461, 70, 76, 65, 144, 12753], [19, 80, 1, 30], [19, 315, 104, 65, 51, 7, 315, 30, 1106, 758, 281], [165, 5023, 55, 34, 31, 393, 151, 788, 42, 4, 546, 74, 2180, 23, 238, 28, 60, 127, 1278], [29, 9, 17], [3, 134, 35, 18, 4, 12754, 3, 196, 2527, 485, 244, 213], [136, 136, 136, 43, 93, 203, 391], [5486, 5436, 12, 99, 179, 6, 62, 393, 59, 7313, 74, 1536], [533, 133, 1, 525, 4293, 195, 3, 117], [290, 26, 1459, 9, 58, 60, 889, 315, 45, 393, 1864, 371, 7, 71, 5339, 7314], [79, 170, 2, 968, 572, 104], [7, 19, 1, 21, 97, 168, 7, 5487, 6, 1553, 42], [122, 17, 24], [1996, 3, 29, 44, 138, 1238, 5, 816, 5488], [1996, 3, 2726, 10, 30, 3392, 1], [1, 31, 23, 3291, 130, 5, 88, 20, 752, 37, 411], [1, 23, 7315, 3003, 3695, 9], [12755, 135, 88, 1], [523, 42, 7, 183, 7, 174, 830, 12, 2, 1], [1], [462, 12756, 12, 10, 1, 3, 41, 546, 12757, 803, 11, 10, 3536], [37, 239, 9], [262, 17, 181], [181], [12758, 163, 73, 11, 1723, 74, 3656, 73, 11, 12759], [43, 4, 19, 42, 75, 171, 1, 690, 16, 488, 61, 28, 25, 9, 218, 42, 48, 61, 14, 385], [411, 2703, 30, 339, 30, 1], [4, 699, 652, 21, 263, 280, 736], [814, 132, 81, 56, 371, 66, 220, 292, 8, 3219], [104], [559, 1, 104, 243, 5, 75, 94, 20, 104, 730, 345, 260, 141, 77, 345, 11, 4, 731, 320, 5, 46, 2, 91, 5489], [29, 14, 2, 505, 141, 104], [25, 415, 14, 194, 17, 13, 2919, 51, 22, 674, 782, 30, 12760], [549, 1, 12761], [870, 27, 4, 1453, 3839, 1563], [281, 289, 7316, 7, 141, 1, 224, 32, 264, 192, 6, 150, 2, 1102, 370, 21, 170, 6874], [8, 3, 49, 18, 305, 193, 6, 19, 20, 1], [181, 7, 60, 315, 30, 45], [18, 10, 193, 6, 19, 20, 1], [249, 6, 249, 83], [336, 36, 118, 415, 79, 5, 54, 21, 14, 4, 2065, 104, 5, 49, 4510, 417, 122, 1168], [140, 40, 2, 1413, 179, 12762], [12763, 903, 957, 5490, 1274, 2, 138, 11, 4, 30, 8, 2, 138, 11, 4, 24, 51, 4, 199, 148, 817], [1, 3, 79, 622, 108], [1, 5, 87, 6, 316, 20, 30, 6, 19, 12764], [262, 17, 1], [75, 304, 201, 94, 10, 1, 12765], [158], [3, 29, 13, 147, 12766, 32, 143, 202, 617, 65, 13, 765, 68, 12767, 423, 82, 143, 673], [221, 3, 509, 80, 45, 6, 1026, 1], [585, 161, 1102, 1], [2984, 1, 3, 146, 61, 1481, 27, 10, 77, 10, 710, 161, 730, 2224], [2141, 24], [3, 13, 7, 20, 712, 427, 2, 180, 1339, 780, 13, 247, 16, 39, 186, 9], [3, 2931, 4, 12768, 8, 195, 119, 12769, 8, 2122], [322, 13, 2, 1], [33, 2838, 426, 52, 47, 4, 68, 3864, 13, 43, 740, 426, 52, 2, 24], [5, 2, 1, 205, 3, 62, 21, 362, 23, 1591, 1502, 28, 20, 30, 257, 123, 245, 16, 10, 1, 7, 488], [7089, 5, 33, 410, 630, 1315, 5, 12770], [2997, 114, 102, 12771], [3505], [12772], [1314, 37, 40, 2, 1], [161, 24, 210, 706, 17, 108, 4125], [7317, 3003, 11, 68, 12773, 116, 407, 614, 6, 14, 7, 239, 2005, 16, 2, 12774, 412, 18, 68, 95], [526, 43, 2054, 139, 79, 17, 98, 12775, 49, 66, 11, 12776, 5, 19, 104], [57, 2, 12777, 491, 2, 9], [3, 29, 94, 71, 4191, 28, 24, 38, 42, 630, 49, 2, 285], [5491, 1612, 33, 12778, 17], [199, 135, 25, 4, 691, 15, 405, 3, 41, 254, 19, 27, 305, 412, 1], [553, 16, 10, 624, 25, 31, 5, 28, 7, 23, 259, 27, 5, 55, 8, 23, 719, 68, 16, 76, 1, 8, 4241], [20, 1570, 5, 198, 14, 1742, 82, 81, 59, 5492, 144, 13, 5, 1642, 11, 4, 1369, 27, 20, 144, 30, 2326], [55, 33, 28, 12779, 95, 430, 4, 1329], [2, 496, 3, 216, 1546, 1202, 4216, 643, 12780, 6744, 605, 496, 27, 159, 925, 527], [211, 2, 201, 115, 1, 3645, 485], [12781, 2, 12782, 44, 191, 50, 678, 7318, 127, 1721, 1381, 16, 1508, 74, 2, 1721, 1381, 16, 4511], [104], [37, 47, 3393, 12783, 8, 48, 100, 287, 6, 12784, 7319, 2511, 1170, 12785, 2225, 2225, 3, 63, 58, 22, 32, 115, 55], [71, 59, 2297, 391], [403, 252, 194, 69, 20, 79, 2, 812], [10, 586, 67, 17, 6, 7320, 1167], [20, 7321, 3, 14, 224, 10, 7322], [241, 286, 43, 36, 208, 4512, 8, 3, 259, 11, 7323, 209, 5493, 88, 4, 9, 11, 12786], [8, 12787, 47, 727, 179, 8, 6732, 1047, 211, 50, 2257, 1332, 12788, 261, 1255, 12789, 4, 2490], [104], [1439, 992, 75, 12790, 15, 13, 1226, 3865, 4513, 6, 2, 1633], [43, 68, 62, 4, 324, 6, 7, 323, 36, 101, 62, 4, 643, 12791, 1576, 1486, 12, 2, 285], [12792], [7, 7, 53, 105, 79, 2, 1, 361, 53, 45], [21, 112, 3330, 30, 1, 55], [2080, 12793, 15, 305, 61, 683, 4254, 42, 138, 249, 9], [552, 57, 174, 72, 415, 1773, 21, 10, 24], [42, 79, 174, 5494, 2, 1, 23, 380, 40, 2, 381, 7, 4209, 99, 209], [99, 24, 74, 57], [700, 1591, 36, 372, 13, 141, 283], [3, 210, 382, 393, 47, 191, 3, 442, 11, 6889, 12794, 8, 121, 43, 71, 12, 7, 382, 245, 4187, 1242, 7, 32], [128, 252, 5, 49, 415, 4, 796, 181, 11, 12795], [411, 120, 56], [174, 2, 900, 30, 1], [1302, 22, 141, 24, 75, 1514, 5452, 3866, 289, 132, 12796, 241, 219, 4499, 28, 4514, 2495], [12797, 88, 201, 104, 11, 618, 612], [1037, 1343], [190, 12, 110, 165], [32, 1330, 137, 451, 123, 4352, 2, 3376, 692, 5309, 3000, 12798, 452, 197, 4453, 72, 158, 11, 155, 323], [103, 5, 844, 85, 14, 79, 158, 12, 12799, 3, 1279, 12800, 26, 5495, 12, 12801, 14, 79, 2, 1078, 12, 96, 422], [25, 14, 1160, 445, 24, 15, 46, 4515, 661, 16, 475, 69, 147, 1, 19, 85, 29, 42, 28, 4516, 667, 169], [20, 117, 734, 46, 878, 43, 104], [221, 9, 30, 25], [51, 7, 446, 33, 79, 17, 2157], [217, 87, 6, 134, 39, 1, 2, 12802, 74, 1654], [20, 476, 20, 24, 20, 30, 10, 138, 8, 2, 1799, 211, 66, 1066, 57, 716, 938, 12, 7], [12803, 12, 56, 5240], [4, 202, 77, 12, 3515, 130, 155, 166, 1, 18, 135, 78, 1551, 139, 868, 172, 35, 2297, 77, 481, 3378], [29, 192, 161, 1], [43, 33, 2, 12804, 7, 86, 40, 5496], [151, 58, 7, 31, 5, 1279, 6, 114, 20, 12805, 7324, 65, 158, 30, 108, 6, 12806], [122, 60, 201, 12807, 3, 566, 52, 136, 60, 180, 517, 319], [19, 5, 1, 162, 10, 7325], [369, 12, 174, 3668, 1], [42, 8, 12808, 4, 45, 490], [365, 327, 28, 102, 10, 909, 42, 523, 4288, 12809], [58, 5, 196, 5, 220, 99, 6931, 123, 14, 2, 1, 12810], [104], [120, 111, 87, 212, 4176, 6, 2024, 943, 82, 4, 12811, 56, 20, 5497, 12812, 18, 2012], [31, 3382, 3698, 2128, 5048, 12813, 36, 452, 44, 37, 209, 6, 475, 2195, 208, 20, 207, 849, 2736], [66, 29, 302, 39, 9, 55, 1710, 34, 15, 1104, 21, 263, 3, 86, 426, 247, 189, 81, 6, 77, 250, 31, 5, 594], [166, 130, 212, 4, 1814, 8, 4, 120, 202, 8, 355, 68, 233, 4, 763, 56, 2656, 36, 33, 70, 45, 35, 92], [5, 19, 7, 1], [5498, 43, 267, 289, 132, 492, 588, 35, 21, 22, 446, 11, 12814, 7326], [3, 196, 66, 44, 166, 327, 16, 17, 12815, 85, 5, 2603, 7, 68, 7327, 1, 7327], [1, 3, 103, 204, 80, 1822], [1, 1625, 142], [19, 1, 28, 169], [241, 5, 1175, 134, 329, 5276, 299, 278, 14, 2, 1], [695, 1261, 3679, 402], [267, 21, 72, 84, 225, 1], [56, 59, 263, 8, 20, 82, 246, 12816, 5, 63, 72, 3394], [3861, 539, 10, 3538, 802, 549, 30, 1], [5, 198, 70, 17, 348], [3, 29, 594, 4, 87, 21, 3312, 12817, 3, 380, 374, 61, 6, 176, 18, 444, 36, 63, 1650, 378, 641, 4, 1294], [244, 5, 222, 191, 4, 1630, 3756, 16, 4, 85, 37, 239, 49, 7054, 22, 950, 931, 6256], [46, 7, 2, 83], [709], [217, 1815, 273, 17, 7, 2, 1595, 2981, 47, 61, 6, 4890, 10, 186, 1024, 6, 3360, 986, 5174, 1530], [3, 14, 12818, 637, 6, 61, 112, 1398, 234, 2397, 18, 36, 269, 809, 7328, 3, 3854], [3, 259, 11, 4, 387, 16, 2, 120, 56, 12819, 12820, 12821, 162, 111, 168, 2295, 426, 16, 12822, 48, 6, 492, 4, 12823], [74, 2511, 1170, 997, 7319, 7329, 7330, 2733, 414, 12824, 7330, 1455, 71, 416, 317, 67, 6, 316, 7, 35], [484, 5, 158], [569, 59, 17, 32, 4, 106, 238, 70, 17, 65, 89, 13, 5, 407, 33, 119, 10, 24, 26], [57, 499, 58, 5, 772, 82, 7, 158, 2907], [5, 189, 49, 24], [7, 164, 9, 152, 14, 9, 98, 5, 222, 924, 4986], [95, 16, 2, 12825], [151, 229, 5, 71, 209, 16, 2, 181, 3, 195], [98, 1309, 29, 157, 76, 11, 1531, 6, 14, 1875, 4, 1248, 1784, 63, 32, 14, 157, 18, 4126, 4212, 12, 56], [2375, 7, 434, 2318, 107, 82, 2, 2940, 1309, 5, 362, 49, 2, 2773, 1263, 20, 56, 33, 13, 20, 1024], [541, 93, 5164], [242, 20, 537, 1751, 941, 5, 5499, 1981, 4465, 1735, 759, 466, 12826, 12827, 2701, 43, 1357, 1], [36, 87, 6, 139, 479, 35, 12828, 56, 464, 8, 1478, 35, 116, 373, 1938, 2760], [2774, 5, 49, 1239, 19, 726], [36, 72, 3, 41, 99, 239, 1, 188, 3, 300, 3, 46, 41, 4, 117, 68], [4, 443, 467, 16, 120, 56, 12829], [122, 22, 68, 4312, 553, 16, 7, 1307, 2355], [7, 12830, 12831, 12, 2, 4201, 12832], [1, 42, 308, 59, 1748, 1024, 183, 5402], [290, 17, 5, 19, 12833, 2284], [3, 109, 200, 117, 102, 10, 2818, 162, 5, 157, 32, 39, 1301, 190, 3205, 4357, 76, 54, 4, 12834], [5, 49, 98, 609, 838], [5, 96, 49, 2, 187], [4, 395, 428, 555, 4, 673, 12, 48, 12835, 15, 50, 746], [550, 100, 290, 5, 5426, 104], [105, 121, 3, 67, 6, 19, 2, 12836], [718], [25, 497, 313, 17, 11, 4, 2309, 194, 17, 107, 54, 27, 2, 3342, 269, 7331, 3184], [3, 195, 7, 494, 12837, 3867, 8, 43, 15, 407, 17], [2517, 12838], [7, 2, 83, 3, 44, 43, 5500, 6, 94, 7, 209, 908, 1292], [219, 52, 12, 51, 7332, 37, 52, 12, 4, 2023, 104], [7, 7333, 816, 12, 45, 18, 5492, 1292], [2520, 4, 193, 40, 397, 801, 1, 128], [241, 109, 181, 49, 3680, 5, 1457, 2627, 549, 1534], [15, 171, 187, 13, 5, 7, 70, 17, 611, 6, 44, 1759, 11, 2, 1317, 37, 5, 452, 44, 1836], [32, 4, 4489, 11, 4452, 49, 248, 3, 301, 3, 222, 33, 728, 98, 4517, 2115, 7334, 2621, 65, 13, 12839], [241, 37, 339, 66, 398, 103, 14, 20, 1, 32, 115, 12840, 16, 12841], [64, 5, 99, 1, 2064], [32, 22, 12842, 45, 12, 726], [721, 59, 20, 674, 246, 185, 104, 102, 4, 360, 293, 5, 7335], [3, 94, 2, 406, 16, 5, 366, 270, 2, 91, 16, 4104, 2158, 312, 5, 2958, 49, 98, 12843], [55, 270, 2, 312], [55, 12844, 324, 12845, 214, 315, 104, 19, 12846, 28, 51, 17, 1, 30, 916], [693, 42, 687, 27, 7, 183, 1, 18, 186], [286, 12847, 3140, 123, 837, 98, 112, 30, 388], [12848, 147, 12, 1710, 12849, 7336, 12850, 1676, 1057, 12851, 717, 12852, 12853, 3739, 12854, 3727, 965, 698, 9, 2232, 3284, 12855], [12, 18, 12856, 56], [57, 27, 7, 12857, 95, 12858], [108, 12859, 1], [97, 62, 12860, 3, 1557, 15, 34, 88, 3, 47, 13, 2761, 23, 43, 141, 260, 108, 1], [365, 5501], [3, 1918, 3366, 34, 2, 1, 47, 1380, 21, 2, 413, 2903, 710], [20, 2, 1], [576, 664], [5502, 4518, 2929, 12861, 12, 56, 8, 1672, 2408, 103, 134, 5, 4, 298], [104, 3847], [1, 30, 626, 17, 55, 5, 29, 176, 35, 27, 4, 154, 68, 478], [3, 29, 86, 52, 200, 4, 4519, 2078, 204, 170], [23, 96, 162, 7, 1055, 12862, 45, 119, 7, 1468, 27, 12863, 1353], [43, 5, 609, 12864, 235, 5161, 5, 121, 12865, 75, 5, 172, 509, 5, 19, 5360, 5361, 7337], [128, 85, 118, 66, 538, 170, 88, 52, 2, 9, 31, 7, 573], [57, 4, 226, 16, 7, 9, 55, 15, 372, 93], [108, 11, 314, 261, 545, 1155, 19, 39, 9, 92, 25, 55, 7, 57, 36, 21], [52, 103, 87, 269, 904, 18, 84, 12866], [52, 136, 68, 79, 2775, 12867, 3, 86, 15, 21, 534], [19, 7197, 12, 98, 1], [648, 12, 2, 1], [43, 68, 279, 1], [847, 294, 1], [63, 3, 191, 10, 1, 21, 166, 1], [3, 516, 61, 955, 18, 20, 306, 859, 24], [79, 50, 2, 187, 99], [85, 118, 3, 87, 6, 79, 50, 8, 12868, 6, 20, 231, 23, 81, 6, 50, 48, 5, 1496], [3, 64, 5, 8, 1, 64, 307], [3, 79, 5, 9, 55], [3588, 201, 23, 51, 197, 1, 58, 5, 110, 44, 245, 2333, 542, 3868], [766, 5, 1842, 12869, 24, 5503, 151, 1156, 42, 35, 13, 3, 200, 174, 2776, 174, 2537, 174, 795, 2537, 174, 2776, 2776, 174, 2776, 2092, 5118, 5503, 5503], [107, 2872, 27, 263, 181], [9, 39, 115], [71, 1038, 2532, 7, 5175, 4828, 12870, 5, 49, 2, 171, 838], [55, 40, 156, 3869, 3870, 7338, 87, 6, 176, 84, 9, 18, 2, 12871, 3, 196, 84, 746, 649], [29, 113, 57, 4, 19, 6, 12872, 2047, 1700, 31, 5, 86, 15, 7339, 6, 157, 688, 565, 11, 217, 69, 7340, 20, 2, 144], [68, 184, 59, 15, 260, 3, 103, 105, 79, 2, 1, 310, 133, 2, 916, 432, 62, 57, 2565, 495, 137, 27, 34, 15, 46, 17], [12873, 717, 6852, 12874, 3715, 11, 1137, 12875, 12876, 6245, 409, 4355, 7341, 12877, 12878, 123, 12879], [151, 1475, 325, 3026, 151, 14, 108, 83], [7342, 44, 5, 566, 7, 3142, 44, 2048, 7, 11, 488, 1, 58, 14, 1070], [12880, 33, 4, 104, 12881, 380, 5, 452, 14, 224, 727, 12882, 97], [48, 2247, 235, 6, 197, 370, 236], [128, 31, 4, 845, 1023, 3855, 76, 1, 562, 23, 81, 11, 979], [195, 3, 194, 1231, 74, 24, 1520, 369], [267, 5, 4520, 1172], [107, 194, 12883, 88, 104], [372, 59, 117, 6, 239, 171, 1, 197, 116, 1073, 6, 10, 164], [666, 16, 1549], [766, 5, 19, 24], [92, 23, 12884, 314, 27, 2, 332, 30, 1270, 2442, 116, 568, 10, 12885, 222, 15, 14, 2, 843, 1], [40, 65, 13, 4, 24, 767, 49, 1139], [1274, 4, 1045, 1], [3, 41, 183, 145, 7343, 55, 34, 5, 41, 322, 145, 7343, 99, 89, 36, 4, 199, 2029], [24, 45], [145, 143, 315], [4024, 9], [23, 152, 467, 4521, 1062, 3, 3046, 66, 525, 4, 1], [695, 68, 25, 124, 7, 1700, 327, 73, 12886, 7, 24, 82, 12887, 695, 7, 45, 204, 17], [560, 5, 63, 101, 1191, 6, 2, 77, 73, 1063, 31, 40, 136, 249, 20, 717], [1, 19, 5, 26, 20, 4900], [12888, 697, 12889, 12890, 226, 32, 12891], [425, 370, 1, 43, 68, 13, 5, 66], [158], [5, 63, 694, 8, 57, 5, 41, 6, 119, 12892, 2777, 10, 312], [1365, 85, 374, 1835, 56, 558, 224, 129, 126, 12893], [19, 5, 398, 283], [23, 48, 2, 2352, 5, 12894, 81, 12895, 7344, 3, 7345, 5, 23, 43, 12896], [598, 31, 36, 29, 107, 35, 27, 15, 15, 56, 357, 619, 1991, 62, 57, 574, 103, 389, 6, 12897, 380, 212, 11, 5504, 29], [3, 44, 7, 1, 7346, 128], [43, 4, 19, 195, 48, 1, 71, 133, 42, 28, 54, 116, 1, 30, 25, 185, 30], [536, 3161, 310, 158], [3, 29, 13, 15, 1258, 7, 723, 3, 13, 290, 3, 107, 82, 4, 179, 58, 42, 375, 7, 15, 1145, 4522, 21, 17, 48, 6], [162, 5, 132, 51, 2308, 3, 46, 297, 5, 11, 2, 3871], [326, 65, 51, 22, 12898, 2136, 4523, 12899, 5139], [5, 146, 538, 2, 1, 230, 40, 100, 5, 157, 20, 1119, 1291, 11, 50, 4524], [3, 64, 973, 11, 618, 123, 531, 140, 3, 44, 2, 1883, 1366, 618, 8, 1, 14, 1823, 35, 6746, 8, 3, 46, 1412, 7], [1, 14, 2349], [128, 835, 10, 164, 18, 2, 89, 115, 12, 165, 130, 245, 93, 115, 7, 814, 182, 4525, 19, 2, 115, 1, 281], [2774, 646, 66, 11, 7, 9], [20, 248], [31, 20, 70, 2416, 949, 21, 394, 473, 3, 293, 5, 58, 15, 21, 2, 259], [128, 367, 3, 698, 16, 13, 15, 15, 48, 7, 179, 478, 26, 36, 49, 8, 88, 52, 72, 2080, 150, 986], [3, 724, 5, 220, 2, 104, 464], [2943, 120, 1], [259, 116, 8, 63, 12900, 6, 760, 302, 76, 129, 245, 1433, 1129, 123, 2, 937, 480, 213], [49, 66, 58, 214, 3047, 92, 3767, 12901, 1347, 2903, 358, 2335, 12902, 12903, 1579, 2350, 7347], [680, 1, 4317], [56], [9, 411], [57, 4, 19, 12, 329, 27, 350, 5, 75, 79, 4526, 2, 91, 31, 42, 79, 2, 77, 2, 83, 174, 2, 172, 1818, 280], [411, 1], [52, 79, 2, 158], [22, 9, 41, 60, 1222], [241, 5505, 2449, 23, 560, 1626, 6755, 8, 255, 98, 12904, 12905, 28, 51, 17, 494], [23, 122, 6, 430, 4527, 37, 23, 172, 2, 120, 1], [355, 8, 190, 15, 198, 14, 88], [12906, 12907, 7348, 486, 7, 12908, 12909, 17, 86, 16, 4, 12910, 11, 4, 12911, 7349], [167, 2, 1, 15, 48, 13, 5, 63, 94, 4, 2752], [7, 9, 129, 116], [375, 586, 298, 2, 12912, 9, 129, 1901, 211, 2, 2033, 6, 762, 4, 544, 338, 102, 211, 36, 227, 524], [20, 2, 19, 711], [140, 126, 915, 2942, 12, 248], [116, 156, 12913, 105, 623, 36, 49, 4, 12914, 4, 12915, 12916, 56, 12917], [1, 41, 1291, 13, 12918], [12, 384, 3, 67, 6, 136, 10, 4167, 6976, 34, 143, 186, 72, 115, 242, 10, 207, 30, 142], [57, 244, 714, 11, 391], [221, 34, 7350, 47, 330, 2, 2914, 12919, 22, 12, 1232, 8, 12920, 52, 821, 111, 27, 4, 508, 1405, 16, 7351, 980], [12921, 576, 381, 298, 22, 1], [7, 1746, 269], [71, 115, 150, 133, 207, 617], [139, 14, 2, 1, 8, 569, 18, 10, 226, 141, 77, 267, 350], [5, 29, 62, 17, 34, 3, 41, 2, 413, 496, 16, 5, 249, 4, 164, 54, 16, 10, 24, 680, 3336], [3, 41, 7352, 107, 129, 104], [23, 6441, 181], [221, 5, 117, 8, 5, 62, 76, 953, 316, 32, 36, 730, 7, 9, 556, 14, 1440], [5, 268, 87, 6, 139, 208, 13, 268, 141, 283], [84, 837, 30, 118, 512, 97, 5506, 157, 97, 117, 244, 6, 4, 1889, 3659, 18, 84, 388, 30, 1842], [331, 176, 433, 12922, 3048, 72, 43, 140, 2139, 12923, 12, 642, 812, 48, 84, 654, 69, 277, 4, 3048, 3149], [242, 35, 27, 20, 5217, 330, 5, 1], [12924, 9], [19, 78, 31, 5, 1592, 17, 23, 2, 864, 16, 120, 56, 3, 72, 15, 5507], [7, 2, 93, 2154, 1030, 32, 4, 7353, 1, 1502, 19, 118, 28, 554], [8, 5, 2, 356, 3276, 10, 7259, 2062, 132, 243, 3, 216, 228, 125, 143, 617, 147, 1051, 263, 6, 143, 154, 360, 11, 2827], [34, 88, 5, 44, 43, 1179, 57, 111, 428, 395, 49, 13, 485, 7354, 136, 156, 132, 2, 187, 736], [52, 47, 43, 127, 2, 187, 27, 2, 1096, 764, 130, 12925, 74, 7354, 74, 12926], [2581, 1016, 5508, 29, 12927, 4, 12928, 99, 209, 27, 270, 2, 979], [4316, 74, 24], [31, 5, 29, 946, 5, 29, 44, 2, 117, 6, 7355, 7, 14, 121, 3, 210, 946, 21, 4, 386, 16, 2, 1], [221, 278, 67, 6, 512, 4, 386, 16, 2, 1, 2542, 55], [31, 5, 61, 222, 5, 1553, 35, 4, 3041, 620, 104, 74], [24], [23, 1003, 5, 222, 509, 15, 27, 935, 21, 387], [652, 36, 4, 237, 116, 761, 12, 135, 92, 15, 106, 6, 1550, 305, 190, 228, 51], [8, 5, 299, 2, 1651, 118, 719, 20, 4401, 242, 4, 19, 35, 5, 185, 3004], [3, 47, 878, 4, 395, 7, 168, 2, 743, 8, 75, 114, 98, 30, 792, 12, 2, 24], [221, 3, 2464, 5, 1071, 30, 8, 737, 1, 11, 4, 561, 26, 3, 29, 86, 5, 63, 662, 55], [40, 2, 391], [1, 47, 51, 2, 1069, 2539, 12929, 3, 300, 7, 37, 12930, 50, 25, 198, 157, 50, 11, 12931], [23, 12932, 12933, 3, 131, 14, 174, 5509, 333, 2618, 3], [183, 391], [1, 622, 3872, 223, 844, 17, 108], [23, 619, 162, 5, 51, 8, 23, 4, 24], [42, 93, 91, 358, 106, 10, 145], [1], [19, 5, 1], [403, 3, 380, 78, 911, 23, 11, 22, 1, 99, 55], [12934, 1416, 258, 54, 2, 1, 298, 42, 281], [3, 29, 94, 1516, 1], [345, 1], [31, 5, 90, 435, 37, 209, 85, 5, 122, 6, 65, 13, 68, 185, 141, 187], [221, 15, 47, 270, 2, 308, 7, 85, 5, 998, 15, 2157], [3, 118, 1257, 27, 4, 355, 1217, 34, 23, 48, 2, 158], [2140, 8, 4, 26, 8, 1509, 804, 1225, 37, 239, 2823], [1906, 12935, 427, 12936, 4, 111, 16, 5510, 49, 43, 127, 12937, 130, 4, 111, 16, 4, 7356, 2307], [13, 3, 41, 106, 6, 14, 936, 18, 60, 1, 69, 291, 35, 27, 17], [4, 1, 30, 25, 3, 33, 79, 2, 1], [467, 24, 1402, 25], [4051, 1, 29, 90], [26, 117, 39, 9, 18, 10, 138, 59, 42, 147, 71], [7, 71, 388, 12938], [1084, 19, 2923, 24, 5, 49, 284], [7357], [403, 4151, 1080, 10, 226, 12939, 6375, 422, 100, 33, 28, 7, 344, 5, 237, 14, 108, 102, 230, 3, 61, 179], [632, 2, 2035, 24], [533, 133, 4, 144, 20, 2662, 18], [206, 187, 87, 6, 309], [6, 286, 27, 4, 12940, 1], [76, 9, 46, 834, 51, 32, 42, 1353], [12941, 90, 225, 660, 5042], [422, 92, 20, 81, 10, 2318, 553, 16, 22, 7358, 4921, 1545], [469, 15, 28, 587, 78, 152, 14, 56, 361, 55], [151, 94, 5, 189, 3026, 3, 146, 61, 2338, 10, 1009, 3255], [410, 17, 9], [262, 17, 494, 2692], [3, 47, 1268, 7, 1311, 222, 901, 2, 12942, 684, 7, 12943], [7, 2219, 27, 4, 9], [16, 1134, 404, 74, 468, 5, 156, 124, 4, 247, 1110, 12944, 7359, 1009, 8, 32, 8, 5, 652, 2, 56, 3291], [38, 1991, 12945, 424, 84, 758, 102, 8, 192, 801, 11, 4, 991, 4361, 13, 2, 4528, 629, 27, 4, 628], [5, 2, 291, 1, 776], [411, 42, 183, 391], [79, 170, 2, 24, 73, 52, 198], [52, 65, 13, 5478, 7250, 56, 66, 41, 76, 3648], [369, 588, 47, 33, 2, 860, 1347, 596, 3132, 2196, 3, 41, 236], [1, 3, 318, 14, 12946], [55, 66, 146, 100, 39, 9, 1507, 12947, 12948, 22, 46, 57, 36, 2197, 3198], [52, 2, 165, 3502, 12949, 109, 208, 13, 2, 1, 601], [2042, 526, 526, 17, 99, 28, 12950, 123, 10, 4845, 1544, 251, 18, 798, 12951, 133, 5504, 12952, 52, 346, 17, 1, 333], [8, 325, 2151, 211, 3, 1761, 6, 547, 104, 30, 25, 28, 4529, 16, 84, 12953, 23, 1267, 12954], [91, 1481, 147, 6866, 12955, 91, 30, 12956], [55, 221, 95, 14, 5511, 3395, 7360], [6547, 3, 3873, 22, 141, 24, 27, 2, 741, 8, 52, 2194, 35, 173, 2, 141, 466, 13, 2, 1515, 12957], [372, 13, 2, 89, 83], [34, 38, 15, 4, 199, 12958, 166, 12959, 654, 12960, 5381, 12961, 36, 29, 28, 6, 1, 38, 15, 126, 12962], [61, 4, 12963, 250, 940, 198, 14, 2, 5266, 4530], [171, 9], [10, 1, 58, 32, 7, 8, 96, 61, 54], [117, 37, 4, 1827, 118, 14, 20, 56, 3806, 12964], [221, 40, 210, 1863, 316, 7, 24, 6, 263, 74, 113, 263, 162, 52, 47, 37, 66, 222, 33, 61, 258, 68, 953, 11, 22, 620, 392], [12965, 5512, 179, 517, 35], [2308, 471, 17, 4, 406], [3, 41, 20, 306, 30, 18, 10, 1238, 24, 1707], [141, 1], [6446, 5, 1], [1, 333], [85, 5, 146, 9, 17, 13, 7], [12966, 4, 1224, 48, 28, 35, 656, 547, 4, 79, 12967, 44, 132, 1847, 519, 193], [3, 1419, 7, 1, 3748, 47, 12968, 130, 50, 12969], [7, 3797, 642, 12, 134, 76, 6, 4, 3874, 12970], [7, 602, 16, 70, 501, 16, 144, 111, 81, 7, 193], [5, 94, 17, 262, 5, 1], [12971, 5262, 8, 12972, 49, 560, 641, 12973, 844, 76, 73, 12974, 274, 114, 423, 20, 466, 73, 7361], [100, 5358, 1147, 312], [1, 85, 75, 3, 800, 20, 45, 55, 64, 5, 293, 20, 44, 2, 434, 1451, 647], [20, 255, 10, 12975, 11, 20, 1690, 761, 9, 64, 5, 205, 55], [3, 47, 293, 5, 363, 27, 4, 1753, 5163, 820, 18, 5513, 1272, 3134, 200, 5, 7362, 171, 1, 30, 12976], [411, 2703, 30, 339, 30, 1], [23, 33, 265, 23, 48, 2, 19, 104], [369, 7, 1, 47, 484, 224, 551], [24], [241, 221, 8, 19, 4, 1583, 99, 1, 1587], [403, 1, 177], [57, 2, 187, 52, 1437], [190], [43, 11, 4, 12977, 23, 48, 144, 2129], [37, 71, 133, 92, 47, 33, 56, 5028], [3, 64, 5, 99, 2570, 805], [2040, 7, 9, 97, 58, 15], [550, 64, 5, 1], [85, 118, 3, 389, 352, 38, 3, 63, 12978, 24, 7, 70, 43, 12979, 51, 32], [189, 518, 12980, 18, 4, 232, 65, 13, 674, 2356, 128, 23, 309], [151, 428, 204, 7, 1], [5514, 131, 340, 142, 30, 1], [23, 2, 2001, 12981, 5428, 728, 20, 33, 2, 4531, 12982, 241, 8, 5, 44, 2, 231, 13, 2, 83], [13, 66, 32, 105, 502, 4, 1651, 1320, 6802], [55, 242, 35, 7301, 1524, 3, 33, 132, 61, 539, 12983, 23, 93, 92], [1318, 17, 24, 151, 7088, 42], [23, 2, 104, 964], [42, 79, 17, 2, 24, 34, 20, 4, 68, 81, 45, 8, 70, 919, 211, 28, 20, 30, 257, 411, 27, 4, 81], [57, 93, 88, 1, 30, 25, 430, 20, 3011], [7, 25, 4226, 208, 13, 52, 190, 1006, 27, 7363, 253, 8, 75, 729, 2, 25, 310], [60, 19, 1], [15, 12984, 48, 12985, 5, 19, 285, 28, 15, 1777], [4128, 12, 156, 79, 111, 7364, 52, 2, 19, 12986], [901, 7365], [60, 664, 12987, 349, 2, 743, 18, 5375, 8, 3, 2, 607, 449, 1712, 3, 47, 7366], [55, 12988, 15, 1310, 34, 3, 259, 11, 2, 322, 388, 12989, 37, 15, 105, 28, 5515, 7367], [403, 15, 837, 2511, 8, 3627, 4, 4532, 1987], [7, 426, 3, 998, 12990, 469, 3, 486, 20, 12991, 244, 106, 33, 410, 17, 1000, 5315, 3, 58, 64, 865, 95, 12992], [57, 2, 590, 30, 1, 394, 40, 1559, 171], [7, 57, 582, 38, 5, 438, 2, 207], [23, 61, 6, 1012, 7, 19, 187], [1, 5, 330, 62, 3, 118, 61, 284, 27, 54, 5], [4242, 52, 2, 185, 30, 1], [40, 216, 501, 16, 2, 3396, 12993, 5516, 46, 7, 1, 6, 19, 27, 22, 658], [183, 120, 1], [174, 12994, 12, 1031, 2499, 718, 2703, 1], [12995, 4, 12996, 47, 117, 1539, 9, 46, 2395], [158, 976, 102], [40, 2, 391, 26, 65, 13, 40, 1296], [7, 47, 108, 38, 158, 451, 47, 2576], [33, 14, 13, 17, 70, 1, 420], [1864, 699, 1274, 2, 12997, 16, 10, 940, 11, 1436], [1, 3, 262, 5], [1, 3779, 563, 35, 51, 2173, 1526, 314, 261, 74, 1454, 3, 41, 60, 45, 18, 10, 2170, 195, 61, 114, 15, 54, 18, 78], [78, 60, 24, 30, 25], [1, 195, 569, 19, 2965, 42, 19, 5341, 1932], [1, 7, 317, 110, 70, 245, 1237, 83], [1, 42, 183, 88, 9], [1, 19, 7, 3689, 162, 42, 14, 51, 563, 35, 8, 28, 20, 657], [25, 411, 42, 48, 356, 66, 32, 528, 51, 80, 144, 30, 33, 411], [1, 57, 34, 3, 349, 127, 9, 4, 42, 651, 16], [71, 222, 3, 14, 2, 181, 34, 3, 13, 1, 333, 113, 17], [80, 1, 81, 59, 6469, 42, 48, 18, 10, 822, 58, 42, 110, 62, 12998, 65, 13, 139, 65, 1202, 265], [509, 4, 3350, 5, 2608, 32, 1049, 192, 11, 4, 1728, 64, 4955, 4432], [241, 151, 70, 5, 60, 348, 12999], [43, 1], [1, 5, 65, 13, 2, 7368, 2261, 16, 7369], [20, 2, 181], [7, 407, 73, 89, 464, 1552, 4533, 59, 7370, 5517, 1095, 18, 2, 2472, 395, 2961, 12, 2, 2529, 5372], [410, 17, 88, 104], [5, 96, 87, 6, 134, 15, 6, 17, 1, 23, 18, 2088, 8, 13000, 27, 15, 97, 968], [1, 3, 1460, 5, 3, 62, 10, 780, 35], [447, 149, 3, 229, 97, 1, 30], [221, 40, 2, 112, 2332, 13001], [78, 2145, 99, 56, 21, 7], [241, 92, 20, 1, 30, 67, 6, 1257, 108, 211, 292, 115, 1, 680], [5518, 12, 2, 190, 3163, 5163, 1223, 99, 13002, 47, 326, 7371, 7372, 5518, 12, 68, 1101, 13003, 40, 98, 13004], [4, 2523, 49, 56, 10, 89, 3, 94, 57, 5, 1456], [4, 323, 59, 1635, 13005, 8, 13006], [13007, 469, 273, 17, 13008, 49, 2, 13009, 58, 766, 36, 6205], [3286, 1], [13010, 35, 1], [3, 1233, 37, 4, 718, 363, 54, 22, 2428, 3, 44, 2, 13011], [434, 1257, 1030, 15, 47, 56], [13012, 13013, 13014, 13015, 875, 27, 1096, 1622, 18, 60, 918, 30, 2701, 27, 13016, 1634, 43, 5519, 8, 43, 3380, 71, 7], [219, 3, 29, 168, 15, 1046, 8, 278, 13, 2, 13017, 23, 33, 2, 291, 1, 37, 221], [36, 56, 464], [52, 266, 1942, 66, 1373, 52, 2, 1565, 95, 513], [3, 492, 10, 237, 2601, 21, 13018, 178, 97, 4230, 383, 1234, 142, 286, 2619, 245, 1, 7, 28, 11, 20, 193, 225], [203, 9, 87, 2, 7373, 55, 2147, 13019], [358, 815, 43, 1357, 44, 1], [4, 450, 47, 144], [32, 3, 255, 12, 13020, 1454, 8, 732, 1736, 13021, 23, 4, 4534, 16, 2, 13022], [280, 3, 300, 6, 274, 3, 47, 33, 133, 6, 4025, 5, 5313, 59, 39, 9], [286, 576, 52, 46, 52, 4, 883, 16, 7, 412, 55, 34, 23, 362, 7, 120, 2109, 79, 170, 2, 25], [25, 29, 14, 113, 10, 624, 18, 22, 9, 55], [13, 432, 279, 71, 7, 1, 7374, 82, 197, 291, 35, 27, 50, 91, 8, 40, 47, 1806, 17, 4, 413, 761, 1528, 1528, 1528], [55, 3, 81, 6, 2, 462, 69, 121, 44, 2, 656, 13023, 2240, 51, 2, 3234, 1550, 107, 102, 73, 13024, 40, 47, 206], [122, 17, 1, 177], [281, 221, 15, 33, 152, 14, 2, 1, 61, 1906, 116, 8, 7375, 18, 338, 13025, 23, 7366, 36, 49, 205], [497, 174, 24, 315, 483], [242, 174, 104, 30, 35, 5, 640, 24], [519, 1977, 74, 726], [5, 569, 207, 99, 3, 86, 3, 14, 11, 64], [13026, 136, 60, 434, 13027, 34, 12, 2, 966, 83, 55, 1145], [176, 11, 1471, 21, 4, 7376, 699], [1801, 252, 318, 628, 6, 975, 21, 5139], [7, 162, 95, 510, 5365], [714, 1501, 21, 350, 31, 48, 901, 901, 901, 55], [61, 108, 6, 13028, 489, 104], [3, 394, 5, 49, 711], [221, 422, 2157], [242, 35, 104], [29, 10, 25, 17, 1391], [117, 140, 73, 750, 73, 23, 2515, 3, 46, 43, 1, 7377], [13029, 4504, 23, 13030, 3, 64, 10, 1], [5, 2, 354, 851, 615], [29, 28, 17, 329, 7378, 278, 2280, 95, 34, 7, 2, 320, 16, 197, 188, 219, 3, 33, 46, 7, 807], [3, 29, 2280, 95, 650, 5, 914, 512, 7379, 54, 16, 658, 102, 10, 863, 493, 27, 2, 5520, 743], [13, 3, 13031, 3, 318, 44, 6, 536, 34, 23, 33, 48, 362, 95, 565, 914, 73, 28, 7380], [39, 9, 315, 7, 85], [3, 911, 20, 4, 199, 1450, 7, 121, 7381, 47, 93, 8, 7, 5521, 12, 56], [15, 48, 207, 5522, 171, 138], [1805, 145], [1, 49, 152, 70, 15, 1234, 18, 17], [5, 1341, 175, 17, 312], [149, 5, 41, 5, 436, 18, 4, 440, 98, 1, 18, 4, 117, 25, 91, 2326], [110, 7, 1, 136, 6, 1124, 256, 427, 117, 27, 305, 26], [3, 380, 5, 168, 6, 28, 1, 149, 552, 1311, 7, 2520, 100, 574, 974, 76, 163, 33, 400, 1271, 1118, 71, 32, 22], [5, 189, 29, 28, 7382, 58, 5, 5, 101, 958, 2, 2269, 13032, 27, 3875], [128, 25, 80, 830, 37, 56, 10, 310, 266, 110, 2163, 7, 45], [673], [3397, 5, 46, 13033, 34, 2, 689, 25, 503, 1, 25], [2466, 1, 604, 182, 563], [78, 41, 4, 3842, 117, 92, 8, 63, 3, 28, 4, 354, 6678, 117, 92, 31, 1756], [183, 5455, 56, 61, 311], [1300, 84, 30, 1285, 161, 1, 87, 6, 7383, 4, 19, 8, 87, 6, 139, 208, 13, 1262], [597, 35, 5, 141, 1, 8, 253, 17], [7, 118, 14, 2, 2198, 88, 144], [60, 1107, 30, 1, 69, 229, 35, 8, 33, 440, 98, 755, 790], [66, 220, 614, 6, 197, 612, 225, 1], [39, 9, 30, 25, 46, 28, 357, 11, 351, 7185], [3, 195, 356, 1], [280, 3, 566, 5523, 323, 233, 36, 32, 56, 233, 36, 33, 4090], [13034, 5, 100, 2, 181, 58, 22, 6, 17, 3, 299, 66, 220, 431], [281, 48, 350, 33, 28, 45, 82, 416, 499, 38, 10, 710, 443, 412, 12, 4, 13035], [106, 6, 1476, 246, 2093, 2543, 11, 4, 56], [3, 13036, 5, 113, 68, 16, 4, 5524, 826, 5, 293, 50, 260, 510, 54, 144, 8, 15, 200, 188, 55], [3, 346, 5, 99, 104], [7, 5, 104, 5, 119, 45, 21, 501], [15, 13037, 171, 1, 8, 43, 10, 586, 452, 479, 5, 35, 52, 317, 13, 104, 13, 5], [5, 29, 62, 162, 3, 13038, 5, 185, 187], [20, 1332, 51, 7, 8, 5, 29, 62, 162, 3, 259, 104], [241, 221, 4, 13039, 565, 13040, 13, 2, 83, 157, 60, 684, 18, 15, 21, 2, 1102, 31, 5, 67, 1627, 61, 142, 13041], [13042, 362, 29, 598, 13, 1770, 425, 34, 4221, 151, 14, 7, 13043, 92, 49, 5, 328], [221, 23, 142, 23, 192, 6, 2040, 21, 13044, 1903, 37, 42, 165, 61, 1], [37, 36, 222, 733, 59, 3382, 2296, 23, 362, 3049, 816], [174, 96, 7384, 13045, 51, 4535, 2097, 968, 847, 3050, 13046, 7, 2, 179, 651], [356, 3, 299, 1638, 846, 22, 449, 118, 44, 5, 662, 17, 129, 2, 56, 63, 123, 10, 2303], [267, 294, 544, 280, 1824, 21, 13047, 3051, 18, 5, 13048, 5, 67, 6, 259, 4862, 381], [7, 353, 73, 180, 73, 52, 65, 18, 886], [7, 57, 4, 141, 13049, 1, 655, 84, 235, 12, 1139, 21, 217, 69, 28, 5085, 38, 4, 2136, 665], [128, 48, 110, 280, 31, 2, 77, 2, 3222, 176, 15, 1310, 79, 50, 2, 9], [1221, 45, 49, 5, 2848, 74, 144], [9, 30, 25, 128], [1956, 7, 155, 120, 395, 33, 140, 60, 318, 598, 142, 6, 1681, 29, 196, 116, 48, 152, 168, 158, 641, 263], [2100, 2100, 13050], [5, 70, 17, 150, 32, 1097, 8, 858, 1077], [2480, 7, 588, 104], [55, 410, 5, 14, 2, 187], [281, 199, 135, 1, 12, 1070], [31, 5, 67, 2, 9, 61, 18, 4207, 13051, 7, 162, 32, 4, 9, 1563, 8, 3703, 63, 28, 929, 11, 4, 13052], [5, 210, 110, 433, 13053, 478, 5, 1, 128], [3, 1244, 3, 47, 33, 2135, 54, 9, 206, 7, 175, 47, 55], [8, 28, 13054, 1, 133, 126, 500, 8, 61, 2011, 12, 256, 2, 1, 277], [344, 3617, 1030, 1436, 12, 2, 83, 71, 4, 13055, 55], [101, 613, 120, 1132, 62, 57, 237, 21, 202, 1225, 31, 36, 29, 94, 7, 374, 2441, 674, 13056], [649, 44, 501, 3, 745, 132, 6, 2, 849, 371, 2940, 13057, 284, 388, 3017, 649], [267, 6772, 2251, 23, 37, 13058, 3, 64, 197, 897, 1627, 14, 13059, 223, 123, 4, 106, 3, 61, 895, 964], [455, 482, 5387, 86, 2075, 35, 125, 4, 24], [550, 431, 88, 23, 48, 4, 101, 68, 588, 12, 202, 8, 858, 8, 15, 136, 1106, 18, 4, 108, 11, 32, 5018, 13060], [49, 5, 197, 18, 7385, 298, 8, 13061, 604, 14, 2, 93, 5525, 21, 13062, 44, 501, 27, 4, 120, 56, 529, 13063, 3585], [5, 2, 530, 161, 1], [3, 113, 15, 71, 15, 12, 31, 622, 2778, 1158, 1, 74, 1158, 9, 3, 79, 622, 123, 80, 226], [97, 252, 28, 4, 24, 551], [1, 61, 137, 544], [10, 112, 161, 280, 110, 205, 1114, 2, 1, 128], [7309, 1], [6910, 1], [20, 49, 101, 2, 9, 38, 5, 19, 170, 8, 86, 20, 554, 188, 48, 38, 5, 460, 612], [26, 258, 68, 162, 14, 257, 13064, 2179, 235, 173, 4, 684, 776, 802, 4456, 12, 344, 56, 73, 750, 73, 7386], [24, 3261, 281], [13065, 2346, 25, 356, 91, 55, 13066, 47, 614, 6, 28, 54, 16, 7, 1, 211, 52, 47, 35, 2, 1130, 251], [57, 40, 196, 12, 40, 2, 203, 1], [212, 9, 46, 334], [253, 4, 2777, 8, 604, 2905, 14, 3398, 11, 24], [20, 33, 2, 285], [403, 15, 7314, 247, 111, 90, 17, 21, 15, 34, 73, 358, 73, 23, 96, 243, 36, 63, 1, 32, 36, 67], [2, 6386, 16, 480, 5526, 82, 4, 2056, 2, 1229, 768, 121, 19, 50, 117, 11, 4, 24, 239, 259, 220, 396, 7, 115], [31, 5, 46, 27, 217, 5, 63, 96, 376, 224, 14, 2, 9, 8, 48, 4, 5363], [456, 44, 298, 54, 16, 348], [66, 198, 396, 7, 6, 1, 59, 2049, 21, 3876, 10, 504, 29, 13, 4, 1790, 3, 662, 27, 40, 482], [15, 80, 1791, 114, 2, 312, 54, 744], [2905, 393, 7, 207, 355, 1725, 5211, 355, 13067, 7387, 82, 4, 275, 13068, 13069, 74, 13070, 13071], [33, 13, 2, 13072, 235, 2179, 13073, 6, 72, 19, 2309, 2132], [264, 5449], [434, 13074, 41, 2, 2831, 13075, 21], [157, 20, 1169, 423, 5, 13076, 13077, 42, 13, 1212, 427, 15, 722, 5, 618, 106, 19, 102, 83], [13078, 41, 378, 1030, 3399, 3391, 502, 76, 201, 4, 918, 201, 204, 732, 380, 52, 12, 849, 1380], [37, 2604, 13079, 230, 433, 54, 18, 4, 2022, 211, 194, 13080, 173, 4, 2076, 7388, 41, 254], [5527, 147, 9, 43, 194, 17, 13081], [13082, 86, 15, 59, 122, 6, 14, 4, 247, 13083, 66, 11, 13084, 79, 13085], [1, 333, 23, 2, 2577], [3, 210, 1318, 5, 664, 55], [3187, 1], [41, 17, 13086, 13, 898, 1, 7211, 55], [7389, 4, 203, 1, 69, 498, 138, 27, 2, 13087, 6119], [278, 134, 7, 9, 4, 714, 744, 51, 197, 444, 3, 28, 739, 21, 254], [5, 194, 22, 56], [4, 786, 49, 58, 322, 93, 22, 213], [56, 16, 4, 1739, 257, 4, 786, 1547, 215, 213], [43, 5, 2187, 263, 1, 29, 122, 6, 70, 15, 57, 15, 48], [336, 36, 100, 1374, 2616, 1218, 56, 51, 103], [1202, 883, 49, 1843, 1273, 1669, 23, 47, 81, 59, 39, 1211, 5371, 13088], [367, 3, 64, 4, 343, 18, 50, 13089], [51, 577, 1375, 713, 1000, 218, 13090, 8, 1393, 152, 1281, 76, 1, 444, 13091], [237, 13092, 12, 2, 13093, 15, 170, 8, 2, 666, 16, 144, 3, 452, 302, 27, 2, 1295, 6827], [13094, 211, 13095, 1381, 7, 1, 316, 11, 4991, 21, 4, 6362, 1556, 7, 103, 6643, 13096], [584, 152, 628, 5, 117, 11, 4, 13097], [2086, 33, 146, 44, 2, 355, 235, 13098, 1376, 7390, 7391, 13099, 7392, 18, 4, 13100], [2893, 13101, 13102, 120, 1, 284], [52, 428, 93, 55, 29, 9, 1167, 34, 3, 196, 7, 60, 1540, 6, 3595, 45, 13103, 6, 13104, 13105, 13106, 26, 13107], [221, 161, 25, 3, 47, 3600, 1065, 8, 96, 132, 28, 89, 1, 73, 42, 94], [23, 102, 2767, 3, 150, 13, 254, 23, 102, 1062, 13108, 8, 5, 157, 11, 20, 268, 449, 788, 76, 4, 95, 3825], [46, 13, 3, 44, 393, 6, 58, 1, 177, 649], [2585, 13109, 266, 137, 4, 786, 361, 22, 7393], [13110, 13111, 13112, 5056, 13113, 388, 2342, 12, 13114], [447, 236], [6195, 1553, 1359, 104, 75, 28, 24, 249, 51, 2702], [], [218, 174, 2, 3722, 1, 181], [26, 601, 2, 93, 9, 739, 87, 60, 13115, 99, 230, 1627, 61, 13116], [78, 46, 41, 43, 207, 617, 18, 143, 3723, 3, 6987, 147, 14, 529, 8, 45], [13117], [727, 329, 128, 22, 1, 599, 122, 6, 3761, 217, 11, 22, 629], [643, 1], [241, 447, 3, 911, 42, 1389, 6, 44, 1436, 2, 9, 661, 16, 1231, 10, 89], [80, 183, 30, 445, 387, 1412, 30, 1], [23, 48, 223, 94, 20, 260, 269, 161, 30, 769, 1746, 30], [20, 586, 12, 3052, 243, 189, 140, 84, 265, 652, 158, 464, 1960, 12, 10, 25, 13118], [7, 1, 152, 28, 2, 3705, 1276], [5, 33, 192, 2, 413, 166, 3019, 5, 171, 13119, 187], [20, 270, 2, 13120], [52, 146, 14, 207], [33, 140, 60, 13121, 7394, 5528, 2, 13122, 51, 5, 5, 86, 20, 60, 13123, 1065], [286, 160, 47, 811, 6, 44, 13124, 160, 1751, 1540, 220, 2, 1], [22, 22, 1305, 1440, 15, 35, 8, 235, 6, 2327, 2034, 934, 14, 79, 2, 1307, 21, 2, 607, 213, 107, 337, 13125], [24], [13126, 13127, 3, 375, 50, 82, 159, 8, 4, 1018, 5200, 69, 58, 5, 86, 204, 7395, 3, 86, 15, 47, 7396], [2834, 12, 2, 1101, 106, 8, 507, 21, 6582, 1637, 105, 8, 11, 4, 6584, 10, 730, 4946, 59, 126, 13128, 13129], [3, 442, 7, 5, 172, 63, 1043, 25, 1], [286, 447, 363, 82, 3, 64, 5, 6, 19, 5, 8, 7, 339, 1], [13130, 17, 23, 33, 304, 21, 13131, 6, 316, 108, 494, 73, 3696], [25, 57, 42, 3348, 133, 113, 76, 9, 28, 18, 36, 2335, 4977, 45, 31, 36, 46, 249, 294, 15, 54], [3, 62, 71, 5, 13132, 105, 299, 278, 94, 4, 1111, 404, 11, 10, 13133, 293, 5, 63, 168, 3477, 232, 1553, 35, 6, 94, 2, 178], [570, 95, 28, 4, 1329, 7397], [20, 96, 2, 141, 24, 7397], [26, 124, 17, 37, 314, 102, 4, 269, 6941, 1157, 2648], [161, 340, 330, 6, 3228, 21, 4, 9], [252, 20, 19, 315, 5, 216, 2, 186, 33, 6, 382, 17, 19, 4536], [15, 19, 112, 144, 1084, 19, 63, 5, 48, 509, 10, 175, 5140], [3, 29, 65, 13, 120, 248, 23, 48, 554, 8, 1584, 5529, 3, 44, 625, 1069, 37, 72, 2180], [1, 5, 194, 20, 19, 476, 5, 537, 3174, 3, 300, 6, 274, 7, 2, 4537, 493], [1158, 3, 86, 84, 306, 64, 170, 5, 19, 1633, 23, 362, 20, 1679, 14, 37, 1875, 13134, 66, 32, 442], [411, 5, 185, 1, 13, 338, 263, 771, 43, 68, 134, 2, 19, 59, 350, 321, 33, 572, 876, 220, 1639], [3, 44, 256, 7, 5, 29, 83, 156, 375, 760], [550, 83, 740, 11, 4, 5530, 5531, 14, 1271], [5, 1507, 5087, 21, 261, 6, 311, 32, 76, 1], [13135, 6, 28, 327, 34, 210, 44, 7398, 456, 14, 2, 5532, 13136, 135, 22, 13137, 12, 13, 2, 388, 13138, 54, 116], [78, 56, 34, 587], [56, 57], [7, 1, 7399, 44, 15, 6, 42, 18, 1461, 10, 25], [15, 47, 4, 1636, 6, 50, 7400, 37, 4, 675, 18, 5, 1, 136], [43, 690, 71, 209, 5, 1, 8, 13139, 770, 12, 11, 165, 1471, 6, 71, 642, 592, 15, 1230], [370, 3, 346, 7, 5, 196, 162, 3, 259, 12, 1570, 74, 7, 7, 1433, 11, 4, 2743, 523, 1570, 74, 398, 44, 2, 434, 13140], [55, 5, 63, 101, 28, 11, 51, 13141, 38, 20, 13142, 32, 4, 1, 116, 49, 13143], [1, 3695], [403, 1, 13144], [3, 300, 3, 75, 58, 45, 117, 92, 34, 23, 142, 6, 28, 173, 256, 390, 31, 42, 49, 312], [219, 3, 330, 41, 60, 55, 34, 23, 133, 6, 907, 11, 4, 1306, 8, 119, 256, 112, 705, 88, 151, 14, 18, 10, 193, 312], [949, 15], [486, 7, 116, 2, 13145, 699, 6, 4, 7001, 7, 602, 21, 2, 13146], [31, 4417, 42, 210, 330, 61, 23, 142, 312], [241, 94, 13147, 94, 57, 20, 5476, 2057, 13148, 1601, 2, 177, 69, 86, 15, 422, 6, 79, 2, 414, 2, 838], [44, 501, 468, 390, 1], [20, 81, 6, 155, 1307, 11, 1914, 4093, 3, 498, 27, 2, 180, 2655, 11, 4, 13149], [73, 11, 13150, 95, 27, 358, 7401, 13151, 51, 1323], [13152, 362, 28, 6, 14, 2, 13153, 3053, 13154, 184, 601, 317, 52], [23, 33, 72, 15, 48, 13, 5, 220, 35, 641, 2, 13155, 3054, 74, 2180, 394, 2063, 328, 15], [336, 3110, 22, 24, 2440], [272, 1207, 174, 949, 54], [52, 33, 2, 187, 8, 357, 13, 1167, 52, 198, 955, 18, 45], [83, 361], [33, 683, 717, 856, 4457, 218, 42, 62, 211, 7402, 66, 13, 6, 479, 35, 707, 206, 2846, 4912, 55], [2815, 640, 9], [336, 1416, 497, 3, 64, 4, 1], [19, 104], [100, 61, 94, 4, 13156, 9], [13157], [16, 1134, 83, 3, 716, 131, 3185, 6, 137, 4538, 205], [48, 11, 1382, 144], [13158, 12, 37, 129, 4, 13159, 1], [7, 206, 187, 87, 6, 400, 142], [19, 50, 117, 11, 4, 24], [158], [5473, 1208, 56, 26, 8, 23, 5533, 34, 57, 47, 4, 178, 13160], [1, 7137, 174, 754], [48, 43, 34, 286, 43, 38, 5235, 139, 854, 158, 3, 103, 57, 36, 63, 44, 3, 63, 2912, 22, 12, 770], [888, 145, 58, 42, 13161, 13162], [7, 117, 145, 7403], [13163, 2484, 145, 55], [1061, 4, 3045, 18, 116, 355, 4539, 220, 56, 13164], [1301, 22, 9, 198, 14, 197, 51, 13165], [22, 12, 10, 275, 1630, 2098, 13166, 40, 566, 2, 95, 3395], [975, 26, 51, 2, 629, 27, 2243, 3, 2836, 2, 312, 292, 106, 8, 41, 1415, 6, 7404, 2854], [22, 13167], [773, 3, 538, 97, 2734, 8, 32, 34, 29, 175, 17, 1046, 56, 30, 13168, 42, 7003], [1408, 1], [104, 3, 724, 5, 2128, 109, 10, 3675], [3, 29, 279, 57, 36, 12, 36, 63, 430, 76, 9], [52, 2, 2820, 30, 1, 128], [241, 10, 7405, 85, 49, 37, 37, 342, 996, 819, 819, 819, 819, 819, 819, 819, 819, 1], [51, 577, 3, 44, 2, 520, 171, 1], [7, 32, 4, 1781, 604, 415, 28, 1], [93, 1, 955], [200, 3, 844, 5, 49, 98, 183, 187, 61, 108, 6, 13169], [4307, 71, 59, 36, 49, 51, 337, 878, 265, 5, 49, 726], [1628, 16, 39, 1, 943, 46, 45, 13170, 16, 2, 1508, 2230, 612], [321, 66, 47, 10, 1154, 579, 221, 24, 25, 28, 43, 7406], [71, 12, 15, 14, 207, 1380], [4, 111, 69, 197, 51, 212, 2494, 2464, 6, 14, 248], [13, 3, 121, 7407, 87, 6, 139, 14, 2, 24, 55], [43, 3, 58, 48, 301, 6, 1049, 13171, 6, 61, 6, 2, 2009, 13172, 8, 194, 2, 858, 1464, 27, 89, 6346], [5, 141, 1298, 51, 577, 3, 103, 19, 2, 414, 6, 44, 2749, 1853, 197, 6, 608, 980, 1792, 2460], [221, 23, 122, 1836, 46, 1665, 11, 59, 2, 2861, 132, 13173, 13174, 7408, 98, 2845, 386, 16, 2, 1, 617], [3, 67, 6, 94, 7, 34, 3, 13, 56, 601, 55], [3, 96, 86, 52, 12, 2, 24, 281], [95, 45, 46, 43, 675], [206, 13175, 17, 8, 7, 1, 132, 13176], [51, 577, 15, 48, 13177, 140, 7, 21, 3300], [2948, 168, 4, 324, 187, 603, 292, 3017, 15, 3877], [10, 1, 29, 67, 20, 183, 30, 2499, 802, 2533, 91, 541, 30], [411, 5, 29, 28, 245, 24, 19, 177], [1, 411, 42, 2478, 102, 305, 1997, 169, 99, 66, 389, 45, 33, 13, 42, 37, 29, 28, 7, 120, 863, 45, 6, 235], [5498, 162, 4, 19, 12, 7, 51, 2109, 42, 87, 6, 597, 35, 8, 623, 15, 5534, 8, 28, 102, 16, 4, 682], [693, 29, 42, 450, 263, 269, 88, 42, 90, 263, 140, 220, 165, 130, 353, 26, 3, 64, 254, 839, 142, 42, 62, 2948, 328, 777, 201, 42], [232], [93, 509, 7409, 85, 20, 534, 86, 20, 2, 1139, 7410, 673], [627, 7, 1, 8, 107, 28, 60, 16, 22, 120, 1018], [1, 25, 107, 129, 135, 23, 18, 13178, 13179, 163, 1374, 5535, 19, 177, 913, 81, 147, 45], [69, 12, 325, 1144, 30, 353], [69, 364, 12, 13180, 13181, 2, 25, 13182, 28, 84, 30, 257, 1113, 1, 25, 42, 94, 112, 25, 13183], [5, 33, 2, 991, 5391, 10, 13184, 15, 13185], [120, 177, 2041, 2888, 151, 94, 5, 740, 51, 261, 158], [697, 2935, 7411, 21, 98, 4367, 59, 48, 100, 2, 13186, 13187, 28, 173, 20, 2267, 7412], [221, 369, 5, 652, 2, 285], [176, 39, 9, 18, 478, 1109, 29, 113, 76, 295], [267, 1], [622, 1741, 194, 4540, 2959, 133, 147, 68, 4061, 9], [1573, 16, 97, 3173, 1], [7413, 1, 66, 3133, 3348, 6, 5, 1327, 80, 183, 193, 54], [1314, 384, 1052, 7414, 9, 510, 54, 143, 1932, 18, 10, 30], [13188, 9], [1, 3, 3133, 13189, 3, 61, 2544, 6, 521, 10, 826, 564, 483], [1, 3, 2520, 13190, 622, 1158, 938, 80, 1384, 4899, 1731, 235, 3603], [147, 47, 5446, 143, 488, 9, 242, 80, 30, 35], [171, 30, 9], [9, 622, 510, 51, 17, 250, 364], [15, 210, 458, 143, 693, 3, 191, 1027, 3, 299, 622, 672, 827, 3, 124, 4147, 3310, 190, 1173, 163, 1324], [55, 3878, 34, 272, 28, 10, 833, 740, 37, 29, 14, 214, 9], [221, 117, 9], [1910, 79, 50, 1157, 8, 66, 79, 50, 2, 1, 8, 88, 13191], [147, 45, 284, 2, 153, 168, 6, 255, 147, 45, 1446], [330, 636, 153], [55, 143, 153, 47, 2544, 163, 928, 125, 54, 15, 34, 252, 2544, 674, 782, 153, 92], [55, 819, 1, 243, 133, 3055, 305, 3819, 781], [55, 1151, 242, 147, 1, 45, 35, 7415, 810, 125, 17], [192, 113, 32, 1, 71, 6, 259, 126, 4541, 63, 66, 28, 2068, 82, 13192], [5, 65, 13, 2, 1, 25, 6, 17], [262, 17, 10, 310, 14, 2, 187, 3174], [1417, 181], [13193, 92, 242, 35, 9], [3, 394, 3, 19, 80, 1, 205], [23, 48, 784, 2779, 23, 556, 405, 22, 1], [1, 134, 17, 10, 3515, 74, 28, 565], [119, 4449, 9], [253, 108, 1], [253, 17, 108, 9], [286, 576, 1, 43, 547], [39, 1, 132, 854, 36, 47, 338, 371, 292], [2320, 24, 303, 2, 19, 7416, 42, 41, 147, 4382, 13194], [1, 3, 191, 5, 2, 938], [36, 208, 13, 36, 1845, 4, 1341, 3056, 136, 281, 1, 5, 407, 11], [3, 216, 5, 1255, 5, 203, 104], [3626, 23, 122, 94, 31, 7, 1, 47, 61, 74, 48, 26, 17, 26, 3799, 271, 13195, 59, 52, 29, 28, 9], [15, 70, 5, 2, 158, 19, 2, 13196], [22, 12, 1610, 48, 101, 49, 5, 2, 181, 34, 20, 560, 726], [128, 1, 62, 66, 397, 116, 744], [1, 29, 800, 10, 13197, 5276, 530, 30, 1989], [12, 7, 23, 1829, 7417, 74, 584, 7417, 13, 5536], [1158, 20, 248], [33, 194, 20, 496, 93, 1216, 299, 278, 100, 5, 11, 18, 4, 154, 900, 2934, 72, 206, 2220, 34, 103, 14, 13198, 15, 687], [160, 1, 23, 35, 21, 1881, 155, 696], [526, 50, 628], [3, 47, 114, 2, 406, 8, 7, 1, 626, 17, 128], [1, 242, 35, 435, 49, 81, 98], [7410, 12, 98, 919, 21, 144], [281, 6676, 200, 3, 167, 7, 9, 74, 57], [43, 48, 51, 1284, 15, 2, 2529, 5372, 33, 29, 67, 6, 468, 10, 117, 6, 653, 7418, 841, 15, 2015, 536, 88], [7419], [17, 163, 3057, 177, 103, 28, 379, 3310, 11, 7, 1, 99], [5, 633, 11, 10, 56, 63, 361], [23, 48, 2, 2308], [2211, 16, 39, 388, 8, 553, 16, 76, 63, 176, 4, 739, 13199], [140, 519, 193, 7, 70, 5, 2, 83], [56], [140, 9, 13200, 943, 73, 112, 287], [425, 7, 544, 76, 9, 146, 389], [382, 1122], [7420, 13201, 8, 118, 196, 15, 118, 505, 13, 2, 1, 6, 44, 68, 2085, 1724], [45, 12, 56], [7, 1, 87, 2, 13202], [2491, 1717, 5, 44, 43, 7421, 4345, 118, 70, 7, 1, 13, 2, 13203, 7422, 8, 1, 63, 32, 3853], [3, 210, 62, 7, 47, 2, 5286, 372, 19, 144, 281], [7423, 7287, 1325, 1325, 5, 200, 65, 322, 3307, 135], [13204, 9, 1707], [34, 34, 34, 5, 121, 5537, 678, 196, 3, 44, 6, 72, 1, 29, 204, 10, 5537], [736, 15, 70, 1237, 9, 7424], [100, 662, 181], [165, 102, 1742, 660, 8, 126, 2733, 732, 608], [226, 7, 9, 13205, 13206, 18, 10, 4508, 205], [43, 2732, 34, 39, 89, 9, 46, 109, 89], [39, 9, 29, 67, 43, 547, 34, 36, 67, 32, 4, 547], [57, 22, 1346, 2697, 23, 420, 6, 3253, 8, 2583, 84, 977], [13207, 30, 768, 589, 1], [336, 7425, 408, 46, 556, 44, 2, 158, 298, 4, 7426], [179, 1052, 1551, 14, 4, 250, 451, 5438], [158, 214], [321, 85, 15, 65, 13, 2, 145, 138, 491, 4, 260], [13, 3, 109, 67, 2, 13208, 269], [49, 5, 21, 112, 117, 92, 22, 265, 281, 162, 5, 51, 24], [3, 62, 283, 100, 58, 256, 22, 3270, 100, 2338], [15, 48, 634, 790, 9, 650, 20, 44, 2, 13209], [1253, 17, 9, 3, 87, 6, 893, 5447], [242, 35, 1, 15, 65, 4233, 13, 2, 517], [15, 317, 690, 31, 15, 47, 2, 675, 4, 488, 96, 2614, 7, 52, 2, 104, 21, 1463, 6, 14, 2, 77], [1, 3, 210, 110, 62, 5, 3, 47, 101, 19, 27, 112, 25, 8, 148, 362, 407, 68, 16, 76], [1, 290, 17, 37, 3, 63, 70, 5, 242, 35, 195, 61, 6, 108, 10, 45, 35], [1, 411, 8, 28, 102, 10, 1447], [277, 13210, 397, 21, 5538, 10, 138, 917], [141, 5489, 1], [3, 465, 1005, 13, 1900, 56, 13, 350], [26, 13211, 3727, 13212, 3337, 5539, 13213, 3715, 2545, 13214, 13215, 13216, 13217, 3737, 581, 3337, 3283, 9, 13218, 2268, 12], [3, 13, 71, 84, 1356, 18, 84, 235, 2300, 2, 13219, 120, 56, 111, 63, 14, 37, 1182, 601], [3, 64, 120, 3370, 8, 64, 13220, 289, 2344, 509, 331, 16, 338, 21, 2654, 15, 382, 17, 18, 10, 13221], [24], [280, 469, 23, 116, 244, 213, 151, 70, 5, 65, 13, 344, 56, 37, 934, 15, 4, 141, 106, 5, 44, 440], [391, 2925], [20, 13222, 1], [61, 19, 20, 653, 24], [811, 269], [1, 177], [2, 5540, 847, 114, 17, 92, 1, 5, 61, 21, 2, 5540, 8, 4140, 13223, 19, 54, 4, 1251], [2, 1243, 831, 1092, 70, 2, 379, 153, 61, 332, 233, 313, 11, 2, 2709, 310, 3, 63, 28, 5, 440, 18, 4, 2412], [2, 7427, 7428, 116, 568, 4, 13224, 1105, 7429, 241, 304, 15, 330, 132, 1459, 73, 983, 13225, 2, 7427, 7428], [2, 1253, 21, 32, 16, 1044, 5541, 159, 4057], [2, 399, 1218, 147, 1144, 6, 20, 1], [2, 232, 404, 70, 245, 115, 2058], [2, 89, 1, 69, 62, 50, 13226], [2, 339, 1, 103, 633, 17, 102, 155, 419, 817], [2, 1214, 8, 1661, 49, 614, 6, 528, 51, 39, 9, 2780, 2, 189, 198, 105, 44, 39, 9, 528, 51, 84, 77], [2, 180, 30, 2418, 47, 635, 657, 18, 10, 1195, 10, 2610, 1195, 2153, 139, 4, 1195, 1071, 7, 1, 123, 4, 1919, 8, 313, 15, 54, 4, 1371], [2, 95, 33, 4507, 173, 10, 1371, 3, 293, 52, 550], [2, 95, 33, 737, 117, 173, 10, 347, 4542, 10, 731, 347, 1371, 626, 4, 19, 459, 17], [2, 1, 75, 2344, 2, 7430, 27, 2, 1241, 311, 45, 3, 63, 2674, 2344, 531, 38, 1137, 28, 68], [2, 1, 222, 105, 107, 54, 16, 50, 476, 8, 569, 18, 45, 7, 40, 136, 43, 1179, 57, 40, 81, 2195], [2, 1, 13, 5, 87, 6, 28, 19, 117, 155, 264], [2, 1, 131, 28, 2274], [2, 1, 69, 75, 176, 2, 91, 678, 68, 16, 5, 1211, 235, 1, 216, 22], [2, 1, 69, 75, 498, 138, 12, 4531], [2, 1, 103, 14, 705, 6, 28, 214, 31, 36, 44, 6, 1053, 8, 2897, 34, 61, 448, 2472, 175, 27, 13227], [2, 520, 69, 113, 9, 8, 659, 296, 44, 2, 6412, 12, 2, 112, 30, 3870], [2, 138, 136, 2, 611, 164, 84, 343, 12, 2, 780, 84, 730, 12, 879, 84, 2233, 98, 1034, 84, 2781, 2, 24, 26, 84, 3835, 257, 1167], [2, 142, 1, 21, 2, 112, 25], [2, 252, 27, 169, 63, 101, 1268, 2, 291, 83], [2, 391, 69, 255, 1882, 18, 75, 1580, 6, 17, 7, 40, 257, 4, 24, 165, 130, 17, 140, 50, 3170, 75, 1266, 8, 70, 50, 2498], [2, 203, 1, 715, 2, 870, 202, 414, 715, 13228, 7431], [2, 19, 46, 45, 6, 39, 154, 1247, 9], [2, 179, 77, 237, 394, 12, 6, 258, 197, 51, 2, 79, 2485, 8, 122, 6, 3879, 7, 5241, 13229], [2, 77, 62, 38, 2, 145, 33, 1174, 19, 26], [2, 77, 69, 28, 15, 11, 261, 8, 13230, 3, 7432, 5, 78, 4, 112, 1, 78, 58, 57, 5, 58, 8, 58, 15, 219], [2, 504, 12, 603, 2, 1005, 13231, 37, 51, 22, 446, 11, 10, 164, 162, 3, 198, 14, 525, 459, 10, 306, 967, 151, 516, 33, 44, 319], [2, 504, 118, 14, 431, 34, 24, 12, 32, 36, 41, 2330, 2064], [2, 189, 708, 6, 14, 1108, 79, 13232, 1199, 8, 121, 7433, 90, 7, 158, 13233], [2, 189, 18, 573, 1009, 12, 28, 84, 1757, 7024, 8, 4, 1998, 273, 170, 15, 65, 13, 98, 2568], [2, 9, 276, 14, 2, 9, 7, 46, 2, 13234], [2, 9, 223, 14, 2, 9, 36, 46], [2, 9, 152, 14, 2, 9, 1804], [2, 9, 25, 103, 48, 14, 3674], [2, 1859, 381, 259, 11, 2, 56, 3707, 28, 3820, 8, 88, 277, 256, 1455, 333, 13235, 527], [2, 1612, 1612, 153], [2, 762, 18, 4, 7434, 1472, 222, 15, 14, 51, 22, 13236, 3, 13237, 142, 4, 13238, 1472, 12, 1732, 3, 13239, 15, 2, 89, 1, 8, 2, 13240, 4, 13241], [2, 462, 3400, 17, 191, 17, 31, 3, 47, 5070, 8, 38, 3, 121, 43, 40, 13242, 17, 18, 71, 23, 61, 6, 2384, 94, 5, 116, 284, 1], [2, 480, 5542, 190, 2101, 1054, 27, 2, 1621, 2590, 684, 5543, 216, 82, 1965, 2196], [2, 320, 16, 3, 19, 35, 79, 17, 108, 22, 1, 12, 840, 233, 55], [2, 320, 16, 1, 119, 30, 2330], [2, 320, 16, 431, 1, 7, 2, 25, 363, 6, 261, 27, 47, 1082, 9, 188, 8, 36, 91, 29, 62], [2, 320, 16, 171, 1, 54, 13243], [2, 320, 16, 5, 25, 227, 39, 1, 173, 13244, 30, 1], [2, 2108, 153, 32, 81, 3, 383, 100, 240, 58, 15], [2, 2108, 42, 153, 46, 69, 42, 72, 42, 12], [2, 91, 103, 359, 18, 84, 7435, 19, 787, 511, 1, 11, 378, 1608], [2, 2257, 1, 12, 18, 4, 13245, 1185, 7436, 13246, 5544, 165, 28, 13247, 4, 748, 2995, 47, 13248], [2, 154, 193, 6, 65, 21, 2525, 258, 126, 56], [2, 153, 46, 58, 45, 32, 115], [2, 153, 46, 697, 34, 10, 548, 12, 1604], [2, 153, 41, 60, 284, 235, 215, 264], [2, 153, 12, 807, 188, 73, 19], [2, 153, 12, 807, 73, 1156], [2, 153, 12, 807, 73, 286], [2, 153, 87, 2, 13249], [2, 153, 72, 52, 3029, 191, 240, 162, 84, 2003, 163, 84, 13250, 51, 48, 13251, 84, 754, 163, 84, 1250, 51], [2, 153, 96, 515, 82, 215, 264, 188, 369], [2, 25, 222, 113, 5, 52, 46, 19, 27, 50, 34, 109, 58, 14, 7, 85, 5, 146, 191, 26, 247, 16, 4, 106, 2, 1, 266, 308, 59, 7], [2, 25, 103, 72, 4, 884, 59, 2, 1, 8, 1358, 96, 150, 6655, 73, 358, 73, 52, 118, 19, 876], [2, 13252, 579, 84, 1076, 95], [2, 1107, 195, 3861, 1351, 17, 3192, 159, 1766, 13253, 352, 33, 2431, 196, 5, 210, 467, 602, 591, 7, 115], [2, 112, 3043, 30, 25, 62, 4, 137, 4, 112, 3043, 30, 25, 28, 4, 5050, 16, 4, 1, 191, 7, 3043, 30, 25, 141, 1137], [2, 112, 25, 46, 983, 461, 2, 112, 1], [2, 13254, 573, 2381, 82, 4, 354, 7, 603, 41, 13255], [2, 1916, 16, 391, 13256, 1293, 7437, 36, 1128, 130, 4, 3880], [2, 1888, 3401, 163, 667, 13257, 845, 18, 3, 2505, 810, 80, 1], [2, 1328, 47, 298, 224, 2176, 11, 269, 7438, 801, 7439, 7439, 585, 585, 26, 4, 1023, 712, 77, 220, 13258, 47, 225, 1953, 6, 589, 17], [2, 449, 634, 23, 54, 22, 812, 267, 274], [2, 120, 3515, 12, 89, 1640, 48, 190, 174, 185], [2, 2571, 91, 469, 121, 2596, 3, 90, 2, 1, 7, 13, 6, 687, 579, 1931], [2, 190, 1925, 1351, 18, 10, 476, 8, 13259, 17, 288, 3, 47, 311, 13260, 6, 72, 52, 1159], [4543, 121, 4, 518, 52, 255, 18, 84, 2134, 12, 21, 3172, 412, 6, 1293, 170, 34, 4, 488, 12, 4543, 12, 2, 148, 2031, 6, 4], [3160, 2839, 11, 22, 1, 66, 11, 1192, 331], [3625, 648, 2, 1], [32, 52, 87, 12, 2, 7376, 362, 65, 13, 2, 1, 6, 307, 26], [732, 2315, 2892, 1600, 7440, 1601, 2, 154, 979, 16, 24, 26], [8, 79, 2, 2319, 55, 7441, 4, 845, 1023, 149, 15, 362, 65, 13, 52, 791, 68, 26], [701, 645, 46, 21, 3109, 1047, 5, 3881, 65, 9], [13261, 32, 524, 1814, 1607, 4, 139, 8, 13262, 2311, 103, 14, 13263, 5279, 173, 1107, 4408, 13264, 93, 7442], [7396, 317, 594, 71, 681, 40, 12, 1, 5, 12, 344, 35, 3882, 5, 62, 189, 14, 13265, 13266, 29, 2833, 128], [7443, 8, 3, 49, 152, 2690, 11, 1382, 8, 28, 32, 4, 89, 1, 11, 4, 3218, 2247], [7443, 65, 13, 52, 136, 6, 114, 2, 45], [59, 32, 42, 63, 772, 82, 2, 153, 7, 63, 1240, 81, 128, 252, 75, 1175, 783, 45, 80, 55], [59, 6, 14, 13267, 1239, 98, 206, 30, 1], [59, 6, 61, 194, 325, 1, 1809, 4, 1377], [59, 6, 737, 60, 2710, 11, 2, 1105, 2380], [1064, 4911, 7, 36, 110, 124, 6, 86, 59, 7, 7444], [1273, 20, 3058, 8, 13268, 140, 7, 57, 70, 5, 5, 94, 23, 2, 19, 969, 138, 104, 27, 915, 69, 29, 64, 307], [2950, 6, 10, 646, 7226, 15, 5545, 13269, 31, 37, 3, 13270, 7, 2038, 6923, 16, 4, 2060, 232, 103, 2347, 84, 2690, 4544, 378], [4300, 190], [208, 13, 23, 7445, 28, 2782, 27, 2, 1], [428, 1083, 82, 1595, 670, 160, 2834, 49, 99, 239, 24, 11, 22, 13271], [428, 23, 152, 44, 1036, 50, 6, 14, 2, 1298, 29, 5, 1038, 316, 2, 177, 173, 10, 331, 5, 13272, 7446, 13, 2, 93, 77], [2453, 1684, 128, 22, 12, 56, 340], [1299, 10, 1690, 161, 1, 13273], [13274, 273, 17, 6, 338, 76, 1613, 177, 4545, 45, 1, 3, 200], [483, 336, 39, 9, 185], [211, 2783, 449, 344, 16, 7, 25, 14, 5, 3059, 66, 28, 15, 1, 78, 19], [211, 13275, 7447, 66, 87, 22, 128, 1325, 77, 93, 13276, 55], [211, 3, 72, 60, 45, 3, 33, 14, 13, 53, 583, 7, 47, 37, 5356, 21, 20, 109, 2, 1, 53, 764, 18], [211, 13277, 502, 15, 84, 32, 157, 35, 2184, 518, 34, 28, 43, 298, 608, 4, 232, 29, 655, 6, 28, 173, 4, 360, 1957], [211, 2, 290, 11, 4, 489, 11, 154, 2253, 76, 1, 192, 756], [211, 94, 4111, 137, 5546, 2, 535, 449, 892, 3, 222, 113, 5, 23, 1003, 7, 159, 5369, 136, 132, 100, 13278, 23, 1591], [211, 4, 645, 2386, 3, 47, 157, 539, 225, 294, 35, 4, 2458, 12, 2, 344, 35, 1], [211, 5547, 239, 127, 264, 6, 107, 3, 103, 229, 5, 57, 2, 587, 548, 1, 63, 58], [211, 194, 4, 13279, 16, 13280, 3, 44, 107, 6, 4, 4533, 7, 13281, 216, 32, 166, 4146, 65, 13, 1, 11, 13282], [211, 5, 28, 93, 24, 5, 14, 1596, 13, 5, 33, 592, 4, 215, 2078, 13283], [7448, 3, 424, 10, 13284, 421, 6, 1769, 21, 2, 1102, 48, 6, 135, 22, 1, 13285], [3625, 19, 15, 100, 61, 13286, 3363, 21, 4, 9], [13287, 34, 92, 23, 172, 32, 5, 1956, 9], [7070, 306, 859, 13288], [46, 132, 18, 22, 9, 32, 115], [46, 132, 18, 22, 9, 32, 115, 281], [46, 110, 172, 125, 2762, 1], [46, 172, 125, 3883, 9, 41, 69, 3, 67], [46, 15, 2, 1, 38, 68, 16, 4, 111, 5, 28, 37, 1110, 465, 82, 471, 4, 13289, 247, 13290, 184, 182, 1035, 100, 142], [46, 13, 76, 189, 69, 2289, 8, 6551, 6, 176, 36, 7449, 10, 1, 101, 67, 268, 184, 7, 6, 28, 314, 8, 543, 15], [46, 17, 46, 17, 39, 24, 30, 25, 46, 17], [46, 704, 2, 1, 478, 7, 222, 4546], [46, 43, 1, 277], [46, 43, 291, 1, 397, 244, 6, 17], [46, 43, 64, 11, 4, 179], [46, 43, 24, 165, 130, 334, 24], [46, 357, 35, 233, 909, 2274, 544, 233, 166, 130, 4, 275, 2546, 153, 570, 325, 561, 55], [46, 553, 16, 39, 9, 334, 553, 16, 240, 31, 3, 3060, 229, 78, 4, 1216, 14, 107, 785, 10, 13291, 7, 46, 553, 16, 78, 624], [46, 295, 5297, 88, 194, 2, 414, 122, 6, 869, 50, 4547, 9, 62, 40, 13, 6, 28, 167, 82, 4, 108, 8, 44, 2, 13292], [46, 295, 5297, 88, 194, 495, 259, 2, 983, 511, 164, 18, 4, 1213, 3, 14, 13, 1472, 22, 9, 86, 40, 13293], [46, 295, 7, 93, 235, 74, 24, 7, 2194, 1533, 1109, 35], [46, 1573, 13294, 59, 22, 1], [46, 2357, 34, 2, 120, 56, 2429], [46, 45, 13, 19, 246, 25, 1, 8, 3248, 50, 1472, 24, 12, 4548, 8, 40, 72, 20, 128, 43, 1, 23, 719, 22, 24, 55], [46, 45, 322, 34, 10, 1, 8, 10, 734, 621, 63, 28, 4, 2087], [46, 7, 2, 83], [46, 22, 2, 1], [46, 22, 2, 13295, 2670, 2638, 11, 13296, 160, 527, 4463, 484], [46, 383, 757, 3, 3012, 13297, 115], [46, 22, 2, 836, 3, 33, 486, 10, 1, 605, 2, 1, 26, 5, 811, 3, 29, 204, 80, 30, 34, 5, 63, 96, 28, 3402, 792, 160, 1441], [46, 43, 1, 3192, 219, 13, 292], [46, 43, 9, 11, 1009], [46, 43, 9, 783, 1394, 20, 436, 46, 43, 990, 783, 1394, 20, 164], [46, 43, 24, 165, 88, 5178, 24], [46, 357, 255, 212, 154, 7450, 13298, 34, 953, 26, 1900, 731, 56, 120, 3403], [46, 22, 2, 1, 4, 863, 54, 82, 22, 385], [1057, 4549, 3884, 99, 713, 172, 104, 128], [3372, 1159, 1000, 37, 694, 5548, 1], [3158, 644, 570, 95, 163, 32, 760, 264, 32, 13299], [13300, 9, 439, 3, 13301], [1285, 1609, 486, 84, 2184, 338, 27, 7, 7451, 8, 13302, 7, 1, 108, 11, 27, 474, 52, 4525], [1285, 1609, 270, 2, 41, 148, 1, 91], [1285, 1609, 255, 355, 8, 190, 92, 37, 559, 14, 3330, 500, 520, 8, 28, 129, 1167, 52, 11, 4, 722], [13303, 310, 502, 263, 207, 8, 4217, 41, 190, 23, 309], [5034, 13304, 13305, 33, 13306, 2513, 56], [13307, 964, 1429, 581, 146, 64, 2, 189, 69, 257, 13308, 7452, 1376, 30, 108, 6, 4, 2012, 6828, 2620, 13309], [13310, 424, 4832, 16, 17, 215, 13311, 7, 1, 266, 390], [32, 1019, 1290, 638, 24], [32, 3, 191, 21, 12, 64, 163, 13312, 26, 295, 3714, 43, 687, 129, 166, 7453, 43, 52, 72, 40, 72, 43, 685, 871, 13313, 33, 64], [32, 3, 200, 47, 121, 50, 441, 47, 56], [32, 3, 182, 67, 12, 21, 217, 6, 64, 17, 73, 13314, 8, 13315, 73, 159, 3885, 64, 4, 13316], [32, 3, 41, 21, 39, 9, 12, 138, 7454, 2050, 8, 2, 13317], [32, 3, 87, 12, 2, 947, 937, 831, 426, 3, 41, 7, 89, 1], [32, 3, 87, 12, 68, 3, 29, 67, 1320, 9, 53], [32, 3, 67, 21, 10, 457, 12, 2, 180, 517, 9], [32, 3, 67, 21, 10, 457, 12, 2, 180, 517, 282], [32, 3, 67, 12, 2, 947, 937, 831, 8, 2, 89, 1], [32, 3, 67, 12, 2, 947, 937, 831, 8, 43, 89, 83, 23, 1948, 55], [32, 3, 67, 12, 1, 180, 517, 1], [32, 3, 67, 12, 3782, 1407, 8, 348], [32, 3, 67, 6, 58, 47, 28, 60, 9, 99, 647], [32, 3, 67, 47, 947, 937, 831, 8, 2, 89, 83, 34, 92, 3, 67, 4027, 8, 2, 13318, 11, 10, 13319], [32, 3, 67, 12, 6, 3149, 143, 164, 709, 143, 207, 720], [32, 289, 191, 12, 21, 68, 2432, 26, 68, 184, 101, 26, 34, 3, 28, 127, 88, 57, 247, 1, 222, 182, 13320, 34, 13321], [32, 5549, 49, 248], [32, 39, 9, 1428, 1696], [32, 2, 153, 87, 12, 106, 233], [32, 2, 153, 67, 12, 60, 13322, 2339, 8, 3404, 13323, 205], [32, 1, 58, 12, 1851, 28, 554, 163, 671, 13324], [32, 1, 87, 2, 1195, 2153, 13325, 2, 890, 524, 1, 491, 253, 123, 60, 856, 579, 3586, 2241, 5550], [32, 717, 1208, 9, 376], [32, 143, 161, 1582, 235, 1, 13326, 619, 16, 2219, 7455, 238, 28, 11], [32, 143, 120, 617, 102, 186, 478, 143, 207, 175, 51, 264, 288, 78, 376, 218, 5, 146, 4550, 2199], [32, 1019, 1, 62, 7, 20, 10, 916], [32, 1019, 1, 2281, 35, 23, 7456, 227, 240, 142], [32, 93, 184, 456, 107, 6, 98, 450, 7, 32, 117, 28, 240, 740], [32, 9, 169, 12, 13327], [32, 3, 636, 12, 70, 76, 9, 5551, 2198], [32, 15, 114, 12, 21, 68, 1, 6, 458, 50, 476, 8, 25, 192, 172, 562], [32, 10, 1, 64, 17, 32, 10, 32, 10, 1, 64, 17, 32, 10, 1, 64, 307, 5, 46, 172, 27, 10, 4551], [32, 10, 1052, 12, 120, 48, 1343], [32, 10, 9, 41, 169, 40, 11, 4, 1483, 40, 3029, 1, 303, 256, 21, 17], [32, 10, 9, 36, 37, 1395], [32, 10, 164, 3, 132, 22, 587, 32, 10, 264, 132, 27, 319], [32, 10, 638, 165, 44, 51, 577, 292, 183, 1, 518, 11, 126, 310, 22, 6530], [32, 10, 206, 9, 223, 64, 10, 496], [32, 10, 206, 9, 1863, 44, 10, 260], [32, 10, 37, 1430, 1587, 223, 498], [32, 10, 120, 261, 826, 108, 11, 2949, 724, 48, 6, 134, 17, 43, 285, 23, 113, 32, 16, 10, 956], [32, 10, 379, 177, 657, 17, 854, 28, 169, 8, 19, 39, 9], [32, 10, 379, 177, 657, 17, 72, 4859, 169, 8, 19, 39, 894], [32, 16, 2, 2547, 3061, 4, 286, 54, 16, 7457], [32, 16, 10, 1, 62, 36, 4141], [32, 16, 10, 169, 13328, 32, 16, 10, 1, 2452, 326, 636, 15, 15, 46, 2, 1564], [32, 111, 58, 11, 10, 331, 12, 1], [32, 7, 34, 4, 1, 75, 114, 2, 5284], [32, 7, 2299, 1410, 43, 454, 4, 1, 41, 268, 235], [32, 4, 5552, 1563, 5553, 12, 415, 4, 796, 104, 16, 32, 106], [32, 4, 89, 1, 49, 11, 4, 1198, 808, 13329, 42, 62, 85, 36, 46, 41, 43, 401], [32, 4, 89, 1, 86, 36, 183, 8, 32, 4, 3112, 1, 86, 36, 13330], [32, 4, 1, 243, 485, 68, 16, 84, 275, 228, 63, 258, 170, 2, 13331], [32, 4, 1, 11, 13332, 49, 344, 13333], [32, 4, 490, 168, 4, 199, 2471, 18, 126, 406], [32, 4, 595, 1, 3, 87, 78, 6, 167, 17, 35, 10, 1517, 13334, 13335, 1369, 380, 4, 215, 201], [32, 4, 9, 3, 200, 44, 92, 36, 1389, 36, 67, 6, 14, 1039, 409, 4552, 19, 32, 7, 35], [32, 4, 9, 62, 69, 3, 728, 125], [32, 4, 9, 18, 13336, 61, 6, 2358], [32, 4, 406, 16, 4, 500, 49, 13337, 43, 406, 27, 4, 234, 9, 13338, 173, 84, 706, 13339], [32, 4, 590, 9, 18, 13340, 340], [32, 4, 786, 208, 13, 3405, 1, 4, 1], [32, 4, 1795, 11, 22, 1], [32, 4, 106, 55, 55, 272, 9, 601], [32, 4, 197, 223, 37, 66, 46, 61, 777, 34, 19, 1, 11, 4, 941], [32, 76, 9, 284, 834, 2821, 703, 3609, 8, 905, 681, 231], [32, 39, 13341, 175, 49, 144, 247, 16, 39, 312, 1902, 745, 110, 366, 2, 13342, 182], [32, 39, 9, 172, 34, 36, 29, 131, 598, 13, 2, 9, 5, 146, 167, 76, 2422, 717, 2061], [32, 39, 5554, 1143, 49, 56, 1782, 4, 5555, 13343, 8, 13344, 1143], [32, 39, 1, 26, 25, 14, 1070, 7458, 57, 409, 16, 575, 17, 26, 4553, 41, 13, 66, 48, 948, 43, 127, 26, 66, 48, 13345], [32, 39, 1, 62, 7, 20, 10, 25], [32, 39, 1, 64, 6729, 4554, 18, 4, 7459], [32, 39, 1, 81, 45, 7, 85, 912, 240, 11, 36, 45], [32, 39, 1, 131, 14, 13, 960, 888, 8, 19, 126, 193, 173, 14, 613, 34, 15, 29, 197, 13, 760, 28, 2, 2718, 26, 197, 2, 4555, 401, 5, 9], [32, 39, 1, 131, 19, 18, 2, 1021], [32, 39, 1, 67, 64, 82, 3628, 26], [32, 39, 421, 35, 276, 14, 2, 284, 9, 351, 7460, 22, 850], [32, 39, 104, 976, 1922, 18, 17], [32, 39, 172, 252, 58, 12, 1, 51, 4, 13346, 4, 19, 35, 8, 137], [32, 39, 9, 13347, 14, 279, 33, 2393, 40, 65, 93, 29, 196, 40, 93, 21, 5], [32, 39, 9, 19, 34, 36, 29, 67, 6, 598, 13, 2, 9, 37, 5, 146, 167, 240, 18, 4, 3886], [32, 39, 9, 72, 7, 131, 14, 1354, 1, 2359, 22, 138], [32, 39, 9, 13348, 3, 63, 105, 2359, 289, 132, 505, 230, 37, 3, 63, 105, 134, 2, 19], [32, 39, 9, 67, 520, 34, 4, 215, 184, 3, 87, 12, 127, 1469], [32, 39, 25, 27, 39, 53, 64, 13349, 1447, 49, 60, 1549, 76, 25, 29, 14, 259, 57, 36, 81, 133], [32, 39, 590, 1, 1976, 2468, 77], [32, 39, 590, 9, 14, 18, 794, 199, 1216], [32, 39, 37, 79, 112, 25, 8, 36, 9, 46, 2357, 34, 60, 6687, 13350, 674, 782, 26, 2092, 13351, 13352, 143, 13353], [32, 39, 881, 1464, 310, 8, 9, 42, 96, 41, 788], [32, 39, 9, 18, 17, 36, 37, 5376], [32, 56, 92, 7, 2, 320, 16, 3318, 13354], [32, 78, 1, 1490, 55], [32, 78, 1, 472, 3720, 1287, 125, 7], [32, 78, 1, 365, 98, 131, 1662, 28, 78, 164], [32, 5, 1, 63, 176, 28, 13355, 3, 13356, 13357], [32, 5, 1, 1037, 1016, 38, 78, 551, 55, 650, 174, 3062, 228, 116, 6, 492, 4556], [32, 5, 1, 62, 20, 122, 6, 258, 630, 18, 4, 2920, 69, 49, 5, 265, 55], [32, 5, 1, 640, 625, 475, 59, 798], [32, 5, 146, 58, 12, 14, 356, 13358, 8, 5556, 8, 4, 1, 103, 107, 6, 5, 905, 5, 46, 110, 146, 58, 45, 34, 14, 630], [32, 5, 9, 49, 9, 21, 3406, 59, 97, 1277, 1426, 631], [32, 5, 9, 848, 226, 427, 7461, 4, 1280, 12, 2360], [32, 5, 462, 429, 20, 24, 13, 22], [32, 5, 1433, 2907, 87, 6, 58, 68, 2432, 113, 1433, 11, 4, 13359, 6, 338, 3015, 4545, 29, 192, 43, 45, 266, 14, 43, 385], [32, 5, 3276, 41, 440, 12, 143, 13360, 165, 934, 147, 230, 263, 207, 617, 28, 147, 99], [32, 5, 24, 12, 1818, 32, 10, 25, 12, 7462], [32, 5, 94, 12, 344, 24, 11, 10, 1074], [32, 20, 1142, 49, 517, 7463, 149, 1, 5, 156, 65, 13, 30], [4557, 46, 2361, 17, 32, 850, 92, 32, 16, 2, 2547, 11, 4, 848, 16, 2294, 45, 12, 7464, 6, 28, 1798, 46, 7, 59, 2, 1], [4557, 44, 10, 387, 32, 355, 8, 1346, 387, 3, 65, 13, 23, 1771], [603, 3864, 325, 1, 54, 51, 1653, 2041, 143, 4558, 142, 37, 765, 75, 1759, 13361, 1, 134, 263, 143, 522, 996, 351, 913], [603, 328, 27, 22, 1, 30, 712, 749], [603, 416, 3, 704, 11, 47, 1064, 248, 8, 31, 36, 608, 2, 1108, 2315, 3, 293, 36, 19, 2754], [603, 911, 13362, 175, 96, 43, 1], [603, 41, 11, 2, 290, 27, 2, 7465, 104, 51, 4, 7402, 55], [603, 41, 6, 94, 2, 120, 177, 28, 257, 224, 225, 34, 52, 920, 13, 2, 83], [603, 470, 16, 3407, 732, 95, 2475, 2187, 123, 4816, 396], [603, 33, 121, 60, 1, 45], [603, 559, 225, 36, 124, 17, 19, 2360, 2784, 1373, 6, 28, 17, 6, 197, 2222, 7, 60, 9, 385], [7466, 1, 2783, 691, 230, 3, 906, 2, 13363], [3201, 111, 72, 36, 334, 6, 36, 25, 8, 1, 749, 78, 46, 13364, 26, 217, 313, 2, 607, 2969, 11, 97, 231, 604, 14, 13365], [330, 124, 6, 753, 7, 83, 589, 3617], [330, 127, 190, 130, 4, 215, 201, 213, 4506], [330, 2650, 102, 588, 389, 21, 24, 96, 18, 10, 1857, 1304], [1417, 13366, 5, 1], [1417, 97, 1716, 100, 33, 139, 27, 32, 4, 1017, 8, 13367, 43, 68, 134, 2, 19, 18, 57, 5, 86, 16, 166, 1225, 415, 308, 769], [1417, 20, 106, 12, 35, 3063, 56], [560, 64, 1076, 206, 2716, 5557, 2775, 44, 68, 828, 8, 191, 21, 2, 1178, 16, 591, 19, 76, 3, 609, 7, 1931], [560, 621, 69, 67, 6, 1, 59, 4, 1990, 51, 5558, 87, 6, 536, 22, 54, 244, 817], [560, 15, 2, 13368, 6, 377, 3408, 36, 7467, 943, 73, 4, 101, 68, 103, 6, 309, 21, 126, 13369], [156, 2, 93, 5559, 125, 10, 145, 13370], [156, 291, 153, 71, 622, 13371], [156, 299, 2889, 354, 220, 4, 199, 73, 2647, 354, 34, 241, 10, 274, 3, 33, 13372], [156, 67, 6, 19, 7, 1, 267, 5, 274, 3, 19, 7, 1], [195, 3, 109, 61, 6, 400, 135, 8, 345, 13, 2, 2200], [195, 3, 4, 101, 91, 461, 2, 181, 5560, 3, 380, 3, 2975], [195, 3, 4, 101, 395, 7, 150, 974, 123, 4, 95, 2715, 5561, 405, 18, 20, 580, 13373], [195, 3, 329, 996, 3345, 51, 384, 153, 18, 841, 3576, 69, 14, 3246, 163, 4, 7468, 712], [195, 179], [195, 37, 314, 7, 95, 8, 2185, 49, 10, 13374], [195, 370, 3, 75, 397, 397, 60, 202, 275, 1047, 4, 392, 1407, 1644, 1, 14, 44, 3654, 8, 45, 3, 2689, 120, 77], [195, 1674, 36, 72, 23, 2201, 15, 2, 13375, 3, 176, 2416, 13, 4, 5562, 27, 2416, 1, 27, 4, 5563, 3, 132, 2, 6487, 21, 4, 13376], [3208, 13377, 12, 284, 1153, 57, 499, 78, 131, 79, 15, 34, 143, 1, 132, 2349], [3208, 12, 2, 1, 526, 3, 118, 257, 50, 30, 55], [5564, 5, 62, 57, 36, 72, 59, 95, 16, 2, 1508], [2007, 1085, 12, 68, 16, 212, 89, 1, 69, 3518, 28, 1738, 27, 13378], [2007, 67, 2, 13379, 1336, 33, 1671, 422, 1, 3, 1049, 7, 18, 201, 13380], [13381, 53, 31, 20, 504, 317, 13, 7, 1, 5, 29, 81, 6, 7, 368], [770, 12, 120, 56, 8, 37, 49, 32, 7469], [732, 2755, 12, 861, 6, 4, 234, 16, 4, 13382, 13383, 13384, 11, 7470, 63, 1601, 165, 2725, 461, 245, 4536, 56, 352, 13385], [13386, 7471, 1892, 5, 33, 19, 4, 1, 3, 29, 13, 50, 768], [1733, 662], [98, 1772, 3491, 48, 2, 115, 21, 13387, 13388, 2027, 246, 696, 6, 1120, 3064, 10, 3007, 494, 617], [98, 31, 42, 46, 2, 9, 28, 35, 54, 10, 941, 13389], [13390, 1889, 41, 3065, 13, 2, 202, 1, 13391], [8, 3, 75, 14, 1370, 21, 19, 125, 2, 56, 83], [8, 3, 735, 15, 211, 5, 656, 15, 119, 24, 13, 2, 391, 34, 3, 19, 13, 2, 3364], [8, 3, 131, 72, 256, 3887, 89, 6, 39, 268, 187, 18, 186, 13392], [8, 3, 47, 13, 221, 1], [8, 23, 857, 503, 292, 51, 1955, 257, 11, 4, 620, 34, 78, 158, 64, 20, 941, 257, 37, 78, 415, 266, 1124, 7], [8, 23, 54, 133, 4222, 233, 39, 9, 14, 1078, 17, 91], [8, 23, 2298, 1806, 325, 1, 2499, 10, 231], [8, 289, 124, 3740, 753, 147, 30, 1], [8, 2, 9, 276, 14, 2, 9, 1804], [8, 1, 3, 46, 133, 6, 1726, 27, 97, 1746, 30, 2164], [8, 123, 78, 3, 13393, 1703, 298, 108, 113, 5565, 369, 23, 58, 7, 48, 10, 25, 381, 25, 579, 1], [8, 143, 9, 3, 636, 42, 465, 2876, 163, 4, 2015], [8, 325, 153, 96, 742], [8, 325, 45, 12, 21, 4, 95, 201], [8, 29, 107, 6, 10, 663, 331, 7472, 174, 148, 6271, 28, 364, 54, 4, 347, 26, 1013, 10, 2408, 83], [8, 110, 31, 4, 2623, 107, 3888, 1, 272, 96, 14, 3066, 3, 41, 1148, 11, 10, 441, 91], [8, 1910, 47, 2298, 294, 102, 528, 23, 13, 1, 109, 31, 40, 182, 616, 224, 17, 272, 28, 11, 10, 347, 8, 338, 50, 116], [8, 28, 10, 653, 2, 89, 1, 7, 334, 8, 68, 7473], [8, 77, 289, 132, 1265, 16, 193, 1265, 16, 154, 193, 6, 257, 7, 24, 142, 26], [8, 77, 7, 24, 46, 45, 6, 17, 260, 77, 694, 35, 8, 28, 314], [8, 136, 1, 421, 142, 10, 441, 601], [8, 135, 397, 11, 4, 355, 1825, 7318, 13394, 4, 24, 2275, 2098, 16, 4, 360, 2453, 13395, 1609], [8, 1061, 23, 2, 685, 282, 151, 81, 6, 245, 8, 3109, 2488, 11, 116, 200, 3, 121, 19, 249, 8, 13396], [8, 3, 46, 1161, 502, 2, 810, 59, 2, 1, 177], [8, 3, 210, 131, 107, 102, 73, 2, 1, 37, 3, 424, 246, 167, 92, 3, 86, 23, 150, 6, 314], [8, 31, 42, 46, 2, 236, 28, 35, 54, 10, 941, 13397], [8, 31, 622, 182, 87, 2, 5566, 6, 345, 18, 3, 266, 14, 116, 1027, 23, 18, 10, 19, 7, 1, 45], [8, 272, 651, 59, 445, 203, 1, 861, 11, 2, 1951, 1536, 18, 2, 341, 850, 115], [8, 15, 156, 4, 202, 1, 7, 1577, 713, 483, 21, 43, 2437, 487, 1813, 4, 462, 11, 351, 1062, 1296, 26, 13398, 565], [8, 15, 146, 14, 60, 179, 902, 964], [8, 33, 13, 17, 7, 1, 13399], [8, 141, 1, 30], [8, 214, 9, 5, 63, 191, 7474, 3, 28, 295, 7475], [8, 10, 1, 276, 1626, 8, 40, 41, 4, 30, 1671], [8, 10, 306, 47, 109, 28, 17, 2, 347, 251, 9, 1561, 42, 21, 147], [8, 153, 49, 7476, 341, 31, 36, 1135, 787, 1889, 21, 7, 13400], [8, 92, 377, 1580, 59, 2, 4467, 859, 11, 13401, 620, 11, 13402], [8, 92, 541, 30, 25, 8, 541, 30, 1, 103, 14, 4, 1067, 16, 13403, 103, 14, 5479, 26, 2362, 11, 155, 19, 193], [8, 16, 1134, 60, 13404, 18, 4, 2099, 12, 924, 4, 4559, 544, 3204, 5567, 18, 26, 13405, 13406], [8, 13407, 14, 4, 395, 20, 1348, 6, 2305, 5, 29, 44, 6, 14, 494, 6, 114, 256, 82, 7, 7477], [8, 371, 23, 6403, 7478, 10, 1, 33, 4507, 82, 4560], [8, 217, 82, 10, 521, 12, 599, 400, 1117, 82, 17, 18, 4, 1195, 37, 3, 75, 110, 79, 586, 8, 1], [8, 4, 1422, 443, 10, 175, 1168, 649, 29, 44, 1046, 106, 21, 22, 248], [8, 76, 25, 13408], [8, 39, 9, 46, 73, 93, 73, 36, 13409, 87, 6, 114, 10, 373, 2068, 13410, 149, 31, 7, 13411, 93, 88, 23, 93], [8, 2712, 7479, 4981, 52, 136, 9], [8, 220, 1, 177], [8, 38, 3, 72, 4561, 4561, 4561, 4561, 1, 7, 14, 13412], [8, 38, 1, 14, 13, 7480, 8, 170, 641, 4, 13413, 1, 29, 357, 110, 62, 78, 612, 2129, 357, 7481], [8, 162, 58, 5, 86, 13414, 7482, 82, 13415, 1333, 61, 4, 13416, 86, 16, 32, 4, 434, 178, 7, 49, 11, 56, 1476, 73, 66, 569, 647], [8, 5, 2, 812, 110, 38, 5, 72, 5, 64, 17, 5, 2, 83, 3, 1646, 5, 1780, 13, 13417, 173, 2, 13418], [8, 5, 3200, 1, 3, 29, 134, 2, 19, 57, 698, 16, 13419, 13420, 36, 7483, 571, 204, 97], [8, 5, 636, 66, 4, 4534, 16, 142, 1, 66, 35], [8, 20, 2, 1, 20, 2, 141, 19, 1329, 5, 62, 7], [1647, 139, 7484, 7, 2943, 1], [4491, 1480, 4267], [2303, 689, 1, 27, 358, 1349, 12, 4, 884, 184, 182, 1349, 7, 14, 881, 126, 4465, 2303], [13421, 5, 284, 9], [13422, 20, 2, 13423], [589, 1087, 7394, 244, 676, 136, 1020, 1227, 897], [246, 89, 1, 19, 50, 21, 2, 755, 246, 2390, 246, 879, 246, 1306], [246, 314, 446, 47, 2, 7485, 79, 17, 7486, 4827, 8, 7486, 887, 21, 58, 2411], [246, 358, 4562, 13424, 274, 2, 153, 54, 135, 6, 94, 15, 205, 112, 45], [246, 1082, 4563, 11, 4, 377, 2120, 1057, 13425, 3131, 377, 13426, 191, 3889, 21, 5568, 26, 1457, 3180, 1525], [246, 25, 9, 12, 246, 25, 2029, 132, 124, 6343], [246, 658, 16, 800, 155, 68, 16, 725, 232, 175], [246, 414, 46, 276, 176, 17, 3305, 77, 39, 9, 46, 41, 295, 18, 97], [245, 1, 69, 229, 35, 928, 65, 13, 4, 1, 82, 4, 1013, 23, 929, 344, 11, 4, 1511], [245, 961, 25, 74, 322, 418, 12, 276, 44, 111, 3590, 126, 13427, 78, 146, 632, 35, 27, 7, 463, 41, 894, 4564], [245, 91, 110, 1557, 2633, 3766, 12, 315, 315, 315, 2337, 97, 177, 72, 7487, 28, 127, 9, 88, 42, 211, 3, 28, 39, 154, 7488], [245, 153, 525, 15, 163, 143, 30, 12, 2, 181, 13428, 333, 1365, 22, 186, 6760, 23, 3890], [245, 395, 7, 157, 1311, 499, 624, 54, 116, 21, 766, 540, 12, 2, 83], [245, 554, 1, 51, 13429, 3, 198, 62, 59, 11, 59, 6, 420, 116, 244, 188, 7297, 3, 29, 61, 6, 13430], [245, 24, 3, 124, 3, 63, 28, 361], [245, 5569, 6, 7193, 678, 317, 799, 27, 13431, 160, 101, 997, 160, 12, 43, 7489], [245, 162, 4, 7490, 51, 12, 162, 4, 24, 4565], [621, 67, 60, 1064, 1455, 8, 4277, 1241, 697, 269, 1407], [621, 67, 6, 958, 126, 299, 18, 126, 382, 1122, 33, 5043, 242, 20, 2009, 148, 476, 5, 13432], [621, 69, 510, 6, 4, 263, 73, 98, 13433, 13434, 12, 120, 248], [3241, 495, 72, 42, 3012, 465, 2, 356, 7, 45, 276, 14, 2278], [5570, 954, 6864, 657, 227, 377, 173, 13435, 3891], [1918, 11, 3865, 21, 10, 1781, 23, 2843, 796, 1, 38, 23, 1470], [13436, 4126, 16, 7491, 2036, 13437, 13438, 160, 2, 95, 7, 13439, 2, 13440, 4, 2328, 13441], [1302, 3, 41, 1485, 21, 10, 7492, 1128, 1451, 2336, 1269, 649], [1302, 23, 2, 5571, 13442, 13, 7, 2, 89, 2432], [1302, 48, 67, 6, 1695, 20, 13443, 13444, 11, 4443, 70, 5, 2, 13445, 711], [1302, 72, 256, 417, 6, 217, 39, 115, 196, 20, 122, 6, 741, 76, 27, 20, 13446, 28, 129, 5155, 283], [1232, 87, 6, 1299, 60, 207, 1217], [1232, 1645, 83], [7493, 22, 189, 255, 4, 7494, 190, 825, 1297, 18, 84, 1511], [49, 1245, 1802, 1072, 12, 59, 6, 309, 22, 19, 665, 964], [49, 950, 141, 1802, 1072, 309, 647], [49, 5, 399, 72, 5, 67, 5431, 6123, 73, 5457, 7, 399, 29, 594, 112, 732, 1784], [49, 5, 419, 34, 20, 24, 12, 11, 2, 575], [49, 5, 515, 16, 4, 5572, 13447, 100, 33, 58, 22, 31, 4472, 12, 48, 4, 841, 479, 69, 86, 657, 378, 671, 13448], [652, 39, 141, 1909, 3302, 614, 6, 14, 11, 261], [687, 6, 70, 562, 48, 6, 421, 35, 26, 28, 108, 612, 7, 144, 11, 10, 387], [687, 129, 2, 1, 27, 2, 13449, 18, 971], [4940, 13, 183, 1, 7, 13, 6, 19], [7495, 2632, 1635], [13450, 176, 79, 17, 179], [73, 13451, 72, 7, 3, 623, 4, 490, 420, 82, 467, 3284, 6, 13452, 32, 2785, 150, 32, 2785, 37, 2751, 27, 32, 2785, 13453, 3892, 2997], [73, 3, 175, 230, 245, 91, 113, 17, 6, 61, 6, 4, 2635, 22, 658, 222, 113, 84, 306, 7, 1544, 415, 452, 16, 13454], [73, 2, 504, 23, 105, 28, 637, 6, 10, 520, 228, 149, 36, 63, 14, 113, 17, 68, 184, 8, 113, 39, 9, 7496], [73, 2, 504, 5, 146, 1273, 4, 488, 9, 223, 14, 32, 35, 11, 84, 1511, 34, 73, 2, 520, 52, 165, 100, 76, 9, 62, 13455], [73, 2, 91, 188, 3, 150, 13, 5, 2, 1, 31, 5, 259, 102, 2, 275, 26, 1412, 50, 303, 32, 80, 45, 810, 7, 105, 14, 2579, 18, 217], [73, 156, 3116, 136, 4, 185, 1307, 13456, 65, 18, 84, 231, 1055, 408, 204, 13457, 15, 152, 14, 2], [73, 93, 73, 13458, 13459, 8, 2533, 18, 4, 199, 412, 372, 7, 37, 144, 128], [73, 31, 15, 407, 276, 28, 3409, 6, 17, 1, 20, 459, 20, 948, 453], [73, 358, 73, 5, 276, 1090, 17, 24, 38, 3, 28, 4, 5573], [73, 16, 225, 23, 311, 4566, 102, 7453, 7, 105, 229, 64, 74, 33, 4141, 111, 1409, 87, 2074], [73, 738, 73, 2, 1033, 28, 2, 1180, 6, 4, 1086, 4036, 568, 6, 2786, 88, 108, 27, 13460, 128], [73, 738, 73, 2, 1, 86, 45, 13461, 134, 240, 827, 36, 132, 191, 21], [73, 738, 73, 1, 28, 18, 2, 107, 35, 5, 41, 7, 68, 1, 7, 75, 304, 6, 113, 574, 20, 7063, 230, 4, 107, 35, 26], [73, 738, 73, 66, 440, 4446, 32, 39, 3893, 235, 86, 36, 63, 19, 13462, 11, 8, 114, 129, 57, 66, 197, 37, 332, 6, 644, 562, 633, 17, 1724], [7497, 124, 2, 141, 768, 11, 10, 235, 113, 17, 6, 19, 27, 39, 319, 407, 13463], [7497, 10, 1, 277], [191, 2, 1, 11, 862, 31, 40, 118, 516, 44, 847, 130, 3171, 26, 1052, 3, 394, 42, 40, 113, 2, 4567], [191, 224, 163, 4, 606, 1, 133, 1615], [191, 4, 1837, 71, 66, 49, 614, 6, 389, 21, 22, 1413, 7498, 2315, 12, 1893, 444, 66, 87, 76, 55], [191, 1118, 1, 38, 40, 276, 100, 2, 1290, 25, 1626, 1118, 30], [191, 20, 1, 59, 17, 40, 227, 173, 13464], [51, 1973, 93, 1640, 7499, 7499, 23, 1973, 13465, 68, 16, 5, 1, 165, 7500, 27, 307, 3, 63, 134, 5, 98, 13466], [51, 5574, 4568, 8, 155, 106, 495, 294, 11, 3, 519, 1087, 590, 74, 9, 8, 37, 17, 8, 10, 646, 41, 543, 54], [51, 2, 446, 162, 289, 41, 6, 70, 2, 1715, 164, 13467, 684, 202, 13468, 508, 74, 2531, 202, 508, 18, 10, 5575, 13469, 7275, 74, 1685, 13470], [51, 32, 10, 7501, 3255, 552, 57, 6, 58, 27, 531, 2027], [51, 577, 272, 2, 1148, 1], [51, 24, 534, 13471, 1976, 15, 27, 10, 7502, 8], [51, 4, 3361, 4544, 238, 258, 2, 91, 1, 66, 94, 42], [51, 4, 953, 3894, 6806, 8, 15, 1440, 3592, 9], [51, 4, 904, 11, 13472, 125, 10, 674, 22, 145, 1941, 293, 52, 317, 28, 263, 173, 2, 290, 128], [51, 4, 1998, 27, 1620, 40, 270, 2, 24, 4, 124, 6, 157, 2, 1984, 13473, 11, 50, 1359, 8, 40, 33, 59, 192, 6, 345, 2129], [51, 4, 450, 16, 4, 115, 1526, 96, 64, 7, 379, 1241, 24, 82, 1684, 1548, 637], [51, 22, 877, 278, 1801, 21, 4, 1210, 154, 1648, 232, 129, 4, 2921, 3749, 7503], [51, 197, 34, 301, 3, 47, 3853, 11, 10, 1313, 6961, 18, 1881, 51, 2000, 388, 2340, 7, 10, 2401, 415, 2764, 656, 371, 215, 3270], [672, 4, 3634, 109, 1026, 74, 12, 433, 6297, 56], [701, 68, 8, 1284, 33, 13474, 10, 5576, 217, 28, 22, 3523, 60, 5577, 40, 26], [13475, 9], [13476, 243, 1987, 115, 283, 13477, 137, 22, 288, 5, 28, 5411], [2294, 3650, 179], [1670, 12, 2, 356, 145], [2659, 70, 10, 2228, 3895, 396, 6, 9, 1068, 57, 4, 7504], [1696, 12, 339, 8, 339, 12, 56], [1210, 91, 7, 1, 40, 61, 13478, 157, 15, 18, 17, 23, 13, 2229, 13479, 43, 1277, 260, 43, 1865], [2895, 200, 3, 311, 5, 102, 8, 70, 5, 214, 7, 99, 1301, 89, 1521, 132, 61, 4, 19, 3113, 2148, 1], [13480, 42, 29, 13, 20, 373, 2509, 964, 1081, 426, 305, 13481, 128, 291, 183, 1, 19, 76, 66, 29, 87, 76], [7505, 7, 46, 10, 282], [7505, 36, 43, 4163, 46, 999, 43, 1], [3166, 1114, 15, 341, 483, 26, 23, 556, 61, 303, 80, 1, 60, 684, 853, 26, 55], [3166, 19, 7506, 375, 6, 119, 230, 5, 467, 8, 375, 6, 467, 591, 288, 20, 467, 8, 560, 6, 61, 119, 45, 5, 24, 1643], [3166, 57, 49, 60, 93, 13482, 6, 167, 35, 11, 7507, 198, 14, 35, 116, 1445, 264, 6, 490, 897], [3166, 78, 566, 7, 613, 1190, 2050, 2310, 7, 1, 18, 3216], [773, 2, 153, 12, 515, 205], [773, 15, 2, 320, 16, 25, 54, 135, 7, 75, 19, 2, 89, 1, 650, 36, 28, 50, 551, 251], [773, 10, 5578, 188, 223, 100, 97, 1, 19, 125, 10, 412, 13483], [773, 4, 820, 14, 557, 4, 1, 99, 93], [773, 66, 32, 1551, 176, 49, 235, 35, 314, 69, 279, 31, 66, 514, 66, 32, 363, 8, 122, 305, 237, 13484, 12, 2, 666, 16, 56, 81, 24, 2032], [773, 13485, 41, 2, 739, 30, 2923, 5333, 13486, 22, 1, 37, 631], [773, 9], [4569, 3, 383, 124, 2, 1951, 548, 1183, 747, 4, 13487, 3299, 163, 739, 353, 29, 1223, 3], [4569, 816, 177, 3, 146, 154, 310, 134, 17, 80, 1429, 92], [4569, 85, 143, 286, 46, 357, 1443, 17, 6, 39, 153, 188], [4569, 5005, 17, 37, 3, 2036, 113, 5, 71, 1439, 80, 1, 30, 13488], [4493, 7508, 12, 2, 179, 261, 92], [4493, 80, 10, 25, 14, 32, 35, 18, 13489, 48, 4570, 147, 13490, 13491], [6577, 23, 3896, 18, 2, 351, 13492, 8, 94, 4, 580, 1529, 1146, 23, 2, 243, 5579], [339, 117, 1919, 13493, 13494, 660, 13495, 32, 90, 305, 2342, 2777, 8, 13496], [426, 78, 9], [1214, 3, 86, 66, 87, 60, 1245, 13497, 1661, 128, 85, 57, 21, 1214, 140, 23, 2275, 20, 24, 4571], [1, 139, 86, 174, 6437, 6, 1086, 1675, 13498], [1238, 5, 49, 61, 6, 204, 630, 31, 5, 29, 5580, 1976, 5, 9, 26], [280, 230, 236, 188, 8, 116, 3, 47, 27, 10, 280, 461, 245, 13499], [321, 695, 76, 9, 47, 530, 34, 3, 1874, 119, 76, 53, 57, 4, 19, 582, 6, 39, 53], [321, 76, 183, 9, 72, 2, 25, 13500], [260, 3, 63, 70, 7, 24, 13501, 7509], [260, 3, 63, 70, 7, 24, 1234, 1725], [260, 3, 63, 70, 7, 24, 13502, 1725], [260, 151, 3410, 13503, 6, 5, 32, 1221, 13, 13504, 7510, 4912, 709, 13505], [260, 77, 20, 24, 65, 37, 13506], [260, 13507, 41, 17, 6590, 3, 67, 22, 1, 244, 17, 24, 13, 4249, 26], [260, 24, 75, 14, 20, 101, 13508, 650, 42, 89, 73, 7511, 13509, 196, 2, 320, 16, 574, 41, 13510, 339, 2567, 46, 4, 101, 2567], [13511, 87, 3772, 169, 72, 7, 827, 40, 223, 58, 81, 2, 413, 3201, 45, 34, 300, 7, 1, 223, 107, 539], [108, 17, 8, 168, 6, 44, 6, 13512, 1, 7, 1874, 238, 719, 305, 1023], [108, 11, 770, 8, 289, 671, 2, 339, 1, 1404], [108, 11, 22, 1, 13513], [13514, 12, 458, 76, 9, 103, 100, 5, 19, 240, 11, 4, 809, 1326, 98, 1037, 1338, 1853, 4, 877, 5, 1279, 7512], [89, 668, 1, 447, 40, 65, 33, 13, 6659], [89, 1, 13515, 5, 11, 250, 507], [89, 1, 134, 93, 235, 171, 1, 28, 689, 613], [89, 1, 93, 235, 3, 86, 40, 585, 4102], [89, 1], [89, 1, 18, 10, 493, 238, 134, 17, 1209], [89, 1, 24, 7513, 79, 50, 13516], [89, 1, 506, 1361, 3, 318, 114, 68], [89, 1, 27, 17, 8, 5, 636, 7, 50, 30, 12, 203], [89, 1, 2170, 13517, 454, 85, 346, 5581, 176, 18, 28, 440, 54], [89, 1, 46, 2113], [89, 1, 46, 2113, 165, 433, 50, 31, 42, 291], [89, 1, 98, 93, 441], [89, 1, 8, 93, 441], [89, 1, 14, 32, 1926, 17, 233, 1782, 24, 57, 222, 5, 1761, 17], [89, 1, 155, 162], [89, 1, 82, 13518, 40, 222, 13519, 2, 1263], [89, 1, 90, 291, 5582], [89, 1, 11, 537, 30, 331, 4502], [89, 1, 11, 4, 5087, 70, 10, 1109, 2194], [89, 1, 12, 4, 101, 184, 3, 13], [89, 1, 12, 4, 101, 184, 7, 3, 13], [89, 1, 12, 4, 101, 184, 7, 3, 13, 22, 1445], [89, 1, 12, 4, 101, 184, 7, 3, 13], [89, 1, 12, 4, 101, 184, 7, 13], [89, 1, 101], [89, 1, 101, 188], [89, 1009, 11, 4, 2521, 26, 31, 15, 133, 2, 1, 33, 62, 3, 29, 538, 15, 774], [89, 418, 471, 240, 7514, 339, 9, 2878, 240, 54, 75, 110, 28, 3328, 13520, 90, 25, 7515, 240, 54, 223, 28, 4, 13521, 54], [89, 1797, 1, 40, 2, 2900, 5583], [89, 161, 1, 46, 105, 297, 50], [89, 161, 752, 595, 1, 161, 5584, 2075], [482, 146, 1, 1866], [482, 2520, 4, 154, 234, 1, 3623, 42, 46, 1101, 9], [482, 216, 17, 839, 860, 354], [558, 558, 7, 7, 558, 169, 56, 558, 202, 8, 15, 1207, 35, 27, 169], [4979, 526, 22, 1, 12, 13522, 26], [2338, 13523, 813, 3782, 7065, 7066, 13524, 2101, 2849, 13525, 26, 13526, 190, 3711], [1582, 235, 1, 86, 15, 126, 106, 6, 5585], [466, 12, 164, 43, 1, 3819, 12, 164], [1130, 103, 70, 50, 856, 4476, 103, 70, 50, 987, 31, 4505, 671, 970, 39, 9, 103, 44, 6, 1869], [1467, 1, 5, 86, 23, 5586, 1, 15, 1972, 13, 2, 19, 13527, 1], [1689, 13528, 69, 2503, 13529, 472, 1462, 1205, 72], [7516, 12, 56], [5271, 13530, 13531, 298, 1060, 11, 13532, 253, 4, 1337, 16, 13533, 1043, 5587, 1561, 4, 13534], [5271, 9, 1995, 12, 294, 11, 615, 183, 2944, 40, 1437], [1519, 427, 4, 199, 461, 4, 232, 11, 4, 1408, 26, 1641, 427, 4, 199, 461, 4, 1583, 11, 2165], [13535, 545, 21, 50, 457, 21, 60, 540, 55, 13536, 232, 13537, 18], [339, 1, 43, 497], [339, 1, 26, 564, 25, 2979], [339, 1, 1666], [339, 145, 11, 84, 339, 754], [339, 72, 7, 4, 1381, 317, 1642, 6, 263, 8, 15, 13538, 3279, 187], [339, 13539, 58, 350, 4795, 37, 31, 20, 475, 59, 14, 2, 236, 74, 65, 13, 68, 93, 7442], [2787, 6519, 3411, 13540, 5588, 48, 21, 933, 111, 8, 478], [13541, 152, 61, 4572, 129, 315, 95, 7517], [426, 3, 41, 99, 239, 1], [14, 2, 381, 6, 39, 1, 3558, 14, 2, 1065, 6, 97, 1235], [14, 2, 77, 27, 2, 453, 2, 1, 27, 98, 764, 8, 2, 462, 27, 3319], [14, 1293, 16, 4, 13542, 16, 274, 11, 2, 823, 162, 239, 382, 2524, 4573, 13543, 2828, 8, 1625, 6, 13544], [14, 196, 74, 1395, 6, 10, 141, 746, 361, 8, 151, 543, 20, 809, 15, 3768, 6, 32, 16, 5, 141, 13545, 283, 888, 6900], [14, 10, 13546, 155, 153, 87, 2, 5589], [14, 1070, 38, 3, 79, 5, 9, 34, 1, 5, 62, 3, 81, 13, 147, 1546, 768], [1324, 7, 220, 190, 230, 928, 264, 49, 524, 13547, 607, 875, 338, 13548, 34, 48, 13549, 1366, 7518, 160, 503, 450, 13550], [1538, 178, 225, 1, 48, 6, 844, 2110, 8, 1852, 230, 4, 1036, 498, 55, 513], [257, 4, 24, 142, 13, 10, 13551], [257, 4, 24, 11, 37, 219, 50, 45, 96, 505, 82, 2, 449, 892], [257, 97, 1, 24, 35, 155, 106, 3, 94, 50, 13, 2, 2352, 233, 88, 471, 50, 459, 975, 125, 445, 851], [681, 1219, 13552, 472], [140, 3, 124, 6, 1273, 14, 79, 2, 1, 155, 106, 3, 13553, 2542], [140, 278, 516, 255, 10, 343, 358, 8, 44, 1663, 23, 2, 104, 7, 103, 105, 61, 2978, 11, 1068], [140, 2, 399, 34, 29, 196, 20, 24, 12, 859], [140, 51, 20, 1595, 3380, 7460, 4, 2051, 12, 156, 305, 83], [140, 552, 31, 20, 96, 238, 28, 27, 50, 361, 74, 13554, 1, 3, 318, 14], [140, 31, 357, 47, 1105, 4, 95, 22, 1024, 452, 110, 149, 2, 13555, 11, 717, 2372], [140, 16, 4, 1253, 7, 471, 6, 5590, 4378, 11, 4, 2853, 48, 73, 31, 1684, 3038, 12, 2, 5591, 21, 494, 1225, 225, 12, 13556], [6860, 1926, 1, 1695, 97, 2193, 21, 2332, 2332], [132, 5592, 332, 8, 679, 1574, 876, 237, 2242, 13557, 289, 182, 5593], [132, 2, 3897, 153, 371, 2, 161, 153], [132, 2, 288, 371, 15, 33, 132, 17, 2288, 51, 4, 967, 150, 716, 1045, 13, 2, 9], [132, 2667, 32, 115, 515, 130, 1], [132, 261, 39, 1, 371, 5594], [132, 376, 13558, 209, 19, 15, 272, 934, 15, 230, 3, 192, 197, 201, 401, 13, 2, 9, 281], [132, 273, 123, 2, 320, 16, 111, 7, 23, 431, 88, 2, 9, 8, 7, 36, 29, 594, 85, 217, 452, 13, 17], [828, 466, 427, 21, 24], [230, 3, 100, 2, 24, 311, 10, 343, 3, 33, 103, 100, 15, 632], [230, 4, 214, 27, 10, 419, 283], [747, 155, 5595, 414, 12, 2, 1440, 16, 90, 9], [14, 2, 77, 5193, 66, 44, 6, 799, 27, 1230, 70, 263, 2, 1, 1390, 305, 645, 18, 2, 1697, 5483, 8, 475, 59, 57, 66, 7519], [14, 2, 9, 46, 342], [14, 2, 9, 12, 342, 11, 862], [14, 2, 3062, 931, 33, 407, 13559, 1, 23, 259], [14, 490, 51, 78, 49, 13560], [14, 419, 8, 48, 262, 43, 1, 713, 264, 603, 13561, 130, 107, 337, 211, 4, 489, 551, 8, 172, 20, 504], [442, 11, 4, 548, 16, 4, 1092, 83], [442, 15, 74, 48, 9, 28, 723, 211, 13562], [2724, 103, 13563, 97, 60, 1982, 2724, 103, 28, 97, 60, 235], [7520, 7521, 248], [7522, 12, 2, 1, 446, 3221, 1230], [1782, 10, 746, 22, 12, 68, 16, 268, 1, 5, 103, 156, 430, 17, 2047], [237, 5596, 265, 182, 51, 3646, 2786, 13564, 354, 5597, 21, 326], [237, 16, 1640, 6, 7523, 4, 6503, 7028, 11, 2133, 13565, 3898, 12, 492, 13566], [237, 3027, 7, 568, 6, 2, 7524], [394, 159, 870, 136, 1372, 13567], [394, 36, 67, 2, 851, 13568, 5, 196, 13, 5, 67, 2, 353, 716, 1150, 135, 225, 13569, 13570], [394, 5, 46, 223, 410, 240, 5598, 1710, 85, 1312, 33, 175, 7, 26, 40, 62, 136, 24, 963], [1741, 191, 657, 39, 606, 1, 133, 1615], [165, 176, 97, 45, 163, 493, 153, 188], [165, 628, 7, 45, 11, 4, 1852, 13571], [165, 137, 20, 820, 1, 29, 14, 2, 1220, 1, 218, 3, 318, 44, 2, 396, 16, 548], [808, 4, 4210, 13572, 8, 4, 89, 1, 137, 943, 54, 21, 701, 8, 4, 185, 1787, 327, 610, 514, 307], [808, 22, 1839, 8, 4, 1454, 208, 13, 287, 15, 13, 25, 487, 304, 6, 14, 104], [1904, 127, 16, 2, 1792, 1, 125, 43, 1443, 39, 115], [180, 13573, 1017, 6, 153, 55], [180, 355, 8, 203, 13574, 5061, 10, 5599, 12, 37, 356], [180, 13575, 3899, 38, 103, 13576, 1476, 3412, 5600, 5601, 13577, 13578, 48, 61, 6, 582, 3900, 13579, 962, 818], [180, 95, 555, 1160, 7525, 708, 2079, 277, 48, 279, 21, 4, 3210, 13580], [180, 1, 14, 13, 23, 834, 447, 1, 13581, 4, 13582], [180, 202, 1, 54, 135, 687], [180, 1473, 903, 43, 30, 43, 30, 903, 180, 1473, 180, 1473, 8, 180, 30, 903, 183, 231, 180, 1473, 180, 30, 322, 231, 903, 282], [180, 280, 4315, 122, 1099, 173, 39, 9, 706], [180, 13583, 3406, 30, 153], [180, 343, 1, 13584], [180, 3901, 1315, 13, 2, 9, 281, 6416], [180, 264, 16, 8], [180, 802, 24, 13585, 572, 17, 361], [180, 834, 322, 1], [796, 5602, 3, 182, 297, 3902, 1, 124, 2, 4473, 2645, 3302, 18, 65, 13, 98, 129, 1414, 4473], [4574, 47, 8, 156, 103, 14, 4, 5050, 187, 11, 5603], [7526, 2389, 7527, 11, 117, 7009, 13586], [4355, 5238, 827, 12, 717, 13587, 1536, 855, 13588, 855, 13589, 13590, 13591, 13592, 704, 13593, 13594, 309, 5003, 3739, 1057, 13595, 13596], [7528, 1190, 65, 30, 1, 27, 815, 7529, 1449, 386, 16, 13597], [1005, 7530, 719, 24], [1005, 13598, 12, 96, 2, 838, 69, 486, 7, 68, 3305], [1005, 1609, 13599, 7531, 13600, 5590, 13601, 1593, 13602, 1, 479, 1155, 19, 90, 350, 3, 62, 5, 818, 34, 385], [457, 225, 1, 8, 3, 146, 197, 964], [1, 3, 67, 10, 518, 108, 80, 24, 7532, 241, 221, 19, 147, 1, 302, 17], [1, 23, 48, 59, 6, 119, 97, 24, 32, 115, 7138, 3, 41, 2, 1068], [1, 23, 4, 91, 7, 117, 3, 121, 15, 1, 23, 4, 91, 29, 5, 627, 254], [1, 46, 42, 84, 3647, 693, 42, 267, 13603, 481, 411, 204, 147, 1, 6], [1, 8, 69, 4, 19, 523, 42, 195, 569, 38, 4, 19, 3, 150, 13, 15, 8, 139, 2, 24, 30, 25, 8, 874, 4, 19, 35], [1, 30, 25, 14, 90, 18, 202, 13604, 674, 782, 1, 6989], [1, 30, 111, 49, 4, 250, 6, 79, 217, 54, 21, 14, 2, 1063], [1, 1, 1], [1, 29, 81, 80, 45, 88, 72, 5, 18, 1010, 38, 2, 1, 4860, 28, 142, 5, 2, 344, 181, 1, 3859, 6809, 939, 30, 282], [1, 1438, 18, 835, 30, 659, 187, 136, 2858, 15, 13605, 205, 3169, 13606], [1, 19, 80, 25, 57, 35, 27, 7, 24], [1, 1156, 827, 2, 1543, 146, 72, 13607, 4802, 97, 1], [1, 124, 2, 13608, 1024, 27, 32, 1142, 18, 4, 1299, 13, 1, 43, 843, 131, 94, 80, 231], [1, 3, 452, 119, 1533, 24, 125, 246, 25, 1200], [1, 33, 249, 10, 138, 8, 122, 6, 134, 17, 2196, 1, 28, 54], [1, 3244, 223, 14, 13609, 11, 7, 1, 3702], [1, 153, 2041, 2, 663, 13610, 78, 46, 143, 1583], [1, 4995, 41, 148, 2959, 9, 13611, 46, 276, 547, 80, 1746, 30, 2585], [1, 5, 13612, 1, 5, 13613, 55], [1, 20, 4, 2272, 187, 1269], [1, 5, 600, 44, 2, 937, 831, 481, 34, 5, 41, 2, 831, 5604, 231, 8, 2, 13614, 2877, 24, 37, 5, 46, 783, 385], [1, 585, 44, 2, 260, 26, 14, 13, 1673, 708, 10, 7533, 1, 5, 93, 26, 2082, 219, 46, 357, 708, 20, 4034], [1, 46, 45, 34, 9, 8, 843], [1, 156, 13, 5, 41, 1541, 3, 14, 13, 3878, 23, 238, 70, 5, 68, 16, 240, 2648], [1, 156, 86, 495, 67, 76, 74, 36, 141, 5244, 55, 497, 29, 1838, 3883, 1409, 67, 78, 9], [1, 14, 1584, 11, 4, 13615, 940, 81, 59, 53, 162, 10, 482, 51, 53, 43, 1, 162, 97, 1789, 51], [1, 14, 243, 59, 2183, 1065, 1635, 13616, 18, 1255, 421, 51, 197, 34, 208, 13, 1283, 27, 154, 638, 146, 14, 13617], [1, 14, 44, 2, 25, 34, 67, 6, 14, 246, 25, 3105, 1, 15, 29, 197, 13, 7], [1, 14, 11, 36, 150, 6, 209, 13, 259, 1], [1, 14, 13, 7534, 1954, 23, 13618, 250, 16, 32, 1, 357, 47, 1617], [1, 14, 13, 3145, 830, 7535, 8, 23, 33, 13, 1, 20, 154, 830, 12, 183, 20, 206, 830, 47, 183, 1, 5, 2030], [1, 14, 13, 3, 67, 256, 112, 188, 8, 3, 14, 13, 3, 67, 2, 1, 27, 112, 343, 34, 66, 75, 156, 28, 57, 66, 67, 92, 63, 66, 55], [1, 14, 13, 23, 3872, 990, 129, 2, 145, 251], [1, 14, 13, 25, 46, 45, 188, 576, 1, 485, 5, 33, 46, 45], [1, 14, 214, 36, 1151, 25, 525, 2788, 35, 123, 32, 39, 835, 1533, 24, 700, 963, 1335], [1, 14, 801, 19, 36, 25, 34, 28, 214, 38, 246, 1, 19, 36, 25], [1, 14, 372, 13619, 144, 18, 1249, 496, 2648], [1, 14, 13620, 1163, 13621, 43, 1, 15, 326, 13622], [1, 14, 122, 6, 5605, 32, 990, 1497, 36, 258, 54, 36, 554, 60, 9, 29, 134, 2, 19], [1, 14, 194, 17, 82, 166, 1, 13623, 7, 117, 1, 412, 197], [1, 14, 255, 7536, 365, 387, 7537, 8, 70, 35, 533, 133, 36, 89, 283, 43, 1, 5, 49, 48, 89, 20, 2, 1601, 781], [1, 1, 1], [1, 75, 19, 27, 10, 1, 36, 5606], [1, 359, 18, 36, 836, 34, 14, 3887, 7538, 38, 36, 1, 359, 895], [1, 733, 59, 36, 260, 803, 48, 14, 45, 34, 1, 5, 724, 52, 407, 45, 5, 210, 44, 6, 176, 7, 260, 5, 2603, 6], [1, 1490, 27, 7, 48, 492, 518, 45, 3, 90, 76, 9], [1, 29, 110, 61, 54, 6, 44, 501, 1046, 36, 33, 61, 54, 6, 175, 59, 4, 2508, 8, 6, 114, 327, 125, 166, 1], [1, 29, 13624, 4575, 17, 43, 127, 1, 131, 4575, 32, 10, 1], [1, 28, 18, 186, 98, 227, 6, 2602, 13, 36, 48, 9, 7, 45, 204, 2, 25], [1, 62, 36, 1, 83], [1, 64, 990, 129, 2, 25, 7, 156, 11, 166, 1, 13625], [1, 70, 17, 3567, 2601, 4336, 70, 1, 243], [1, 18, 17, 133, 143, 161, 4576, 45, 18, 1690, 1, 333], [1, 516, 14, 1949, 27, 84, 9, 661, 16, 448, 3772, 92, 7, 585, 109, 1481, 240, 13626], [1, 37, 185, 2346, 75, 62, 71, 23, 1967, 192, 429, 1], [1, 300, 35, 8, 142, 36, 24, 4, 237, 34, 7539], [1, 2041, 36, 13627, 41, 39, 1, 11, 13628], [1, 86, 374, 2274, 34, 43, 690, 71, 332, 36, 122, 8, 869, 15, 66, 63, 96, 113, 31, 374, 9, 74, 48], [1, 103, 14, 1], [1, 103, 14, 283], [1, 27, 265, 49, 144], [1, 27, 56, 24, 156, 67, 7540, 352], [1, 1, 283], [1942, 17, 1, 3413, 18, 2, 4559, 13629], [13630, 415, 429, 2, 13631, 230, 40, 124, 39, 467, 27, 13632, 40, 598, 13, 7, 698, 16, 16, 3897, 802, 83], [13633, 33, 216, 2, 392, 73, 13634, 6792, 3, 29, 33, 17, 392, 73, 355, 8, 13635, 3, 196, 73, 355, 759, 190, 8, 13636, 13637, 73], [13638, 7541, 30, 1419, 1014, 170, 102, 250, 16, 1284, 15, 1466, 234, 8, 212, 2487, 1663, 3392, 73, 2384], [202, 7542, 2211, 4, 9, 223, 10, 138, 2222, 130, 13639, 13640], [202, 1, 14, 13641, 13642, 7543, 439], [202, 1, 29, 14, 4283, 35, 11, 305, 2119, 1, 96, 1506, 125, 5607, 96, 18, 36, 235, 579, 385], [202, 670, 67, 6, 204, 120, 7544, 1282, 670, 67, 6, 204, 7545, 7544, 13643, 670, 49, 32, 13644], [202, 189, 11, 521, 13645, 6, 313, 2, 1010, 466, 173, 4, 7268, 13646, 3067, 13647, 1322, 2, 2158, 6, 20, 849, 13648], [202, 111, 13, 1570, 17, 528, 51, 217, 69, 309, 171, 269, 30, 25, 13, 5, 87, 6, 14, 1020, 35, 33, 21, 185], [202, 186, 87, 6, 28, 102, 1939, 1576, 138, 59, 170, 7546, 2, 13649, 1336, 5355, 1655, 5355, 1264, 227, 2, 9, 173, 2, 2255], [1528, 1528, 1004, 133, 5, 284, 30, 1], [1528, 1528, 1528, 7547, 71, 15, 372, 38, 39, 1, 81], [3710, 11, 32, 13650, 3, 33, 87, 60, 285, 7, 15], [13651, 56, 99, 188, 34, 186, 121, 52, 47, 93], [572, 84, 858, 971, 26, 609, 22, 702, 164, 13652], [1958, 1, 125, 50, 759, 387, 13, 2101, 38, 40, 1624], [1009, 22, 25, 13653, 144], [665, 35, 4, 24, 13, 13654, 1, 65, 51, 17, 284, 13, 69, 7548], [665, 10, 453, 71, 60, 189, 44, 39, 1263, 409, 77, 88, 359, 18, 76, 27, 60, 179, 282], [866, 6, 4, 235, 19, 1599, 3, 119, 24, 634, 10, 1200, 355], [1602, 163, 9, 1602, 163, 9, 146, 44, 17, 10, 1602, 163, 9], [1364, 1], [1364, 1, 405, 11, 2043, 691, 464, 749, 100, 7, 2258, 11], [1364, 13655, 25], [1364, 1, 5399, 503, 292, 1364, 4055, 323, 1121, 341, 25, 1272, 1375], [1364, 1796, 4, 202, 82, 7549, 7550, 34, 40, 1874, 32, 4, 2307], [859, 20, 331, 88, 19, 20, 83, 32, 7255, 1057, 3670], [5608, 124, 4, 9, 8, 4, 169, 13656, 543, 30, 43, 13657, 3750, 156, 100, 2, 1, 309], [4175, 30, 1, 2729, 54, 1951, 1641], [1971, 920, 22, 9], [5469, 37, 56], [723, 88, 2, 9, 11, 4, 13658, 2147], [723, 88, 2, 9, 477, 6, 39, 19, 30, 2008, 7551, 263, 27], [900, 30, 1, 3903], [13659, 35, 18, 10, 206, 9], [3814, 377, 3904, 8, 1607, 1291, 16, 4, 1387, 13660, 439, 852, 21, 770, 527], [398, 34, 7, 47, 4, 206, 17, 55, 42, 14, 1412, 1, 18, 2609, 21, 4, 352, 74, 15, 2, 154, 2198, 155, 106], [398, 16, 10, 1, 484, 3414, 5609], [398, 16, 76, 9, 1818, 8, 87, 6, 167, 4, 1198], [398, 56, 34, 3, 380, 36, 41, 515, 16, 5610, 56, 192, 71, 5610, 468, 84, 401, 6, 5611, 2890, 1667], [398, 78, 24, 386, 257, 15], [1048, 7, 1, 7552, 13661, 1, 64, 7552, 741], [1048, 39, 1, 1418, 8, 92, 28, 605, 18, 10, 2487, 4577, 13662, 536, 54, 12, 599, 11, 473, 1204, 205], [1048, 22, 7553, 11, 7554, 4, 166, 449, 124, 43, 1179, 15, 47, 1934, 13663, 91, 57, 2, 719], [133, 1118, 106, 162, 4, 9, 49, 525, 138, 142], [133, 6, 912, 22, 1, 2044, 7555, 270, 2, 936, 16, 169], [133, 6, 5612, 325, 1], [133, 6, 28, 2, 2624, 6444, 39, 1, 14, 11, 4, 193], [133, 6, 70, 60, 348, 11, 2, 13664], [133, 6, 157, 17, 60, 9, 18, 2789, 233, 122, 10, 1078, 402, 54], [133, 6, 366, 2, 5613, 163, 325, 1, 233], [133, 6, 753, 32, 4, 1, 3, 253, 1254, 8, 253, 32, 154, 283, 3, 87, 396, 11, 10, 164, 8, 3, 150, 13, 7, 2, 93, 192], [1967, 13665, 32, 39, 185, 1], [1625, 142, 1, 1625, 142, 7556], [1743, 875, 2852, 65, 206, 73, 1066, 13, 654, 13666, 3905, 34, 36, 58, 44, 2, 320, 16, 1, 37, 3, 380, 7, 914, 21, 2, 320], [177, 80, 1, 2, 564, 29, 357, 62, 50, 34, 5], [177, 1290, 1021, 12, 2, 181], [177, 2, 1, 96, 46, 41, 4, 4512, 3751, 16, 376], [177, 148, 7557, 41, 84, 30, 1, 491, 11, 143, 1605, 2412, 1506, 6, 2248, 1230, 3, 47, 13667, 163, 45], [177, 39, 13668, 153, 198, 14, 1811], [177, 5, 146, 227, 7, 2830, 323, 32, 4, 193, 142, 18, 4, 7558, 7559, 15, 56, 188, 34, 7, 4, 30, 203, 3415], [177, 60, 9, 14, 644, 943, 35, 21, 13669, 45, 14, 37, 356, 23, 376, 205], [520, 8, 646, 103, 405, 102, 8, 479, 35, 1, 82, 126, 1026, 522, 401, 73, 358, 73, 126, 1373, 2, 351, 6573], [177, 29, 131, 598, 13, 1, 7, 85, 36, 29, 2130, 150, 13, 263, 275, 58], [177, 67, 89, 1, 8, 13670, 435, 67, 870, 287, 69, 538, 943, 8, 608, 84, 1862, 288, 806, 7560], [13671, 31, 3, 124, 2, 1, 69, 24, 578, 161, 779, 13672, 7, 118, 340, 378, 243, 1], [13673, 11, 143, 13674, 13675, 125, 667, 1, 344, 13676], [4363, 7561, 12, 1944, 130, 159, 4807, 57, 4, 13677], [1974, 566, 78, 72, 52, 47, 1089, 92, 52, 1089, 4, 2025, 18, 5, 9, 30, 956], [1580, 133, 20, 9, 5, 700, 28, 984, 6, 43, 285], [1580, 6, 5, 59, 4, 9, 52, 2111, 8, 38, 5, 191, 21, 2, 327, 52, 229, 5, 60, 370, 30, 13678, 88, 32, 5, 63, 58, 12, 7562], [2262, 2790, 56], [421, 45, 19, 4, 13679, 7, 13680, 7, 1], [1418, 860, 813, 2600, 813, 7212, 7563, 120, 1173, 579, 1160, 190, 1173, 579, 1324, 2391, 579, 873], [1418, 16, 2098, 7564, 7565, 466, 7234, 13681, 1374, 860, 579, 2, 417, 180, 13682, 13683, 21], [421, 1199, 174, 2, 141, 1], [421, 80, 1, 13, 2, 13684, 25], [13685, 3803, 2086, 1014, 13686, 1416, 33, 616, 108, 479, 35, 10, 234, 9, 218, 3, 271, 11, 13687], [4346, 146, 376, 22, 9], [13688, 273, 17, 4, 237, 2068, 3, 182, 502, 50, 47, 7, 15, 3507, 295, 6, 311, 147, 1, 2235, 1522], [13689, 121, 2086, 220, 612, 371, 230, 66, 220, 13690, 5, 189, 49, 13691, 2574, 83, 526, 69, 2171, 4, 3906], [7080, 401, 123, 6, 5499, 15, 108, 6, 4, 2380, 461, 149, 2, 1343, 301, 52, 210, 87, 6, 1168], [316, 2, 145, 60, 13692], [316, 246, 1, 21, 2, 112, 916], [7566, 764, 14, 21, 43, 540, 1, 214, 51, 1418], [280, 23, 723, 88, 2, 9, 945], [280, 326, 12, 2, 236, 88, 19, 15, 20, 443, 207, 12, 3672, 355, 5, 49, 2, 236, 5, 1338, 20, 310, 32, 4, 193, 6, 1843, 903, 236, 251], [280, 57, 11, 4, 19, 78, 1, 86, 188, 7, 12, 48, 422], [280, 230, 9, 48, 280, 129, 20, 504], [280, 230, 9, 48, 280, 129, 20, 5614], [291, 1, 14, 13, 241, 52, 41, 13693], [291, 1, 70, 17, 549], [291, 1, 18, 10, 7567], [291, 1, 7, 81, 45, 212, 4, 68, 7, 3, 1985, 21], [291, 1, 7, 81, 45, 92, 76, 4, 1, 3, 1985, 21], [291, 9, 156, 131, 687, 42, 46, 672, 32, 115, 220, 42, 28, 7, 2548, 82], [291, 24, 177, 7568, 7569], [6741, 118, 96, 762, 470, 42, 153, 54], [13694, 1745, 372, 13695, 88, 2, 9, 1315, 34, 10, 734, 70, 5275, 2632, 7570, 37, 3, 380, 23, 1192, 27, 7], [13696, 7, 13697, 363, 2668, 3374, 3, 344, 920, 539, 7, 9], [524, 12, 2, 207, 37, 10, 387, 49, 207], [348, 348, 348], [524, 8, 786, 982, 14, 1557, 1593, 412], [13698, 9, 13699, 4355, 3738, 13700, 13701, 9, 13702, 855, 13703, 2175, 186, 3005, 3738, 6771, 13704, 13705, 1536, 855, 13706, 13707, 13708], [321, 23, 542, 6, 28, 22, 1763, 13709, 7, 1, 12, 1026, 2117], [321, 52, 1589, 67, 6, 79, 1432, 728, 2, 158, 11, 7, 215, 13710], [321, 1, 14, 255, 3261, 8, 489, 1927, 6, 261, 8, 45], [321, 338, 15, 6, 4, 7571, 490], [321, 22, 145, 156, 616, 1922], [321, 363, 37, 332, 18, 7, 1, 52, 655, 1078, 16, 4, 213], [2549, 5553, 8, 13711, 1246, 152, 14, 2, 89, 5552, 1], [2549, 13712, 201, 13713, 204, 22, 9, 99, 215, 264, 288, 66, 47, 2791], [7572, 1709, 3770], [13714, 9, 30, 997, 124, 6, 19, 35, 4, 501], [2752, 2303, 12, 2, 1], [13715, 65, 77, 28, 102, 4, 3367, 73, 23, 294, 173, 2, 511, 7573, 43, 1, 42, 75, 107, 11, 42, 75, 42, 75, 107, 2073], [4578, 456, 86, 52, 37, 342, 61, 54, 596, 84, 185, 30, 228, 8, 338, 17, 135, 34, 194, 38, 52, 28, 108, 161, 1], [13716, 1, 70, 15, 2427], [3558, 1, 233, 145, 156, 124, 116, 402, 54], [3558, 13717, 174, 237, 3494, 1, 59, 42, 6, 17, 559, 13718], [1492, 2, 2463, 2262, 121, 5, 2, 537, 30, 490], [1492, 692, 4, 413, 1036, 128, 93, 188, 1037, 30, 9], [1492, 491, 84, 2354, 1040, 54, 18, 7, 1208, 83, 57, 3, 328, 273, 42, 9, 133, 154, 1648, 25, 26, 36, 5615], [1478, 2, 1538, 7574, 1478, 2, 1], [1450, 207, 3869, 7575, 5, 185, 83, 5546, 255, 3907, 13719, 7576, 1450, 70, 43, 4166], [1731, 741, 6, 2, 399, 148, 7074], [1731, 539, 2, 399, 4579, 1708], [2352, 997, 49, 21, 1549], [1699, 30, 9], [1699, 1, 266, 110, 10, 409], [13720, 1438, 212, 2532, 13, 2, 626, 120, 24], [1571, 173, 2, 1, 7, 3908, 21, 1719, 2995, 51, 197, 641, 2, 13721, 46, 132, 37, 5293, 11, 10, 164], [3909, 7, 25, 25, 825, 2363, 13722, 22, 9, 61, 13723, 13724, 619, 934, 22, 1032], [666, 16, 505, 25, 26, 1, 18, 10, 798, 1747, 5547, 5053, 564, 73, 286, 340], [1276, 1], [13725, 32, 232, 8, 126, 13726, 4451, 7577], [4849, 49, 56], [7578, 1, 27, 10, 13727, 13728], [6649, 12, 7, 830, 24, 1872, 18, 2, 7579], [912, 2, 153, 7580, 2, 13729, 4, 489, 35], [912, 2, 153, 7580, 2, 9, 8, 512, 4, 489, 35, 37, 57, 66, 58], [912, 11, 147, 1, 231, 3, 29, 67, 386, 1546], [912, 10, 767, 137, 466, 37, 92, 3, 75, 934, 24, 8, 22, 4277, 3672], [34, 3137, 12, 2, 1], [34, 3, 1275, 54, 143, 849, 13730, 46, 43, 207, 13731, 54, 1038], [34, 3, 75, 303, 2199, 7, 85, 3, 61, 332, 282], [34, 3, 75, 28, 50, 6, 366, 650, 3, 1, 59, 254, 4, 1784, 16, 44, 2, 77, 69, 13732, 11, 428, 15, 2, 434, 2432], [34, 3, 44, 4, 9], [34, 23, 79, 22, 1, 221, 422, 211, 5, 79, 17, 3, 2753, 79, 1047, 31, 15, 46, 10, 77], [34, 1996, 36, 100, 17, 13733, 2, 104, 31, 42, 176, 212, 409, 16, 186, 1564], [34, 1, 5, 276, 1390, 74, 5263, 7, 24, 230, 3, 1236, 15, 7581], [34, 1, 49, 284, 278, 14, 11, 865, 21, 362], [34, 1, 14, 214, 130, 2, 663, 38, 36, 29, 62, 57, 23, 58, 26, 71, 3, 28, 15], [34, 31, 5, 724, 1, 604, 58, 165], [34, 43, 68, 79, 170, 2, 24, 21, 84, 3068], [34, 48, 4153, 130, 13734, 50, 24, 12, 322], [34, 613, 12, 2, 480, 682, 2993, 37, 15, 13735], [34, 40, 2, 89, 89, 1, 70, 5, 713, 21, 254], [34, 40, 63, 1691, 4, 45, 54, 2, 1], [34, 40, 12, 2, 282, 552, 59, 7], [34, 271, 35, 276, 14, 2, 83], [34, 36, 101, 81, 18, 186, 426, 24, 11, 112, 164], [34, 22, 1393, 45, 12, 1064, 21, 4, 13736], [34, 69, 12, 17, 6, 81, 59, 4, 244, 1, 1764, 38, 3, 328, 2314, 15, 230], [34, 85, 200, 22, 1, 33, 253, 13737, 110, 13, 42], [34, 85, 277, 10, 261, 156, 44, 2358, 18, 928, 4, 7582, 13, 22, 427, 60, 3489, 1259, 3030, 45, 110, 205, 60, 1, 152, 65, 15], [34, 78, 25, 131, 79, 39, 287, 9, 38, 36, 338, 5, 21, 2, 25, 7, 1512, 876, 19, 5, 161, 956], [34, 5, 95, 30, 25, 54, 135, 28, 20, 1508, 13738, 33, 13739, 8, 46, 43, 270, 184, 73, 2, 470, 193, 13740], [34, 5, 75, 113, 2, 291, 1, 777], [34, 5, 64, 17, 5, 29, 131, 14, 27, 357, 499, 1528, 7547, 908, 996, 4, 7583], [34, 1834, 3236, 3, 29, 94, 85, 435, 974, 287, 123, 79, 76, 1248, 226, 13, 1063, 4580, 7584, 74, 13741, 251], [13742, 13743, 2202, 752, 2261, 1430, 249, 8, 2, 4419, 1531, 2348, 12, 2431, 13744, 13745], [2101, 28, 32, 4, 9], [680, 83], [680, 680, 159, 5225], [3910, 47, 98, 13746, 439, 71, 4, 286, 22, 1, 1494, 81, 133, 71, 209, 40, 375, 133, 4266, 230, 52, 13747], [7585, 7586, 2, 167, 1304, 21, 377, 527, 31, 5, 49, 2, 355, 1009, 5, 600, 14, 18, 4, 13748], [13749, 8, 5241, 9], [7587, 7588, 2550, 4224, 2, 89, 83], [5616, 357, 14, 214, 51, 69, 52, 1668, 6, 14, 27, 3, 75, 14, 214, 51, 43, 1, 15, 4, 25, 37, 4484], [107, 6, 13750, 13751, 192, 51, 1212, 253, 123, 514, 149, 13752, 264, 2665, 8, 13753, 1708, 100, 1207, 22, 83], [5617, 87, 6, 139, 14, 2, 141, 83], [5617, 2, 138, 8, 7589, 2, 1, 3, 90, 76, 398, 92], [2203, 136, 1190, 140, 2203, 12, 248], [2203, 12, 337, 6, 13754, 248], [79, 2, 9, 2, 9, 8, 2, 2682, 2, 2682], [79, 2, 664], [79, 147, 836], [79, 17, 2, 171, 1, 34, 432, 110, 62, 369, 13755, 12], [79, 17, 2, 181, 34, 3, 64, 38, 111, 227, 126, 235, 74, 65, 54, 16, 126, 347, 38, 3, 484, 123, 149, 36, 235, 17, 13756, 1, 64, 15], [79, 17, 179, 31, 5, 67, 34, 23, 294, 6, 8, 82, 521, 27, 10, 13757, 18, 10, 4416], [79, 16, 3384, 54, 22, 1], [79, 38, 5, 632, 562, 31, 5, 259, 7, 7590, 370, 21, 915, 27, 270, 950, 1970, 36, 41, 5, 26, 206, 368], [79, 3730, 2, 3034, 123, 2638, 5245, 55], [79, 15, 195, 570, 264, 13758, 12, 2, 1], [79, 54, 660, 2302, 18, 126, 1662, 527], [79, 39, 530, 9, 54, 3067, 219, 12, 99, 112], [5618, 7591, 12, 270, 2, 141, 77, 13, 632, 35, 8, 559, 896, 13, 2, 1], [5618, 7591, 12, 270, 2, 24, 52, 87, 6, 632, 35, 8, 683, 52, 427, 2, 13759, 245, 127], [510, 337, 8, 592, 10, 534, 376, 18, 10, 2270, 5350, 3, 64, 7, 4581], [4582, 115, 430, 17, 51, 261, 5592, 21, 339, 1], [63, 16, 2337, 22, 360, 47, 1601, 6, 941, 76, 8, 1090, 76, 6, 13, 13760], [63, 159, 824, 349, 68, 129, 18, 825, 1215, 219, 52, 200, 349, 68, 129, 18, 384, 13761], [63, 138, 4583, 28, 906, 58, 665, 16, 2, 718, 2956, 60, 106, 738, 333, 2689, 5147, 7592], [63, 3, 316, 246, 1, 63, 66, 44, 2, 3181, 74, 7593], [63, 3, 316, 246, 1, 74, 336], [63, 3, 316, 246, 1, 74, 336], [63, 3, 957, 1216, 20, 354], [63, 3, 28, 60, 93, 833, 54, 325, 9], [63, 3, 44, 2, 89, 1, 461, 43, 3058, 107, 6, 563, 17, 461, 43, 7594], [63, 3, 44, 2, 89, 1, 461, 43, 13762], [63, 3, 389, 5, 6, 139, 14, 2, 161, 1, 7595, 148, 242, 4, 19, 35], [63, 3, 400, 18, 20, 231, 400, 18, 2, 341, 7596, 1], [63, 3, 316, 246, 1, 74, 336], [63, 10, 261, 333, 172, 3416, 39, 1107, 30, 56, 63, 11, 4, 848, 16, 4, 4584, 7, 3, 156, 172, 298, 173], [63, 105, 253, 1, 69, 1618, 65, 13, 22], [63, 109, 555, 310, 2535, 11, 10, 331, 27, 22, 56, 30, 2312], [63, 217, 257, 1748, 4309, 30, 52, 270, 141, 285], [63, 217, 28, 17, 873, 8, 353], [63, 217, 333, 1365, 6, 17, 85, 49, 4, 95, 37, 1076, 26, 2275, 1072, 337], [63, 217, 557, 17, 6, 60, 13763, 23, 291, 1, 129, 1184], [63, 39, 95, 242, 4, 19, 35], [63, 22, 1, 330, 1588], [63, 22, 1, 1867, 3123], [63, 22, 1, 400, 4, 19, 142, 8, 242, 4, 19, 35], [63, 42, 72, 9, 9, 9, 2584, 40, 47, 3365, 3, 47, 37, 196, 6, 50, 18, 4, 5619, 151, 3539, 4, 4585, 649], [63, 66, 859, 4, 13764, 54, 16, 10, 1747], [63, 66, 5620, 725, 1179, 16, 268, 412, 16, 137, 641, 922, 166, 3, 118, 13, 6, 94, 2, 178, 155, 92, 26, 2932], [63, 5, 430, 2, 874, 9], [63, 5, 430, 2, 874, 9], [63, 5, 2337, 2250, 80, 4586, 6, 139, 2, 1, 3069, 7597, 8, 96, 1506, 35, 7598], [63, 5, 100, 17, 3070, 7, 24, 54, 74, 336], [63, 5, 100, 17, 3070, 7, 24, 54, 74, 7593], [63, 5, 109, 114, 138, 74, 336, 63, 3, 316, 246, 1, 74, 336], [75, 304, 6, 2792, 39, 25, 11, 4, 1408, 1404, 444, 88, 93, 401, 9], [75, 14, 2, 1082, 25, 27, 2, 3698, 9], [75, 14, 239, 184, 1128, 130, 44, 670, 5621, 140, 2, 4430, 232, 178, 12, 96, 61, 962], [75, 257, 2, 1228, 16, 1296, 18, 567, 95], [75, 110, 376, 11, 4, 19, 347, 140, 22, 639, 1534, 484, 13, 2, 144, 8, 2870, 4, 421, 99, 332], [75, 258, 10, 426, 3132, 233, 151, 33, 901, 22, 1334, 13765], [75, 19, 125, 43, 1, 183, 228], [75, 19, 27, 2, 490, 30, 77, 321], [75, 19, 27, 43, 283, 33, 75, 58, 254], [75, 28, 43, 169, 82, 17, 5, 1482, 9], [75, 28, 43, 24, 6, 2841, 4084, 1153, 71, 358, 15, 132, 21, 97], [75, 44, 2, 1, 27, 43, 1152, 74, 7599, 3, 64, 265, 34, 31, 20, 48, 2, 915, 250, 3, 75, 799, 27, 5], [75, 176, 2, 1, 34, 15, 431, 149, 169, 96, 224], [75, 176, 2, 5622, 1, 31, 97, 1434, 46, 5623], [75, 100, 357, 137, 10, 3794, 1, 13, 168, 35, 32, 97, 5624, 163, 525, 97, 252, 13766, 123, 4, 670], [75, 1161, 14, 2, 3417, 21, 43, 812, 7, 46, 17], [75, 43, 9], [75, 492, 39, 9], [75, 397, 2, 1, 7, 156, 150, 4, 87, 6, 14, 58, 7600, 400, 20, 30, 51, 337, 8, 14, 723, 5, 46, 146, 14, 2, 9, 32, 4, 106], [75, 397, 2, 25, 7, 1189, 84, 177, 21, 60, 9], [75, 397, 2, 4572, 30, 1], [75, 397, 1, 30, 956], [75, 397, 179, 590, 30, 5625], [75, 397, 7, 668, 252, 33, 92, 104, 134, 17, 764, 149, 3, 603, 911, 10, 591, 19, 42, 104, 31, 3, 407, 18, 1706], [75, 397, 7, 711], [75, 397, 4, 232, 34, 891, 167, 2, 337, 298, 11, 84, 679, 51, 2640, 11, 2327, 118, 14, 3767, 28, 1324, 118, 14, 165], [75, 397, 38, 3, 94, 2, 275, 33, 28, 54, 16, 575, 26, 201, 115, 790, 126, 13767, 6, 246, 189, 9, 152, 14, 9, 251], [75, 139, 119, 2155, 353], [75, 114, 42, 490, 2488, 26, 3, 196, 2488], [75, 113, 31, 3418, 136, 132, 1268, 74, 31, 2484, 136, 33, 132, 56, 225], [75, 113, 17, 45, 218, 432, 279, 83], [75, 302, 155, 231, 1, 5, 146, 194, 240], [75, 302, 39, 283, 8, 39, 25, 2164], [75, 302, 39, 1928, 8, 38, 3, 72, 9, 3, 196, 252, 6], [75, 227, 2, 9, 173, 2, 331, 436], [75, 304, 634, 3, 28, 10, 392, 13768, 895, 101, 672, 2, 470, 179, 13769, 43, 7601, 43, 2766], [75, 304, 634, 10, 1, 28, 135], [75, 304, 6, 157, 22, 142, 5626, 18, 10, 1], [75, 304, 6, 94, 10, 1, 13770], [75, 475, 133, 2, 1, 7, 46, 475, 133, 17], [2055, 7, 1, 13, 13771], [2055, 7, 9, 53, 15, 46, 295, 6, 311, 7, 7602, 2235], [2031, 12, 2, 9, 78, 1646, 21, 4, 111, 69, 44, 254, 53], [75, 806, 22, 1, 8, 50, 5010, 203], [75, 137, 43, 178, 125, 7603, 25, 74, 1], [75, 304, 32, 25, 131, 58, 51, 2655, 12, 429, 5627, 8, 429, 379, 1], [75, 143, 207, 8, 143, 120, 617, 28, 1738, 66, 32, 14, 143, 199, 7604, 143, 207, 435, 41, 143, 7605, 138], [5628, 1228, 13772, 36, 1337, 7606, 11, 4, 503, 2636, 27, 95, 18, 13773], [3137, 122, 119, 4, 24, 34, 7, 180, 30, 1359, 14, 19, 45, 35], [7607, 12, 152, 1576, 8, 13774, 22, 83], [13775, 2, 836], [3324, 87, 6, 242, 4, 19, 35, 19, 1, 30, 156, 122, 6, 192, 45], [7608, 6300, 12, 37, 56, 22, 12, 180], [430, 17, 172, 102, 390, 188, 11, 7, 1, 73, 13776], [430, 17, 18, 4, 1510, 16, 3288, 5629, 740, 1477, 3, 1, 491], [430, 22, 2523, 9], [430, 35, 27, 4, 3623, 4587, 2456, 1], [149, 23, 2, 3340, 2280, 141, 1], [149, 23, 4, 409, 16, 13777, 6, 675, 18, 5, 74, 6, 137, 224, 37, 29, 14, 2, 141, 1], [149, 5630, 56, 85, 36, 1042, 4, 1197, 1408, 3503, 45, 37, 570], [149, 83, 3, 516, 119, 24, 88, 28, 588, 13778], [149, 5, 4230, 78, 9, 137, 1119, 99, 1572], [3599, 56, 99], [3911, 41, 50, 413, 1722, 154, 13779, 82, 50, 261, 26, 14, 18, 7, 1, 45, 99, 17, 13, 550, 34, 769, 66, 96, 384, 7502], [3911, 121, 3522, 1, 3, 593, 5, 47, 18, 331, 1462, 37, 5, 46, 294, 43, 13780, 526, 3, 90, 50], [13781, 94, 71, 358, 212, 3893, 235, 63, 61, 461, 122, 6, 1183, 3015, 88, 345, 6, 1129, 871, 38, 36, 28, 429, 361], [13782, 288, 5, 1500, 83], [1120, 1022, 109, 14, 120, 73, 385, 3, 196, 29, 28, 17, 329, 10, 45, 46, 190, 123, 750, 34, 3, 87, 766, 13783, 36, 14, 168], [4588, 196, 120, 248, 31, 217, 72, 374, 4588, 15, 196, 374, 120, 248], [7609, 1177, 5631, 899, 13784, 4, 7610, 250, 1065, 16, 4, 4347, 94, 5631, 899], [7609, 1177, 5631, 7225, 3022, 13785, 18, 119, 2045, 13786, 8, 95], [3586, 1488, 11, 22, 83], [1180, 12, 56], [1180, 70, 2098, 153, 46, 295, 139, 5], [1180, 70, 2098, 153, 46, 295, 139, 5], [396, 4, 178, 18, 42, 1], [13787, 190, 13788, 13789, 8, 13790, 7611, 216, 27, 64, 21, 26], [13791, 3061, 207, 968], [3867, 13792, 387, 49, 127, 190, 130, 1901], [3867, 47, 1831, 56, 30, 7612, 11, 7, 13793, 62, 52, 47, 96, 950, 51, 4, 106, 55], [159, 1186, 21, 2793, 13794, 247, 3047, 13795, 11, 247, 3047, 654, 608, 523, 21, 3554, 381, 527], [159, 2719, 65, 93, 21, 2655], [159, 2193, 1259, 1290, 151, 2202], [159, 824, 13796, 3, 717, 160, 13797, 3912, 6, 2389, 2, 13798], [159, 824, 468, 13799, 1382, 401, 6, 878, 4134, 2872, 12, 783, 15, 160, 2302, 13800, 527], [159, 824, 8, 825, 1215, 49, 398, 5632, 4589, 1489, 7, 824, 136, 478, 6, 298, 68, 33, 68, 1531, 1086, 13801], [159, 824, 136, 191, 6, 176, 2961, 11, 7613, 458, 444, 13802, 708, 358, 5212, 871, 1193, 72, 7614, 480, 11, 13803], [159, 824, 404, 1033, 4590, 11, 1382, 1837, 849, 3540, 1969, 527], [159, 824, 13804, 90, 13805, 8, 13806, 21, 1448, 4, 970, 3913, 57, 2, 823, 57, 2, 5633], [159, 1908, 568, 102, 18, 3183, 1893], [159, 1908, 2505, 328, 2, 165, 401], [159, 13807], [159, 3278, 41, 1075, 59, 4, 684, 1857, 1611, 8, 661, 1476, 2, 1857, 16, 2454, 18, 84, 1643], [159, 5634, 296, 124, 2488, 6, 4847], [159, 7615, 4490, 503, 451, 3645], [159, 2244, 60, 1108, 442, 7, 3393, 427, 129, 335, 910, 13808, 7039, 849, 1092, 946, 1033, 54], [159, 925], [159, 925, 105, 13809], [159, 925, 67, 6, 2753, 6, 268, 8, 2, 470, 435, 335], [159, 925, 496, 1253, 6, 970, 642], [159, 8, 13810, 64, 7, 13811], [159, 8, 2925, 136, 1577, 157, 54, 1136, 21, 126, 1119, 2184], [159, 1102, 17], [159, 1766, 249, 30], [159, 12, 98, 802, 1500, 902], [159, 12, 37, 6790], [159, 65, 13, 52, 4, 68, 7, 216, 7, 1375], [159, 48, 3419, 224, 11, 13812, 155, 449, 495, 28, 543, 102, 4, 3117], [159, 13813, 12, 482], [778, 109, 41, 9, 11, 155, 654, 15, 284, 84, 410, 226, 4, 910], [778, 4, 24, 15, 2, 13814, 616, 11, 97, 3231, 15, 2, 13815], [778, 39, 9, 165, 28, 1278, 25], [359, 10, 193, 6, 28, 736, 22, 1, 356, 31, 20, 37, 475, 59, 17, 88, 139, 1411, 17, 171, 30], [7616, 7616, 2617, 5635, 162, 5, 258, 7, 43, 93, 120, 56, 282], [359, 427, 59, 93, 287, 8, 1541, 2431, 59, 98, 13816, 13817, 25, 359, 18, 93, 287, 744, 2436], [536, 84, 9, 21, 3, 536, 50], [536, 20, 2972, 203, 77, 228, 610, 13818, 31, 40, 29, 44, 2043, 638, 11, 155, 327, 1887, 21, 203, 77, 285], [4591, 299, 73, 4, 5176, 4444], [1801, 35, 3039], [1801, 379, 462, 13819, 13820, 13821, 13822, 8, 13823], [873, 1, 13824, 65, 13825], [7617, 2443, 3914, 973, 354, 8, 2, 13826, 1178, 16, 7618, 117, 615, 23, 4, 13827, 6704, 2756], [2962, 9, 64, 1106, 5636], [2962, 25, 113, 1, 393, 38, 36, 238, 58, 147, 13828], [418, 4518, 2, 407, 59, 2733, 2506, 15, 47, 59, 4, 250, 13829, 31, 5, 210, 28, 7, 88, 5, 44, 43, 117, 6, 1, 59, 7619], [418, 41, 2, 91, 34, 43, 13830, 25, 41, 9, 34, 43, 7620, 26, 148], [418, 14, 214, 51, 17, 21, 3406, 59, 9, 13, 23, 533, 59, 2, 3889, 217, 55, 370, 462, 31, 4, 845, 1023, 88, 255, 15], [418, 64, 39, 183, 1792, 1716, 700, 149, 36, 65, 13, 4, 586, 7, 47, 105, 11, 126, 1068], [1830, 408, 49, 4, 101, 68, 7, 708, 10, 114, 49, 329, 59, 7621, 56, 7622, 1285, 13831], [497, 31, 3, 182, 671, 970, 571, 1742, 2794, 82, 13832, 21, 2, 115, 33, 6, 94, 5, 664, 13833, 13834, 368], [497, 1, 66, 46, 11, 64], [497, 27, 4, 1887, 1, 10, 418, 117, 244, 6, 17, 21, 112, 9], [497, 23, 48, 2, 490, 549, 16, 5, 365, 7623, 30, 490, 55], [1397, 11, 4, 689, 27, 10, 144, 30, 13835, 3, 150, 51, 2247], [1397, 125, 10, 1, 69, 105, 5191, 1146], [1397, 27, 10, 455, 9, 7624], [13836, 955, 18, 13837, 32, 4, 148, 106, 3, 4480], [1018, 1054, 12, 37, 248], [3310, 4, 503, 18, 4, 13838, 7, 2, 7625, 1766, 188, 13839, 358, 73, 98, 7536, 2652, 1, 3, 466, 13, 1488, 8, 3, 137, 392, 1605], [890, 2894, 133, 6, 2158, 4, 3340, 13, 2, 112, 104, 251], [890, 524, 28, 1, 321, 128], [890, 1939, 56, 425], [890, 2, 104], [890, 2894, 216, 3841, 875, 84, 1, 215, 264], [2677, 1701, 873, 427, 4, 199, 73, 38, 3, 47, 2, 4441, 2677, 2, 703, 1, 26, 36, 424, 423, 4, 466, 7626, 91, 369], [5637, 48, 2, 179, 7627, 219, 716, 34, 15, 48, 7628], [2390, 421, 579, 369, 49, 2364, 387, 4466, 13, 159, 3138, 11, 4, 4592, 112, 360, 55], [620, 1194, 1], [620, 13840, 13841, 1478, 480, 190, 759], [708, 6, 14, 2, 900, 34, 5, 2, 161, 291, 1], [4330, 16, 7629], [1677, 613, 730, 265, 58, 692, 8, 13842, 14, 32, 179, 8, 13843, 428, 179, 950, 265, 65, 21, 2342, 6, 28, 459, 116], [13844, 1, 3, 33, 41, 102, 4, 310, 27, 240], [1113, 23, 1491, 16, 95], [2886, 12, 4, 237, 412, 21, 3031, 1061, 4, 7630, 63, 168, 4, 1248, 52, 124, 27, 4, 786, 26, 4, 524, 717, 12, 417, 125, 2, 1589, 7631], [637, 20, 387, 8, 100, 4, 360, 1622, 2, 1721, 406, 68, 93, 77, 12, 783, 2, 1721, 2365], [3060, 271, 719, 111, 4069, 250, 40, 114, 2790, 123, 72, 7632, 88, 40, 114, 588, 123, 72, 1163, 13845, 28, 20, 373, 10, 312, 1301], [1353, 30, 399], [4472, 12, 2, 1, 25, 28, 84, 30, 102, 10, 412], [3718, 87, 2, 190, 21, 2090], [5616, 302, 74, 266, 3539, 2, 1, 13846], [968, 5638, 1, 371, 5639], [2913, 1, 27, 580, 1022, 7, 741, 54, 82, 2482, 36, 3845, 2979], [6534, 3228, 106, 1], [1803, 16, 13847, 24, 7633, 25, 351, 10, 25, 13848, 717, 13849, 13850, 13851, 2653, 163, 10, 25, 5381, 13852, 163, 10, 25, 1137, 1091], [2543, 8, 120, 283], [13853, 13854, 820, 201, 13855, 212, 386, 16, 1, 36, 3009, 15, 54, 8, 5640, 15, 8, 591, 15, 142, 7, 23, 37, 2082, 7634], [13856, 139, 14, 816, 8, 428, 197, 267], [107, 108, 9], [107, 21, 4, 3211, 8, 166, 13857, 59, 2755, 511, 1671, 1, 2054], [107, 28, 22, 2070, 24], [107, 50, 161, 1, 3, 67, 7, 1339, 3915], [107, 337, 82, 197, 6, 13858, 1347, 8, 2, 1149, 16, 2289], [107, 18, 1686, 421, 384, 9, 108], [107, 18, 91, 354, 87, 6, 497, 5, 62, 59, 39, 93, 74, 336], [107, 18, 579, 28, 7, 813, 158, 64, 147, 813, 82, 6527], [107, 54, 50, 24, 8, 61, 11, 50, 30, 107, 54, 50, 30, 8, 61, 11, 50, 476], [107, 785, 7635, 5, 1235, 16, 593, 1], [1506, 82, 2, 203, 1], [1088, 1, 51, 95, 21, 13859, 34, 201, 7086, 189, 58, 15, 6, 1492, 8, 15, 1492, 1791], [983, 102, 3371, 1004, 59, 7, 322, 9, 205], [5641, 7636, 87, 6, 28, 2, 164, 27, 7, 13860, 13861, 522, 7120], [4593, 11, 68, 193, 24, 11, 7496, 37, 5586], [1075, 6998, 598, 6, 28, 11, 4, 193, 16, 20, 314, 5642, 127, 21, 5643], [2254, 18, 14, 2, 187, 8, 58, 20, 70, 35, 1128, 130, 2, 1296, 213, 3905, 183, 1], [2774, 20, 33, 13, 155, 166, 861, 35, 13862, 732, 83], [13863, 2874, 13864, 664, 693, 5644, 2537, 5645, 43, 7637, 13865, 2998, 13866], [829, 80, 1541], [829, 4, 3196, 2652, 4, 413, 268, 8, 2, 470, 755, 484, 337, 8, 210, 3383, 2, 419, 3037, 394, 20, 520, 487, 58, 7, 1], [867, 1418, 11, 4, 677, 12, 1039, 2161, 19, 988, 3, 44, 428, 867, 230, 26, 3, 46, 59, 6, 28, 43, 3852, 1276, 18, 10, 628], [431, 501, 184, 6, 13867, 4, 13868, 16, 3563, 56, 2742, 51, 1721, 16, 1634, 3783, 755, 117, 2037, 5], [490, 39, 9, 64, 157, 4594, 8, 2107, 18, 4, 199, 19, 13869], [7638, 480, 12, 248, 13870, 3, 29, 110, 13, 5646], [7639, 12, 56], [1675, 13871, 4, 2623, 12, 190, 989, 12, 2619, 2012, 988, 23, 626], [1675, 52, 165, 316, 68, 1677, 1, 337, 140, 734, 46, 61, 6, 14, 799, 27, 1107, 9, 11, 4, 331], [2926, 13872, 3, 46, 303, 43, 24, 3, 41, 99, 239, 253, 21, 7, 42, 11, 3570, 29, 346, 2746], [2063, 132, 6545, 80, 1], [487, 279, 882, 59, 245, 1], [487, 349, 10, 25, 11, 97, 13873, 651, 9], [914, 169, 288, 10, 1, 2791], [823, 13874, 324, 16, 4, 115, 2981], [823, 451, 8, 742, 451, 398, 81, 59, 4, 199, 339, 45, 13875, 13876, 13877, 13878, 743, 55], [1081, 65, 21, 1, 3, 293, 4, 19, 12, 22], [1739, 49, 4, 237, 11, 4, 13879, 59, 106, 39, 104, 41, 126, 45, 612], [1144, 4595, 63, 719, 20, 1, 82, 5], [5647, 739, 7, 45, 35, 9], [13880, 715, 93, 24], [4596, 35, 2, 141, 4164, 400, 18, 4, 689, 8, 467, 23, 59, 6, 28, 10, 388, 18], [3061, 348], [284, 30, 3, 132, 208, 37, 196, 590, 8, 179, 3, 1144, 531, 35], [284, 1, 160, 13881], [3386, 989, 96, 861, 11, 10, 235, 1], [3386, 27, 10, 234, 1, 293, 3, 29, 28, 906, 359], [1790, 833, 30, 399], [7640, 503, 8, 60, 314, 3609, 752, 193, 6, 48, 65, 13, 98, 7641, 187, 425], [2795, 1815, 1088, 70, 170, 2, 1104, 7337, 130, 159, 925, 26, 52, 210, 110, 44, 245, 3339, 1009], [13882, 657, 4, 606, 11, 10, 3420, 7642, 4, 1, 5638, 4, 9], [2795, 11, 10, 61, 13883, 51, 2000, 506, 7643, 61, 3421, 1124, 104, 22, 45, 12, 13884, 130, 971, 13885], [345, 6, 4, 13886, 7, 60, 732, 29, 13, 5, 26, 318, 79, 5, 226, 66, 79, 7, 14, 2, 3126, 83, 13887], [2350, 41, 32, 4, 319], [2209, 39, 9, 91, 7, 162, 5, 363, 89, 3916, 5, 700, 525, 528, 51, 218, 326, 1131, 7], [1354, 12, 2, 43, 988, 10, 1013, 714, 271, 6903, 85, 14, 11, 2, 575, 31, 5, 48, 100, 20, 9, 61], [1114, 22, 12, 305, 13888, 220, 556, 1131, 60, 1], [187, 187, 3648], [4414, 77, 12, 162, 15, 51, 8, 5, 1, 87, 6, 28, 27, 15], [1254, 13889, 30, 1], [1254, 14, 167, 27, 4, 7644, 2392], [1254, 477, 6, 1320, 7491, 13890, 5543, 101, 137, 38, 2513, 6, 7223, 283], [1254, 400, 142, 301, 2, 1, 3694], [1254, 2517, 816, 5488], [3056, 830, 21, 2543, 140, 52, 2, 181, 8, 2764, 157, 15, 18, 478], [1027, 5, 2212, 717, 9], [3864, 54, 123, 2, 203, 388, 18, 4, 215, 115, 3831], [2051, 2312, 439, 3, 109, 87, 22, 1, 6, 28, 4, 4575, 54, 10, 3023, 33, 458, 10, 154, 1024, 8, 338, 17, 771, 5648], [2051, 14, 238, 208, 13, 5, 29, 594, 57, 374, 72, 43, 1, 5, 29, 594, 57, 23, 7239], [311, 1019, 1, 102, 13, 13891], [311, 7, 1, 102], [311, 76, 25, 102, 36, 46, 80, 228, 311, 76, 1, 102, 36, 33, 1463], [311, 39, 9, 102, 117, 92, 3, 109, 87, 6, 432, 109, 62, 77, 34, 3, 442, 11, 42], [342, 1688, 1328, 28, 50, 13892, 24, 19, 288, 13893], [342, 30, 4581], [342, 5649, 189, 294, 11, 8, 88, 52, 458, 84, 476, 8, 52, 47, 2, 788, 144], [342, 171, 275, 248], [342, 1328, 28, 50, 24, 2971, 13894], [4597, 882, 1970, 51, 3347, 130, 2, 144, 13895], [218, 31, 15, 56, 23, 2546, 15, 51, 72, 52, 87, 6, 61, 108, 6, 865], [218, 15, 6663, 71, 23, 1976, 39, 9], [218, 24, 101, 24, 91, 3, 28, 15, 38, 3, 87, 15], [218, 36, 29, 131, 340, 492, 85, 12, 492, 9, 89], [218, 42, 2, 9], [218, 5, 2, 9, 1847, 7645, 78, 44, 352, 27, 2, 252, 88, 52, 303, 5, 2, 558, 74, 389, 20, 2354, 57, 7], [13896, 1, 762, 54, 18, 4, 2994], [1098, 891, 2427, 2427, 13897], [5650, 13898, 13899, 13900, 2971, 545, 13901, 2551, 13902, 5651, 16, 1755, 2104, 42, 3722, 674, 782, 30, 13903], [4143, 399, 472, 356, 73, 286], [58, 15, 58, 15, 604, 96, 1701, 2, 181, 34, 58, 13904, 151, 433, 13905, 1707], [13906, 12, 85, 49, 13907, 33, 191, 8, 4, 13908, 394, 13909], [143, 1, 2959, 47, 4271, 13, 143, 13910, 13911, 51, 143, 13912, 1194], [143, 7646, 236], [143, 331, 244, 676, 6, 17, 132, 1597, 6, 1391], [13913, 128, 117, 108, 6, 76, 206, 193, 65, 51, 22, 9, 30, 25, 1112, 1336, 231, 5, 9], [7647, 523, 263, 399], [586, 1048, 17, 2, 348, 1448], [586, 1051, 17, 337, 2, 2829, 13914, 34, 3, 29, 13, 15, 37, 15, 61, 11, 4, 56], [586, 79, 17, 2, 1909, 5036], [586, 33, 1087, 54, 3114, 133, 6, 860, 60, 813, 13, 2, 3111], [586, 85, 49, 20, 387, 37, 355, 386, 3, 366, 441, 4900, 586, 29, 308, 6, 17, 5, 220, 345, 140, 5, 49, 2, 711], [803, 353, 8, 2, 607, 89, 2365], [5652, 12, 4494, 95], [13915, 13916, 28, 50, 24, 19, 8, 249, 968, 13917], [2118, 9, 85], [1301, 3, 33, 146, 293, 7, 145, 29, 1431], [1301, 22, 145, 1070, 102, 4249], [148, 53, 15, 716, 56, 91, 53, 71, 239, 16, 5, 428, 44, 124, 2, 13918, 13919], [148, 26, 84, 158, 451, 597, 35, 4, 413, 261, 11, 4, 561, 233], [148, 159, 2090, 12, 96, 224], [148, 3, 90, 2, 1, 7, 13, 6, 687, 8, 45], [148, 3, 90, 2, 1, 69, 13, 6, 687, 8, 45], [148, 3, 86, 20, 786, 514], [148, 3, 168, 6, 14, 2, 180, 408, 16, 13920, 34, 37, 750, 40, 132, 2, 180, 187], [148, 23, 11, 143, 2156, 6, 119, 667, 24, 69, 41, 15, 1241, 18, 2, 13921, 21, 17, 1517, 13922], [148, 852, 1889, 33, 70, 15, 372, 13, 7648, 47, 56, 38, 52, 137, 21, 4, 13923, 497, 54, 7649], [148, 7650, 12, 56, 91], [148, 4598, 13924, 92, 32, 39, 9, 328, 297, 20, 91, 7651], [148, 95, 3754, 502, 17, 2, 548, 13925, 8, 32, 40, 121, 47, 13926, 1, 13927], [148, 1, 146, 13928], [148, 1, 13929], [148, 1, 5, 3613, 333, 29, 881, 10, 310, 333], [148, 280, 23, 807, 88, 2, 9, 945, 8, 46, 41, 45, 6, 119, 51, 4, 967, 7652], [148, 396, 396, 153], [148, 77, 151, 14, 20, 2084, 269], [148, 2072, 5, 37, 183, 110, 1687, 2538, 121, 13930], [148, 1760, 3158, 6672, 1025, 35, 51, 13931, 150, 1485, 82, 10, 7653, 5653, 13932, 4244, 5654, 17, 6, 4, 13933], [148, 15, 14, 587, 972, 2, 207, 91], [148, 55, 114, 2, 406, 15, 215, 1363, 130, 1442, 13, 2, 804, 30, 83], [148, 388, 619, 512, 743, 176, 597, 10, 265, 562, 43, 376, 21, 263, 1146, 267, 197, 51, 7654, 12, 61, 6, 14, 37, 13934], [148, 60, 354, 118, 14, 37, 19, 3374, 117, 92], [148, 7, 1, 171], [148, 4, 89, 184, 59, 44, 234, 9, 12, 5, 75, 28, 214, 38, 36, 29, 167, 5, 35, 32, 115], [148, 36, 208, 13, 7655, 13935, 84, 5655, 4381, 35, 1, 55], [148, 22, 1, 284], [148, 22, 1, 530, 55], [148, 212, 3688, 728, 212, 1852, 480, 5656, 8, 7, 7656], [148, 69, 724, 22, 413, 106, 7, 3, 47, 4, 1076, 664, 252], [148, 5, 2, 9], [148, 95, 271, 45, 18, 10, 13936], [4973, 55, 13937, 786, 1, 100, 19, 61, 19, 4, 1935, 66, 133, 6, 1276, 7, 1, 142, 13938], [13939, 12, 2, 1], [7657, 7658, 349, 102, 7, 13940, 4458, 33, 65, 13, 2, 104], [1908, 116, 43, 5268, 1011, 8, 9, 142, 11, 13941, 22, 620, 259, 55], [3841, 524, 165, 157, 54, 127, 451, 230, 52, 7659, 7, 252, 12, 54, 84, 172, 95], [3841, 890, 8, 3, 198, 48, 14, 1166, 54, 11, 775, 612], [991, 682, 77, 27, 1958, 343, 87, 6, 139, 254, 4, 101, 1, 7, 63, 728, 7, 12, 13942, 82, 4, 818, 2865], [3422, 5463, 146, 497, 125, 84, 190, 1927, 91], [147, 1, 2, 593], [147, 1, 146, 973, 18, 50, 108, 6, 2168], [147, 1, 124, 5281, 2487], [147, 1, 476, 216, 143, 2552, 694], [147, 1, 1060, 73, 45, 2042], [147, 143, 89, 184, 133, 14, 4287, 115, 316, 17, 11, 6, 290, 34, 29, 13943, 17, 6, 143, 4297, 13944], [147, 9, 7660, 13, 40, 47, 18, 50, 1230], [147, 153, 124, 1488, 5385], [147, 153, 1010, 13945, 163, 143, 5602], [438, 2, 1021, 140, 5, 62, 36, 266, 24, 54, 38, 15, 107, 6, 2024, 350], [438, 5, 118, 14, 13, 13946, 438, 7, 13947, 1252, 1, 5514, 55], [147, 693, 3, 29, 687, 125, 1019, 1, 55], [3917, 4186, 227, 173, 2, 2944, 52, 301, 217, 118, 113, 170, 584, 825, 1297, 368, 37, 52, 63, 1866, 7, 30], [2862, 12, 1, 216], [2862, 12, 10, 1], [797, 30, 9], [797, 1767, 2304, 3796, 61, 37, 172, 332, 340, 1558, 172, 2993, 251], [797, 91, 22, 59, 6, 14, 246, 56, 1903, 264, 178], [797, 57, 4, 19, 582, 6, 2236, 8, 7661, 162, 200, 36, 61, 99, 475, 133, 1, 8, 1698, 36, 61, 346, 11, 13948], [115, 5657, 51, 4, 2511, 8, 23, 11, 966, 1, 13949, 21, 293, 2, 2501, 5658], [3549, 42, 7662, 42, 223, 44, 663, 86, 23, 2726, 10, 231, 13950, 4892, 163, 2745, 13951], [855, 13952, 436, 11, 7663, 12, 4, 710, 796, 187, 16, 32, 106, 250, 12, 96, 1576, 639, 11, 665], [544, 483, 185, 1, 96, 81, 45], [13953, 1488, 1467, 147, 1], [1656, 274, 5659, 263, 21, 2, 2366, 699, 16, 13954, 7664, 12, 33, 2, 322, 324, 21, 4850, 13955, 13956], [1656, 13957, 13958, 361, 139, 208, 202, 8, 569, 2307, 569, 1793, 5, 46, 43, 179, 5582], [1656, 7665, 5660, 648, 2, 83], [1656, 7666, 1, 51, 13959, 43, 68, 67, 6, 465, 59, 20, 395, 1068], [1656, 3423, 179, 19, 18, 4, 1036, 1117, 82, 17, 97, 62, 20, 310, 136, 3762, 166, 130, 5661, 310, 117], [1656, 183, 9, 139, 137, 332, 6, 28, 20, 330, 332, 6, 2197], [1656, 835, 29, 113, 17, 3, 75, 856, 38, 4, 101, 856, 5, 58, 12, 458, 20, 645, 8, 1448, 20, 30, 13, 2, 496, 236, 6, 1096, 5603], [1726, 3918, 27, 2, 315, 3071, 4955, 77, 8, 702, 7667, 388, 12, 48, 10, 1179, 16, 2, 501, 4204, 264], [2576, 1695, 21, 4, 2, 2914, 5421, 21, 60, 13960], [3662, 445, 9], [2643, 5439, 28, 6, 2079, 63, 19, 10, 368, 2161, 27, 32, 39, 13961], [13962, 3397, 4198, 925, 7668, 586, 7474, 26, 7475, 1892, 13963, 22, 12, 33, 2, 1304, 16, 60, 1288, 144, 3107, 13964], [1762, 203, 9, 204, 307, 3, 46, 297, 22, 209, 1144, 371, 36, 1020, 6920, 13965], [1762, 9, 14, 896, 2360], [1762, 25, 24, 37, 19, 240, 1762, 25, 30, 37, 4105, 240], [4246, 61, 6, 94, 7, 154, 1260, 16, 4, 673, 390], [13966, 1319], [7568, 2, 1], [13967, 1205, 49, 60, 1928], [998, 92, 5, 1, 30, 25, 31, 4, 786, 257, 263, 3, 103, 998, 10, 19, 798], [998, 22, 128, 3120, 7669, 8, 1968, 13968, 398, 670, 665, 82, 4, 199, 13969, 29, 453, 17, 205], [5289, 86, 52, 63, 139, 1603, 11], [384, 9, 14, 1702, 54, 10, 4551], [384, 9, 127, 22, 25, 54, 135, 19, 2690, 7670, 154, 849, 19, 202, 414, 26], [384, 153, 298, 137, 99, 705], [4984, 200, 84, 663, 1162, 11, 84, 154, 629, 177, 3, 300, 2779, 52, 137, 4, 45, 459, 7, 1, 124, 17, 11, 4, 629, 542, 6, 14, 2, 1854], [4978, 2891, 14, 1823, 6279, 481, 1, 92], [855, 9, 1482, 7671], [855, 2796, 9, 14, 11, 143, 193, 32, 4, 106, 3825, 3175], [1019, 1, 896, 13, 36, 334, 134, 147, 9, 2, 2553], [1019, 638, 18, 147, 4599, 13970], [1953, 2758, 27, 2, 56, 1023, 12, 96, 2278], [7672, 4, 1172, 355, 3315, 1101, 7132, 257, 212, 1586, 6354, 13971], [4452, 1388, 323, 13972, 10, 13973, 12, 4, 1937, 1, 13974], [2397, 4600, 1], [2397, 153, 34, 23, 93, 11, 4, 2], [13975, 13976, 2, 1], [765, 502, 143, 329, 153, 169], [765, 157, 263, 18, 13977, 1027, 765, 13978, 1, 347, 996, 147, 961], [765, 67, 6, 5662, 305, 455, 606, 3361, 13979, 3, 273, 384, 147, 103, 110, 626, 143, 207, 617, 423], [2695, 12, 1054, 35, 27, 60, 1, 74, 256, 149, 52, 48, 137, 13, 2695, 4578], [7673, 7673, 260, 717, 1188, 42, 1080, 1701, 523, 605, 2, 25, 1, 697, 43, 13980], [4527, 13981, 13982, 3919, 1239, 3824, 1616, 348, 1742], [138, 178, 70, 2, 1148, 1, 192, 359, 11], [138, 37, 141, 183, 9, 238, 258, 307], [200, 3, 33, 94, 2, 120, 1, 28, 735, 808, 50, 645, 123, 2, 381, 530, 19], [200, 4601, 33, 13983, 645, 13984, 2, 1, 82, 4, 503, 5663], [200, 416, 499, 915, 168, 6, 1191, 6, 4, 863, 3228, 77, 73, 13985, 3228, 5664, 74, 220, 588, 33, 1030, 144], [200, 52, 72, 4, 13986, 311, 74, 187], [200, 52, 72, 1441, 13987, 1], [200, 819, 13988, 33, 1191, 6, 1227, 73, 2, 3422], [200, 68, 16, 4, 796, 9, 224, 109, 33, 800, 7], [200, 4, 3920, 95, 33, 79, 7674, 2, 13989], [200, 22, 1, 109, 33, 191, 17, 58, 3, 44, 2, 5104, 6, 14, 11, 22, 1478, 288, 61, 6, 10, 5665, 120, 111, 33, 29, 396, 51, 1284], [200, 66, 33, 671, 237, 228, 27, 39, 9, 18, 4, 1602, 219, 415, 37, 34, 66, 29, 64, 240, 205], [200, 5, 32, 465, 22, 388, 217, 198, 229, 170, 71, 25, 2833], [200, 5, 1043, 1, 114, 10, 7675, 853, 873], [210, 28, 6, 167, 4, 699, 225, 34, 7196, 3245, 250, 184, 11, 4, 561], [210, 62, 13990, 124, 13991, 1], [309, 1547, 1, 267, 350, 20, 4, 13992, 9, 16, 32, 106, 26], [2093, 652, 21, 13993, 1, 14, 5666, 705, 82, 119, 13994, 8, 45], [511, 808, 6468, 8, 13995, 10, 2730], [4602, 4602, 4602, 439, 7676, 160, 13996], [7677, 11, 2510, 2300, 453, 20, 624, 9, 7678, 251, 7194, 505], [537, 9], [537, 429, 18, 4, 5667, 1, 537, 11, 15], [325, 14, 68, 643, 1], [325, 1, 2, 3756, 4311, 17, 677, 13, 325, 55, 26, 50, 2022, 13997, 369], [325, 1, 2613, 17, 91, 19, 42], [325, 1, 123, 10, 234, 8, 151, 105, 14, 7679], [325, 1, 41, 39, 13998, 3921], [325, 1383, 328, 1318, 325, 153, 163, 2, 496, 16, 84, 2537, 134, 3817, 233], [325, 9, 41, 1158, 13999, 1359], [325, 9, 407, 325, 5668, 18, 3922, 1683], [325, 153, 363, 11, 18, 147, 296, 176, 14000], [325, 153, 564], [325, 4603, 51, 143, 1069, 2539, 3882, 14001, 84, 1, 53, 1, 69, 1138, 1863, 498, 125, 2, 4603, 163, 2, 5669, 14002, 4579, 35, 1, 383, 242, 4, 1481, 35, 55], [325, 25, 65, 144], [1570, 14003, 306, 33, 1048, 17, 2, 1245, 158, 26], [5670, 150, 4368, 82, 4487, 1057, 3670, 4487, 3923, 6, 1120, 3314, 6, 14004, 126, 377, 14005, 14006], [2335, 5671, 2, 902, 26, 14007, 21, 2, 1013, 21, 2830, 7, 1, 1049, 2, 93, 937, 18, 50, 183, 30, 2675], [2335, 5671, 12, 144], [1138, 137, 27, 80, 77, 548, 7, 85, 50, 24, 116, 21, 26], [58, 73, 3, 72, 1709, 523, 14008, 1137, 9], [58, 95, 44, 5471, 71, 58, 36, 2832, 547, 17, 23, 98, 2008, 69, 317, 62, 71, 978, 352, 197], [58, 77, 255, 5672, 96, 218, 3, 44, 109, 342, 858, 6372, 5672, 82, 3499, 1564, 12, 7, 110, 422, 6, 255], [58, 39, 1178, 70, 10, 187, 65, 203], [58, 66, 64, 39, 9], [58, 78, 375, 38, 186, 424, 423, 14009, 536, 211, 890, 524, 291, 35, 27, 50, 128, 185, 1], [58, 5, 182, 65, 14010, 8, 14, 13, 2079, 187, 14, 14011], [58, 5, 772, 17, 6, 14, 342, 27, 5, 241, 286, 988, 23, 48, 2, 1, 342, 28, 5, 3041, 11, 2, 3924, 2, 575, 604, 4232], [58, 5, 44, 2, 5673, 57, 12, 15, 7680, 7680, 7563, 14012, 1430, 1430, 3833, 2528, 1430, 1286, 5255, 14013], [58, 5, 62, 162, 3, 2430, 35, 4794], [58, 5, 109, 442, 111, 3157, 82, 673, 48, 3704, 23, 2066, 2413, 27, 4, 7382, 16, 91, 34, 188], [58, 20, 138, 662, 702, 58, 15, 5261, 6, 8, 3269, 63, 5, 1469, 15, 11, 2, 14014, 63, 5, 741, 15, 11, 2, 9], [277, 7681, 44, 5674, 18, 50, 24, 99], [277, 15, 2361, 621, 499, 7, 4, 1260, 16, 4, 673, 1747, 70, 43, 1237], [381, 3, 86, 15, 2, 25, 391, 3, 47, 454, 4, 199, 12, 4, 395, 7, 751, 43, 1764, 1674, 2, 1693, 74, 275], [58, 50, 1162, 21, 5, 2204, 7, 112, 1], [5434, 79, 17, 1, 177], [7612, 14015, 2720, 7004, 7682, 2443, 14016, 903, 120, 56, 6898, 3, 1273, 20, 14017, 33, 1146], [29, 442, 3540, 14018, 3008, 3150, 2961, 12, 434, 1199, 21, 1108, 160, 341, 1211], [29, 14019, 17, 5, 1], [29, 3424, 14020, 1680, 8, 14021, 14022, 3809, 519, 1209, 3360, 74, 2, 87, 21, 6974, 74, 485, 40, 33, 2, 1], [29, 208, 32, 933, 1, 14023, 7, 562], [29, 14, 2, 291, 9, 90, 18, 2, 1135, 7683], [29, 14, 2, 902, 1730, 20, 2502, 14024, 5, 131, 14, 2, 590, 120, 1, 51, 4, 4604, 27, 445, 260, 14025, 40, 1302, 7684], [29, 14, 2, 141, 1, 74, 151, 58, 22, 6, 6884], [29, 14, 2, 285], [29, 14, 902, 3, 14026, 27, 25, 8, 1, 1944, 88, 5, 37, 26, 26, 26], [29, 14, 214, 149, 80, 1, 2797], [29, 14, 214, 149, 80, 1, 2797, 8, 3, 157, 50, 30, 11, 4, 14027, 3209], [29, 14, 43, 1, 26, 48, 569, 38, 3, 5675, 2, 1565, 14028], [29, 14, 168, 1022, 9, 7, 1133], [29, 924, 17, 924, 97, 1, 75, 547, 40, 67, 2, 25], [29, 316, 147, 1205, 30, 153, 657, 17], [29, 2515, 630, 125, 10, 14029, 27, 166, 283], [29, 856, 14030, 15, 56, 33, 13, 20, 4605], [29, 182, 14, 1811, 16, 69, 5, 49, 650, 20, 2, 282], [29, 182, 605, 4, 166, 77, 11, 2, 7685, 29, 1420, 7, 9, 553, 16, 7], [29, 253, 4, 4292, 36, 4063, 374, 56, 36, 4063, 219, 92, 65, 51, 76], [29, 810, 125, 1894, 218, 52, 2, 1, 163, 440, 819], [29, 19, 5676, 43, 260, 30, 1, 11, 4, 324, 16, 7686, 55], [29, 19, 27, 77, 7, 255, 1493], [29, 1181, 1339, 9, 5, 318, 430, 7687], [29, 28, 2, 663, 764, 83, 23, 48, 59, 6, 4606, 385], [29, 28, 80, 1, 30, 204, 11, 154, 3780, 260], [29, 28, 20, 455, 1, 8, 234, 1, 1075, 116, 2, 180, 5132], [29, 167, 17, 35, 81, 133, 1472, 7, 1, 793, 80, 14031, 28, 80, 30, 557], [29, 1105, 3040, 3, 195, 14032, 8, 14033, 38, 15, 107, 6, 1, 974, 307], [29, 605, 39, 9, 11, 4, 2747, 650, 5, 44, 1836], [29, 62, 43, 183, 1, 29, 62, 43, 291, 956, 29, 62, 43, 1431, 25], [29, 100, 4, 9, 308, 6, 5], [29, 100, 4, 863, 16, 4, 831, 227, 5, 173, 2, 282], [29, 100, 22, 905, 343, 279, 45, 902, 350, 60, 16, 5, 9, 87, 2, 14034], [29, 468, 376, 133, 39, 1, 426, 36, 107, 8, 61], [29, 64, 39, 9, 29, 2110, 18, 1], [29, 64, 80, 1, 33, 19, 80, 1, 38, 3, 41, 106, 6, 58, 15], [29, 70, 17, 70, 5, 616, 11, 64, 27, 2, 3505, 13, 17], [29, 70, 17, 114, 80, 1, 25], [29, 453, 202, 14035, 158], [29, 453, 7, 1347, 49, 152, 14, 223, 727, 2515, 59, 4, 763, 16, 5291, 3925, 493], [29, 43, 25, 67, 98, 14036, 1, 188, 100, 17, 3383, 7038, 48, 68], [29, 137, 27, 10, 14037, 3, 146, 70, 60, 14038, 14039, 38, 3, 28, 4607, 7, 9, 103, 44, 5, 14040], [29, 157, 99, 209, 4438, 173, 39, 1, 31, 5, 46, 525, 553, 895, 134, 76, 1314, 57, 36, 134, 5], [29, 109, 279, 31, 2, 1938, 202, 120, 190, 74, 14041, 31, 52, 12, 93, 52, 12, 1639], [29, 1411, 17, 410, 10, 226, 37, 3, 43, 15, 112, 183, 1], [29, 81, 59, 3600, 444, 5, 428, 58, 254, 2855, 14042, 111, 44, 2, 540, 6, 382, 4, 2429], [29, 81, 6, 50, 13, 760, 3, 200, 2, 1785, 21, 14043, 1893, 2607, 8, 380, 57, 5, 510, 503, 2299], [29, 113, 17, 3412, 7688, 165, 130, 7621, 1285, 1609, 56, 30, 776, 1066], [29, 313, 17, 4, 24, 100, 17, 107, 28, 15], [29, 881, 17, 1, 23, 6355], [29, 881, 43, 1339, 9, 5, 318, 430, 7687], [29, 302, 2, 1, 69, 1574, 14044, 12, 1499, 1724], [29, 302, 39, 9], [29, 122, 8, 349, 7, 365, 228, 45, 18, 17, 83], [29, 475, 59, 4, 1, 3, 168, 6, 19, 14045], [29, 475, 133, 17, 3, 41, 15, 32, 14046, 83, 453, 20, 624, 271, 11, 20, 3496, 1], [29, 5, 90, 7, 171, 30, 768, 7, 416, 168, 38, 36, 122, 6, 382, 256, 5, 121], [29, 5, 90, 38, 217, 5, 279, 59, 12, 438, 2, 9, 34, 36, 266, 477, 6, 5], [328, 21, 4, 232], [29, 442, 76, 319], [29, 182, 109, 81, 59, 20, 2768, 6, 20, 177, 7, 25, 318, 33, 227, 224, 8, 114, 7, 24], [29, 19, 125, 291, 1], [29, 5, 81, 38, 23, 81, 5, 165, 3765, 15, 9], [14047, 120, 14048, 74, 3926, 21, 4, 2630, 16, 4, 3311, 70, 76, 2, 433, 6, 307, 120, 508, 776], [957, 1216, 354, 1151, 72], [957, 4301, 8, 571, 14, 2293, 9, 2293, 9], [957, 35, 18, 7, 665, 1], [14049, 1920, 56], [142, 6, 430, 2, 481, 1], [1122, 467, 178, 901, 2, 828, 2026, 5, 94, 2, 202, 414, 3731], [898, 14050, 292, 2396, 2598, 226, 2, 992, 7, 1628, 16, 111, 14051, 5, 86, 12, 56], [898, 28, 4, 1], [898, 2205, 1655, 990, 1290, 3900, 161, 3610, 890, 524, 1, 2910, 18, 186, 14052, 28, 692, 102, 5677, 480, 682, 114, 14053], [898, 47, 751, 7, 45, 37, 1, 118, 303, 14054, 357, 110, 375, 7, 1623], [651, 401, 21, 2, 7127, 472, 35, 13, 2038, 3018, 8, 1420, 265, 32, 115], [651, 3, 47, 119, 2, 348, 8, 192, 14055, 8, 1025, 35, 603, 3927, 531, 6, 4399, 225, 12, 2, 14056], [651, 16, 4, 24, 7, 3, 1705, 18, 14057, 14058], [472, 13, 2, 9, 23, 784, 51, 5, 13, 2, 9, 33, 13, 245, 166, 14059, 627, 3072], [472, 13, 20, 152, 94, 7, 1, 5, 90, 744], [472, 758, 6682, 1708, 3224, 232, 1100, 92, 7, 2916, 1008], [467, 35, 1], [467, 14060, 39, 1, 49, 559, 14061, 26], [467, 14062, 288, 194, 1693, 2087, 1235, 1, 18, 3928, 413, 320, 16, 1431, 61, 962], [467, 14063, 2, 14064, 2289, 8, 137, 616, 54, 95, 736], [14065, 12, 7, 153, 128], [484, 4, 14066, 160, 718, 1878, 8, 1284], [405, 544, 2476, 2, 1, 46, 309, 21, 2, 25], [405, 544, 2476, 34, 4, 1, 46, 309, 21, 2, 25], [405, 50, 102, 147, 1, 2, 14, 294, 31, 3, 2151, 14067], [405, 15, 142, 21, 2, 145], [405, 32, 10, 9, 21, 4460, 34, 47, 7, 2, 93, 2496, 258, 54, 18, 4, 244, 1510, 16, 14068], [405, 32, 10, 9, 555, 18, 100, 17, 479, 39, 1, 108, 35, 2, 25, 47, 1465, 8, 5678], [14069, 27, 9, 361, 146, 44, 4, 14070, 496, 1269], [551, 3929, 27, 10, 743, 482, 1, 1904], [14071, 14072, 39, 14073, 866, 344, 3909, 22, 9, 18, 60, 166, 45, 280, 3, 41, 453, 19, 13, 38, 202, 14074, 3860], [252, 3, 197, 27, 12, 37, 285], [252, 259, 244, 6, 17, 14, 167, 60, 183, 30, 9, 41, 148], [252, 121, 14075, 1, 3, 424, 2, 413, 1966, 230, 10, 14076, 5679], [252, 121, 684, 3930, 1127, 1601, 781, 18, 2686, 144, 99, 55], [252, 47, 2041, 296, 29, 62, 85, 416, 90, 14077, 140, 374, 56, 7, 6321], [252, 85, 58, 3, 44, 6, 14, 270, 2, 812, 13, 23, 3890], [252, 12, 79, 1, 54, 440, 8, 117, 225], [252, 2, 104, 6438], [252, 44, 437, 5427, 352, 14078, 1, 28, 436, 14079, 75, 176, 2, 1564, 31, 20, 7689, 14080], [252, 204, 17, 27, 7, 296, 452, 780, 27, 5680, 1754, 31, 40, 46, 44, 2840, 289, 297, 4, 9, 78, 14, 167, 28, 112], [252, 415, 33, 86, 119, 24, 12, 249, 18, 24, 767], [252, 5507, 3775, 6, 14, 260, 803, 8, 14081, 1930, 14, 2, 1544, 74, 48, 32, 129, 60, 24, 7690], [252, 271, 122, 6, 167, 18, 217, 499, 1, 62, 36, 330, 3073], [6652, 1274, 1096, 14082, 620, 264, 12, 625], [171, 30, 1], [171, 30, 1, 3, 300], [171, 30, 365, 1, 1133, 45, 81, 214, 45, 59, 922, 166, 8, 108, 6, 237, 228, 128], [171, 30, 9], [171, 30, 1607, 28, 941, 11, 2, 1055, 14083], [171, 1], [171, 1, 29, 62, 50, 207], [171, 1], [171, 1, 338, 17, 771], [171, 1, 49, 68, 184, 3622, 105, 671, 7691], [171, 1, 7, 86, 14084, 72, 14085], [171, 187], [171, 141, 1383, 420, 4, 19, 1738, 1], [171, 399], [3239, 14086, 418, 7, 366, 49, 248, 43, 11, 14087, 43, 14088], [2507, 2505, 124, 17, 661, 16, 7, 183, 379, 9], [391, 1, 204, 17, 1265, 36, 109, 41, 9, 55], [391, 4372, 14, 11, 4, 1403, 331, 238, 2359, 32, 4, 24, 321, 321], [14089, 7692, 5681, 8, 718, 3, 44, 2, 14090, 7692, 14091, 5681, 8, 14092, 27, 14093, 1634, 7, 510, 102, 2, 14094], [14095, 3, 486, 22, 14096, 14097, 14098, 14099, 8, 47, 13, 60, 1, 226, 1386, 14100, 1796, 10, 169], [14101, 4, 201, 494, 51, 3931, 55], [14102, 131, 14, 1486, 1620, 1, 37, 1758], [2798, 176, 2010, 39, 391, 1, 8, 315, 1840, 25, 6, 81, 1201], [1459, 377, 3102, 8, 1012, 14103, 8, 893, 6, 7693, 2252, 1714, 8, 1205, 527], [1935, 408, 103, 156, 14, 589, 104], [1935, 19, 224, 26, 468, 1627, 14, 204, 4, 353, 51, 4, 7694, 967, 1737], [1935, 19, 56], [570, 95, 430, 4, 1329], [570, 95, 430, 4, 1329], [570, 95, 28, 4, 5682], [570, 95, 28, 4, 1329, 34, 4, 710, 3018, 28, 4, 873], [570, 95, 28, 4, 1329, 117, 293, 3, 28, 2, 401, 738, 211, 225], [570, 95, 28, 4, 1329], [570, 95, 28, 4, 1329], [570, 95, 28, 4, 14104], [570, 561, 828, 73, 2, 7695, 21, 597, 35, 8, 114, 4, 56, 54], [570, 1329, 28, 4, 95], [1016, 14105, 172, 104, 32, 464, 3, 119, 10, 1255, 18, 4, 1540, 7696], [1016, 1, 71, 5683, 40, 47, 10, 77], [1016, 24, 317, 4608, 17], [119, 2, 138, 1], [119, 50, 24, 38, 40, 214, 119, 50, 24, 38, 40, 611, 119, 50, 24, 38, 40, 376, 119, 50, 24, 38, 40, 1808, 119, 50, 24], [119, 10, 138, 1], [119, 37, 209, 24, 7, 10, 3074, 1106], [119, 7, 24, 13, 587, 14106], [119, 7, 24, 13, 3, 41, 4, 5573], [119, 4, 24, 13], [119, 20, 3223, 74, 604, 632, 35, 6, 14, 2, 24], [119, 348, 8, 88, 61, 6, 4, 14107, 552], [119, 24, 12, 501], [119, 24, 18, 503, 16, 10, 5566], [5684, 32, 22, 24, 23, 7464, 6, 28, 3932], [1206, 372, 13, 2, 689, 9], [7697, 523, 4, 1433, 280, 96, 298, 184, 26, 101, 2, 6699, 2058, 7698, 43, 14108, 16, 384, 464], [2997, 1, 71, 59, 5, 475, 59, 20, 373, 7311, 809, 65, 13, 5, 87, 6, 3744, 14109, 82, 14, 2, 6820, 1], [519, 78, 25, 33, 625, 356, 74, 40, 33, 238, 9, 224, 4, 572, 34, 5, 4230], [5685, 12, 2, 185, 9], [5685, 12, 14110, 282], [14111, 12, 1, 8, 13, 287], [4573, 254, 64, 254, 788, 22, 1143, 16, 588, 7699, 591, 207, 3791, 102, 8, 70, 2, 7700], [14112, 9], [1217, 30, 399], [14113, 34, 36, 109, 56, 37, 553, 435, 71, 239, 14114, 8, 1756, 58, 78, 44, 18, 860, 785, 2192, 264], [2548, 3288, 32, 224, 22, 83], [934, 6370, 102, 1683, 27, 305, 1803, 8, 536, 263, 54, 51, 5602, 4917, 348, 4112, 26, 127], [934, 10, 2818, 33, 697, 21, 17, 10, 2799, 1538, 8, 269, 254], [934, 4, 14115, 16, 725, 14116, 159, 1908, 2052, 11, 268, 16, 4, 1058, 1510, 3, 44, 14117], [3232, 2038, 106, 14118, 268, 8, 2, 470, 435, 288, 3, 14119, 1118, 372, 127, 13, 254], [5131, 37, 1773, 40, 1580, 133, 7701, 30, 14120, 119, 50, 2741, 583, 52, 174, 260, 803, 171, 1, 23, 362, 42, 502, 52, 3817, 73, 219], [14121, 238, 19, 4, 244, 25, 1, 48, 4086, 84, 1, 12, 4, 244, 25, 1], [14122, 38, 1, 49, 211, 10, 3521, 156, 1617, 956, 3, 216, 170, 479, 246, 183, 25, 6, 157, 18, 4609], [1047, 384, 14123, 153, 147, 45, 47, 4445], [1047, 7, 2076, 187, 7, 294, 59, 5686, 32, 4, 106, 55, 2517, 7702, 7, 45, 5, 49, 473, 1735, 19, 1284, 1686, 10, 1400, 5418], [3933, 14124, 770, 247, 120, 56, 1795, 527, 22, 12, 1943], [14125, 2594, 125, 17, 66, 258, 2, 83, 44, 2, 1992], [14126, 303, 17, 3607, 3, 103, 119, 20, 24, 634, 4, 3642, 5687], [110, 7703, 95, 13, 4, 1216], [110, 1, 27, 89, 764, 3909, 6, 305, 14127, 36, 314, 14128], [110, 4610, 7704, 14129, 51, 10, 1, 331], [110, 1132, 49, 14130, 123, 159, 2244, 708, 4, 1755, 108, 3393, 160, 341, 1211], [110, 10, 306, 62, 3, 29, 19, 27, 179, 111], [110, 4, 95, 86, 22, 597, 35, 570, 184, 12, 14131], [110, 4, 379, 1754, 49, 9, 55], [110, 39, 322, 1, 214, 653, 7705, 31, 7, 610, 327, 29, 28, 7706, 64, 15, 28], [110, 36, 62, 5, 10, 1], [110, 464, 161, 1441, 451, 136, 227, 173, 56, 43, 7707, 8, 3, 195, 48, 2, 1044, 14, 103, 156, 14, 10, 14132], [182, 338, 17, 224, 80, 1, 8, 272, 28, 50, 1771], [182, 429, 2, 558, 16, 1499, 8, 7, 1, 912, 458, 18, 4, 450, 231, 4, 172, 1352], [155, 4611, 521, 136, 7, 589, 187, 69, 1342, 474, 6, 1227, 33, 426, 40, 136, 1299, 8, 50, 915, 41, 2285], [155, 1, 7, 64, 1689, 1024, 11, 14133], [155, 1, 47, 1348, 6, 421, 2, 91], [155, 2220, 18, 12, 248, 8, 374, 56, 18, 5129, 31, 5, 29, 28, 7, 5, 29, 28, 4, 5284], [155, 418, 72, 7, 40, 2, 89, 83], [155, 115, 3, 597, 35, 14134, 85, 3, 33, 2210, 2, 1731, 82, 2, 284, 83], [155, 93, 761, 192, 102, 27, 2236, 22, 14135, 55], [155, 1479, 11, 198, 14, 4407, 74, 5688], [155, 3934, 670, 11, 770, 12, 122, 6, 999, 120, 2282], [155, 25, 63, 70, 2, 275, 208, 13, 2, 83], [155, 25, 238, 19, 4, 244, 25, 1, 34, 48, 62, 84, 1, 12, 4, 244, 25, 1], [155, 25, 238, 19, 4, 244, 25, 1, 48, 62, 84, 1, 12, 4, 244, 25, 1], [155, 25, 1174, 948, 4, 244, 25, 1, 48, 62, 84, 1, 12, 4, 244, 25, 1], [155, 68, 16, 88, 118, 33, 14, 1401, 17, 6, 126, 3526, 16, 9], [155, 24, 4, 199, 34, 3, 150, 13, 3, 46, 28, 602], [155, 112, 153, 87, 2, 112, 1], [155, 1650, 11, 198, 14, 14136, 212, 2757, 44, 43, 117, 6, 14, 1184, 14137, 198, 14, 14138], [155, 1282, 670, 11, 136, 999, 74, 136, 299, 59, 999, 2, 120, 2013, 7, 85, 212, 3934, 28, 401, 73, 14139], [155, 1282, 670, 11, 12, 334, 6, 4], [155, 1282, 670, 198, 14, 5688, 212, 1072, 101, 41, 126, 401, 6, 28, 110, 34, 120, 111, 105, 200, 393, 6, 980], [155, 106, 3, 19, 3, 146, 167, 17, 577, 13, 268, 2365], [155, 106, 3, 137, 2, 14140, 178, 8, 465, 4, 14141, 14142, 3, 86, 16, 2, 14143, 2319, 2605, 80, 80, 28, 14144], [155, 106, 23, 448, 35, 168, 10, 310, 2, 7708, 4612, 131, 626, 17, 1], [155, 106, 10, 306, 79, 17, 15, 6, 1, 51, 17, 59, 256, 55], [326, 326, 326, 326, 400, 80, 1, 30, 142, 8, 477, 6, 22, 573, 3289, 273, 123, 2598, 2599, 694, 1780], [326, 47, 133, 6, 19, 2, 203, 1], [326, 19, 326, 1, 326, 27, 4, 45, 14145, 164], [326, 41, 1797, 1, 8, 1797, 347], [326, 41, 60, 6, 72, 326, 90, 31, 5, 191, 17, 155, 1, 315], [326, 12, 14, 2, 1, 51, 10, 331], [326, 64, 1616, 348, 34, 3, 316, 2350, 4396, 7643, 6, 2, 460, 5561, 23, 4, 6532], [326, 7, 96, 18, 1126, 179, 74, 554, 7091], [744, 3, 597, 35, 3, 41, 2, 511, 1], [744, 3, 597, 35, 1120, 85, 3, 33, 2210, 2, 1731, 82, 2, 284, 83], [416, 87, 6, 139, 2450, 59, 14146, 20, 125, 4, 215, 449, 16, 1519, 82, 4, 2387, 781, 6, 255, 2, 232, 2134], [416, 79, 17, 14147, 36, 14, 13, 241, 1287, 340, 8, 3, 14, 13, 1287, 10, 145], [416, 12, 81, 59, 1103, 1297, 74, 4, 768, 8, 23, 33, 135, 119, 853, 1207, 54, 16, 4613], [416, 13, 1893, 307, 22, 17, 12, 2, 285, 19, 14148], [416, 1442, 51, 17, 13, 57, 22, 1, 58, 135], [416, 113, 17, 4, 5539, 199, 184, 34, 3, 266, 477, 490], [416, 7, 72, 12, 2, 3206], [416, 86, 7, 23, 48, 4, 395, 18, 10, 6516, 13, 65, 51, 10, 14149, 3, 29, 7709, 13, 3, 207, 10, 343, 57, 2, 180, 511], [416, 35, 3407, 12, 28, 554, 23, 721, 10, 1, 30, 420, 142, 135], [474, 29, 655, 2, 14150, 37, 29, 86, 140, 5, 58, 256, 7, 23, 14151, 1, 23, 4931, 18, 169, 48, 20, 611, 30], [2026, 3, 656, 4, 712, 10, 306, 113, 17, 1378, 1, 12, 107, 129, 22, 14152, 128, 57, 2, 138], [2026, 3, 19, 3, 146, 167, 17, 51, 577, 268, 1], [2026, 3, 61, 54, 3, 46, 105, 125, 43, 154, 1], [1666, 5, 65, 32, 5, 94, 12, 837, 14153, 180, 14154, 11, 2, 969, 4614], [2320, 3, 90, 38, 590, 30, 9, 448, 3336, 2744, 2584, 1], [2320, 369, 55, 2642, 7710, 1, 784, 315, 21, 22, 26], [14155, 1, 5, 65, 13, 98, 14156], [2584, 1], [1030, 3, 168, 6, 14, 889, 2011, 8, 92, 23, 14157, 4615], [1030, 147, 5689, 2461, 3, 86, 32, 384, 9, 18, 4972, 14158, 62, 3, 63, 167, 32, 16, 240, 99], [919, 17, 135, 20, 3935, 3, 592, 15, 11, 10, 624, 282], [3075, 300, 36, 63, 58, 165, 88, 5, 94, 126, 244, 1, 2059], [1924, 3039, 791, 414, 69, 64, 341, 310, 352, 27, 5690, 63, 5, 28, 17, 102, 160, 2783], [1924, 3039, 791, 414, 69, 64, 341, 310, 352, 27, 5690, 63, 5, 28, 17, 102, 160, 2783], [1924, 3039, 791, 414, 69, 64, 341, 310, 352, 27, 5690, 63, 5, 28, 17, 102, 160, 2783], [1037, 332, 21, 39, 319], [1256, 35, 8, 142, 13, 1842, 606, 14159, 78, 1, 1060, 27, 3936], [5691, 136, 132, 2447, 68, 16, 5692, 884, 14160, 2023, 5691, 47, 1639, 34, 4, 1119, 2023, 1814, 12, 92, 11, 4, 248], [19, 49, 5, 533, 59, 15, 13, 4, 189, 7, 191, 21, 20, 518, 8, 88, 72, 5, 183, 8, 2, 1, 38, 5, 72, 43], [19, 5, 53, 66, 44, 78, 104, 244, 53], [19, 5, 20, 2, 19, 2, 4536, 864, 16, 248], [19, 294, 102, 11, 4, 4440], [4616, 18, 186, 26, 41, 23, 147, 3870], [231, 101, 80, 1, 222, 64], [1126, 12, 21, 181], [1126, 12, 21, 4, 14161, 129, 15], [488, 63, 14, 2, 1, 3937], [1941, 300, 6, 274, 23, 14162, 10, 1, 2342, 124, 50, 7711, 389, 4, 5626], [104, 30, 1, 25], [1219, 2381, 1100, 160, 351, 7712, 4617, 21, 1388, 8, 2008, 51], [1219, 2381, 360, 128], [365, 30, 9, 32, 224], [365, 30, 1225, 7, 85, 3, 29, 44, 43, 538, 21, 2165, 3425, 30, 1, 99], [365, 153, 46, 750, 381, 36, 117, 11, 97, 231], [365, 1169, 2, 9, 63, 42, 380, 57, 3, 47, 2287, 20, 923, 1980, 26], [616, 11, 7, 24, 13, 705, 2955], [2784, 192, 1], [3849, 113, 1, 20, 14163, 37, 5, 63, 167, 240, 1744, 14164], [1303, 287, 14, 4, 796, 319], [2554, 1916, 58, 37, 56, 964], [203, 7713, 7, 145], [203, 30, 9, 555, 35, 4, 4618], [203, 30, 4299, 388, 13, 4619, 14165, 49, 1871, 7, 49, 61, 14166, 3, 196, 65, 51, 7, 414, 3, 118, 90, 6, 14, 50, 14167], [203, 1], [203, 1, 186, 226, 14, 53, 14168, 53, 695], [203, 1, 41, 4, 247, 406], [203, 1, 87, 64, 99, 151, 19, 240], [203, 19, 1746, 530, 30, 9], [203, 9, 18, 186, 79, 943, 3938, 1, 5, 46, 43, 148, 3938, 5, 2, 148, 279, 5693], [7714, 3370, 7715, 29, 13, 1438, 7716, 7717, 529, 7718, 2707, 4122, 519], [7714, 3370, 7715, 29, 13, 1438, 7716, 7717, 529, 7719, 660, 7718, 2707, 4122, 519], [1481, 384, 206, 4620, 43, 957, 14169], [1293, 43, 1], [1293, 4, 494], [5030, 1494, 47, 2, 1665, 644, 115, 21, 4, 324, 104, 1302], [1599, 500, 60, 112, 9, 177], [14170, 3939, 14171, 187], [150, 13, 2, 1, 21, 79, 4, 670, 18, 111, 34, 278, 516, 22, 1, 61, 6, 865, 88, 217, 28, 167, 123, 2, 2909, 882, 14172], [150, 13, 3, 46, 200, 22, 11, 2, 288, 100, 17, 1097, 35, 119, 7, 24, 21, 2, 470, 98, 755, 41, 50, 784, 879], [1596, 13, 3, 63, 44, 245, 1, 3, 2197, 1596, 13, 32, 39, 9, 11, 22, 1, 67, 307], [976, 1922, 8, 1025, 35, 6, 60, 804, 30, 1442, 51, 307, 57, 105, 297, 2, 918, 376, 230], [275, 377, 3933, 26, 732, 4621, 2744, 160, 852, 21, 770, 527], [275, 208, 13, 36, 105, 297, 2, 153, 69, 878, 36, 265, 233, 4, 2522, 70, 17, 528, 155, 106], [275, 156, 238, 70, 2, 25, 150, 89, 59, 60, 45, 13, 1, 272, 366, 22, 441, 8, 14, 243, 32, 115], [275, 14, 148, 1196, 927, 454, 85, 153, 383, 131, 1156, 55], [275, 105, 594, 7, 189, 29, 134, 483, 59, 275, 7, 36, 29, 13, 13, 980, 139, 1070, 52, 29, 62, 7, 9], [275, 37, 537, 280, 112, 81, 5, 146, 137, 39, 1, 92, 115, 140, 31, 5, 29, 36, 96, 152, 58, 15, 6, 5], [275, 81, 142, 18, 153, 38, 3, 63, 446, 54, 2, 607, 275, 69, 14, 18, 7, 1011], [275, 168, 2624, 2031, 3764, 707, 73, 98, 919, 6, 14, 2, 9, 18, 685, 2555, 251, 62, 148, 219, 36, 62, 295, 59, 7, 385], [3746, 1274, 2, 83], [7720, 11, 22, 1], [5583, 1812, 1, 15, 2, 454, 2432], [607, 610, 13, 2, 1, 300, 147, 40, 18], [290, 17, 984, 218, 374, 56, 71, 239, 14173, 1901, 381, 200, 5, 748, 225], [290, 17, 913, 9], [290, 17, 5, 7721, 1, 53, 151, 290, 621], [290, 264, 390, 61, 14174, 737, 7, 14175, 187, 142, 11, 580, 16, 14176], [290, 18, 4, 1213, 12, 13, 3426, 11, 4, 1101, 3352, 110, 31, 5, 404, 20, 96, 726], [1244, 32, 143, 3276, 13, 6, 94, 10, 730, 4123], [679, 108, 747, 4, 741, 1550, 17, 1], [679, 328, 14177, 382, 14178], [679, 41, 98, 1588, 327, 27, 1647, 1919, 207], [679, 41, 10, 7722, 8, 353], [679, 298, 4, 178, 8, 326, 1070, 92, 34, 432, 134, 2, 19, 3, 41, 126, 1, 5316, 615], [258, 7723, 51, 5412, 1], [258, 2, 180, 971, 1, 1504, 8, 28, 10, 879, 605], [258, 50, 30, 8, 842, 50, 142, 60, 2458, 123, 5694, 313, 60, 591, 18, 4, 5665, 385, 543, 2, 83], [258, 2113, 14179, 18, 6904, 34, 36, 32, 87, 2, 154, 718], [595, 151, 1385, 21, 98, 354, 5695], [595, 30, 203, 836], [595, 418, 3231, 856, 156, 56], [595, 9, 101], [1056, 14180, 8, 96, 90, 4, 2696, 14181, 21, 404, 11, 7724, 232, 1521, 124, 7], [556, 443, 10, 215, 175, 37, 153, 103, 636, 3, 132, 724, 1287], [556, 28, 14182, 149, 1, 11, 107, 51, 17, 329], [739, 83], [14183, 136, 227, 82, 2, 431, 2267, 3, 168, 6, 14, 5201, 14184, 2, 467, 21, 24, 823, 252, 69, 465, 15, 11, 2, 3037], [250, 2582, 237, 8, 14185, 232, 178, 182], [250, 418, 6, 316, 17, 60, 14186, 82, 3328, 331, 117, 92, 103, 28, 50, 24, 672], [250, 178, 250, 2833, 147, 63, 19, 10, 1], [250, 1280, 16, 4, 264], [250, 1250, 489, 56, 479, 35, 27, 4, 1554], [250, 16, 32, 5, 10, 409, 16, 1], [250, 102, 19, 20, 1, 26, 4, 3076, 5, 708], [250, 4, 120, 1, 131, 191, 1037, 938, 26, 2355, 26, 14, 2, 161, 1, 59, 474, 27, 50, 703, 30], [250, 184, 3, 58, 38, 3, 167, 4, 7725, 12, 303, 268, 203, 1, 8, 194, 50, 119, 398, 11, 68, 400], [250, 184, 40, 125, 97, 244, 691, 40, 641, 97, 13, 7, 9, 82, 4, 4893], [1023, 14187, 1882, 76, 1, 118, 14, 1744, 73, 2384], [14188, 12, 56, 321], [3610, 2, 413, 9, 2473, 94, 118, 16, 132, 294], [14189, 95, 372, 14190, 649, 151, 33, 741, 6, 194, 1622, 14191], [1736, 1, 14192, 5141, 66, 264, 73, 219, 14, 137, 641, 4, 1736, 45], [3216, 104, 7, 5696, 654, 71, 36, 67, 474, 402, 6, 7726, 13, 19, 5, 252, 28, 102, 20, 1529, 30, 8, 58, 256], [567, 95, 661, 16, 1470, 372, 4344], [567, 95, 12, 152, 14, 4, 989, 16, 17], [567, 95, 18, 14193], [567, 95, 1040, 17, 54], [14194, 169, 34, 97, 1, 1574, 48, 7399], [3058, 283, 3058, 1, 3648], [1861, 82, 14195, 198, 33, 14, 14196, 6, 14197, 201, 95, 378, 4215], [788, 108, 8, 5697, 808, 1408, 1519, 8, 4, 14198, 14199, 1370, 73, 4, 154, 1648, 2523], [14200, 12, 2, 89, 1], [4494, 95, 5610, 129, 135, 114, 211, 84, 2580, 1103], [2985, 333, 2470, 17, 82, 14201, 73, 3, 241, 37, 301, 22, 1, 118, 1867, 2843, 19, 35, 37, 3, 63, 7727, 18, 10, 2818], [14202, 12, 2, 144, 2067, 12, 79, 2, 260, 14203, 228, 8, 605, 170, 260, 14204, 103, 204, 5, 91], [635, 73, 2, 1, 18, 14205, 3705], [635, 153, 43, 7728], [14206, 1259, 14207, 11, 1914, 7244, 74, 3116, 1259, 786, 11, 2152], [4294, 14208, 1827, 6, 2252, 377, 3102, 1013, 527], [253, 2, 153, 18, 798, 14209], [253, 2, 153, 18, 798, 14210], [253, 585, 1, 18, 798, 205, 14211], [253, 17, 108, 83], [253, 10, 25, 14212, 638, 90, 579, 1736, 84, 1756, 19, 97, 1, 7, 85, 78], [1231, 4, 101, 184, 3, 41, 43, 482, 3, 29, 41, 43, 9, 36, 32, 107, 8, 61, 106, 6, 33, 192, 4931, 18, 256, 7, 112], [21, 2, 104, 30, 25, 7, 345, 59, 111, 69, 81, 59, 543, 52, 7698, 70, 2, 320, 16, 19, 845, 4898, 7, 78, 91, 1737], [21, 59, 4, 215, 755, 16, 28, 10, 1855, 1356, 3, 1559, 13, 3, 47, 61, 6, 7729, 274, 7246], [21, 32, 66, 62, 22, 25, 2, 14213, 78, 9, 171, 14214, 26], [21, 32, 5, 9, 62, 3, 222, 14, 2335, 14215], [21, 32, 5, 4611, 1, 18, 20, 14216, 58, 22, 6, 497, 364, 54], [21, 155, 9, 54, 116, 116, 60, 25, 54, 116, 238, 492, 50, 8, 70, 227, 50, 173, 2, 93, 14217, 383, 176, 609, 84, 262], [21, 155, 1887, 381, 308, 2, 640, 83], [21, 189, 280, 129, 319, 21, 77, 418, 129, 14218, 21, 17, 15, 1703, 136, 10, 108, 129, 4, 365, 30, 111, 245, 115], [21, 14219, 121, 394, 5, 266, 290, 876, 3, 121, 394, 40, 121, 4480, 792, 2, 705, 14220, 1866, 7, 30, 8, 363, 6, 865], [21, 60, 540, 3, 156, 1233, 189, 69, 208, 13, 7, 11, 2474, 44, 2649, 138, 281], [21, 270, 3907, 111, 3013, 598, 6, 70, 1, 54, 16, 1628, 16, 5], [21, 212, 454, 85, 7730, 47, 303, 35, 32, 4, 5624, 92, 5, 1507, 469, 4, 159, 7731, 1905, 849, 1317, 192, 15, 18], [21, 5, 1, 25, 54, 116], [627, 5698, 1, 3620, 4, 244, 341, 154, 1839, 103, 14, 5698, 551, 7732], [14221, 3645, 11, 2118, 22, 213, 19, 221, 1], [911, 71, 93, 3, 195, 51, 14222, 99, 89, 12, 2, 24, 8, 266, 303, 254, 626, 6, 28, 172, 14223], [3376, 14224, 883, 159, 1065, 107, 54, 14225, 2254, 8, 1073, 6, 4, 730, 513], [1896, 1896, 3, 118, 100, 4, 7733, 16, 7734, 19, 10, 83, 36, 216, 606, 1938, 8, 5692, 1259, 7734], [14226, 33, 2474, 252, 9, 30, 55], [4156, 14227, 14228, 1376, 3678, 2681, 3, 86, 42, 196, 931, 16, 4, 2372], [4156, 14229, 422, 3358, 1557, 22, 6978, 14230, 14231, 42, 380, 69, 12, 69, 8, 57, 95, 36, 4422], [1763, 14232, 6, 108, 35, 22, 1074, 14233, 675], [14234, 12, 2, 3004], [1125, 9], [1125, 9, 41, 1368], [2452, 1, 119, 4, 138, 288, 23, 137, 4538], [2452, 1, 84], [14235, 47, 2, 1, 30, 916, 71, 25, 739, 129, 787, 565, 51, 84, 429, 34, 52, 210, 28, 102, 378, 218, 52, 405, 4, 743, 251], [351, 14236, 25, 100, 32, 2, 10, 381, 897, 3804, 121, 43, 24, 534, 1077, 10, 381, 331], [351, 14237, 161, 1], [351, 1187], [351, 942, 55], [351, 1, 26, 66, 271, 168, 80, 5699, 80, 922, 166, 3702], [351, 2097, 1, 14238, 14239], [351, 161, 4448, 1, 4, 304, 12, 129], [351, 64, 26, 1719, 1132, 598, 6, 14, 4, 3077, 16, 320, 16, 7735, 351, 24, 21, 76, 1973, 14240, 85, 66, 156, 627, 2142], [351, 10, 646, 14241, 8, 6459, 1], [351, 10, 145, 14242], [351, 4617, 160, 2814, 7712, 1909, 14243, 14244, 2847, 5700, 8, 1100, 2817, 5701], [351, 7, 9], [351, 7, 9, 5115], [351, 1466], [2033, 10, 628, 102, 54, 3192], [1374, 324, 21, 1295, 3858, 73, 14245, 5702, 1972, 12, 14246, 190, 1308, 5702, 7736, 49, 7737, 631, 7738, 14247, 5702], [1241, 1688, 1263, 2105, 50, 14248, 24, 444, 14249], [1241, 54, 4, 1198, 34, 478, 23, 133, 6, 119, 351, 942], [1241, 3607, 18, 5, 1], [1554, 213, 3, 375, 13, 15, 47, 5433, 3, 47, 1267, 2491, 18, 4, 832, 83, 34, 60, 1353, 30, 399, 5703, 147, 35, 55], [928, 12, 1679, 14, 10, 1], [228, 74, 3859, 153, 233, 654, 97, 5296], [228, 1674, 30, 399], [1565, 2068, 6, 7739, 1193, 11, 14250, 29, 7198, 20, 14251, 377, 49, 1345, 42, 26, 1557, 42, 2, 14252, 2176], [228, 671, 3859, 504, 671, 319], [228, 29, 100, 228, 671, 14253], [82, 377, 3483, 14254, 14255, 14256], [82, 92, 18, 3, 103, 79, 32, 5704, 1387, 158, 15, 12, 727, 1023, 8, 15, 12, 529, 3, 195, 529, 641, 621, 69, 90, 770], [82, 7, 446, 198, 486, 71, 3, 557, 7, 1, 19, 50, 92, 468, 10, 518, 3, 46, 729, 45], [82, 4, 2798, 232, 178, 5705, 1320, 3722, 1816, 4227, 14257, 14258, 55, 57, 7, 48, 1032, 5, 1784, 5706], [82, 4, 14259, 725, 10, 443, 2897, 18, 14260, 4, 761, 16, 2, 933, 265, 8, 14261], [580, 1, 28, 7, 3, 33, 41, 102, 4, 2339, 1270, 88, 3, 105, 167, 76, 35, 361, 140, 23, 2, 580, 30, 25], [2923, 14262, 8, 14263, 10, 154, 237, 228, 1517, 1224], [2463, 201, 709, 69, 364, 277, 7740, 86, 36, 49, 1174, 1759, 2, 399, 147, 564, 45], [4514, 63, 14, 2, 1], [948, 42, 72, 32, 39, 9, 65, 93, 18, 798], [810, 153], [810, 153, 1138, 67, 43, 366], [810, 42, 6348, 46, 357, 191, 42, 201, 1988, 3752, 308], [810, 80, 231, 1092, 153], [4622, 80, 1, 8, 15, 631, 13, 2, 2340], [4622, 80, 1, 215, 264, 40, 72, 463, 4, 25], [19, 23, 270, 2, 83], [19, 3361, 85, 277, 14264, 176, 443, 10, 490, 175, 3361, 210, 309, 21, 22], [19, 14265, 2339, 507, 12, 21, 24], [19, 174, 274, 444, 147, 104, 3846, 17, 142], [19, 97, 150, 46, 43, 370, 1], [19, 2, 1, 788, 2, 2839], [19, 2, 341, 235, 24, 3, 2212, 2, 587, 548], [19, 2, 564, 25, 130, 5, 2, 564, 1], [19, 2, 25, 150, 19, 2, 25, 83], [19, 2, 4623, 593, 219, 512, 2, 1], [19, 32, 7, 60, 1, 37, 974, 36, 29, 2800, 36, 103, 81, 19, 97, 520, 8, 96, 569, 6, 4, 3940], [19, 32, 7, 7741, 8, 605, 3, 19, 32, 36, 1], [19, 32, 7, 81, 1, 693, 42, 41, 10, 226, 11, 6, 476], [19, 32, 39, 537, 9, 39, 1, 339], [19, 32, 42, 185, 9], [19, 32, 78, 9, 1190, 45], [19, 32, 5, 9, 69, 176, 134, 10, 518, 6, 39, 1197, 128], [19, 224, 26, 114, 76, 9, 108], [19, 224, 8, 28, 20, 14266, 424, 11, 7, 1, 27, 32, 7, 345, 25], [19, 224, 8, 936, 10, 106, 8, 151, 19, 7, 1, 5, 90, 8, 7, 68, 228, 5, 64], [19, 224, 125, 17, 163, 10, 25, 163, 219, 227, 325, 1, 1077, 54], [19, 30, 786, 1825], [19, 89, 1], [19, 1, 28, 169], [19, 1, 28, 169, 14267], [19, 1, 28, 169, 3653, 983], [19, 1587, 181], [19, 521, 276, 14, 2, 1, 740], [19, 143, 1450, 8, 20, 56, 30, 451, 25, 19, 143, 3599], [19, 147, 1], [19, 2087, 3319, 22, 1, 723, 73, 286], [19, 290, 451, 1, 22, 12, 468, 97, 164, 451], [19, 14268, 13, 278, 311, 5, 187, 35, 964], [19, 50, 24, 19, 50, 476, 19, 50, 30, 149, 40, 530], [19, 50, 24, 19, 50, 476, 19, 50, 30, 149, 40, 530], [19, 50, 24, 19, 50, 476, 19, 50, 30, 149, 40, 530], [19, 50, 117, 11, 4, 285], [19, 12, 78, 854, 1, 581, 14269, 64, 17], [19, 12, 4624, 854, 1, 10, 689, 64, 17], [19, 15, 15, 445, 195, 85, 195, 3, 175, 73, 31, 621, 12, 61, 6, 729, 17, 78, 158, 29, 1257, 51, 445, 14270, 5707, 5707, 5707], [19, 4238, 3397, 7, 1, 75, 1226, 21, 45], [19, 10, 500, 1], [19, 145, 1299, 15, 14271], [19, 399, 1174, 81, 15, 897, 369, 66, 556, 81, 59], [19, 102, 1], [19, 14272, 4, 718, 23, 484, 15, 13, 15, 132, 21, 4, 215, 445, 213, 634, 15, 679, 568, 54], [19, 7, 7742, 45, 785, 7, 18, 1], [19, 7, 3, 41, 2, 14273, 3, 421, 7, 1, 205, 1004, 40, 222, 5374, 8, 3056, 51, 17, 38, 3, 28, 337, 425], [19, 7, 1], [19, 7, 9], [19, 7, 282], [19, 7, 9, 7, 1314, 57, 1019, 9, 14274, 525, 19, 579, 78, 25, 4, 68, 6, 924], [19, 7, 154, 1, 7, 5, 86, 5, 7743], [19, 7, 25, 45, 35, 4625, 24, 41, 14275, 61, 14276], [19, 7, 145, 52, 37, 669, 52, 75, 113, 7, 5, 2, 1125], [19, 7, 145, 52, 37, 669, 52, 75, 113, 7, 5, 2, 1125], [19, 7, 45, 23, 54, 22, 1], [19, 7, 185, 812], [19, 4, 1860, 5, 2377, 19, 20, 274, 19, 4, 399, 5, 79, 4, 6310, 26, 15, 2, 19, 154, 360, 748, 260], [19, 4, 3941, 1047, 2118, 5708, 295, 34, 1116, 24, 8, 640, 956], [19, 4, 1605, 71, 12, 2, 14277, 595, 1299, 35, 6, 14278, 663, 831, 1], [19, 4, 1739, 4, 1055, 4, 786], [19, 4, 3315, 8, 474, 36, 28, 27, 717, 3202, 1, 809, 821, 1150, 1583, 5709, 55], [19, 76, 1], [19, 76, 9, 5, 41, 7, 2276, 3807], [19, 76, 265, 1], [19, 39, 1, 139, 287, 2546, 76, 287, 29, 1838, 11, 22, 5710], [19, 39, 9, 23, 223], [19, 22, 3, 87, 2, 203, 1, 39, 703, 1, 46, 807, 21, 143, 14279, 736], [19, 22, 1, 1153], [19, 22, 172, 1, 8, 50, 185, 7744, 908], [19, 22, 9, 30, 3071, 40, 65, 13, 98, 1037, 82, 923, 4614], [19, 22, 953, 1, 40, 81, 99, 209, 40, 86, 40, 98, 5711, 2025, 14280], [19, 42, 201, 1, 79, 4, 670], [19, 42, 25, 152, 58, 48, 2, 7308, 184, 241, 1, 30, 963, 30, 25, 78, 60, 365, 30, 111], [19, 57, 2, 1, 72, 4, 689, 64, 17], [19, 57, 992, 72, 1, 3, 195, 819], [19, 57, 5, 14281, 3, 86, 76, 1, 5160, 4, 19, 459, 60, 385, 113, 5, 3, 96, 728, 54, 6, 4, 14282, 1082, 16, 43, 4626], [19, 125, 263, 8, 66, 2587, 9], [19, 27, 263, 5, 62, 66, 2587, 9], [19, 3732, 19, 391, 18, 10, 644], [19, 97, 455, 9, 92, 40, 7483, 2990, 4341, 50, 3942, 97, 548, 1497, 3, 1505, 97, 6359, 14283], [19, 5, 8, 4, 1, 5, 81, 6], [19, 5, 1, 3, 44, 6, 19, 633, 3, 114, 954, 710, 5, 114, 473, 19, 691], [19, 5, 1, 69, 471, 252, 6, 1388, 608, 1605, 33, 140, 20, 1949], [19, 5, 321, 272, 65, 51, 20, 379, 812], [19, 5, 104, 53, 632, 35, 23, 152, 14, 98, 206, 30, 91, 96, 137, 496, 14284], [19, 5, 19, 5, 5, 185, 359, 1, 61, 735, 2, 138, 8, 309, 174, 2, 185, 158, 1], [19, 5, 179, 30, 490], [19, 5, 145, 23, 587, 26, 10, 2092, 121, 43, 127, 313, 111, 11, 37, 23, 61, 6, 114, 2, 1306], [19, 5, 88, 1, 1750, 7, 197, 35, 20, 14285], [19, 5, 3406, 17, 1217, 21, 104], [19, 5, 7, 1231, 2757, 2062, 2836, 84, 1661, 6, 989, 8, 935, 84, 3078, 661, 16, 14286, 3161, 2, 5335], [19, 5, 9, 30, 25, 4, 14287, 7292, 12, 4, 101, 166, 2475, 1782, 1044, 7, 1374, 605, 73, 2, 14288, 6, 2637], [19, 20, 2328, 739, 15, 35, 9, 945, 288, 66, 194, 1539, 12, 4, 14289], [19, 14290, 6, 7745, 31, 1186, 3846, 1475, 539, 7746, 450, 16, 14291, 160], [19, 4, 45, 54, 80, 1, 3682, 40, 121, 40, 487, 397, 344], [19, 35, 38, 2, 1125, 9, 113, 5, 97, 1856, 6, 14, 2067, 47, 2270, 81, 99, 233], [19, 20, 1, 33, 704, 50], [2143, 24], [172, 24, 433, 897], [172, 720, 62, 39, 19, 75, 7747, 461, 4, 547, 16, 14292, 34, 66, 557, 76], [172, 2541, 6313, 14293, 2722, 1984, 14294, 13, 5649, 104, 868, 5489, 2610], [19, 1, 105, 167, 2, 25, 108, 35], [19, 3300], [19, 2801, 1669, 20, 2, 181], [19, 104, 652, 82, 74, 259, 11, 2152, 7748, 74, 7749], [19, 7750, 30, 1], [19, 1479], [19, 90, 179, 77, 3, 300, 321], [19, 90, 179, 77, 321], [19, 90, 10, 490, 3603, 674], [19, 308, 187, 91, 146, 64, 76], [19, 24, 321, 55], [19, 388, 494, 8, 126, 178, 1713], [19, 640, 1], [19, 273, 32, 16, 5, 283], [19, 56], [19, 816, 14295, 536, 4, 2994, 281], [19, 27, 39, 9, 25, 29, 14, 43, 7751], [7652, 22, 104, 2620], [6373, 10, 312, 2, 1080, 205, 52, 152, 107, 108], [14296, 5, 5, 9, 3, 29, 67, 5, 108, 1621, 2198], [1156, 147, 1, 55, 768], [1156, 42, 1], [1156, 125, 2, 112, 153], [5712, 125, 10, 153, 14297, 1587, 233, 366, 1069, 233, 383, 14298, 45, 233], [356, 194, 10, 312, 1876, 18, 2798], [2123, 14299, 1088, 3, 182, 3634, 47, 7752, 152, 312, 14300, 233, 128, 529, 4566, 906, 17, 102, 2698], [356, 201, 94, 315, 435, 27, 2296, 1, 18, 886, 59, 14301, 7619], [356, 184, 14302, 48, 33, 4, 111, 58, 254, 15, 4, 111, 69, 94, 39, 327, 8, 1105, 4, 942, 33, 73, 2625], [7753, 5, 5, 185, 19, 187], [14303, 7, 83], [3729, 35, 9, 142, 288, 5, 1400, 1846, 6, 1305], [1069, 159], [1069, 159], [14304, 3, 86, 600, 14, 1777, 12, 2, 269, 362, 208, 13, 1155, 26], [77, 122, 6, 157, 384, 1, 18, 99, 11, 14305, 122, 6, 303, 4, 1675, 14306, 3868, 21, 10, 347], [14307, 14, 4, 95, 7, 210, 28, 4, 1329, 225], [2167, 14308, 124, 1, 7754, 84, 2189, 8, 1855, 51, 4, 199, 106, 11, 14309, 4331], [93, 451, 3178, 379, 169, 181], [14310, 3411, 41, 2, 89, 1, 1], [3794, 2492, 225, 1, 30, 25], [3943, 42, 1, 30, 2286], [189, 3, 33, 294, 173, 98, 1294, 8, 4, 7755, 136, 2, 1187, 65, 13, 3, 600, 33, 258, 54, 21, 2542], [14311, 5, 62, 57, 7, 196, 5713, 647, 247, 16, 10, 228, 49, 9, 22, 75, 14, 573], [14312, 8, 5039, 398, 976, 1922, 18, 307], [1910, 12, 108, 1, 795, 3243], [1910, 12, 625, 179], [1910, 12, 270, 2, 9], [1910, 2, 1, 8, 136, 1058, 1024], [1910, 2, 1, 8, 136, 268, 1024], [3684, 12, 7, 1, 69, 415, 134, 14313, 14314], [14315, 3, 41, 1, 148, 3, 41, 1, 148, 3, 41, 1, 1039, 504, 8, 7756], [178, 6684, 7757, 1652, 51, 154, 1648], [178, 14316, 7757, 1652, 51, 154, 1648], [1190, 1190, 1], [7758, 49, 6759, 918, 1468], [4447, 77, 47, 2, 2986, 3, 454, 57, 118, 44, 671, 16, 31, 3944, 2290, 4447, 2449], [1069, 12, 156, 3726, 11, 4, 179], [7759, 14317, 57, 200, 4, 215, 24, 5, 124, 578, 13], [2345, 1, 237, 14, 5714, 1960], [2345, 1, 165, 14, 168, 1960], [502, 2, 1859, 189, 2, 535, 1889, 225, 8, 210, 110, 72, 267, 5, 33, 294, 423, 136, 550, 7760, 386, 16, 2, 83], [502, 147, 1, 143, 2802, 16, 4, 2078], [502, 50, 7, 5318, 15, 161, 3111, 842, 7761], [502, 7, 1, 98, 1701, 1515, 188, 1, 64, 19, 125, 36, 500], [315, 30, 837, 7762, 323], [315, 30, 25, 1, 5, 299, 5, 299], [7763, 54, 10, 588, 3, 86, 22, 1, 328, 1796, 2, 1243], [4073, 1609, 715, 1285, 1, 1609, 56, 14318, 30], [1576, 14319, 14320, 16, 3258, 2963, 51, 14321, 14322, 818, 6, 72, 10, 674, 3885, 47, 51, 22, 2963, 11, 14323], [1576, 1486, 270, 2, 181], [4950, 315, 189, 440, 11, 2991, 4383, 211, 14, 181, 2546, 11, 7764], [28, 2, 961, 154, 401, 321, 93, 1640, 24, 1876, 1274, 169, 106], [28, 2, 1, 421, 2, 1], [28, 187, 6, 2187, 17, 48, 14324, 278, 5715, 167, 35, 2, 180, 4467, 1143, 3427, 2540, 213, 74, 256, 4313], [28, 135, 2364, 1761, 2, 501, 421, 82, 4, 14325, 789], [28, 10, 226, 2292, 117, 123, 97, 24], [28, 18, 20, 5390, 19, 45, 282], [28, 18, 20, 45, 282], [28, 54, 5716, 14326, 14327, 20, 587, 1006, 82, 727, 587, 14328, 14329, 4, 14330, 381], [28, 60, 14331, 684, 853, 904, 2, 413, 320, 70, 362, 1018, 146, 44, 1018, 720, 60, 2796, 355, 2796, 2155, 353], [28, 364, 102, 5717, 24, 13, 148], [28, 4, 19, 129, 630, 1298, 20, 98, 3641, 2956, 8, 428, 168, 1349, 149, 20, 14332, 5, 49, 48, 2383], [28, 39, 9, 30, 4310, 102, 4, 5677], [28, 22, 1, 102, 10, 886, 321], [28, 22, 269, 102, 10, 3583], [28, 268, 95, 1771, 51, 68, 817], [28, 80, 1, 756, 123, 688, 399], [28, 20, 530, 30, 54, 16, 10, 1690, 1], [28, 20, 373, 406, 83], [28, 20, 981, 30, 54, 10, 193], [28, 20, 669, 30, 7765, 4976, 102, 186, 9], [525, 2, 161, 5718, 1795, 237, 14333, 11, 975, 3700, 27, 10, 312, 8, 14334], [525, 1, 47, 105, 332, 3, 33, 1385, 142, 149, 7, 192, 41, 1490, 98, 10, 77, 14335], [525, 405, 503, 147, 9], [28, 167, 102, 2, 187, 7, 59, 688, 1735, 7766, 8, 2, 187, 7, 47, 11, 4, 1714, 55, 3, 5444, 279, 5, 49, 172, 14336], [28, 638, 6, 2277, 127, 130, 1201, 9, 8, 742, 451, 12, 1268, 34, 37, 332, 6, 58], [28, 102, 186, 2457, 1174, 1040, 17, 54, 127, 3, 29, 87, 22, 409, 16, 1136], [179, 30, 1, 510, 11, 10, 401, 2462, 133, 667, 14337, 367, 42, 803, 3945], [179, 95, 75, 635, 423, 82, 10, 689], [1055, 5719, 541, 13, 56], [1055, 2205, 4627, 95, 1461, 14338, 272, 70, 60, 1919], [1055, 5, 1], [14339, 12, 21, 24], [2451, 246, 828, 1], [2451, 10, 940, 1, 5, 62, 827, 23, 122, 6, 1175], [77, 29, 869, 7, 24, 5, 198, 14, 4, 409, 6, 5094, 7, 24], [77, 13, 4559, 327, 16, 588, 18, 610, 22, 561, 288, 3, 47, 197, 38, 3, 486, 7, 3, 299, 1539, 1, 87, 2, 3895], [77, 5, 119, 127, 24, 88, 17, 77, 5, 198, 44, 132, 2, 25], [77, 49, 37, 19, 14340, 225, 176, 20, 2240, 11, 20, 1286, 5, 537, 9], [77, 14, 13, 14341, 3, 64, 5, 1059, 5393, 1, 427, 7, 225], [77, 14, 13, 14342, 3, 64, 5, 1059, 5393, 9, 427, 7, 225], [77, 14, 65, 21, 540, 6, 58, 9, 45], [77, 14, 840, 27, 7, 463, 41, 894, 45, 3, 58, 62, 166, 77, 7, 49, 10, 228], [77, 7, 255, 207, 1708], [77, 4, 115, 14, 1075, 9, 46, 357, 41, 106, 972, 7], [77, 131, 563, 2, 91, 27, 893, 8, 14343, 8, 2, 177, 18, 2, 2775, 167, 53, 14344], [77, 194, 54, 21, 9, 69, 156, 44, 256, 6, 72, 133, 20, 91, 426, 36, 103, 14, 4, 455, 68, 1532, 6, 19, 170, 747, 20, 108], [134, 2, 1, 201, 74, 292, 2870, 26, 7, 254], [134, 2, 1792, 1, 2, 190, 741, 92, 40, 2482, 138, 11, 4, 689, 8, 45, 14345], [134, 17, 292, 301, 3, 301, 3, 301, 3, 301, 5, 118, 83], [134, 17, 235, 98, 605, 1533, 25, 42, 2, 151, 1], [134, 17, 235, 8, 605, 6, 25, 5, 2, 4628, 1], [134, 7, 9, 98, 2553, 40, 271, 208, 14346], [134, 39, 9, 5720, 253, 5, 41, 2, 413, 154, 1], [134, 263, 305, 1789, 812, 66, 363, 54, 116, 26, 424, 7, 3199], [134, 5, 7, 1900, 731, 248], [721, 3, 46, 41, 43, 95, 645], [721, 3, 900, 35, 18, 10, 206, 9], [61, 14347, 5, 41, 14348, 1, 974, 781, 8, 2, 666, 16, 1794, 1792, 51, 20, 261, 37, 23, 1801, 21, 350], [61, 345, 59, 15, 14349, 33, 13, 4, 141, 1, 5, 49], [61, 194, 1723, 5295, 1133, 30, 1, 4, 1723, 49, 137], [274, 3, 118, 506, 398, 10, 879, 6, 194, 1103, 1516, 84, 5655, 117, 92, 8, 194, 32, 212, 24, 204, 943], [274, 1236, 4, 171, 8, 144], [274, 1236, 4, 171, 25, 69, 302, 39, 9], [274, 1301, 91, 7, 4090, 12, 37, 144, 7, 15, 14350, 483, 526], [274, 148, 95], [274, 148, 567, 95, 669, 30], [274, 148, 1172, 155, 3038, 2201, 4, 14351, 665, 14352], [274, 216, 1693, 8, 275, 3868, 16, 5721, 155, 259, 184, 456, 7500, 3946, 6, 271, 18, 22, 1681, 95, 1578, 8, 5721, 14353], [274, 10, 175, 49, 37, 179], [274, 111, 63, 14, 37, 4629, 22, 668, 189, 3292, 4, 676, 21, 39, 77, 8, 36, 121, 36, 220, 1003, 52, 222, 94, 15, 27, 84, 1650, 387], [274, 20, 2, 104, 31, 5, 29, 86, 5527, 12, 4, 237, 3947], [568, 673, 45, 18, 10, 30, 13, 14354, 364, 5, 1042, 3, 14355, 492, 80, 164, 37, 3, 842, 50, 30, 173, 4, 4, 1842, 88, 40, 1954, 142, 361], [61, 3235, 88, 2, 9, 225, 146, 14, 1769, 21, 2358], [61, 21, 2, 1, 25, 833, 149, 25, 195, 3277], [61, 332, 1, 300, 23, 18, 10, 401, 313, 2, 14356, 11, 4, 1211, 79, 7, 45, 2, 5528], [61, 54, 27, 89, 14357, 176, 80, 504, 1077, 8, 23, 48, 33, 72, 15, 191, 10, 312, 3, 196, 15], [61, 539, 10, 4630, 8, 592, 4, 4881, 7, 7767, 496, 66, 216, 1554, 213, 11, 14358, 47, 99, 752], [61, 6, 2203, 225, 21, 60, 7768, 14359, 61, 173, 138, 7452, 14360, 301, 3, 124, 2, 2011, 207, 2611, 6, 255, 21, 4, 7769], [61, 6, 28, 10, 278, 225, 19, 679, 151, 94, 5, 144, 738], [61, 6, 4, 7770, 27, 10, 1, 740], [61, 35, 6, 4, 1535, 446, 8, 94, 883, 14361, 57, 4, 269], [14362, 242, 142, 9, 371, 14363], [1052, 7414, 30, 1, 55], [2889, 354, 49, 4, 237], [14364, 131, 791, 17, 495, 113, 76, 9, 6, 94, 14365], [14366, 456, 14367, 52, 198, 560, 338, 527, 14368, 3, 380, 6183, 12, 4, 4410, 184, 36, 44, 51, 2, 14369, 167, 7, 83], [223, 912, 15, 458, 21, 2, 112, 153], [152, 467, 8, 81, 59, 1, 7, 289, 603, 4525], [152, 70, 2, 813, 1799, 157, 470, 2, 1149, 16, 14370, 18, 7, 1, 8, 1244, 60, 45, 54], [152, 1306, 21, 4, 508, 1405, 16, 14371, 10, 14372], [152, 344, 1443, 536, 4, 244, 837, 69, 122, 6, 3768, 4, 1067, 14373, 6, 2, 14374, 14375], [152, 1003, 14376, 27, 2, 2986, 237, 7771, 182, 19, 2266, 367], [93, 14377, 104], [93, 561, 6, 1613, 391, 1, 27, 5722, 14378, 14379], [93, 561, 6, 5, 9, 8, 14380], [93, 115, 2266, 27, 10, 104], [93, 115, 5171], [93, 115, 5171, 3589, 121, 93, 115, 14381], [93, 14382, 1391], [93, 110, 159, 8, 228], [93, 1403, 3, 105, 704, 2, 1, 13, 22, 230], [93, 1640, 107, 6, 94, 263, 11, 3570, 7, 162, 32, 4, 1, 49, 51], [93, 561, 159], [93, 561, 1147, 3, 44, 10, 2474, 169, 392, 1686, 8, 3, 210, 58, 245, 5723, 20, 10, 1, 1147], [93, 561, 1610, 70, 225, 2, 1531, 1155, 31, 5, 75, 58, 7, 257, 35, 73, 239, 14383, 73, 7772, 560, 3, 90, 567, 1187], [93, 561, 14384], [93, 561, 798, 749, 134, 42, 120, 56, 481], [93, 561, 5, 9, 30, 956, 14385, 1327, 2114], [93, 802, 3039], [93, 479, 95], [93, 24, 396, 97, 164], [93, 36, 56, 25, 672, 247, 16, 10, 1499, 6240, 851, 8, 4, 851, 745, 132, 11, 4, 331, 787, 755, 478], [93, 184, 59, 5, 9, 42, 46, 9, 5724, 174, 5687, 438, 103, 107, 6], [93, 184, 10, 646, 64, 17, 127, 130, 32, 5, 1, 14386, 52, 1025, 84, 30, 35, 211, 197, 32, 264, 6, 484, 17, 6, 2119, 7, 2608], [93, 441, 89, 83, 41, 39, 9, 18, 10, 138, 13, 4363, 14387], [93, 40, 2, 179, 1021, 2236, 14388, 33, 1462, 21, 14, 11, 4, 5725, 26], [3394, 907, 3041, 106, 6, 3752, 42, 1950, 15], [3394, 2299, 379, 7773, 2217, 7774, 1297, 26, 933, 2414], [5726, 1, 410, 591, 580, 1914, 3719], [5726, 7775, 1, 30, 25], [1929, 1, 14389, 2, 14390], [1929, 10, 112, 3948], [1929, 322, 1, 163, 112, 25, 19, 143, 763], [2666, 809, 1558, 70, 2, 145, 528], [2476, 14391, 455, 490, 534], [41, 378, 260, 779, 43, 1, 43, 436, 749], [41, 201, 89, 1, 27, 17, 1361, 8, 7513], [41, 2, 2188, 1, 33, 14392, 18, 10, 138], [41, 2, 1, 37, 89, 5, 75, 1800, 6, 1066], [41, 2, 535, 2310, 913, 3, 28, 2, 535, 6481, 996, 147, 535, 2310, 1151, 10, 153, 103, 512, 97], [41, 2, 1074, 21, 624, 34, 4, 14393, 12, 21, 4, 1], [41, 2, 161, 1, 82, 4, 14394], [41, 2, 154, 1, 8, 40, 41, 30, 541, 51, 10, 500, 13, 221, 3, 62, 5, 214], [41, 2, 355, 30, 1, 2938, 2, 355, 30, 14395], [41, 32, 4, 202, 1, 214, 218, 10, 455, 1, 5727], [41, 246, 25, 1, 11, 10, 618, 117, 92], [41, 1485, 6882, 225, 16, 2, 434, 2051, 21, 10, 2312, 129, 4, 722, 201, 1164], [41, 148, 91, 4239, 364, 129, 13, 2, 1], [41, 148, 4, 1583, 3770], [41, 93, 285, 34, 432, 119, 50, 1000], [41, 167, 18, 123, 2, 2673, 1164, 206, 14396, 86, 110, 31, 3, 220, 6, 1273, 20, 1719, 3865, 116, 452, 14, 209, 5, 222, 58, 59, 254], [41, 3079, 18, 10, 3398, 14397, 667, 1], [41, 10, 453, 216, 153, 188, 1156, 42, 389, 17], [41, 10, 373, 507, 389, 10, 373, 1005, 26, 2354, 26, 201, 14398, 364, 195, 3, 475, 59, 2, 244, 1, 21], [41, 10, 45, 396, 277, 258, 4, 14399, 92, 1, 281], [41, 10, 1536, 7776, 10, 1434, 1485], [41, 531, 2, 154, 401, 1], [41, 68, 1, 11, 7777, 8, 68, 1, 108, 11, 14400], [41, 4, 14401, 401, 83], [41, 39, 9, 7778, 41, 39, 145, 533], [41, 22, 89, 1840, 1, 26], [41, 6, 1494, 18, 567, 4631], [41, 6, 885, 18, 567, 95, 63, 5, 72, 7779, 77, 18, 1681], [41, 1158, 1, 147, 644, 15, 102, 13, 3512, 7780], [41, 35, 6, 28, 522, 405, 2, 14402, 8, 10, 381, 363, 673, 45, 8, 1025, 4, 413, 331, 562], [41, 97, 14403, 1282, 1346, 8, 4539, 3027, 34, 43, 25, 3361, 46, 290, 21, 295], [41, 20, 1, 1277, 7781, 616], [41, 20, 1, 129, 135, 3557, 10, 343, 21, 307], [41, 20, 1, 27, 17, 117, 615], [14404, 1], [146, 89, 355, 1006, 7, 65, 256, 13, 7628], [146, 1, 27, 60, 1860, 813, 2821], [146, 61, 28, 2, 2572, 4632, 740, 46, 43, 1, 65, 51, 17, 117, 615, 8, 225, 36, 32, 47, 897, 4, 14405], [146, 176, 4, 1111, 142, 288, 374, 142], [146, 64, 14406, 1229, 185, 5192, 8, 392, 709, 14407], [146, 64, 4, 14408, 14409, 1117, 4, 190, 480, 6, 7782, 7171, 140, 4, 250, 68, 47, 14410], [146, 346, 79, 82, 4874, 1], [146, 157, 15, 108, 11, 4380, 46, 566, 42, 14411, 161, 185, 30, 368, 11, 2, 691, 1154, 42, 4633, 55], [146, 938, 4, 153, 397, 244, 6, 5, 311, 240, 102], [146, 872, 147, 484, 89, 1, 284], [146, 194, 39, 9], [2803, 825, 1215, 543, 159, 824, 30], [2803, 825, 1215, 543, 159, 824, 30], [2155, 353, 8, 14412, 1637, 49, 10, 3428], [994, 2426, 1295, 3891, 160, 98, 206, 1698, 1310, 1485, 1295, 3891, 13, 994, 216, 125], [994, 14413, 12, 2, 14414, 3752, 14415, 14416, 14417, 128], [4351, 1, 127, 130, 2, 2367, 213, 206, 120, 1], [14418, 6, 4484, 96, 2, 1, 464], [434, 1337, 2333, 8, 88, 4439, 167, 14419, 21, 2, 1343, 241, 2756], [875, 2994, 8, 1308, 248], [7648, 5, 3308, 386, 16, 2, 1, 5], [14420, 1540, 2622, 14421, 2622, 8, 3, 273, 10, 1, 6, 559, 17, 149, 23, 105, 223, 3812], [632, 35, 33, 140, 2, 25, 136, 9, 317, 196, 52, 317, 64, 5, 26], [632, 35, 1], [14422, 1025, 35, 14423, 14424, 2320, 1485, 14425, 14426, 346, 4, 6944, 378, 14427, 304, 21, 4, 3685, 1567, 3491], [14428, 9], [4610, 635, 1, 8, 40, 397, 54], [1192, 311, 977, 168, 6, 271, 244, 676, 84, 14429, 14430, 1, 3949, 35, 97, 2354, 169], [1192, 150, 13, 4196, 24, 2473, 5, 122, 6, 204, 17, 8, 407, 7180, 25, 811, 1192, 46, 122, 6, 142, 170], [1192, 19, 2, 320, 127, 1303, 1, 34, 52, 4, 409, 6, 48, 44, 6, 569, 18, 14431, 69, 458, 126, 476], [1192, 1151, 18, 2, 1], [14432, 176, 7, 24, 926], [380, 151, 44, 6, 1299, 3429, 2594, 117, 244, 6, 159, 7783, 92, 2453, 14433, 2614, 10, 101, 443, 14434, 4634], [380, 69, 33, 41, 98, 1880, 11, 4110, 3950, 7, 117, 1, 5, 380, 15, 22, 3042], [380, 69, 2, 141, 1], [2343, 405, 65, 1, 1088, 18, 111, 65], [189, 175, 3, 131, 119, 60, 24, 253, 1257, 488, 77, 175, 3, 131, 249, 60, 138, 253, 1257, 9, 48, 1847], [189, 92, 8, 115, 208, 13, 36, 29, 279, 140, 24, 12, 1016, 34, 7, 48, 4, 101, 184, 7, 690], [189, 72, 280, 230, 319, 3, 72, 522, 230, 7784], [189, 37, 705, 6, 81, 45, 6, 2, 1, 36, 118, 605, 30, 6, 26], [189, 7, 1784, 6, 28, 24, 49, 4, 455, 25, 7, 89, 81, 2282, 52, 222, 28, 127, 24, 31, 52, 63, 683, 71, 6, 411, 8, 497], [6869, 365, 1], [281, 1379, 245, 16, 5, 1, 110, 86, 59, 1183, 17, 11, 4, 14435, 26], [1292, 23, 37, 243, 7, 1, 33, 7359, 32, 50, 1637, 1666], [5728, 53, 841, 3, 139, 14436, 913, 3, 7646, 174, 368], [14437, 56], [341, 685, 871, 846, 528, 377, 28, 260, 6, 543, 1368, 235, 5729, 5730], [341, 1331, 685, 871, 846, 528, 377, 28, 260, 6, 543, 1368, 235, 5729, 5730], [341, 1331, 685, 871, 846, 528, 377, 28, 260, 6, 543, 1368, 235, 5729, 5730], [71, 839, 860, 789, 1289, 18, 2, 2155, 353, 4350, 51, 654, 1847, 16, 1094, 3252, 513, 26], [14438, 79, 7785, 2, 269, 2979, 600, 14, 2, 666, 16, 1034, 34, 7, 1088, 216, 17, 2723, 528], [136, 1005, 14439, 452, 134, 98, 1876, 57, 2, 24, 403, 1005, 648, 2, 1], [136, 1], [136, 147, 1, 11, 865], [4385, 69, 63, 28, 4, 24, 6523, 39, 115], [4385, 5, 2, 1045, 9], [124, 6, 572, 7, 83, 1933, 589], [124, 6, 396, 10, 45, 35, 18, 42, 9], [124, 6, 58, 246, 310, 3164, 1274, 998, 39, 9, 82, 10, 1372], [124, 6, 28, 7, 9, 45, 102, 10, 909], [124, 6, 881, 2, 1290, 153, 35, 112, 7786, 215, 4349], [124, 80, 455, 1, 525, 14440], [4361, 2, 180, 55, 6, 32, 4, 4148, 104], [281, 151, 512, 5, 8, 7, 1, 3, 380, 10, 743, 12, 7787], [281, 4635, 363, 14441, 37, 370, 1699], [281, 2, 2440, 3506, 457, 12, 87, 6, 32, 69, 44, 1120, 305, 1451, 4, 722, 707, 3, 75, 304, 21, 305, 3, 94, 5, 14442, 55], [281, 1, 30, 1192], [281, 3, 79, 10, 77, 2, 1, 101, 218, 40, 79, 17, 68], [281, 14443, 47, 33, 18, 10, 7788, 1602, 283, 7, 202, 5669], [281, 145, 502, 35, 75, 176, 35, 27, 17, 1818], [281, 232, 408, 49, 4974, 54, 16, 1471, 59, 4, 14444, 7789], [4322, 15, 356, 71, 32, 4, 141, 171, 9, 67, 6, 253, 5, 25, 33, 6, 14, 32, 35, 11, 20, 30, 13, 1, 4, 19, 5, 14445, 972], [736, 3, 94, 5, 145], [736, 23, 19, 669, 52, 168, 6, 2362, 22, 24, 3884, 425], [736, 314, 261, 57, 2, 675, 127, 13, 365, 1, 98, 171, 25, 14446, 135], [14447, 37, 111, 75, 915, 14448, 186, 12, 172, 56, 14449], [7299, 10, 826, 33, 112, 39, 14450, 40, 121, 463, 87, 6, 139, 208, 179, 149, 15, 48, 4636], [1292, 19, 24], [1292, 3031, 12, 2, 104, 8, 4, 524, 103, 1606, 1167, 404, 404, 21, 17], [14451, 172, 1170, 65, 1], [14452, 20, 520, 56, 581, 139, 238, 2413, 630, 2855, 11, 39, 175], [343, 349, 985, 352, 12, 33, 2, 193, 16, 100, 50, 62, 7, 50, 24, 12, 93], [14453, 47, 79, 2, 6908, 26, 4637, 16, 14454, 8, 40, 14455, 11, 4, 14456, 78, 86, 14457, 210, 1649, 7], [470, 16, 78, 9, 3379, 37, 4, 68, 27, 2821, 3212, 28, 2, 228, 461, 2165, 44, 2, 25, 19, 78, 398, 8, 191, 170, 69, 41, 165, 24], [470, 39, 1, 14, 868, 140, 34, 23, 750, 82, 2, 564], [470, 39, 275, 27, 39, 186, 226, 13, 3510, 10, 887, 46, 110, 59, 7, 164, 5012], [923, 12, 2, 9, 2368], [923, 129, 8, 1, 96, 137, 14458], [402, 17, 2, 7790, 8, 151, 901, 15], [2848, 5095, 1, 3, 731, 162, 3, 2197], [662, 54, 27, 189, 277, 48, 70, 5, 2, 9], [662, 27, 14459, 8, 5731, 225, 10, 1], [662, 27, 10, 1, 3, 487, 14, 127, 243], [243, 14460, 6, 39, 455, 1, 114, 15, 1016, 18, 4, 5068], [243, 1451, 97, 1, 5], [243, 457, 9, 151, 156, 64, 5, 110, 31, 66, 61, 2, 213, 461, 81, 426, 20, 1949, 20, 96, 10, 746], [243, 457, 399, 176, 20, 866, 203, 8, 20, 1833, 1207, 513], [243, 457, 6, 22, 181], [243, 3950, 115, 110, 13, 8, 57, 4, 19, 12, 329, 27, 5, 172, 749], [243, 3950, 115, 33, 14, 721, 66, 407, 5714, 6, 5663, 4, 14461, 944, 14462, 7, 45, 118, 14, 715], [243, 14463, 5, 537, 386, 2, 1], [243, 928, 1], [243, 1451, 3, 64, 5, 10, 399], [243, 457, 3, 64, 5, 104], [243, 457, 95], [243, 457, 1], [243, 457, 181, 64, 97], [243, 457, 141, 1, 177], [243, 457, 312, 346, 20, 202, 30], [243, 457, 429, 1274, 206, 664, 3381, 1274, 4, 91, 69, 121, 3, 47, 98, 5694, 3420, 105, 65, 37], [243, 457, 6, 599, 4, 4638, 1, 3, 62, 23, 37, 243, 23, 1342, 6, 42], [243, 457, 6, 10, 83, 3, 124, 6, 6367, 12, 6479, 30, 14464, 64, 5, 218], [243, 457, 6, 10, 7791, 206, 664, 3381, 12, 3420, 225, 55], [243, 457, 6, 4, 796, 144, 54, 1271, 20, 10, 443, 144, 464, 243, 457, 312], [243, 457, 6, 22, 490, 30, 25, 14465], [243, 250, 115, 16, 1197, 158], [243, 5513, 4, 7792, 12, 92, 14466], [243, 22, 25, 1723, 206, 3, 101, 13, 355, 1006, 30, 12, 194, 1305], [2674, 182, 3062, 1, 3, 460, 634, 15, 2260], [3103, 360, 56, 14467], [2139, 456, 3430, 23, 4, 1, 52, 63, 616, 3409, 18, 585, 667, 1587, 4317], [3582, 41, 4, 884, 9, 4987, 11, 770], [136, 621, 182, 5732, 1519, 1194, 1751, 3, 109, 67, 1751, 82, 1330, 21, 10, 7793, 14468], [90, 2, 1, 7, 156, 11, 60, 780], [90, 2, 9, 7, 86, 575, 49, 14469, 14470, 1506, 100, 17, 28, 17, 2, 14471, 372, 171, 73, 14472], [90, 1210, 36, 14473, 187, 11, 581, 213, 278, 516, 119, 13, 2, 1072, 8, 467, 13, 289, 41, 2, 437], [90, 147, 9], [90, 18, 57, 1], [90, 7, 1, 1410, 7794, 436, 12, 633, 17, 102], [90, 22, 391], [90, 38, 23, 11, 2, 77, 620, 79, 50, 88, 40, 79, 108, 211, 23, 18, 4, 2185, 1, 1449], [90, 38, 1, 28, 520, 88, 627, 32, 59, 5, 13, 5, 407, 116, 230, 36, 41, 612], [90, 38, 1, 81, 13, 36, 3492, 19, 20, 1209, 54, 88, 14, 13, 584, 33, 14474, 128, 19, 42, 1], [90, 38, 1, 238, 157, 5, 11, 4, 14475, 23, 238, 1228, 157, 17, 11, 4, 14476], [90, 38, 1, 27, 358, 343, 1389, 6, 28, 2, 14477, 777, 93, 182, 107, 54, 16, 7], [90, 38, 9, 122, 6, 1337, 42, 18, 576, 13, 161, 1, 23, 14478], [90, 38, 10, 9, 28, 54, 135, 98, 192, 896, 419, 1936], [90, 18, 17, 88, 1, 57, 93], [1100, 102, 6, 32, 5733, 418, 82, 4, 179, 69, 44, 3080, 1183, 51, 5536, 4969], [44, 36, 297, 1260, 16, 4, 673, 2484, 136, 4, 3644, 518, 16, 269, 2475, 16, 245, 1129, 11, 4, 360, 27, 14479], [44, 5, 2883, 191, 2, 153, 162, 765, 41, 667, 365, 1953, 3069], [44, 5, 182, 429, 3892, 18, 2, 2185, 288, 525, 60, 1209, 792, 15, 54, 40, 121, 296, 105, 297, 2218, 18, 2, 14480], [44, 5, 182, 491, 2, 1, 21, 134, 5, 2, 180, 4639], [44, 5, 182, 299, 2, 1, 47, 631, 73, 19, 34, 1025, 35, 4, 244, 561, 26, 623, 7, 40, 47, 33, 18, 50, 1230], [44, 5, 566, 4599, 45, 2217, 14481, 4, 177, 180, 123, 14482, 778, 14483, 18], [44, 5, 1420, 2, 7061, 225], [44, 5, 1649, 32, 4, 179, 111, 226, 126, 265, 211, 347, 14484, 7238, 14485], [745, 81, 6, 10, 1, 11, 2, 288, 649], [44, 14486, 894, 28, 206, 219, 15, 136, 2405, 206, 3807], [44, 2, 154, 520, 155, 707, 317, 196, 20, 14487, 15, 196, 20, 1016, 8, 726], [44, 2, 1, 46, 5734, 44, 1, 147, 46, 334, 12], [44, 2, 1, 107, 11, 5735, 985, 106, 13, 22], [44, 9, 48, 431, 7, 68, 103, 14, 165, 130, 32, 76, 593], [44, 352, 27, 2, 189, 266, 176, 170, 224, 21, 5, 171, 9, 69, 86, 760, 116, 2804, 285, 33, 146, 44, 2, 189, 69, 266, 134, 11], [44, 2266, 4, 413, 16, 430, 739, 113, 4, 1, 244, 6, 17, 6, 157, 50, 310, 423, 3, 195, 92, 2333, 4, 2793, 37, 3, 63, 303, 1778], [14488, 12, 2, 187], [5689, 1701, 65, 13, 2, 4631, 50, 8, 4163, 700, 1342, 123, 1359, 8, 45], [14489, 1637, 8, 2155, 353, 155, 561], [52, 2, 9, 996, 7, 2234, 2240, 12, 2510, 182, 3951, 6, 98, 2234, 2013, 274, 136, 2, 804, 1237, 16, 5736], [52, 46, 45, 77, 52, 2, 1, 216, 25], [52, 14, 13, 757, 14490, 10, 14491], [52, 165, 1668, 35, 218, 46, 43, 1, 14492, 2, 25, 7, 40, 29, 1181, 21, 14, 125, 166, 14493, 29, 110, 372, 117], [52, 316, 4, 9, 54, 18, 186, 25, 41, 1579, 863, 69, 12], [52, 79, 17, 2, 83, 8, 52, 121, 52, 47, 396, 58, 5, 79, 7, 396, 3, 29, 86, 2028, 71, 59, 5, 61, 19, 2915], [52, 79, 17, 33, 6, 72, 52, 47, 998, 10, 14494, 1, 2034], [52, 222, 14, 14495, 245, 9, 36, 124, 11, 4, 14496, 25, 82, 4, 689, 920, 785, 14497], [52, 200, 147, 6500, 45, 18, 1405, 233, 92, 4, 413, 4304, 412, 172, 35, 541, 51, 22, 804, 541, 153], [52, 309, 21, 2, 540, 53, 3, 210, 253, 5, 108, 218, 5, 203, 83, 1449, 2850, 3106, 847, 46, 333, 1154], [52, 277, 128, 3081, 14498, 132, 124, 9, 55], [52, 317, 13, 5, 97, 185, 83, 52, 13, 174, 14499, 1718, 3495], [52, 29, 110, 253, 84, 1], [52, 28, 22, 14500, 764, 82, 3574, 749, 8, 15, 21, 4, 942], [52, 41, 4179, 7795, 73, 84, 7796, 54], [52, 41, 2, 1081, 226, 3030, 7, 728, 143, 4447, 14501, 143, 199, 14502, 1, 98, 7797, 3952], [52, 41, 9, 21, 506, 1495, 27, 170], [52, 136, 4639, 18, 170, 98, 15, 13, 221, 1, 7, 588, 8, 52, 13, 48, 110, 122, 6, 869, 980, 70, 17, 150, 93, 59, 1068], [52, 167, 17, 27, 53, 31, 3, 113, 5, 69, 23, 19, 5, 75, 72, 45, 1, 34, 50, 235, 178, 18, 446, 53], [52, 12, 109, 18, 10, 493, 751, 664, 14503], [52, 811, 52, 41, 2, 1, 7, 62, 71, 6, 867, 233, 656, 26, 1089, 474], [52, 600, 14, 4, 970, 34, 7, 317, 5210, 196, 52, 11, 4, 508, 1531, 16, 863, 11, 3343, 6, 70, 270, 6358], [52, 87, 99, 66, 404, 2003, 38, 52, 737, 9, 180, 2724, 223, 737, 14504, 9, 211, 22, 514, 370], [52, 105, 1257, 6, 10, 191, 59, 84, 79, 17, 2, 5348], [52, 101, 443, 20, 175, 59, 170, 6, 176, 84, 166, 9, 243], [52, 700, 223, 528, 163, 72, 22, 1, 284], [52, 24, 792, 461, 28, 4, 24, 128, 52, 146, 1396, 54, 16, 15], [52, 298, 84, 476, 33, 13, 2, 1, 3, 124, 6, 311, 240, 102], [52, 121, 1, 177], [52, 121, 14505, 8, 1172, 1054], [52, 121, 28, 35, 836, 7, 48, 14506], [52, 121, 931, 7798, 1, 233, 1140], [52, 121, 7, 1, 65, 13, 2, 1646, 14507, 205, 1335], [52, 121, 66, 276, 14, 389, 2, 1, 2354, 23, 48, 110, 238, 303, 50, 98, 1037, 789, 8, 2844, 1645, 51, 1653], [52, 37, 56, 14508, 14509, 41, 1281, 55], [52, 372, 13, 2, 1], [52, 56, 11, 2341, 3379, 252, 78, 6578, 73, 286, 31, 78, 61, 6, 5521, 2341, 8, 5, 29, 1181, 84, 4605], [52, 47, 81, 59, 23, 18, 68, 649, 71, 47, 7, 110, 1756, 38, 3, 47, 18, 2, 2795, 4358, 27, 43, 310, 2312, 664], [52, 363, 8, 41, 7, 1], [52, 2, 83], [52, 2, 322, 148, 93, 14510, 34, 73, 2, 315, 91, 15, 1772, 6, 94, 98, 4640, 494, 3953, 2096, 4, 1337, 2773, 21, 2, 1082, 3947, 7799], [52, 1, 176, 65, 51, 17, 40, 1668, 74, 336], [52, 61, 6, 14, 217, 1, 52, 1048, 6, 430, 286, 11, 2709, 572, 3954, 36, 19, 35, 435, 69, 49, 7800, 8, 1388, 14511], [52, 13, 954, 256, 213, 206, 81, 108, 6, 10, 306, 26, 114, 10, 674, 2474, 461, 4403, 13, 1, 5, 87, 6, 2143, 1769], [52, 70, 362, 31, 15, 422, 21, 4, 1], [52, 56, 205, 15, 546, 937, 7801, 31, 5, 67, 17, 18, 20, 323, 7155, 527], [52, 248, 52, 121, 52, 48, 58, 14512, 21, 393, 882, 130, 546, 3673, 7801, 13, 14513], [235, 344, 6, 4, 503, 83], [465, 4, 95, 18, 4, 850, 14514, 3, 484, 1026], [566, 3, 19, 27, 76, 1, 92, 5, 214, 840], [566, 60, 93, 1199, 225, 8, 32, 3, 146, 72, 12, 648, 12, 2, 1], [566, 7, 1, 4610, 1162, 21, 76, 900, 25], [566, 76, 1543, 81, 3, 566, 76, 1, 6581, 3, 456, 14, 58, 256, 117], [566, 5, 146, 154, 83, 94, 97, 7802, 35, 1265, 7, 15, 70, 17, 3955], [2536, 30, 145], [2536, 30, 145, 34, 69, 427, 92, 14515], [1136, 1], [14516, 53, 31, 2, 1, 176, 167, 20, 25, 7803, 15, 140, 52, 96, 1182, 50, 53], [14517, 47, 2, 2200, 8, 21, 57, 2437], [286, 3, 442, 5, 99, 55, 3, 96, 65, 93, 23, 5326, 130, 470, 39, 9], [286, 576, 66, 29, 19, 125, 43, 5376, 5, 63, 113, 80, 1, 66, 60, 379, 613, 774], [286, 221, 7, 1, 276, 61, 3191], [286, 5257, 36, 167, 281, 1017, 581, 25, 14518, 3413, 68, 114, 2, 901, 88, 14519], [625, 9], [625, 33, 748, 17, 60, 1493], [1687, 732, 111, 10, 226, 12, 3399, 14520, 8, 3, 195, 2, 308, 864, 16, 95, 4641], [1687, 3956, 5, 1555, 1, 5, 43, 475, 4927, 107], [1687, 154, 5008, 3, 195, 978, 64, 158, 69, 12, 99, 950, 6, 1800, 2, 7804, 3957, 11, 14, 2, 14521, 7805, 781, 21, 14522], [1687, 8, 6, 76, 1, 53, 3, 33, 67, 170, 6, 176, 76, 308, 6, 84, 14523], [547, 17, 3113, 35, 4, 4642, 16, 19, 20, 14524, 17], [50, 919, 12, 3151, 3, 309, 42, 63, 44, 32, 10, 14525, 3, 29, 110, 13, 190, 1052, 2027, 3, 502, 50, 32, 16, 4056], [50, 24, 656, 34, 40, 856, 14526], [50, 24, 37, 93, 13, 3, 440, 256], [50, 24, 14527, 88, 60, 1241, 2463, 40, 14528, 3, 467, 4, 237, 1402], [50, 24, 631, 3, 79, 15, 7806, 591], [135, 3, 61, 1073, 6, 4, 815, 3723, 14529, 30, 3, 94, 11, 2, 5302, 38, 3, 19, 879, 11, 5, 13, 2, 1482, 282], [135, 60, 7807, 5737, 21, 5, 22, 12, 71, 5738, 230, 3, 2583, 2, 83], [135, 22, 1, 61, 188, 55], [135, 22, 25, 61, 148, 991, 682, 9, 14, 1412, 32, 7, 30, 34, 14, 541, 13, 4643], [135, 66, 61, 348, 135, 66, 61, 1659, 1659], [135, 66, 61, 22, 203, 1, 192, 81, 8, 92, 103, 105, 139], [135, 78, 9, 61, 4644, 14530, 45], [135, 2, 299, 5, 29, 44, 2, 1987, 426, 20, 2, 196, 183, 1, 281], [403, 3585, 31, 621, 12, 454, 57, 4, 190, 7808, 18, 4, 108, 16, 4, 7809, 21, 160, 15, 21, 412, 7, 44, 1159, 2, 2098], [403, 20, 2, 158, 683, 82, 166, 202, 11, 4, 2025, 18, 71, 6, 14531, 630], [403, 408, 12, 22, 2, 93, 1228], [403, 325, 1076, 120, 91, 79, 17, 2, 158, 38, 3, 210, 729, 143, 676, 18, 817, 52, 46, 1023, 6, 14, 2470, 1421], [403, 14532, 33, 597, 35, 3807, 5, 330, 62, 14533, 8, 14534, 49, 11, 15, 21, 4, 14535, 139, 27, 4, 529, 1430, 90, 5199], [403, 14536, 229, 14537, 127, 5646], [403, 1, 151, 14, 11, 6715, 390, 37, 5351, 4, 3632], [403, 326, 4, 120, 3295, 1130, 137, 22, 14538, 18, 4, 699, 16, 14539, 51, 4645, 14540, 61, 6, 14, 2, 14541], [403, 31, 3, 7810, 2, 3054, 14542, 8, 4521, 612, 8, 901, 15, 118, 3, 14543, 14, 3431, 74, 33, 485, 191, 21, 2, 228], [403, 462, 63, 3, 191, 5, 2, 938, 85, 58, 78, 25, 14, 37, 7811, 564, 15, 14, 4, 832, 1, 125, 4, 4914, 25], [403, 2541, 51, 8, 47, 15, 1086, 38, 2514, 878, 3304, 2551, 117, 230, 4, 1575, 128, 51, 42], [403, 10, 3696, 22, 158, 64, 1422, 177, 191, 31, 3, 47, 70, 989, 2551, 641, 84, 2167, 19, 1225, 19, 1167], [403, 23, 152, 28, 60, 5497, 16, 95, 1356, 18, 10, 481, 14544, 27, 98, 14545, 7812, 43, 68, 58, 7, 117, 92, 117], [403, 111, 95, 194, 5, 58, 623, 116, 13, 2860, 599, 2860, 16, 351, 406, 16, 1473, 18, 4, 1213, 117], [403, 5, 1, 11, 4, 14546, 139, 498, 10, 809, 5, 44, 43, 863, 11, 20, 5020, 33, 139, 3807], [7813, 14547, 22, 47, 10, 1851, 14548, 13, 19, 5, 1, 2397, 3779], [7813, 26, 29, 14, 13, 2, 185, 120, 1, 11, 60, 4528, 629, 191, 6, 869, 82, 747, 60, 14549, 14550], [84, 159, 119, 3521, 1468], [4178, 4178, 9], [314, 261, 12, 1715, 21, 4646, 632, 4, 19, 35, 8, 139, 14, 2, 141, 83, 7, 198, 14, 2, 1318, 493, 21, 10, 154, 569, 2160], [314, 88, 2, 1, 16, 76, 5739, 1028, 2298, 366, 1474, 3729, 27, 10, 25, 5334], [314, 88, 2, 9, 34, 137, 15, 14551], [314, 88, 2, 9, 194, 3513, 16, 1842, 606], [314, 88, 2, 9, 27, 1, 30, 5466], [314, 88, 2, 9, 167, 22, 1743, 21, 10, 25, 825], [314, 3958, 1, 7, 693, 23, 175], [2714, 913, 2, 1], [14552, 194, 3077, 16, 1260, 16, 4, 673], [14553, 14554, 26, 76, 1, 185, 18, 1009, 278, 19, 27, 7686, 5150], [84, 180, 30, 872, 84, 387, 12, 5197], [84, 1, 30, 2, 9, 30, 25, 700, 29, 28, 43, 24], [84, 1, 30, 12, 4, 199, 193, 37, 15, 29, 3813], [84, 1, 3012, 19, 17, 218, 52, 1465, 5740, 17], [84, 520, 152, 14, 13, 463, 46, 70, 2, 412, 23, 344, 1298, 53, 14555, 4, 2423, 109, 311, 1486, 14556, 14557], [84, 343, 37, 342, 125, 84, 7814, 231, 34, 84, 500, 1, 13, 7, 406, 6, 45, 13, 810, 15], [167, 2, 1, 27, 2, 347, 7298], [167, 84, 1, 23, 13, 7815, 23, 13, 43, 15, 407, 17], [167, 15, 8, 433, 15, 444, 7, 24, 14558], [167, 17, 35, 27, 893, 312], [167, 17, 27, 893, 14559, 312], [167, 10, 347, 27, 246, 728, 8, 151, 14, 32, 129, 20, 30, 11, 43, 106, 83], [4395, 210, 1056, 254, 63, 4077, 31, 2, 158, 174, 1422, 3013, 42, 11, 4, 606, 57, 2932], [2111, 735, 57, 5, 28, 459, 7, 5, 26, 80, 177, 12, 60, 24, 534], [167, 287, 12, 329, 2366, 34, 1, 28, 999, 14560, 35, 98, 1597, 6, 14, 352, 2172, 38, 36, 152, 450, 7], [4125, 155, 1, 3, 19, 125, 12, 2, 9, 105, 704, 2, 112, 275, 11, 10, 164], [14561, 30, 32, 1485, 1209, 12, 14562], [2147, 2041, 1141, 34, 38, 3, 349, 35, 15, 954, 166, 153, 125, 97], [9, 1, 208, 35, 3, 227, 890, 4346], [9, 46, 1863, 19, 2, 25, 108, 88, 5, 34, 32, 4, 1, 1863, 19, 2, 25, 92], [9, 32, 18, 10, 3189, 20, 1, 7816, 40, 2523, 14563, 14564], [9, 156, 924, 9, 21, 14, 319], [9, 156, 72, 25, 9, 34, 36, 14, 4, 9], [9, 156, 238, 72, 36, 65, 13, 2, 1120, 749, 43, 1, 5, 13, 4, 166, 9, 7, 64, 18, 14565, 400, 80, 339, 30, 142], [9, 8, 765, 9, 1856], [9, 14, 316, 36, 228, 224, 36, 25, 8, 36, 25, 450, 35, 19, 27, 4, 1, 228, 8, 4, 1, 29, 110, 636], [9, 14, 13, 3153, 14, 14566, 36, 14, 4, 9, 7, 14, 13], [9, 14, 13, 10, 25, 75, 44, 43, 1928, 34, 7, 71, 52, 563, 80, 30], [9, 14, 70, 987, 14567, 81, 133, 4078, 137, 14568, 1, 5, 62, 5, 47, 686], [9, 14, 14569, 153, 1138, 636, 147, 2015], [9, 28, 11, 22, 1, 188, 81, 59, 1555, 45, 188], [9, 276, 156, 14, 9, 74, 44, 36, 9, 193, 51, 14570], [9, 276, 14, 9, 100, 76, 2305], [9, 223, 14, 9, 34, 7, 553, 10, 624], [9, 223, 14, 319], [9, 662, 125, 9, 218, 765, 41, 143, 199, 2371], [9, 538, 25, 69, 28, 5741, 6, 4, 446, 3, 266, 1337, 2, 1, 18, 31, 32, 3, 266, 12, 1780, 913, 15, 103, 14, 14571, 1113, 35], [9, 14572, 36, 14573, 38, 4, 25, 7, 3249, 4, 6966, 192, 3959, 76, 2, 161, 14574, 57, 42, 1159, 9, 2, 14575, 30, 25, 5742], [9, 103, 14, 9, 55], [9, 103, 14, 9, 579, 590, 103, 14576, 42, 62], [9, 103, 14, 9, 1147, 160, 1445, 26, 192, 361, 1461, 211, 1860, 7817], [9, 103, 14, 319], [9, 103, 157, 7818, 97, 91, 53, 73, 4, 3301, 11, 126, 1618, 88, 28, 214, 38, 5, 86, 36, 2, 2072], [14577, 14578, 4272, 14579], [14580, 14581, 1], [555, 32, 20, 179, 3354, 8, 5651, 2876, 2057, 5, 63, 6906, 17, 1482, 245, 921], [555, 35, 1103, 46, 51, 14582, 2242, 31, 52, 41, 4486, 21, 338, 2133, 7, 60, 9, 45, 94, 78, 37, 705, 6, 79, 6250, 646], [555, 35, 287, 338, 93, 435, 21, 60, 1083, 36, 297, 2, 25, 27, 43, 77, 448, 18, 610, 7, 52, 2159, 18, 14583, 9, 284], [3391, 2854, 4326, 427, 1489, 11, 4, 488, 11, 39, 849, 2734, 1, 49, 14584], [1084, 19, 36, 60, 859, 30, 1, 51, 14585], [1084, 1066, 120, 1, 27, 14586, 260, 6859, 344, 568, 1472, 168, 2904, 7819, 1, 485, 5, 198, 37, 1502, 271, 459, 4, 4604], [1084, 269, 466, 15, 1097, 225], [1084, 14587, 45, 3, 745, 132, 18, 610, 11, 2, 490, 1247, 23, 94, 406, 82, 13, 787, 449, 892, 281], [1084, 45, 4, 144, 1510, 16, 2701, 16, 14588, 1404, 7093], [337, 6, 813, 8, 5743, 5034, 8, 354, 8, 6975], [2426, 3891, 12, 727, 93, 27, 3223, 18, 4, 234, 27, 353], [2569, 8, 7023, 438, 27, 14589, 14590], [1061, 3, 86, 3, 118, 56, 7, 379, 720, 8, 151, 19, 84, 83, 8, 151, 737, 84, 5373, 700, 565, 84, 183, 30, 381], [1061, 51, 22, 446, 3, 1592, 278, 19, 1518, 2069, 1046, 7, 1, 12, 2, 14591], [1061, 31, 4, 247, 14592, 590, 1, 191, 17, 6, 50, 2358, 23, 11, 7820], [1061, 15, 602, 89, 1, 11, 4, 1814, 21, 416, 14593, 1581, 14594], [2109, 30, 1, 238, 113, 17, 385], [689, 25, 8, 1, 64, 1217, 425], [293, 78, 636, 1497, 42, 119, 24, 42, 68, 1435, 423, 82, 4399], [293, 5, 258, 2, 1, 27, 60, 30, 7, 3960, 97, 87], [293, 22, 145, 303, 10, 14595, 1474, 149, 3, 67, 76], [1808, 1688, 2869, 1306, 8, 2105, 50, 5744, 7821], [1808, 2869, 11, 643, 2871, 136, 50, 206, 24, 5454, 123, 2, 14596], [1808, 79, 17, 191, 50, 6, 303, 50, 2, 467, 22, 561, 8, 88, 22, 3523, 294, 11, 27, 2, 7822, 467, 11, 50, 402], [1808, 14597, 28, 268, 968, 1750, 11, 14598], [1808, 2424, 1059, 11, 2, 14599, 136, 50, 24, 714, 14600], [1766, 849, 83], [1652, 136, 37, 239, 56, 2153], [71, 3, 257, 35, 4, 24], [71, 23, 614, 6, 62, 5, 48, 33, 2, 4647, 391, 31, 2805, 41, 2, 2189, 10, 91], [71, 1939, 152, 479, 35, 4, 466, 211, 2, 1228, 8, 1, 6, 14601, 8, 4, 3551, 3819, 461, 28, 2, 965], [71, 59, 2, 3867, 11, 1338, 629, 27, 14602, 14603, 73, 159, 8, 3412, 5745, 73, 7372, 26], [71, 49, 8, 3, 614, 81, 45, 59, 1, 30, 92, 7, 52, 136, 2, 14604, 2251], [71, 49, 5, 152, 14, 2, 187, 6, 20, 228], [71, 133, 76, 786], [71, 63, 3, 48, 114, 10, 1907, 108, 82, 153, 38, 153, 47, 114, 10, 1907, 193, 14605], [71, 63, 2, 414, 114, 42, 686, 38, 20, 2, 9, 3, 196, 71, 63, 2, 25, 114, 5, 686, 38, 20, 2, 9, 55, 2922], [71, 63, 2653, 405, 15, 34, 37, 209, 187, 103, 1775, 2077, 15, 74, 61, 18, 7823, 6, 28, 254, 198, 14, 2, 172, 3131, 3712, 11, 1495, 5746], [71, 63, 5, 72, 5, 29, 67, 2, 25, 7, 1565, 34, 20, 24, 12, 13, 7445, 4, 1565, 2782], [71, 107, 3, 266, 1646, 34, 258, 106, 21, 2, 1], [71, 222, 5, 58, 22, 6, 17, 1], [71, 222, 5, 58, 22, 6, 14606, 1], [71, 143, 810, 66, 223, 442, 7, 5, 54, 135, 506, 2839, 125, 60, 537, 30, 543, 153, 42, 46, 3575, 45], [71, 200, 3, 28, 861, 27, 4, 360, 796, 187, 21, 2, 746, 3, 33, 131, 644, 4, 187, 18, 739, 8, 471, 50, 344, 6, 286], [71, 58, 3, 113, 22, 5747, 7, 23, 238, 19, 50, 117, 11, 4, 24], [71, 58, 191, 2, 1383, 6, 33, 119, 50, 24], [71, 58, 5, 7346, 217, 18, 3961, 171, 1, 626, 17], [71, 58, 5, 61, 6, 376, 51, 264, 1, 31, 23, 48, 4, 68, 376, 27, 6533], [71, 58, 5, 3639, 20, 228, 80, 1, 57, 35], [71, 58, 5, 3517, 630, 8, 96, 14, 183, 7, 13, 359, 18, 959, 8, 96, 14607, 14, 1811, 1], [71, 2009, 16, 2, 187, 12, 6, 1463, 7, 642, 2187, 14608, 12, 48, 14609, 127, 14610, 130, 14611, 18, 5059], [71, 52, 420, 11, 2, 712, 392, 16, 43, 71, 52, 271, 1148, 11, 2, 712, 392, 16, 9], [71, 12, 1076, 95, 4, 629, 61, 6, 197, 374, 33, 3853, 95, 235], [71, 12, 7, 48, 2, 190, 18, 14612, 21, 392, 18, 481, 1571, 4, 2286], [71, 358, 211, 4, 786, 396, 126, 14613, 103, 32, 7191, 14614, 226, 14, 14615, 529, 8, 3962, 1775, 245, 299], [71, 358, 49, 36, 61, 6, 100, 4, 902, 11, 1475, 139, 24, 14616, 26, 5279, 76, 123, 766, 196, 3146], [71, 239, 781, 44, 7824, 167, 5, 44, 6, 157, 11, 4, 1514, 21, 237, 232, 1269, 84, 518, 2389, 254], [71, 239, 106, 5, 9, 65, 51, 10, 406, 2, 115], [71, 14617, 106, 4, 1145, 709, 1145, 555, 15, 142, 25, 1, 430], [71, 10, 5086, 276, 79, 17, 53, 111, 53, 13, 272, 1321, 145, 6, 50, 92, 251, 26], [71, 92, 6221], [71, 40, 271, 1148, 27, 2, 712, 392, 16, 9], [71, 364, 5, 208, 13, 2, 1], [71, 4, 286, 47, 2862, 3138, 167, 48, 2, 337, 298, 1113, 129, 4, 190, 2658, 246, 14618, 780, 7825, 251], [71, 22, 183, 30, 25, 28, 127, 24, 130, 17], [71, 42, 62, 42, 29, 28, 112, 164, 285, 101, 14619, 133, 50, 14620, 20, 706, 40, 63, 3963, 10, 706, 3241], [71, 78, 2556, 74, 110, 1182, 7, 1, 30, 25, 12, 2239, 10, 14621], [71, 5, 345, 13, 2, 1, 155, 106, 17, 166, 1830, 408, 44, 1565, 1726], [71, 5, 810, 21, 1278, 34, 42, 48, 2, 9, 8, 71, 23, 61, 6, 538, 42, 31, 20, 7826, 291], [71, 5, 223, 436, 2, 1, 7, 100, 25, 735, 18, 50, 235, 11, 775], [71, 5, 152, 168, 10, 226, 288, 5, 2041, 24, 578, 55], [71, 5, 33, 276, 192, 60, 780, 8, 122, 6, 421, 35, 7, 91, 337, 21, 787, 3065, 151, 204, 7, 9, 21, 4346, 3849], [71, 5, 13, 76, 1232, 5, 2626, 1], [71, 5, 2478, 282], [71, 5, 65, 13, 180, 89, 779, 34, 70, 501, 16, 2, 322, 1, 583, 162, 36, 58, 7, 51], [71, 5, 742, 34, 75, 5512, 1, 6, 97, 451, 157, 4, 2947, 142, 1669], [71, 5, 271, 1148, 11, 2, 712, 392, 16, 9], [71, 5, 5005, 1, 18, 135], [71, 22, 1, 255, 314, 5194, 117, 92], [71, 197, 1], [3964, 14622, 152, 14, 18, 164, 608, 96, 525, 24], [3964, 14623, 136, 259, 4, 164, 7, 247, 16, 263, 435, 101, 651, 4648, 4, 91, 12, 14624, 8, 96, 525, 32, 4, 24, 52, 14625], [1420, 74, 605, 7827, 15, 134, 5, 2, 1097, 858, 5748], [14626, 32, 2785, 5749, 187, 2604, 14627, 644, 21, 4, 14628], [2792, 395, 48, 2, 282, 14629, 237, 14630, 2217, 4, 4534, 352, 63, 44], [807, 73, 14631, 628], [807, 88, 2, 9], [7828, 12, 3923, 6, 138, 543], [7829, 9, 11, 4, 331, 26, 36, 32, 3616, 194, 381, 30, 14632, 466, 1404, 432, 94, 2, 7830, 149, 36, 291, 73, 286, 201, 507, 2778, 784, 291, 74, 865], [1867, 35, 25, 22, 4, 215, 1250, 36, 29, 636, 162, 4, 7831, 1498, 51, 6, 28, 11, 7, 1, 5, 87, 2, 1178, 1250], [1867, 35, 25, 22, 4, 215, 1250, 36, 29, 62, 162, 4, 7831, 1498, 51, 6, 28, 11, 7, 1, 5, 87, 2, 1178, 1250], [2734, 46, 21, 326, 519, 233, 383, 13, 2045, 153, 75, 2667, 74, 137, 1231, 2045, 153, 75, 2734], [2490, 141, 1], [3, 14633, 8, 12, 4, 69, 1465, 24, 11, 4, 14634, 3, 195, 1622, 20, 436, 27, 715], [3, 29, 19, 125, 14635, 5, 161, 185, 30, 1], [3, 2143, 75, 397, 141, 187, 7, 1053, 2, 148, 2897, 18, 71, 4, 150, 59, 256, 18, 3928], [3, 3, 745, 194, 2, 419, 1510, 16, 4589, 23, 194, 4, 7832, 22, 490, 385, 3, 196, 4, 822, 16, 590], [3, 477, 6, 1095, 274, 68, 106, 92, 23, 14636, 43, 1, 5750, 20, 13, 1682, 271, 5751, 4, 1095, 1537], [3, 64, 10, 546, 26, 473, 34, 247, 115, 36, 1093, 17, 85, 1809, 829, 12, 1768, 790, 11, 1068, 3, 346, 10, 4854, 4321, 107, 337, 1494], [3, 47, 142, 21, 2, 691, 76, 1, 440, 2, 25, 76, 9, 911, 59, 17, 13, 36, 1161, 704, 2, 25], [3, 1064, 64, 10, 7214, 1804, 57, 66, 61, 539, 7, 10, 1], [3, 428, 28, 18, 27, 14637, 8, 86, 40, 109, 417, 1102, 20, 37, 268, 231, 8, 1, 59, 50, 32, 4, 4085], [3, 428, 33, 90, 4, 1, 18, 135], [3, 3200, 39, 1], [3, 46, 556, 376, 1, 15, 885, 5752, 38, 5, 1056, 14638, 563, 17, 51, 4, 503], [3, 46, 1161, 279, 57, 585, 1, 124, 6, 72, 133, 17], [3, 46, 2, 1854, 34, 29, 842, 307, 2806, 12, 13, 4, 2466, 3082, 244, 6, 28, 24], [3, 46, 1491, 6, 311, 2, 1, 74, 458, 2, 7833, 74, 7600], [3, 46, 132, 6, 4, 1847, 371, 3, 47, 13, 885, 8, 3, 745, 67, 6, 61, 371, 88, 519, 21, 60, 2437, 99, 239, 158, 21, 17], [3, 46, 133, 6, 477, 6, 22, 25, 742, 59, 119, 24], [3, 46, 303, 43, 24, 3, 41, 99, 239, 253, 21, 7], [3, 46, 1354, 43, 1, 7, 54, 135, 448, 352, 4649, 34, 485, 23, 33, 511], [3, 46, 311, 10, 343, 21, 42, 9, 51, 7631], [3, 46, 29, 5417, 35, 1], [3, 46, 110, 62, 120, 77, 124, 93, 24, 13, 147, 14639, 14640, 36, 99], [3, 46, 7456, 14, 1020, 35, 5753, 755, 2, 115, 257, 10, 138, 21, 2, 2899, 663, 69, 54, 135, 19, 351, 360, 285], [3, 46, 61, 6, 629, 9, 66, 344, 14641], [3, 46, 41, 43, 9], [3, 46, 41, 43, 24, 74, 441, 23, 18, 7, 1, 249, 10, 138, 2093], [3, 46, 41, 43, 409, 89, 1, 12, 4, 101, 184, 3, 2226], [3, 46, 41, 106, 21, 2, 9, 113, 50, 907, 11, 4, 792, 26, 242, 4, 7834, 277], [3, 46, 43, 1, 43, 127, 3, 41, 10, 14642, 717], [3, 46, 109, 1070, 59, 4, 169, 80, 7, 45, 1577, 107, 13, 2, 1, 24], [3, 46, 3247, 5, 319, 62, 147], [3, 46, 81, 4203, 310, 4647, 66, 344, 14643, 432, 131, 61, 6, 4, 629, 1, 66, 14644], [3, 46, 122, 6, 19, 83, 3, 33, 67, 5292], [3, 46, 214, 51, 5, 1, 7, 57, 9, 58], [3, 46, 214, 51, 5, 7, 57, 9, 58], [3, 46, 105, 124, 2, 2825, 27, 43, 166, 1, 129, 2, 25, 31, 1118, 80, 25, 431, 23, 1944, 602, 99, 61, 258, 17, 246], [3, 46, 43, 3244, 34, 29, 842, 17, 2806, 12, 4, 2466, 3082, 244, 6, 525, 24], [3, 46, 72, 5, 2, 1, 34, 5, 14, 208, 13, 2, 275, 6946], [3, 603, 257, 7, 1, 562], [3, 603, 202, 5247, 141, 187, 47, 974, 10, 14645, 8, 66, 29, 974, 14646], [3, 603, 920, 22, 595, 355, 1, 2260], [3, 603, 795, 18, 2, 95, 298, 224, 4, 1352, 585, 36, 49, 37, 2504], [3, 603, 47, 417, 14647, 88, 3, 623, 111, 87, 6, 4381, 35, 8, 139, 14, 270, 1393, 1], [3, 330, 328, 132, 1459, 18, 1126, 123, 60, 9], [3, 330, 62, 23, 59, 6, 303, 37, 239, 1, 467, 390, 7, 151, 105, 19, 34, 164, 32, 59, 167, 8, 14648, 146, 114, 1180], [3, 330, 62, 2090, 223, 9, 790, 18, 100, 17, 223, 28, 10, 5624], [3, 330, 62, 5, 56, 31, 14, 2292, 12, 18, 4, 1304, 16, 184, 5, 67, 11, 2, 2461], [3, 560, 124, 2, 651, 7, 3, 363, 6, 4, 1793, 229, 8, 1793, 47, 1395, 6, 17, 8, 47, 28, 6576, 167, 18, 123, 60, 3386], [3, 156, 1559, 356, 59, 2, 418, 79, 17, 14649, 372, 643, 8, 32, 34, 1, 5, 87, 6, 61, 8, 258, 20, 14650], [3, 156, 477, 6, 179, 30, 742, 38, 3, 28, 542, 21, 1231, 3965], [3, 156, 65, 13, 270, 2, 1], [3, 156, 64, 38, 8, 3, 7294, 59, 1], [3, 156, 14651, 147, 3, 136, 1091, 288, 253, 913, 207], [3, 156, 67, 2, 1450, 381, 76, 9, 656, 19, 2, 2380], [3, 195, 2, 232, 123, 1809, 8, 259, 209, 16, 10, 164, 11, 7835, 3, 94, 43, 5232, 11, 822, 16, 2331], [3, 195, 2, 4519, 481, 1687], [3, 195, 1254, 168, 2, 190, 6885, 7, 12, 599, 79, 1840, 1685, 21, 22, 1552, 16, 26, 1064, 5314], [3, 195, 2420, 611, 6, 44, 6, 1124, 7, 60, 16, 4, 237, 5754, 5755, 2983, 3683, 44, 132, 2290, 123, 377], [3, 195, 21, 1805, 11, 4, 997, 21, 32, 111, 120, 202, 355, 190, 8, 7836, 2460, 14652, 219, 3, 1552, 4, 14653], [3, 195, 4909, 913, 2, 1], [3, 195, 2112, 11, 22, 1], [3, 195, 48, 20, 234, 1, 43, 2760], [3, 195, 54, 3, 75, 477, 6, 852, 1, 59, 184, 52, 200, 1399, 8, 113, 470, 14654, 20, 14655, 655, 165], [3, 195, 37, 148, 328, 799, 27, 9, 27, 2749, 5013, 4194, 7837, 3, 29, 2800], [3, 195, 270, 2, 803, 77, 15, 284, 3, 103, 405, 2, 1, 11, 2, 710, 129, 10, 586, 1669], [3, 195, 270, 2, 141, 1, 225], [3, 195, 270, 2, 24], [3, 195, 4, 112, 3288, 2157], [3, 195, 57, 42, 121, 3, 195, 34, 195, 46, 43, 1], [3, 3844, 22, 1253, 93, 24, 12, 2, 14656], [3, 191, 10, 268, 237, 228, 6, 2162, 17, 11, 1058, 324, 3, 28, 108, 7838, 30, 368, 8, 14657, 14658, 8, 14659, 3, 64, 10, 2243], [3, 191, 4, 226, 16, 4, 95, 5397, 14660, 168, 73, 4, 2192, 16, 274, 14661, 14662, 14663, 14664], [3, 672, 2, 2319], [3, 340, 37, 705, 6, 5612, 2, 1, 15, 611], [3, 340, 238, 1093, 39, 1, 188, 3, 724, 42, 2713, 325, 685, 1848, 3285], [3, 1095, 25, 18, 71, 36, 1, 65], [3, 14, 1397, 125, 4, 1, 218, 2, 2108, 153, 365], [3, 14, 148, 31, 3, 61, 1926, 4061, 163, 28, 10, 30, 7839, 35, 3, 636, 827, 15, 65, 13, 1, 3, 137, 79, 16, 3384, 7696], [3, 14, 5316, 11, 37, 209, 148, 1645, 41, 1, 542, 6, 735, 15, 102], [3, 14, 1873, 14665, 14666, 14667, 14668, 14669, 7840, 14670, 2225], [3, 14, 675, 54, 51, 470, 4, 1383, 18, 135, 7, 1580, 59, 71, 93, 36, 14671, 178, 4650], [3, 14, 13, 25, 5, 2, 112, 2873, 30, 1, 21, 7, 55], [3, 14, 1671, 1, 2034, 55], [3, 14, 1045, 3, 44, 43, 9], [3, 14, 308, 11, 41, 39, 1, 13, 42, 18, 10, 172, 14672, 34, 3, 14, 109, 1841, 33, 18, 22, 169], [3, 14, 54, 7, 1, 27, 4, 705], [3, 14, 542, 6, 113, 2, 1, 242, 143, 19, 35, 55], [3, 14, 854, 23, 328, 7841, 744, 34, 88, 68, 16, 10, 228, 167, 17, 35, 13, 296, 146, 14673, 8, 101, 104, 227, 142, 351, 828], [3, 14, 4651, 5, 1, 11, 4, 792, 125, 20, 520, 34, 52, 14, 541, 13, 20, 586, 37, 3, 14, 387, 3029, 88, 135, 107, 1384, 2141, 30, 1214], [3, 14, 1509, 9, 513], [3, 14, 1226, 1, 71, 6, 1891, 4, 5739, 14674], [3, 14, 113, 14675, 451, 46, 14676, 146, 44, 2, 4577, 451, 1342, 14677, 353, 67, 6, 506, 256, 27, 20, 1511], [3, 14, 122, 2, 2489, 18, 6, 798, 98, 13, 327, 34, 1, 29, 14, 448, 43, 14678], [3, 14, 168, 39, 5756, 1], [3, 14, 304, 21, 2, 1, 6, 1465, 1877, 23, 1153], [3, 14, 597, 153, 35, 55], [3, 14, 597, 35, 18, 60, 154, 45, 13, 19, 7, 1, 45], [3, 257, 7, 24, 35, 35, 35, 35], [3, 257, 4, 24, 14679, 7842], [3, 671, 127, 16, 2, 1, 115, 123, 115], [3, 132, 28, 1, 10, 413, 164, 3, 132, 28, 169, 10, 413, 164], [3, 132, 28, 169, 3, 46, 475, 133, 2, 9], [3, 132, 28, 169, 3, 46, 475, 133, 2, 9], [3, 132, 28, 169, 3, 46, 475, 59, 2, 9], [3, 132, 784, 785, 60, 45, 82, 10, 25, 6, 10, 1, 36, 541, 13, 36, 131, 1868], [3, 132, 11, 3780, 1313, 1204, 579, 41, 201, 89, 9, 518], [3, 132, 11, 22, 3431, 371, 688, 23, 33, 238, 271, 3262, 21, 14680, 2102, 88, 3, 63, 3896, 22, 14681, 8, 460, 27, 4, 763, 16, 4, 490], [3, 132, 4633, 18, 4, 684, 178, 3, 1551, 670, 2, 194, 37, 3, 63, 19, 17, 2, 610, 9, 26, 1160, 572], [3, 132, 1021, 39, 9, 371, 14682], [3, 132, 6, 5108, 4490, 469, 74, 1547, 34, 69, 5077, 34, 777, 1945, 6, 39, 759, 26, 190, 2016, 1515], [3, 132, 193, 6, 2447, 18, 25, 23, 44, 6, 405, 60, 56, 6, 28, 1512], [3, 132, 27, 4, 199, 2577, 21, 2, 14683, 1, 50, 764, 3365], [3, 2020, 6, 511, 18, 7, 767, 14684, 385, 325, 1, 1102, 10, 767, 579, 122, 6, 249, 10, 14685, 46, 45, 643, 59, 7], [3, 4974, 80, 1, 129, 7, 85, 5, 214, 39, 25, 291, 7, 85, 3, 528], [3, 394, 52, 3492, 61, 284, 2422, 1, 1429, 7843], [3, 394, 31, 66, 424, 2, 186, 14686, 4652, 14, 51, 577, 14687, 339, 30, 1], [3, 394, 7, 25, 41, 1338, 21, 1012, 21, 794, 7762, 16, 14688, 1259, 14689, 149, 344, 204, 7, 9], [3, 394, 39, 1, 122, 6, 644, 17, 35], [3, 394, 42, 1050, 14690, 28, 193, 127, 24, 130, 1050, 14691], [3, 394, 66, 49, 152, 94, 292, 178, 4653, 781, 2202, 99, 33, 140, 111, 49, 7, 209, 16, 2, 187], [3, 394, 5, 86, 5, 2, 14692, 1828, 5028, 19, 104], [3, 1, 2, 320, 34, 15, 5001], [3, 1, 63, 113, 7, 23, 1812, 6, 24, 40, 541, 433, 15], [3, 1048, 2, 14693, 8, 363, 108, 6, 4, 2323, 8, 912, 7, 1], [3, 1048, 170, 2, 14694, 758, 21, 84, 457, 99, 3, 716, 131, 14, 2, 187, 8, 191, 21, 15, 108, 55], [3, 1048, 14695, 8, 14696, 3, 33, 87, 1795, 8, 385, 3, 87, 6, 303, 353, 8, 45], [3, 291, 260, 459, 84, 1021, 1706, 163, 227, 170, 173, 2, 24, 15, 47, 332, 34, 3, 200, 15, 92, 52, 229, 127, 150, 130, 2, 1722, 1102], [3, 79, 51, 577, 787, 106, 6, 70, 10, 343, 4454, 8, 39, 1, 29, 479, 2032, 380, 3, 44, 6, 139, 11, 6, 70, 98, 4454], [3, 14697, 11, 6, 197, 163, 1, 121, 36, 318, 48, 67, 17, 6, 61, 108], [3, 63, 14, 2, 1, 8, 23, 595, 27, 7], [3, 63, 14, 727, 14698, 29, 14, 2, 838], [3, 63, 19, 80, 1, 8, 5, 75], [3, 63, 3014, 7, 1079, 54, 16, 546, 16, 78, 1, 253, 307], [3, 63, 465, 95, 619], [3, 63, 465, 10, 306, 137, 567, 95, 11, 4, 259, 712], [3, 63, 465, 4, 95, 7844], [3, 63, 1280, 34, 3, 75, 1280, 7644, 13, 7, 154, 1280, 41, 37, 209, 11, 15, 7, 5, 222, 58, 5, 109, 146, 14, 11, 1471, 21, 254], [3, 63, 33, 644, 7, 9, 18, 739], [3, 63, 70, 2, 1, 1303], [3, 63, 70, 2, 2610, 72, 40, 3156, 7, 14699, 3, 63, 70, 2, 462, 72, 40, 3156, 7, 24, 30, 25, 7, 502, 50, 7, 260], [3, 63, 1161, 914, 10, 4654, 149, 3, 156, 468, 5126, 3, 63, 1161, 176, 43, 1, 218, 3, 157, 76, 9, 54], [3, 63, 48, 26, 103, 48, 19, 27, 39, 797, 30, 9, 43, 127, 188], [3, 63, 94, 97, 9, 26, 32, 16, 240, 5757], [3, 63, 578, 1229, 163, 24, 18, 10, 1200], [3, 63, 113, 38, 2045, 8, 3889, 111, 49, 448, 18, 2, 14700, 14701, 1447, 123, 4, 2447, 144, 2039], [3, 63, 227, 2, 9, 173, 2, 7845, 149, 3, 62, 71, 6, 2608, 7, 32, 126, 6681], [3, 75, 397, 98, 500, 7, 266, 100, 61, 13, 1, 28, 2, 164, 46, 357, 5758, 80, 30], [3, 75, 687, 27, 2, 1, 129, 2, 2400], [3, 75, 442, 23, 1176, 32, 3, 63, 86, 12, 1378, 2082, 1, 47, 11, 20, 712, 6, 114, 2, 327, 16, 5, 11, 618, 27, 20, 758, 14702, 2129], [3, 75, 442, 7, 217, 2347, 230, 4, 629, 6, 4, 1816, 7, 3147, 510, 21, 4, 952], [3, 75, 442, 39, 179, 19, 440, 22, 141, 265, 244, 6, 307, 52, 92, 137, 27, 19, 2049, 5759, 16, 84, 2273, 14703], [3, 75, 442, 22, 25, 273, 17, 6, 157, 7846, 18, 2, 1, 230, 5, 119, 50, 54], [3, 75, 665, 2115, 74, 14704, 23, 339, 726], [3, 75, 1182, 39, 9, 74, 39, 291, 25], [3, 75, 110, 14, 423, 82, 10, 310, 7, 358, 4598, 117, 40, 12, 2, 284, 1], [3, 75, 110, 258, 15, 11, 17, 6, 382, 2027, 22, 12, 14705, 22, 2793, 609, 12, 7847, 367, 6722, 3, 5395], [3, 75, 182, 119, 2313, 990, 1046, 461, 1265, 133, 991, 682, 14706, 267, 2, 320, 14707], [3, 75, 2130, 71, 209, 3, 90, 1620, 52, 12, 123, 750, 402, 142, 43, 938, 191, 10, 577, 443, 2220, 37, 1, 216], [3, 75, 19, 2, 939, 282], [3, 75, 19, 245, 802, 1, 25, 14, 4314, 138, 54, 135], [3, 75, 19, 27, 77, 7, 81, 59, 126, 24, 18, 685, 7848], [3, 75, 19, 27, 9, 25, 3, 75, 302, 39, 9, 14708], [3, 75, 19, 27, 5, 43, 1091, 9, 8, 23, 7849], [3, 75, 806, 38, 111, 134, 17, 98, 764, 3, 544, 76, 37, 5760, 13, 85, 58, 5, 44, 6, 14, 2, 530, 1], [3, 75, 105, 14, 43, 1, 25, 7, 71, 5, 28, 557, 13, 2, 1], [3, 75, 137, 567, 1187, 15, 70, 17, 7850], [3, 75, 376, 37, 272, 194, 3611, 8, 119, 353, 8, 3167, 2101], [3, 75, 397, 2, 181, 1, 13, 810, 28, 54, 116, 26, 70, 4, 169], [3, 75, 397, 2, 6980, 861, 35, 1], [3, 75, 397, 22, 203, 1, 244, 6, 17, 27, 50, 1031, 30, 645, 605, 5761], [3, 75, 397, 6, 94, 10, 500, 27, 246, 183, 1], [3, 75, 114, 80, 1, 31, 3, 75, 94, 80, 836], [3, 75, 114, 5, 9, 686, 140, 40, 474, 2, 25, 87, 11, 2, 7435, 60, 16, 78, 33, 65, 93, 26, 7, 254], [3, 75, 114, 5, 686, 31, 5, 255, 207, 14709], [3, 75, 81, 6, 621, 34, 5, 63, 61, 729, 14710, 79, 82, 20, 141, 1, 18, 4, 702, 11, 4, 3966, 1449], [3, 75, 113, 31, 3, 67, 6, 19, 5, 74, 31, 3, 67, 6, 935, 20, 977], [3, 75, 113, 5, 4, 215, 106, 3, 297, 201, 638, 44, 2, 290, 34, 3, 94, 1, 290, 18, 496, 5619], [3, 75, 302, 2, 1], [3, 75, 304, 6, 448, 4, 1953, 16, 10, 154, 14711, 758, 2557, 8, 1100, 198, 44, 4, 1239, 382, 35, 328, 2199, 374, 4181], [3, 75, 304, 6, 5762, 27, 10, 1, 26, 3, 346, 76], [3, 75, 304, 6, 194, 4, 2602, 157, 126, 4462, 117, 11, 4, 1739, 971, 26, 2118, 12, 56], [3, 75, 194, 159, 2921, 3060, 140, 3, 345, 13, 2, 141, 2727, 14712, 7851, 817], [3, 75, 27, 39, 710, 521, 1], [3, 75, 27, 22, 974, 30, 1], [3, 2053, 14, 475, 133, 43, 1, 149, 3, 62, 2, 1, 222, 14, 1504, 249, 2, 138, 14713], [3, 2053, 2130, 71, 6983, 165, 4, 1177, 12, 6, 22, 248], [3, 75, 948, 125, 43, 1, 7, 1812, 6, 14714], [3, 778, 1407, 129, 9, 149, 3, 105, 704, 2, 831, 3, 46, 13], [3, 359, 18, 5763, 16, 4, 1, 3, 124, 364, 55, 357, 110, 67, 6, 14, 32, 1694, 8, 45], [3, 107, 125, 4, 728, 18, 622, 63, 28, 429, 18, 480, 190, 5764, 199, 207, 73, 2796], [3, 14715, 23, 7390, 74, 2180, 3, 299, 47, 444, 13, 14716], [3, 670, 2, 6389, 34, 3, 87, 60, 1731, 21, 7, 1], [3, 222, 105, 316, 531, 6, 1181, 2, 1, 74, 25, 7, 255, 326, 499, 45, 13, 2074, 43, 20, 291, 26, 4379, 97, 948, 4655], [3, 222, 340, 54, 135, 13, 60, 16, 39, 14717, 4, 606, 6780, 24, 21, 2, 535, 831, 34, 23, 48], [3, 222, 3221, 32, 5, 386, 16, 1, 54], [3, 222, 61, 21, 2, 348, 117, 92], [3, 222, 44, 37, 239, 1, 117, 2704, 713, 36, 132, 64, 7852], [3, 222, 72, 10, 226, 14718, 97, 1, 330, 62, 15], [3, 2063, 14719, 3, 47, 4, 215, 1, 18, 5565, 798], [3, 487, 44, 43, 14720, 14721, 51, 10, 7853, 57, 2, 7666, 30, 1], [3, 487, 1160, 14722, 7, 175, 59, 2705, 260, 47, 110, 99, 1744, 21, 307], [3, 2359, 43, 9], [3, 1189, 80, 83, 20, 7854], [3, 311, 5, 54, 16, 10, 164, 21, 2, 540, 5, 185, 812, 29, 253, 17, 18, 7855], [3, 1038, 2, 1, 6, 1250, 10, 2474], [3, 1589, 41, 2, 607, 1691, 14723, 311, 10, 779, 5721, 116, 568, 10, 190, 5765, 55], [3, 857, 75, 1181, 2, 25, 7, 2556, 1399, 125, 1, 3, 29, 1181, 364, 5, 948, 14724], [3, 5145, 14725, 5, 46, 2647, 1, 5, 49, 2, 14726], [3, 200, 393, 21, 10, 1, 92, 39, 9, 101, 28, 332, 138, 2648], [3, 200, 474, 34, 302, 39, 9], [3, 200, 474, 1030, 302, 39, 9], [3, 210, 61, 6, 261, 135, 2696, 392, 16, 183, 9, 32, 10, 1562, 450, 35, 183, 211, 314, 261, 148, 1898], [3, 210, 110, 28, 6, 94, 10, 260, 1185, 251, 15, 32, 10, 306, 14727, 1948, 83], [3, 210, 14728, 32, 166, 1, 21, 10, 436, 6, 14, 28, 19, 18, 123, 246, 916, 8, 5, 62, 40, 791, 5, 146, 2754], [3, 210, 62, 10, 312, 14729, 124, 1912, 2, 937, 1535, 18, 68, 16, 84, 323, 281, 7, 284], [3, 210, 131, 94, 20, 9, 30, 406, 3379, 114, 279, 16, 20, 172, 265, 776], [3, 210, 303, 245, 2116, 22, 696, 8, 101, 1048, 787, 2191, 818, 7, 3, 96, 44, 1369, 14730, 1249], [3, 1138, 100, 357, 2324, 10, 385, 3, 100, 10, 504, 41, 10, 1513, 55, 794, 71, 42, 62, 40, 2685, 14731, 4656, 9, 75, 28, 2, 1568, 82, 17], [3, 58, 1628, 16, 19, 77, 34, 3, 29, 19, 14732, 3, 132, 11, 4, 199, 24, 371, 230, 3967, 510, 3101], [3, 58, 143, 2325, 11, 2, 3968, 225, 972, 14733, 8, 147, 1422, 125, 4, 1746, 343, 113, 17, 3, 14734, 52, 113, 17, 3, 46, 43, 1091, 1044, 913, 2, 269], [3, 58, 62, 68, 184, 464, 1, 36, 107, 36, 2631], [3, 58, 4, 45, 5, 1, 12, 99, 24, 6, 58], [3, 381, 9, 48, 68, 34, 32, 9], [3, 29, 81, 56, 3343, 4474], [3, 29, 176, 228, 36, 107, 8, 61, 29, 19, 27, 39, 1, 26, 365, 32, 36, 1507], [3, 29, 14, 345, 129, 1740, 1, 7, 440, 17, 21, 252, 27, 169, 1000, 7856, 751, 59, 254], [3, 29, 442, 11, 7, 14735, 45, 69, 827, 6, 44, 2, 1, 13, 147, 27, 42, 32, 4, 106], [3, 29, 924, 1780, 21, 48, 958, 27, 5, 604, 415, 81, 56, 59, 15, 13, 5, 58, 522, 2474], [3, 29, 303, 24, 218, 15, 351, 1, 3, 303, 14736], [3, 29, 279, 71, 341, 2, 1, 12, 31, 50, 395, 12, 45, 40, 385], [3, 29, 279, 71, 206, 3, 195, 38, 5, 157, 17, 11, 580, 16, 2, 558, 16, 14737, 151, 119, 7, 1], [3, 29, 279, 31, 20, 315, 14738, 133, 6, 17, 79, 17, 1063, 8, 14739, 8, 86, 45, 12, 7857, 3, 29, 110, 13, 77, 58, 760], [3, 29, 778, 43, 1, 33, 778, 10], [3, 29, 110, 137, 567, 95, 1046, 140, 19, 170], [3, 29, 1481, 125, 212, 14740, 69, 24, 165, 88, 2, 284, 1, 1302, 593], [3, 29, 150, 13, 32, 202, 111, 49, 158, 34, 31, 20, 202, 8, 20, 14, 2, 158, 571, 113, 5, 1153], [3, 29, 1841, 18, 1, 1, 1841, 18, 307, 7411, 123, 14741], [3, 29, 19, 125, 1, 7, 477, 6, 7, 5766, 45, 21, 60, 540, 76, 1, 14, 1412, 214, 2548, 8, 3, 13, 6, 497], [3, 29, 19, 125, 9, 25], [3, 29, 19, 125, 39, 1, 218, 36, 86, 36, 2274], [3, 29, 19, 27, 39, 25, 149, 36, 2762, 3, 29, 19, 27, 39, 1, 32, 36, 67, 12, 6, 44, 10, 260], [3, 29, 19, 27, 5, 4252, 14742, 78, 29, 157, 1293, 11, 10, 548, 78, 5767, 4, 199, 3, 58, 8, 1238, 4, 199], [3, 29, 28, 254, 23, 519, 2, 24, 74, 7858, 162, 12, 4, 712, 21, 1320, 7859, 8, 74, 1163, 1242, 18, 10, 14743, 685, 871, 19, 562], [3, 29, 28, 57, 397, 18, 97, 1011, 1109, 277, 21, 39, 327, 39, 9, 14, 114], [3, 29, 28, 85, 1, 924, 4, 9, 126, 91, 359, 18, 76, 14744, 47, 398, 126, 14745, 520, 2505, 121, 5768], [3, 29, 134, 2, 19, 59, 80, 4189, 80, 1039, 74, 80, 1567, 510, 135, 123, 531, 1, 23, 238, 1006], [3, 29, 7860, 325, 45, 34, 1, 3, 195, 57, 3, 195, 8, 15, 12, 57, 15, 12], [3, 29, 41, 43, 409, 89, 1, 12, 4, 101, 184, 7, 3, 14746], [3, 29, 41, 7, 89, 16, 2, 476, 58, 3, 19, 45, 30, 1, 187, 14747, 855, 2369, 1466], [3, 29, 44, 2, 436, 40, 10, 1, 21, 4, 1477, 31, 40, 47, 430, 481, 88, 15, 318, 14, 1417], [3, 29, 44, 98, 1074, 37, 3, 44, 6, 3969, 609, 39, 9], [3, 29, 44, 246, 231, 166, 130, 10, 1, 1511], [3, 29, 44, 9, 15, 2, 14748], [3, 29, 44, 43, 409, 233, 89, 1, 12, 4, 101, 184, 3, 13], [3, 29, 167, 287, 34, 278, 491, 364, 54, 2, 83, 43, 637, 2103, 624, 464, 7, 60, 14749, 385], [3, 29, 555, 150, 21, 10, 206, 14750, 3, 383, 1695, 384, 1, 11, 13, 10, 206, 3414], [3, 29, 543, 15, 27, 19, 264, 8, 1], [3, 29, 62, 57, 9, 2271, 2447, 16, 426, 3, 29, 5221, 11, 980, 45, 15, 37, 239, 3, 148, 1196, 75, 175, 461, 14, 2, 9], [3, 29, 62, 57, 5, 132, 273, 34, 3, 64, 76, 1969, 9], [3, 29, 62, 57, 127, 1040, 5679, 74, 567, 942], [3, 29, 62, 85, 1383, 551, 5351, 14751, 376, 9], [3, 29, 1507, 485, 15, 12, 2, 93, 1083, 8, 2, 93, 193, 6, 150, 34, 289, 297, 193, 99, 239, 1949, 14752, 1, 168, 7, 6696], [3, 29, 13, 2640, 91, 464, 3, 19, 84, 1, 14753], [3, 29, 13, 7, 83], [3, 29, 13, 5, 1, 37, 26, 23, 44, 2, 460, 32, 696, 10, 734, 61, 54, 16, 4614], [3, 29, 259, 21, 5, 9, 91], [3, 29, 64, 10, 9, 3, 64, 2, 535, 48, 32], [3, 29, 64, 39, 1, 74, 39, 319, 19, 36, 299, 3, 64, 10, 169], [3, 29, 64, 5, 319], [3, 29, 70, 451, 21, 25, 7, 29, 28, 1], [3, 29, 87, 43, 7861, 3, 87, 6, 28, 19, 314, 8, 28, 60, 285], [3, 29, 1632, 5, 45, 1, 338, 17, 771], [3, 29, 373, 245, 18, 3, 600, 44, 6, 28, 68, 615, 126, 154, 7553, 12, 3190, 11, 1714, 875, 1934, 14754], [3, 29, 2740, 74, 90, 26, 1719, 14755, 49, 3146, 234, 2471, 16, 26, 34, 14756, 51, 14757, 12, 2, 821, 19, 35], [3, 29, 157, 295, 433, 357, 38, 15, 107, 169, 163, 285], [3, 29, 538, 169, 188, 538, 112, 153], [3, 29, 81, 6, 153, 3, 81, 6, 274, 66, 63, 1342], [3, 29, 302, 43, 1, 188, 3, 381, 240, 54], [3, 29, 302, 39, 1], [3, 29, 594, 71, 5, 63, 14, 270, 2, 1], [3, 29, 594, 38, 111, 72, 14758, 10, 250, 106, 366, 3, 210, 28, 4074, 149, 148, 7, 172, 249, 321, 3, 47, 144, 314], [3, 29, 594, 85, 36, 214, 51, 50, 70, 2, 1345, 7, 3432, 7558, 59, 5, 14759, 32, 4, 9, 26, 1, 1345, 59, 275], [3, 29, 67, 2, 1, 7, 2, 25, 330, 124, 3, 67, 2075, 154, 188, 74, 2, 7862, 15, 99, 1016, 25, 3, 1273, 4, 1611], [3, 29, 67, 2, 1, 7, 14760, 1], [3, 29, 67, 17, 43, 93, 77, 3, 976, 3929, 27, 39, 1125, 9], [3, 29, 67, 43, 3299, 3024, 55, 593, 1], [3, 29, 67, 43, 4655, 9, 74, 43, 1965, 77], [3, 29, 67, 352, 1, 3, 101, 67, 97, 833, 1, 55], [3, 29, 67, 6, 799, 27, 1157, 56, 116, 2, 540, 15, 41, 3433, 54, 11, 4, 250, 507], [3, 3854, 14761, 480, 682, 1, 103, 44, 954, 7863, 262, 26, 96, 175, 14762, 6, 81, 3608, 233, 5, 1, 12, 459, 829], [3, 3083, 398, 16, 10, 14763, 14764, 2358, 472, 6, 1328, 69, 487, 1800, 6, 303, 1155, 29, 14, 2, 1948, 83], [3, 328, 132, 6, 4, 503, 3, 328, 3896, 4, 14765, 8, 27, 7, 14, 121, 95, 5769, 103, 105, 58], [3, 328, 4959, 32, 698, 16, 45, 78, 153, 33, 1207, 45], [3, 328, 167, 133, 688, 1058, 54, 22, 1], [3, 328, 297, 2, 320, 16, 365, 385, 7, 1, 46, 89, 40, 5770], [3, 29, 110, 72, 25, 3, 72, 2157, 23, 13, 2677, 14766, 3, 72, 4, 158, 324, 461, 536, 129, 10, 14767], [3, 29, 19, 125, 9, 74, 291, 1], [3, 29, 134, 2, 419, 45, 69, 5, 49, 31, 5, 255, 2, 2611, 8, 120, 1984, 1568, 3, 195, 33, 61, 6, 1233, 5, 49, 2508, 726], [3, 29, 41, 43, 14768, 89, 1, 12, 4, 101, 1162, 7, 3, 13, 5, 46, 41, 43, 5771, 1833, 27, 4, 684, 8, 66, 58, 22, 155, 264], [3, 29, 869, 1, 23, 314, 38, 23, 11, 775], [3, 29, 605, 553, 16, 39, 9], [3, 29, 62, 2, 145, 7, 222, 1112, 21, 17], [3, 29, 64, 39, 9, 26], [3, 29, 780, 27, 3308, 574, 579, 36, 9, 2768], [3, 29, 453, 315, 111, 34, 4, 14769, 2398, 65, 51, 17, 272, 2826, 716, 315, 589, 307, 321, 33, 137, 125, 97, 517, 11, 5772, 432, 2800], [3, 29, 72, 19, 1, 28, 169, 140, 3, 64, 240, 398], [3, 29, 86, 289, 182, 297, 2, 290, 18, 4, 112, 3434, 3, 196, 2, 324, 290, 1530, 3435, 16, 3017, 34, 148, 7, 1, 7864], [3, 29, 594, 613, 111, 69, 472, 13, 56], [3, 3009, 2, 1, 123, 50, 343, 2216, 14770, 14771], [3, 651, 59, 44, 1883, 77, 2, 320, 447, 648, 3, 62, 15, 5, 1], [3, 472, 71, 3, 150, 31, 3, 1559, 13, 2, 1, 278, 472, 13, 68], [3, 484, 123, 8, 76, 1, 4404, 34, 77, 3, 75, 139], [3, 119, 979, 14772, 7865, 27, 2, 5773, 83], [3, 119, 4, 285], [3, 1293, 43, 145, 3, 302, 43, 14773], [3, 150, 89, 21, 32, 5, 1, 7, 44, 105, 132, 6, 5558, 360], [3, 150, 89, 21, 50, 153, 205, 188, 97, 77, 2, 9, 10, 153], [3, 150, 89, 44, 22, 2973, 34, 51, 4, 199, 106, 648, 2, 1], [3, 150, 155, 323, 3, 465, 12, 2, 5345, 6, 10, 1068, 21, 378, 575, 3325, 641, 246, 176, 11, 453, 4, 215, 323, 47, 24, 829], [3, 150, 13, 3, 41, 1, 491, 123, 14774], [3, 150, 13, 3, 198, 14, 611, 8, 32, 7, 24, 45, 34, 3, 195, 33, 37, 633, 117, 92, 552, 57, 23, 5748], [3, 150, 13, 2, 89, 1, 38, 3, 255, 10, 14775, 1434, 1708, 26], [3, 150, 13, 2, 1, 7, 33, 41, 50, 6541, 2, 115, 230, 50, 2242], [3, 150, 13, 2, 1008, 181, 596, 22, 758, 128], [3, 150, 13, 1880, 16, 4, 11, 1816, 13, 367, 1, 100, 7866, 81, 45], [3, 150, 13, 15, 276, 14, 2, 2460, 14776, 657, 325, 1, 1762, 25, 14777], [3, 150, 13, 491, 2, 1], [3, 150, 13, 7, 145, 4266, 39, 1, 644, 17, 562], [3, 150, 13, 22, 9, 1632, 17, 256, 233], [3, 150, 37, 4545, 3, 346, 10, 37, 1572, 3, 90, 4, 120, 56, 69, 999, 8, 204, 50, 8, 305, 14778], [3, 150, 370, 972, 25, 147, 4610, 70, 35, 45, 6, 308, 2195, 3, 118, 90, 6, 44, 6, 86, 7, 172, 1572], [3, 150, 370, 21, 953, 8, 668, 25, 36, 41, 4, 1128, 1471, 1, 18, 4347], [3, 150, 4, 370, 21, 4, 417, 111, 11, 22, 360, 140, 374, 428, 4, 7489, 15, 32, 5, 9, 8, 1034, 7, 4, 437], [3, 150, 14779, 726, 267, 180, 646], [3, 976, 11, 64, 125, 10, 234, 1, 284, 184, 40, 407, 110, 10, 1], [3, 290, 21, 57, 3, 64, 34, 5, 70, 256, 16, 1, 3, 86, 295, 4648], [3, 1244, 7, 31, 9, 131, 137, 178, 19, 240, 8, 338, 240, 513], [3, 258, 2, 154, 323, 3, 13, 8, 137, 7, 9, 193, 127, 106, 130, 3, 198, 2706], [3, 258, 15, 356, 2117, 71, 111, 103, 122, 8, 113, 5, 71, 5, 198, 259, 20, 1068, 13, 1, 271, 11, 10, 4405, 267, 5, 55], [3, 258, 15, 5425, 7, 3048, 12, 98, 2705, 2727], [3, 258, 15, 332, 6, 442, 14780, 999, 9, 15, 99, 1016, 6, 28, 76, 1277, 102, 38, 5, 1875], [3, 14781, 22, 2070, 45, 12, 356, 7867, 32, 71, 63, 22, 1, 86, 7, 40, 47, 81, 6, 1625, 583, 277], [3, 788, 147, 14782, 121, 810, 2, 1, 163, 363, 8, 200, 15, 361], [3, 253, 667, 2514, 30, 1, 18, 135], [3, 911, 71, 120, 56, 14783, 7868, 219, 15, 12, 14784, 14785], [3, 592, 4, 7869, 3025, 3025, 7870, 2402, 2449, 71, 4, 19, 277, 217, 751, 21, 473, 213, 8, 48, 3064, 51, 32], [3, 592, 20, 1291, 11, 7, 56, 14786, 8, 20, 645, 11, 4, 5532, 142, 123, 7, 14787, 198, 1557, 176, 165, 1345, 16, 20, 14788], [3, 82, 4, 1260, 16, 673, 1065, 7135, 2193], [3, 19, 2525, 1, 3364, 8, 1647, 1, 2, 535, 16, 14789, 1, 41, 109, 551, 8, 19, 2, 2078, 418, 2, 535, 14790], [3, 19, 89, 1, 6, 7871, 14791, 85, 5, 25, 466, 759, 13, 98, 7872], [3, 19, 1, 165, 194, 1533, 9], [3, 19, 27, 3970, 8, 84, 2968, 34, 2321, 5774, 5403, 12, 3084, 127, 6, 4, 1225, 2349], [3, 19, 4, 1, 3, 168, 6, 651, 59, 8, 2063, 309, 38, 3, 510, 82, 14792, 336, 3, 29, 301, 6, 569, 18, 50, 226, 7, 45, 12, 669], [3, 19, 4, 45, 54, 80, 1, 1157, 1062, 40, 487, 397, 344, 40, 79, 17, 3682, 191, 222, 40, 107, 8, 28, 2, 14793], [3, 19, 20, 141, 746, 215, 264, 4, 24, 47, 117, 4, 24, 47, 926], [3, 14794, 20, 1, 130, 502, 50, 2, 1795, 1440], [3, 172, 90, 22, 1, 768, 526], [3, 19, 90, 22, 19, 2323, 39, 172, 1, 44, 217, 129, 744, 14795], [3, 19, 90, 5, 158, 7572], [3, 2759, 2, 607, 1381, 2, 1, 65, 14796], [3, 14797, 18, 39, 25, 3, 41, 1069, 21, 32, 39, 9], [3, 502, 10, 2092, 10, 2316, 2387, 167, 3712, 7, 1, 12, 811, 3, 64, 10, 2316, 3712], [3, 28, 2, 1243, 1381, 558, 16, 797, 21, 4, 3728], [3, 28, 1, 18, 4800], [3, 28, 14798, 92, 7, 1, 375, 17], [3, 28, 127, 677, 130, 32, 5, 1], [3, 28, 37, 839, 11, 7, 24, 3, 881, 4, 108, 16, 50, 931], [3, 134, 10, 25, 293, 8, 506, 39, 1, 651], [3, 134, 102, 4, 1948, 141, 1, 1822, 34, 31, 5, 28, 6, 428, 62, 17, 3, 2464, 6, 157, 166, 230, 531, 1978], [3, 152, 192, 753, 1076, 283, 45, 12, 214, 2214], [3, 41, 14799, 16, 1234, 1157, 1581, 4, 95, 45, 11, 10, 14800], [3, 41, 201, 1, 31, 76, 1, 1431, 88, 714, 14801, 565, 240, 4, 2635, 5775, 1089, 4, 14802], [3, 41, 1212, 73, 26, 2, 340, 18, 10, 3064, 1193, 26, 3, 96, 14, 5128, 1130, 1, 28, 13, 17], [3, 41, 1569, 437, 8, 2, 1, 46, 7573, 40, 32, 1569, 3, 86, 3, 87, 2, 1341, 4618, 743], [3, 41, 1569, 437, 34, 2, 1, 46, 378], [3, 41, 1569, 437, 34, 2, 1, 46, 68], [3, 41, 1569, 437, 34, 2, 1, 46, 68, 40, 32, 1569, 16, 240, 3, 87, 2, 14803, 743], [3, 41, 1569, 437, 34, 2, 24, 30, 1, 46, 68, 1707], [3, 41, 2203, 64, 172, 1, 6, 7, 429, 45], [3, 41, 14804, 928, 21, 1813, 6, 134, 35, 10, 310, 39, 1, 63, 605, 10, 30, 149, 116, 48, 28, 15], [3, 41, 2, 6611, 201, 7873, 201, 14805, 201, 1541, 14806, 43, 14807, 91, 7, 1, 3877, 160], [3, 41, 2, 1840, 1, 50, 226, 5776], [3, 41, 2, 1081, 7, 3277, 188, 41, 2, 1, 11, 794, 14808], [3, 41, 2, 1190, 16, 206, 30, 1122, 32, 56], [3, 41, 2, 455, 1, 3, 41, 154, 9, 64, 10, 7704, 34, 3, 41, 10, 14809], [3, 41, 2, 14810, 14811, 253, 18, 610, 7, 415, 85, 39, 1, 46, 1823, 17, 686], [3, 41, 2, 346, 79, 82, 20, 1], [3, 41, 2, 256, 7, 389, 17, 201, 7829, 155, 449, 101, 112, 1, 636, 71, 6, 2081, 169], [3, 41, 2, 1003, 21, 5, 1], [3, 41, 2, 834, 30, 833, 1000, 1584, 3003, 74, 1494, 18, 39, 319, 75, 4188, 10, 470, 4188, 7874, 54, 22, 83], [3, 41, 2, 674, 539, 1603, 252, 41, 1443, 13, 180, 734, 3, 300, 32, 4, 161, 265, 382, 84, 294, 8, 52, 29, 110, 62, 15], [3, 41, 30, 2487, 18, 10, 120, 3401, 32, 39, 9, 176, 5153, 18, 17], [3, 41, 89, 1, 18, 397, 123], [3, 41, 1, 5678, 1465, 7875, 1501, 4, 2051], [3, 41, 1, 5777, 13, 2699, 6594, 125, 674, 14812], [3, 41, 1, 18, 10, 138, 36, 33, 46, 135, 478, 25], [3, 41, 1, 5598, 7, 32, 3, 4461], [3, 41, 537, 95, 403, 512, 13, 2206, 95, 403], [3, 41, 155, 540, 6, 150, 13, 23, 7, 1], [3, 41, 93, 5422, 37, 10, 1, 1789, 146, 1141, 588], [3, 41, 625, 9], [3, 41, 9, 3, 41, 172, 9, 3, 41, 172, 9], [3, 41, 9, 11, 511, 1890, 1803], [3, 41, 319, 3, 41, 319, 3, 41, 319, 3, 41, 319], [3, 41, 2110, 3, 41, 197, 3, 41, 1130, 10, 399], [3, 41, 169, 8, 9, 169, 8, 9], [3, 41, 127, 2440, 1345, 130, 775, 18, 10, 14813, 3, 1551, 1056, 39, 2198, 37, 3, 63, 549, 240, 18, 78, 9], [3, 41, 127, 302, 11, 692, 88, 39, 171, 30, 1], [3, 41, 10, 797, 5611, 60, 759, 3216, 21, 84, 1451, 147, 1, 487, 110, 467, 4116, 34, 42, 43, 429, 2116, 30, 142, 15], [3, 41, 10, 387, 18, 22, 355, 1006], [3, 41, 10, 453, 18, 10, 169, 32, 3, 87, 2, 89, 1, 37, 3, 63, 498, 657, 4, 620, 8, 1049, 22, 1278, 27], [3, 41, 10, 373, 3898, 1, 19, 78, 3898], [3, 41, 10, 373, 14814, 8, 2863, 4617, 38, 23, 133, 6, 879, 14, 96, 83], [3, 41, 43, 3971, 21, 9, 896, 564, 272, 139, 172, 125, 80, 30, 705, 5778], [3, 41, 43, 327, 35, 493, 3, 271, 18, 10, 1862, 3, 113, 2, 1, 32, 4, 106, 757, 28, 11, 10, 347, 53, 3, 41, 10, 3420, 3249, 18, 14815, 3432], [3, 41, 43, 538, 21, 9, 45], [3, 41, 37, 239, 1766, 32, 4, 9, 72, 7, 15, 2476, 188, 11, 794, 1211, 147, 162, 10, 676, 14816], [3, 41, 60, 1, 30, 14817, 3, 271, 713, 155, 115, 215, 449, 3, 29, 733, 59, 76, 7876, 36, 271, 713, 36, 471, 2697, 7, 3, 440], [3, 41, 60, 1613, 24, 68, 106, 8, 4, 1, 148, 1196, 124, 17, 133, 6, 7877], [3, 41, 60, 2412, 197, 3, 87, 14818, 41, 17, 829, 20, 1110, 5779, 100, 5780, 7878, 1], [3, 41, 256, 21, 20, 30, 176, 86, 23, 24], [3, 41, 1709, 239, 356, 406, 82, 1157, 1, 47, 948], [3, 41, 4, 606, 11, 2, 235, 1020, 3, 41, 80, 1, 11, 2, 645, 1020], [3, 41, 4, 606, 1427, 7879, 3, 41, 80, 1, 1427, 645, 1020, 3, 58, 48, 19, 27, 4, 1599, 670], [3, 41, 4, 606, 1427, 7879, 3, 41, 80, 1, 1427, 645, 1020], [3, 41, 4, 14819, 1427, 235, 14820, 41, 80, 1, 1427, 645, 1020], [3, 41, 39, 473, 7837, 9, 7, 3436, 167, 17, 35, 155, 37, 1725, 26, 75, 113, 31, 36, 13, 17, 74, 238, 1505, 307], [3, 41, 22, 1752, 828, 1397, 11, 4, 3536, 571, 1144, 7, 1, 458, 11, 2, 607], [3, 41, 6, 28, 4, 56, 54, 8, 70, 1418, 21, 4, 14821, 8, 192, 3894, 37, 78, 14, 93, 634, 3, 28, 895, 353, 54], [3, 41, 80, 1, 138, 792], [3, 4461, 2, 5781, 16, 3179, 32, 35, 18, 10, 138], [3, 146, 2, 89, 1, 8, 32, 40, 58, 12, 2338, 851], [3, 146, 1124, 3, 168, 113, 1, 474, 36, 67, 6, 465, 14822, 396, 10, 193, 2, 161, 1102], [3, 146, 89, 83, 156, 41, 50, 343, 14823, 156, 163, 4, 1483, 125, 50, 228, 303, 1927], [3, 146, 180, 235, 1533, 1, 3, 86, 15, 3437, 1366], [3, 146, 1, 6, 249, 10, 138, 634, 3, 879, 1218, 15, 18, 10, 2138, 8, 14824, 7, 45, 108, 35, 46, 7, 2, 659], [3, 146, 1149, 16, 5782, 51, 4, 967, 38, 3, 28, 102, 23, 167, 147, 1, 14825, 4, 5782, 147, 12], [3, 146, 28, 15, 288, 143, 525, 93, 10, 399], [3, 146, 134, 855, 14826, 5422, 52, 12, 2, 91, 16, 84, 2392, 14827, 75, 1462, 25, 21, 441, 1046, 1292, 7753, 14828, 1], [3, 2430, 6, 90, 1958, 8, 4590, 207, 1349, 34, 7, 452, 139, 17, 82, 3972, 60, 93, 14829], [3, 2430, 35, 1427, 2309, 125, 4, 3342, 2218, 26, 95, 30, 25], [3, 2430, 35, 27, 145, 29, 302, 43, 145, 43, 64, 21, 145], [3, 3014, 116, 103, 340, 60, 341, 816, 54, 390, 11, 472, 27, 43, 645, 8, 458, 6, 4657], [3, 380, 3, 33, 107, 102, 73, 2, 1, 6, 111], [3, 380, 1, 41, 15, 1717, 8, 86, 23, 669, 74, 7880, 58, 3, 65, 669, 58, 3, 65, 939, 58, 3, 65, 13, 495, 5, 556, 479, 4459], [3, 380, 153, 86, 31, 36, 1632, 5, 169, 21, 37, 358, 604, 627], [3, 380, 553, 16, 1762, 5783, 30, 25, 131, 313, 384, 1, 125, 143, 180, 774], [3, 380, 7, 241, 47, 2, 1, 3, 29, 136], [3, 124, 2367, 181, 11, 4, 3563, 3427, 292, 755, 919, 17], [3, 124, 2, 438, 125, 7881, 579, 7, 1, 2970, 17, 35, 690, 16, 488, 40, 2970, 143, 413, 620, 35, 7882, 5, 19, 187, 7881, 35, 174, 30, 43, 3852], [3, 124, 2, 961, 30, 14830, 22, 449, 27, 1914, 14831, 2062, 1159, 34, 76, 9, 920, 108, 4, 479, 7883, 45, 14, 4424, 80], [3, 124, 2, 651, 3, 47, 11, 2700, 940, 361, 27, 10, 521, 1030, 73, 10, 1254, 653, 8, 375, 86, 1322, 284, 5, 671, 2, 9, 14832], [3, 124, 2, 1496, 2813, 58, 7, 18, 2, 14833, 3, 47, 33, 13, 22, 171, 1], [3, 124, 7884, 27, 348, 21, 1283, 1146, 14, 98, 2008, 12, 70, 39, 3973, 2496], [3, 124, 13, 22, 68, 1, 34, 40, 156, 47, 11, 60, 45, 149, 60, 19, 2087], [3, 124, 4, 14834, 234, 9, 107, 54, 6, 17, 3, 580, 16, 10, 77, 579, 192, 5128, 2, 399], [3, 124, 6, 1420, 4, 6951, 5, 1, 33, 1835, 51, 15], [3, 124, 6, 113, 2, 1, 3, 67, 4, 14835], [3, 124, 6, 753, 60, 284, 668, 1, 3682, 55, 3, 29, 137], [3, 124, 963, 138, 444, 3, 192, 780, 27, 120, 319, 36, 861, 224, 26, 100, 2, 379, 4968, 2905, 18, 2165], [3, 2674, 262, 108, 37, 39, 9, 64, 6, 310, 17], [3, 90, 14836, 14837, 7885, 176, 7886, 3223, 193, 82, 17], [3, 90, 2039, 14838, 43, 4567, 3, 86, 4276, 16, 15, 12, 248], [3, 90, 2, 53, 86, 40, 62, 71, 6, 54, 235, 409, 1, 1449, 53], [3, 90, 2, 14839, 51, 14840, 30, 2072], [3, 90, 2, 296, 168, 6, 81, 6, 14841, 25, 74, 1, 13, 1449, 1543, 66, 105, 81, 42, 383, 62, 240], [3, 90, 2, 1, 7, 64, 2, 1, 7, 72, 40, 64, 2, 25, 99, 1075, 30, 1, 57, 5, 276, 58, 12, 5, 315, 1, 12, 5, 344, 1], [3, 90, 2, 29, 28, 45, 328, 30, 399], [3, 90, 2, 1037, 30, 1, 74, 98, 1037, 30, 25, 26, 20, 58, 99, 209, 33, 139, 26, 15, 4658, 26], [3, 90, 2, 3613, 1, 13, 453, 1533, 624], [3, 90, 2, 802, 203, 1570, 2000, 197, 30, 3162], [3, 90, 2, 861, 35, 83, 14842, 5750, 5, 46, 45, 3108], [3, 90, 2, 56, 89, 1], [3, 90, 2, 3438, 3439, 1], [3, 90, 32, 39, 3506, 2191, 3, 293, 36, 32, 28, 4, 5784, 850, 2094], [3, 90, 14843, 1], [3, 90, 14, 14844, 23, 48, 14845, 23, 48, 2, 14846, 23, 3399, 4659, 14847, 8, 23, 58, 57, 70, 17, 243, 48, 393, 3714], [3, 90, 1, 216, 25, 7, 86, 73, 738, 73, 36, 28, 60, 24, 374, 89, 809, 20, 1494, 73, 2, 4660, 8, 5, 1467, 14848], [3, 90, 1, 34, 183, 14849, 203, 1, 49, 4, 884], [3, 90, 1, 7, 1127, 21, 2558], [3, 90, 1, 7, 44, 764, 32, 4, 106], [3, 90, 1, 7, 255, 212, 365, 30, 1410, 1742, 374, 101, 4137, 139, 14, 14850], [3, 90, 1, 69, 86, 416, 67, 126, 530, 30, 13, 43, 20, 48, 342], [3, 90, 1, 27, 89, 1256], [3, 90, 1, 27, 834, 1256], [3, 90, 283, 640, 30, 1], [3, 90, 467, 123, 2542, 416, 37, 19, 723, 615, 19, 5, 189, 151, 14, 501, 123, 531, 24], [3, 90, 171, 1], [3, 90, 203, 1], [3, 90, 275, 7, 842, 126, 30, 54, 73, 36, 4990, 5, 62, 5, 65, 13, 2, 144, 14851, 117], [3, 90, 179, 1, 27, 2, 14852], [3, 90, 61, 6, 460, 162, 109, 203, 1, 61, 8, 208, 13, 374, 4, 45, 140, 374, 51, 4, 2429, 13, 148, 14853, 23, 135, 99], [3, 90, 9], [3, 90, 9, 69, 14, 65, 32, 417, 14854, 27, 126, 343, 8, 1574, 328, 34, 36, 265, 65, 13, 36, 1240, 2273, 2, 4285], [3, 90, 71, 77, 1, 59, 1701, 2545, 1701, 523, 693, 965, 1188, 3, 163, 1080], [3, 90, 10, 381, 7627, 15, 372, 37, 2307], [3, 90, 111, 69, 81, 1229, 609, 30, 639, 1534, 8, 179, 1225], [3, 90, 322, 1, 7, 497, 27, 564, 25], [3, 90, 349, 173, 14855, 25, 14, 1442, 13, 36, 105, 297, 2, 1, 484, 2, 347, 27, 3440, 8, 2, 2879, 26], [3, 90, 2617, 2304, 7482, 5, 166, 120, 1, 49, 284, 374, 530], [3, 90, 590, 823, 9, 23, 1811], [3, 90, 7887, 202, 283], [3, 90, 7887, 1, 11, 979, 34, 10, 111, 109, 28, 18, 10, 19, 1203, 3937], [3, 90, 185, 1, 69, 345, 21, 185, 540], [3, 90, 1823, 54, 4, 56, 3, 156, 14, 772, 2, 180, 30, 381, 6, 14, 11, 4, 14856, 74, 13, 2, 14857, 6, 756, 54, 4, 3239], [3, 90, 262, 723, 1], [3, 90, 7, 3, 597, 35, 570, 4, 561, 211, 3, 14858, 34, 4, 488, 7, 116, 47, 2, 587, 190, 4661, 11, 4, 3536, 28, 17, 37, 243], [3, 90, 7, 9, 188, 40, 46, 133, 45], [3, 90, 7, 9, 2779], [3, 90, 7, 10, 306, 72, 40, 122, 6, 420, 54, 3192, 13, 1, 4, 101, 540, 20, 14859, 12, 140, 5, 29, 44, 2, 507, 6, 14860], [3, 90, 7, 68, 1107, 1516, 7, 107, 54, 38, 5, 745, 5785, 13, 25, 139, 14, 2, 1], [3, 90, 7, 2076, 177, 7702, 4, 5786, 387, 11, 4, 178, 16, 14861], [3, 90, 7, 38, 3, 44, 4662, 930, 36, 400, 17, 123, 4, 247, 589, 1, 11, 4, 413, 3319], [3, 90, 4, 3874, 1195, 3, 90, 4, 3874, 1195, 314, 236, 4, 14862, 3, 90, 4, 3874, 1195], [3, 90, 4, 179, 56, 51, 4, 1101, 261, 1117, 4, 606, 82, 10, 14863, 32, 16, 76, 103, 632, 35, 6, 14, 7111], [3, 90, 4, 120, 56, 670, 69, 999, 8, 1012, 10, 14864, 1246, 8, 2896], [3, 90, 39, 9, 7, 65, 834, 82, 4, 580, 76, 40, 433, 42, 26, 50, 30, 14, 346], [3, 90, 22, 851, 1484, 1], [3, 90, 212, 265, 11, 20, 521, 7, 49, 156, 733, 8, 33, 14, 2, 14865, 6, 4, 826], [3, 90, 1118, 9, 3, 70, 15, 37, 332, 33, 6, 81, 29, 3, 3, 28, 102, 3371, 29, 3, 3, 28, 15, 1872, 29, 3, 151, 450, 35, 14866, 266, 3], [3, 90, 1610, 33, 2, 666, 16, 643, 1, 3, 75, 44], [3, 90, 6400, 22, 145, 91, 55], [3, 90, 38, 3, 94, 2, 834, 1, 18, 610, 88, 40, 229, 35, 65, 13, 2, 2799, 14867], [3, 90, 38, 3, 2885, 2, 327, 27, 2, 1787, 7, 72, 7480, 8, 10, 5787, 8, 217, 191, 2612, 12, 7, 20, 5787, 14868, 1, 3, 592, 170, 619], [3, 90, 38, 2, 1, 75, 114, 2, 2558, 1322, 37, 14869, 1600, 23, 48, 23, 5021, 3522, 45, 5, 183, 88, 14870], [3, 90, 38, 2, 1, 41, 19, 35, 1022, 8, 40, 1174, 872, 11, 50, 406, 364, 425], [3, 90, 38, 2, 77, 32, 584, 419, 8, 3, 58, 419, 45, 14871, 2, 161, 14872, 2359, 17, 31, 5, 44, 2, 14873, 13, 1, 151, 6818, 20, 30], [3, 90, 38, 1, 14874, 14875, 251], [3, 90, 38, 1, 14, 13, 296, 64, 170, 37, 209, 14876], [3, 90, 38, 1, 28, 564], [3, 90, 38, 1, 176, 72, 14877, 3498, 13, 1, 42, 372, 185, 411], [3, 90, 38, 1, 101, 131, 81, 6, 17, 12, 38, 126, 1214, 421, 35, 27, 76, 74, 374, 18, 421, 27, 126, 14878, 43, 916, 19, 54, 10, 3655], [3, 90, 38, 1, 448, 406, 27, 166, 342, 1, 8, 29, 1318, 240, 11, 254, 7, 702, 1250, 727, 1948, 73, 19], [3, 90, 38, 1, 72, 14879, 8, 7103], [3, 90, 38, 1, 86, 5, 772, 256, 11, 2753, 21, 303, 76, 2, 2113, 30, 2006, 74, 4988, 22, 12, 10, 164, 100, 17, 259], [3, 90, 38, 1, 122, 6, 81, 45, 27, 1499, 1574], [3, 90, 38, 202, 111, 122, 8, 14, 120, 37, 89, 188, 20, 2, 158], [3, 90, 38, 342, 30, 77, 44, 963, 483, 520, 13, 1, 20, 14880, 559, 20, 1385, 8, 14, 27, 2, 112, 25], [3, 90, 38, 275, 122, 6, 372, 13, 95, 235], [3, 90, 38, 77, 72, 584, 419, 34, 10, 548, 12, 7888, 1, 7, 25, 29, 64, 5, 282, 420, 962], [3, 90, 38, 77, 72, 584, 419, 34, 10, 548, 12, 7888, 1, 7, 25, 29, 64, 350, 420, 18], [3, 90, 38, 77, 72, 7889, 5788, 13, 242, 35, 20, 7889, 2, 917, 48, 1115, 771, 37, 242, 35, 230, 3, 28, 20, 138, 1238, 18, 17], [3, 90, 38, 9, 122, 6, 137, 4, 1039, 694], [3, 90, 38, 9, 175, 59, 14881, 550, 7, 46, 2490], [3, 90, 38, 3, 94, 2, 587, 9, 238, 543, 2968], [3, 90, 38, 10, 237, 228, 28, 2, 154, 1, 8, 1240, 497, 27, 17], [3, 90, 38, 25, 107, 35, 6, 17, 8, 113, 17, 36, 41, 22, 1, 102, 186, 74, 41, 50, 8, 15, 14, 2, 1, 3, 948, 125, 55, 251], [3, 90, 38, 111, 191, 31, 3, 512, 35, 3, 29, 87, 7, 24, 45, 6, 14, 1104, 130, 5, 14882, 25], [3, 90, 38, 111, 79, 17, 14883, 220, 48, 11, 5367, 5, 19, 816], [3, 90, 38, 111, 44, 2996, 7890, 1970, 8, 733, 99, 1572, 241, 20, 306, 309, 71, 59, 5, 139, 14, 2, 285], [3, 90, 38, 111, 33, 3436, 139, 81, 6, 5, 13, 134, 17, 2, 540, 1], [3, 90, 38, 111, 1947, 893, 8, 5, 450, 35, 1912, 4, 14884, 230, 14885, 29, 191, 17, 31, 23, 135], [3, 90, 38, 111, 113, 17, 3, 44, 6, 239, 1356, 8, 36, 70, 17, 65, 2030, 13, 1, 19, 5], [3, 90, 38, 111, 5789, 8, 88, 998, 4, 2518, 13, 78, 60, 9, 21, 7, 26, 23, 122, 6, 509, 76], [3, 90, 38, 574, 421, 35, 2, 290, 13, 1153, 31, 36, 237, 228, 746, 766, 100, 76, 1, 290, 3441], [3, 90, 38, 574, 107, 6, 10, 331, 8, 70, 2, 780, 11, 4, 3966, 13, 1, 58, 3, 107, 6, 20, 331, 8, 137, 11, 4, 2258, 4549], [3, 90, 38, 212, 141, 120, 265, 122, 8, 208, 4329, 13, 1, 5, 49, 120], [3, 90, 38, 120, 56, 122, 6, 208, 13, 374, 10, 14886, 15, 101, 70, 15, 7, 209, 14887, 71, 120, 56, 36, 1563], [3, 90, 2346, 278, 998, 10, 186, 31, 3, 124, 1406, 165, 6, 58, 1, 30, 25], [3, 90, 190, 1925, 75, 150, 1291, 8, 108, 55], [3, 90, 5, 153, 55], [3, 44, 984, 9], [3, 44, 2, 1, 231, 8, 2, 1, 768, 6, 1141, 15, 37, 15, 716, 332, 70, 2243], [3, 44, 2, 150, 390, 103, 14, 248], [3, 44, 32, 39, 1037, 30, 4658, 754, 26, 3911, 131, 208, 13, 2, 1722, 282], [3, 44, 165, 184, 6, 58, 13, 484, 10, 190, 19, 7891], [3, 44, 679, 107, 6, 1067, 27, 4, 488, 3, 195, 51, 10, 3644, 1, 822, 38, 3, 29, 119], [3, 44, 10, 197, 328, 2, 115, 211, 3, 28, 15, 8, 326, 499, 14, 14888, 18, 7892, 22, 4, 115, 16, 763, 1820], [3, 44, 105, 428, 297, 2, 190, 7504], [3, 44, 43, 754, 7, 70, 17, 65, 13, 2, 388, 34, 3, 122, 10, 237], [3, 44, 43, 9, 720, 3, 29, 87, 212, 464], [3, 44, 43, 538, 21, 111, 69, 359, 7, 45, 33, 144], [3, 44, 1239, 1845, 10, 117, 6, 1, 59, 184, 21, 4, 244, 268, 213, 2939], [3, 44, 68, 127, 115, 16, 19, 2119, 274, 7893, 12, 19, 144], [3, 44, 109, 480, 207, 1256, 905, 8, 15, 48, 422], [3, 44, 270, 2, 1765, 7894, 16, 817, 3, 86, 3, 318, 14, 144, 251], [3, 44, 76, 1, 2685, 1497, 147, 1952, 107, 148], [3, 44, 6, 472, 35, 740, 21, 382, 1876, 8, 3, 96, 29, 62, 71, 6, 1469, 4, 1469], [3, 44, 6, 869, 39, 1, 74, 10, 746, 28, 76, 8, 119, 32, 16, 76], [3, 44, 6, 139, 168, 1063, 37, 1725, 11, 10, 744, 1514], [3, 44, 6, 113, 5, 2, 1564, 1322, 2, 185, 917], [3, 44, 478, 6, 594, 85, 37, 239, 3910, 28, 4, 1450, 1663, 15, 79, 2, 3784, 74, 256, 13, 7, 188], [3, 745, 132, 79, 183, 469, 10, 413, 164, 205, 189, 69, 1191, 6, 287, 73, 1, 49, 37, 183, 6, 17, 128, 42, 1570, 17], [3, 465, 4, 95, 11, 4, 850, 14889, 3, 484, 3287, 3, 195, 771, 51, 6788], [3, 465, 4, 199, 184, 115, 11, 8, 115, 5247, 15, 21, 4, 942], [3, 566, 1, 1694, 2998, 21, 2765], [3, 566, 3912, 16, 2, 4375, 4663, 2736, 1, 226, 14890, 6756, 224, 545, 1775, 2525, 288, 2001, 28, 4, 6867], [3, 566, 40, 429, 24, 18, 4, 702], [3, 566, 76, 199, 24, 25, 1500], [3, 167, 1744, 288, 23, 477, 6, 4323], [3, 1061, 29, 594, 85, 435, 64, 6, 2546, 4, 287, 7, 70, 76, 150, 1639, 1749, 249, 10, 138, 1933, 14891, 40, 2, 2402, 14892], [3, 293, 159, 1051, 4, 5790, 21, 22, 14893], [3, 293, 3, 840, 8, 616, 173, 60, 24, 14894], [3, 293, 54, 70, 36, 14895, 14896, 14897, 143, 9, 14898], [3, 293, 4, 232, 28, 7895, 1521, 105, 502, 170, 423, 21, 1285, 5014], [3, 293, 4, 56, 3, 81, 2353, 725, 950, 3925, 317, 505, 10, 1180, 16, 28, 2010, 73, 2, 1899, 14899, 3, 47, 1325, 14900], [3, 293, 5, 32, 3215, 28, 2, 203, 202, 1, 554], [3, 293, 5, 28, 387, 2031, 83], [3, 293, 5, 623, 7, 20, 398, 144], [3, 293, 5, 1730, 15, 35, 134, 7, 24, 2, 421, 32, 76, 25, 5, 172, 105, 132, 18, 2, 438], [3, 293, 325, 29, 107, 73, 2, 1368, 2135, 6, 168, 34, 23, 207], [3, 609, 95], [3, 1268, 143, 379, 120, 77, 244, 277, 123, 114, 54, 10, 1055, 664, 1162, 8, 5714, 15, 6, 788, 143, 7896, 21, 143, 439], [3, 383, 131, 259, 93, 271, 1241, 8, 19, 89, 1], [3, 383, 131, 366, 1849, 18, 2, 1, 517, 163, 1571, 2237, 14901], [3, 383, 131, 194, 22, 215, 1510, 16, 1685, 12, 4, 154, 202, 34, 2676, 383, 67, 6, 14, 2, 1], [3, 33, 14, 1397, 205, 749, 3, 29, 19, 545, 9, 74, 9, 25, 37, 3, 29, 62, 59, 71, 36, 2807, 188, 485, 23, 329], [3, 33, 14, 19, 39, 1, 39, 25, 14, 2209, 39, 9], [3, 33, 1, 491, 10, 646], [3, 33, 1048, 2, 14902, 8, 2, 1, 510, 125, 15], [3, 33, 75, 438, 2, 179, 30, 77, 321], [3, 33, 75, 2337, 531, 14, 1376, 281], [3, 33, 906, 22, 203, 1, 5791, 114, 2, 1142], [3, 33, 1144, 10, 3289, 310, 274, 148, 3, 150, 13, 929, 2, 1, 11, 4, 3289, 977], [3, 33, 2210, 2, 1731, 82, 2, 284, 1], [3, 33, 29, 28, 85, 553, 16, 5, 111, 81, 108, 6, 14903, 380, 5, 253, 17, 21, 4, 11, 293, 3, 253, 108, 34, 385, 81, 6, 2, 353], [3, 33, 976, 11, 2608, 33, 486, 4, 832, 1, 484, 2, 862, 14904, 14905, 7897], [3, 33, 19, 98, 6650, 15, 47, 804, 140, 15, 47, 13, 2, 120, 481, 7179, 2, 202, 14906, 13, 2207, 5792], [3, 33, 28, 192, 241, 97, 66, 41, 15, 83], [3, 33, 41, 37, 1617, 281, 100, 61, 257, 4, 45, 54, 147, 24, 30, 1956], [3, 33, 566, 10, 306, 61, 1749, 12, 1452, 2545, 589, 1, 4, 19, 5, 772, 3, 1705, 21, 71, 358, 8, 92, 23, 807, 680, 14907], [3, 33, 4240, 4, 247, 1107, 7856, 14908, 14909, 143, 19, 12, 61, 18, 619, 10, 14910, 23, 48, 65, 54, 7, 83], [3, 33, 64, 7, 14911, 9, 2884, 9, 323, 7, 4, 101, 820, 3, 43, 2076, 14, 28, 169, 37, 66, 466, 54, 60, 7898, 7898], [3, 33, 318, 303, 531, 98, 4543, 1586], [3, 33, 318, 28, 6, 39, 613, 3, 318, 61, 291, 18, 39, 1], [3, 33, 87, 4, 232, 6, 404, 4, 7107], [3, 33, 87, 6, 62, 57, 7, 24, 13, 37, 68, 106, 12, 595, 27, 17, 160, 5227, 55], [3, 33, 157, 142, 2, 2477, 16, 348], [3, 33, 509, 700, 1474, 175, 82, 1474, 511, 77, 59, 71, 126, 14912, 575, 450, 3195, 14913, 2605, 9, 103, 28, 14914], [3, 33, 486, 2, 91, 44, 2, 428, 1514, 27, 84, 95, 281], [3, 33, 297, 2, 167, 1, 79, 2, 167, 1, 183, 233, 7, 45, 14, 356, 1335], [3, 33, 297, 4, 2272, 1, 11, 2786, 2142, 18, 1147, 264, 1231], [3, 33, 297, 20, 455, 1, 3, 318, 19, 27, 50], [3, 33, 881, 142, 18, 7, 24], [3, 33, 131, 2126, 27, 10, 520, 793, 2, 858, 2708, 26, 467, 341, 1289, 8, 44, 10, 343, 137, 27, 37, 3, 63, 61, 6, 2818], [3, 33, 131, 19, 89, 1], [3, 33, 131, 28, 2916, 26, 19, 3331, 1], [3, 33, 131, 491, 2, 535, 16, 78, 1], [3, 33, 131, 935, 22, 663, 977], [3, 33, 131, 881, 143, 1, 19, 143, 1, 13, 2, 1852, 29, 302, 4, 83], [3, 33, 131, 2742, 4, 360, 27, 10, 1], [3, 33, 67, 2, 77, 3622, 14, 2, 9, 21, 17, 7, 32], [3, 33, 67, 60, 354, 26, 1778, 14915, 33, 139, 123, 4, 1333, 26, 479, 35, 60, 18, 20, 193, 108, 55], [3, 33, 67, 4, 89, 9, 8, 3, 131, 1912, 4, 1334], [3, 33, 67, 6, 257, 4, 19, 54, 16, 416, 7, 1442, 51, 17, 13, 1, 14916], [3, 33, 67, 6, 929, 5, 11, 4, 977, 38, 5, 28, 10, 748, 329, 185, 1, 51, 7822], [3, 33, 67, 5727, 354], [3, 33, 792, 35, 39, 288, 337, 14, 2, 14917, 216, 27], [3, 33, 301, 3, 124, 2, 504, 6, 107, 337, 6, 211, 2, 358, 264, 16, 172, 125, 1, 11, 4, 489], [3, 33, 301, 60, 275, 118, 65, 11, 4, 2772, 2713, 36, 907, 18, 685, 1848, 26, 81, 142, 18, 319], [3, 33, 2171, 2, 797, 30, 2897, 26, 47, 197, 18, 4, 14918, 26, 10, 7804, 14919, 23, 204, 2, 1, 31, 15, 28, 514, 149, 3, 4935, 492, 254], [3, 176, 298, 793, 1308, 74, 38, 95, 635, 6, 2438, 126, 14920, 14, 2176, 123, 126, 3044, 16, 2, 7899, 2879], [3, 176, 94, 9, 79, 166, 14921, 3, 14, 1075], [3, 176, 4, 832, 9, 271, 1241, 82, 235, 6, 1109], [3, 176, 39, 9, 11, 536, 444, 36, 1846], [3, 724, 2, 154, 2253, 312, 118, 72, 256, 284, 55], [3, 636, 15, 7900, 142, 187], [3, 62, 3, 81, 2, 320, 16, 45, 34, 1, 237, 442, 3, 63, 108, 7, 45, 562], [3, 62, 23, 2, 837, 34, 12, 116, 393, 165, 130, 2, 180, 1616, 16, 1324, 8, 5793, 141, 341, 1645, 18, 4609], [3, 62, 31, 3, 29, 420, 54, 123, 244, 213, 10, 306, 152, 1, 51, 17, 4, 413, 106, 3, 259, 27, 50], [3, 62, 2730, 638, 8, 1], [3, 62, 7901, 38, 3, 94, 7901, 282], [3, 62, 2, 320, 16, 168, 30, 9, 7, 33, 67, 1407, 98, 2701, 82, 25, 61, 1862, 1], [3, 62, 1, 14, 214, 73, 45, 38, 36, 228, 2324, 126, 754, 26, 15, 2, 666, 16, 77, 11, 50, 798, 1088, 854, 71, 342, 4, 1927, 12], [3, 62, 1, 69, 506, 24, 21, 5613], [3, 62, 71, 15, 150, 6, 48, 44, 45, 442, 307, 3, 47, 1348, 11, 4, 548, 16, 14922, 15, 29, 28, 1046, 179, 130, 7], [3, 62, 23, 48, 4, 101, 145, 7, 486, 7], [3, 62, 1777, 28, 68, 189, 54, 91, 5, 124, 68, 401, 3571, 7902], [3, 62, 6552, 3, 90, 203, 1229, 1], [3, 62, 45, 59, 326, 3, 33, 29, 279, 602, 6, 569, 18, 15, 34, 3, 3809, 5, 1, 194, 15, 1896, 26], [3, 62, 60, 590, 1, 8, 36, 2999, 4, 3407, 234], [3, 62, 7, 648, 99, 112, 37, 3, 293, 5, 58, 4664, 34, 96, 185, 30, 1, 3, 46, 172, 596, 350], [3, 62, 7, 648, 99, 112, 37, 3, 293, 5, 1042, 4664, 34, 96, 185, 30, 1, 3, 46, 172, 27, 350], [3, 62, 39, 9], [3, 62, 39, 2284, 566, 17, 801], [3, 62, 22, 68, 9, 18, 186, 117, 92, 7, 14923, 45], [3, 62, 38, 1932, 14924, 8, 180, 1701, 220, 2300, 35, 14925, 47, 13, 3507, 7, 2, 368], [3, 62, 38, 1, 2277, 17, 11, 2, 1143, 1253, 4, 324, 14926, 14927, 8, 14928, 7903, 49, 2362, 5009], [3, 62, 78, 1, 113, 78, 653, 57, 118, 14929, 58, 218, 78, 30, 271, 253, 17], [3, 62, 5, 1, 12, 90, 18, 4, 3886, 85, 17, 205, 15, 193, 127, 638, 11, 22, 360, 7, 63, 1800, 254], [3, 62, 5, 14930, 10, 14931, 276, 471, 2, 1, 6786, 7904], [3, 62, 78, 120, 617, 101, 14, 868, 125, 307, 3, 207, 8, 3, 62, 10, 507], [3, 2493, 39, 1, 25, 3069, 193, 3583, 31, 42, 47, 585, 24, 11, 14932, 42, 585, 24, 92], [3, 7905, 172, 125, 22, 25, 52, 28, 32, 1393, 52, 1093, 17, 16, 10, 1, 12, 7, 5, 7906, 14933], [3, 528, 51, 22, 1], [3, 683, 7, 155, 89, 1, 107, 125, 2156, 2246, 33, 13, 7221, 14934, 14935, 14936, 37, 573, 1151], [3, 14937, 59, 95, 73, 2, 4665, 237, 106, 6, 683], [3, 100, 32, 16, 240, 4565, 31, 42, 41, 268, 9, 42, 87, 6, 100, 68, 61], [3, 100, 9, 70, 15, 99, 209], [3, 308, 4, 1847, 427, 4, 101, 507, 14938, 77, 472, 35, 13, 14939, 659, 14940, 7907, 1318, 1], [3, 13, 1745, 14941, 34, 3, 90, 32, 4, 1346], [3, 13, 2190, 52, 81, 2, 320, 16, 56, 5, 63, 113, 52, 64, 4, 178], [3, 13, 2, 431, 89, 83, 40, 62, 40, 643, 34, 50, 764, 12, 13, 5477, 766], [3, 13, 2, 9, 7, 13, 2, 9, 33, 21, 10, 5425], [3, 13, 32, 4, 265, 18, 2239, 626, 344, 208, 13, 36, 49, 332, 30, 3043, 450, 35, 338, 466, 126, 387, 54, 13, 1, 55], [3, 13, 89, 1, 149, 36, 13, 89, 1, 99], [3, 13, 89, 1, 149, 36, 13, 89, 1, 99, 4484, 7908], [3, 13, 89, 1, 7, 10, 19, 437], [3, 13, 14942, 2680, 8, 2084, 3, 13, 10, 1, 1768], [3, 13, 14, 3362, 29, 134, 17, 4, 24, 99, 1026], [3, 13, 1, 7, 13, 1], [3, 13, 1, 27], [3, 13, 497, 27, 20, 1, 8, 3, 13, 19, 876], [3, 13, 93, 441, 3, 13, 89, 1, 7, 63, 694, 1770], [3, 13, 14943, 1289, 1, 43, 690, 31, 621, 499, 4348], [3, 13, 71, 3911, 663, 30, 443, 10, 175, 34, 210, 262, 17, 3409, 90, 7, 282], [3, 13, 71, 25, 122, 98, 107, 51, 17, 8, 23, 13, 58, 15, 88, 1, 8, 36, 29, 58, 385, 24], [3, 13, 15, 38, 5, 79, 17, 14944, 3, 13, 38, 89, 1, 3949, 2443, 18, 10, 7909, 481, 15, 48, 110, 4, 1638], [3, 13, 254, 617, 208, 13, 4, 324, 14945, 12, 4, 6863, 16, 2084, 269, 74, 2606, 14946, 15, 1591, 43, 112], [3, 13, 10, 1, 89, 125, 2, 161, 764], [3, 13, 10, 1, 1310, 2434, 108, 1769, 20, 1288], [3, 13, 10, 930, 142, 702, 8, 10, 1371, 4666, 1144, 498, 125, 2, 89, 9, 125, 50, 504, 11, 4, 108], [3, 13, 72, 4, 324, 24, 9, 432, 43, 85], [3, 13, 114, 25, 9, 34, 3, 139, 58, 7], [3, 13, 4, 232, 14947, 14948], [3, 13, 6, 971, 19, 595, 4864, 103, 3, 955, 555, 2, 1, 219, 485], [3, 13, 6, 382, 1232, 34, 23, 7910, 1489, 6, 94, 57, 126, 14949, 65, 2226], [3, 13, 441, 348, 8, 851, 23, 344, 34, 4651, 2966, 41, 5450, 4024, 5002, 293, 3, 840, 8, 14950, 173, 60, 24], [3, 13, 2, 496, 4, 1568, 1219, 2, 752, 2348], [3, 13, 2, 496, 14951, 14952, 56, 81, 3586, 7911, 296, 63, 763, 10, 466, 18, 20, 14953], [3, 599, 33, 65, 426, 22, 265, 2, 1982], [3, 259, 21, 14954, 348], [3, 259, 11, 4, 1026, 3496, 1], [3, 65, 165, 18, 20, 1, 130, 50, 1927, 18, 10, 1352], [3, 65, 13, 4984, 38, 3, 7912, 10, 235, 6, 4, 234, 99, 1], [3, 65, 13, 2, 3193, 95, 3195], [3, 65, 144], [3, 468, 14955, 253, 155, 1608, 947, 1, 753, 17, 140, 16, 10, 14956, 18, 220, 61, 4857, 14957, 2, 9, 14958, 12, 2, 9, 3803], [3, 514, 32, 10, 538, 21, 10, 646, 149, 5, 208, 13, 2, 344, 35, 1], [3, 514, 254, 463, 86, 20, 99, 93, 21, 17, 5, 1010, 368, 8, 3, 976, 18, 4, 618, 8, 3, 976, 102, 4, 618, 8, 3, 1705, 18, 4, 5665], [3, 514, 3635, 1, 5076, 34, 3, 105, 514, 10, 453], [3, 514, 256, 127, 1768, 130, 531, 215, 213, 37, 919, 17, 21, 14, 2, 141, 1948, 1], [3, 64, 14959, 123, 14960, 34, 278, 64, 15, 127, 31, 5794, 1553, 47, 33, 4107, 21, 1058, 8, 2, 470, 691, 661, 16, 14961, 56, 14962], [3, 64, 668, 1], [3, 64, 14963, 3, 301, 7893, 1, 30, 124, 15], [3, 64, 4930, 38, 40, 28, 179], [3, 64, 2, 1, 27, 3065, 16, 50, 373], [3, 64, 32, 10, 283, 8, 23, 3249, 21, 32, 10, 1, 43, 690, 3779], [3, 64, 32, 111, 21, 69, 36, 49, 34, 116, 22, 68, 181, 7, 568, 6, 10, 261, 7, 63, 430, 2, 3652, 883, 6, 4, 231, 4632], [3, 64, 89, 1], [3, 64, 89, 1, 15, 10, 19, 2371, 8, 221, 374, 18, 32, 1763, 13, 2, 19, 14964], [3, 64, 89, 1, 7, 10, 172, 2029], [3, 64, 89, 1, 7, 10, 172, 437, 1896, 112, 45, 3, 75, 110, 547, 15], [3, 64, 104, 1064, 64, 76, 1047, 4, 68, 7, 63, 472, 6, 4, 1289], [3, 64, 203, 1], [3, 64, 203, 283, 7, 10, 19, 2029], [3, 64, 1657, 27, 169, 29, 43, 166, 1, 28, 10, 106, 74, 10, 387], [3, 64, 3853, 269, 235, 73, 209, 73, 4, 244, 395, 34, 2271, 14965, 2920, 12, 33, 14966], [3, 64, 172, 125, 1225, 3, 14, 3959, 3279, 30, 4603, 206, 73, 353, 125, 5687, 873, 765, 14, 1275, 17, 13, 25, 23, 4219, 14967, 7671], [3, 64, 61, 6, 8, 65, 51, 27, 10, 4667, 66, 81, 59, 76, 11, 1840, 73, 4, 388, 1442, 51, 263, 8, 7100, 26], [3, 64, 71, 326, 1, 59, 1136, 408, 38, 66, 404, 34, 31, 36, 468, 32, 4, 1543, 49, 5158, 127, 7913], [3, 64, 71, 1, 14, 533, 71, 4, 419, 164, 12, 4, 237, 164, 88, 2450, 8, 733, 71, 36, 87, 2, 520], [3, 64, 71, 9, 14, 13, 526, 14968, 2160, 14969], [3, 64, 71, 10, 646, 428, 122, 6, 594, 84, 77, 8, 94, 50, 446, 16, 1535, 38, 36, 687, 661, 16, 14, 2, 1, 59, 15, 26], [3, 64, 71, 111, 168, 186, 6, 33, 1, 98, 733], [3, 64, 71, 66, 63, 791, 8, 96, 14, 4, 199, 494, 1208, 356, 5440, 3778, 2227, 2948, 156, 5795, 85, 3, 64, 2012], [3, 64, 2457, 2457], [3, 64, 259, 11, 14970, 4, 1032, 12, 89, 602, 21, 111, 6, 1, 59, 15, 34, 66, 29, 44, 393, 4668, 271, 1498, 1398, 2679], [3, 64, 17, 60, 1485, 260], [3, 64, 17, 60, 1241, 24, 32, 5, 63, 119, 14971], [3, 64, 169, 948, 2, 1, 3, 266, 1040, 531], [3, 64, 10, 1543, 36, 10, 796, 14972, 23, 18, 4, 1194, 384, 1, 11, 4, 397], [3, 64, 4, 7173, 3817, 11, 4, 14973, 443, 507, 6, 751, 11, 5796, 43, 4567], [3, 64, 39, 185, 2368, 14974, 5, 299, 5, 220, 61, 6, 28, 2, 347, 1171, 1, 5, 41, 98, 183, 30, 2557], [3, 64, 22, 1, 52, 1656, 6, 10, 4942], [3, 64, 22, 236], [3, 64, 6, 119, 24], [3, 64, 6, 1090, 4, 24], [3, 64, 194, 95, 14975, 301, 3, 2467, 85, 15, 270, 2, 1258, 7914], [3, 64, 255, 858, 1568, 6, 197], [3, 64, 38, 77, 433, 35, 4, 189, 69, 67, 256, 112, 8, 6, 557, 76, 117, 21, 4, 189, 69, 33, 168, 240, 218, 88, 36, 1, 59, 15], [3, 64, 38, 10, 228, 100, 17, 168, 126, 310, 6, 1509, 4, 1, 7, 572, 17, 18, 3928], [3, 64, 38, 10, 306, 568, 6, 4, 7915, 1333, 444, 40, 28, 337, 8, 3, 44, 6, 1281, 15, 32, 2073, 88, 15, 249, 269, 879], [3, 64, 38, 111, 1, 59, 3605, 14, 389, 6, 1572, 13, 3298, 227, 142, 937, 57, 4, 19, 182], [3, 64, 38, 4, 24, 737, 98, 15, 372, 13, 42, 1223, 4594], [3, 64, 5, 10, 399, 34, 20, 2, 1262, 30, 91], [3, 64, 50, 73, 209, 8, 73, 358, 73, 3, 222, 581, 145, 26], [3, 14976, 6, 735, 4, 848, 13, 98, 354], [3, 1950, 194, 1069, 269, 36, 14, 1412, 60, 1621, 18, 1271], [3, 216, 97, 1, 14977, 125, 7, 68], [3, 216, 5, 1], [3, 70, 1, 635, 13, 1892, 2477, 58], [3, 3832, 173, 4, 2871, 7167, 54, 16, 14978, 71, 1038, 40, 313, 15, 11, 4, 56, 230, 3, 28, 6, 65, 51, 15], [3, 600, 74, 600, 48, 44, 51, 577, 445, 1793, 1342, 1356, 330, 893, 897], [3, 196, 3, 13, 6, 28, 530, 34, 7916, 10, 30, 35, 11, 2, 1, 231, 46, 11, 10, 2452, 1674], [3, 196, 31, 2, 1, 14979, 54, 40, 223, 28, 762, 364, 54], [3, 196, 31, 40, 2, 187, 88, 40, 2, 838, 15, 3781], [3, 196, 247, 574, 1075, 38, 6, 168, 7917, 8, 14980, 22, 153, 168, 4, 324, 14981, 38, 52, 1419, 168, 7917], [3, 196, 66, 63, 28, 7918, 73, 358, 66, 63, 821, 2, 14982, 14983, 15, 862, 83], [3, 4629, 3, 380, 3, 192, 168, 22, 361, 371, 104, 1126, 572, 17, 21, 72, 196, 184, 6, 462, 3684], [3, 14984, 5, 665, 2, 2446, 116, 15, 136, 6, 14, 2, 190, 11, 7, 3019, 43], [3, 1456, 1, 25], [3, 318, 1125, 4, 1, 34, 29, 87, 4, 1], [3, 346, 7566, 274, 148, 1, 112, 25, 129, 135, 260], [3, 346, 1347, 8, 7374, 14985, 14986, 3516, 6, 7919, 57, 12, 244, 14987, 2681], [3, 346, 44, 14988, 1, 11, 10, 14989, 3625, 4, 93, 802, 4669], [3, 346, 50, 34, 3, 75, 1, 3, 47, 4, 68, 69, 19, 35, 766], [3, 346, 10, 181, 228], [3, 346, 10, 788, 310, 233, 7, 1, 105, 309], [3, 346, 10, 269], [3, 346, 5, 14, 2, 2076, 4591, 187, 6, 17, 611, 106], [3, 346, 256, 16, 10, 3276, 2243, 115, 32, 626, 123, 143, 1815, 14990, 29, 4516, 14991, 2599, 72, 5, 13, 143, 207, 617], [3, 420, 7, 145, 3379], [3, 456, 14, 2, 1], [3, 456, 44, 633, 22, 25, 102, 2534, 2074, 140, 52, 10, 9, 26, 52, 208, 459, 493], [3, 226, 10, 25, 211, 2808, 14992, 25, 2206, 95, 12, 2, 5741, 172], [3, 226, 10, 138, 4, 910, 218, 1, 75, 806, 15, 128], [3, 226, 10, 1757, 1320, 7859, 140, 1, 75, 806, 254], [3, 87, 2, 14993, 3328, 8, 2, 535, 89, 1], [3, 87, 2, 1840, 2013, 36, 29, 44, 179, 7042, 36, 63, 7920, 36, 142, 27, 42, 634, 4, 3974, 8, 36, 14994], [3, 87, 2, 89, 1, 7, 276, 557, 17, 93], [3, 87, 2, 1], [3, 87, 2, 1], [3, 87, 2, 1, 6, 405, 15, 142, 21, 17, 55], [3, 87, 2, 1, 6, 61, 142, 13, 3, 87, 2, 257], [3, 87, 2, 1, 6, 503, 17, 634, 3, 28, 5797], [3, 87, 2, 1739, 1854, 8, 2, 587, 68, 59, 615, 415, 99, 515, 205, 6, 28, 2014], [3, 87, 2, 77, 82, 4670, 3, 75, 19, 27, 39, 339, 202, 1], [3, 87, 2, 1136, 1865, 140, 10, 628, 505, 37, 89], [3, 87, 2, 154, 1], [3, 87, 2, 4024, 1, 3, 46, 125, 7, 342, 45], [3, 87, 13, 5798, 858, 2708, 6, 376], [3, 87, 17, 2, 1], [3, 87, 17, 2, 112, 334, 30, 1], [3, 87, 68, 16, 212, 14995, 606, 821, 1196, 14996, 26, 662, 7, 1, 2037, 10, 618, 55], [3, 87, 376, 34, 75, 598, 6, 28, 7, 507, 7, 100, 5, 949, 142, 8, 376, 647], [3, 87, 60, 93, 24, 19], [3, 87, 60, 154, 9], [3, 87, 667, 9, 585, 667, 218, 3, 597, 35, 32, 3, 44, 12, 625, 2697, 34, 48, 2, 14997, 74, 1929, 7921, 45, 48, 110, 2, 419, 262], [3, 87, 6, 396, 531, 3572, 23, 144, 73, 19], [3, 87, 6, 1858, 27, 26, 162, 147, 153, 51, 55], [3, 87, 6, 756, 11, 4, 1495, 18, 14998, 21, 5799, 828, 90, 65, 13, 787, 14999, 3, 87, 6, 28, 7922, 181, 4671, 61, 6, 65, 13, 2, 15000], [3, 87, 6, 479, 808, 268, 15001, 4, 15002, 15003, 10, 342, 15004, 3085, 74, 10, 355, 2356, 1723, 4414, 68], [3, 87, 6, 2410, 35, 18, 60, 9], [3, 87, 6, 139, 14, 2, 141, 1, 55], [3, 105, 124, 245, 228, 4, 1119, 106, 3, 259, 11, 26, 43, 68, 47, 431, 6, 307, 3, 293, 212, 120, 56, 2738, 32, 2754], [3, 105, 137, 2, 836, 34, 1, 247, 857, 137, 36, 653], [3, 105, 157, 43, 9, 2713, 10, 280], [3, 105, 297, 2, 668, 74, 1745, 1, 554, 15005, 3, 15006, 36, 265, 33, 15007, 13, 79, 16, 3384], [3, 105, 299, 5, 222, 2083, 17, 2226, 333, 139, 14, 2, 19, 83, 1003, 20, 520, 157, 35, 27, 350], [3, 5673, 3970, 1309, 888, 140, 461, 170, 66, 118, 16, 105, 566, 16, 5546, 55, 159], [3, 469, 122, 6, 14, 474, 22, 1, 121, 40, 67, 11, 2, 4672, 7, 45, 210, 28, 17, 6549], [3, 101, 316, 35, 15008, 226, 6, 4, 9, 3, 62, 27, 265, 140, 36, 87, 6, 62], [3, 101, 19, 27, 89, 1, 23, 4673], [3, 101, 13, 287, 69, 24, 532, 13, 1965, 873], [3, 101, 538, 1, 7, 538, 15009, 15010], [3, 101, 131, 94, 89, 1, 18, 1396, 1858], [3, 5800, 279, 218, 3, 41, 319, 147, 2592, 3, 41, 2804, 16, 240], [3, 5800, 13, 43, 3778, 1, 37, 3, 33, 3139, 531, 163, 45], [3, 5800, 13, 7, 178, 125, 7, 144, 30, 95], [3, 4640, 1124, 6, 14, 4, 822, 16, 120, 56, 7, 103, 484, 1117, 975, 6, 4, 1069, 2539, 27, 351, 341, 381, 26, 470, 1990, 15011], [3, 748, 885, 1018, 1499, 851, 26, 22, 1, 502, 17, 860, 251, 3, 487, 110, 114, 4, 45, 108, 140, 3, 47, 276, 14, 713, 21, 197], [3, 310, 688, 431, 34, 339, 23, 5801, 1, 37, 1015, 163, 3520], [3, 479, 7923, 21, 10, 3117, 3, 44, 6, 14, 60, 698, 16, 187, 367], [3, 406, 6615, 298, 35, 4, 234, 16, 1793, 7924, 27, 155, 115, 11, 6222], [3, 893, 18, 119, 22, 1119, 1400, 1421, 3, 33, 748, 13, 2, 3177, 83], [3, 2689, 3763, 3975, 6, 48, 569, 18, 886, 51, 1284, 148, 2993], [3, 349, 9, 15012], [3, 349, 35, 11, 2, 2451, 80, 1], [3, 157, 50, 24, 18, 4, 5802], [3, 157, 15, 2422, 1, 70, 50, 1467, 581, 644, 3, 502, 22, 9, 138, 3, 510, 3, 440], [3, 2510, 467, 37, 551, 1, 2083, 17], [3, 516, 194, 4, 5470, 7925, 786, 8, 5470, 7925, 15013, 137, 286], [3, 623, 15014, 12, 2, 1], [3, 109, 195, 156, 116, 21, 10, 1, 8, 36, 62, 7, 26], [3, 109, 14, 15015, 1, 27, 43, 437, 11, 1641, 752, 340, 3, 29, 62, 31, 15, 10, 872, 74, 10, 7926, 74, 485, 15, 33, 10, 1008, 552], [3, 109, 75, 397, 288, 111, 4044, 45, 4275, 56], [3, 109, 1694, 6, 19, 27, 4, 15016, 16, 1], [3, 109, 29, 14, 1160, 21, 1, 18, 685, 7848, 58, 3, 81, 6, 76, 2140, 58, 3, 67, 15017], [3, 109, 29, 13, 7, 399, 1939, 205], [3, 109, 28, 1917, 38, 10, 1613, 228, 44, 246, 342, 991, 682, 15018, 23, 614, 6, 14, 4, 101, 342, 3422, 42, 662, 125], [3, 109, 90, 2, 203, 1, 149, 23, 15019, 64, 366, 625, 5803, 38, 23, 150, 1045, 15020, 15021], [3, 109, 90, 14, 2, 1, 6, 111, 34, 51, 22, 446, 3, 43, 1363, 134, 2, 19], [3, 109, 90, 38, 3, 29, 28, 2, 1680, 108, 6, 2, 262, 7477, 13, 2, 1, 46, 94, 15, 74, 667], [3, 109, 293, 5, 8, 7927, 29, 28, 108, 612, 5, 63, 58, 37, 209, 165, 130, 7, 188, 29, 79, 50, 2, 9], [3, 109, 33, 200, 60, 9, 2745, 34, 33, 37, 42, 62, 23, 101, 2, 9, 21, 1753], [3, 109, 33, 131, 3942, 20, 19, 235, 11, 34, 151, 65, 13, 2, 1, 31, 167, 15022], [3, 109, 33, 67, 6, 204, 60, 3893, 235, 2769, 330, 63, 314, 261, 14, 129, 92, 333], [3, 109, 86, 574, 2024, 5804, 313, 18, 3716, 51, 4, 967, 38, 1, 49, 1506, 129], [3, 109, 131, 44, 2, 81, 59, 164, 27, 4, 993, 50, 117, 11, 4, 887, 252, 288, 1921, 2, 866, 230, 3, 309], [3, 109, 67, 2, 77, 6, 70, 17, 60, 348], [3, 109, 67, 2, 1201, 883, 6, 28, 2, 1245, 269, 8, 226, 170, 15023], [3, 109, 301, 3, 373, 2, 3315, 7928, 6, 168, 18, 155, 144, 484, 11, 580, 16, 17, 225], [3, 1813, 148, 1, 49, 156, 81, 45, 59, 4552], [3, 1813, 6, 878, 2, 1388, 11, 22, 1, 30, 3671], [3, 375, 201, 16, 10, 228, 124, 22, 8, 3, 47, 7929, 124, 22, 1, 5, 487, 113, 17, 45, 321], [3, 375, 973, 18, 2, 3431, 618, 211, 14, 565, 2910, 59, 71, 3333, 7564, 47, 248], [3, 375, 17, 26, 4553, 47, 687, 26, 52, 276, 72, 7930, 35, 1, 7, 85, 5, 999, 17, 53, 33, 1133], [3, 375, 4, 7749, 5260, 1130, 79, 263, 1260, 16, 4, 3875, 3, 47, 542, 6, 788], [3, 375, 76, 1, 695], [3, 375, 38, 15024, 551, 30, 976, 1922, 288, 66, 162, 32, 137, 3130, 1936, 57, 2, 181], [3, 375, 38, 1, 452, 100, 2, 25, 19, 21, 13, 292, 707, 92, 15, 292, 115, 74, 37], [3, 375, 38, 15, 47, 15025, 54, 21, 50, 40, 136, 15026, 92, 15, 6149, 423, 82, 7, 9, 40, 136, 15027], [3, 375, 38, 22, 161, 1, 906, 17, 5791, 163, 124, 17, 28, 1427, 347, 98, 201, 1204, 790, 23, 541, 51, 22, 25, 5472, 2, 743, 11, 10, 1511], [3, 3820, 2, 260, 95], [3, 538, 245, 25, 7, 113, 17, 52, 41, 2, 1, 37, 3, 616, 4, 19, 108, 43, 90], [3, 498, 224, 27, 37, 32, 76, 1, 63, 94, 17], [3, 694, 2, 866, 165, 130, 4, 1, 11, 15028, 149, 23, 4, 1065, 657, 135], [3, 121, 848, 261, 115, 73, 11, 4, 179, 193, 7931, 8, 57, 3, 195, 2174, 135, 6, 1268, 5, 57, 49, 5, 4565], [3, 2002, 6, 4, 9, 69, 636, 36, 15029, 166, 130, 7, 1, 346, 17], [3, 486, 37, 239, 339, 1, 33, 479, 35, 10, 261, 2951, 3, 716, 67, 6, 313, 35, 7017], [3, 72, 5805, 12, 3976, 140, 40, 317, 208, 13, 2, 15030, 99, 2446, 51, 4, 476, 8, 15031, 44, 6, 257, 4, 83], [3, 72, 19, 76, 166, 25, 1, 23, 32, 5, 87], [3, 72, 1131, 4, 15032, 3, 303, 2, 154, 68, 9], [3, 72, 66, 32, 58, 2, 180, 203, 493, 16, 4396, 211, 4, 15033, 18, 5, 24, 1145], [3, 94, 2, 112, 153, 38, 3, 65, 11, 4, 2772], [3, 94, 1, 46, 132, 58, 1573, 34, 15034, 26, 15035], [3, 94, 4, 199, 9], [3, 94, 785, 32, 5, 365, 1, 26, 956], [3, 94, 42, 3631, 3424, 15036], [3, 94, 97, 180, 1587, 11, 4, 354, 1259], [3, 94, 5, 19, 283, 3, 19, 1, 4510], [3, 94, 20, 175, 1, 425, 7665, 543, 17, 6, 4, 4159, 3, 198, 79, 163, 3056, 50, 30, 54], [3, 297, 7932, 9, 60, 25, 51, 4, 3152, 99], [3, 5229, 58, 346, 10, 674, 782], [3, 512, 51, 4, 24, 3, 912, 11, 4, 24, 23, 15037, 99, 15038], [3, 565, 2, 1740, 140, 9, 176, 719, 10, 7283], [3, 198, 14, 11, 865, 15, 2, 2672, 9, 3, 204, 39, 257], [3, 198, 14, 4, 101, 25, 10, 1, 262, 117, 92], [3, 198, 2212, 2, 15039, 15040, 9], [3, 198, 2825, 1390, 10, 1282, 4654, 738, 15, 716, 28, 54, 16, 402], [3, 198, 192, 255, 1493, 127], [3, 1419, 3006, 5, 38, 3, 47, 129, 116, 31, 101, 3, 47, 531, 8, 3, 745, 429, 7, 81, 59, 42, 101, 87, 268, 167, 1, 333], [3, 1419, 3433, 2, 413, 694, 16, 4345, 8, 216, 50, 707, 7, 83], [3, 229, 58, 13, 4, 7933, 147, 1576, 70, 17, 131, 458, 35, 2, 1015, 656, 7266, 8, 79, 32, 143, 120, 617, 2109], [3, 229, 64, 6, 326, 48, 18, 852, 106, 3, 33, 90, 861, 35, 111, 7, 9, 45], [3, 2131, 15041, 9, 218, 3, 75, 973, 35], [3, 1705, 93, 3958, 1, 205], [3, 532, 3, 532, 3, 532, 24], [3, 366, 2, 203, 1381, 16, 2994, 8, 616, 18, 10, 30, 2693, 130, 4, 203, 1, 69, 4162, 142, 6, 3287], [3, 366, 2, 320, 16, 441, 6, 176, 76, 1, 16, 581, 453], [3, 6204, 45, 27, 127, 77, 11, 10, 5774, 130, 2, 252, 128, 2543, 235, 1820], [3, 372, 144, 34, 52, 12, 683, 5332], [3, 1049, 10, 169, 18, 441, 754, 163, 522, 48, 9], [3, 2266, 10, 413, 2700, 541, 21, 10, 1541, 346, 4, 5806, 8, 32, 230, 3, 623, 3, 210, 44, 245, 1541], [3, 2735, 2, 535, 640, 9, 18, 15042], [3, 1509, 10, 1214, 3961, 8, 253, 245, 77, 7, 1657, 27, 1167, 626, 4, 1], [3, 192, 15043, 1147, 233, 15044, 161, 1], [3, 271, 423, 82, 1, 7, 14, 1937, 3, 14, 7934, 54, 11, 775, 72, 23, 7935], [3, 96, 75, 28, 129, 60, 16, 39, 144, 61, 673, 45, 129, 22, 1074, 473, 70, 43, 1237, 6, 17, 57, 37, 1269], [3, 96, 75, 594, 85, 66, 29, 1476, 305, 56, 11, 4, 15045, 15, 322, 180, 8, 4652, 362, 14, 3726, 130, 15046, 15, 173, 15047], [3, 96, 90, 4, 1, 51, 4, 2257, 9], [3, 96, 94, 2804, 339, 1, 27, 1074, 7936], [3, 96, 86, 1396, 1858, 21, 104, 8, 314, 7937], [3, 139, 1396, 18, 287, 8, 79, 76, 283], [3, 608, 32, 16, 10, 638, 8, 1, 58, 961, 45, 18, 4, 1684, 234, 8, 11, 10, 620, 819], [3, 300, 3, 279, 59, 474, 499, 34, 39, 1, 26], [3, 300, 3, 41, 7, 45, 7, 70, 4, 1, 61, 4674], [3, 300, 3, 90, 38, 23, 1504, 8, 2, 414, 430, 10, 15048, 7, 1113, 72, 7938, 3977, 15049, 8, 191, 17, 195, 3, 2, 15050, 367, 1, 55], [3, 300, 3, 566, 7, 1, 15051], [3, 300, 3, 1551, 61, 18, 163, 61, 108, 6, 4, 206, 17, 140, 1, 86, 15, 2, 178, 4319, 100, 14, 112], [3, 300, 3, 475, 59, 17, 8, 295, 34, 307, 3, 176, 43, 166, 1, 18, 10, 15052, 23, 48, 15053], [3, 300, 15054, 15055, 14, 525, 2, 153, 233, 133, 6, 192, 509, 10, 373, 148, 4926], [3, 300, 2, 153, 376, 34, 23, 35, 233, 515, 73, 1156], [3, 300, 46, 295, 1128, 130, 2, 89, 1, 7, 514, 15], [3, 300, 1, 12, 15056, 3, 13, 2, 327, 749, 23, 19, 7, 1], [3, 300, 1, 452, 44, 295, 6, 475, 59, 34, 36, 29, 62, 71, 6, 242, 4, 19, 562], [3, 300, 325, 9, 15057, 22, 1262, 163, 643, 1611, 65, 13, 2, 1613, 15058], [3, 300, 275, 86, 36, 62, 3651, 1, 5, 29, 62, 10, 2768, 5, 33, 86, 5, 58], [3, 300, 77, 27, 93, 24, 86, 7, 4, 729, 6, 474], [3, 300, 432, 94, 71, 291, 153, 96, 54, 135, 525, 24, 251], [3, 300, 357, 428, 279, 59, 1987, 115, 650, 36, 49, 419, 26, 15059, 8, 67, 6, 83], [3, 300, 357, 63, 733, 59, 9, 570, 36, 44, 6, 597, 35, 6, 61, 6, 1869, 140, 357, 597, 35, 51, 3978, 6, 28, 542], [3, 300, 2177, 274, 25, 32, 1019, 9, 67, 12, 2, 15060, 749], [3, 300, 7, 9, 340, 122, 2021], [3, 300, 4, 111, 656, 4, 1294, 1868, 57, 234, 4, 56, 1259, 3805, 63, 49, 18, 18, 1405, 6, 780, 27, 307], [3, 300, 39, 15061, 181, 61, 6, 2311, 33, 6, 114, 406, 6, 448, 6, 1610, 2919, 3, 47, 15062, 986], [3, 300, 39, 9, 15063, 41, 295, 18, 5, 2064], [3, 300, 22, 9, 132, 253, 17, 182, 371, 3, 363, 18, 421], [3, 300, 6, 274, 3, 14, 11, 4, 848, 16, 4, 489, 70, 54, 125, 1, 13, 23, 238, 2348, 2, 7939, 3687, 74, 1406], [3, 300, 6, 274, 3, 167, 1369, 735, 23, 161, 340, 8, 23, 48, 43, 1, 38, 23, 102, 7, 961, 3, 1505, 10, 1], [3, 300, 6, 274, 60, 9, 65, 13, 36, 114, 4, 199, 5539, 406, 15064, 396, 15, 35, 21, 469, 15065], [3, 300, 78, 1383, 27, 2, 154, 1, 155, 15066, 75, 110, 28, 68, 3940, 485, 256, 12, 329, 27, 17], [3, 300, 154, 1, 135, 17, 742, 8, 15, 2, 1730], [3, 114, 2, 1, 337, 134, 50, 358, 138], [3, 114, 392, 3442, 11, 4, 30, 10, 734, 136, 37, 1236, 17, 2047, 92, 50, 12, 33, 4675, 18, 32, 7940, 50, 190, 30, 41, 108, 21, 213], [3, 114, 15, 15067, 7941, 12, 96, 248], [3, 114, 565, 125, 43, 7942, 3, 28, 1, 3, 29, 778, 240], [3, 81, 6, 39, 1, 13, 3, 109, 58, 2800], [3, 81, 6, 60, 4425, 3, 976, 11, 64, 7943], [3, 113, 2, 1, 3, 29, 64, 45, 19, 1406], [3, 113, 1, 3, 41, 7, 15068, 647, 2071, 4676, 7163, 513], [3, 113, 4, 2317, 1, 6, 28, 4, 2248, 1, 6, 6, 44, 4, 2588, 1, 316, 2760], [3, 113, 4, 832, 9, 257, 15, 650, 5, 223, 1692], [3, 113, 4, 15069, 7, 1, 12, 183, 221, 50, 2092, 8, 734, 776, 3, 47, 223, 308, 59, 1905, 34, 280, 3, 124, 6, 113, 4, 3544], [3, 113, 22, 1, 5807, 40, 725, 17, 72, 5807, 88, 317, 5807, 572, 13, 19], [3, 113, 42, 22, 205, 15070, 42, 158, 287, 192, 28, 15071, 15072, 33, 29, 58, 15], [3, 262, 10, 500, 10, 154, 1, 24, 4026], [3, 3430, 23, 2, 322, 1696, 1, 97, 62], [3, 86, 3, 291, 2, 15073, 38, 3, 976, 11, 7, 4677, 227, 173, 2, 24, 3, 86, 1591], [3, 86, 3, 1244, 54, 162, 120, 56, 732, 107, 82, 4, 15074, 820, 16, 15075], [3, 86, 3, 592, 2, 1975, 3979, 361, 3267, 14, 6, 847, 39, 1254, 68, 49, 59, 6, 28, 126, 977, 935, 11, 126, 376], [3, 86, 3, 33, 146, 1273, 4, 488, 7, 32, 39, 1, 152, 14, 9, 1062, 36, 224, 4, 1247, 16, 2783, 8, 164, 103, 14, 2, 320, 2245], [3, 86, 3, 204, 2, 15076, 34, 7, 386, 16, 2, 1, 47, 3287, 3, 87, 6, 536, 10, 15077], [3, 86, 3, 509, 4, 884, 1876, 1269, 2097, 15078, 8, 68, 16, 4, 201, 961, 283, 1776, 68, 16, 39, 268, 1642, 11, 7944], [3, 86, 151, 44, 2107, 904, 21, 1255, 1185, 146, 70, 35, 21, 4, 457, 348, 15079], [3, 86, 151, 33, 119, 22, 348, 8, 433, 54], [3, 86, 23, 2, 1, 390], [3, 86, 23, 152, 294, 224, 4, 331, 351, 73, 2, 1187], [3, 86, 23, 44, 10, 189, 1230, 1185, 3, 44, 132, 270, 98, 1393, 1, 5808, 5808, 5808], [3, 86, 2, 320, 16, 1, 29, 872, 11, 126, 1142, 140, 126, 1238, 1729, 8, 36, 29, 67, 6, 7945, 35, 126, 580, 1651], [3, 86, 59, 4, 488, 7, 7946, 3157, 173, 95, 155, 106, 3, 119, 4433, 7946, 49, 15080], [3, 86, 7947, 745, 65, 51, 2, 3060, 11, 2, 413, 691, 1027, 76, 9, 420, 1026, 2117, 15081], [3, 86, 32, 384, 9, 18, 4972, 15082], [3, 86, 32, 78, 468, 78, 25, 218, 4, 658, 396, 78, 658, 9], [3, 86, 147, 79, 17, 2, 158, 57, 58, 420, 423, 82, 143, 991, 234, 196], [3, 86, 155, 1, 125, 2, 1200, 1663, 249, 138, 23, 33, 14, 112], [3, 86, 15, 356, 71, 9, 81, 133, 14, 15083], [3, 86, 39, 1, 238, 644, 17, 15084], [3, 86, 22, 25, 144, 1080], [3, 86, 287, 103, 1115, 258, 2, 193, 21, 2, 189, 6, 14, 640, 205, 33, 37, 36, 63, 150, 13, 15085, 24, 136, 60, 15086, 15, 3854], [3, 86, 5, 2, 203, 1, 31, 3, 105, 94, 97, 481, 18, 4, 909, 8, 5, 41, 295, 34, 833, 35, 830], [3, 86, 5, 172, 125, 4, 329, 145], [3, 86, 20, 11, 2, 89, 2156, 82, 4289, 18, 1031, 285], [3, 86, 814, 216, 15, 1891, 7, 39, 9, 46, 334], [3, 299, 3, 64, 22, 1, 6, 4, 4365], [3, 299, 15, 47, 1899, 6, 257, 80, 9], [3, 299, 15, 47, 280, 129, 9, 380, 48], [3, 299, 40, 47, 1376, 205], [3, 299, 7, 1, 47, 1174, 493, 17], [3, 815, 2909, 97, 83], [3, 15087, 7, 9, 201, 329, 1138, 70, 2, 2592, 92, 40, 131, 751], [3, 273, 50, 776, 3, 121, 15088, 29, 28, 11, 5789, 27, 621, 140, 20, 56, 51, 1732, 8, 88, 40, 568, 8, 5789, 27, 13, 688, 1554], [3, 273, 10, 306, 40, 119, 6683, 183, 26, 40, 276, 72, 1322, 2, 1395, 141, 368, 3, 33, 299, 3, 198, 100, 1, 62], [3, 273, 7, 1, 1004, 59, 2, 2680, 1], [3, 273, 7, 418, 113, 4, 910, 31, 5, 4, 2166, 1, 3, 182, 704, 88, 229, 17, 60, 2146], [3, 273, 7, 141, 1, 30, 25, 2835, 15, 65, 13, 23, 59, 6, 119, 20, 743, 15089, 151, 491, 5, 8, 20, 9, 30, 15090], [3, 273, 78, 52, 47, 61, 6, 58, 7, 45, 15091, 24, 177], [3, 424, 201, 15092, 2205, 15093, 959, 15094, 938, 3369, 324, 15095, 8, 1228, 2, 966, 5464, 16, 15096, 3980, 2205, 15097, 232, 11, 2738, 15098], [3, 2742, 108, 11, 106, 6, 15099, 8, 15100, 35, 18, 10, 4423, 3, 935, 4, 4146, 977, 8, 123, 6320, 4482, 173, 10, 15101, 3913], [3, 557, 10, 1, 27, 538], [3, 122, 79, 10, 370, 30, 1081, 21, 50, 6159, 7492, 34, 4, 9, 46, 729, 13, 7948, 40, 99, 180, 106, 39, 115, 55], [3, 122, 8, 28, 108, 173, 978, 34, 3, 300, 155, 229, 5809, 224, 519, 3981, 77, 74, 4, 177, 69, 49, 99, 24, 6, 81, 6, 76], [3, 122, 6, 433, 170, 35, 28, 11, 15102, 433, 170, 52, 33, 65, 51, 17, 13, 23, 137, 2, 178, 58, 3, 1835, 84, 1004, 29, 19, 545, 17, 1], [3, 227, 15103, 6, 2, 530, 9, 1350, 6, 2, 1677, 9], [3, 227, 1, 315, 36, 86, 32, 4, 166, 1, 63, 19, 13, 307], [3, 227, 18, 4, 394, 2276, 21, 546, 710, 8, 41, 6, 125, 1107, 1, 28, 551, 8, 15104, 856, 6, 15105], [3, 2885, 2, 496, 15106, 70, 169, 54, 16, 1347, 5184, 11, 351, 3257, 2802], [3, 2885, 2, 496, 1588, 18, 15107, 7949, 1005, 15108, 5344, 3028, 8], [3, 168, 6, 131, 19, 7, 1, 34, 48, 43, 1091], [3, 168, 6, 901, 2876, 8, 1685, 7033, 3, 560, 168, 6, 901, 2876, 8, 15109, 3, 168, 6, 901, 15110], [3, 168, 6, 28, 7950, 2, 320, 1000, 485, 7, 85, 10, 508, 1144, 37, 5810], [3, 168, 6, 406, 170, 107, 35, 4, 15111, 6, 1793, 7924, 27, 2, 3443, 16, 5514, 21, 17], [3, 168, 6, 86, 7, 1, 47, 89, 188, 34, 48, 43, 3901], [3, 597, 35, 155, 561, 301, 2, 1, 3694], [3, 3012, 58, 2, 15112, 2775, 98, 2837, 15113], [3, 131, 1918, 21, 14, 270, 2, 1, 4, 166, 15114, 34, 4, 193, 10, 1393, 49, 644, 2360], [3, 131, 14, 224, 1, 26, 44, 501], [3, 131, 14, 217, 1, 30, 520, 117, 92, 26, 34, 7, 33, 17, 235, 868, 178, 18, 97, 1587], [3, 131, 303, 10, 1, 155, 558], [3, 131, 311, 10, 343, 34, 23, 99, 624, 14, 2, 1, 59, 254], [3, 131, 119, 4, 19, 42, 81, 133, 88, 1], [3, 131, 1924, 7, 713, 954, 26, 570, 1369, 24], [3, 131, 28, 22, 9, 18, 10, 1291, 27, 2, 2454, 107, 54, 16, 4, 15115], [3, 131, 61, 6, 2, 56, 81, 2341], [3, 131, 94, 60, 30, 2427, 645, 1448, 3, 3012, 94, 2, 1, 28, 18, 36, 235, 996, 1019, 15116], [3, 131, 122, 1616, 2122], [3, 67, 354, 69, 63, 547, 17], [3, 67, 2, 1739, 1854], [3, 67, 2, 1763, 4049, 117, 92, 37, 3, 63, 901, 15, 8, 61, 344, 6, 2791], [3, 67, 2, 77, 3000, 24, 532, 13, 3939], [3, 67, 2, 699, 401, 37, 3, 63, 28, 423, 82, 474, 8, 14, 123, 531, 21, 268, 5228, 3, 90, 14, 224, 111, 650, 36, 49, 10, 2243], [3, 67, 32, 10, 9, 108], [3, 67, 17, 2, 490, 30, 77, 55], [3, 67, 10, 1, 6, 729, 31, 10, 500, 79, 27, 10, 138, 11, 50, 476], [3, 67, 68, 3427, 5, 6, 192, 256, 27, 17, 1249, 34, 5, 49, 1210, 24], [3, 67, 60, 851, 348, 8, 684, 3601], [3, 67, 60, 739, 353, 48, 4, 260, 30, 739, 197, 277, 3204, 44, 739, 353], [3, 67, 60, 269, 1407], [3, 67, 60, 269, 7951], [3, 67, 6, 14, 73, 5595, 73, 738, 73, 3, 2960, 3, 29, 13, 2579, 18, 1225, 70, 17, 150, 13, 2, 83], [3, 67, 6, 257, 22, 1, 30, 1933, 89], [3, 67, 6, 61, 6, 4, 2617, 7798, 34, 4, 64, 95, 103, 70, 15, 2, 438, 8, 88, 4, 763, 16, 263, 103, 14, 15117], [3, 67, 6, 1622, 34, 104, 266, 1622, 27, 1566], [3, 67, 6, 1986, 35, 27, 32, 39, 319], [3, 67, 80, 1, 3, 61, 28, 50, 3, 1131, 1905, 92, 40, 266, 100, 35], [3, 47, 2, 1139, 15118, 13, 3, 124, 3938, 34, 101, 140, 10, 3652, 2681, 87, 283], [3, 47, 2, 216, 153, 38, 3, 47, 2, 379, 153], [3, 47, 4637, 16, 105, 114, 2, 392, 580, 231, 565, 37, 135, 12, 1155, 43, 1650, 74, 4678, 74, 2766, 513], [3, 47, 51, 2, 355, 480, 18, 15119, 26, 2720, 15120, 26, 60, 1, 7, 724, 17, 47, 99, 243, 6, 94, 15121, 1, 47, 556, 28, 11, 10, 6377, 930], [3, 47, 51, 10, 1214, 994, 331, 225, 784, 539, 206, 1623, 8, 84, 2902, 124, 927, 327, 16, 84, 234, 236, 82, 4, 1243], [3, 47, 148, 1196, 15122, 27, 4, 1, 5290, 15123, 1210, 44, 393, 139, 5, 82, 119, 24, 31, 37, 57, 47, 15], [3, 47, 119, 26, 10, 306, 276, 72, 2596, 1954, 3945, 364, 1, 3, 195, 1954], [3, 47, 1596, 50, 59, 2, 449, 15124, 92, 40, 33, 2, 1482, 15125, 9], [3, 47, 635, 142, 4, 699, 8, 33, 2423, 173, 22, 969, 668, 177, 265, 41, 35, 13, 2, 4463, 8, 294, 15, 102], [3, 47, 28, 6, 4, 624, 288, 5, 47, 778, 4, 1], [3, 47, 2096, 4, 199, 518, 73, 196, 852, 875, 11, 314, 261, 34, 47, 105, 73, 1715, 73, 7, 386, 16, 2, 83], [3, 47, 152, 157, 3, 131, 119, 4, 24, 13, 2, 3774, 11, 50, 844, 34, 374, 1828, 3740], [3, 47, 1262, 123, 4, 106, 3, 227, 1913, 125, 101, 10, 994, 399], [3, 47, 1679, 119, 4, 24, 34, 23, 18, 2, 2093], [3, 47, 11, 64, 27, 159], [3, 47, 11, 4, 1079, 940, 8, 22, 1, 121, 256, 8, 3, 363, 102, 59, 50, 734, 8, 876, 40, 47, 13, 584, 15126], [3, 47, 11, 4, 489, 8, 116, 47, 22, 93, 541, 83, 7952, 124, 1052, 1022, 1000, 3, 47, 1075, 251], [3, 47, 3256, 59, 2, 95, 15127, 225, 7, 3, 222, 48, 258, 2, 4530, 3378, 15128, 15129, 74, 15130], [3, 47, 265, 189, 3, 29, 44, 9, 29, 100, 308, 6, 3633], [3, 47, 599, 15131, 38, 898, 405, 7, 5811, 2, 1, 82, 245, 25, 7, 57, 66, 7953, 2658, 3, 63, 578, 4, 4793, 92], [3, 47, 541, 13, 38, 384, 153, 273, 17, 147, 45], [3, 47, 137, 451, 11, 4, 2635, 8, 92, 10, 306, 176, 191, 1458, 1542, 134, 2, 1, 20, 548, 38, 40, 516, 44, 2, 5812], [3, 47, 366, 2, 866, 619, 8, 39, 530, 823, 1, 756, 173, 4, 2720, 927, 7, 2720, 12, 530, 73, 19], [3, 47, 270, 2, 24, 108, 88, 55, 13, 15, 284], [3, 47, 273, 105, 4200, 26, 105, 506, 10, 508], [3, 47, 122, 19, 256, 225, 8, 22, 1, 67, 308, 81, 133, 84, 646, 47, 18, 84, 3692, 425, 3, 150, 15132], [3, 47, 27, 2, 1, 27, 2, 15133, 21, 2, 213, 8, 2, 470, 369, 12, 329, 4475, 17], [3, 47, 197, 332, 73, 2, 1, 225, 3, 655, 2, 5051], [3, 407, 1348, 215, 264, 3, 62, 39, 9, 46, 117], [3, 407, 1348, 215, 264, 3, 62, 39, 9, 46, 117], [3, 407, 1348, 3902, 3, 62, 39, 9, 46, 117], [3, 407, 79, 5, 2, 104, 34, 5, 49, 68, 649], [3, 194, 68, 8, 2, 1, 555, 4, 1651, 121, 3525, 87, 6, 1867, 15134, 15135, 59, 6, 7362, 4208], [3, 219, 19, 622, 99, 1], [3, 363, 82, 1220, 347, 6, 2, 1, 27, 60, 1220, 6466], [3, 363, 619, 8, 41, 214, 426, 22, 1032, 12, 56], [3, 363, 6, 94, 22, 12, 162, 3, 338, 5, 51, 2, 629, 7805, 27, 1879, 8, 112, 522, 15, 47, 7954, 3, 748, 2, 348, 15136, 1145], [3, 15137, 38, 309, 8, 3, 7955, 2903, 213, 3026], [3, 103, 257, 2, 1, 30, 364], [3, 103, 119, 39, 9, 1524], [3, 103, 599, 105, 28, 337, 22, 45, 12, 144], [3, 103, 48, 338, 10, 25, 34, 5, 63, 14, 10, 1, 99], [3, 301, 210, 572, 17, 358, 892, 21, 79, 170, 2, 24, 37, 3, 222, 79, 170, 2, 24, 361, 8, 28, 572, 2, 710, 817], [3, 301, 3, 222, 61, 6, 147, 1, 945], [3, 301, 3, 222, 3765, 1173, 5119, 34, 661, 76, 1, 15138, 15139, 26, 15140, 7, 60, 385], [3, 301, 3, 222, 929, 4, 2367, 213, 206, 17, 21, 14, 270, 2, 640, 1], [3, 301, 3, 124, 2, 540, 6, 303, 2, 2611, 21, 2, 2242, 34, 1113, 1, 29, 62, 57, 212, 1563], [3, 301, 3, 105, 704, 7, 1, 280, 18, 274], [3, 301, 3, 366, 37, 3, 222, 167, 127, 7956, 1818, 9], [3, 301, 3, 118, 687, 27, 2, 25, 74, 2, 1, 571, 33, 528, 51, 97, 30], [3, 301, 4800, 118, 559, 229, 17, 32, 39, 1383, 27, 7, 144, 1432, 15141, 374, 48, 1220, 602, 6, 7747, 27, 307], [3, 301, 379, 1021, 216, 722, 17, 4, 15142, 8, 1874, 1439, 30, 1655, 54, 7, 1], [3, 301, 2, 1, 222], [3, 301, 2, 1, 118], [3, 301, 2, 399, 118, 122, 22, 1353, 45, 11, 15143], [3, 301, 1628, 127, 275, 118, 175, 59, 249, 1270, 23, 515, 16, 17, 8, 186, 25, 175, 59, 119, 285, 66, 87, 7957], [3, 301, 1, 118, 14, 344, 35, 125, 126, 228, 8, 113, 240, 36, 65, 183, 38, 36, 109, 58, 8, 48, 72, 36, 342, 251], [3, 301, 416, 3, 724, 407, 2, 104, 2, 122, 332, 74, 2, 15144], [3, 301, 104, 13, 118, 139, 70, 451, 3065, 620, 47, 19, 15145, 28, 4, 19, 459, 15146], [3, 301, 9, 210, 723, 15147, 452, 44, 22, 437, 8, 118, 1495, 51, 9, 523, 263, 155, 4413], [3, 301, 10, 1, 30, 639, 118, 134, 17, 10, 15148, 15149, 608, 172, 1], [3, 301, 10, 646, 118, 139, 316, 537, 1, 11, 10, 331], [3, 301, 111, 222, 33, 14, 344, 35, 27, 307, 29, 14, 2, 365, 1, 6, 17, 140, 23, 48, 2, 365, 1, 6, 350, 74, 621, 7302], [3, 301, 574, 118, 683, 71, 364, 6, 271, 54, 10, 624, 23, 2, 1262, 30, 91, 26, 3, 61, 162, 3, 333, 26, 453, 20, 148, 624, 1], [3, 301, 186, 124, 2, 15150, 22, 368, 3444], [3, 301, 97, 5578, 1040, 97, 265, 13, 97, 1040, 39, 564, 283], [3, 301, 3, 301, 3, 301, 3, 301, 3, 301, 3, 301, 2, 1, 15151, 7604, 40, 330, 200, 152, 44, 6, 806, 22], [3, 125, 4679, 9, 1709, 239, 25, 51, 4, 3152, 632, 35, 23, 81, 870, 1291, 15152, 99], [3, 7958, 61, 6, 15153, 1], [3, 1025, 35, 8, 40, 47, 330, 554, 19, 147, 1], [3, 1025, 35, 11, 2, 618, 392, 16, 1, 7, 3, 46, 15154, 172], [3, 1025, 35, 11, 2, 618, 392, 16, 1, 7, 3, 46, 110, 172], [3, 266, 58, 777, 27, 4, 1, 40, 75, 110, 28, 17, 332], [3, 266, 72, 71, 239, 1, 3, 19, 34, 3, 318, 72, 71, 239, 947, 3, 881], [3, 266, 302, 2, 1], [3, 454, 71, 239, 232, 408, 49, 505, 7, 1098, 891, 12, 54, 444, 211, 4, 32, 883, 421, 128], [3, 454, 31, 3299, 408, 652, 3764, 7, 36, 49, 983, 187, 74, 36, 49, 3764, 34, 49, 33, 422, 27, 254], [3, 454, 31, 7, 3307, 7959, 12, 197, 15155, 957, 142, 18, 15156, 34, 15157, 18, 15158, 18, 15159], [3, 454, 31, 7, 1, 544, 478], [3, 454, 31, 116, 182, 2, 115, 11, 10, 746, 164, 7, 40, 182, 48, 2, 983, 8, 15160, 1, 74, 31, 40, 492, 15, 1101, 33, 21, 17], [3, 454, 31, 186, 210, 1166, 406, 8, 830, 71, 239, 253, 78, 118, 109, 44, 188, 1027, 78, 1, 29, 14, 533, 133, 45], [3, 454, 38, 987, 309, 57, 103, 32, 4, 9, 7, 3086, 360, 883, 1303, 259, 14, 13], [3, 454, 162, 32, 39, 1, 3, 41, 51], [3, 454, 69, 2171, 7, 15161, 519, 2, 9, 147, 100, 2, 607, 16, 76, 25, 257, 6, 43, 3190, 74, 2, 1, 25, 69, 9, 100, 2, 607, 16, 240, 257], [3, 118, 1, 59, 4, 1032, 14, 15162, 34, 23, 33, 152, 1512, 71, 417, 15, 12, 661], [3, 118, 79, 5, 2, 1, 34, 7, 15163, 7512], [3, 118, 1694, 4, 763, 16, 10, 315, 164, 6, 14, 2, 983, 1843, 6366, 1529, 31, 3, 222, 14, 15164, 15165, 83], [3, 118, 1589, 79, 2507, 2, 15166, 1505, 104, 31, 3, 220, 15167], [3, 118, 2162, 725, 197, 73, 7524], [3, 118, 338, 10, 967, 8, 61, 1504, 34, 23, 322, 362, 151, 309, 149, 31, 10, 1, 30, 347, 1099, 1666], [3, 118, 13, 6, 1918, 6, 621, 3, 44, 79, 203, 185, 315, 158, 1422, 74, 726, 3, 195, 1786, 15168, 1325, 33, 1977, 181], [3, 118, 13, 6, 959, 8, 94, 71, 358, 20, 1200, 109, 12, 10, 3519, 15169, 15170], [3, 118, 64, 6, 134, 22, 1, 60, 208, 117, 1402, 55], [3, 118, 64, 6, 48, 14, 167, 27, 4, 1280, 21, 469, 11, 10, 19, 164], [3, 118, 105, 290, 2, 25, 21, 15171, 57, 9, 58, 128], [3, 118, 105, 167, 2, 414, 34, 3, 118, 491, 2, 9], [3, 118, 415, 96, 150, 89, 31, 5, 2128, 270, 2, 1, 59, 2021], [3, 118, 363, 11, 18, 7, 2286, 286, 27, 2, 448, 178, 1876, 72, 52, 79, 17, 611, 8, 248], [3, 452, 14, 208, 13, 2, 284, 1, 31, 5, 33, 273, 17, 57, 4, 286, 568, 18, 11, 20, 235], [3, 452, 1156, 2, 320, 16, 42, 1, 233], [3, 452, 215, 11, 15172, 76, 1, 118, 119, 17, 15173], [3, 452, 67, 10, 77, 229, 50, 7960, 6, 155, 145], [15174, 4, 639, 3562, 715, 715, 715, 409, 45, 12, 2, 675, 59, 4424, 715], [23, 1715, 15175, 8, 3, 62, 1314, 57, 3, 2197, 31, 7, 70, 17, 2, 1, 88, 2385], [151, 15176, 14, 2, 3323, 88, 23, 2, 15177, 2, 1, 129, 15178, 498, 174, 231, 12, 3185, 1012], [23, 2489, 54, 585, 91, 4, 5557, 14, 3575, 24, 99, 3, 299, 101, 4, 1740, 1597, 285], [278, 157, 2, 1731, 11, 7, 836], [278, 14, 4, 237, 51, 373, 2, 1187, 3, 222, 1226, 76, 4, 2123, 184, 6, 3122], [278, 58, 393, 21, 98, 354, 5727, 1324, 467, 82, 5574, 26, 2, 1018, 1499, 15179, 82, 116, 15180, 3187, 26, 7, 372, 37, 93, 615], [278, 484, 17, 284, 6, 44, 6, 14, 51, 7, 179, 30, 261, 4571], [278, 44, 6, 61, 102, 18, 2, 1], [278, 167, 2, 1754, 40, 1014, 169, 51, 17, 321, 495, 118, 44, 6, 349, 17, 102, 7, 9, 1004, 69, 40, 1437, 357, 6, 17, 769, 55], [278, 204, 2, 1, 6, 14, 2404, 6, 2126, 117, 615, 7961, 2952, 21, 4, 185, 385, 3, 5248], [278, 204, 6, 563, 159, 4807], [278, 13, 6, 94, 217, 122, 6, 167, 17, 1724, 675, 18, 5, 1, 3, 29, 44, 1213], [278, 516, 14, 51, 261, 5349, 10, 164, 130, 376, 51, 337], [278, 516, 253, 60, 77, 18, 610, 516, 130, 44, 126, 95, 1209, 175, 18, 10, 909], [278, 516, 44, 2, 1165, 1, 88, 2, 1, 69, 359], [278, 516, 465, 15181, 15182, 6281, 113, 17, 59, 7962, 2638, 11, 126, 6902, 130, 60, 15183], [278, 242, 4, 19, 35, 74, 151, 33, 14, 2044, 8, 6207, 245, 177, 5, 182, 61, 54, 27, 3495, 23, 2, 187, 37, 125, 5, 4680, 58, 45, 6, 139, 1566, 513], [151, 105, 100, 2, 291, 1, 3028, 17], [151, 156, 375, 150, 13, 3, 47, 43, 1639, 13, 3, 487, 58, 15, 21, 5, 13, 7, 5813, 1, 7157, 26, 15, 32, 140, 5, 15184], [151, 14, 2, 232, 408, 1115], [151, 14, 2, 1, 31, 3, 44, 1836, 3, 29, 13, 6, 14, 34, 5814, 27, 17, 8, 1627, 3693], [151, 14, 2, 138, 31, 5, 131, 208, 13, 2, 285], [151, 14, 148, 31, 2, 25, 436, 2, 689, 2072], [151, 14, 1692, 102, 5815, 16, 754, 4, 5816, 66, 28, 108, 6, 4, 15185, 15, 341, 73, 3183, 24, 18, 22, 15186], [151, 14, 7, 128, 24], [151, 257, 60, 24, 35, 117, 59, 92], [151, 421, 245, 1, 25, 142, 3, 29, 279, 59, 20, 6834], [151, 79, 42, 1, 21, 752], [151, 119, 97, 24, 13, 2, 1828, 34, 469, 5, 157, 97, 530, 30, 995, 11, 10, 231, 10, 1568, 8, 7594, 330, 18, 8, 23, 54], [151, 19, 2, 1, 112, 705], [151, 28, 37, 209, 285], [151, 134, 5, 2, 260, 1172, 2449], [151, 61, 6, 521, 4, 215, 954, 691, 16, 7, 9], [151, 44, 39, 1, 1412, 260, 155, 449], [151, 176, 32, 1088, 6, 531, 59, 3862, 151, 33, 528, 59, 15, 27, 10, 312], [151, 100, 42, 949, 18, 503, 8, 100, 147, 15187, 429, 23, 11, 147, 851, 4364, 3, 46, 43, 4145, 15188], [151, 259, 10, 164, 4, 193, 3, 67, 1], [151, 389, 78, 25, 6, 28, 514, 71, 209, 78, 9, 25, 1679, 2926], [151, 559, 14, 2, 1, 38, 5, 559, 14, 2, 365, 3675], [151, 657, 35, 10, 9, 11, 2, 141, 1102], [151, 192, 51, 4, 971, 8, 197, 10, 193, 6, 4, 24], [151, 96, 100, 4, 2633, 1, 58, 50, 831, 26], [151, 139, 692, 2116, 181, 659, 21, 350, 33, 134, 17, 2, 5817, 15, 132, 2, 213, 8, 3, 150, 4, 199, 7, 1113, 196, 2180], [151, 294, 423, 27, 20, 169, 8, 338, 2, 1011, 21, 20, 1], [23, 6266, 173, 10, 1595, 7963, 1333, 26, 4, 7964, 72, 57, 35, 77, 15189, 12, 18, 1881, 7965, 120, 248, 493, 2300, 6, 4, 1777], [23, 5052, 5, 1], [23, 15190, 8, 3, 96, 119, 978, 353], [23, 1651, 933, 29, 81, 18, 310, 8, 64, 38, 15, 15191, 7415, 636, 4, 164, 5, 452, 594], [23, 807, 3, 266, 134, 2, 1, 2, 106, 74, 921, 23, 122, 114, 279, 624], [23, 15192], [23, 554, 159, 524], [23, 825, 1297, 1], [23, 966, 515, 16, 14, 5354, 4427, 836, 15, 2405, 7904, 3905], [23, 2250, 113, 78, 2893, 3, 363, 125, 2, 659, 163, 222, 48, 139, 143, 1, 3069, 7966, 147, 45, 939], [23, 238, 227, 5818, 6, 1662, 11, 22, 1], [23, 7967, 2849, 2299, 877, 1], [23, 2, 15193, 15194], [23, 2, 89, 1], [23, 2, 180, 1, 8, 445, 12, 4, 2167, 23, 99, 1810, 21, 2591], [23, 2, 1], [23, 2, 1, 140, 10, 730, 164, 12, 19, 10, 64, 164, 12, 19, 10, 685, 164, 12, 19, 33, 10, 5445, 18, 164, 12, 19], [23, 2, 1, 25, 647, 7, 505, 10, 15195, 8, 23, 13, 37, 4668], [23, 2, 1, 92, 3351], [23, 2, 291, 9, 651, 613, 9, 853], [23, 2, 291, 9, 651, 613, 77, 853], [23, 2, 535, 1, 15196, 15197, 240], [23, 2, 138, 8, 5, 46, 110, 41, 97, 1882, 18, 24], [23, 2, 961, 30, 25, 163, 39, 1, 7659], [23, 2, 9, 21, 7], [23, 2, 462, 1], [23, 2, 480, 682, 145], [23, 2, 216, 91, 78, 24, 25, 11, 4, 15198], [23, 2, 349, 35, 119, 18, 7, 24, 8, 1598], [23, 2, 2016, 235, 187], [23, 2, 388, 34, 461, 4, 15199, 8, 2331], [23, 2, 3070, 7, 24, 54], [23, 2, 2952, 21, 207, 387], [23, 2, 816], [23, 2, 2322], [23, 59, 6, 28, 22, 1, 2, 2709, 2832], [23, 59, 6, 167, 2, 1], [23, 59, 6, 15200, 2714, 22, 185, 1, 30, 9, 15201, 410], [23, 59, 6, 448, 10, 159, 2193, 1259, 1290, 151, 742, 2333, 2202, 11, 2, 607], [23, 59, 6, 842, 22, 145, 102, 10, 930, 122, 6, 15202, 17, 8, 45], [23, 59, 6, 1999, 7968, 18, 20, 1, 140, 31, 3, 44, 6, 65, 51, 15203, 318, 73, 219, 532, 2576], [23, 59, 6, 192, 2, 89, 1, 7969, 2556, 426, 77, 20, 2, 89, 1, 29, 100, 1311, 113, 97, 166, 2571], [23, 59, 6, 192, 79, 54, 111, 8, 85, 36, 58, 144, 184], [23, 1812, 6, 798, 186, 33, 10, 234, 1], [23, 330, 515, 8, 1826, 185, 483, 1389, 6, 229, 263, 2, 496, 18, 15204, 5101, 37, 2074, 221, 3, 33, 67, 6, 72, 20, 2, 9], [23, 156, 171, 99, 2, 1037, 981, 30, 1], [23, 98, 1494, 213, 206, 315, 484, 539, 4, 108, 1540, 16, 388, 3038, 1626, 7331, 3403, 31, 7, 317, 801, 7970, 57, 277], [23, 191, 22, 177, 938, 13, 52, 10, 1], [23, 51, 337, 313, 35, 114, 279, 16, 10, 4441, 478, 23, 2, 9, 5742, 241, 2385], [23, 108, 1], [23, 108, 1], [23, 108, 1, 4681, 108, 11, 2471, 15, 18, 3445], [23, 257, 1, 1615, 1615, 30, 38, 3, 94, 22, 25, 26, 3, 109, 1926, 135, 544, 205], [23, 2589, 6, 3430, 10, 646, 12, 4246, 173, 203, 953, 5501, 15205], [23, 133, 6, 15206, 18, 10, 206, 45, 3, 346, 10, 9, 262, 17, 72, 36, 131, 107, 94, 17], [23, 133, 6, 998, 5, 640, 9, 32, 129, 4, 199, 186, 25, 7, 2, 357, 78, 65, 1428, 963], [23, 133, 6, 28, 22, 1, 2, 2709, 2832], [23, 133, 6, 907, 102, 22, 9, 36, 238, 28, 18, 10, 30], [23, 133, 6, 192, 751, 8, 45, 55, 9, 61, 284, 74, 22, 25, 2294], [23, 2891, 2609, 22, 1, 11, 4, 231, 26], [23, 2891, 7289, 2, 399], [23, 316, 517, 895, 61, 3421, 8, 113, 76, 703, 1, 760], [23, 624, 57, 23, 113, 32, 9, 69, 137, 17, 6, 4, 234, 749, 23, 624], [23, 587, 73, 2, 1, 8, 29, 110, 87, 2, 7874, 8, 31, 40, 2, 89, 1, 113, 50, 405, 6, 80, 5576], [23, 107, 21, 7, 43, 378, 1251, 399], [23, 284, 3873, 54, 20, 387, 935, 80, 4172, 5, 134, 2, 45, 218, 23, 4, 45], [23, 342, 27, 74, 461, 4, 1631, 26, 3446, 78, 1, 2579, 18, 7, 45], [23, 147, 25, 7, 39, 9, 33, 75, 15207, 15208], [23, 857, 194, 7, 15209, 3970, 2333, 225, 148, 15], [23, 328, 3731, 23, 328, 14, 475, 46, 43, 1, 11, 17, 74, 12, 185, 2290, 129, 17], [23, 328, 125, 22, 1801, 412, 32, 39, 1, 49, 599, 1209, 1923], [23, 15210, 1, 29, 41, 2, 437, 4869, 2, 1, 3102, 240, 1183, 240, 27, 7971, 163, 45], [23, 472, 35, 73, 98, 1376, 68, 115, 8, 626, 4, 45, 54, 16, 15211, 306], [23, 551, 119, 2, 19, 816], [23, 1015, 5819, 9, 3445, 7578, 18, 36, 1980, 37, 36, 91, 799, 125, 240, 3026, 495, 77, 525, 19, 4028], [23, 2435, 11, 7, 9, 88, 15212, 12, 59, 6, 14, 7972, 23, 11, 7, 9, 21, 112, 22, 106], [23, 595, 483, 11, 7, 9], [23, 556, 559, 22, 1, 5820, 17, 2224, 23, 549, 16, 22, 45, 100, 17, 192, 401, 5592, 92], [23, 556, 94, 4, 232, 404, 2, 1519, 178], [23, 556, 192, 491, 1], [23, 4576, 18, 39, 1, 32, 1052, 1149, 43, 15213], [23, 1764, 18, 25, 8, 36, 1], [23, 788, 785, 4, 886, 486, 4, 15214, 18, 5821, 21, 2, 710, 8, 32, 3, 63, 72, 12, 2211, 76, 9, 7973], [23, 82, 37, 3, 62, 15, 89, 15215, 15, 46, 13, 5, 259, 11, 15216], [23, 82, 358, 2868, 15217, 37, 111, 1870, 86, 272, 2188, 74, 2, 2200, 15218], [23, 19, 224, 27, 268, 1, 34, 3, 105, 216, 212, 9, 10, 7756], [23, 28, 5797, 8, 10, 310, 12, 208, 7974], [23, 28, 3143, 11, 2554, 52, 257, 10, 123, 947, 140, 16, 22, 148, 154, 5367, 178, 26, 15219, 15220, 56], [23, 28, 515, 16, 5, 113, 57, 4, 19, 23, 58, 155, 106, 23, 58, 256, 649, 15221, 189], [23, 721, 5731, 62, 6, 262, 17, 74, 28, 11, 1372, 27, 17, 149, 289, 132, 79, 10, 1, 32, 921, 3, 14, 15222], [23, 721, 7, 211, 113, 17, 71, 209, 16, 2, 339, 1, 3, 195, 560, 1124, 6, 14, 5770], [23, 721, 6, 94, 7, 1383, 49, 96, 173, 4, 5453, 65, 38, 15, 107, 6, 479, 7784], [23, 721, 5, 9, 46, 10, 734], [23, 784, 180, 1, 249, 10, 138], [23, 61, 785, 15, 10, 1, 46, 110, 10, 1, 40, 100, 4, 413, 412, 167], [23, 61, 6, 14, 98, 183, 145, 21, 923, 37, 3, 63, 33, 14, 2542], [23, 61, 6, 472, 35, 73, 56, 21, 3072, 241, 304, 3, 65, 13, 7, 4571], [23, 61, 6, 929, 2, 1, 31, 10, 5385, 29, 107, 11], [23, 61, 6, 506, 10, 1074, 8, 398, 10, 2391, 3, 29, 608, 1716], [23, 61, 6, 4, 629, 22, 696, 123, 2542, 43, 4495, 43, 1, 43, 25, 33, 1566], [23, 152, 14, 179, 8, 207, 129, 4, 3266, 27, 2, 5822, 1335], [23, 152, 61, 673, 45, 31, 116, 12, 98, 31, 15223], [23, 152, 9, 4, 45, 54, 16, 5, 38, 66, 563, 361, 75, 304], [23, 152, 204, 1, 1185], [23, 402, 18, 38, 15, 106, 2177, 4682, 2, 1], [23, 5715, 1041, 5031, 26, 3, 46, 359, 21, 553, 16, 5, 319], [23, 243, 3, 46, 7, 1, 3, 168, 6, 14], [23, 1553, 18, 269, 15224], [23, 11, 2977, 1], [23, 11, 10, 618, 13, 470, 1922, 8, 5447, 34, 3, 109, 67, 7, 354, 1637, 7975], [23, 11, 10, 3595, 1], [23, 11, 4, 311, 27, 10, 206, 177, 8, 22, 1, 191, 17, 6, 366, 441, 27, 50, 11, 2, 19, 15225, 4, 19, 55, 286, 988], [23, 11, 4, 1674, 13, 4, 5719, 43, 308, 1, 23, 15226, 88, 2, 1245, 15227], [23, 11, 22, 1, 13, 2, 663], [23, 11, 22, 9, 15228, 54, 111, 14, 7976], [23, 383, 2, 3897, 153, 1151], [23, 33, 152, 28, 10, 381, 6, 119, 2, 1], [23, 33, 259, 10, 7322], [23, 33, 1141, 2046, 125, 10, 1154, 1], [23, 33, 48, 61, 6, 14, 2, 1, 6, 5, 140, 66, 29, 569, 21, 15229, 15, 47, 2, 2496, 8, 15, 328, 8, 129, 27, 85, 192, 45], [23, 33, 18, 22, 9, 6, 528], [23, 33, 2141, 1], [23, 33, 7977, 7, 10, 260, 26, 3, 330, 273, 5, 1820], [23, 33, 72, 11, 20, 186, 327, 5, 65, 13, 270, 2, 6356, 8, 3, 64, 15], [23, 33, 400, 135, 304, 21, 186, 6, 4435, 469, 22, 232, 178, 450], [23, 33, 238, 28, 6, 376, 230, 4, 95, 192, 28, 15230], [23, 33, 1917, 36, 41, 104, 18, 22, 229], [23, 1370, 224, 15231, 73, 4, 183, 265, 27, 43, 9], [23, 7053, 8, 9, 25, 3674], [23, 713, 73, 15232, 109, 90, 218, 39, 9, 67, 7, 1613, 252, 11, 865, 78, 284], [23, 2916, 230, 23, 4673, 54, 16, 22, 1], [23, 13, 5064, 8, 3, 200, 50, 13, 38, 52, 592, 54, 4, 179, 910, 59, 15233], [23, 599, 59, 6, 801, 8, 313, 2, 1, 1023, 31, 111, 29, 1867, 4, 19, 562], [23, 599, 528, 11, 2135, 1455, 15234, 15235, 2049, 11, 474, 429, 4, 3892, 732, 7978, 66, 44, 15236], [23, 70, 2, 15237, 15, 72, 15238, 4, 120, 56, 659, 3, 301, 3, 15239, 21, 3981, 77, 27, 1096, 578, 11, 4605], [23, 70, 1635, 2, 819, 15240, 225], [23, 15241, 143, 177, 9, 536, 17, 54, 3, 58, 60, 1455, 45], [23, 905, 15242, 3, 14, 122, 6, 397, 1975, 26, 3, 86, 3, 65, 7368, 288, 9, 86, 7, 45, 12, 2383], [23, 105, 152, 14, 422, 27, 10, 25, 224, 1628, 16, 1, 288, 27, 84, 15243, 149, 3, 47, 469, 7, 275, 20, 177, 157, 5, 18], [23, 417, 6, 416, 34, 29, 100, 22, 322, 872, 1075, 5, 140, 3, 63, 227, 6, 1, 11, 15244], [23, 43, 15245, 3862], [23, 43, 24, 34, 174, 96, 2, 1270], [23, 48, 291, 1, 23, 1236], [23, 48, 2, 236, 140, 3, 86, 268, 435, 8, 68, 414, 612, 12, 2, 3181, 8, 48, 2, 15246], [23, 48, 2, 236, 13, 350, 20, 481, 914, 415, 12, 637, 6, 947], [23, 48, 180, 18, 4, 5600, 5601, 15247, 769, 34, 63, 66, 51, 577, 3338, 15, 21, 212, 69, 1845, 15, 48, 33, 212, 69, 1038, 6, 48, 946, 384], [23, 48, 1967, 100, 43, 1, 137, 27, 553, 16, 10, 2865, 15, 29, 690, 31, 3, 19, 27, 76, 74, 1591], [23, 48, 438, 621, 117, 92, 23, 134, 10, 24, 2, 15248], [23, 48, 2024, 1410, 1173, 34, 7, 957, 1911, 12, 2, 1, 46, 15], [23, 48, 142, 6, 14, 2, 234, 1, 205], [23, 48, 82, 4, 2307], [23, 48, 172, 125, 3956, 40, 18, 60, 154, 45, 1, 587], [23, 48, 61, 6, 778, 2, 171, 1], [23, 48, 209, 16, 2, 262, 28, 102, 10, 15249, 9], [23, 48, 7979, 933, 34, 332, 21, 17, 6, 421, 684, 27, 2, 3336, 74, 11, 166, 324, 23, 2, 24, 281, 40, 47, 37, 342, 99], [23, 48, 109, 2, 310, 716, 15250, 3, 428, 90, 81, 18, 4, 310, 26, 262, 716, 56, 6, 17, 4510], [23, 48, 4, 5823, 34, 3, 63, 380, 50, 178, 2, 161, 8, 3, 62, 71, 209, 16, 701, 835, 212, 1, 49], [23, 48, 4, 409, 16, 189, 6, 1, 59, 71, 341, 15, 12, 34, 15, 59, 6, 14, 1474, 8, 23, 96, 1513], [23, 48, 4, 409, 6, 290, 43, 1, 129, 2, 25, 23, 4, 409, 6, 72, 810, 7, 26, 114, 84, 1], [23, 48, 804, 20, 33, 2, 104], [23, 2441, 48, 81, 59, 4683, 140, 7, 178, 12, 21, 7978], [23, 102, 197, 162, 4, 927, 9, 8, 2116], [23, 1239, 5612, 7, 530, 15251, 1691, 16, 355, 7, 65, 93, 18, 43, 68, 7, 5, 1326, 94, 11, 4, 179, 15252, 15253], [23, 550, 27, 15254, 81, 56], [23, 206, 34, 10, 24, 96, 1872, 205], [23, 206, 261, 151, 737, 2, 1], [23, 18, 2, 1602, 1], [23, 18, 10, 19, 7, 1, 45], [23, 18, 7, 93, 3250, 8, 15255, 3, 41, 60, 142, 1, 34, 4, 63, 7980], [23, 101, 484, 551, 149, 22, 1, 3087, 17, 6, 467], [23, 101, 18, 135, 149, 10, 1, 840], [23, 1947, 2, 4437, 739, 808, 1582, 235, 1, 8, 1349], [23, 54, 53, 1878, 1361, 11, 4, 15256, 7530, 54, 135, 19, 1, 27, 3848, 429, 15257], [23, 54, 22, 1], [23, 633, 102, 1, 18, 10, 138, 34, 45, 10, 138, 1221, 149, 4, 193, 5, 1281, 630, 41, 17, 4684, 102, 3, 46, 1532, 6, 14, 825, 15258], [23, 322, 362, 289, 105, 4162, 11, 4, 228, 1674, 304, 21, 285, 5, 146, 157, 20, 138, 18, 4, 1879, 8, 94, 57, 582], [23, 322, 362, 4, 4143, 266, 100, 17, 114, 2, 154, 327, 34, 2, 1, 318, 3215, 468, 10, 4508, 361, 162, 36, 44, 6, 114, 2, 154, 327], [23, 24, 23, 48, 59, 22, 1213, 164, 26], [23, 24, 792, 39, 9], [23, 542, 6, 1846, 54, 325, 1, 2032], [23, 542, 6, 345, 23, 37, 214, 13, 17, 26, 22, 1, 276, 44, 6, 3866], [23, 109, 417, 34, 2, 1, 51, 106], [23, 109, 48, 2, 983, 1, 33, 685, 2848], [23, 144, 7981, 8, 32, 66, 124, 220, 7982, 2, 320, 16, 7982], [23, 613, 1, 15259, 11, 3917, 4186, 2114], [23, 2313, 4, 250, 68, 16, 10, 153, 69, 728, 76, 45], [23, 72, 464, 32, 10, 1277, 14, 2205, 432, 65, 13, 39, 1, 205], [23, 94, 127, 26, 127, 158, 15260, 3022, 35, 7983, 15261, 251], [23, 686, 321, 40, 99, 322, 3, 118, 119, 398, 50, 24, 26, 971], [23, 15262, 213, 206, 27, 2, 2315, 401, 191, 17, 31, 3, 134, 268, 19, 59, 4, 244, 1], [23, 549, 8, 515, 16, 122, 6, 94, 71, 358, 230, 204, 2, 15263], [23, 549, 8, 515, 16, 4, 2037, 4, 15264, 1816, 374, 32, 4, 199, 1816, 4, 15265, 5377, 4, 7984, 15266, 35, 1549], [23, 549, 73, 7105, 22, 45, 12, 21, 4, 95], [23, 549, 16, 252, 448, 496, 16, 76, 751, 18, 15267, 58, 7, 45, 11, 4, 1306, 74, 256, 181], [23, 549, 16, 25, 15268, 23, 549, 16, 1, 15269, 690, 16, 488, 23, 549, 16, 4328, 1028, 180], [23, 549, 16, 5, 9, 21, 112, 3, 41, 495, 7, 65, 35, 6, 17, 37, 3, 46, 133, 43, 24, 385], [23, 549, 16, 5, 9, 2779], [23, 4554, 18, 4054, 25, 10, 1, 89, 6, 4, 1006, 25, 26, 40, 19, 35, 23, 19, 35, 40, 13, 53, 71, 66, 276, 28, 337, 25, 53], [23, 37, 1110, 6, 662, 54, 27, 10, 1], [23, 37, 1941, 10, 25, 23, 59, 6, 4685, 11, 22, 1], [23, 37, 721, 3, 29, 597, 35, 541, 13, 68, 212, 15270, 541, 1], [23, 37, 314, 314, 314, 7, 2, 1, 75, 665, 10, 314], [23, 37, 214, 149, 9, 86, 15, 356], [23, 37, 639, 2143, 4181, 3, 44, 43, 106, 6, 14, 2, 1633], [23, 37, 1744, 12, 437, 4, 237, 323, 1655, 103, 44, 393, 211, 7, 12, 56], [23, 37, 549, 16, 42, 7217], [23, 37, 515, 16, 22, 148, 401, 91, 3, 131, 665, 22, 1, 35, 55], [23, 370, 34, 31, 20, 1980, 12, 2, 15271, 261, 3578, 22, 1164, 3, 103, 1115, 1557, 42, 2, 339, 83], [23, 370, 34, 22, 70, 17, 150, 37, 7985, 13, 2, 19, 15272, 1187], [23, 370, 34, 85, 198, 3, 279, 59, 57, 1, 10, 25, 47, 19, 596, 230, 17], [23, 4686, 23, 4686, 3, 75, 948, 125, 42, 43, 1091, 2072, 8, 23, 370], [23, 192, 6, 208, 1991, 657, 22, 1], [23, 192, 6, 48, 13, 3982, 22, 312, 2, 161, 6, 4281, 21, 17], [23, 741, 27, 725, 3863, 7, 202, 24, 578, 13, 5333, 5824], [23, 96, 214, 140, 22, 25, 109, 121, 296, 41, 1, 262, 17, 191, 15273, 241, 109, 34, 100, 17, 72, 667, 125, 7, 11, 15], [23, 96, 669, 102, 4, 1, 525, 633, 18, 55], [23, 861, 11, 10, 15274, 4, 331, 12, 4485, 74, 766, 8, 15, 168, 6, 14, 33, 698, 16, 2, 1, 6, 458, 10, 676, 34, 92, 15, 2922, 15275], [23, 270, 2, 1, 601, 55], [23, 270, 2, 1, 6, 1670], [23, 270, 2, 144, 3937], [23, 362, 118, 1299, 22, 547, 15276, 15277, 31, 39, 220, 388, 2710, 4432], [23, 1003, 23, 96, 51, 261, 1249, 3, 63, 14, 559, 4, 144, 51, 3017, 23, 519, 1030, 51, 2, 5825, 74, 1064, 15278], [23, 533, 133, 7986, 15279, 4, 2286, 47, 18, 60, 9, 45, 641, 7508, 15280, 252, 424, 2, 392, 691, 16, 15281], [23, 267, 21, 384, 180, 517, 9, 277], [23, 4, 796, 786, 1301, 117, 92, 31, 36, 28, 22, 139], [23, 4, 1, 7, 2, 107, 54, 163, 1513, 163, 96, 44, 97, 25, 536, 21, 17], [23, 4, 284, 1, 7, 103, 79, 5, 546, 106, 11, 68, 755], [23, 4, 1198, 65, 51, 1, 517], [23, 4, 91, 224, 325, 1, 260], [23, 4, 349, 1], [23, 4, 112, 1458, 2616, 3, 41, 1243, 927, 1, 18, 2, 1972, 1602], [23, 4, 409, 16, 395, 69, 208, 13, 3, 29, 279, 6, 2045, 2522, 34, 1786, 23, 2, 141, 1, 1077], [23, 86, 52, 136, 702, 822, 15282, 16, 60, 15283, 7, 74, 52, 33, 784, 392, 15284, 322, 362, 392, 144], [23, 515, 16, 1, 86, 36, 431, 38, 36, 2030, 31, 20, 183, 1, 7, 32, 5, 49, 12, 183], [23, 99, 209, 16, 2, 1, 6, 72, 393, 59, 7], [23, 99, 417, 6, 111, 34, 38, 3, 679, 1389, 6, 72, 256, 23, 2, 1, 26, 454, 26], [23, 238, 119, 2717, 163, 325, 9, 131, 119, 3167, 1546, 768], [23, 238, 231, 19, 7987, 5, 1, 6711, 990, 151, 28, 4, 7601, 163, 3079], [23, 238, 227, 5818, 6, 1662, 15285, 1, 8, 3, 46, 105, 1135, 6, 14, 125, 43, 1], [23, 227, 173, 2, 2536, 83], [23, 35, 8, 51, 15, 230, 4, 95, 597, 35, 37, 5, 75, 113, 17, 385], [23, 35, 723, 3592, 1], [23, 35, 9], [23, 168, 6, 39, 9, 29, 137], [23, 27, 292, 1, 26, 201, 16, 240, 1223], [23, 27, 246, 25, 1], [15286, 14, 110, 322, 15287, 197, 1579, 18, 1, 233, 55, 3, 176, 1509, 50, 798, 6, 94, 71, 697, 3, 67, 10, 15288, 15, 332, 6, 479], [571, 61, 27, 26, 218, 76, 801, 1, 271, 28, 762, 129, 98, 385, 19, 76, 1549, 461, 1003, 36, 15289], [289, 132, 376, 27, 10, 306, 21, 4, 722, 607, 449, 8, 3, 300, 22, 1, 12, 44, 352, 651, 74, 256, 156, 1897, 11, 50, 376], [289, 132, 1532, 6, 113, 25, 2425, 1202, 44, 4, 5078, 1], [289, 3148, 2604, 1440, 16, 1687, 2538, 2463, 1795, 225, 140, 3, 63, 1, 23, 98, 15290], [289, 41, 2, 95, 387, 1535, 16, 32, 4, 1564, 5, 15291], [289, 41, 326, 15292, 39, 9], [289, 41, 5826, 353, 8, 355, 2289, 1184, 12, 15, 1756, 6, 15293, 2, 15294, 3, 1158, 745, 132, 6, 1860, 11, 15295], [289, 105, 1559, 22, 3235, 224, 2, 284, 11, 10, 1068, 1384, 431, 284, 30, 83, 22, 10, 25, 117, 1184], [289, 105, 124, 2, 3983], [289, 105, 124, 2, 437, 4459, 1311, 135, 289, 132, 4459, 4, 2494, 21, 2, 213, 8, 88, 22, 1431, 19, 1, 12, 122, 6, 28, 17, 739], [289, 322, 209, 3148, 98, 1119, 874, 16, 10, 2509, 873, 15296, 3, 101, 150, 89, 2, 7988], [289, 297, 27, 159, 15297, 4, 1694, 2998, 38, 36, 4030, 73, 2, 2640, 15298], [289, 297, 155, 1510, 16, 7989, 1269, 1237, 4, 250, 1510, 145], [289, 273, 212, 1, 51, 4, 15299, 59, 10, 2343, 15300, 21, 4, 722, 172, 213, 8, 92, 36, 131, 2559, 17, 59, 15], [3, 3, 94, 60, 9, 11, 15301], [3, 21, 68, 1073, 305, 154, 5827, 15302, 15303, 8, 293, 36, 58, 2, 165, 401, 130, 4, 2981, 69, 41, 263, 135, 11, 4, 250, 7990], [798, 14, 4, 3173, 1, 98, 39, 171, 30, 231, 55], [23, 305, 135, 1207, 39, 9, 3447, 234], [1331, 377, 2277, 303, 8, 506, 4687, 77, 73, 2172], [1331, 377, 11, 15304, 512, 91, 11, 4, 231, 5587, 1331, 103, 271], [1331, 608, 11, 770, 4, 377, 244, 676], [2859, 194, 3088, 11, 37, 358, 15305, 255, 1708, 18, 4, 229, 3448, 3, 380, 52, 13, 6499, 3, 87, 6, 472, 35, 21, 39, 179, 30, 574, 1046], [15306, 1390, 24, 714, 8, 19, 230, 50, 926, 141, 15307, 16, 98, 30, 15308], [278, 480, 7, 1, 18, 739, 192, 27, 7, 590, 30, 1349], [278, 70, 5, 65, 13, 98, 1064, 24, 140, 20, 99, 626, 6, 72, 393, 6, 10, 231, 5728], [278, 516, 14, 20, 145], [1153, 3, 119, 4, 24], [1153, 59, 553, 16, 39, 1, 26], [1004, 3, 44, 10, 490, 1029], [1004, 59, 217, 1412, 2, 15309, 22, 1, 1276], [1004, 59, 39, 169, 807, 1], [1004, 59, 5, 1165, 2170, 9, 150, 519, 5, 2, 1262, 30, 91, 916], [1004, 59, 5, 1804, 1, 5, 41, 17, 32, 921], [1004, 59, 5, 74, 97, 435, 97, 1, 553, 16, 39, 283, 78, 32, 63, 19, 102, 21, 32, 3, 2800], [1004, 31, 15, 15310, 11, 4, 5554, 1, 70, 10, 2519], [1004, 31, 7, 372, 15311, 22, 186, 83], [1004, 57, 621, 3122, 7991, 12, 3176, 13, 31, 5, 1577, 1, 59, 48, 44, 169, 85, 364, 118, 5, 61, 6, 2, 7663], [1004, 57, 42, 58, 6, 28, 15, 358, 73, 42, 61, 332, 11, 760, 506, 692, 1789, 1092, 536, 1692, 506, 24, 3169, 5282, 1138, 340, 15312], [1718, 15313, 484, 123, 970, 1332, 6, 594, 7, 52, 5474, 377, 123, 5828, 4, 1213, 15314], [552, 59, 78, 34, 3, 64, 17, 2, 640, 83, 1996, 36, 48, 1491, 6, 15315, 2, 25], [552, 280, 2, 666, 16, 9, 109, 317, 1945, 6, 44, 7, 68, 1148, 77, 321], [552, 71, 3, 44, 228, 23, 37, 866, 8, 3227, 111, 415, 86, 23, 2, 3736, 83], [552, 71, 1, 302, 166, 1, 1428, 7992, 3, 96, 44, 4, 199, 2243], [552, 485, 15, 33, 17, 14, 1150, 34, 134, 1, 169, 8, 33, 14, 2, 3052, 25, 46, 41, 17, 2488, 37, 19, 760, 1784, 282], [552, 57, 1128, 88, 2, 291, 9, 27, 4419], [552, 162, 22, 25, 383, 363, 34, 52, 165, 258, 17, 60, 522, 230, 3, 671, 2, 112, 164, 1], [552, 69, 364, 15316, 26, 7694, 49, 34, 23, 721, 36, 41, 1, 3089, 21, 4, 1454, 11, 36, 792], [552, 85, 1, 86, 36, 781, 55, 1, 44, 1527, 178], [15317, 67, 2, 2781, 520, 2067, 2174, 15318, 19, 32, 78, 1, 1335, 1153, 1153], [31, 210, 62, 3, 64, 20, 490, 30, 218], [31, 448, 378, 127, 327, 16, 84, 1835, 23, 316, 10, 15319, 108, 18, 39, 9, 21, 4, 862], [31, 5058, 12, 56, 88, 57, 277, 7, 70, 17, 107, 18, 189, 217, 13, 5058, 75, 14, 56, 52, 70, 99, 239, 111, 872], [31, 7993, 6768, 404, 98, 230, 3412, 5745, 277, 571, 311, 2, 83], [31, 2203, 7994, 317, 61, 102, 51, 110, 169, 74, 165, 3, 318, 788, 2, 56, 63, 129, 3, 196, 148, 63, 3, 28, 7995, 241, 4, 1044], [31, 537, 717, 47, 96, 224, 3, 454, 71, 239, 16, 5, 3984, 189, 52, 118, 79, 2, 15320, 386, 16, 2, 368], [31, 2335, 5671, 119, 1704, 1992, 24, 52, 556, 578, 416, 11, 4, 742, 3506], [31, 5829, 15321, 220, 2, 1078, 52, 487, 110, 167, 2, 282], [31, 3, 671, 970, 326, 18, 15322, 23, 152, 298, 22, 1, 13, 2, 15323], [31, 3, 79, 5, 2, 1, 88, 1502, 700, 90, 17, 233, 31, 3, 79, 5, 2, 89, 1, 88, 604, 700, 267, 17], [31, 3, 75, 70, 43, 169, 102, 16, 5, 88, 1, 3, 29, 110, 67, 6, 350], [31, 3, 29, 13, 7, 9, 3, 227, 50, 30, 173, 2, 7996], [31, 3, 29, 15324, 2, 180, 517, 9, 225, 23, 61, 7997, 14, 15325], [31, 3, 182, 672, 20, 24, 230, 8, 5, 19, 129, 292, 25, 230, 7, 100, 17, 62, 117, 92, 140, 5, 1632, 17, 4137, 5, 537, 1], [31, 3, 182, 7998, 2, 2672, 5, 63, 15326, 15327, 73, 14, 4, 508, 15328], [31, 3, 182, 486, 15329, 2906, 11, 395, 278, 204, 50, 18, 7914, 3, 90, 7, 1, 127, 130, 393, 11, 1068], [31, 3, 19, 2, 25, 1, 272, 33, 1665, 15, 98, 176, 172, 50, 1062, 40, 137, 171, 88, 272, 44, 6, 229, 170], [31, 3, 124, 2, 831, 21, 155, 106, 217, 79, 17, 7999, 278, 70, 15, 1234, 18, 32, 39, 9], [31, 3, 124, 343, 3, 118, 944, 61, 21, 2, 8000, 615, 4932, 12, 2, 1771, 587, 83], [31, 3, 167, 5, 545, 7, 5830, 1, 3, 394, 7, 481, 788], [31, 3, 555, 4, 676, 458, 21, 5, 1, 5, 1741, 72, 267, 5, 74, 571, 2131, 4, 676, 11, 97, 895], [31, 3, 448, 2, 406, 16, 10, 414, 32, 5, 9, 756, 102, 2, 4688, 390, 55], [31, 3, 538, 5, 3, 2389, 20, 538, 895, 31, 5, 86, 5, 63, 14, 2, 1, 3, 63, 14, 98, 110, 1104, 1155, 316, 15], [31, 3, 94, 246, 1, 27, 2, 15330, 558, 272, 8001, 7, 1], [31, 3, 366, 27, 97, 1, 15, 129], [31, 3, 47, 2, 189, 278, 857, 472, 35, 73, 4, 19, 50, 117, 11, 4, 24, 189], [31, 3, 47, 8002, 18, 2, 4314, 2339, 8, 3, 222, 101, 316, 378, 184, 3, 118, 316, 8003, 7, 9, 136, 474, 11, 7, 15331], [31, 3, 220, 2, 265, 15332, 642, 1255, 118, 2136, 35, 11, 4, 56, 63], [31, 3, 220, 1348, 4329, 3, 118, 44, 3435, 16, 265, 105, 197, 28, 320, 16, 351, 1216, 26, 1, 59, 15, 267, 274, 3, 15333, 2, 3009, 278, 340], [31, 3, 2503, 2, 5401, 43, 1, 118, 67, 17, 7, 57, 305, 381, 12, 152, 14, 113, 1399, 744], [31, 23, 2824, 122, 4, 884, 184, 5, 63, 58, 12, 122, 8, 137, 178, 27, 307, 604, 28, 4, 95, 1428, 3287], [31, 23, 958, 10, 25, 27, 155, 166, 1, 85, 364, 58, 3, 67, 1167, 52, 46, 43, 1363, 3108, 4, 15334], [31, 289, 105, 297, 50, 58, 60, 4580, 45, 27, 10, 373, 387, 88, 3, 1813, 6, 100, 246, 25, 3028, 10, 299, 18, 876, 37, 57], [31, 15335, 47, 2, 781, 3298, 2870, 170, 27, 15336, 8, 113, 170, 6, 139, 14, 2, 285], [31, 3968, 257, 5831, 225, 3, 103, 14, 2, 243, 5579], [31, 2, 1, 589, 40, 28, 4634], [31, 2, 1, 1102, 10, 138, 278, 415, 257, 4, 45, 54, 16, 876], [31, 2, 1, 2797, 100, 50, 1668, 128, 7, 12, 32], [31, 2, 1, 29, 13, 17, 5317, 329, 125, 143, 1], [31, 2, 1, 29, 578, 50, 373, 5, 982, 110, 1038, 119, 15], [31, 2, 1, 136, 6, 5374, 15337, 129, 2, 145, 7, 1420, 35, 233, 8004, 35, 596, 4, 244, 1, 1113, 317, 15338, 133, 42], [31, 2, 1, 12, 89, 163, 419, 40, 419, 972, 2, 15339, 700, 5832, 74, 2, 15340], [31, 2, 1, 70, 42, 1897, 985, 352, 40, 373, 20, 4401], [31, 2, 418, 67, 17, 6, 119, 50, 24, 88, 338, 151, 1273, 15341, 55], [31, 2, 342, 1, 19, 27, 2, 564, 25, 40, 1870, 671, 546, 106, 882, 1252, 11, 10, 387], [31, 2, 15342, 1161, 273, 5, 757, 5, 41, 60, 859, 2671, 15343, 204, 5092, 1], [31, 2, 25, 11, 1966, 63, 19, 10, 1, 7, 196, 40, 564, 21, 172, 2, 15344, 32, 1762, 25, 135, 1490, 5778], [31, 2, 25, 12, 194, 64, 8, 5492, 661, 16, 4, 1408, 52, 315, 3592, 1], [31, 2, 25, 310, 291, 237, 442, 52, 101, 276, 6723, 84, 455, 1, 518, 74, 4, 1, 7, 1278, 11, 170, 54, 518], [31, 2, 1282, 182, 81, 6, 2, 120, 395, 8, 4, 120, 395, 204, 76, 15, 653, 7418], [31, 2, 826, 502, 17, 60, 24, 11, 2949, 261, 3, 41, 6, 113, 15345], [31, 2, 826, 122, 6, 313, 17, 60, 24, 38, 3, 47, 11, 261, 25, 3, 46, 854, 45], [31, 3080, 47, 2, 395, 278, 204, 7, 1, 37, 172, 3287], [31, 621, 182, 28, 98, 764, 74, 596, 1701, 27, 17, 1004, 69, 15, 12, 3, 195, 61, 6, 14, 2, 1, 117, 108], [31, 621, 67, 6, 316, 17, 2, 789, 1289, 6, 10, 15346, 5105, 70, 10, 1451, 15347, 219, 7, 8, 353, 3443], [31, 393, 289, 182, 121, 136, 1001, 5, 7, 2, 5, 437, 48, 2, 17, 2029, 29, 14, 270, 2, 141, 83], [31, 119, 4, 24, 70, 5, 243, 23, 32, 21, 254, 513], [31, 182, 1201, 598, 3906, 22, 450, 6, 22, 232, 178, 1392, 15], [31, 326, 330, 167, 16, 1134, 2, 25, 75, 114, 5, 6742, 552, 85, 9, 14, 37, 15348], [31, 50, 1618, 72, 3518, 274, 63, 1105, 986, 40, 2, 282], [31, 50, 306, 15349, 2, 9, 88, 40, 247, 13, 2, 9, 776, 162, 58, 5, 86, 40, 683, 15, 82], [31, 3, 46, 167, 7, 1, 88, 3, 46, 167, 7, 1, 85, 308, 59, 15, 7, 1949, 908], [31, 3, 19, 50, 3, 62, 155, 145, 67, 876], [31, 3, 15350, 10, 343, 15, 152, 14, 358, 8, 4, 9, 152, 90], [31, 3, 47, 6, 28, 2, 613, 77, 37, 14, 254, 51, 577, 40, 13, 307, 40, 486, 256, 11, 17, 5, 9, 210, 94], [31, 3, 407, 2, 232, 408, 3, 415, 118, 14, 2, 15351, 1055, 408, 55], [31, 15, 407, 21, 22, 2708, 10, 628, 118, 14, 2222, 130, 4, 1785, 21, 3377, 15352], [31, 1344, 4, 1714, 28, 5, 1, 88, 6, 4, 1714, 3, 2631], [31, 3531, 15353, 109, 86, 374, 56, 3, 456, 14, 19, 325, 426, 5, 177, 49, 681, 3742], [31, 10, 4689, 2601, 15, 118, 14, 2, 19, 8005, 859, 6, 665, 22, 1, 562], [31, 10, 1214, 448, 2, 327, 16, 10, 1246, 33, 13, 15, 8, 176, 15354, 20, 1088, 652, 5833, 367, 1, 3, 62, 40, 2383], [31, 10, 1, 255, 2, 2500, 15355, 114, 7, 30, 6, 1746, 975], [31, 10, 228, 29, 131, 5358, 10, 1870, 1680, 12, 6, 79, 76, 2, 83, 15356], [31, 10, 175, 167, 99, 637, 6, 337, 85, 5, 1341, 17, 161, 185, 30, 1, 536, 97, 373, 19, 653, 1222, 161, 83], [31, 48, 21, 5327, 118, 14, 1524, 117, 22, 15357, 366, 2, 1743, 8, 175, 59, 757, 8, 5834, 270, 2, 417, 265, 52, 7868], [31, 48, 88, 5, 49, 2, 1894, 8, 1491, 229, 5, 44, 43, 15358, 246, 1377, 836], [31, 101, 3, 438, 2, 77, 7, 259, 102, 8006, 1540, 3, 222, 33, 28, 4, 1084, 8007, 16, 15359, 179, 18, 2, 1697, 5483], [31, 101, 416, 724, 4, 112, 15360, 1, 3, 62], [31, 101, 10, 154, 1595, 1483, 407, 37, 179], [31, 101, 5, 1, 109, 724], [31, 24, 767, 222, 81, 151, 61, 142, 116, 13, 15, 3410], [31, 40, 2, 9, 23, 2, 282], [31, 40, 2, 9, 18, 685, 871, 40, 2, 9, 11, 112, 164, 99], [31, 40, 46, 80, 462, 42, 165, 48, 262, 50, 30, 93, 561, 559, 557, 39, 234, 9, 13, 1039, 2601], [31, 40, 46, 533, 6, 5, 88, 69, 40, 81, 6, 1027, 5, 62, 1, 75, 139, 81], [31, 40, 29, 1512, 7, 8, 72, 2140, 4, 1, 46, 1798], [31, 40, 90, 14, 605, 11, 4, 476, 40, 2, 15361, 17, 5835], [31, 40, 62, 80, 226, 193, 230, 5, 563, 50, 88, 147, 1, 2, 15362], [31, 40, 70, 2, 93, 8008, 8, 40, 134, 2, 93, 15363, 436, 147, 9, 562, 7, 193, 5, 63, 119, 288, 40, 119], [31, 40, 255, 39, 6, 1283, 88, 40, 389, 21, 50, 373, 522, 140, 23, 557, 7, 1, 13, 2, 15364], [31, 1358, 113, 5, 40, 2, 15365, 368, 88, 8009, 40, 89, 21, 20, 3919], [31, 60, 68, 427, 98, 4491, 2311, 36, 44, 43, 117, 6, 14, 1524, 11, 4, 2012, 553, 51, 32, 36, 49, 1797, 4362], [31, 217, 12, 820, 16, 1297, 2299, 88, 52, 2, 120, 56, 15366], [31, 217, 842, 5, 99, 332, 225, 36, 600, 14, 1003, 5642, 127, 21, 8010], [31, 7, 24, 46, 1947, 8011, 351, 43, 15367, 5836, 1241, 15368, 3844, 3, 46, 172, 27, 254], [31, 7, 24, 29, 107, 27, 235, 3, 29, 67, 15], [31, 7, 80, 9, 188, 7, 10, 9, 201], [31, 7, 57, 78, 9, 67, 88, 19, 254], [31, 4, 28, 8012, 36, 33, 65, 13, 374, 28, 5837, 316, 60, 4499], [31, 4, 232, 75, 257, 4, 355, 1111, 36, 29, 110, 655, 6, 14, 11, 4, 1408], [31, 4, 4350, 46, 2155, 353, 176, 7, 2215], [31, 4, 101, 184, 40, 81, 59, 12, 50, 1256, 40, 41, 15369, 285], [31, 4, 7040, 21, 202, 2175, 201, 208, 315, 225, 22, 12, 10, 1, 972, 4, 4349], [31, 4, 324, 835, 9, 659, 4113, 15370, 2128, 4690, 126, 118, 14, 1628, 127, 24, 6, 61, 657], [31, 4, 360, 47, 351, 16, 3417, 351, 15, 118, 14, 33, 17, 8, 10, 312, 440], [31, 76, 25, 24, 66, 2801, 240, 66, 656, 240, 54], [31, 39, 9, 46, 308, 59, 14, 203, 36, 869, 2, 2789, 2296, 60, 15371], [31, 22, 1, 29, 227, 1780, 11], [31, 22, 1, 662, 35, 18, 17, 68, 127, 15372], [31, 22, 1, 154, 4, 3751, 16, 45, 3, 3432, 133, 50, 18, 10, 15373, 55], [31, 1036, 1294, 7, 49, 255, 481, 4339, 397, 108, 6, 194, 4, 366, 15374, 85, 277, 155, 743, 236, 131, 6607], [31, 42, 2, 89, 1], [31, 42, 2, 1, 98, 3, 15375, 42, 3, 452, 134, 2, 19, 31, 890, 524, 558, 42, 1, 3, 124, 42, 330, 55], [31, 42, 46, 19, 42, 46, 249, 827, 42, 1042, 9], [31, 42, 89, 25, 2, 109, 137, 417, 6, 28, 6, 4, 24, 8013, 7, 30, 223], [31, 42, 772, 17, 6, 139, 868, 27, 25, 34, 42, 868, 5676, 1, 3, 75, 799], [31, 42, 41, 80, 45, 349, 15376, 722, 80, 15377, 5, 49, 99, 206, 21, 3294, 1286, 1, 15, 46, 15378], [31, 42, 62, 22, 1, 42, 62, 174, 953], [31, 42, 48, 81, 133, 169, 74, 441, 1, 3, 29, 110, 131, 81, 6, 350], [31, 174, 1, 192, 3419, 15379, 4671, 151, 70, 362, 3, 421, 256, 15380, 2559, 79, 4237, 27, 15381, 7, 3957, 11, 4691, 3360], [31, 5627, 47, 21, 1, 4652, 14, 79, 7781], [31, 66, 28, 245, 843, 16, 15382, 3, 103, 14, 134, 54, 4211, 8014, 5174, 139, 18, 11, 104], [31, 78, 8015, 1, 182, 687, 13, 22, 51, 2, 460, 8, 29, 58, 295, 78, 28, 167, 27, 2, 1149, 1446], [31, 78, 25, 276, 14, 315, 85, 78, 146, 14, 37, 129, 4, 503, 472, 35, 11, 1, 45, 7, 287, 452, 110, 1038, 8016, 1936], [31, 3161, 152, 1475, 6, 14, 2, 7984, 836, 61, 309, 2932, 289, 43, 106, 21, 270, 3985], [31, 80, 226, 2151, 11, 22, 323, 5, 2151, 2, 9, 88, 26, 2, 15383, 593, 15384], [31, 80, 25, 430, 5, 359, 8, 257, 80, 30, 11, 580, 80, 161, 221, 8, 161, 221, 29, 8017, 5, 96, 134, 170, 24, 462], [31, 80, 24, 93, 10, 15385, 178, 669], [31, 5, 13, 74, 8, 5, 175, 89, 59, 15386, 49, 2, 3562, 715], [31, 5, 2, 89, 1, 157, 97, 402, 35, 314], [31, 5, 2, 9, 272, 557, 5, 13, 68, 33, 13, 31, 20, 2, 93, 77, 272, 557, 5, 13, 1155, 3, 29, 5306], [31, 5, 2, 503, 3790, 1, 1416, 135, 5, 15387, 647], [31, 5, 208, 13, 2, 19, 144, 38, 20, 314, 15, 129, 1151, 271, 423, 82, 307], [31, 5, 46, 2356, 2809, 1, 16, 1134, 604, 79, 170, 4, 2757, 16, 4, 15388, 1, 1553, 288, 374, 1917, 1168], [31, 5, 46, 2, 9, 28, 35, 54, 10, 941, 331, 26], [31, 5, 46, 581, 280, 5, 165, 194, 80, 1, 2324, 80, 9, 3388, 581, 1078], [31, 5, 46, 10, 15389, 20, 1, 419, 11, 10, 387], [31, 5, 46, 249, 138, 85, 5, 400, 116, 27, 15390, 767, 7, 15391, 15392, 1], [31, 5, 49, 5526, 82, 393, 882, 130, 3933, 8018, 4415, 8019, 88, 5, 49, 15393, 2269, 5838, 248], [31, 5, 49, 54, 489, 155, 696, 8, 338, 20, 1388, 27, 20, 260, 734, 3, 29, 131, 465, 5, 1, 59, 1388, 4205], [31, 5, 652, 61, 6, 741, 6, 68, 1439, 63, 21, 3805, 23, 48, 61, 6, 134, 2, 419, 19, 59, 162, 23, 157, 10, 248], [31, 5, 191, 17, 155, 1, 315], [31, 5, 1252, 111, 33, 223, 35, 8, 1233, 5, 41, 9], [31, 5, 3029, 88, 303, 97, 1, 256], [31, 5, 466, 303, 80, 1, 1406], [31, 5, 481, 914, 127, 88, 588, 5, 2, 9, 15394], [31, 5, 75, 227, 610, 15395, 173, 60, 112, 164, 45], [31, 5, 210, 44, 1356, 73, 2, 5650, 21, 20, 95, 2170, 8, 15396, 481, 5779, 20, 610, 118, 14, 56], [31, 5, 29, 19, 27, 20, 519, 15397, 4633, 15398, 2, 3791, 15399, 15400, 2, 24, 1511, 74, 15401, 32, 16, 4, 2037], [31, 5, 29, 62, 57, 80, 1, 58, 15402, 46, 5, 1, 23, 33, 7977], [31, 5, 29, 72, 267, 5, 211, 217, 555, 4, 676, 458, 21, 5, 20, 2, 1], [31, 5, 29, 62, 674, 3930, 20, 2, 1], [31, 5, 934, 2280, 21, 1201, 88, 20, 248, 31, 5, 2280, 21, 522, 5, 655, 6, 15403], [31, 5, 253, 17, 18, 186, 8, 5, 49, 14, 1229, 187, 18, 4, 2246, 51, 15404, 29, 14, 2, 3336], [31, 5, 172, 21, 20, 2354, 5, 2, 564, 9], [31, 5, 28, 173, 98, 2469, 27, 217, 8, 72, 4065, 2, 417, 164, 26, 93, 1640, 11, 15405, 7, 2, 993, 5, 1, 15406], [31, 5, 61, 6, 4, 3986, 1495, 18, 928, 5, 44, 6, 20, 4256, 8, 60, 1795, 11, 7, 1], [31, 5, 61, 6, 4, 1692, 489, 155, 696, 5, 103, 105, 1924, 1845, 285], [31, 5, 41, 2, 481, 914, 330, 11, 862, 5, 75, 81, 59, 1311, 14, 2, 9], [31, 5, 41, 2, 93, 77, 29, 227, 50, 173, 2, 1983, 4865], [31, 5, 41, 2, 25, 8, 5, 246, 25, 5, 2, 9], [31, 5, 41, 2, 437, 27, 17, 316, 15, 35, 27, 17, 230, 3, 5686, 35, 18, 80, 1, 30, 26, 2032], [31, 5, 41, 1338, 2, 25, 35, 21, 238, 81, 6, 20, 418, 5, 109, 2, 1937, 104, 8, 44, 43, 829, 129, 4235], [31, 5, 41, 2292, 18, 20, 2624, 5, 2, 56, 30, 1, 8, 271, 750, 423, 82, 17, 27, 97, 4300, 285], [31, 5, 41, 6, 208, 13, 5, 1354, 2, 1, 6, 28, 30, 20, 2, 564, 1896, 112, 25, 100, 1, 62, 57, 15, 12, 82, 756], [31, 5, 662, 27, 9, 20, 2, 9, 123, 15407, 31, 5, 122, 8, 1726, 22, 20, 2, 282, 31, 5, 28, 1001, 123, 22, 20, 2, 282], [31, 5, 44, 7035, 4, 101, 166, 184, 5, 87, 12, 15408, 34, 106, 2, 83], [31, 5, 44, 20, 228, 756, 173, 2, 290, 15, 229, 7, 20, 33, 98, 4692, 285], [31, 5, 9, 139, 1390, 23, 298, 224, 1999, 8020, 18, 32, 16, 3633], [31, 5, 756, 217, 20, 2, 1], [31, 5, 756, 217, 20, 2, 1, 1804, 4, 3019], [31, 5, 204, 32, 670, 8, 353, 260, 57, 244, 202, 654, 120, 654, 8, 3307, 654, 427, 7, 420, 3224], [31, 5, 62, 2, 189, 136, 2, 15409, 260, 85, 4, 19, 49, 5, 122, 6, 81, 6, 170, 1773, 30, 9], [31, 5, 13, 4, 15410, 1052, 15411, 20, 2, 24], [31, 5, 64, 495, 5, 75, 359, 44, 9, 58, 2045, 45, 149, 76, 2148, 409, 385], [31, 5, 456, 79, 17, 2, 353, 333, 79, 17, 2, 7617, 48, 2, 15412], [31, 5, 48, 84, 734, 74, 84, 746, 3394, 1, 3, 58, 48, 44, 106, 21, 760], [31, 5, 48, 4693, 1109, 5, 2, 339, 812, 8, 3, 75, 19, 27, 2, 339, 1], [31, 5, 48, 10, 83, 3, 109, 29, 279], [31, 5, 68, 16, 10, 9, 749, 70, 630, 1370], [31, 5, 101, 13, 873, 1421, 20, 2, 285, 271, 423, 82, 17, 8, 10, 64, 4506, 1421], [31, 5, 2682, 18, 20, 730, 33, 37, 5, 29, 28, 11, 1885, 20, 2, 141, 1], [31, 5, 109, 62, 17, 5, 62, 32, 4, 437, 3, 61, 539, 27, 32, 39, 90, 30, 283], [31, 5, 121, 127, 225, 18, 4, 1213, 59, 1438, 15413, 130, 59, 4, 20, 2, 4531, 7208], [31, 5, 72, 245, 16, 4, 253, 324, 4, 2535, 12, 129, 158, 25, 1008, 3831, 181, 1633], [31, 5, 72, 393, 59, 17, 151, 762, 174, 520, 897, 61, 21, 15, 83, 20, 520, 12, 2, 15414, 15415], [31, 5, 94, 17, 569, 83], [31, 5, 419, 33, 192, 167, 35, 212, 319], [31, 5, 981, 142, 21, 2, 8021, 20, 2, 1], [31, 5, 1465, 1877, 26, 3, 107, 6, 5, 238, 1636, 4, 5675, 1222, 26, 5, 72, 15, 46, 8022, 5, 2, 1], [31, 5, 1513, 24, 15, 1406, 154, 6, 1834], [31, 5, 114, 2, 358, 106, 6, 262, 108, 5, 2, 9], [31, 5, 113, 2, 391, 40, 65, 33, 13, 2, 25, 12, 7, 2, 2558, 289, 156, 454, 7], [31, 5, 262, 166, 25, 33, 100, 17, 62, 37, 3, 63, 258, 17, 60, 166, 283, 43, 332, 150], [31, 5, 86, 7, 4, 1067, 14, 1248, 12, 2, 1086, 1222, 5, 49, 15416], [31, 5, 67, 15, 107, 8, 303, 15, 46, 43, 4103, 580, 2330, 153, 137, 178, 59, 2, 607, 1612, 1546], [31, 5, 47, 2, 1, 25, 11, 5534, 5, 96, 8023, 14, 2, 1, 25, 11, 862], [31, 5, 103, 19, 74, 122, 8, 19, 97, 153, 77, 233, 5, 2, 8024, 55], [31, 5, 197, 2, 15417, 4485, 40, 359, 18, 5, 102, 15418, 495, 499, 276, 14, 3545, 97, 1, 2073], [31, 5, 118, 44, 253, 1576, 2421, 11, 15419, 15, 196, 7, 20, 120, 248], [31, 20, 2, 1693, 8, 15420, 4415, 15421, 12, 20, 5839, 324, 21, 15422, 146, 2631, 3416, 630, 2034], [31, 20, 2, 4478, 1, 44, 2, 8025, 8, 242, 4, 19, 35], [31, 20, 208, 13, 127, 16, 2, 1, 130, 20, 836, 116, 2, 437], [31, 20, 14, 2, 141, 626, 1, 59, 4, 1756, 16, 2, 5840, 15423, 61, 6, 15424], [31, 20, 152, 14, 2, 9, 88, 29, 65, 21, 15425, 5, 514, 7, 2930, 38, 5, 1389, 6, 14, 2, 282], [31, 20, 44, 77, 437, 3, 150, 89, 21, 5, 2896, 3, 41, 1569, 437, 34, 2, 1, 46, 68], [31, 20, 48, 1252, 749, 1, 5, 46, 70, 10, 15426, 364, 5, 86, 22, 1437], [31, 20, 48, 8026, 5526, 82, 3933, 8019, 8, 2630, 8018, 88, 20, 48, 3850, 5496, 20, 33, 2269, 5838, 248], [31, 20, 48, 194, 22, 15427, 178, 20, 625, 83], [31, 814, 182, 132, 6, 551, 6, 1127, 5, 318, 14, 2, 388], [31, 20, 2, 25, 188, 8, 5, 168, 4, 1067, 53, 15428, 53, 23, 33, 152, 1233, 20, 2, 181], [31, 20, 455, 540, 21, 3449, 256, 12, 140, 15, 12, 3357, 116, 12, 2, 1843, 1180, 20, 2, 141, 185, 1718, 1, 260, 4665], [31, 20, 915, 100, 5, 467, 7641, 374, 19, 144, 8, 37, 49, 350], [31, 20, 24, 1729, 5, 46, 784, 6, 2056], [31, 20, 186, 12, 2440, 34, 20, 610, 12, 775, 42, 523, 2825, 2, 56, 81, 593], [31, 4556, 100, 80, 1, 338, 27, 246, 145, 8, 29, 72, 45, 7, 18, 4556], [2207, 15429, 12, 43, 68, 167, 15430, 40, 12, 2, 89, 83], [2207, 12, 15431, 186, 56, 1185], [15432, 6, 822, 1850, 37, 750, 18, 567, 95, 251], [8027, 2, 15433, 1], [8027, 76, 214, 1, 162, 4, 721, 68, 51], [6720, 2533, 29, 14, 2, 104, 22, 484], [1676, 84, 1, 30, 486, 17, 844, 84, 1888, 30], [15434, 2, 535, 663, 7, 277, 22, 116, 443, 493, 3, 452, 58, 7, 7, 8028, 1, 15435, 20, 379, 453], [151, 739, 7, 5776, 13, 15, 50, 250, 115, 18, 4, 401, 98, 4, 1, 129, 1705], [151, 114, 80, 1, 8, 70, 50, 326, 1], [15436, 1, 1524], [23, 2, 419, 1, 18, 22, 169, 45], [23, 2, 6826, 30, 145, 6, 39, 1026, 9], [23, 2, 511, 15437, 4, 24, 93, 23, 48, 238, 19, 21, 43, 15438, 139, 108, 54, 15, 393, 3, 2036, 86, 16, 6, 215, 1363], [23, 2, 179, 30, 25, 5, 4694], [23, 2, 7326], [23, 2, 613, 15439, 3, 87, 2, 613, 83], [23, 2, 1658, 234, 145, 19, 224, 19, 224], [23, 2, 816], [23, 2, 3821, 145, 37, 5, 62, 23, 2351, 125, 178], [23, 59, 6, 19, 2528, 1, 30, 35], [23, 59, 6, 28, 32, 4, 285], [23, 1812, 6, 89, 1, 13, 3, 105, 124, 1], [23, 1166, 6, 840, 18, 10, 1, 40, 75, 840, 18, 17, 205], [23, 108, 1], [23, 108, 6, 1986, 68, 26, 43, 1, 15440, 441, 2, 2108, 662, 1926], [23, 328, 27, 3895, 23, 33, 542, 6, 597, 35, 8, 44, 24, 21, 1418, 15441], [23, 15442, 3, 433, 18, 10, 8029, 3700, 6, 10, 1246, 34, 40, 560, 41, 4, 144, 3700, 776], [23, 82, 4, 15443, 5, 330, 62, 133, 6, 912, 2, 2325, 18, 22, 1, 9, 226, 4601, 12, 1397, 27, 10, 25, 8030], [23, 28, 5797, 22, 591, 58, 2, 1, 117], [23, 721, 3, 704, 22, 6872, 1093, 17, 4, 56, 3, 440, 747], [23, 2674, 18, 22, 9, 1046, 55], [23, 684, 8031, 42, 63, 79, 17, 4, 15444, 3, 41, 174, 1304, 34, 3, 46, 134, 42, 45, 83], [23, 11, 2, 392, 2611, 1625, 1469, 8, 32, 51, 2, 3450, 26, 79, 10, 4042, 2, 1, 30, 15445, 531, 426, 23, 224, 120, 574, 1442, 51, 17, 55], [23, 11, 2038, 2882, 8, 52, 223, 191, 21, 2, 957, 873, 2183, 125, 43, 873], [23, 33, 2, 379, 145, 54, 135, 778, 11, 1062, 23, 11, 4, 2153, 930, 16, 10, 2680], [23, 33, 2, 379, 145, 238, 259, 10, 164, 358], [23, 33, 525, 192, 241, 221, 66, 41, 15, 1], [23, 33, 11, 10, 347, 1873, 6, 2528, 8032, 27, 10, 234, 1], [23, 65, 21, 2, 540, 6, 109, 5430, 18, 2, 1, 7348, 10, 15446, 15447, 1, 553, 4, 882, 55], [23, 214, 1297, 100, 17, 467, 7, 2355, 1915, 12, 2, 1], [23, 791, 6, 2, 144, 456, 14, 85, 220, 37, 93, 2780, 25, 15448, 17, 11, 84, 2791], [23, 163, 2, 926, 2120, 1, 5, 75, 28, 785, 325, 4107], [23, 105, 2209, 650, 10, 1, 1262, 74, 208, 6560, 3, 75, 799, 125, 161, 77, 2648], [23, 48, 1200, 605, 39, 1, 205], [23, 3872, 3492, 81, 59, 2, 1496, 1, 7, 514, 11, 22, 360, 40, 109, 87, 6, 14, 492, 51, 492, 122, 15, 15, 15449], [23, 101, 2913, 6, 9, 4359, 3, 454, 85, 15450, 218, 3, 29, 19, 125, 78], [23, 748, 6, 14, 2, 112, 153, 5, 146, 14, 112, 188, 153], [23, 700, 125, 80, 1, 180, 971, 75, 1023, 35, 11, 4, 688], [23, 542, 21, 225], [23, 144, 21, 112, 23, 400, 135, 28, 214, 86, 10, 1246, 609, 17, 88, 3, 375, 40, 46, 1184], [23, 825, 1297, 1, 229, 17, 97, 815], [23, 4554, 341, 1289, 1], [23, 366, 93, 163, 10, 1, 4695, 3630], [23, 3887, 515, 16, 22, 138, 391, 229, 35, 18, 10, 2283, 15451, 112, 2577, 29, 810, 956, 33, 14, 15452], [23, 370, 34, 5, 210, 44, 6, 14, 2, 1, 215, 1477], [23, 370, 3, 168, 6, 14, 18, 7, 45, 34, 23, 48, 475, 59, 4, 244, 1], [23, 192, 3248, 1019, 9, 25, 31, 36, 41, 2955, 11, 36, 2570], [23, 96, 61, 843, 74, 15453, 7, 351, 5573, 1], [23, 270, 2, 1, 601], [23, 113, 5, 91, 15454, 41, 84, 1665, 15455, 8, 3086, 248], [23, 4, 796, 24, 38, 15, 107, 6, 939, 1216], [23, 4, 91, 224, 22, 1, 260, 536, 54, 10, 3078, 194], [23, 4, 145, 40, 109, 131, 498, 125], [23, 1265, 59, 168, 22, 257, 8, 221, 3, 216, 15, 99, 1, 55], [23, 515, 16, 32, 39, 669, 30, 435, 11, 10, 844, 1806, 17, 85, 15, 12, 422, 74, 4606, 6, 929, 2, 414, 11, 4, 1511, 7, 45, 12, 1, 4949], [23, 515, 16, 94, 22, 5670, 1, 27, 292, 1169], [23, 515, 16, 39, 1, 896, 13, 36, 334, 55], [23, 122, 6, 107, 108, 73, 2, 595, 30, 1, 244, 15456], [23, 122, 6, 114, 4, 324, 1063, 459, 10, 6569, 4586, 45, 182], [23, 193, 54, 16, 20, 2025, 9, 333, 919, 10, 2121], [23, 2722, 68, 16, 2000, 1925, 224, 2000, 12, 7, 179, 128, 19, 254], [23, 125, 80, 1, 15457, 100, 50, 176, 4, 3660, 571, 694, 22, 6147], [272, 14, 337, 740, 37, 493, 35, 2, 1, 21, 17], [272, 44, 6, 19, 27, 10, 25, 5841, 59, 212, 441, 348], [272, 8033, 151, 72, 296, 29, 19, 27, 894, 88, 201, 115, 790, 100, 2, 9, 137, 27, 10, 138, 11, 4, 1653, 484, 8034, 64, 126, 860], [272, 204, 3911, 1035, 40, 271, 18, 10, 215, 1203, 34, 3, 64, 7, 15458, 1], [272, 762, 7, 24, 54, 13, 290], [272, 762, 4, 24, 54, 13, 290, 1477], [272, 349, 35, 119, 18, 7, 24, 8, 1598], [272, 349, 35, 119, 18, 7, 24, 8, 15459], [272, 349, 35, 119, 18, 7, 24, 163, 1598], [272, 4055, 856, 11, 7, 24, 9], [272, 234, 1, 82, 106, 6, 106, 8, 3, 271, 11, 10, 507], [272, 1624, 7, 24, 54, 13, 2, 8035], [272, 192, 228, 1674, 39, 9], [272, 1516, 7, 24, 5842], [272, 56, 11, 2554], [571, 28, 337, 224, 15460, 437, 12, 15, 2, 490, 338, 4, 904, 7, 8036, 1212, 565, 16, 3437, 2095, 86, 52, 96, 63, 484], [571, 762, 4, 24, 54, 13, 290, 264], [571, 2148, 10, 2556, 27, 39, 940, 1561, 1, 244, 213, 18, 10, 164, 33, 223, 14, 17, 8, 2, 607, 574, 29, 41, 106, 21, 4, 1662, 2224], [571, 557, 5, 71, 5, 208, 188, 31, 5, 208, 13, 2, 1, 604, 28, 557, 13, 2, 1], [11, 862, 23, 8037, 6, 697, 10, 1, 1511], [11, 293, 16, 4155, 127, 287, 1331, 458, 377, 1056, 261], [11, 2, 629, 326, 46, 4, 15461, 87, 2393, 883, 8, 15462, 439, 3, 90, 9, 7, 114, 3442, 11, 14, 4, 166, 15463], [11, 1548, 5, 911, 9, 3, 132, 35, 371, 15464, 18, 4, 5396, 216, 15465, 831, 51, 197, 8, 96, 745, 4812], [11, 521, 96, 551, 82, 215, 264, 8, 22, 1383, 12, 58, 2, 2336, 18, 2765, 1, 63, 3, 259], [11, 521, 1516, 35, 13, 2, 1], [11, 143, 489, 1955, 5843, 3, 150, 13, 2976, 15466, 172, 25, 15467, 13, 85, 15468, 2212, 7918], [11, 2949, 261, 3, 1469, 2, 77, 6, 4, 8038, 3327, 27, 4, 8038, 149, 40, 47, 1426, 2, 83], [11, 164, 5, 456, 191, 15469, 5, 2, 5357, 68, 74, 2, 339, 1], [11, 10, 1727, 213, 289, 608, 127, 25, 8, 1, 8, 36, 265, 8, 6483, 10, 15470, 136, 8039], [11, 10, 1242, 15471, 12, 2, 1251, 18, 7130, 16, 71, 60, 16, 3780, 1437, 171, 9, 8, 25, 590, 1383, 8, 185, 5844], [11, 10, 1242, 155, 1, 2506], [11, 748, 6, 14, 2, 112, 153, 5, 41, 6, 14, 112, 153], [11, 166, 1199, 10, 15472, 12, 96, 15473, 157, 18, 15474, 225, 47, 2, 83], [11, 166, 324, 79, 5, 2, 83], [11, 2127, 564, 25, 8, 1490, 25, 28, 1, 426, 15, 1428, 239, 16, 384, 25, 2648, 55], [11, 388, 1351, 1707], [11, 4, 722, 449, 398, 4619, 4659, 8, 10, 674, 514, 126, 401, 21, 72, 7364, 15475], [11, 4, 324, 16, 161, 15476, 584, 7, 368], [11, 22, 1588, 5, 103, 258, 320, 16, 3131, 968, 249, 30, 1381, 8, 24, 15477, 15478, 3, 44, 6], [11, 268, 707, 205, 9], [11, 80, 1, 706, 2922], [15479, 12, 13, 4, 4696, 8, 759, 8040, 4, 323, 16, 2, 1187, 2, 872, 51, 4, 580, 15480, 4, 7968, 16, 4, 2372, 18, 15481, 15482], [15483, 119, 440, 129, 15484], [1581, 97, 1366, 9], [15485, 383, 41, 17, 32, 1617, 51, 197, 3, 724, 10, 1, 8041, 46, 309], [4190, 46, 223, 134, 39, 153, 45, 188, 36, 47, 1856, 6, 404, 4, 215, 178], [4190, 514, 6, 1743, 5136, 180, 1654, 1475, 6, 14, 248], [6555, 30, 141, 1, 13, 5, 62, 10, 19, 518, 8, 162, 3, 4260], [15486, 1179, 59, 98, 15487, 1222, 1342, 6, 20, 5642, 127, 21, 4697], [2660, 2, 1139, 1816, 16, 15488, 6, 400, 8, 194, 4, 15489, 15490, 15491, 129, 135, 123, 4, 56, 15492, 1651, 49, 897, 116, 12, 15493], [610, 44, 5, 65, 51, 1400, 13, 1472, 4, 19, 277, 22, 8042, 86, 15494, 15495], [661, 16, 79, 922, 166, 9, 77, 198, 14, 608, 922, 8043, 552, 7, 33, 17, 1168], [661, 16, 1344, 1201, 412, 9, 14, 1344, 987, 7232], [1760, 997, 5845, 2807, 3987, 3090, 1689, 5846, 160, 5847, 1760, 997, 5848], [1760, 997, 5845, 2807, 3987, 3090, 1689, 5846, 160, 5847, 1760, 997, 5848], [1760, 997, 5845, 2807, 3987, 3090, 1689, 5846, 160, 5847, 1760, 997, 5848], [1760, 1205, 2807, 3987, 3090, 1689, 5563, 160, 8044, 4, 8045, 8046], [1760, 1205, 2807, 3987, 3090, 1689, 5563, 160, 8044, 4, 8045, 8046], [432, 279, 19, 7, 9], [432, 110, 131, 94, 22, 1, 26, 81, 133, 151, 70, 5, 1418], [432, 290, 34, 15, 46, 43, 24, 11, 10, 548, 25, 432, 1293, 357, 34, 274, 1394, 404, 74, 1552], [432, 134, 2, 19, 432, 134, 2, 19, 432, 432, 432, 134, 2, 19, 1, 3, 29, 134, 2, 19, 59, 5, 74, 393, 7, 5, 58], [432, 41, 43, 15496, 89, 1, 12, 4, 101, 184, 7, 3, 13], [432, 636, 827, 716, 2750, 754, 571, 28, 10, 1290, 153, 325, 213, 66, 46, 1042, 143, 3607, 325, 213, 146, 7112, 240, 125, 5317, 499], [432, 636, 57, 23, 58, 15497, 383, 636, 15, 276, 450, 125, 17, 138, 250, 11, 60, 2570], [432, 62, 85, 22, 1, 15498, 18, 113, 17, 162, 40, 14, 61, 615, 1004, 59, 4516, 1, 13, 2629], [432, 13, 2945, 231, 9], [432, 13, 4, 236, 149, 40, 81, 6, 663, 209, 27, 136, 112, 971, 183, 30, 171, 379, 30, 236], [432, 389, 21, 24, 140, 50, 24, 15499, 3, 61, 6798, 11, 15, 8, 3, 46, 2, 15500], [432, 302, 43, 1], [6158, 41, 43, 409, 89, 1, 12, 4, 101, 184, 7, 3, 13], [1409, 279, 59, 162, 2, 8047, 132, 162, 2, 1, 784, 74, 4, 716, 45, 36, 132, 785], [1409, 41, 43, 409, 576, 89, 1, 12, 4, 101, 184, 7, 3, 13], [1409, 41, 43, 409, 89, 1, 12, 4, 101, 184, 7, 3, 13], [1409, 94, 71, 60, 16, 5, 25, 181], [15501, 12, 2, 1, 21, 48, 100, 17, 2324, 84, 15502], [2083, 509, 574, 1, 2353, 15503, 478, 1761, 45, 21, 15504, 6, 110, 608, 126, 7429, 2431, 733, 12, 4, 1016, 5218], [12, 3424, 4, 5849, 95, 2104, 527], [12, 3424, 4, 5849, 95, 2104, 527], [12, 15505, 2, 144, 55, 192, 15506, 661, 3427, 15507, 333, 107, 108, 5850], [12, 1441, 1974, 152, 44, 6, 955, 2, 1], [12, 1441, 1974, 152, 44, 6, 737, 2, 1], [12, 232, 11, 2, 93, 2156, 225, 74, 57], [12, 393, 61, 142, 390, 1782, 10, 1], [12, 1038, 245, 207, 781, 11, 2702], [12, 15, 33, 17, 74, 12, 1307, 72, 15508, 15509], [12, 15, 804, 735, 20, 373, 628], [12, 40, 10, 698, 16, 9, 74, 3155, 53, 15, 422, 5, 2, 9, 769, 53], [12, 7, 2, 3750, 57, 4, 19, 698, 16, 95, 12, 7], [12, 7, 4, 3903, 1154, 39, 9, 46, 3647, 55, 18, 274, 7, 10, 1988, 890, 524, 323], [12, 7, 4, 3903, 53, 39, 9, 46, 3647, 128, 10, 3428, 890, 524, 15510], [12, 116, 2, 392, 2179, 54, 54, 11, 392, 1453, 8, 23, 48, 81, 59, 1433, 74, 1132, 8, 23, 11, 4, 2156, 6, 15511], [12, 116, 2, 6954, 975, 130, 31, 367, 278, 13, 6, 1550], [12, 116, 2, 15512, 4618, 224, 22, 1, 23, 7324], [12, 116, 2, 2920, 7, 2470, 3320, 2289, 8048, 8, 180, 517, 9, 6, 10, 676, 795], [12, 116, 98, 5851, 1338, 21, 4, 24, 6, 477, 6, 10, 395, 437], [12, 22, 1, 21, 112, 23, 1136, 2549], [12, 22, 9, 223, 706, 17, 108], [12, 22, 8049, 1, 144, 74, 185, 369, 118, 5, 3972, 17, 210, 40, 509, 10, 1618, 15, 322], [12, 22, 144, 1, 109, 22, 185], [12, 5, 542, 1, 149, 10, 343, 5411, 20], [2651, 377, 298, 423, 6, 15513], [15514, 646, 41, 17, 1628, 16, 24, 2756, 114, 1895], [15, 46, 5383, 902, 15515, 439, 1615, 2268, 15516], [15, 46, 777, 6, 311, 2, 1, 102], [15, 46, 777, 6, 311, 7, 1, 102], [15, 46, 295, 13, 778, 169, 149, 5, 44, 2, 1405, 34, 778, 39, 9, 21, 57, 15517, 15518], [15, 46, 295, 6, 311, 7, 1, 102], [15, 46, 8050, 6, 311, 7, 1, 102], [15, 46, 295, 6, 311, 7, 1, 15519, 888, 2521], [15, 46, 8051, 6, 311, 7, 1, 102], [15, 46, 1573, 6, 311, 147, 1, 102], [15, 46, 2357, 6, 311, 7, 1, 15520, 85, 7, 45, 10, 1013, 3008], [15, 32, 192, 11, 5639, 1], [15, 330, 5744, 2258, 26, 3988, 37, 405, 7, 45, 1, 1004, 15521, 35, 74, 28, 906], [15, 14, 954, 3297, 1527, 8, 9, 96, 61, 54, 13, 15, 1638, 2718, 1853, 1997], [15, 14, 37, 93, 6, 48, 146, 4550, 11, 143, 15522, 3, 143, 101, 207, 147, 4550, 218, 207, 617, 14, 1810, 8, 259, 102, 143, 120, 4244], [15, 14, 372, 13, 4, 1, 7, 4, 670, 81, 6, 18, 126, 2099, 12, 4, 199, 372, 1, 155, 419, 817, 15, 46, 105, 2, 252, 768], [15, 2361, 17, 38, 2, 183, 77, 136, 2, 89, 1, 2497], [15, 317, 33, 3242, 2749, 15, 3242, 4, 15523, 4, 5852, 7, 197, 51, 39, 261, 7, 49, 3206], [15, 150, 2880, 6, 44, 4, 137, 641, 4, 26, 3, 196, 66, 32, 62, 69, 23, 1752, 21, 34, 15, 15524], [15, 28, 17, 214, 38, 2, 953, 61, 641, 3418, 13, 369, 608, 20, 412, 1], [15, 582, 361, 202, 1440, 257, 15525, 22, 198, 70, 1129, 8052], [15, 12, 19, 144, 71, 3, 75, 72, 2, 419, 184, 11, 22, 331, 461, 60, 15526], [15, 12, 4522, 21, 275, 6, 14, 781, 1078, 15527, 374, 79, 9], [15, 70, 17, 611, 62, 22, 494, 266, 14, 142, 4, 606, 2027], [15, 318, 14, 2627, 25, 118, 109, 227, 7, 24, 142, 8053], [15, 101, 14, 78, 2933, 1, 7, 14, 13, 7, 464], [15, 458, 35, 27, 60, 3060, 820, 8, 27, 15528, 66, 28, 2, 712, 18, 4, 15529, 16, 4, 179], [15, 15530, 17, 364, 102, 38, 3, 79, 5, 108, 2, 470, 2, 710, 790, 579, 5, 29, 8054, 5, 2, 1, 30, 25, 21, 7], [15, 700, 598, 13, 3, 1657, 34, 1409, 67, 553, 16, 78, 9], [15, 109, 46, 777, 6, 311, 7, 1, 102], [15, 109, 12, 99, 89, 7, 124, 104, 1603, 1453, 2619, 50, 211, 50, 4402, 4698, 15, 15531], [15, 611, 71, 1, 597, 35, 14, 1208, 13, 1, 258, 5, 246, 2184, 149, 22, 46, 197, 54, 21, 42], [15, 598, 13, 15532, 81, 6, 8055, 16, 32, 15533, 9, 2648], [15, 1729, 11, 22, 1, 15, 456, 14, 76, 24, 30, 25, 533, 45], [15, 1729, 11, 135, 456, 14, 88, 24, 30, 25, 533, 45, 959, 17], [15, 4, 5146, 16, 4, 690, 1], [15, 47, 10, 4839, 213, 7, 3, 683, 39, 9, 2128, 334], [15, 47, 417, 16, 5, 6, 753, 17, 181], [15, 118, 14, 322, 431, 31, 3, 41, 6, 94, 378, 127, 106, 230, 3, 61, 108, 6, 837, 975, 188], [15, 2151, 80, 203, 30, 7, 1207, 54, 4, 15534, 6, 197, 116, 48, 17, 3162], [15, 83], [15, 862, 8, 78, 25, 96, 172, 27, 39, 319, 61, 28, 5, 2, 436, 321], [15, 1638, 2718, 8, 22, 1, 136, 2, 2178, 978, 1730, 224, 50, 833], [15, 928, 1], [15, 15535, 264, 260, 84, 236, 84, 236, 15, 102, 6, 751, 3, 61, 27, 2, 768, 7, 372, 13, 15536, 84, 236, 84, 236], [15, 3067, 1080, 283, 7, 3067, 15537, 31, 3, 29, 62, 350], [15, 3956, 1059, 5, 29, 44, 6, 14, 2, 9, 2027], [15, 60, 9, 54, 135, 3445, 26, 3, 41, 1619, 125, 17], [15, 2, 3085, 15538, 2368, 92, 52, 818, 8, 15539, 7, 52, 4, 2987, 120, 15540, 1307, 14, 148, 474, 12, 15541, 2049], [15, 2, 95, 15, 2, 2185, 43, 15, 1892, 15542, 18, 15543, 15544], [15, 2, 161, 1, 51, 4, 1195, 139, 27, 4870, 15545, 26, 1568, 962, 3, 62, 384, 663, 6967, 73, 1066], [15, 2, 320, 16, 674, 782, 30, 25, 54, 1184], [15, 2, 320, 16, 203, 1, 51, 22, 460, 23, 66, 51, 117, 92, 10, 1927, 193, 99, 209, 739, 6, 14, 51, 2, 2508, 13, 22], [15, 2, 690, 16, 1604, 1414, 15546, 2, 2043, 3989, 95, 63, 48, 1281, 2, 68, 1381, 3333], [15, 2, 2185, 15, 2, 95, 336, 15, 33, 17, 58, 3231, 224, 4, 15547, 55], [15, 2, 5853, 18, 474, 778, 24, 12, 105, 1252], [15, 2, 611, 611, 115, 38, 2, 1, 468, 50, 5201], [15, 2, 969, 360, 8, 9, 70, 15, 5326], [15, 603, 1503, 159, 15548], [15, 339, 1, 2942, 224, 39, 820], [15, 1493, 1032, 1], [15, 132, 2, 691, 371, 66, 497, 13, 66, 168, 1836, 3, 293, 7, 24, 96, 150, 13, 15, 168, 1836], [15, 4699, 1461, 1], [15, 133, 7, 106, 220, 3, 150, 13, 132, 2, 332, 197, 414, 8056, 2, 1740, 9, 123, 264, 29, 1105, 17], [15, 857, 2, 1, 474, 11, 164, 12, 1585, 123, 1946, 270, 2, 2366, 15549], [15, 519, 20, 28, 24, 74, 49, 68, 57, 103, 15, 14], [15, 488, 7, 2, 1693, 1209, 2053, 156, 465, 4, 314, 4279, 768, 16, 2, 7449, 37, 1, 29, 28, 15550, 109, 210, 465, 5], [15, 356, 71, 275, 29, 67, 6, 14, 79, 2, 1063, 34, 31, 5, 157, 4, 324, 89, 11, 580, 16, 15, 88, 374, 243, 483], [15, 356, 71, 77, 49, 345, 129, 126, 677, 14, 18, 798, 13, 1, 85, 5, 471, 677, 6, 2589, 27], [15, 356, 71, 39, 15551, 120, 177, 131, 208, 13, 374, 3029, 634, 15, 107, 106, 6, 8057, 611, 30, 3255], [15, 356, 38, 42, 28, 2, 202, 275, 214, 36, 192, 208, 179, 88, 2, 1], [15, 61, 142, 15, 61, 142, 15, 61, 142, 161, 83], [15, 152, 14, 2, 358, 658, 21, 4, 232, 31, 22, 7078, 12, 117], [15, 332, 14, 2, 112, 25, 38, 39, 25, 41, 1, 8058], [15, 332, 28, 2, 1, 82, 4, 689, 6, 249, 20, 138, 18, 15552, 300, 326, 62, 15553, 40, 90, 4, 8059], [15, 1943, 94, 418, 345, 8, 1545, 539, 323, 1788, 18, 135, 140, 36, 41, 27, 2, 141, 2149, 181, 661, 16, 2, 112, 91], [15, 341, 8, 10, 4557, 49, 204, 3, 150, 13, 2, 141, 1], [15, 15554, 54, 22, 1, 163, 1905, 184], [15, 33, 48, 4, 199, 49, 48], [15, 698, 16, 356, 38, 111, 113, 17, 36, 745, 297, 17, 11, 213, 8, 162, 44, 3, 5795, 13, 51, 337, 1], [15, 564, 7, 5, 63, 303, 754, 7, 65, 13, 112, 2388, 15555, 31, 5, 255, 15, 3, 103, 70, 501, 16, 350, 20, 2, 445, 883, 83], [15, 822, 6, 10, 1, 5, 75, 19, 50, 25, 149, 40, 13, 355, 1529, 5, 75, 1800, 50, 25, 40, 41, 2680, 5, 498, 5485, 2950], [15, 13, 1527, 1, 11, 1966, 7, 276, 741, 123, 80, 234, 31, 5, 616, 102], [15, 3901, 1147, 1654, 1654, 1654, 4700, 18, 80, 815, 1], [15, 169, 129, 1, 110, 464, 3, 64, 462], [15, 10, 455, 1, 5754, 15556, 243, 457, 15557], [15, 10, 91, 457, 32, 4, 180, 517, 1, 229, 170, 60, 64], [15, 43, 454, 10, 15558, 2303, 12, 204, 307, 8060, 144, 1444, 1032], [15, 48, 15559, 1, 15, 15560], [15, 48, 15561, 15, 179, 73, 2384], [15, 48, 2, 2998, 6, 44, 2, 15562, 15563, 34, 38, 7, 1, 29, 2728, 108, 18, 188], [15, 48, 1725, 5, 94, 4, 324, 15564, 15565, 8, 8061, 15566, 32, 11, 68, 1355, 8, 5854, 15567], [15, 15568, 3, 338, 770, 8062, 15569, 94, 97, 1, 11, 7106, 44, 501, 27, 1444, 21, 307], [15, 422, 6, 113, 2, 25, 52, 56, 8, 2, 2217, 103, 105, 582, 3849], [15, 68, 184, 6, 14, 2, 9, 34, 2, 590, 9, 1, 333, 114, 2, 930, 5855, 15570], [15, 101, 15571, 195, 135, 34, 23, 59, 6, 3949, 35, 60, 2626, 7656, 26, 1626, 22, 1152, 1523, 51, 8063, 822, 140, 1, 23, 11, 2977], [15, 101, 2, 607, 112, 1, 3, 1507], [15, 54, 340, 115, 1], [15, 322, 209, 132, 3033, 7, 3, 44, 4, 237, 1, 231, 18, 4, 8064], [15, 109, 2, 1, 38, 20, 122, 6, 70, 2, 511, 6, 217, 499, 8, 36, 2768, 70, 2, 446, 6, 70, 5, 150, 13, 385], [15, 2951, 35, 330, 205, 715, 715, 68, 175, 8, 52, 41, 54, 116, 70, 501, 16, 715], [15, 7962, 2914, 7, 43, 68, 63, 48, 345, 51, 577, 469, 288, 194, 159, 2921, 15572], [15, 37, 939, 9, 15573, 277, 474, 3, 58, 40, 208, 33, 13, 17], [15, 37, 2762, 38, 5, 1, 81, 6, 189, 545, 504, 7, 37, 974, 6, 58, 6, 246, 77], [15, 96, 2750, 1], [15, 96, 61, 188, 23, 152, 192, 751, 149, 22, 25, 41, 4, 9], [15, 1216, 13, 22, 7, 70, 202, 111, 65, 726, 15, 48, 2130, 630, 15, 185], [15, 850, 1], [15, 850, 283], [15, 4, 5754, 5755, 462, 1794, 20, 720, 29, 14, 2, 7043, 861, 35, 83], [15, 4, 247, 837, 299, 1269, 2, 184, 12, 2, 193, 68, 106, 74, 6, 68, 5856, 8, 3962, 15, 456, 14, 7, 193, 7948], [15, 22, 391, 418, 311, 343, 11, 4, 8065, 65, 33, 13, 1152], [15, 22, 9, 327, 23, 65, 51, 40, 41, 50, 30, 54, 11, 15574, 88, 41, 473, 27, 50, 15575, 9, 284], [15, 313, 15, 11, 50, 977, 1903, 37, 70, 2, 179, 15576, 54, 16, 50], [15, 106, 6, 382, 15577, 11, 15578, 71, 133, 15579, 35, 5517, 66, 44, 5704, 5857, 298, 4, 3671], [15, 6, 239, 9, 238, 208, 13, 4, 1039, 4840], [15, 99, 570, 6, 81, 59, 119, 285, 69, 672, 30, 22, 449], [15, 8066, 6, 17, 7, 116, 49, 732, 69, 1813, 6, 204, 4, 15580, 7, 196, 32, 732, 669, 103, 248], [15, 804, 34, 3, 346, 4122, 15581, 647, 5855, 82, 15582, 6, 2038, 1654, 3664, 527], [15, 1039, 129, 1, 34, 169, 129, 50, 218, 169, 793, 295, 10, 164, 12, 270, 2, 15583, 15, 48, 4, 193, 15, 136, 6, 4565], [15, 1444, 35, 22, 1], [15, 1036, 159, 524], [15, 3574, 1], [15, 2, 1, 259, 11, 2, 823, 162, 5, 44, 268, 2154, 21, 970, 8, 8067, 2154, 21, 346, 770, 2059], [15, 2, 937, 89, 1, 11, 22, 360, 8, 5, 15584, 18, 185], [15, 2, 437, 1, 97, 165, 253, 3651, 3, 134, 97, 22, 138, 5, 88, 1159, 4, 15585], [15, 280, 1926, 9, 34, 1039, 107, 230, 97, 280], [15, 431, 15, 2544, 3, 62, 78, 41, 4, 329, 1, 3, 594], [15, 284, 9, 66, 32, 8068, 617, 23, 81, 32, 10, 228, 12, 10, 730], [15, 150, 13, 8069, 1], [15, 356, 71, 1, 3390, 17, 36, 383, 214, 36, 75, 44, 17], [15, 356, 71, 39, 9, 103, 14, 262, 80, 310, 32, 115, 8, 88, 292, 115, 790, 44, 2, 520], [15, 15586, 54, 410, 22, 1, 86, 15, 15587, 74, 256], [15, 2394, 130, 2, 1026, 1, 2821, 1849, 612, 288, 40, 298, 2, 5858], [15, 13, 42, 67, 17, 6, 14, 4, 2089, 9, 8, 147, 4333, 46, 15588, 556, 15589, 288, 23, 219, 8, 259, 19, 147, 3, 516, 72, 19, 15, 8, 42], [15, 48, 156, 93, 6, 44, 15590, 601, 20, 33, 2, 185, 1, 15591, 513], [15, 3872, 7, 3, 90, 7, 1, 3, 33, 90, 4, 565, 52, 58], [15, 3990, 4, 1, 12, 96, 8070, 8, 745, 100, 61, 16, 4, 722, 4282, 33, 231, 254, 5, 19, 35, 2, 93, 184], [15, 550, 6, 1131, 68, 16, 20, 2067, 1, 74, 84, 77, 33, 73, 358, 73, 5, 113, 170, 59, 15, 5859], [15, 37, 239, 1, 163, 126, 228, 29, 13, 17, 32, 140, 16, 68, 916, 2, 25, 7, 8071, 103, 233, 96, 44, 233], [15, 614, 6, 14, 190, 34, 66, 29, 58, 190], [15, 4, 905, 16, 942, 5, 100, 68, 16, 76, 15592, 184, 5, 62, 814, 1713, 4, 1119, 15593, 6, 45, 18, 20, 1832], [15, 99, 570, 21, 32, 22, 908, 19, 32, 78, 9, 425], [15, 573, 464, 55, 31, 20, 77, 86, 59, 5, 26, 5, 29, 70, 50, 24, 756, 5, 46, 45, 15594], [15, 8072, 1619, 278, 405, 10, 3488, 9, 445], [15, 6132, 127, 61, 18, 92, 130, 201, 44, 42, 842, 80, 56, 30, 451, 117, 92], [15, 57, 66, 79, 31, 2, 153, 113, 2, 275, 246, 91, 41, 214, 77, 5188, 3451, 7, 91, 315, 344, 35], [15, 97, 1587, 15595, 143, 15596, 1274, 4, 112, 3982, 4523, 3, 47, 18, 22, 1681, 250, 24], [8073, 1389, 6, 632, 10, 343, 3, 46, 5029, 15, 15597, 2194, 54, 325, 1], [289, 41, 4, 237, 228, 2, 2508, 144, 222, 2912], [289, 105, 297, 22, 820, 16, 24, 975, 15598, 5860, 4, 450, 16, 22, 323, 15599], [3930, 15600, 47, 18, 84, 1262, 91, 45, 32, 5861, 92, 100, 28, 15], [3512, 739, 136, 105, 405, 17, 21, 81, 6, 3488, 9], [5862, 600, 70, 98, 2052, 51, 4, 15601, 64, 7, 181], [5862, 90, 21, 1615, 12, 983, 5820, 736, 3, 96, 64, 5862, 464, 37, 31, 52, 87, 217, 79, 2, 104, 151, 79, 217, 2, 1298], [7338, 29, 70, 17, 65, 13, 2, 1, 128], [2407, 525, 32, 143, 1, 1315], [4670, 5062, 27, 2339, 15602, 110, 15603, 49, 698, 16, 4, 199, 31, 5, 1341, 4, 15604, 206, 2965, 15605], [3763, 3975, 41, 3819, 21, 397, 18, 2, 1879, 8, 72, 993, 50, 117, 11, 50, 5863, 4, 5864, 12, 37, 839, 5, 63, 168, 2, 15606], [3763, 175, 19, 50, 117, 11, 4, 24], [1297, 12, 4, 796, 1, 11, 1641, 3, 15607, 172, 3186, 944], [5865, 39, 611, 323, 366, 1986, 86, 133, 2365], [1688, 1059, 5177, 15608, 28, 50, 668, 24, 15609], [1688, 2424, 534, 27, 1251, 136, 50, 206, 24, 3001, 2044, 8, 1207, 27, 15610], [1688, 1328, 136, 50, 5701, 24, 2105, 123, 2, 15611], [3030, 1124, 20, 2, 861, 35, 1, 55, 678, 5, 1563, 86, 20, 37, 209, 165, 130, 15612, 6890], [5386, 2, 9], [1615, 2268, 160, 15613, 26, 42, 29, 62, 259, 410, 337, 26, 337, 2341, 232, 1330, 527], [4352, 41, 378, 16, 4, 832, 2883, 7, 1392, 435, 29, 109, 87, 6, 65, 93, 6, 349, 39, 9, 67, 3332], [15614, 8074, 138, 15615, 70, 1, 4301, 54, 371, 6664], [1176, 30, 1, 238, 227, 17, 6, 2, 735, 34, 5, 266, 259, 6, 94, 7, 45], [1176, 1, 251], [1176, 25, 1326, 471, 4, 90, 1014, 4, 1], [5866, 12, 270, 2, 83], [5866, 103, 70, 2, 1, 58, 3991, 1887, 103, 70, 2, 25, 58, 3991], [1708, 3691, 30, 9], [3992, 510, 21, 68, 2035, 16, 4657, 424, 268, 2035, 26, 1763, 5867, 3114, 15616, 50, 144, 30, 12, 61, 6, 1869, 55], [3992, 137, 4, 2593, 26, 2391, 33, 65, 51, 263, 13, 15617, 1820], [3992, 271, 3144, 39, 9], [5033, 5868, 677, 2668, 248, 23, 96, 8075, 464, 43, 1592], [6842, 4456, 136, 4, 237, 3511, 18, 3578, 2149, 11, 4701, 64, 4, 193, 40, 70, 1, 8076], [2523, 8077, 2, 1], [891, 603, 291, 232, 1330], [2523, 56], [15618, 15619, 46, 45, 34, 2, 8078, 234, 9, 40, 46, 110, 595], [377, 1050, 8079, 16, 8080, 4294, 8, 15620, 47, 2983, 4702, 8081, 527], [377, 1050, 136, 8082, 1404, 4072, 27, 4, 3323, 15621, 57, 12, 4, 18, 84, 235, 106, 445, 170, 201, 563, 5262], [377, 429, 451, 1726, 80, 280, 200, 5, 465, 4, 3150, 3452, 15622, 167, 43, 280, 23, 966, 98, 3452, 15623, 408], [377, 3408, 15624, 124, 15625, 823, 7586, 327, 16, 126, 3091, 201, 6997, 5113, 4689, 82, 3946, 26, 8083], [377, 8084, 87, 6, 1024, 21, 4, 15626, 488, 7, 15, 4, 884, 15627, 7, 15628, 15629], [377, 3483, 2252, 1938, 3993, 73, 3452, 15630, 1057, 15631, 204, 11, 4848], [377, 227, 2421, 1129, 15632, 173, 15633, 21, 928, 4072], [377, 49, 298, 2, 708, 7, 4, 1065, 16, 4427, 309, 268, 115, 1712, 456, 14, 4, 859, 616, 18, 240, 7, 523, 70, 240, 15634], [377, 394, 18, 775, 2311, 11, 15635, 6, 1453, 2743, 3554, 54, 16, 4, 15636, 15637], [377, 5869, 2, 496, 16, 4, 204, 123, 15638, 15639, 16, 2, 5784, 3091, 5443, 211, 84, 8085, 47, 512, 142], [377, 708, 6, 44, 565, 98, 1714, 8086, 1183, 8085, 11, 15640, 26, 3993, 15, 3091, 123, 226, 3503], [377, 3993, 2, 91, 82, 73, 4, 68, 69, 1281, 2, 4467, 3396, 859, 18, 15641, 2521], [377, 176, 18, 15642, 59, 44, 565, 142, 225, 57, 36, 86, 12, 98, 5570, 8087, 485, 15, 47, 98, 8086], [377, 598, 6, 14, 127, 1917, 129, 4, 3301, 16, 4, 15643, 4703, 11, 130, 15, 1405], [377, 3889, 191, 21, 1760, 261, 11, 6, 14, 2176], [377, 8088, 770, 26, 1624, 15644, 4822, 7, 2052, 11, 2, 496, 16, 2, 15645, 1036, 2521, 1196, 15646], [15647, 598, 6, 14, 44, 98, 15648, 1924, 15649, 123, 1101, 348, 15650, 35, 8, 51, 240], [15651, 23, 61, 6, 14, 2, 24, 59, 254, 3, 29, 67, 4, 64, 16, 10, 164, 4651, 17, 32, 626, 8, 385], [6571, 6122, 65, 13, 2, 1859, 189, 7, 1159, 2, 15652], [852, 5103, 156, 4576, 18, 1696, 186, 25, 125, 84, 2340, 460, 163, 1, 4, 25, 75, 3426, 125, 4656, 742, 25], [852, 1028, 18, 2, 8089, 5870, 3273, 288, 52, 48, 15653, 57, 2, 141, 1], [852, 379, 223, 512, 7, 1], [852, 460, 41, 9, 34, 15, 156, 341, 73, 286], [1050, 15654, 4, 3722, 71, 22, 24, 2728, 305, 4114, 11, 15655, 92, 52, 15656, 8090], [1050, 2112, 12, 3681, 22, 823, 1, 35, 18, 50, 373, 323], [1050, 7060, 56, 1615, 8091, 259, 18, 4058, 160], [15657, 1920, 12, 2, 344, 35, 285], [2017, 3031, 33, 788, 495, 4, 4631], [2017, 3980, 160, 31, 3, 222, 14, 2, 158, 21, 2, 115], [2017, 3980, 160, 559, 20, 2450, 158], [2017, 12, 2, 1043, 1, 277], [1344, 10, 1790, 1], [4488, 2906, 33, 514, 32, 10, 538, 227, 142, 2, 290, 13, 2, 1, 293, 52, 468, 84, 244, 290, 92], [4488, 15658, 114, 2, 1144, 51, 185, 660, 2541, 825, 3994, 8, 84, 15659, 15660], [2906, 8, 15661, 49, 54, 16, 1069, 211, 134, 15, 126, 32, 3682, 11, 4, 250, 15662, 4, 15663, 198, 28, 127, 137, 106], [15664, 65, 13, 2, 9, 82, 15665, 8, 4342], [1488, 37, 15666, 132, 35, 6, 51, 1197, 17, 172, 1, 26, 1216, 97, 62, 1488, 1417, 944], [4171, 6787, 4704, 16, 2, 3376, 315, 660], [15667, 33, 15668, 8092, 1756, 52, 63, 70, 15, 4, 2614, 5871, 3231, 34, 3, 2711, 1592, 254, 103, 87, 1343], [3571, 20, 2, 9], [2809, 18, 10, 995, 7, 323, 12, 56, 99, 5872], [15669, 51, 2775, 18, 6895], [2263, 1137, 75, 72, 43, 6, 590, 24, 375], [15670, 2771, 96, 598, 726], [756, 54, 1700, 1352, 1371, 218, 23, 129, 10, 234, 1, 967, 8, 10, 77, 3055, 18, 4, 676, 160, 3571, 15671], [2309, 4421, 14, 10, 443, 4792, 147, 120, 77, 64, 147, 207, 91, 15672, 40, 114, 15, 332, 8, 5623, 484, 147, 77, 803, 1060, 284], [4660, 49, 96, 24], [383, 2, 717, 153, 163, 4, 2], [383, 87, 2, 89, 1, 7, 223, 156, 555, 17, 142], [383, 87, 10, 312, 8006, 1060, 6, 15673, 4, 2276, 205], [383, 515, 6, 113, 2, 153, 379, 1021, 47, 7595, 1157, 153, 46, 442, 17], [383, 597, 35, 8, 465, 59, 22, 1103, 2646, 57, 2, 5007, 26, 43, 538, 21, 170, 61, 28, 97, 1013, 8, 107, 108, 112, 15674], [2520, 41, 22, 282, 351, 37, 85, 48, 8093, 1145], [33, 2, 379, 145, 125, 2, 1373, 5873], [33, 73, 56, 73, 4, 15675, 1720, 553, 16, 10, 8094, 6436, 621, 2077, 2575, 15676, 478], [33, 426, 20, 343, 12, 15677, 74, 15678, 29, 196, 5757, 80, 45, 146, 532, 5692, 29, 43, 25, 67, 2, 1, 69, 532, 13, 1965, 1349], [33, 140, 5, 44, 2, 1222, 8, 20, 5874, 12, 54, 16, 975, 317, 196, 5, 63, 14, 2, 1, 6, 307, 244, 106, 29, 28, 11, 1885], [33, 1048, 154, 1525, 8, 6, 32, 16, 5, 24, 1545, 59, 15679], [33, 79, 2, 4908, 1641, 781, 54, 21, 4, 1941, 18, 186, 218, 147, 24, 399, 259, 11, 15680, 107, 28, 17, 1], [33, 149, 5, 14, 18, 155, 460, 297, 29, 196, 5, 89, 1], [33, 149, 5, 41, 2, 520, 92, 29, 196, 5, 96, 46, 2, 282, 92, 20, 33, 2, 9, 27, 2, 520], [33, 656, 10, 15681, 27, 2, 15682], [33, 656, 22, 83], [33, 218, 52, 65, 51, 5, 317, 196, 52, 13, 5, 9], [33, 29, 14, 65, 21, 43, 138, 790, 218, 23, 48, 2, 282], [33, 29, 14, 1001, 15, 2, 324, 20, 33, 2, 1, 69, 65, 21, 256, 6, 1, 2195], [33, 405, 147, 595, 30, 414, 26, 66, 136, 143, 237, 813, 15683, 3, 15684, 60, 1886, 34, 40, 2, 462, 8, 143, 207, 1162], [33, 41, 328, 114, 60, 846, 27, 348], [33, 41, 173, 27, 60, 8095, 11, 2221, 731, 320, 1, 3113, 539, 4, 731, 320, 8, 603, 167, 10, 4068], [33, 41, 54, 4, 1198, 486, 98, 206, 202, 9, 27, 4, 5875, 481, 34, 4, 9, 124, 2, 4705, 2194, 13, 15, 47, 15685], [33, 41, 4706, 424, 2, 291, 25, 1], [33, 41, 45, 18, 123, 2, 95], [33, 124, 217, 793, 1727, 5876, 191, 17, 57, 4, 5691, 2970, 21, 18, 10, 1832, 523, 42, 15686, 686, 83], [33, 402, 76, 4, 178, 5, 1172, 1429, 30, 8, 492, 263, 32, 4, 1885, 16, 194], [33, 167, 1369, 11, 567, 1187], [33, 555, 18, 66, 784, 6, 4, 967, 1], [33, 11, 1548, 4, 115, 487, 28, 165, 436, 15687, 445, 124, 2, 1165, 8, 14, 4, 388, 3, 195, 3, 157, 1913, 1435, 3440, 18, 15, 37, 116, 568, 15688], [33, 204, 292, 95, 27, 378, 1771, 267, 274, 3, 389, 701, 11, 10, 2227, 521], [33, 1351, 11, 15689, 4, 1861, 47, 73, 15690, 73, 2, 1], [33, 100, 5, 62, 66, 32, 653, 7705, 110, 4, 322, 1], [33, 13, 2, 83, 1413, 385, 795, 11, 7990, 15691, 385, 3756, 16, 7611, 5877, 385, 194, 2915, 15692, 385], [33, 65, 51, 2, 1199, 761, 8, 299, 6, 531, 296, 40, 19, 35, 60, 716, 8096, 140, 3, 195, 15693, 5161], [33, 216, 7, 959, 10, 1], [33, 318, 19, 80, 455, 83, 147, 33, 71, 3, 150], [33, 87, 2, 89, 1, 7, 223, 156, 555, 17, 142], [33, 87, 6, 62, 57, 7, 24, 13, 37, 68, 106, 12, 595, 27, 17], [33, 469, 11, 10, 164, 3, 131, 94, 217, 18, 730, 15694, 65, 51, 126, 730, 2005, 8, 72, 1678, 2, 1765, 729, 49, 5, 15695], [33, 748, 1745, 522, 1, 316, 18, 4, 534], [33, 433, 10, 500, 2323, 8, 510, 1117, 4, 299, 7, 11, 4, 450, 3, 47, 4, 234, 83], [33, 448, 2, 846, 410, 232, 1330], [33, 5732, 10, 250, 15696, 684, 15697, 12, 2, 2529, 699], [33, 509, 22, 610, 2296, 15698, 10, 15699, 2550, 123, 1809, 1, 123, 15700, 15701, 20, 4664], [33, 375, 38, 44, 1911, 671, 431, 15702, 152, 79, 2, 320, 16, 5, 54, 21, 271, 2066, 13, 2, 1, 32, 22, 817], [33, 121, 680, 6, 26, 215, 106, 3, 44, 6, 94, 84, 1, 30, 21, 1763, 707], [33, 121, 187, 11, 580, 16, 22, 206, 462, 3, 716, 4384, 88, 40, 1087, 8097, 5, 113, 7, 2607, 12, 15, 99, 713, 11, 164, 6, 28, 3200], [33, 486, 2, 1170, 15703, 1117, 4, 15704], [33, 486, 2, 462, 7, 65, 13, 2443, 1567, 1567, 3995, 2082, 7, 1, 12, 2030], [33, 486, 4, 832, 1, 11, 164, 294, 142, 4, 606, 31, 40, 210, 44, 7, 8098, 758, 18, 3, 700, 2062, 178, 50, 30, 35], [33, 486, 827, 200, 6, 10, 347, 7227, 1], [33, 854, 57, 35, 9, 19, 3, 58, 6, 42, 1], [33, 297, 2, 252, 255, 32, 202, 8, 120, 1927, 27, 15705, 15706, 40, 28, 60, 24, 1146], [33, 297, 2, 327, 5319, 16, 3404, 15707, 8, 52, 994, 102, 8099, 837, 8, 3, 75, 139, 345, 1516, 16, 15708, 15709], [33, 297, 4, 832, 1, 11, 6665, 15710, 10, 548, 33, 41, 1097], [33, 872, 1, 64, 872, 717], [33, 366, 2, 413, 3389, 16, 7, 3338, 267, 6, 10, 145], [33, 3432, 545, 2112, 7969, 159, 15711, 434, 6, 430, 35, 545, 212, 69, 547, 458, 676, 21, 3307, 15712], [33, 192, 572, 15713, 5, 1894, 285, 3952, 6726, 2, 405, 11, 10, 186, 5008, 295, 15714, 2411], [33, 192, 10, 4436, 21, 4, 822, 201, 991, 15715, 4948, 15716, 15717, 7, 47, 2, 1, 6, 5462], [33, 139, 14, 2, 9, 274, 3742, 1, 15, 46, 7, 332], [33, 139, 123, 4, 493, 35, 712, 96, 65, 13, 2, 2369, 1466, 15718], [33, 344, 609, 1], [33, 344, 13, 760, 43, 15719, 8, 4, 1, 47, 2, 2531, 2043, 18, 50, 2242, 115, 10, 916], [33, 1469, 10, 117, 845, 288, 484, 18, 4, 4999, 31, 7, 46, 1008, 1, 88, 3, 29, 62, 57, 12], [33, 6, 28, 42, 214, 61, 18, 20, 1785, 904, 18, 135, 8, 1785, 35, 4817, 4707, 26, 907, 18, 495, 235, 88, 844, 17, 55], [33, 881, 142, 11, 4670, 238, 366, 268, 8035, 26, 471, 2, 399, 6, 84, 15720], [33, 1174, 44, 2, 89, 1, 107, 785], [33, 753, 246, 284, 83, 69, 244, 55], [33, 2761, 4, 115, 3, 28, 102, 15721, 5, 62, 22, 1, 12, 152, 14, 18, 4, 2179, 8, 23, 48, 152, 107, 108, 6, 1681, 21, 2, 3871], [33, 194, 4, 2149, 11, 1527, 991, 8100, 162, 36, 429, 7270, 1, 30], [33, 38, 23, 150, 966, 4531, 11, 4, 360, 15722, 260, 95, 592, 11, 87, 16, 33, 79, 17], [33, 1087, 54, 2596, 15, 5338, 16, 441, 11, 15723, 15724, 211, 22, 3119, 181, 210, 1011, 17, 288, 2, 670, 47, 294, 8101, 281, 283], [1748, 3032, 365, 84, 4691, 1, 231, 8, 15, 2946, 4, 45, 54, 16, 307], [888, 252, 944, 23, 48, 144, 37, 139, 81, 6, 17, 13, 3, 195, 74, 151, 192, 14, 144, 8, 70, 5, 396, 10, 7181, 1833], [5805, 1471, 34, 15, 15725, 322, 34, 40, 2, 3976, 15726, 4, 141, 3598, 343, 33, 65, 15727], [5805, 81, 133, 75, 878, 43, 91, 219, 3353, 1, 52, 330, 1262], [4071, 5878, 56, 92], [15728, 435, 3337, 1536, 15729, 3283, 6750, 9, 6244, 15730, 15731, 15732, 2331, 3284, 15733, 3715, 3221, 15734, 12], [15735, 26, 890, 107, 21, 78, 1, 73, 2, 535], [15736, 12, 2, 1], [8102, 15737, 2, 1, 125, 1015, 1349, 19, 3, 65, 13, 9, 26], [1264, 154, 496, 37, 1, 216, 3733, 321, 71, 5, 223, 313, 565, 2, 15738, 913, 107, 35, 125, 147, 45], [1264, 1684, 12, 2, 104], [15739, 12, 33, 2, 2412, 673, 208, 15740, 15741], [1264, 2665, 18, 296, 15742, 12, 70, 9, 150, 13, 3340, 21, 1798], [4598, 383, 157, 32, 39, 1, 18, 25, 165, 192, 5879, 36, 2701, 211, 78, 405, 78, 1, 102], [648, 2, 1, 34, 40, 75, 1244, 17, 54, 27, 4, 45, 23, 15743], [648, 12, 2, 1], [648, 12, 2, 1, 8, 1326, 107, 224, 8, 568, 224, 117, 74, 58, 60, 111, 33, 156, 430, 4, 811, 421], [648, 12, 2, 1, 37, 260, 5, 103, 28, 20], [648, 12, 2, 83, 4, 1879, 103, 227, 110, 31, 4, 395, 67, 15, 6, 74, 1591, 5, 75, 139, 15, 519], [648, 12, 2, 836], [648, 12, 2, 1, 219, 33, 70, 362, 7, 1, 12, 15744], [648, 12, 4, 796, 1, 604, 182, 563, 176, 842, 50, 15745], [648, 12, 4, 884, 1, 375, 7], [648, 12, 15746, 796, 1], [648, 362, 12, 2, 83, 55], [648, 2, 1, 932], [648, 2, 1], [648, 2, 1, 3, 380, 5, 198, 16, 64, 4, 206, 307], [648, 2, 1, 8, 37, 49, 350, 604, 14, 28, 1738, 33, 595, 112, 5287], [15747, 98, 15748, 216, 4, 9, 11, 4, 2015, 15749], [3322, 1630, 3165, 390, 82, 15750, 3453, 15751, 819, 680, 680, 1], [15752, 438, 2, 104, 251], [8103, 8, 3, 3639, 922, 166, 123, 72, 2398, 2607, 13, 15, 70, 17, 55], [176, 384, 4641, 9, 102, 97, 909, 15753], [176, 58, 20, 184, 265, 111, 85, 738, 623, 20, 2, 308, 104], [176, 15, 1080, 3, 105, 19, 2, 15754, 1], [176, 15, 112, 176, 15, 112, 176, 15, 112, 176, 15, 1798, 25, 72, 52, 19, 10, 1, 8, 52, 487, 304, 6, 7176], [176, 15, 7304, 130, 4, 244, 1, 43, 87, 21, 42, 6, 182, 1513, 4, 244, 1, 5106], [176, 212, 423, 3069, 159, 115, 33, 469, 11, 10, 164, 278, 13, 21, 217, 443, 820, 16, 10, 481, 6, 14, 10, 1570, 5576], [176, 6, 531, 22, 213, 1, 8104], [8105, 2097, 146, 14, 143, 101, 480, 682, 153, 147, 119, 15755], [4263, 860, 4708, 6, 143, 120, 3696, 43, 207, 5604], [3079, 18, 794, 257, 9], [2219, 3658, 15756, 1], [15757, 154, 5880, 7, 66, 207, 215, 264], [15758, 1754, 554, 123, 1374, 2616, 380, 40, 157, 11, 197, 8, 429, 7, 24, 128], [543, 384, 810, 153, 54, 143, 1251], [543, 142, 20, 676, 8, 737, 7, 1, 70, 17, 131, 498, 722, 97, 331, 8, 15759], [543, 7, 1, 117, 11, 4, 285], [543, 1, 54, 4, 331, 13, 15760], [543, 153, 364, 8106, 844, 13], [265, 2, 1], [265, 29, 157, 35, 27, 20, 639, 79, 5, 2, 5881, 40, 214, 140, 9, 407, 2, 431, 184, 6, 14, 79, 108, 11, 50, 15761, 921], [8107, 2, 83, 5882, 402, 5882, 402], [204, 50, 481, 27, 15762, 50, 24, 198, 14, 37, 669, 82, 3362, 7, 15, 4522, 6, 555, 108, 2, 15763, 985, 1136, 352], [204, 819, 204, 47, 56], [15764, 147, 1, 8108, 1, 26], [1976, 39, 153, 163, 3, 90, 32, 10, 500, 9], [204, 15, 51, 337], [960, 888, 12, 1417, 34, 1061, 37, 239, 25, 132, 11, 7, 278, 516, 15765, 8, 1518, 41, 753, 7, 1, 12, 33, 15766], [960, 1754, 65, 13, 2, 718, 27, 32, 7, 3766], [716, 42, 214, 228, 203, 19, 1746, 530, 30, 9], [716, 33, 131, 2795, 8, 94, 31, 3, 94, 7, 207, 30, 1, 294, 3141, 237, 442, 116, 103, 14, 68, 882, 1353, 18, 22, 1681], [716, 67, 6, 1218, 10, 2343, 173, 60, 1, 4416], [1065, 4956, 1259, 1011, 8, 7, 8109, 1623, 32, 248], [15767, 15768, 190, 189, 197, 6, 158, 4, 3788, 15769, 8039, 99, 89, 116, 246, 2980, 869, 11, 4, 1919, 6, 2566, 1167], [2841, 15770, 61, 19, 171, 54, 7, 1], [605, 5240, 22, 15771, 15, 15772, 195, 44, 60, 8110, 5, 83], [605, 5761, 22, 1, 33, 1401, 246, 1243, 710, 6, 50, 761, 3, 86, 15, 2, 154, 7569], [605, 7, 1, 34, 40, 249, 17], [762, 240, 142, 125, 667, 1485], [15773, 2, 6461, 11, 325, 180, 1, 4616, 1666, 26], [62, 7, 648, 99, 112, 293, 5, 1042, 4664, 34, 96, 185, 30, 1, 3, 46, 172, 27, 15774], [62, 7, 4, 89, 1, 41, 6374], [62, 85, 95, 29, 255, 1286, 149, 126, 5341, 11, 4, 193], [62, 85, 4, 2023, 3551, 309, 274, 64, 181, 52, 47, 98, 7949, 15775, 37, 2, 141, 480, 675, 49, 3146], [62, 5, 210, 94, 15, 34, 3, 62, 5, 1, 566, 15], [62, 5, 29, 13, 17, 149, 20, 1, 247, 13, 277], [62, 57, 5, 67, 317, 70, 5, 2, 83, 15, 70, 5, 2, 414, 69, 266, 1385, 21, 393, 882, 130, 57, 40, 15776], [1370, 6, 114, 2, 25, 1, 112, 705], [1362, 4578, 12, 270, 2, 83, 632, 35, 285], [1362, 46, 43, 282], [1362, 12, 203, 26, 23, 120, 60, 111, 33, 144, 55, 78, 109, 86, 1362, 203, 205, 134, 17, 2, 421], [1362, 6, 2507, 463, 2, 1221, 4566, 8, 5, 2, 1, 30, 1590, 805], [15777, 22, 1, 15778, 51, 15779, 69, 4554, 125, 1566, 3801], [15780, 1008, 1], [5883, 2, 1], [15781, 25, 103, 728, 393, 2, 89, 1, 448, 448, 18, 39, 685, 15782, 296, 33, 67, 2, 25, 6, 3497, 2, 2729, 102, 10, 30, 1144, 13, 15783], [819, 5884, 5885, 15784, 3005, 4975, 473, 15785, 15786, 5885, 5884, 5645, 15787, 15788, 15789, 819, 5884, 15790], [819, 12, 4, 101, 507, 162, 5, 103, 94, 60, 16, 4, 832, 1, 11, 4, 360, 188, 51, 4, 1195, 139], [599, 203, 9, 555, 2, 25, 142], [128, 852, 47, 79, 15791, 1761, 8014, 221, 4, 970, 279, 57, 2, 2158, 3376, 388, 331, 189, 82, 15792, 72], [128, 367, 26, 43, 12, 15, 422, 6, 257, 2, 1, 35, 129, 60, 175, 74, 336], [128, 448, 423, 59, 22, 1063, 289, 297, 32, 4, 4709, 4, 324, 136, 6, 1761, 11, 3343, 6, 17, 3, 1061, 29, 2800], [128, 5, 2, 83, 8, 1350, 156, 152, 14, 4710, 130, 15793], [128, 200, 42, 109, 33, 79, 17, 2, 9, 55, 53, 221, 5, 917], [128, 57, 2, 15794, 72, 4, 816, 27, 4, 234, 16, 50, 235, 1390, 13, 2, 148, 5886], [1522, 186, 141, 1, 30, 2555, 26, 3, 87, 6, 192, 168, 22, 9, 2760], [695, 1655, 436, 9, 8, 3981, 84, 164, 249], [695, 1324, 22, 1, 12, 37, 185, 251], [805, 410, 15795, 7, 368, 78, 58, 99, 209, 82, 747, 2, 310], [3454, 15796, 15797, 148, 186, 1303, 1, 54, 5550, 15798], [425, 3, 592, 10, 5629, 17, 733, 59, 5, 14, 2, 1, 5887, 23, 544], [425, 242, 35, 42, 2972, 120, 9, 210, 62, 4, 2378, 41, 2275, 390, 1667], [425, 185, 1, 113, 17, 51, 4, 676, 36, 330, 192, 8, 6, 107, 895, 8111, 336], [1558, 495, 1088, 18, 10, 1177, 72, 3, 87, 3092, 701, 1, 5, 4, 68, 509, 15], [2642, 680, 732, 1201, 248, 1520, 8, 2702, 4, 237, 4474], [4711, 315, 73, 19, 28, 39, 268, 104, 102, 10, 909], [8112, 233, 439, 1192, 109, 30, 34, 21, 60, 9, 151, 1571, 2, 535, 15799], [8112, 188, 439, 43, 1691, 3073, 15, 15800, 21, 1989, 8, 13, 15801, 15802], [15803, 439, 847, 5194, 617, 125, 15804, 34, 78, 9, 131, 28, 4473, 2645, 15805], [55, 3, 33, 375, 7, 199, 1, 121, 40, 13, 10, 343, 88, 191, 296, 15, 15806, 1737, 188], [55, 51, 4, 3760, 15807, 7, 1392, 295, 166, 130, 1108, 101, 279, 59, 114, 142, 15808], [55, 116, 2, 81, 269, 259, 18, 4, 1213, 103, 454, 105, 4437], [55, 57, 1, 447, 61, 28, 4, 5888, 66, 220, 387, 3029, 20, 1113, 24, 30], [3280, 3489, 96, 44, 32, 4, 95, 15809, 96, 2, 631, 91, 2139, 96, 18, 7058, 8, 66, 3451], [15810, 30, 399], [5630, 41, 2, 320, 16, 640, 209, 530, 319, 1231, 412, 271, 298, 785, 78, 3455, 1683, 67, 9, 55], [15811, 15812, 15813, 704, 15814, 8113, 15815, 15816, 9, 15817, 8113, 4343, 15818, 11, 15819, 3405, 15820, 4343, 15821, 12, 631, 15822, 15823], [462, 31, 20, 235, 178, 165, 130, 20, 24], [462, 64, 2, 112, 153], [462, 375, 166, 287, 6913, 20, 15824, 49, 3985, 5, 569, 99, 434, 59, 20, 25, 166, 1, 103, 122, 170, 251, 55], [462, 5, 49, 48, 2, 9, 31, 5, 19, 18, 4, 250, 1477, 29, 100, 39, 1045, 1, 308, 6, 350], [462, 58, 78, 15825, 230, 1550, 174, 15826, 74, 100, 15, 632, 54, 410, 140, 42, 29, 131, 598, 13, 2, 9], [15827, 15828, 26, 439, 31, 20, 24, 165, 130, 20, 15829], [462, 244, 6, 17, 276, 72, 50, 15830, 12, 4475, 26, 1276, 40, 86, 40, 41, 2, 15831, 43, 1, 7, 256, 499, 142, 116], [1583, 49, 2, 2016, 8, 190, 1439, 63], [1583, 49, 56, 117, 615], [1583, 408, 103, 150, 4, 1964, 4, 232, 408, 49, 150, 225, 51, 4, 450, 16, 1641, 3359], [2599, 15832, 12, 270, 2, 141, 83, 15, 8114], [564, 4140, 96, 100, 9, 11, 15833, 137, 76, 212, 9, 777, 6, 263, 66, 46, 1078, 34, 36, 96, 75, 1160, 22, 1696], [564, 25, 248], [564, 638, 304, 11, 493, 304, 21, 1, 304, 6, 1601, 304, 21, 217, 499, 6, 58, 45, 21, 980], [15834, 2, 89, 1, 106, 292], [215, 264, 22, 1, 47, 81, 133, 40, 131, 366, 26, 61, 6, 15835, 26, 3, 47, 4, 841, 395, 40, 299, 15836, 69, 389, 21, 32, 22], [215, 106, 3, 2503, 4, 758, 23, 255, 225, 3, 3006, 2, 83, 647, 18, 43, 590, 15837, 34, 40, 1316, 4, 19, 459, 22, 15838], [215, 213, 3, 1354, 7, 1, 219, 92, 15, 15839], [215, 213, 3, 1354, 7, 1, 219, 92, 15, 129], [713, 264, 310, 2535, 27, 10, 15840, 7, 25, 2, 1479], [713, 264, 2851, 15841, 3, 41, 7, 15842, 97, 15843, 164], [1959, 1, 101], [3345, 51, 32, 78, 1], [528, 51, 10, 2609, 7, 36, 502, 17, 190, 8, 847, 15844, 32, 129, 15], [528, 51, 39, 9], [8115, 26, 3, 672, 1468, 66, 592, 18, 4, 1352, 985, 521, 66, 49, 56], [3415, 847, 100, 1646, 21, 39, 9], [3415, 3, 41, 37, 239, 3996, 1, 3, 29, 110, 62, 233], [1103, 133, 6, 345, 161, 1], [15845, 15846, 79, 15847, 2, 1, 649], [2110, 125, 15, 728, 125, 15, 3204, 15848, 55], [15849, 1888, 9, 11, 2, 419, 15850], [338, 2, 153, 8116], [338, 15, 201, 201, 1545, 59, 15851, 38, 36, 523, 4, 68, 69, 266, 389, 21, 254, 304, 18, 274, 6, 1720, 15], [338, 15, 6, 4, 1, 7, 958, 50, 24, 27, 416, 6, 19, 35, 4, 575, 16, 4, 101, 111, 11, 64, 11, 4, 331], [338, 15, 35, 6, 15852, 6, 70, 10, 30, 528, 38, 23, 15853, 19, 1, 188], [338, 15, 35, 6, 17, 15, 1560, 132, 11, 4, 3770, 32, 16, 254], [338, 4, 15854, 6, 1], [1103, 1097, 35, 1925, 392, 88, 2, 1], [1103, 223, 3837, 7, 9, 13, 7, 27, 8117], [1103, 12, 270, 2, 1982, 156, 136, 6, 28, 479, 35, 21, 3186, 8, 45], [440, 2, 417, 141, 1253, 11, 84, 3655, 37, 52, 998, 4, 1088, 162, 52, 79, 17, 2, 1, 39], [440, 10, 15855, 679, 751, 23, 2, 900, 30, 1, 31, 7, 245, 4945, 18, 71, 7, 15856], [440, 10, 215, 1, 1738, 46, 43, 87, 21, 1040], [645, 115, 216, 17, 15, 83], [15857, 16, 1280], [1416, 258, 54, 7, 1, 25, 81, 45], [2425, 32, 14, 13, 15858, 8, 7446, 17, 15859], [3245, 12, 445, 8118, 827, 499, 58, 66, 87, 1782, 1486, 1620, 21, 263, 181, 6, 28, 2, 15860, 15861, 44, 126, 184, 66, 44, 305], [100, 2, 1, 14, 2, 1, 163, 2, 9, 14, 2, 9], [100, 2, 1, 72, 3, 41, 2, 969, 138, 18, 274, 151, 792, 7, 45, 54, 8, 229, 416, 11, 4, 712, 57, 3, 4461, 15862], [100, 2, 1, 122, 8, 644, 17, 35, 40, 223, 14, 861, 808, 2, 728, 579, 325, 4103, 6666, 10, 1, 89, 40, 2996], [100, 2, 145, 122, 17], [100, 2, 399, 122, 17, 19, 224, 19, 224, 19, 224, 563, 84, 803], [100, 50, 14, 2, 9, 85, 5, 139, 50], [100, 170, 19, 84, 234, 9, 11, 1258, 251, 301, 10, 520, 118, 2182, 6, 10, 262, 647], [100, 17, 998, 7, 21, 4, 141, 1, 1193, 17, 6, 15863], [100, 17, 258, 54, 2985, 3816, 12, 14, 2, 1150, 1, 225, 32, 18, 4, 685, 15864], [100, 17, 61, 18, 10, 572, 3011, 149, 5, 9, 2298, 107, 21, 17], [100, 17, 94, 76, 815, 1, 684, 3601], [100, 17, 229, 5, 71, 7, 24, 197, 2911, 15865, 198, 44, 127, 15866, 84, 451, 12, 2049, 2049], [100, 17, 113, 15867, 124, 2, 1178, 16, 256, 15868, 1, 1051, 17, 2, 392, 1178, 23, 86, 15, 4, 199, 184, 8, 192, 15869], [100, 17, 262, 10, 9, 2982, 74, 15870], [100, 25, 90, 1, 64, 254], [100, 4, 1280, 5889], [100, 4, 153, 150, 18, 50, 15871, 128, 114, 50, 6, 4, 689, 220, 36, 58, 247, 93], [100, 76, 9, 14, 434, 78, 1, 14, 109, 1912, 21, 4, 15872, 65], [100, 39, 9, 14, 434], [100, 39, 9, 14, 319, 7, 32, 66, 62], [100, 22, 120, 177, 14, 179], [100, 212, 1, 176, 64, 2399], [100, 61, 819, 10, 153, 43, 690, 57], [100, 14, 4668, 247, 15873, 67, 6, 298, 5890, 8, 3752, 8, 15874, 317, 197, 434, 641, 2, 717, 5, 75, 28, 1037, 15875, 641], [100, 1224, 4, 15876, 15877, 71, 428, 192, 13, 69, 66, 49, 8, 71, 66, 8119], [100, 61, 21, 4, 3164], [100, 33, 72, 4, 3716, 289, 132, 271, 51, 427, 61, 6, 67, 22, 402, 3893, 895, 3, 124, 43, 1179, 3, 222, 227, 240, 7, 1691, 16, 1343], [100, 48, 627, 960, 29, 290, 3, 204, 9], [100, 137, 1378, 103, 4, 179, 120, 77, 27, 833, 1356, 11, 580, 16, 17, 15878, 31, 5, 729, 15879, 297, 22, 1510, 2713], [100, 298, 2, 1036, 18, 22, 1], [100, 94, 71, 22, 568, 55, 23, 168, 10, 15880, 281, 2737, 706, 262, 74, 31, 97, 142, 175, 7, 9, 5860], [5216, 95, 2094, 8120, 1415, 54, 16, 3163, 3215, 363, 15881, 7049], [100, 1056, 870, 232], [100, 61], [100, 61, 9, 15, 751, 2, 358, 106, 5, 62, 4, 15882, 302, 98, 442, 8121], [100, 39, 9, 14, 9, 7, 32, 66, 62], [8122, 4511, 3, 62, 78, 62, 170, 52, 132, 762, 9, 102, 21, 213, 8, 1897, 11, 4, 4642], [15883, 63, 14, 270, 24, 299, 5, 442, 11, 653, 2145, 478, 5, 67, 2, 1258, 15884], [7983, 8, 2854, 21, 32, 61, 28, 17, 2, 1799, 158, 74, 151, 204, 5], [3047, 56, 15885, 8123, 98, 15886, 1108, 69, 1159, 2, 930, 11, 4, 1684, 3038, 15887], [164, 23, 48, 134, 39, 9, 351, 3455, 37, 36, 63, 61, 973, 35, 27, 4, 252, 36, 75, 28, 2260, 3573], [164, 46, 777, 34, 1, 8, 1946], [164, 46, 45, 34, 1, 26, 169], [164, 46, 4515, 34, 1, 8, 169], [164, 46, 45, 34, 1, 98, 169, 3, 433, 7, 441, 13, 3, 1470], [164, 46, 45, 34, 1, 8, 169], [164, 14, 10, 1, 8, 7, 9, 420, 38, 3, 72, 37], [164, 107, 51, 5, 1026, 189, 225, 3, 592, 54, 7, 23, 2, 234, 9], [164, 12, 2, 1, 34, 3, 1512, 50], [164, 12, 2, 1, 34, 155, 381, 136, 15, 115], [164, 12, 2, 1, 34, 155, 381, 136, 15, 115], [164, 12, 2, 2200, 34, 3, 1512, 50, 7408], [164, 12, 101, 5891, 31, 20, 2, 187], [164, 12, 99, 172, 752, 21, 351, 95], [164, 118, 14, 37, 209, 15888, 31, 5, 222, 748, 24, 13, 5, 58, 1421], [164, 2, 1, 26, 88, 5, 309], [164, 2, 1, 88, 5, 15889, 1458], [164, 2, 1, 8, 88, 97, 309, 7, 85, 66, 28, 314], [480, 682, 77, 12, 4, 796, 9], [480, 682, 153, 156, 131, 122, 6, 14, 2071, 4676, 55, 101, 31, 42, 63, 114, 68, 108], [480, 682, 145], [480, 10, 322, 30, 35, 596, 76, 190, 883, 2042], [1613, 8, 1840, 77, 14, 208, 13, 421, 25, 548, 12, 2, 15890, 139, 14, 7218, 1], [1613, 14, 13, 78, 41, 17, 19, 35, 23, 138, 142, 76, 379, 1, 21, 116, 4712, 536, 3, 41, 6, 389, 2354], [13, 134, 2, 45, 59, 74, 60, 166, 172, 4360, 19, 27, 2, 172, 26, 15891, 70, 17, 15892], [13, 9, 46, 223, 14, 3960, 444, 60, 127, 481, 107, 35, 346, 11, 15893, 233, 100, 17, 14, 4, 250, 6, 113, 5], [13, 15894, 230, 76, 26, 1057, 3670, 608, 8124, 12, 73, 4911, 73, 126, 149, 160, 2333, 21, 69, 4, 127, 8125, 377], [13, 1687, 10, 995, 220, 1113, 18, 4, 108, 16, 4, 4555, 1], [13, 3, 75, 44, 25, 1265, 15895, 81, 106, 12, 1880, 16, 10, 460, 15896], [13, 3, 15897, 19, 2, 5892, 84, 408, 1095, 3189, 138, 3027, 26, 334, 30, 15898, 3, 29, 13, 1, 25, 26, 212, 7, 64, 1155], [13, 1783, 1, 33, 58, 15], [13, 2, 703, 1263, 4175, 1], [13, 2, 414, 6, 113, 5, 57, 40, 67, 5, 6, 58, 461, 372, 13, 2, 5495, 2389, 15899, 2725, 6, 7, 12, 4181], [13, 89, 265, 1, 66, 15900], [13, 1], [13, 1, 7, 46, 110, 1252, 251], [13, 1, 693, 42, 46, 58, 7, 11, 4, 250, 507], [13, 1, 20, 2, 720, 7, 196, 5, 29, 229, 1293, 74, 15901, 5, 14, 870, 38, 166, 5893], [13, 148, 9, 3, 502, 5, 2, 1180, 38, 5, 47, 1696, 85, 5, 46, 681, 70, 129, 38, 66, 47, 2780], [13, 29, 137, 27, 17, 1], [13, 2452, 1, 34, 3, 19, 27, 50], [13, 810, 3, 41, 173, 15, 125, 10, 779, 5894, 4, 148, 1255, 462, 4553, 15902, 1267, 26, 60, 1722, 6907, 9, 32, 11, 68, 115], [13, 274, 148, 5, 537, 1], [13, 15903, 72, 112, 25, 41, 2, 548, 99, 15, 33, 114, 2, 112, 1, 21, 170, 6, 229, 15], [13, 8122, 37, 595, 40, 63, 44, 32, 10, 9, 571, 70, 10, 2401, 123, 50, 2, 7891], [13, 599, 211, 23, 328, 262, 217, 38, 3, 29, 262, 108, 3, 1099, 4, 1, 6, 4, 440, 278, 404, 7, 169], [13, 10, 2636, 940, 826, 168, 6, 72, 463, 519, 119, 24, 74, 5, 49, 1155, 57, 15, 152, 15904], [13, 10, 734, 121, 29, 936, 80, 106, 18, 15905, 855, 365, 30, 1, 8, 1699, 30, 252, 149, 36, 46, 223, 28, 42, 2488, 34, 554, 8], [13, 10, 816], [13, 54, 16, 43, 162, 814, 671, 98, 3423, 1, 8, 23, 2239, 328, 27, 20, 1096, 764], [13, 112, 45, 252, 143, 4410, 153, 3, 328, 297, 6, 7947], [13, 40, 41, 2, 989, 881, 22, 1, 397, 11, 580, 16, 17, 65, 13, 15906, 82, 4, 15907], [13, 60, 25, 308, 6, 1, 26, 454, 85, 36, 61, 284, 188, 7, 46, 17], [13, 139, 14, 2, 1, 21, 15908, 8126], [13, 7, 1, 15909, 74, 495], [13, 4, 9, 38, 36, 973, 545, 3040, 4382, 387, 38, 3, 61, 854, 271, 125, 17], [13, 4, 323, 1374, 8127, 32, 4, 202, 1, 214, 140, 10, 455, 1, 15910, 3280], [13, 39, 399, 24, 116, 43, 166, 15911], [8128, 4110, 1, 51, 2, 15912, 91, 221, 7, 466, 178, 2799, 15913, 525, 11, 66, 167, 8129], [161, 1913, 4713, 11, 1885, 21, 3055, 2, 1, 229, 4, 1105, 1527, 7406, 55, 2444, 25, 8, 36, 5615], [161, 960, 109, 216, 1227, 56, 251], [161, 1441, 136, 19, 155, 89, 1, 11, 4, 178], [161, 1], [161, 1, 30], [161, 1, 34, 50, 30, 420], [161, 1, 2063, 100, 17, 61, 3, 47, 117, 123, 10, 331], [161, 1, 171], [161, 1, 27, 602, 30, 233, 2, 1152], [161, 218, 87, 6, 547, 2, 1, 54], [161, 171, 30, 1, 3, 46, 19, 27, 5], [161, 9, 175, 18, 446], [161, 15914, 2662, 322, 288, 42, 1, 8130, 1949], [161, 8131, 9, 2900, 6, 305, 15915, 21, 15916], [15917, 33, 122, 6, 3879, 35, 2, 1308, 211, 2, 95, 8, 983, 1332, 241, 10, 274], [15918, 1293, 396, 34, 478, 67, 6, 1, 59, 71, 209, 15, 249], [477, 6, 50, 53, 40, 1189, 5, 18, 4, 702, 53, 57, 15, 196, 31, 2, 77, 86, 42, 44, 4, 9, 34, 42, 15919], [477, 6, 4, 1959, 287, 81, 59, 126, 260, 803, 15920, 1, 15921, 70, 14, 11, 4, 1341, 51, 15922, 783, 15923, 141, 1102], [1304, 6, 10, 171, 30, 306, 26, 33, 28, 10, 1256, 328, 51, 2, 154, 507, 4, 1, 948, 76, 35, 26, 3, 44, 406, 115, 740], [599, 155, 91, 11, 10, 1154, 670, 2, 89, 120, 1, 73, 2, 4667, 3, 46, 110, 2891, 421, 143, 8132, 650, 2, 1959, 107, 224], [599, 11, 4, 848, 16, 4, 179, 8, 39, 111, 65, 939], [599, 33, 41, 45, 18, 123, 2, 15924, 20, 152, 172, 309, 95], [599, 33, 41, 35, 8, 4, 250, 184, 3, 200, 47, 901, 2, 1139, 1178, 16, 591], [599, 47, 11, 4, 237, 2156, 8, 1, 599, 204, 10, 1822], [4420, 75, 304, 21, 22, 696, 27, 10, 89, 1], [141, 1], [141, 2456, 5895, 1578], [141, 19, 1479, 69, 532, 13, 385, 98, 130, 86, 374, 4, 3289, 5896, 4, 19], [141, 184, 63, 33, 204, 2, 664, 2156, 91], [259, 95, 592, 11, 15925, 2945, 51, 15926, 1909, 15927, 513], [259, 27, 10, 1], [259, 27, 10, 1, 2039, 259], [128, 10, 153, 827, 902], [128, 18, 4, 137, 28, 24, 12, 37, 1016, 38, 36, 442, 20, 5841, 15928, 646, 74, 4, 3355, 235, 1309, 2896], [128, 439, 439, 296, 196, 148, 1, 5, 47, 603, 542, 787, 691, 5897, 5648], [128, 3, 65, 13, 60, 5898, 144, 225], [128, 1103, 2130, 72, 15, 32, 22, 25, 12, 2, 172, 104, 26], [128, 4, 522, 46, 276, 298, 82, 5, 203, 1], [128, 221, 7, 24, 20, 15929, 107, 28, 60, 1418, 82, 3025, 1418, 2054], [128, 31, 42, 259, 125, 97, 77, 8, 42, 58, 2417, 42, 2, 104], [128, 37, 553, 16, 5, 1, 18, 10, 909, 537], [128, 4, 11, 508, 11, 15930, 1621, 75, 110, 806, 4, 4527, 1414, 825, 2363, 555], [128, 80, 2, 490, 54, 158, 177], [128, 7, 32, 15, 114, 272, 192, 2916, 1, 35, 211, 4, 489, 99], [128, 1267, 2533, 91, 56], [128, 1, 12, 15931, 509, 4, 250, 1355, 6, 5092, 383, 94, 71, 171, 5, 15932], [128, 497, 1594, 5, 86, 5, 165, 130, 25, 149, 5, 11, 2133, 5, 15933, 207, 104], [128, 898, 12, 18, 60, 908, 27, 8133, 2594, 3997, 40, 65, 13, 2, 718], [128, 52, 440, 7, 1], [128, 31, 3, 430, 42, 11, 794, 1194, 23, 2613, 242, 80, 1, 30, 35, 4623, 55], [128, 100, 39, 9, 14, 9, 46, 43, 7861, 4714], [128, 65, 51, 39, 9], [128, 786, 5417, 35], [128, 2279, 186, 226, 12, 24, 201, 15934, 23, 544], [128, 7, 4, 2123, 193, 6, 974, 2, 395, 123, 79, 170, 2, 4587, 2456, 83, 70, 17, 150, 702, 11, 164], [128, 4, 3577, 496, 12, 322, 1772, 40, 363, 142, 13, 2, 3435, 16, 2839, 649, 146, 64, 1391, 4400, 5899, 15935, 7, 12, 1284], [128, 36, 41, 4, 7122, 756, 11, 22, 1], [128, 22, 1, 314, 2117, 8, 40, 191, 17, 2835, 3, 65, 4074], [128, 22, 1, 86, 40, 2751, 27, 60, 1486, 6442], [128, 22, 83], [128, 3985, 30, 1], [128, 963, 30, 992, 271, 214, 70, 165, 451, 88, 141, 83, 28, 18, 4, 249, 10, 138, 1304], [128, 3997, 20, 530, 1], [128, 128, 604, 105, 14, 3570, 5, 104, 1043, 83], [128, 12, 1127, 24, 15936], [128, 4303, 65, 13, 4, 215, 1211, 15937, 54, 22, 83], [128, 5, 25, 8134, 15938, 59, 9, 615, 33, 72, 393, 18, 1610, 70, 15, 501, 205], [128, 357, 656, 2, 331, 2693, 130, 2, 25, 772, 60, 285], [1522, 3, 96, 150, 137, 133, 22, 282], [15939, 39, 9], [695, 89, 1, 63, 3, 167, 7, 463, 1141, 15940, 89, 1, 15941, 15942, 15943, 5, 1141, 15944], [695, 3, 1419, 297, 7, 107, 203, 1, 87, 64, 6, 5647], [695, 174, 2, 1, 21, 48, 253, 108, 26], [695, 321, 70, 2, 323, 79, 3373, 8, 4, 1553, 63, 14, 7, 3373, 70, 7, 24, 631], [695, 15945, 49, 42, 6, 2689, 57, 2, 414, 255, 18, 50, 995, 1, 3, 90, 1, 7, 255, 8135], [695, 91, 22, 1, 86, 40, 37, 15946], [695, 242, 35, 9], [695, 1458, 3143, 15, 15947, 106, 6, 7, 1, 768], [695, 42, 2, 8136, 136, 132, 15948, 30, 1], [695, 66, 47, 854, 22, 199, 2917, 215, 213, 5469, 12, 56, 280, 23, 328], [805, 40, 2, 718, 31, 40, 63, 458, 2, 4364, 16, 4449, 123, 1227], [805, 576, 91, 80, 67, 11, 42, 686, 280, 55, 8137, 570, 95, 1101], [805, 25, 121, 2, 15949, 15, 3945, 391, 47, 11, 4, 2015], [805, 304, 37, 85, 326, 2462, 133, 1092, 353, 3, 346, 15], [1140, 84, 746, 415, 41, 4, 24, 7, 264, 26], [1140, 839, 7, 77, 1189, 155, 25, 7, 122, 6, 2661, 8, 357, 121, 993, 5, 88, 6206], [1140, 336, 23, 142, 135, 227, 35, 1533, 48, 152, 442, 22, 34, 14, 2, 1, 11, 5481, 14, 2, 1], [1140, 53, 2, 95, 11, 4, 402, 12, 783, 268, 11, 4, 15950, 53], [1140, 375, 38, 78, 1, 220, 15951, 2847, 859, 224, 22, 106, 215, 213], [2516, 1, 14, 13, 575, 7599, 171, 30, 25], [2516, 23, 459, 135, 1364, 4055, 65, 13, 2, 664, 2025, 781], [2560, 439, 7, 1, 1692, 51, 2, 1012, 2149, 10, 1535], [2560, 410, 5460, 14, 248, 380, 15952, 12, 56, 6, 932], [2560, 2653, 109, 12, 2, 180, 1339, 83, 52, 203, 73, 385], [2560, 161, 3917, 5, 2, 9, 21, 7], [5900, 5, 1025, 35, 2, 104, 210, 5, 10, 25, 46, 28, 1092, 371, 3, 47, 2, 4839, 340], [5900, 1476, 4, 2745, 459, 307, 19, 329, 27, 876, 23, 697, 13, 1647, 24], [5900, 15953, 700, 417, 73, 45, 51, 4538, 615, 1522, 203, 83], [425, 203, 9, 11, 926, 754, 14, 541, 13, 2, 470, 458, 63, 16, 5878], [425, 119, 24, 16, 57, 3, 109, 67, 10, 15954, 102, 15, 11, 4, 193], [425, 4, 154, 1648, 44, 1159, 2783, 360, 1957, 2003, 8138, 247, 16, 15955], [425, 3, 101, 987, 6, 15956, 11, 5517, 140, 38, 7204, 72, 987, 5, 987, 1], [425, 32, 1, 12, 9, 88], [425, 1, 41, 50, 45, 728], [425, 34, 53, 66, 29, 81, 53, 3943, 1, 3, 380, 15, 26, 3, 47, 117], [425, 15957, 1, 14, 13, 647, 513, 107, 18, 11], [425, 9], [425, 25, 47, 61, 3191, 18, 4, 56, 63, 11, 3319], [425, 43, 5, 210, 41, 342, 154, 830, 8, 32, 34, 40, 99, 206, 21, 207, 1372], [425, 7321, 5, 724, 5, 47, 15958, 139, 90, 282], [425, 22, 12, 60, 344, 35, 144, 45, 35, 11, 135], [425, 42, 8139, 7774, 1297, 27, 2, 1769, 541, 30, 368, 3, 90, 158, 571, 192, 81, 6, 120, 8140], [425, 194, 15959, 4490, 27, 2528, 218, 2948, 398, 105, 297, 15, 2534], [8141, 241, 3, 15960, 262, 15, 6, 42, 92, 3, 273, 42, 6, 262, 17, 57, 3, 87, 6, 303, 21, 4, 2107, 2, 1, 807], [1614, 25, 25, 80, 767, 65, 13, 2, 5435, 1, 285], [1614, 22, 1, 167, 10, 347, 8, 79, 4, 670, 8, 72, 15, 47, 10, 1791, 171, 1], [1614, 268, 89, 1, 134, 17, 235, 51, 4, 199, 1301, 8142, 55, 26], [1667, 3610, 260, 779, 2788, 7, 1, 931], [2642, 75, 302, 2, 1, 7, 29, 872, 27, 50, 5366], [4711, 23, 37, 721, 10, 2279, 46, 32, 129, 186, 8, 798, 238, 14, 2, 1303, 3950, 9], [4711, 15961, 135, 107, 80, 1, 30, 15962], [7710, 280, 1740, 18, 186, 81, 59, 71, 209, 169, 36, 216, 1146, 13, 1, 3, 103, 1505, 5], [2163, 22, 1, 35, 27, 5901, 1457], [1020, 473, 203, 1, 11, 378, 712, 21, 473, 115, 27, 33, 473, 15963, 92, 7, 4327, 178], [2489, 102, 158], [55, 53, 4, 832, 1, 14, 1202, 883, 163, 15964], [55, 410, 7371, 1004, 59, 98, 2271, 9, 73, 358, 73, 40, 48, 19, 10, 720, 87, 6, 683, 71, 6, 453, 20, 3023], [55, 410, 17, 244, 106, 1], [55, 1544, 136, 1, 3949, 2696, 1289, 18, 943, 11, 22, 68, 496], [55, 3, 253, 4, 1, 33, 37, 3, 63, 753, 50, 149, 40, 533, 45, 45, 423, 27, 50, 268], [55, 3, 64, 38, 574, 86, 272, 19, 65, 423, 13, 2, 24, 38, 3, 430, 76, 1442, 51, 17, 128, 65, 423, 9], [55, 3, 70, 9, 4592, 15965, 26, 1707], [55, 3, 105, 2467, 144, 69, 168, 4, 15966, 8, 389, 2, 8143, 4334, 6, 28, 5902, 8, 157, 15, 11, 1069, 37, 4, 29, 389, 4, 1789, 1990, 2129], [55, 3, 94, 57, 5, 200, 116, 286, 221, 1, 90, 7, 45], [55, 3, 273, 8144, 1214, 3, 47, 61, 6, 139, 3864, 8, 52, 15967, 11, 10, 231, 13, 1, 42, 29, 110, 62, 17], [55, 3, 273, 10, 646, 571, 93, 8145, 77, 52, 121, 336, 42, 2, 8146, 9, 695, 37, 15968, 69, 72, 45, 13, 147, 52, 196, 483], [55, 15, 46, 1573, 329, 125, 2250, 6, 14, 378, 16, 143, 4855, 153, 163, 143, 620, 205], [55, 1325, 3, 396, 10, 518, 18, 76, 15969], [55, 1103, 2, 812, 92, 7, 1641, 12, 108, 72, 3394, 6, 1201, 15970, 15, 1103, 2485, 3448], [55, 153, 5187, 178, 41, 1709, 209, 15971, 153, 784, 6, 143, 1333, 6, 303, 667, 3010], [55, 4078, 87, 6, 62, 57, 7, 24, 13, 37, 68, 106, 12, 595, 27, 986], [55, 15972, 41, 25, 34, 3, 29, 41, 1], [55, 247, 418, 7, 61, 6, 15973, 49, 9, 74, 15974, 9], [55, 1620, 121, 15975, 15976, 12, 2, 9], [55, 428, 1, 333, 955, 18, 10, 8147], [55, 51, 1, 86, 1264, 12, 4, 697, 91, 140, 52, 458, 4, 347, 676, 21, 84, 8148, 5, 1, 29, 62, 369, 78, 15977], [55, 51, 4, 1107, 15978, 15979, 1274, 24, 1750, 1141, 51, 15980, 1146], [55, 51, 39, 1391, 81, 56, 23, 328, 27, 22, 45], [55, 51, 22, 1, 30, 177, 113, 17, 71, 6, 2182, 6, 8149, 8150, 21, 1884, 16, 8149, 8150, 7, 1805, 14, 79, 2, 3093], [55, 1], [55, 1, 42, 2, 136, 132], [55, 1, 5, 86, 20, 1677, 4, 19, 182], [55, 1, 14, 625, 214, 59, 36, 500, 13, 85, 75, 5, 14, 228, 8, 627, 59, 4, 722], [55, 207, 1372, 137, 897], [55, 147, 1, 1949], [55, 104, 412, 1952, 15981], [55, 286, 576, 19, 147, 68, 2246, 32, 2246, 1, 68, 223, 28, 929, 88, 4, 763, 223, 28, 929, 364, 54, 128], [55, 2071, 4676], [55, 23, 54, 135, 1189, 1, 13, 23, 1041], [55, 15, 15982, 8, 1, 49, 54, 135, 15983, 551], [55, 15984, 7, 85, 3, 46, 19, 27, 7557, 3, 105, 131, 14, 3354, 2, 4580], [55, 164, 216, 50, 2, 9], [55, 65, 12, 1480, 524, 1610, 65, 51, 4, 56, 52, 2171, 59, 1522, 8151, 1055, 10, 30], [55, 10, 646, 2, 181, 2683], [55, 10, 646, 33, 121, 52, 2, 24, 30, 4603, 219, 11, 4, 324, 16, 15985, 3, 710, 147, 695, 338, 42, 505, 54, 135], [55, 10, 1202, 226, 12, 2291, 5488, 369, 693, 3, 146, 44, 147, 1, 30, 226], [55, 153, 375, 4, 15986, 1453], [55, 25, 54, 135, 492, 9], [55, 25, 96, 14, 81, 59, 17, 1014, 1, 251], [55, 1949, 30, 15987, 2, 9], [55, 1619, 51, 2646, 502, 17, 50, 518, 281, 3, 313, 1118, 45, 11, 56, 619], [55, 139, 172, 125, 384, 942, 19, 78, 9, 32, 78, 58, 12, 308], [55, 7, 60, 9, 45], [55, 36, 843, 153, 440, 163, 117], [55, 22, 1554, 121, 85, 472, 35, 73, 2, 260, 7, 37, 144, 3, 121, 219, 3, 196, 42, 208, 13, 2, 260, 37, 318, 73, 219, 472, 13, 68], [55, 22, 77, 70, 501, 16, 189, 21, 44, 13, 480, 768, 34, 23, 33, 13, 1, 20, 768, 12, 13, 6546, 130, 2043, 435, 612, 369], [55, 42, 214, 3289, 9], [55, 38, 2, 25, 72, 52, 346, 42, 72, 29, 346, 17, 346, 97, 1, 128], [55, 20, 2, 187, 3792, 8, 3, 293, 5, 405, 544, 888, 2988], [55, 15988, 15989, 5, 141, 5903], [55, 37, 371, 23, 82, 4, 1658, 3, 1870, 372, 13, 2, 19, 4431, 1292, 71, 59, 19, 5, 185, 809], [55, 57, 3, 65, 13, 304, 18, 246, 25, 83], [649, 417, 6861, 282], [2706, 242, 35, 128, 570, 95, 28, 4, 1329], [3280, 3321, 15990, 310, 33, 79, 170, 144], [5860, 48, 6, 14, 2, 9, 34, 7, 47, 2, 15991, 68], [358, 343, 903, 24, 245, 106, 5, 67, 15], [358, 833, 30, 1, 15992], [358, 1343], [15993, 1], [65, 2, 78, 1631, 1, 541, 13, 2, 2782, 38, 97, 597, 35, 1], [65, 51, 307, 277, 15, 65, 13, 3, 134, 2, 19, 74, 470, 2, 19, 74, 4, 1986, 1752, 16, 2, 1066, 988, 4, 699, 16, 10, 19, 12, 8152], [65, 51, 7, 8153, 24, 429, 21, 15994], [65, 51, 76, 9, 91, 19, 76, 9, 145, 100, 28, 366], [65, 51, 22, 89, 1], [65, 51, 22, 490, 30, 25, 15995, 397, 18, 2, 148, 3316, 65, 224, 21, 84, 15996], [65, 51, 22, 19, 15997, 15998, 101, 2, 158], [65, 51, 22, 141, 711, 53, 113, 50, 40, 681, 73, 209, 73, 5, 2960, 1627, 70, 50, 15999], [65, 51, 22, 24], [65, 51, 78, 1, 101, 2147, 38, 97, 3251, 18, 1], [65, 51, 5, 308, 30, 1, 487, 1056, 261, 1692, 18, 97, 453, 30, 1], [65, 51, 1834, 92, 65, 51, 5904, 32, 10, 25, 65, 24, 73, 19], [65, 1, 233, 61, 8, 249, 2, 138, 23, 2, 112, 606, 153, 3, 46, 125, 147, 3417, 45], [65, 613, 208, 950, 8, 105, 840, 129, 2, 1, 7, 46, 20], [8119, 79, 17, 16000, 79, 17, 2, 171, 16001, 72, 23, 98, 5886, 3169, 34, 66, 16002, 62, 3, 63, 742, 1, 242, 4, 286, 35, 4313], [65, 13, 5, 34, 51, 4, 199, 106, 65, 13, 60, 7528, 1, 74, 1043, 728, 1, 82, 2, 1638, 629], [541, 51, 10, 1, 3, 394, 40, 134, 80, 30, 2, 1006], [541, 51, 42, 9], [541, 21, 20, 1, 40, 415, 27, 17], [541, 13, 2, 966, 1008, 181, 5083], [65, 108, 3, 13, 207, 2058, 100, 61, 108, 6, 7], [65, 3998, 6, 8, 1641, 11, 4, 654, 738, 8, 16, 1134, 16003], [65, 13, 2, 2329, 235, 9, 34, 16004, 7, 3397, 16005, 1790, 833, 205], [65, 73, 31, 16006, 743, 997, 6, 14, 3812, 22, 449, 3044, 26, 293, 4, 8, 1816, 955, 18, 8154], [65, 13, 2, 2502, 34, 12, 168, 73, 2, 6888, 4532], [65, 13, 4, 103, 14, 3426, 27, 21, 4, 1398, 16007, 22, 213], [65, 13, 4, 244, 2801, 558, 6, 14, 3437, 1837, 12, 60, 16008, 226, 16009, 16010, 27, 16011], [1403, 33, 242, 35, 5, 2169, 30, 1, 20, 37, 2933], [1403, 333, 28, 17, 54, 16, 22, 179, 30, 3431], [2061, 1, 1460, 17, 4, 573, 196, 16, 8155, 38, 50, 1277, 605, 50, 2303], [2061, 1, 273, 17, 31, 10, 226, 192, 27, 2, 717, 3, 222, 16012, 340, 1327, 40, 41, 4, 717], [2061, 24, 30, 514, 123, 292, 446, 3, 16013], [320, 16, 10, 1702, 137, 4906, 1080, 137, 641, 4, 1136, 10, 312, 16014, 137, 641, 5831, 8, 10, 77, 16015, 137, 11, 4, 3732, 679], [3404, 12, 270, 2, 161, 1], [64, 2, 1, 290], [64, 203, 9, 163, 926, 754, 163, 5716, 1277, 16016], [64, 28, 677, 82, 10, 1], [64, 44, 1341, 149, 38, 10, 306, 192, 14, 2, 19, 1, 3, 33, 4596, 35, 4, 2879, 1310, 5569], [64, 12, 2, 95, 16, 16017, 267, 5, 21, 7, 323], [64, 10, 1], [64, 38, 4, 1, 114, 1142, 27, 126, 1200, 54, 33, 16018, 35, 21, 7, 169, 565], [64, 5, 127, 130, 212, 1, 5905, 72, 604, 375, 260, 72, 604, 8156, 3, 103, 64, 5, 444, 4, 450, 16, 817], [16019, 8, 90, 8157, 439, 180, 517, 16020], [1886, 9, 34, 7, 199, 1, 66, 157, 4, 1952, 2073, 40, 2482, 138, 7, 4, 199, 1, 5, 134, 1929, 605], [702, 2973, 111, 49, 633, 241, 43, 171, 16021, 849, 2692, 1], [1267, 41, 2, 408, 16, 10, 2667, 1970, 51, 16022, 2534, 52, 10, 145, 92, 55], [1267, 20, 96, 10, 1], [334, 24, 1115, 1426, 165, 130, 4, 1, 7, 132, 433, 3141], [811, 1, 96, 11, 16023], [8158, 121, 7, 84, 1, 89, 219, 588, 65, 165, 11, 245, 1032, 55], [3531, 4278, 12, 270, 2, 104, 2502], [308, 1], [7329, 2990, 1021, 2187, 2864, 16024, 8159, 107, 21, 7, 1, 16025, 4, 4933, 266, 139, 2325], [17, 99, 23, 556, 65, 21, 1118, 16026, 16027, 62, 16028, 133, 2, 2688], [2364, 53, 5362, 3552, 2086, 49, 818, 5310, 16029, 53, 12, 7, 2, 16030], [1012, 50, 38, 42, 19, 27, 284, 1, 45, 13, 22, 582, 647, 150, 89, 21, 802, 177], [10, 2170, 272, 70, 2, 323, 79, 16031, 16032, 8, 15, 16033, 59, 2, 315, 460, 177, 69, 2, 203, 659, 27, 43, 283], [4841, 25, 150, 93, 6, 48, 44, 43, 319, 78, 75, 110, 313, 7, 1338, 10, 193, 43, 2760], [581, 1529, 1, 1984, 479, 31, 3, 113, 50, 99, 40, 134, 17, 169, 32, 80, 9, 134, 5, 12, 764], [16034, 26, 873, 16035, 39, 1, 26, 1955, 10, 873], [6914, 21, 20, 436, 159, 524], [214, 538, 6, 16036, 21, 1813, 6, 255, 2, 232, 2486, 464, 73, 2, 1111, 408, 255, 2, 704, 2486, 415, 2083, 170, 776], [214, 7, 15, 2, 24, 1198, 8, 392, 16, 19, 111], [216, 15, 6, 4, 360, 7349, 4715, 4120, 54, 135, 19, 326, 1, 18, 4, 3886], [216, 68, 16, 10, 32, 106, 443, 65, 13, 2, 1, 18, 4, 16037, 1706, 16, 240, 32], [6408, 8, 22, 206, 837, 49, 1943, 2780], [16038, 5, 249, 51, 56, 2481], [1579, 885, 466, 49, 39, 9, 334], [1082, 16, 15, 12, 56, 2656], [1082, 16, 4, 9, 18, 22, 2046, 16039], [1082, 16, 4, 106, 2, 414, 761, 12, 56, 16040], [70, 10, 2183, 1], [70, 362, 7, 24, 656, 218, 272, 119, 444, 5, 801], [70, 35, 2526, 903, 1112, 35, 21, 506, 24, 74, 710, 8160, 21, 5557, 74, 1607], [70, 20, 250, 1268, 27, 17, 4, 237, 74, 13, 3475, 524, 272, 2055, 7, 1], [5775, 119, 10, 30, 371, 119, 24, 46, 1082, 3883], [1631, 14, 492, 1628, 16, 39, 1, 82, 14, 419], [1631, 492, 5, 9], [70, 348], [70, 35, 898, 16041, 75, 304, 6, 79, 15, 56, 8, 113, 416, 7, 340, 1432, 42, 103, 16042, 14, 4, 2167, 54, 16, 819], [91, 26, 1438, 17, 13, 2, 573, 8161, 118, 44, 3001, 7, 120, 56, 104, 16043], [91, 3, 75, 139, 65, 51, 22, 9, 987, 18, 10, 1126], [91, 3, 58, 44, 9, 8, 36, 49, 32, 11, 4, 199, 3301], [91, 3, 293, 40, 29, 86, 3, 86, 40, 2, 282], [91, 3, 33, 194, 7, 1243, 1691, 16, 315, 1900, 8, 7, 45, 65, 13, 4, 16044, 629, 16, 32, 817, 78, 14, 1617, 35, 56, 18, 135], [91, 3, 516, 94, 4, 561, 1142, 16, 1, 69, 29, 396, 36, 65, 27, 4, 1548, 16, 4, 1147, 88, 94, 4, 16045, 16046, 16047], [91, 3, 300, 225, 13, 1129, 167, 1458, 288, 52, 484, 16048, 22, 1346, 603, 1131, 173, 1566], [91, 3, 299, 7, 16049, 47, 80, 206, 1, 38, 5, 250, 363, 6, 4, 1599, 3, 47, 7, 25, 40, 118, 366, 2047], [91, 3, 301, 22, 1, 118, 33, 411], [91, 23, 515, 16, 799, 27, 39, 9, 34, 10, 138, 48], [91, 23, 1532, 6, 114, 10, 16050, 6, 159, 925, 822, 225, 8, 23, 61, 6, 58, 33, 7], [91, 23, 238, 134, 1830, 3188, 1523, 2, 1180, 34, 22, 45, 56], [91, 1462, 211, 1369, 458, 628, 1149, 16, 2876, 592, 11, 347], [91, 1, 64, 16051, 929, 493], [91, 252, 244, 6, 17, 41, 201, 16, 4, 884, 65, 9, 3, 182, 297, 34, 403, 15, 12, 201], [91, 19, 39, 1, 30, 25, 71, 78, 1042], [91, 16052, 12, 2, 1], [91, 31, 2, 89, 2421, 3759, 418, 18, 16053, 13, 17, 1071, 50, 24, 8, 1087, 54, 1378, 93, 5787, 23, 96, 172], [91, 31, 7, 1, 29, 79, 17, 108, 21, 4, 401, 16054, 16055, 14, 16056], [91, 23, 721, 23, 224, 6, 94, 4, 786, 61, 6, 4, 1408, 1557, 15, 101, 582, 469, 11, 2, 8162], [91, 11, 1172, 2645, 472, 1505, 1689], [91, 15, 60, 89, 1484, 1, 11, 1914, 16057, 31, 42, 75, 255, 2, 4165, 18, 4, 2868, 80, 30, 394, 48, 800, 22], [91, 10, 1, 12, 681, 16058, 16, 16059], [91, 139, 208, 13, 104, 8, 61, 21, 4, 404], [91, 81, 6, 240, 16, 1134, 295, 12, 329, 27, 6633, 31, 5, 13, 56, 4988], [91, 7, 89, 16060, 638, 175, 47, 2, 16061, 1090, 908, 1864, 8, 638, 493, 35, 21, 2, 4924], [91, 7, 25, 5906, 156, 1426, 2, 83, 167, 147, 45, 161, 25], [91, 7, 298, 178, 46, 43, 282, 19, 5907, 29, 110, 87, 84, 1, 30], [91, 116, 2, 320, 16, 203, 1, 135], [91, 39, 1, 49, 37, 723, 3154, 162, 4, 8163, 501, 1060, 1, 51], [91, 39, 9, 37, 4716, 68, 691, 18, 4, 412, 244, 691, 36, 46, 2866], [91, 22, 1, 532, 13, 2113, 767, 741], [91, 69, 143, 19, 100, 22, 9, 11, 4, 2015, 65, 13, 2, 41, 148, 1172], [91, 85, 58, 39, 9, 110, 2361, 255, 754, 38, 374, 61, 54, 13, 760], [91, 85, 4, 2272, 1, 81, 4, 16062], [91, 3, 41, 19, 5908, 98, 1435, 16, 10, 164, 22, 110, 23, 37, 16063, 123, 7, 1], [91, 23, 301, 180, 517, 3910, 118, 168, 60, 166, 5673, 166, 130, 16064, 933, 12, 37, 1413, 8, 16065], [91, 2092, 16066, 12, 2, 2095, 83], [91, 7, 12, 2, 686, 3688, 16067, 16068, 16069], [1151, 31, 325, 153, 79, 17, 378, 1091, 106, 163, 72, 52, 556, 349, 35, 34, 1138, 349, 35], [1151, 369, 3, 597, 35, 65, 51, 143, 1371, 15, 3681, 13, 2, 663, 16070, 184, 2, 153, 363, 6, 2000, 1157, 93, 16071, 1795], [2683, 49, 250, 178, 12, 292, 449, 82, 92, 75, 304, 160, 469, 2, 786, 156, 2, 786, 160], [2683, 7, 24], [16072, 3512, 7780, 47, 2, 16073, 1], [16074, 390, 150, 13, 248], [16075, 39, 9, 46, 334], [3969, 4135, 37, 56], [239, 111, 708, 2529, 699, 12, 92, 1064, 49, 199, 68, 69, 121, 2529, 699, 12, 98, 2469, 21, 4, 5909, 16076], [5308, 712, 1, 16077, 1907], [16078, 41, 37, 239, 9, 40, 1075, 18, 57, 6, 58], [3606, 16079, 37, 148, 248], [3606, 1220, 1642, 18, 4, 16080, 398, 248, 15, 47, 16081], [3606, 12, 11, 22, 9, 16082], [3094, 227, 93, 24, 16083], [3094, 16084, 24, 9, 30, 815], [5910, 8164, 644, 4, 1911, 21, 57, 9, 63, 16085, 11, 5339], [2873, 3999, 679, 795, 35, 2102, 8, 535, 16, 5520], [791, 2, 703, 1, 34, 16086, 125, 2, 834, 812, 40, 41, 667, 180, 1443, 3, 79, 7, 3626, 2, 2490], [1386, 3456, 12, 2, 171, 1, 1892, 136, 2, 401, 492, 4, 620, 73, 16087, 8, 40, 1, 59, 71, 52, 2764, 510, 6, 50, 137], [16088, 16089, 3485, 709, 5911, 236, 16090], [1436, 12, 1115, 1075, 6, 17], [3335, 2031, 351, 146, 9, 313, 170, 60, 517, 230, 84, 8165], [3335, 41, 4, 1691, 18, 1532, 6, 16091, 2, 1], [3088, 12, 356, 601, 34, 4, 590, 9, 18, 116, 87, 6, 28, 762, 4, 19, 54], [600, 4, 95, 16, 5591, 635, 35, 20, 3935, 600, 98, 3387, 16092, 5, 27, 84, 8166, 600, 20, 436, 44, 7862, 42], [485, 12, 207, 1380, 27, 84, 355, 493, 8, 1284, 1715, 81, 43, 4990], [485, 3, 29, 150, 99, 434, 140, 3, 101, 41, 16093, 16, 2791, 362, 15, 48, 215, 264, 874, 16, 851, 26, 353, 1283], [485, 3, 29, 262, 5, 250, 140, 5, 509, 10, 1253, 8, 29, 8167, 888, 83], [485, 3, 1521, 3256, 10, 1081, 16, 10, 685, 3080, 230, 114, 17, 6, 22, 129, 1816, 6973, 18, 4, 2409, 234, 1094, 136, 16094, 1], [485, 151, 64, 5, 68, 115, 485, 219, 16095, 16096, 634, 88, 33, 400, 20, 551, 30, 18, 7, 8168, 282], [485, 23, 33, 60, 1150, 30, 399, 13, 16097], [485, 23, 4, 68, 485, 23, 4, 268, 485, 23, 4, 399, 7, 5, 79, 38, 20, 5706], [485, 31, 5, 2128, 270, 2, 4695, 1, 127, 111, 118, 13, 350], [485, 244, 106, 3, 115, 467, 151, 7957, 15, 54, 27, 10, 1, 1386, 3456, 149], [485, 16098, 34, 5912, 328, 254, 57, 277, 22, 196, 21, 2, 5306, 997, 11, 4, 654, 2755, 21, 494, 111, 11, 4, 654], [485, 5, 198, 119, 1631, 37, 5, 63, 14, 322, 18, 4, 1077, 560, 83], [3816, 12, 2, 24, 52, 101, 404, 1027, 52, 479, 84, 290, 8, 52, 479, 4, 357, 1938, 26], [4717, 5249, 48, 44, 4, 2387, 16, 658, 118, 14, 2, 795, 35, 82, 2567, 16099, 4717, 74, 16100, 16101], [1653, 12, 625, 56, 6, 17, 92], [1653, 1952, 653, 16102, 257, 22, 12, 68, 158, 69, 402, 3, 118, 4718, 7, 71, 5, 799, 27, 16103], [17, 26, 5685, 49, 142, 283], [17, 26, 16104, 511, 18, 8169, 3, 72, 737, 7, 1, 394, 40, 194, 50, 2959], [17, 26, 5599, 1769, 82, 4, 2851, 21, 2, 16105, 235, 2544, 6, 10, 2443, 2369, 1466, 1466, 1451, 2546, 16106], [17, 26, 10, 244, 1, 223, 227, 35, 18, 4, 1698, 8170, 26, 66, 46, 255, 1573, 16, 7, 1953, 385, 7, 45, 339, 483], [17, 8, 4278, 96, 54, 22, 1], [17, 8, 143, 152, 58, 2, 16107, 16, 143, 7933, 101, 325, 106, 52, 152, 14, 3619, 8, 66, 791, 4479, 2175, 718], [17, 8, 10, 180, 802, 815, 1], [17, 8, 10, 1], [17, 8, 10, 1, 323], [17, 8, 10, 774, 2351, 7, 1, 32, 264, 92], [17, 8, 10, 312, 14, 298, 45, 11, 2133, 18, 4, 1605, 66, 101, 514, 68, 178, 11, 292, 115], [17, 8, 10, 399, 271, 1042, 15], [17, 8, 22, 323, 95, 3457, 11, 4, 199, 2940, 4202, 16108], [17, 79, 133, 2, 25, 45, 21, 4, 942, 26, 88, 2, 25, 7, 46, 19, 17, 3, 58, 48, 19, 279], [17, 6628, 1635, 37, 16109, 760, 649], [17, 163, 153, 97, 409, 1161, 7645, 233, 131, 81, 142, 163, 96, 2759, 82, 263], [17, 6, 16110, 17, 368, 140, 3, 29, 62, 71, 6, 168, 3917, 1637, 5256], [17, 38, 617, 122, 6, 107, 21, 307, 422, 9, 431], [307, 5000, 27, 32, 10, 9], [17, 8171, 1061, 267, 5, 21, 70, 17, 2, 89, 1664, 306, 8172, 146, 16111], [17, 2077, 567, 16112, 8173, 16113, 116, 568, 5913], [17, 157, 2, 1717, 1469, 18, 4, 558, 16, 684, 74, 604, 28, 15, 32, 129, 20, 347, 8107, 3309, 1, 1627, 14, 32, 16114], [16115, 853, 1295, 8174, 2717, 8, 6736, 3326, 1324, 8, 5793, 16116, 16117, 163, 1407, 3848, 410, 16118], [3982, 58, 60, 879, 45, 68, 106, 52, 2, 1, 3, 380, 78, 911, 32, 4, 9, 45, 5914, 200, 18, 186, 241, 422], [3982, 4523, 121, 28, 80, 178, 35, 230, 5, 468, 80, 1, 148, 55], [563, 16119, 1455, 16120, 269, 1065], [8175, 4158, 19, 5915, 1, 74, 7880, 52, 103, 48, 313, 10, 91, 4, 3725], [16121, 16122, 12, 1469, 35, 8, 114, 1058, 968, 11, 50, 24, 16123], [3021, 1419, 41, 4, 1, 21, 4, 1398], [2005, 38, 1, 157, 16124, 11, 580, 16, 2049, 5, 48, 1797, 663], [2005, 16, 16125, 4187, 49, 32, 16126, 248], [2530, 696, 570, 95, 2289, 294, 1990, 12, 96, 3190, 66, 44, 1850, 4719, 3301], [844, 415, 65, 13, 2, 3784, 8176, 61, 6352, 4709, 17], [2721, 1503, 1], [2721, 1503, 6, 32, 78, 1, 8, 9], [1208, 12, 86, 16127, 12, 270, 2, 1, 487, 110, 70, 15, 54, 84, 16128, 16129], [1208, 30, 9, 46, 20, 19, 228], [1208, 4996, 1, 3, 118, 1626, 78, 171, 1, 34, 23, 48, 110, 276, 5821, 6, 78, 822], [704, 2, 89, 1, 82, 16130, 10, 1100, 407, 968, 3154], [704, 2, 1797, 1, 51, 16131, 26, 40, 165, 79, 17], [704, 2, 414, 69, 47, 122, 6, 1090, 2, 1170, 2, 2484, 879], [704, 22, 1, 4904, 79, 50, 10, 16132], [663, 29, 279, 59, 794, 265, 1030, 2, 607, 16, 10, 25, 26, 10, 1], [663, 94, 2, 406, 16, 2, 535, 294, 18, 4, 2458, 612, 26, 1787, 15, 8177, 1, 32, 36, 58, 12, 61, 142, 4, 2458], [2125, 16133, 855, 1635, 16134, 2234, 5644, 2, 6925, 2632, 2125, 16135, 693, 2125, 16136, 16137, 16138], [1963, 47, 37, 475, 133, 2356, 1137, 1603, 7, 1, 46, 110, 623, 40, 216, 2, 352, 2050, 27, 2, 791, 91], [16139, 1787, 16140, 53, 336, 16141, 152, 176, 305, 2699], [2133, 1], [2133, 298, 2145, 12, 1285, 1609, 248], [1486, 1620, 14, 311, 3022, 1392, 7, 66, 181, 29, 1642, 11, 1231, 74, 15, 12, 2, 16142, 1201, 21, 8118], [3677, 12, 2, 180, 2853, 4, 9, 18, 186, 8, 610, 70, 33, 15, 16143], [848, 5827, 8, 16144, 287, 49, 3877, 105, 297, 2, 183, 1, 11, 2, 16145, 2348, 182], [318, 303, 20, 1, 2, 558, 22, 696, 552], [1518, 2069, 41, 4, 4586, 323, 11, 4, 489, 2809, 46, 18, 10, 995, 205, 39, 9, 64, 39, 2137], [1518, 2069, 33, 67, 6, 5819, 184, 8, 366, 441, 27, 50, 144, 809], [1518, 2069, 363, 82, 2, 2, 3851, 69, 124, 50, 16146, 229, 6, 2, 1740, 69, 75, 16147, 87, 2, 180, 30, 8, 16148, 8, 40, 103, 14, 147, 1], [1518, 2069, 716, 65, 13, 2, 144, 279, 16149], [1778, 1386, 29, 3844, 6, 5, 183, 9], [1778, 1386, 40, 41, 322, 24, 79, 15, 1106, 149, 2, 25, 976, 11, 64, 27, 254], [937, 831, 1, 491, 2, 236], [937, 16, 25, 63, 5603, 63, 245, 16, 78, 70, 451, 13, 2, 2561, 3037, 48, 33, 5, 8178, 8179, 45, 5, 63, 137, 125, 4, 1], [3856, 354, 5916], [8180, 32, 4, 144, 950, 16150], [346, 581, 145, 2927], [346, 39, 939, 9, 513], [346, 5, 161, 1], [3569, 654, 408, 49, 4, 237, 6, 33, 6185, 15, 37, 2495, 950, 2853, 15, 332, 28, 404, 641, 503, 1727, 16151], [8181, 41, 76, 1008, 181, 128], [8182, 4505, 223, 114, 423, 1349, 31, 52, 671, 970, 9, 223, 14, 2900, 224, 65, 13, 161, 1005, 26, 16152], [8182, 4505, 90, 180, 1187, 16153], [1223, 15, 35, 283], [16154, 216, 2, 413, 19, 2184, 7458, 79, 3207, 77, 16155, 8183, 40, 514, 4, 1414, 16156, 15, 47, 16157, 8, 92, 40, 328], [1263, 1, 11, 4, 1198, 197, 18, 36, 1023, 34, 15, 29, 196, 295, 218, 36, 96, 276, 303, 60, 815], [5066, 115, 3851, 81, 59, 4, 199, 45, 992, 81, 59, 16158], [1361, 8, 16159, 87, 4, 1289, 37, 2373, 3, 2631, 416, 499, 12, 102, 6, 6645, 3, 487, 28, 106, 102, 37, 403, 236, 16160], [1361, 70, 1, 284], [1361, 7, 1, 5, 64, 38, 40, 107, 34, 90, 38, 40, 16161], [306, 33, 79, 17, 2, 1395, 30, 9], [306, 109, 510, 11, 8, 592, 393, 1756, 6, 1, 59], [306, 121, 3, 487, 44, 1018, 1778, 722, 4124, 37, 3, 929, 7, 1, 11, 4, 24], [306, 814, 132, 2, 112, 1, 713], [306, 8184, 2, 323, 59, 60, 189, 27, 1, 8, 2, 358, 256, 74, 166, 37, 52, 222, 19, 4, 360, 21, 5799, 755, 74, 16162, 4370], [734, 156, 273, 17, 3, 47, 284, 195, 4, 9, 72, 23, 1455, 34, 3, 29, 477, 6, 2, 462], [734, 156, 273, 17, 3, 47, 284, 8, 4, 9, 72, 23, 1455, 34, 3, 29, 477, 6, 2, 462], [3646, 121, 43, 24, 534, 1077, 10, 797, 331], [306, 12, 2, 16163, 974, 68, 439, 78, 1, 49, 56, 26], [1147, 13, 1445, 1], [169, 3453, 4, 237, 24], [169, 46, 2, 1162, 1, 7, 2, 4567, 15, 101, 829, 155, 1, 7, 8185], [169, 75, 303, 5, 64, 37, 3, 29, 389, 21, 43, 24], [169, 317, 70, 17, 243, 68, 5336, 169, 70, 17, 150, 127, 3235, 31, 3991, 3, 63, 28, 24, 14, 544, 30, 291, 205, 1249], [169, 250, 414, 710, 34, 5, 9, 49, 215], [169, 136, 3806, 18, 10, 453, 713, 37, 3, 86, 15, 106, 6, 338, 4, 9, 771, 8, 28, 27, 4, 4212], [169, 807, 9, 36, 63, 105, 28, 2, 5769], [169, 70, 1, 19, 8, 25, 719], [169, 101, 1268, 291, 283], [169, 129, 1, 110, 464, 3, 64, 462], [169, 24, 26, 2964], [169, 9, 347, 8, 754], [269, 94, 269, 58, 109, 3452], [269, 94, 269, 2369], [269, 94, 269, 58, 8186, 16164, 26, 8186, 903, 2169, 8, 5670, 2035, 16, 1021, 818], [6708, 12, 19, 185, 19, 7, 171, 30, 178, 1, 30, 45], [2616, 5917, 455, 154, 16165, 3407, 8, 1658, 16166, 16167, 32, 507, 5, 63, 420, 98, 16168, 6, 8, 14, 3567], [2366, 6, 4, 761, 31, 5, 13, 4, 1316, 151, 322, 209, 58, 393, 5, 113, 17, 6, 2019], [127, 7168, 4377, 82, 4, 440, 71, 63, 5, 2024, 5424, 8, 50, 144], [6396, 14, 2, 141, 83, 5, 171, 83], [561, 3304, 509, 5918, 16, 4, 2372, 56, 12, 223, 8, 43, 68, 62, 162, 15, 363], [561, 56], [247, 1488, 7, 405, 11, 862, 220, 56, 101, 19, 27, 13, 292, 2035, 8, 7, 1581, 4, 16169], [247, 153, 291, 34, 156, 163, 4, 16170], [247, 25, 471, 90, 785, 4, 1], [247, 16, 106, 3, 14, 86, 1, 38, 42, 152, 134, 17, 7, 24], [247, 16, 5, 9, 2159, 8, 722, 34, 116, 136, 6, 14, 217, 36, 49, 2159, 5365, 8, 6, 5, 3, 134, 5, 10, 8187], [247, 76, 153, 3, 299, 47, 112, 122, 6, 8188, 17], [247, 39, 1, 46, 112], [639, 905, 90, 4, 232, 8, 1519], [639, 905, 12, 551, 361, 22, 1, 62, 71, 6, 2429], [639, 191, 57, 3, 67, 21, 1503, 22, 1608, 1257, 27, 21, 50, 6, 48, 61, 284, 8, 10, 746, 6, 48, 14, 2, 83], [639, 340, 12, 270, 2, 1], [639, 19, 474, 5, 41, 61, 18, 225, 140, 23, 61, 6, 2977, 11, 2, 607, 755, 83], [16171, 238, 90, 18, 10, 792, 208, 13, 36, 41, 2857, 16172, 35, 5661, 286, 336, 1, 177], [420, 136, 132, 2, 1, 22, 696], [420, 12, 156, 2, 812, 23, 1110, 21, 2118, 1168], [1826, 970, 26, 16173, 3332, 333, 609, 245, 1797, 2551, 8, 1841, 20, 508, 701, 18, 305, 1205, 1453], [16174, 28, 43, 24, 42, 2, 16175], [5818, 1961, 46, 43, 282, 36, 172, 16176, 35], [3177, 132, 16177, 17, 18, 22, 1, 1000], [2776, 1279, 27, 17, 174, 14, 2, 2076, 16178, 187, 8, 5, 4680, 799, 27, 4, 488, 23, 16179], [2776, 273, 17, 59, 7, 189, 82, 68, 2634, 16180, 18, 4, 16181, 579, 3, 47, 13, 37, 577, 4, 187, 16182, 2, 214, 16183], [4289, 18, 16184, 353, 26, 1470, 2327, 5919, 16185, 371, 2327, 26, 3, 745, 124, 2, 184, 11, 129, 1313, 1164], [3474, 2321, 6, 7, 45], [3474, 2321], [451, 6933, 70, 17, 549, 1], [451, 12, 4, 101, 1, 3, 157, 35, 27], [451, 372, 2, 937, 106, 165, 11, 10, 347, 3, 64, 44, 2, 1341, 8, 154, 16186, 15, 13, 2, 1951, 3555, 11, 22, 83], [456, 44, 132, 2, 480, 682, 9, 425, 369, 40, 196, 483, 52, 407, 542, 321, 1028, 26], [16187, 100, 384, 144, 54, 6, 522, 16188, 68, 33, 795, 18, 10, 2137, 11, 143, 16189, 78, 62, 48, 6, 795, 18, 2, 25, 845], [3765, 15, 282], [3765, 1982, 8, 8189, 8, 8189, 251], [8190, 2380, 1450, 27, 977, 935, 592, 18, 234, 16, 1540, 11, 5920, 527, 4663, 2362, 977, 935, 440, 6, 309], [10, 16190, 168, 6, 294, 4, 3868, 16191, 37, 4, 193, 3, 94, 15, 7, 1, 29, 44, 43, 507, 6, 122, 26, 113, 17, 369, 3, 198, 26, 982, 58], [10, 862, 72, 12, 1, 61, 28, 80, 25, 9, 218, 23, 152, 257, 80, 30, 33, 13, 195, 152, 257, 25, 1, 61, 28, 80, 25], [10, 2554, 16192, 192, 225, 41, 24, 25, 2061, 35, 250, 16193, 3788, 717, 311, 5921], [10, 6333, 299, 16, 4, 115, 43, 7466, 21, 1433, 1072, 182], [10, 610, 12, 14, 2, 1, 8, 113, 17, 3, 75, 253, 22, 395, 19, 22], [10, 610, 323, 46, 133, 17, 7802, 406, 15, 59, 71, 9, 48, 1166, 6, 448, 406, 16, 17, 8, 3, 46, 448, 553, 16, 76], [10, 161, 1081, 132, 1020, 35, 21, 201, 213, 21, 257, 2, 1, 2047, 4248, 1857], [10, 3020, 16194, 48, 202, 16195, 3020, 228, 121, 158, 510, 82, 16196, 49, 37, 16197, 1318, 1566], [10, 1767, 16198, 3689, 4, 154, 1351, 16, 351, 16199], [10, 16200, 8115, 1925, 107, 2199, 23, 134, 54, 351, 1420, 37, 39, 1, 63, 62, 57, 314, 2561, 16201, 150, 2226], [10, 573, 164, 1510, 107, 18, 790, 18, 390, 51, 16202, 4257, 817, 573, 164, 3, 131, 14, 2, 2986], [10, 186, 2565, 12, 4641, 248], [10, 2068, 16, 4, 115, 31, 20, 2, 16203, 19, 20, 653], [10, 3158, 2670, 198, 14, 7490, 1275, 55, 597, 80, 30, 35, 8, 28, 22, 169, 1], [10, 16204, 27, 40, 4, 832, 120, 77, 12, 1749, 16205, 16206, 27, 40, 56, 12, 3134, 40, 16207], [10, 1034, 5347, 110, 388, 90, 307], [10, 2092, 121, 23, 3643, 19, 5, 9], [10, 8191, 1675, 70, 17, 372, 37, 1793], [10, 260, 16208, 40, 12, 2, 413, 46, 45, 1, 11, 4, 16209, 370, 30, 16210, 7, 50, 101, 16211, 96, 64, 5, 205], [10, 260, 177, 1922, 27, 10, 269, 7, 3, 124, 371, 3, 47, 141, 3, 64, 10, 386, 37, 209], [10, 260, 1802, 1072, 12, 37, 342], [10, 89, 4243, 7, 80, 9], [10, 1758, 7, 47, 59, 85, 1, 208, 13, 3, 75, 509, 74, 13, 324, 29, 44, 2, 5922], [10, 482, 121, 42, 1, 194, 78, 476, 128], [10, 3986, 48, 1426, 2404, 6, 311, 10, 343, 1157, 109, 3035, 17, 82, 784, 6, 4, 489, 8, 525, 214, 1, 340, 52, 1632, 17, 292, 351, 311], [10, 237, 228, 64, 1748, 4309, 57, 2, 181], [10, 237, 228, 72, 3, 29, 87, 6, 14, 11, 64, 117, 92, 749, 52, 86, 15, 99, 738, 6, 64, 16212], [10, 2781, 12, 4, 796, 1, 3, 1507, 7, 85, 66, 49, 237, 228, 649], [10, 1214, 64, 4444, 299, 52, 318, 934, 4, 215, 175], [10, 95, 41, 2, 4992], [10, 1], [10, 1, 8192, 861, 11, 8193], [10, 1, 30, 1492, 16213], [10, 1, 30, 13, 98, 5340, 2522, 40, 2312, 10, 16214], [10, 1, 89], [10, 1, 89, 13, 3574, 34, 3, 301, 3, 124, 3574], [10, 1, 89, 541, 13, 2, 558, 16, 3894], [10, 1, 89, 864, 80, 1, 41, 89, 995], [10, 1, 89, 40, 82, 4, 16215], [10, 1, 16216, 132, 1427, 93, 2156, 36, 6690, 50, 379, 5342], [10, 1, 63, 14, 393, 1030, 1696], [10, 1, 587, 48, 1696, 5, 487, 19, 10, 215, 1], [10, 1, 587, 48, 5923, 5, 487, 19, 10, 215, 1], [10, 1, 2342, 124, 50, 7711, 389, 4, 5626], [10, 1, 82, 1579, 620, 40, 1448, 30, 26, 815], [10, 1, 28, 18, 10, 1203], [10, 1, 146, 14, 73, 635, 73, 17, 31, 48, 4720], [10, 1, 24, 41, 625, 863], [10, 1, 24, 16217, 15, 114, 22, 138, 8, 869, 10, 961], [10, 1, 72, 23, 11, 4, 381, 331, 19, 5, 196], [10, 1, 72, 23, 11, 4, 381, 331, 19, 5, 196], [10, 1, 47, 37, 2163, 215, 264], [10, 1, 1159, 16218, 21, 307, 267], [10, 1, 197, 21, 8095, 4518, 8, 40, 72, 22, 12, 48, 112, 340, 53, 6, 492, 2, 164, 53], [10, 1, 49, 1342, 26, 36, 49, 16219, 16220, 26], [10, 1, 656], [10, 1, 28, 76, 2524, 25], [10, 1, 48, 5923, 1049, 169, 3, 41, 254, 97, 77, 67, 17, 40, 276, 28, 19, 46, 43, 3248], [10, 1, 429, 7, 16221, 7, 2343, 8, 429, 1515], [10, 202, 1235, 2328, 10, 16222, 5, 247, 314, 21, 22, 3020, 1235, 3, 191, 5, 16223, 67, 6, 14, 165, 27, 50], [10, 759, 1736, 16224, 579, 97, 1, 665, 17, 13, 137, 16225], [10, 177, 41, 4, 9, 92], [10, 520, 12, 270, 2, 1220, 30, 1, 194, 630, 5, 255, 4, 1286, 34, 3, 19, 16226, 980, 4356], [10, 646, 317, 62, 57, 732, 4528, 761, 12, 1, 5, 564, 30, 19], [10, 646, 12, 2, 19, 285], [10, 646, 3430, 23, 137, 52, 176, 157, 4, 5519, 18, 1973, 948, 125, 17, 151, 421, 15, 26, 66, 103, 32, 14, 11, 22, 1, 1276, 5842], [10, 646, 500, 47, 2, 203, 4119, 91, 3, 300, 22, 12, 4, 540, 85, 52, 317, 44, 245, 169, 74, 393, 117, 92, 15, 149, 16, 7, 120, 9], [10, 347, 37, 631, 10, 1, 37, 631, 38, 3, 484, 3, 347, 2340], [10, 534, 12, 290, 4, 606, 534, 1281, 539, 4, 1178, 11, 10, 3220, 57, 4, 2384], [10, 534, 33, 694, 18, 17, 8, 121, 2231, 61, 298, 2, 178, 16, 1850, 368], [10, 534, 2, 1, 4581], [10, 16227, 291, 30, 3455, 3, 124, 60, 1711, 3796, 34, 66, 46, 44, 43, 16228, 43, 2771, 2766, 3, 157, 16229, 18, 76, 283], [10, 754, 49, 156, 8194, 1719, 13, 23, 16230, 8, 3, 137, 2, 1, 13, 8195, 114, 50, 21, 2, 498, 11, 10, 16231, 160], [10, 1081, 1618, 18, 50, 610, 8196, 682, 991, 682, 524, 682, 1, 2661, 51, 986, 40, 356, 73, 286], [10, 1081, 33, 121, 39, 9, 46, 385, 552, 85, 36, 67, 307, 3, 46, 45, 2164, 41, 17, 309, 129, 135, 55], [10, 586, 568, 386, 16, 2, 1, 8, 33, 480, 2, 2390, 11, 4, 16232, 241], [10, 586, 12, 2, 83], [10, 586, 12, 270, 2, 1], [10, 586, 33, 121, 16233, 47, 156, 4, 796, 24, 16, 32, 292, 16, 4, 265, 23, 370, 6575, 6241, 20, 33, 2, 887, 3, 64, 10, 586, 425], [10, 586, 33, 273, 725, 586, 6, 262, 68, 16, 126, 228, 8, 72, 2039, 285, 1292, 23, 328], [10, 586, 81, 59, 10, 381, 16234, 1970, 296, 297, 7, 25, 58, 214, 45, 1211, 1852, 10, 30, 1211, 887], [10, 586, 228, 47, 113, 10, 586, 8, 3, 59, 71, 52, 8127, 60, 93, 24, 215, 16235, 8, 71, 40, 47, 2, 2987, 16236, 15, 47, 2, 112, 16237], [10, 586, 234, 16, 4, 730, 12, 179, 483, 10, 306, 234, 31, 4, 730, 32, 16238, 8, 16239, 281], [10, 797, 273, 17, 15, 2, 456, 3, 14, 22, 1445, 2351, 7, 1, 125, 794], [10, 138, 67, 60, 24], [10, 138, 20, 1, 18, 254], [10, 1998, 390, 12, 270, 2, 2257, 838, 110, 10, 3218, 12, 633, 1724, 40, 132, 135, 371, 16240, 8, 2764, 107, 6, 94, 17, 4925], [10, 1998, 1294, 12, 144, 2086, 1649, 5, 157, 11, 2, 16241, 748, 37, 66, 2055, 254, 134, 263, 2, 79, 31, 5, 87, 2, 16242, 4879], [10, 381, 12, 518, 378, 482, 8, 193, 129, 39, 9], [10, 381, 33, 2916, 50, 645, 6, 16243, 40, 270, 2, 4647, 83], [10, 381, 91, 3, 375, 422, 77, 262, 10, 310, 18, 36, 1662, 1916, 47, 542, 839, 3958, 1, 542, 6, 61], [10, 142, 1, 10, 2672, 3635, 272, 1, 38, 52, 28, 214, 10, 161, 1998], [10, 1438, 41, 180, 73, 1066, 367, 1438, 13, 4, 1187], [10, 1496, 136, 2, 786, 16244, 1586], [10, 500, 33, 67, 2, 540, 6, 1475, 6, 14, 2, 413, 9, 2473, 8, 122, 6, 70, 17, 150, 89, 21, 2, 1088, 82, 2, 16245], [10, 500, 131, 197, 15, 54, 1, 122, 3294], [10, 772, 49, 314, 38, 15, 107, 6, 3991, 10, 441, 10, 24, 10, 16246, 754, 163, 543, 1225, 7, 45, 1551, 14, 3160, 6, 17], [10, 387, 6945, 556, 14, 18, 16247, 3238, 1], [10, 387, 150, 37, 1346, 387], [10, 443, 2152, 3450, 12, 159, 16248], [10, 443, 12, 7, 2, 171, 1, 69, 33, 448, 2, 327, 8, 427, 362, 40, 198, 44, 74, 48], [10, 2325, 144], [10, 1487, 21, 1520, 22, 213, 12, 6, 28, 2, 190, 1092, 155, 178], [10, 1487, 68, 115, 12, 6, 373, 2, 417, 8197, 8, 255, 7, 9, 744], [10, 274, 639, 86, 23, 2, 3119, 140, 40, 136, 217, 194, 10, 175, 425, 43, 97, 177, 656, 73, 2830, 1992, 24], [10, 994, 1014, 54, 32, 16, 10, 16249, 68, 3, 216, 82, 2588, 940, 6, 615, 23, 599, 3731, 7, 32, 10, 197, 11, 4, 248], [10, 2902, 1553, 84, 228, 35, 27, 60, 24, 11, 3570], [10, 343, 12, 68, 16, 2, 698, 37, 29, 182, 1720, 20, 476, 6, 72, 305, 343, 12, 3720, 149, 380, 57, 9, 15, 7539], [10, 343, 12, 248, 3, 87, 6, 157, 2, 16250, 18, 1770, 34, 7, 114, 37, 209, 2548, 7, 3, 29, 2912], [10, 235, 99, 180, 21, 8198, 3, 13, 1493, 165, 769], [10, 314, 261, 87, 6, 276, 8, 313, 2, 689, 6528, 2429, 326, 62, 66, 47, 179, 73, 2384], [10, 2371, 2447, 16, 376, 26, 1411, 59, 1107, 111, 82, 261, 7, 29, 110, 62, 17, 140, 23, 2, 4895, 1], [10, 9, 1070, 55], [10, 9, 64, 6, 61, 16251], [10, 9, 36, 58, 16252], [10, 2067, 41, 2, 9, 518, 18, 331, 1462, 188, 3, 121, 7, 93, 40, 266, 191, 6, 61, 2978], [10, 1391, 10, 5571, 10, 1400, 5571], [10, 331, 12, 37, 864, 392, 267, 274, 39, 141, 2309, 2132, 49, 459, 10, 231], [10, 401, 60, 9, 71, 5, 152, 79, 51, 16253, 81, 133, 107, 6, 197, 51, 885, 16254, 43, 23, 271, 11, 2818], [10, 164, 12, 61, 6, 2, 1, 21, 688, 752, 449], [10, 161, 1, 2, 2001, 40, 72, 40, 87, 2, 381], [10, 161, 1, 33, 79, 17, 121, 40, 1551, 6514, 34, 5, 63, 16255, 218, 1, 23, 1042, 434], [10, 161, 431, 30, 1, 40, 82, 8199], [10, 161, 1081, 14, 7481, 1, 156, 67, 4, 1944, 25, 48, 10, 1791, 2174, 200, 3, 19, 4, 1, 37, 16256], [10, 455, 1, 26, 10, 234, 1, 214, 51, 17, 3, 222, 134, 268, 16257], [10, 455, 1, 8, 10, 234, 1, 214, 51, 17, 3, 222, 134, 268, 16258, 32, 3, 87, 12, 268, 1833], [10, 455, 1, 79, 6, 113, 17, 40, 346, 307, 889, 342, 64, 5, 8200], [10, 455, 1, 12, 2, 2782], [10, 455, 77, 238, 28, 2, 1236, 85, 10, 234, 9, 238, 28, 3242], [10, 455, 8201, 16259, 5924, 8202, 1], [10, 779, 216, 17, 60, 348, 36, 47, 474], [10, 2081, 154, 2057, 335, 4479, 160, 748, 92, 545, 16260, 16261, 16262, 16263, 26, 16264, 5925, 1493], [10, 2081, 12, 144, 321, 156, 191, 4721, 60, 16265, 5926, 25, 12, 5927, 483, 277], [10, 2081, 2, 185, 187, 367, 3, 121, 15], [10, 844, 26, 909, 420, 1026, 483, 370, 31, 23, 2971, 80, 45, 23, 1267, 238, 28, 102, 22, 9, 21, 78], [10, 663, 8203, 3, 346, 22, 9, 91], [10, 306, 1, 99, 209], [10, 306, 210, 303, 17, 354, 40, 317, 64, 17], [10, 306, 12, 2, 187], [10, 306, 12, 37, 16266, 6, 57, 61, 18, 27, 17, 55, 40, 13, 463, 75, 302, 664, 2866, 2840, 425, 16267], [10, 306, 33, 1048, 2, 666, 16, 154, 16268, 26, 88, 1499, 50, 1109, 1574, 92, 15, 13, 360, 1317, 292, 11, 22, 1], [10, 306, 297, 10, 3064, 1193, 26, 47, 13, 37, 369, 12, 35, 125, 22, 340, 1, 369, 58, 5, 48, 94, 76, 1212, 73, 364, 40, 33, 7760], [10, 306, 273, 17, 105, 168, 4, 324, 4503, 15, 10, 443, 324, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187], [10, 306, 67, 6, 303, 2, 1172, 13, 21, 112], [10, 306, 2, 19, 187, 3870], [10, 306, 3984, 646, 152, 107, 974, 10, 306, 26, 79, 50, 2, 1, 26, 10, 1081, 152, 113, 10, 306, 6, 411, 16269], [10, 734, 176, 81, 6, 17, 13, 1, 3356, 23, 18, 1610], [10, 306, 2, 1128, 1, 130, 17, 13, 1035, 3, 75, 397, 7, 282], [10, 639, 110, 1, 84, 1, 30, 1335], [10, 226, 12, 16270, 5, 63, 258, 17, 51, 23, 4, 832, 1, 604, 563, 140, 326, 67, 6, 14, 17], [10, 16271, 28, 37, 180, 188, 40, 542, 6, 929, 18, 667, 1, 55], [10, 2233, 14, 549, 38, 3, 597, 2074, 35, 6, 32, 22, 158, 451, 1335], [10, 2233, 90, 17, 218, 3, 366, 441, 8, 1626, 4, 247, 179, 451, 82, 10, 3220], [10, 2509, 1376, 1376, 44, 16272, 387, 16273, 5254, 1380, 15, 48, 126, 1791], [10, 2509, 176, 238, 605, 17, 8, 23, 13, 1, 5, 41, 1527, 253, 4288, 2915], [10, 154, 1, 119, 2, 138, 13, 2, 16274], [10, 154, 1, 5493, 130, 2, 663, 34, 3, 29, 594, 45, 40, 72], [10, 153, 300, 52, 63, 94, 17, 11, 4538, 55], [10, 153, 898, 3130, 178, 12, 32, 89, 55], [10, 153, 1011, 75, 208, 21, 45, 11], [10, 153, 18, 667, 8204, 45, 869, 163, 2, 311, 429, 54, 163, 405, 2, 1], [10, 153, 47, 99, 112, 996, 39, 606, 2071, 16275], [10, 312, 53, 53, 367, 202, 111, 259, 11, 5917, 128, 16276, 143, 45, 54, 17, 99, 53], [10, 312, 4722, 5928, 2, 2944], [10, 312, 132, 81, 133, 57, 52, 152, 14, 21, 923, 371, 5234, 6, 1110], [10, 312, 383, 592, 54, 84, 77, 172, 4998, 312, 37, 52, 563, 35, 125, 325, 8205], [10, 312, 383, 121, 46, 2357, 1128, 913, 2, 203, 1229, 16277, 172, 761], [10, 312, 16278, 424, 17, 54, 21, 60, 127, 16, 7, 93, 206, 154, 2253, 931, 522], [10, 312, 121, 52, 29, 94, 4, 511, 808, 4723, 8, 4521, 16279, 10, 231], [10, 25, 16280, 277, 295, 34, 404, 27, 4, 1, 3290], [10, 25, 79, 203, 1, 16281, 128], [10, 25, 4963, 2, 1, 8, 121, 8206, 387, 49, 37, 681, 36, 3988, 986, 1140, 25, 299, 52, 47, 509, 2, 7939, 3687, 629, 3906], [10, 25, 41, 17, 662, 54, 27, 84, 203, 2070, 1, 251], [10, 25, 8207, 5929, 33, 293, 108, 18, 4, 1], [10, 25, 37, 4673, 34, 84, 1, 110, 8208, 749, 17, 7, 12], [10, 25, 47, 467, 4661, 13, 15, 48, 16282, 341, 55, 1, 467, 591], [10, 145], [10, 145, 3, 1705, 697], [10, 145, 3, 47, 304, 32, 696, 6, 114, 39, 45], [10, 145, 10, 16283], [10, 145, 194, 17, 14, 3262, 634, 473], [10, 25, 1104, 88, 4, 5888, 694, 35, 11, 4, 1, 96, 532, 13, 98, 3989], [10, 399], [10, 399, 17, 905, 1115, 14, 635], [10, 628, 49, 587], [10, 677, 49, 16284], [10, 5930, 82, 3569, 273, 17, 16285, 892, 296, 41, 201, 449, 6, 19, 32, 39, 422, 9, 862, 23, 795, 10, 178, 1452], [10, 310, 208, 144], [10, 310, 12, 679, 108, 18, 1, 43, 127, 16286], [10, 310, 18, 5763, 3197, 3, 96, 146, 28, 6, 4, 190, 821, 55, 55, 1906, 3, 4373, 11, 6844, 55], [10, 2380, 14, 16287, 82, 1042, 384, 8209, 12, 332, 18, 2, 802, 207, 481, 11, 143, 8210, 384, 120, 287, 14, 16288, 38, 115, 67, 1038, 2325, 1720], [10, 8211, 568, 256, 13, 22, 366, 1345, 21, 10, 25, 16289, 21, 4, 1, 8, 981, 1873, 21, 7, 811, 462], [10, 2980, 548, 96, 3055, 1026, 143, 193, 147, 158, 801, 173, 147, 16290, 3, 1559, 13, 3, 14, 51, 143, 3329, 1294, 8, 311, 143, 493], [10, 437, 12, 3, 41, 2, 870, 16291, 2497, 432, 229, 43, 150, 6, 39, 24, 663], [10, 437, 12, 279, 59, 1, 26, 16292], [10, 24, 30, 347, 266, 16293, 15, 626, 16, 4, 16294], [10, 24, 5931, 1368], [10, 24, 578, 13, 4000, 8212], [10, 24, 578, 13, 4000, 8213], [10, 24, 783, 16295], [10, 2522, 38, 2, 1794, 120, 265, 72, 6579, 13, 36, 2, 4938], [10, 3979, 12, 119, 37, 7913, 3, 131, 19, 935, 84, 977], [10, 352, 178, 165, 130, 80, 500, 145], [10, 4485, 266, 14, 129, 43, 106, 37, 11, 4, 196, 106, 23, 58, 57, 3, 44, 6, 61, 6, 28, 8101, 8, 31, 15, 196, 175, 56, 3, 103], [10, 234, 864, 44, 112, 401, 25, 3, 29, 19, 27, 43, 95], [10, 746, 79, 4, 1346, 98, 191, 47, 36, 458, 1335, 40, 860], [10, 746, 12, 2, 83, 10, 2509, 41, 84, 250, 2572, 8, 52, 1582], [10, 746, 12, 270, 2, 1], [10, 746, 12, 270, 2, 1, 6, 17, 38, 40, 29, 28, 50, 193], [10, 746, 121, 10, 795, 306, 12, 2, 838, 2251, 3, 64, 10, 746, 647], [10, 746, 273, 17, 7, 3, 65, 13, 2, 1187, 288, 10, 722, 273, 17, 7, 3, 65, 13, 98, 16296], [10, 746, 1, 7, 40, 136, 261, 740, 13, 3, 29, 19, 35, 9, 51, 577, 5, 652, 35, 1470, 117, 92], [10, 491, 2, 1, 1237, 12, 107], [10, 386, 12, 1079, 8, 96, 136, 1222, 1469, 84, 845, 140, 52, 8214, 32, 4, 106, 11, 1548, 5, 67, 6, 62, 10, 837, 8215], [10, 1855, 505, 13, 2, 1, 8216], [10, 2615, 33, 121, 52, 405, 4270, 6, 389, 102, 4, 215, 16, 84, 1607, 4653, 8, 949, 52, 12, 5932, 25, 42, 33, 405, 4270, 13, 15, 295], [10, 578, 11, 451, 568, 82, 64, 323, 6, 16297, 7, 24, 368, 11, 13, 7279, 8126], [10, 826, 156, 72, 6667, 2, 91, 182, 2362, 84, 436, 288, 168, 3094, 48, 650, 40, 869, 4, 354, 851, 88, 40, 655, 4798], [10, 826, 79, 10, 306, 1027, 3, 47, 119, 11, 521, 188, 2032, 19, 1], [10, 826, 2462, 133, 40, 118, 70, 155, 1526, 61, 6, 143, 1714, 996, 8217, 1, 333, 1734, 16298, 1042, 1158, 148, 1162], [10, 268, 455, 1319, 8, 3], [10, 2000, 3401, 914, 73, 1953, 39, 25, 9, 11, 1953, 754], [10, 413, 1487, 12, 6, 19, 217, 1, 8, 149, 16299, 11, 2, 243, 575], [10, 1319, 3412, 5745, 762, 35, 2883, 7911, 1008, 7, 91, 4, 19, 54], [10, 16300], [10, 1128, 1, 65, 165, 130, 20, 455, 83, 92, 7, 89, 117, 116, 55], [16301, 271, 125, 32, 4, 89, 1], [163, 23, 37, 515, 16, 465, 16302, 452, 58, 15, 21, 42, 2064, 802, 1, 52, 452, 44, 99, 10, 111, 29, 137, 18, 10, 450], [163, 147, 1, 372, 13, 2, 91, 31, 147, 97, 994, 810, 622, 99], [163, 88, 4, 9, 2668, 183, 13, 1, 5, 183, 381, 13, 171, 185, 30, 183, 13], [8047, 167, 4, 16303, 1099, 51, 4, 450, 16, 7, 1], [2808, 5040, 696, 12, 98, 16304, 664, 2368], [2808, 806, 20, 16305], [5452, 3, 592, 980, 7285, 4, 2455], [154, 7012, 3370, 64, 2183, 1391, 5465, 8, 1071, 2, 8218], [1199, 2370, 38, 5, 389, 1997, 5, 49, 389, 21, 474, 5, 1, 59], [1199, 2370, 642, 1159, 4, 1575, 8, 5933, 126, 518, 11, 16306, 139, 27, 4, 908, 330, 8, 16307, 1], [4887, 1658, 12, 56, 1402], [16308, 508, 1645, 28, 212, 508, 3334, 361], [43, 5, 29, 44, 16309, 111, 33, 29, 13, 350, 28, 129, 630, 282], [2327, 871, 215, 449, 55, 65, 51, 4, 16310, 2710, 1125, 897, 2327, 871, 92, 316, 54, 20, 1923], [1710, 399, 3, 29, 62, 71, 5, 53, 16311], [336, 109, 4, 91, 51, 5481, 3290, 25, 41, 1107, 1, 51, 4, 904, 107, 35, 6, 17, 13, 3, 2377, 4, 1814, 22, 12, 284], [336, 5278, 1219, 2381, 598, 431, 34, 278, 516, 303, 60, 692, 27, 7, 169], [336, 3, 857, 146, 258, 17, 2, 1, 6, 484, 17, 224, 11, 10, 792, 288, 23, 551, 6, 22, 5658, 2969, 8219, 2050, 340, 15, 101, 117], [336, 1963, 2, 1], [336, 1, 1232, 1232, 1232, 34, 1, 3802, 218, 1685, 1685, 1685, 83, 5, 171, 73, 1066], [336, 1, 5, 33, 183], [336, 19, 16312, 36, 46, 16313, 17, 16314, 16315, 8220, 30, 956, 5, 56, 51, 4452, 31, 5, 46, 51, 577, 1727], [336, 19, 240, 1150, 1136, 1, 53, 356, 94, 1136, 8, 1450, 408, 28, 1738, 1821], [336, 31, 40, 2151, 1125, 98, 41, 6554, 123, 3312, 25, 5, 16316, 88, 1354, 35, 2, 1774], [336, 33, 80, 9, 40, 33, 7864, 690, 488, 622, 28, 9], [336, 10, 25, 33, 122, 6, 644, 17, 35, 27, 4, 2272, 1, 16, 32, 106, 51, 4, 489, 33, 615, 66, 1239, 46, 228, 43, 127, 797, 369], [336, 153, 3537, 49, 10, 873, 860, 28, 17, 68, 316, 15, 6, 4, 3986, 16317, 51, 1474, 333], [336, 153, 15, 6, 480, 6, 14, 10, 991, 30, 55, 16318, 7159, 7, 20, 260, 406, 55], [336, 16319, 5, 41, 1069, 665, 1069], [336, 39, 9, 706, 291, 205], [336, 194, 4, 9, 7, 383, 525, 19, 192, 3406, 133, 5437, 8221], [336, 66, 96, 562, 32, 4, 1165, 517, 1, 1922, 478, 74, 336], [8222, 15, 16320, 111, 29, 113, 57, 58, 1836, 7, 16321, 4, 857, 16, 57, 66, 49, 122, 6, 229, 26], [927, 1, 134, 17, 2115, 2787], [16322, 1, 29, 81, 6, 7, 9, 27, 136, 1037, 1662, 30], [7511, 8223, 1350, 1518, 16323, 1, 55], [2329, 8224, 343, 1, 23, 8225, 3899], [1129, 2202, 79, 1603, 8226], [905, 38, 2, 1096, 5857, 4338, 81, 56, 59, 246, 1096, 5857, 4338, 5, 165, 616, 11, 2658, 74, 20, 54, 16, 4, 3941], [905, 16324, 12, 681, 16325, 16326, 846, 2510, 16327, 355, 1065, 16328, 906, 11, 7162, 591], [8227, 2424, 8228, 1263, 136, 50, 789, 24, 1624, 123, 2, 16329], [576, 23, 33, 868, 3, 101, 19, 27, 89, 1], [576, 195, 3, 4, 101, 68, 214, 7, 2798, 152, 14, 81, 59, 104, 30, 5743, 654, 32, 449], [576, 1, 3, 46, 3982, 4523], [576, 1, 5, 784, 641, 2, 4521, 55, 1788, 8229], [576, 40, 48, 2, 9, 40, 33, 2, 16330, 77], [6488, 31, 5, 2, 9, 5, 2662, 18, 4, 1352, 8, 48, 10, 148, 16331], [579, 39, 9, 32, 636, 23, 5934, 125, 2, 1079, 3, 46, 81, 133, 2, 743, 23, 81, 150, 15, 11, 97, 5589], [579, 78, 299, 1, 724, 71, 6, 16332], [87, 2, 1, 6, 405, 15, 142, 21, 2, 145], [87, 60, 3344, 24], [8230, 41, 32, 4, 9, 16333, 55], [1161, 302, 2, 1], [105, 361, 103, 3, 157, 37, 209, 173, 2, 575, 650, 4, 1, 428, 157, 127, 4438, 173, 15, 130, 307], [105, 687, 27, 2, 1, 7, 51, 4, 1529, 16, 4, 522, 8132], [105, 132, 2, 1], [105, 316, 39, 9, 6, 10, 331, 149, 39, 1, 81], [105, 200, 13, 7, 1], [105, 1069, 9, 34, 3, 58, 114, 36, 30, 337], [105, 134, 2, 1, 4, 1268, 7, 42, 87, 76], [105, 134, 4, 244, 1, 98, 2746, 6, 5585, 102, 16, 20, 16334], [105, 61, 392, 16335], [105, 176, 16336, 11, 20, 1068, 31, 1, 114, 127, 130, 36, 134, 15, 106, 6, 311, 76, 102], [105, 338, 20, 302, 11, 2, 1], [105, 100, 2, 177, 70, 5, 150, 13, 20, 393, 882, 130, 2, 89, 1], [105, 100, 76, 9, 28, 11, 808, 16, 57, 66, 192], [105, 4570, 147, 399, 168, 186, 11, 10, 310, 361], [105, 780, 27, 2, 9, 7, 363, 6, 865, 650, 3, 210, 62, 50, 215, 226], [105, 157, 777, 433, 39, 9, 149, 32, 16, 39, 9, 344, 590], [105, 297, 2, 24, 52, 210, 2226], [105, 297, 2, 16337, 190, 1200, 5905, 40, 33, 672, 2, 3745, 16338, 8231], [105, 297, 2016, 95, 2715, 444, 225, 55], [105, 297, 80, 1, 34, 3, 394, 3, 222, 19, 50, 18, 4, 250, 115], [105, 114, 2, 1, 162, 5, 271, 105, 176, 197, 162, 5, 973], [105, 113, 2, 1, 7, 3, 64, 50], [105, 113, 2, 1, 57, 42, 35, 8232], [105, 7, 686, 299, 5, 47, 556, 2795, 27, 2, 154, 1], [105, 302, 2, 1, 149, 39, 1, 172, 3721, 72, 5, 62, 2, 1148, 1, 162, 40, 51, 3, 146, 28, 17, 68], [105, 302, 2, 1, 5, 424, 82, 2, 25], [105, 302, 2, 153, 69, 3775, 246, 91, 2973, 233], [105, 227, 10, 108, 18, 4, 95], [105, 103, 66, 14, 98, 16339, 3330, 1], [16340, 137, 17, 21, 185, 140, 23, 750, 82, 1770, 5, 1, 318, 14, 3176, 34, 48, 17], [154, 1586, 198, 14, 190, 27, 2, 875, 16341, 8233, 13, 159, 524, 1586], [154, 830, 1, 14, 669], [154, 1, 330, 8, 15, 4, 710, 1510, 26], [154, 900, 121, 10, 3444, 18, 10, 758, 75, 14, 4428, 37, 3, 207, 76, 9, 27, 2, 5822, 16342], [154, 24, 46, 156, 165], [154, 229, 2347, 11, 5935, 3737, 51, 4645, 159, 18, 5545, 1474, 4943], [154, 229, 2347, 11, 5935, 3737, 51, 4645, 159, 18, 8062, 5936, 8234], [154, 323, 107, 54, 1410, 1173, 7, 9], [154, 7959, 6, 28, 1, 14, 3120, 7669], [154, 959, 70, 20, 2715, 7068, 207, 31, 5, 44, 16343, 2031], [154, 213, 182, 28, 51, 17, 83, 1517], [244, 1461, 104], [244, 1, 3, 1066, 23, 784, 6, 50, 1251, 55], [244, 106, 42, 223, 79, 2, 3422, 2, 16344, 147, 490, 2, 2309, 2132, 16345, 4253], [244, 106, 5, 338, 1579, 56, 11, 10, 1925, 122, 48, 6, 44, 20, 5675, 2290, 18, 980], [153, 11, 10, 706, 3348, 133, 253, 84, 610, 233, 564, 153, 3, 92, 43, 1363, 253, 5, 18, 186, 233], [153, 163, 325, 1, 868, 178, 18, 84, 310], [153, 14, 4001, 9, 36, 105, 223, 429, 233, 251, 188, 700, 105, 223, 563, 50], [153, 14, 90, 18, 10, 153, 4196, 188], [153, 14, 294, 445, 1165, 6, 430, 2, 153, 36, 636, 11, 4, 489], [153, 132, 16346, 17, 5937, 696, 34, 3, 394, 3, 167, 147, 2, 4418, 325, 696, 31, 153, 868], [153, 4101, 384, 8235, 793, 8236, 1338, 54, 16347, 183, 3, 380, 153, 2250, 28, 15, 996, 143, 2368], [153, 28, 2, 607, 831, 8, 192, 137, 39, 2773, 238, 45, 18, 80, 153, 661, 16, 137, 39, 9], [153, 168, 6, 14, 13, 5, 156, 2250, 349, 2, 16348, 153, 3, 87, 588], [417, 1095, 298, 361, 123, 4, 26, 19, 16349], [16350, 16351, 255, 811, 190, 758, 1574, 16352, 160, 16353, 16354, 16355, 7387, 82, 1289, 16356], [1723, 4002, 16357, 439, 2, 16358, 213, 206, 1, 11, 1094, 47, 1463, 6, 14, 1313, 8, 363, 6, 314, 261, 688, 16359], [1704, 16360, 214, 73, 19, 1000, 4589, 1789, 3353, 6, 5804, 21, 4, 1680, 52, 210, 1877, 1704, 34, 204, 5, 541, 30, 1], [1704, 121, 993, 212, 703, 16361, 241], [25, 3, 739, 22, 5776, 13, 15, 4, 250, 115, 11, 4, 401, 8, 4, 1, 129, 4812], [25, 3, 41, 1515, 1872, 1, 11, 4, 16362, 16, 4, 16363], [25, 4003, 18, 294, 544, 12, 2, 1, 251], [25, 2, 391, 233, 3021, 1439, 30, 33, 92, 167, 4270], [25, 14, 2, 344, 8237, 88, 52, 569, 1, 107, 27, 7, 1746, 30, 764, 88, 4, 8237, 45, 568, 54, 4, 4542], [25, 450, 35, 61, 7765, 780, 27, 76, 9, 8, 88, 821, 2, 4, 16364, 16, 16365, 2366, 16, 4, 761, 114, 57, 42, 63, 28], [25, 19, 9, 432, 67, 19, 80, 9, 40, 2, 203, 418, 26, 40, 89, 1484], [25, 19, 562, 46, 553, 16, 7, 45, 784, 142, 27, 80, 25, 5, 25, 86, 5, 150, 1, 10, 25, 5], [25, 5512, 1, 557, 50, 71, 40, 131, 14, 557, 34, 3, 46, 16366], [25, 223, 44, 6, 28, 2, 712, 13, 2, 1], [25, 41, 2110, 16367, 3, 62, 25, 14, 459, 116, 11, 7, 9], [25, 146, 258, 76, 9, 705], [25, 807, 88, 2, 1, 99], [25, 3, 2151, 1851, 31, 5, 407, 11, 4, 2248, 940, 11, 4268, 5, 2, 9], [25, 151, 114, 97, 455, 9, 70, 50, 79, 50, 337, 77, 8, 70, 240, 958, 4, 199, 138], [25, 33, 124, 76, 353, 18, 2, 16368], [25, 1915, 2, 812], [25, 2168, 2076, 12, 2, 1], [25, 800, 4, 247, 56, 45], [25, 121, 438, 12, 24, 16369, 893, 37, 12, 7, 85, 5, 146, 176, 72, 50, 38, 5, 28, 15, 218, 15, 105, 1786, 20], [25, 47, 1513, 13, 2, 2899, 8238, 11, 7, 1], [25, 5, 2, 24, 293, 5, 41, 1079, 4541], [25, 5, 12, 2, 902, 3, 150, 13, 1831, 579, 3055, 2, 24, 35], [25, 5, 216, 15, 25, 66, 216, 6201, 237, 3027, 7, 568, 6, 2, 16370], [25, 622, 1, 216], [25, 22, 1, 12, 626, 307, 433, 17, 4, 866], [2400, 55, 552, 16371, 122, 6, 2788, 326, 107, 18, 786, 16372, 61, 821, 7247, 552, 57, 52, 67, 2042], [145, 145, 145, 29, 442, 17, 33, 16373], [145, 896, 13, 36, 1078, 34, 36, 389, 4, 1], [145, 87, 6, 176, 116, 1, 11, 536], [145, 194, 69, 5, 19, 33, 6, 90, 18, 20, 1], [25, 2, 303, 2, 16374, 1927, 6, 1268, 2, 8239, 1], [25, 896, 13, 9, 247, 16, 240, 1], [25, 46, 334, 16375, 1, 8208, 130, 5], [25, 46, 475, 133, 166, 25, 4259, 125, 765, 319, 25, 475, 16376, 9, 4259, 125, 765, 9], [25, 330, 208, 13, 1, 37, 85, 48, 28, 2, 112, 1, 117, 286, 31, 5, 223, 208, 13, 2, 24, 3, 516, 33, 44, 1155, 385], [25, 49, 2181, 26, 648, 12, 2, 83, 93, 561, 26], [25, 49, 37, 19, 16377, 8, 36, 122, 6, 2055, 15, 54, 123, 72, 2403, 220, 280, 15, 16378, 16379, 5, 2, 104, 321], [25, 51, 4, 4544, 65, 21, 9, 26, 36, 54, 116, 99, 23, 362, 16, 15], [25, 14, 1, 9, 14, 1, 432, 94, 43, 511], [25, 14, 3425, 21, 60, 24, 36, 46, 125, 17], [25, 14, 44, 334, 24, 18, 16380, 8, 96, 14, 640, 73, 1066, 13, 280, 61, 19, 20, 414, 26, 28, 60, 16, 76, 5836, 54, 55], [25, 14, 7546, 4, 247, 339, 16, 1820, 43, 401, 29, 62, 71, 6, 484, 2, 347, 43, 169, 43, 16381, 163, 454, 85, 36, 2257], [25, 14, 11, 36, 150, 38, 36, 258, 54, 126, 9, 172, 246, 25], [25, 14, 13, 38, 36, 94, 36, 234, 1, 16382, 246, 25, 53, 1687, 5390, 16383], [25, 14, 1160, 21, 24, 15, 46, 16384], [25, 14, 37, 16385, 31, 3, 67, 10, 24, 672, 744, 21, 4, 763, 16, 22, 213, 15, 118, 582], [25, 14, 238, 19, 4, 244, 25, 1, 48, 62, 126, 1, 4, 244, 25, 1], [25, 14, 67, 1, 27, 169, 16386, 14, 291, 73, 1751], [25, 75, 397, 17, 218, 36, 1, 14, 1596, 2, 25, 26, 28, 214, 51, 80, 37, 79, 16387], [25, 359, 18, 36, 1, 8, 29, 772, 43, 389, 108, 6958, 78, 33, 73, 6237, 73, 39, 283], [25, 345, 38, 36, 28, 167, 314, 8, 345, 38, 36, 28, 167, 3886, 1593, 392, 16, 24, 92], [25, 655, 165, 1], [25, 1110, 123, 39, 1, 76, 4, 804, 177], [25, 616, 11, 64, 27, 98, 1893, 1, 8, 227, 36, 108, 18, 36, 16388, 15, 431, 1000], [25, 28, 24, 11, 4, 228, 1674], [25, 61, 284, 129, 1, 92, 2, 115, 13, 1954, 80, 243, 30, 142], [25, 2468, 13, 9, 91, 3, 46, 2938, 7, 45], [25, 90, 17, 218, 36, 62, 23, 2, 2551, 6, 76, 26, 36, 1], [25, 12, 1], [25, 12, 9, 8, 11, 112, 164, 5156], [25, 12, 1604, 16389, 31, 5, 41, 2, 437, 27, 97, 91, 1636, 7, 45, 2277, 15, 26, 5605, 2021, 101, 1, 555, 16390], [25, 12, 344, 9, 321, 272, 139, 172, 27, 240], [25, 1976, 4, 199, 25, 36, 2430, 35, 27, 233, 39, 1, 172, 4, 199, 25, 36, 3036, 47, 3929, 2047], [25, 1551, 139, 255, 5491, 7, 21, 1, 55], [25, 101, 28, 19, 35, 101, 18, 696, 8, 3, 28, 19, 35, 1697, 1, 3, 96, 58, 15, 1104, 48, 18, 10, 822], [25, 157, 18, 2675, 8, 208, 13, 1, 21, 800, 7, 45, 3458], [25, 109, 14, 16391, 129, 39, 9, 2422, 2046, 7, 4, 540, 36, 41, 4, 180, 235, 92], [25, 144, 55], [25, 94, 5, 125, 143, 190, 765, 131, 167, 5, 35], [25, 7296, 27, 1, 994, 425, 3088, 365, 483], [25, 2668, 24, 3, 300, 3, 29, 81, 23, 32, 1781], [25, 1049, 8236, 33, 6, 65, 93, 21, 2, 1, 36, 452, 110, 303, 1569, 8240, 2183, 21], [25, 300, 36, 29, 302, 39, 9, 34, 14, 19, 1744, 251], [25, 81, 127, 130, 1, 39, 115], [25, 81, 127, 88, 1, 39, 115], [25, 81, 133, 39, 9, 46, 334, 34, 36, 132, 6, 688, 511, 16392], [25, 7, 119, 16393, 119, 24, 99], [25, 56, 483], [25, 255, 2675, 127, 130, 1, 39, 2124], [25, 69, 397, 11, 493, 21, 1615, 214, 51, 17, 615, 5477, 19, 350, 3, 349, 9, 579, 1985, 461, 240, 18], [25, 69, 81, 59, 24, 4, 247, 28, 4, 577, 57, 2, 1994, 874, 16394, 24], [25, 436, 9, 26, 183, 1, 3, 28, 18, 1126, 33, 6, 1093, 531, 23, 58, 595], [25, 103, 79, 2, 275, 2, 9, 74, 593, 88, 546, 1204, 790, 61, 6, 8, 1887, 129, 2, 1202, 883], [25, 27, 1, 16395], [25, 454, 85, 1, 14, 18, 7, 16396, 2, 25, 1931, 218, 39, 25, 14, 18, 7, 1749, 33, 246, 368, 45], [4724, 359, 149, 663, 156, 86, 36, 525, 137], [638, 132, 70, 56, 5938, 219, 48, 326, 34, 60, 55], [638, 5820, 39, 16397, 6, 756, 89, 133, 2, 836], [638, 800, 1, 30, 638, 34, 266, 800, 2, 112, 25], [264, 283], [264, 158], [1783, 2152, 12, 248], [2830, 1992, 12, 2146, 7, 905, 12, 165, 16398, 12, 237, 60, 16, 78, 9, 14, 7689, 15], [4004, 2, 315, 1], [16399, 23, 109, 611, 7, 3, 29, 44, 602, 228, 6, 182, 14, 79, 1829, 1440, 16, 4707, 2047, 7, 10, 172, 651], [3475, 524, 241, 143, 17, 3475, 524, 18, 78, 319], [16400, 39, 16401, 6631, 16402, 28, 351, 1421, 155, 115, 8, 29, 1011, 385, 560, 105, 134, 263, 245, 3023, 178, 12, 2260], [1357, 1972, 269], [43, 3, 29, 64, 39, 9, 8, 19, 39, 25, 8241], [43, 1, 3, 29, 44, 393, 6, 16403, 3, 33, 29, 13, 111, 65, 539, 10, 16404], [43, 83, 5, 2639, 497], [43, 218, 786, 49, 3239, 1402, 178, 16, 4, 2501, 96, 4, 237, 8124, 11, 1201], [43, 231, 43, 16405, 24, 177], [43, 19, 2096, 59, 4, 1593, 1122, 15, 1519, 658, 1], [43, 77, 43, 9, 33, 17, 531, 8, 3], [43, 3934, 1282, 136, 245, 117, 6, 72, 393, 6, 245, 7545, 182, 8, 198, 14, 204, 21, 58, 2028], [43, 9, 45, 205, 3, 47, 133, 6, 72, 6495, 41, 971, 927, 1, 58, 2417], [43, 3, 29, 373, 4, 24, 3, 33, 4112, 15], [43, 882, 130, 292, 89, 1, 11, 10, 618, 51, 2, 4085], [43, 690, 71, 332, 5, 122, 6, 14, 1395, 16406, 36, 176, 81, 6, 350, 13, 1, 58, 3, 62, 5], [43, 127, 1690, 8242, 43, 127, 610, 8242, 43, 127, 295, 3, 103, 48, 14, 2, 89, 1, 2, 449, 91, 57, 195, 3, 61, 6, 58], [43, 127, 9, 163, 4267], [43, 127, 8243, 43, 127, 382, 8244, 15, 679, 1122, 921], [43, 87, 6, 175, 39, 1, 62, 10, 2161], [43, 25, 2, 338, 2, 418, 27, 60, 93, 24, 650, 52, 33, 1010, 5939], [43, 1294, 3, 407, 551, 484, 3, 47, 3527, 18, 76, 319], [43, 68, 63, 114, 20, 2013, 36, 63, 101, 114, 20, 282], [43, 68, 568, 173, 16407, 6, 547, 1225, 212, 111, 49, 32, 16408, 416, 69, 197, 11, 7, 1194, 12, 1604, 248], [43, 68, 136, 110, 3148, 2, 1347, 11, 13, 16409], [43, 68, 594, 71, 209, 15, 633, 17, 102, 38, 111, 168, 4, 324, 16410], [43, 1205, 4326, 7, 2010, 16411, 3934, 8, 2308, 198, 14, 8245], [43, 492, 9], [43, 352, 1, 3, 101, 67, 4, 833, 1], [43, 16412, 45, 135, 1], [43, 376, 376, 12, 21, 1549], [43, 850, 261, 119, 2, 138, 2119, 23, 328, 27, 20, 1, 30], [43, 267, 462, 5, 65, 13, 5, 33, 41, 102, 4, 120, 56, 1036, 278, 516, 48, 430, 2, 16413], [43, 39, 49, 101, 120, 16414, 219, 58, 5, 44, 245, 664, 2215], [43, 22, 1, 200, 48, 1087, 142, 4, 795, 6, 113, 17, 29, 119, 50, 148, 4433, 364], [43, 22, 141, 689, 1, 200, 48, 33, 122, 6, 114, 17, 6, 16415, 21, 675, 27, 10, 4068, 59, 48, 14, 2, 4923, 16416, 16417], [43, 106, 21, 1, 956], [43, 106, 21, 778, 211, 217, 12, 13, 227, 35, 102, 2289, 2857, 5, 65, 13, 2, 1, 38, 5, 109, 86, 59, 15, 55], [43, 193, 32, 42, 158, 49, 4612, 16, 4, 707], [43, 4985, 317, 16418, 82, 14, 79, 2157, 34, 96, 277, 5349, 16419, 2561, 16, 164, 16420, 16421], [43, 454, 39, 574, 7, 79, 943, 25, 26, 1021, 2404, 6, 2413, 126, 9, 2784, 1179, 59, 435, 13, 17, 11, 305, 8246, 472], [988, 2, 381, 13, 7, 87, 1, 8, 52, 46, 182, 152, 28, 1, 27, 7, 18, 170], [988, 15, 329, 6, 122, 6, 396, 715, 116, 12, 43, 16422, 37, 198, 594, 8, 5091, 13, 36, 49, 715], [988, 40, 152, 400, 364, 142, 26, 262, 50, 7094, 40, 48, 152, 279, 59, 57, 20, 8247], [16423, 48, 114, 980, 16424, 1752, 1515, 70, 10, 2240, 58, 4, 1466], [357, 279, 5, 19, 181, 148, 5, 316, 1, 591, 110, 464, 20, 640, 73, 19], [357, 182, 41, 1303, 123, 14, 2, 1779, 83, 519, 396, 4, 184, 7, 70, 5, 5940, 74, 14, 2, 1545, 16425], [357, 134, 17, 2, 3340, 149, 23, 206, 8, 207, 439], [357, 12, 61, 6, 72, 393, 59, 71, 2770, 3840, 234, 1, 12], [357, 18, 1260, 1681, 127, 1367, 130, 1450, 391], [357, 198, 182, 44, 352, 27, 2, 537, 138, 74, 285, 7, 72, 2, 320, 59, 5, 31, 5, 19, 240, 62, 36, 532, 13, 16426], [357, 125, 17, 23, 18, 32, 771, 45, 37, 29, 86, 23, 896, 356, 38, 23, 11, 10, 1674, 1], [553, 16, 10, 1, 63, 271, 129], [553, 16, 263, 363, 6, 39, 16427, 6269, 37, 220, 1113, 48, 73, 4342, 73, 39, 19, 7629], [16428, 48, 8248, 2179, 8, 1916, 3114, 4, 489, 545, 32, 10, 1, 541, 16429], [1171, 15, 33, 190, 16430], [16431, 214, 73, 2, 1, 3596], [16432, 179, 483, 55, 32, 16, 2, 2547, 416, 2, 6912, 8, 3349, 408], [1359, 568, 18, 114, 54, 4, 56, 22, 817], [48, 2080, 952], [48, 378, 1102, 16, 8110, 82, 245, 16, 39, 16433, 16434, 7788, 6424, 19, 240, 244, 106, 3, 86, 725, 152, 16435, 3945, 1915, 2, 1], [48, 32, 275, 1577, 175, 59, 126, 520, 34, 3, 301, 989, 18, 4, 68, 7, 2019, 515, 16, 5, 8, 170, 1], [48, 32, 344, 435, 160, 3, 195, 16436, 2186, 18, 16437, 494, 617, 29, 44, 4, 3136, 6, 16438], [48, 2, 3060, 11, 3281, 99, 322, 6, 236, 6, 1869], [48, 2, 408, 16, 16439, 380, 23, 4, 16440, 1904, 590, 30, 12, 56, 20, 4, 2733, 16441, 16442], [48, 2, 16443, 1], [48, 2, 324, 18, 377, 3483, 59, 4, 16444, 275, 3396, 16445, 11, 16446, 7, 761, 16447, 126, 16448, 18, 1368, 7940], [48, 59, 6, 137, 39, 178, 27, 22, 1], [48, 1166, 6, 137, 567, 95, 224, 994, 140, 40, 300, 51, 17, 6, 139, 300, 55], [48, 2556, 34, 97, 153], [48, 119, 24, 12, 16449], [48, 110, 787, 8, 289, 330, 366, 54, 201, 823, 83, 3, 58, 57, 4, 19, 3, 2197], [48, 110, 1513, 39, 9], [48, 155, 77, 13, 2, 789, 30, 1217, 30, 3815, 60, 77, 13, 2, 463, 643, 16450, 30, 399], [48, 556, 137, 27, 4, 1, 128], [48, 61, 6, 157, 35, 2, 355, 1805, 821, 18, 10, 1126, 140, 23, 48, 2, 104, 34, 23, 32, 21, 1603, 1805], [48, 33, 1838, 34, 16451, 8, 5941, 6, 184, 36, 943, 16452, 7, 1725, 15, 2, 494, 395, 747, 212, 16453], [48, 10, 1791, 80, 1, 131, 788, 17], [48, 68, 1, 12, 262, 17, 117, 615, 5942, 253, 5117, 1435, 3440, 1973, 1435, 886, 8, 344, 30, 1022, 34, 984, 262, 16454, 272, 204, 531], [48, 1367, 11, 4, 654, 16, 16455, 116, 12, 43, 1293, 16, 494, 535, 1453, 1860, 6, 791, 980, 36, 58, 48, 1899, 44, 6, 58, 2028], [48, 109, 362, 71, 6, 2162, 57, 582, 135, 410, 8249, 712], [48, 362, 85, 118, 279, 59, 8250, 16456, 14, 7, 52, 68, 16, 76, 31, 5, 62, 57, 3, 4629], [48, 362, 85, 217, 118, 157, 10, 406, 18, 2, 4005, 2920, 3, 46, 506, 24], [48, 7, 3, 893, 18, 309, 738, 34, 23, 966, 61, 6, 1053, 16457, 11, 73, 10, 508, 16458, 52, 4, 101, 184, 1595, 16459, 16460, 3, 63, 302], [48, 4, 409, 6, 114, 15, 981, 227, 2, 93, 77, 173, 2, 282], [48, 6, 79, 5, 2, 1, 188, 34, 36, 223, 90, 18, 10, 1], [48, 6, 372, 13, 2, 966, 1, 34, 23, 515, 16, 111, 265, 8, 4, 108, 6, 261, 327, 66, 46, 448, 327, 18, 4, 108, 6, 1197, 115], [48, 56, 33, 3520, 73, 19, 21, 16461, 8, 107, 18, 43, 3387, 2645, 18, 2, 292], [48, 573, 155, 91, 136, 9], [48, 122, 6, 253, 245, 1594, 43, 1248, 188], [48, 97, 994, 348, 3459, 3459], [1895, 4, 3315, 3416, 16462, 82, 7928, 8, 1281, 15, 6, 2, 56, 3806, 230, 16463], [1895, 16464, 12, 4, 206, 2983, 226, 21, 820, 16, 8083, 16465, 48, 98, 4690, 16, 5066, 16466], [295, 93, 18, 886, 8, 4, 49, 119, 126, 466, 292, 4195, 2073, 4344], [295, 12, 99, 16467, 8, 31, 15, 12, 2694, 139, 14, 2, 19, 1, 2936, 119, 127, 16, 15, 3258, 345, 5, 19, 24], [295, 127, 2981, 16468, 408, 130, 6, 1577, 16469, 16470, 16471, 305, 101, 2447, 3273, 371, 3954, 16472, 74, 4574, 788, 16473], [295, 72, 660, 13, 2, 6670, 733, 7, 36, 49, 291, 932, 134, 17, 2, 421, 649], [295, 1128, 130, 2, 260, 1, 285, 61, 635, 2, 16474], [1649, 3, 210, 175, 16475, 3910, 12, 511, 82, 2200, 10, 16476, 8, 15, 16477], [1649, 3, 29, 70, 451, 21, 25, 7, 29, 28, 16478], [92, 3, 195, 94, 6314, 4291, 377, 408, 114, 1789, 21, 98, 16479, 3102, 16, 2, 16480, 11], [92, 3, 222, 72, 10, 226, 16481, 97, 1, 330, 62, 15], [92, 3, 29, 110, 67, 6, 58, 3991, 386, 16, 2, 1], [92, 3, 16482, 82, 25, 3, 29, 302, 25, 7, 46, 3187, 125, 17, 8, 32, 4, 1, 3, 210, 948], [92, 23, 1479, 177, 1619], [92, 23, 477, 6, 161, 1594, 28, 4, 93, 716, 611, 571, 14, 419, 22, 616, 3, 62, 604, 28, 589, 27, 17, 18, 20, 909, 34, 773], [92, 753, 55, 10, 24, 132, 227, 102, 16483, 3, 266, 14, 19, 43, 106, 5287, 1115, 1015], [92, 2, 115, 1956, 118, 516, 14, 112, 125, 2, 1956, 74, 1, 36, 131, 19, 125, 516, 130, 36, 115, 68, 1956, 1737, 305, 979, 12, 3888], [92, 2, 115, 9, 14, 3089, 21, 154, 7202], [92, 2, 2323, 25, 13, 17, 46, 614, 6, 28, 43, 24, 13, 22], [92, 32, 4, 9, 133, 6, 448, 1320, 2602, 514, 34, 23, 96, 4636, 327, 18, 4, 2046], [92, 143, 408, 3409, 78, 153, 204, 17, 46, 175, 45, 32, 148, 178], [92, 29, 5, 90, 76, 16484, 2820, 30, 1928, 16485, 11, 97, 231, 2722, 50, 237, 228, 754], [92, 16486, 377, 49, 157, 54, 1012, 3972, 18, 1938, 3091, 69, 4719, 11, 4, 859, 11], [92, 10, 234, 1, 10, 455, 1, 426, 10, 455, 9, 46, 150, 17, 43, 8251, 43, 8251], [92, 10, 234, 1, 10, 455, 1, 149, 10, 455, 1, 46, 1596, 17, 43, 3901], [92, 153, 266, 2572], [92, 157, 97, 30, 18, 22, 4644, 100, 17, 62, 5, 7, 832, 1722, 83], [92, 7, 1704, 1992, 121, 993, 703, 952, 194, 32, 39, 203, 1, 107, 459, 43, 162, 15, 106, 6, 2833], [92, 7, 71, 5, 100, 4, 257, 1478, 1, 233, 7, 10, 16487, 73, 3, 167, 4, 204, 16488], [92, 4, 1, 1532, 6, 58, 5438, 99, 3110, 400, 4540, 30, 142], [92, 36, 359, 1, 78, 2145, 611, 73, 4, 19, 36, 59, 6, 359], [92, 22, 154, 1, 208, 171, 238, 1675, 10, 155, 2392], [92, 38, 3, 157, 22, 24, 18, 16489, 40, 394, 48, 14, 137], [92, 20, 467, 634, 20, 16490, 150, 17, 38, 5, 28, 2, 595, 83], [92, 4, 377, 1848, 597, 35, 26, 708, 2099, 3033, 268, 2185, 565, 142, 26, 378, 3091, 16491], [16492, 115, 4, 16493, 16, 2, 89, 1, 12, 71, 93, 50, 24, 12], [7430, 14, 6, 2065, 27, 4, 8252, 13, 4, 75, 558, 1], [4457, 1158, 96, 16494, 23, 101, 2, 9, 18, 186, 482], [16495, 975, 7, 24], [16496, 16497, 8, 682, 2454, 4, 215, 16, 4, 93, 4129, 1202, 283], [2730, 206, 231, 7473, 27, 2, 379, 9], [2730, 64, 99, 94, 2, 1290, 153, 107, 35], [241, 43, 49, 5, 72, 4, 1033, 514, 4, 946, 128, 8253, 235], [16498, 72, 10, 853, 5659, 715, 12, 1823, 565, 82, 12, 7, 15], [5185, 399], [526, 23, 314, 73, 2, 1], [526, 183, 711, 20, 2, 89, 5373, 5, 198, 204, 630, 13, 3429, 2594], [526, 44, 78, 182, 704, 2, 391, 69, 210, 44, 2, 265], [526, 295, 11, 164, 136, 216, 17, 16499, 130, 993, 17, 27, 20, 158, 5943], [526, 38, 80, 234, 1, 258, 4, 2006, 5, 1048, 21, 97, 77, 26, 4504], [526, 22, 1, 18, 4, 16500, 266, 411, 330], [16501, 3, 47, 313, 828, 1149, 18, 606, 8, 1087, 51, 551, 1859, 111, 6, 139, 2995, 4, 16502], [16503, 25, 121, 4705, 188, 202, 83], [962, 3281, 1, 3, 394, 48, 94, 5, 11, 4, 606, 56, 30, 25], [7124, 153, 324, 6, 4, 25, 69, 137, 847], [642, 382, 4, 1101, 3352, 4079, 2301, 382, 4, 2848, 58, 97, 94, 2, 4617, 1033], [642, 4060, 1525, 8254, 377, 136, 1827, 6, 2769, 11, 2810], [642, 3428, 1387, 202, 179, 56, 527], [642, 16504, 8255, 2464, 6, 16505, 377], [2372, 484, 88, 3, 502, 15, 2, 1515, 3, 86, 53, 3, 704, 7, 24, 18, 2372, 484], [16506, 9, 16507, 147, 16508, 3738, 16509, 704, 163, 16510, 16511, 16512, 855, 16513, 16514, 1710, 16515, 16516, 16517, 16518, 3739, 16519, 3405, 1204, 16520], [16, 32, 4, 1810, 1, 3, 47, 4, 16521, 225], [16, 1134, 10, 21, 12, 102, 22, 1608, 140, 16, 5, 2082, 144], [16, 1134, 1591, 7, 196, 15, 8256, 817, 31, 23, 1165, 3295, 241, 83, 66, 46, 105, 16522], [102, 2, 320, 16, 961, 1, 3, 14, 314, 483], [1248, 493, 12, 56], [1248, 852, 2241, 33, 73, 93, 73, 5892, 31, 48, 2058, 29, 410, 17, 24], [1239, 377, 5944, 92, 1177, 1683, 18, 2795, 4358, 6, 2810], [241, 53, 3, 293, 2653, 616, 16523, 250, 173, 10, 24, 53], [241, 3, 911, 66, 259, 11, 4, 16524], [241, 23, 108, 92, 1700, 16525, 29, 19, 27, 22, 68, 1], [241, 23, 530, 21, 366, 2390, 8, 20, 530, 21, 48, 1089, 747, 20, 1340, 744, 185, 141, 1], [241, 16526, 20, 402, 12, 2619, 17, 20, 4405, 8257, 129, 16527, 20, 8258, 4, 331, 16, 6270, 382, 17, 32, 115, 358], [241, 1, 5, 7778, 219, 1, 23, 3089], [241, 286, 221, 55, 5, 62, 7, 153, 3068, 16528], [241, 15, 47, 3312, 16529, 18, 802, 77, 91, 36, 920, 2, 1036, 18, 7, 9], [241, 15, 490, 2295, 449, 11, 4967, 422, 70, 1237, 92], [241, 65, 4597, 210, 795, 173, 84, 313, 8, 1014, 98, 16530, 417, 1165, 1735, 313, 838], [241, 720, 22, 222, 14, 2, 686, 250, 182, 4725, 558, 16531, 16532, 4725, 558], [241, 10, 274, 241, 10, 16533, 23, 61, 6, 2, 1, 2990, 460, 225, 241, 10, 274], [241, 10, 274, 22, 1, 294, 722, 17, 8, 2824, 532, 13, 2, 1127, 3257, 5945, 5945, 5945], [241, 4841, 116, 47, 98, 354, 2338, 173, 7, 1018, 1499, 16534], [241, 336, 1, 233, 3, 197, 99, 209, 6, 110, 86, 59, 254, 55], [241, 43, 40, 210, 194, 80, 476, 1, 53, 68, 1, 8, 268, 381, 53], [241, 43, 1118, 9, 5946, 365], [241, 988, 15, 928, 264, 4, 264, 32, 4, 1, 8259], [241, 2034, 20, 2, 24], [241, 40, 12, 3, 538, 7, 140, 1, 63, 14, 8078, 38, 15, 107, 6, 1334], [241, 45, 15, 96, 480, 3829, 289, 132, 11, 22, 1, 99, 358], [241, 45, 2118, 248, 20, 16535, 12, 56], [241, 1396, 23, 33, 623, 22, 703, 718, 12, 16536, 16537, 52, 5947, 16538, 27, 32, 7, 1414, 6733, 6990], [241, 37, 92, 426, 66, 210, 1112, 42, 1, 131, 81, 45], [241, 219, 5, 161, 185, 30, 1, 3, 29, 19, 27, 16539, 16540, 12, 2, 1150, 30, 323, 8, 101, 19, 25, 13, 254], [241, 221, 1047, 3975, 153, 128, 86, 3, 266, 649, 39, 16541, 25], [241, 5, 41, 2, 154, 1, 5, 86, 5, 41, 2, 154, 1, 188], [241, 5, 68, 16, 212, 861, 35, 1], [241, 5, 67, 8260, 219, 16542, 12, 179, 8260, 119, 7, 45, 371, 23, 291], [241, 20, 152, 1606, 20, 164, 33, 313, 15, 423, 366, 441, 34, 10, 959, 1228, 49, 2714, 130, 5948, 26, 26, 26, 33, 56, 10, 164], [241, 8, 23, 108, 83, 43, 68, 294, 32, 129, 17, 182, 1404, 1269], [241, 1], [241, 988, 48, 8261, 15, 75, 340, 573, 16543, 4572, 7955, 16544, 241, 4, 1144, 3506, 136, 514, 126, 2098, 97, 171, 83], [5742, 2375, 2438, 7, 83], [2984, 26, 1906, 38, 5, 28, 2, 79, 82, 899, 924, 1, 176, 821, 35, 111, 426, 40, 67, 1198, 1492, 55], [2984, 10, 16545, 3, 1025, 35, 37, 313, 325, 153, 1010, 1705, 163, 10, 148, 347, 163, 52, 1014, 35, 163, 10, 45, 163, 3, 514, 10, 310, 251, 2982], [16546, 581, 1094, 1, 176, 3214, 17, 1275, 3246, 3247, 17, 133, 162, 3, 132, 34, 289, 132, 27, 246, 1, 5082], [16547, 333, 29, 14, 2, 1, 6, 17, 1185], [8262, 65, 51, 22, 24, 18, 20, 618], [422, 37, 48, 32, 4, 229, 18, 3107, 1848, 49, 983, 248, 16548, 1814, 12, 16549], [422, 22, 12, 16550, 2, 818, 1132, 69, 67, 6, 450, 2331, 79, 2586, 1215, 98, 674, 782, 3614, 3047, 1718], [422, 264, 264, 1], [3351, 200, 22, 1, 33, 72, 4183, 3, 86, 16551, 3, 442, 42, 33, 2162, 4526, 1496], [16552, 249, 138, 427, 614, 6, 14, 328, 11, 2, 342, 16553, 51, 1284, 33, 13, 119, 24, 20, 48, 614, 6, 14, 626, 16, 254], [550, 23, 152, 87, 21, 416, 6, 139, 79, 1350, 2, 9, 888, 267, 26], [550, 5894, 41, 68, 127, 106, 6, 79, 17, 2, 1, 11, 68, 16, 84, 1722, 1341, 2518, 13, 1, 3, 103, 810, 80, 1722, 164, 5, 41, 61, 35], [550, 34, 20, 518, 46, 132, 492, 21, 71, 358, 550, 16554, 5, 364, 282], [550, 29, 1257, 88, 3, 210, 67, 5, 6, 769, 1], [550, 37, 3, 62, 23, 13, 1654, 213, 713, 34, 3, 1125, 90, 8263, 16555, 82, 514, 19, 7, 171, 1, 369, 12, 50, 437], [550, 37, 519, 12, 2, 889, 391, 74, 136, 60, 804, 347, 352, 16556], [550, 117, 1, 5, 214, 149, 5, 458, 20, 476], [550, 2749, 33, 510, 962, 7, 71, 3, 62, 23, 175, 193, 99, 713, 18, 2, 1477, 715, 23, 459, 16557], [550, 37, 485, 48, 155, 11, 12, 16558, 34, 3, 118, 3843, 16, 4, 111, 289, 16559, 44, 132, 56, 246, 5763, 1240, 5496], [2385, 1184, 31, 12, 2668, 16560, 71, 107, 5, 1, 29, 79, 642, 123, 2856, 6305, 7, 57, 3, 6457], [2385, 151, 139, 14, 2, 1, 2704, 485], [16561, 136, 8264, 127, 2412, 130, 2874, 8, 12, 101, 35, 445, 446, 16562, 30, 412, 180, 16563, 56], [802, 1, 30, 65, 13, 40, 41, 2, 8253, 1643], [802, 235, 156, 86, 2, 379, 153, 276, 7699, 125, 36, 16564], [206, 9, 55, 10, 1402, 12, 223, 23, 33, 98, 206, 2456, 92], [206, 9, 28, 214, 38, 5, 29, 229, 76, 4, 701, 36, 2197], [206, 462, 363, 6, 389, 8, 1912, 32, 4, 193, 129, 10, 4924, 90, 119, 18, 904, 16565, 185, 120, 83], [1944, 202, 189, 51, 5200, 296, 62, 553, 16, 39, 490, 3, 197, 27, 1011, 37, 135, 16566, 52, 47, 117, 99], [1384, 77, 109, 273, 17, 40, 317, 279, 31, 50, 520, 136, 319, 22, 12, 57, 329, 27, 305, 5710], [4625, 24, 37, 93, 7, 52, 41, 2407, 6, 3896, 1289, 27, 4, 4423, 16567, 12, 4, 832, 83], [16568, 16569, 37, 56, 18, 4, 1248, 234, 16, 4, 1352, 252, 112, 164, 16570, 2369, 2369, 591], [2480, 23, 59, 6, 4682, 2, 1, 32, 3, 94, 12, 355, 252], [2480, 22, 1356, 505, 13, 2, 1], [16571, 4, 284, 1, 12, 135], [526, 1079, 127, 115, 11, 1314, 2, 449, 151, 14, 11, 2977, 1], [526, 5396, 584, 362, 7, 48, 32, 5, 134, 423, 21, 16572, 1], [526, 3, 90, 22, 1, 19, 7562, 242, 4, 19, 16573], [526, 3, 103, 33, 61, 6, 159, 1538, 6, 987, 412, 3, 19, 27, 76], [526, 3, 103, 204, 5, 21, 13, 7, 327, 3, 300, 1], [526, 1, 303, 2, 3170, 8, 411], [526, 321, 121, 22, 1, 65, 13, 2, 275, 6254, 16574, 128], [526, 16575, 33, 349, 35, 6, 10, 331, 13, 3051, 619, 368, 625, 5832], [526, 19, 39, 1], [526, 52, 51, 15, 1404, 52, 4, 247, 2169, 5949, 43, 466, 44, 864, 16, 56, 18, 186, 289, 182, 5593, 100, 17, 61, 313, 35, 3710], [526, 22, 1, 33, 121, 60, 45], [526, 22, 1, 47, 397, 8, 7703, 2, 727, 839, 8, 589, 3008, 4, 413, 106, 40, 47, 51, 4, 5667, 8265], [526, 4, 5950, 141, 4726, 2408, 182], [526, 5, 266, 72, 15, 6, 10, 231, 185, 30, 9, 533, 45, 571, 1866, 50, 30, 16576, 3778, 3981, 8266], [16577, 8267, 8268, 12, 37, 16578, 16579, 1561, 4470, 16580, 40, 13, 2, 95, 16581], [3272, 22, 1, 171, 30, 19], [16582, 16583, 16584, 5159, 4560, 964, 4975, 123, 514, 11, 4560, 123, 4601, 16585], [18, 16586, 3, 7905, 325, 1], [18, 16587, 2852, 32, 4, 202, 418, 135, 49, 56, 34, 374, 152, 14, 1135], [18, 2, 7579, 6621, 24, 11, 16588], [18, 2, 3653, 6, 258, 60, 1172, 1054], [18, 2, 1844, 16, 378, 6, 388, 23, 194, 115, 16, 3769, 117, 615], [18, 421, 150, 16589, 171, 149, 3, 911, 10, 1255, 169, 13, 2, 9], [18, 10, 373, 45, 383, 227, 1494, 1, 18, 147, 8269, 5, 8270, 45], [18, 4, 8271, 16, 3314, 26, 1057, 3670, 608, 922, 708, 2724, 16590, 73, 126, 373, 73, 2, 229, 16, 126, 377, 8125], [18, 4, 1564, 460, 3653, 259, 2884, 6, 382, 16591], [18, 22, 7262, 2492, 167, 18, 39, 145], [18, 3821, 23, 3786, 19, 5575, 1], [18, 3821, 23, 3786, 19, 5575, 1], [18, 97, 24, 742, 2646, 15, 2, 413, 320, 16, 280], [469, 16592, 16593, 2628, 53, 16594, 62, 2, 9, 226, 16595, 160, 16596], [469, 4, 16597, 12, 328, 18, 16598, 51, 3092, 7344, 2494, 36, 79, 11, 4, 5951, 4726, 2105, 6325, 13, 16599], [469, 66, 421, 35, 432, 67, 4, 24, 16600, 78, 109, 90, 932], [469, 5, 90, 217, 474, 36, 58, 12, 6731, 2919, 51, 22, 1, 119, 212, 353, 13, 40, 373, 4, 148, 8272], [68, 180, 261, 392, 16, 365, 283], [68, 115, 5, 25, 223, 683, 38, 48, 6, 19, 98, 183, 83, 140, 39, 8273, 87, 6, 14, 139], [68, 9, 14, 595, 73, 19, 8, 4, 166, 68, 14, 183, 130, 2, 1], [68, 91, 56, 12, 246, 3773], [68, 91, 9, 12, 246, 16601, 2072, 36, 29, 396, 2461], [68, 91, 56, 12, 246, 91, 3124], [68, 91, 56, 12, 246, 91, 3124], [68, 127, 16, 390, 381, 294, 16602, 1274, 4517, 95, 18, 2, 16603], [68, 264, 397, 78, 9, 78, 46, 295, 127], [68, 16, 237, 65, 776, 159, 5369, 535, 707, 892, 662, 16604], [68, 16, 10, 443, 8274, 2834, 2, 91, 18, 4, 16605, 27, 2, 120, 16606, 122, 6, 70, 84, 95, 61, 8275], [68, 16, 10, 312, 8276, 51, 16607, 272, 176, 15, 702, 1250, 205, 18, 678, 68, 15, 47, 55], [68, 16, 4, 796, 1462, 16, 2, 47, 26, 37, 85, 2, 146, 208, 13, 2, 6, 4], [68, 16, 4, 237, 16, 32, 106, 12, 715, 1311, 297, 7, 713, 3, 442, 52, 472, 73, 26], [68, 16, 4, 434, 3124, 16, 259, 11, 1914, 3719, 12, 542, 16608, 6, 953, 1347, 216, 27, 112, 2196, 8, 953, 7459, 8212], [68, 16, 4, 360, 247, 16609, 377, 16610, 33, 41, 242, 142], [68, 712, 392, 16, 89, 1, 26, 128, 75, 442, 23, 543, 15, 27, 10, 455, 82, 5952, 26], [68, 184, 3, 75, 397, 12, 262, 1, 7, 41, 5408], [68, 184, 3, 90, 127, 130, 1613, 25, 12, 2, 1075, 1, 13, 519, 5, 61, 4616, 74, 5, 276, 1181, 39, 956], [68, 184, 3, 64, 59, 10, 575, 12, 66, 44, 98, 594, 7, 66, 29, 13, 342, 385, 342, 12, 21, 4, 942], [68, 184, 3, 64, 59, 2567, 2090, 52, 46, 2, 1, 59, 2685, 15], [68, 184, 3, 105, 200, 8, 7, 64, 2, 1, 218, 23, 16611, 385, 3, 101, 64, 10, 4727], [68, 184, 59, 15, 233, 23, 2, 334, 16612, 153], [68, 184, 3, 156, 113, 10, 5405, 1081, 180, 1081, 10, 1, 233, 145, 42, 156, 152, 14, 93, 1804], [68, 184, 42, 75, 28, 17, 6, 58, 12, 302, 2, 1], [68, 106, 11, 314, 261, 22, 77, 273, 10, 228, 7, 52, 87, 16613, 37, 52, 273, 50, 40, 87, 1414, 16614, 736, 83], [68, 106, 22, 77, 191, 10, 57, 10, 437, 47, 3, 16615, 1257, 3, 64, 89, 1], [101, 732, 49, 7152, 602, 6, 2552, 126, 1317, 544, 123, 44, 2, 16616, 621, 69, 3127, 54, 21, 2530, 115, 12, 248], [101, 732, 118, 2010, 120, 56, 27, 1469, 6, 1760, 3304, 73, 1205, 16617], [101, 1009, 63, 3960, 4, 807, 3216, 16, 16618, 159, 524], [101, 2, 3562, 118, 86, 12, 59, 16619, 988, 47, 2, 715], [101, 2, 291, 25, 152, 1385, 21, 2, 291, 1], [101, 2, 9, 118, 443, 4325], [101, 339, 1, 2386, 51, 1260, 1023], [101, 1, 81, 45], [101, 291, 1, 719, 169, 26], [101, 104, 24, 157, 126, 186, 327, 16, 76, 8, 126, 381], [101, 104, 168, 120, 16620], [101, 181, 72, 16621, 45, 214, 726], [101, 203, 1, 8, 1165, 517, 9, 225, 16622], [101, 21, 68, 540, 149, 2, 1, 266, 61, 315, 26, 31, 20, 226, 3872, 5953, 26, 3, 94, 8277], [101, 1181, 89, 1, 1409, 58, 43, 16623], [101, 28, 1229, 224, 97, 412, 30, 1], [101, 2666, 25, 6497, 129, 418, 27, 2227, 1982], [101, 9, 359], [101, 9, 28, 7824, 253, 18, 610], [101, 9, 64, 17], [101, 11, 10, 1307, 975, 63, 5, 294, 173, 2, 1129, 1201, 904, 8, 28, 6724, 480, 11, 2, 2960, 251], [101, 176, 112, 1, 11, 2377], [101, 629, 3, 75, 304, 6, 8278, 16624, 26, 31, 15, 2, 1332, 23, 61, 1854, 673, 45, 18, 1486, 4387], [101, 664, 6, 176, 1401, 260, 203, 73, 36, 41, 5837], [101, 145, 18, 10, 909, 37, 28, 102, 92], [101, 3989, 8, 35, 145], [101, 111, 48, 337, 117, 92, 49, 3218, 9, 26, 25, 238, 167, 76, 9], [101, 144, 800, 16625], [101, 4, 730, 11, 10, 387, 163, 1, 36, 2592, 135], [101, 4, 870, 2273, 8, 7, 25, 2, 24], [101, 4, 870, 2273, 8, 5, 25, 12, 1], [101, 184, 7, 1954, 17, 4177, 24, 8, 60, 2663, 7347], [101, 175, 17, 31, 7, 24, 41, 8279], [101, 66, 118, 311, 305, 237, 926, 450, 8, 16626, 2, 56, 25, 69, 75, 70, 2, 137, 6, 492, 84, 164], [101, 120, 111, 168, 4, 324, 838, 4722, 109, 12, 114, 129], [101, 120, 56, 8, 2541, 49, 1001, 123, 4, 412, 2439], [101, 120, 56, 194, 8280], [101, 120, 56, 194, 7386], [101, 120, 56, 118, 79, 1650, 8, 16627, 8, 16628, 126, 16629], [101, 324, 3, 63, 594, 18, 12, 16630, 5890, 4728, 11, 22, 3723, 16631, 1216, 665, 5320], [1312, 2, 282, 40, 62, 40, 2, 9, 3, 62, 40, 2, 9, 40, 266, 708, 40, 2, 9, 37, 40, 72, 40, 46, 2, 9, 16632, 32, 62, 5, 2, 9, 9], [1312, 41, 625, 9], [1312, 41, 4, 2731], [1312, 70, 10, 682, 16633, 13, 2320, 83], [16634, 7, 1, 3855, 580, 12, 3855, 19], [3828, 3, 33, 124, 2, 16635, 16636], [458, 50, 645, 88, 5954, 5955, 7, 24], [458, 2959, 605, 10, 6693, 439, 16637, 64, 170, 60, 605, 251, 16638], [458, 35, 50, 645, 8, 5954, 5955, 7, 24], [2807, 191, 16639, 8037, 159, 4729], [74, 1673, 946, 21, 4, 6239, 16640, 7526, 2364, 946, 21, 1837, 16, 6942], [74, 23, 1822, 8, 36, 191, 6, 94, 4, 3196, 2652, 62, 36, 133, 6, 137, 60, 56], [74, 2, 171, 1, 27, 43, 653, 3460, 3, 75, 16641, 34, 21, 92, 15, 2602], [74, 1475, 6, 14, 2, 3162, 7, 431, 99], [74, 104, 380, 52, 41, 906, 72, 916], [74, 28, 4886, 11, 6349, 55], [74, 28, 36, 1574, 328, 199, 9, 1580, 59, 25, 36, 1181, 41, 169, 34, 75, 110, 28, 170, 6, 1207, 126, 1686, 35], [74, 1635], [74, 40, 33, 75, 1800, 1444, 754, 850, 9, 903, 1444, 16642], [74, 4, 1226, 318, 28, 42, 41, 3, 109, 90, 2, 974, 30, 1, 11, 3319, 4, 3071, 12, 81, 5, 411, 83], [74, 126, 451, 12, 56], [74, 38, 20, 11, 10, 2323, 5, 62, 20, 11, 4, 16643, 179, 16644], [74, 5, 146, 389, 60, 1005, 149, 24, 46, 351, 8111, 138, 46, 351, 1776, 63, 5, 479, 22, 7808, 35, 333, 267, 5], [4041, 468, 11, 4041, 16645, 104], [354, 684, 853, 1799, 53], [354, 1448, 3, 67, 350], [354, 5695, 103, 1115, 1093, 17, 16], [354, 8, 1637, 21, 16646, 3, 58, 57, 3, 67], [354, 8, 236, 236, 157, 173, 16647], [354, 49, 10, 164], [1767, 3705, 149, 23, 4720, 130, 2, 16648], [2553, 26, 3, 168, 6, 70, 501, 16, 16649, 111, 612, 34, 92, 7, 374, 18, 1881, 21, 3003, 102, 22, 161, 1, 67, 60], [2553, 16650, 363, 2846, 11, 84, 1700, 2184, 8281, 51, 16651, 57, 2, 16652], [2553, 172, 2313, 117, 92, 41, 17, 625, 8282, 22, 83], [166, 377, 1199, 3973, 8238, 16653, 16654, 7267, 52, 16655, 2420, 26, 16656, 16657, 27, 16658, 27, 84, 16659], [166, 88, 4, 104, 45, 4730, 428, 2, 109, 93, 16660, 130, 1628, 16, 992], [8283, 118, 70, 431, 1245, 31, 36, 2128, 270, 3300], [305, 275, 1802, 1072, 12, 554], [305, 3071, 121, 9, 8, 52, 121, 971, 16661, 57, 2, 900], [54, 16, 115, 279, 23, 114, 2, 2538, 1966, 18, 5, 16662], [619, 10, 3076, 15, 46, 246, 153, 4622, 125, 17], [619, 27, 8284, 172, 2846, 2997], [129, 1, 122, 6, 208, 13, 3, 373, 76, 2, 406], [4692, 22, 419, 164, 12, 59, 7954, 33, 58, 7, 8, 560, 28, 4, 677, 34, 29, 3264, 240, 650, 20, 2, 711], [16663, 2568, 49, 48, 93, 16664], [8169, 16665, 8, 8285, 8, 48, 56, 429], [8286, 12, 10, 3631, 720], [1635, 2, 215, 58, 1635, 8287, 16666, 16667, 3005, 5885, 16668, 16669, 2061, 8287, 16670, 2, 215, 16671], [16672, 7518, 203, 354, 49, 16673, 8, 29, 16674, 5854, 38, 3837, 11, 5824, 271, 423, 82, 76, 374, 16675], [16676, 33, 273, 17, 59, 71, 2370, 47, 881, 1399, 8, 52, 47, 227, 190, 8, 16677], [8288, 16678, 408, 87, 6, 411], [1135, 325, 209, 21, 143, 2758, 3, 1741, 1144, 2, 1], [16679, 165, 262, 2, 1, 55], [1622, 1, 18, 8289, 2739, 1, 64, 8289], [5424, 382, 642, 18, 16680, 16681, 191, 1472, 222, 44, 297, 22, 16682, 4, 1816, 568, 1060], [5024, 2130, 12, 37, 56, 34, 3, 67, 1745, 8, 210, 150, 13, 525, 54, 4, 347], [16683, 160, 473, 691, 771, 473, 691, 24, 16684, 1562, 350], [1010, 129, 24, 149, 24, 316, 437], [4323, 12, 56, 280, 55], [8290, 1407, 27, 4, 16685, 2101, 50, 24, 578, 13], [8290, 41, 4, 237, 813, 1692, 3, 300, 3, 4731, 3745, 129, 76, 9], [915, 16686, 16687, 3663, 352, 2149, 211, 159, 524, 47, 48, 422, 335], [4388, 4002, 12, 1788, 3877, 7, 1, 107, 35, 27, 4, 237, 1788, 21, 84, 8274, 13, 19, 720], [16688, 16, 377, 323, 160, 127, 2471, 130, 16689, 16690, 198, 16691], [16692, 56], [820, 5197], [460, 51, 4, 331, 107, 539, 1], [433, 4732, 5, 171, 30, 1172, 2600], [433, 76, 741, 1], [433, 35, 18, 214, 9, 33, 6, 134, 170, 57, 52, 67], [3793, 29, 64, 39, 9], [4496, 2, 282, 71, 42, 276, 137, 211, 4, 1695, 8291], [4619, 16693, 24, 41, 2, 25, 18, 1706, 18, 84, 1981, 2041, 52, 146, 28, 50, 108, 390], [389, 21, 24, 43, 80, 3, 28, 99, 239, 8292], [1915, 12, 2, 1], [1915, 2, 83], [1258, 1716], [1258, 181, 33, 375, 23, 237, 3970, 608, 16694, 405, 16695, 479, 17, 8, 16696, 35, 16697], [1258, 10, 16698, 16699, 195, 48, 20, 16700, 72, 7, 324, 16701, 51, 10, 1126, 16702, 16, 10, 237, 228, 182, 47, 2, 3020], [1258, 6, 32, 4, 9, 3, 157, 10, 16703, 11, 8, 210, 867, 1418, 21], [7550, 12, 2, 141, 1, 149, 52, 105, 706, 307], [5743, 654, 238, 1650, 8, 1464, 32, 4, 193, 142, 4, 1194, 55], [7096, 12, 120, 56, 8, 12, 37, 49, 32, 16704], [111, 49, 19, 144, 55], [111, 49, 37, 16705], [111, 49, 270, 1, 733, 129, 185, 184], [111, 191, 17, 693, 3, 105, 569, 35, 133, 4, 1411, 163, 161, 45, 111, 72, 16706, 1249, 432, 134, 2, 1301, 133, 553, 16, 7, 43, 25, 74, 1, 2779], [111, 191, 21, 3083, 21, 8293, 16707, 112, 4, 1, 216, 1721, 16, 831, 21, 44, 2637, 1, 165, 14, 172, 17], [111, 14, 37, 1076, 390, 18, 325, 135, 16708, 15, 332, 21, 2, 207, 91, 6, 94, 32, 325, 16709, 13, 1426, 11, 2, 3328, 331, 11, 3569], [111, 79, 8, 733, 6, 8294, 140, 16, 305, 2669, 3108, 128, 1549], [111, 1088, 18, 10, 2283, 16710, 13, 2228, 47, 20, 16711, 13, 1, 369, 58, 3, 62, 5], [111, 28, 127, 8, 127, 144, 744], [111, 146, 683, 6, 1512, 4, 111, 7, 61, 54, 31, 126, 193, 6, 547, 350, 110, 31, 5, 29, 67, 126, 547, 29, 52, 2, 1], [111, 90, 18, 143, 4424, 164, 34, 3, 64, 10, 260, 127, 88, 2, 24, 30, 399], [111, 64, 6, 881, 10, 343, 16712, 12, 22, 5956, 367, 1, 12, 20], [111, 18, 22, 2555, 49, 19, 144, 601], [111, 81, 45, 18, 186, 34, 38, 36, 94, 5, 11, 395, 14, 8295, 13, 1, 369, 5, 65, 3916, 367, 15, 17, 221, 23, 16713], [111, 2464, 6, 1, 59, 1309, 99, 209, 34, 1248, 16714, 136, 204, 4, 16715, 16716, 51, 22, 3461], [111, 69, 2603, 4, 823, 129, 4, 620, 49, 2257, 248, 36, 655, 1776, 538, 2174, 16717, 36, 49, 882, 130, 7169], [111, 69, 29, 157, 126, 16718, 18, 944, 33, 87, 6, 1780, 173, 2, 3327, 74, 256], [111, 69, 934, 229, 13, 8, 49, 2801, 8296, 1326, 120, 56, 776], [111, 69, 61, 6, 1860, 11, 1991, 2036, 49, 32, 120, 56, 4362], [111, 69, 632, 126, 373, 3223, 49, 295, 34, 2269, 16719, 248], [111, 69, 259, 11, 49, 16720, 248], [111, 69, 105, 168, 245, 343, 3925, 49, 16721, 120, 56, 2801, 8296], [111, 69, 137, 49, 120, 56], [111, 69, 137, 49, 1044, 5288, 8, 29, 655, 4, 199, 538, 1502, 134, 2, 16722, 374, 5166, 5838, 248], [111, 69, 2131, 18, 4, 3942, 51, 190, 480, 198, 48, 14, 1166, 6, 6654], [111, 27, 56, 347, 64, 6, 484, 1026, 8, 8104], [111, 22, 406, 750, 8, 2044, 31, 21, 43, 166, 540, 130, 15, 70, 660, 27, 950, 1175, 109, 1076], [4733, 8297, 5660, 12, 4, 250, 1144, 2018, 396, 7, 1804, 16, 4006, 52, 3993, 73, 494, 129, 2506], [4733, 23, 48, 2, 16723, 232, 408, 34, 116, 43, 127, 446, 11, 194, 22, 16724, 37, 57, 499, 12, 18, 55], [4691, 935, 11, 10, 1256, 82, 38, 3, 16725, 142, 4, 16726, 38, 3, 47, 16727, 3, 271, 11, 4, 1905], [395, 10, 154, 213, 5957, 12, 6, 48, 14, 2, 4520, 6, 4646, 17, 221, 8, 23, 61, 6, 303, 2, 16728, 23, 48, 726], [1892, 2477, 7, 236, 105, 1351, 7, 236], [2533, 91, 12, 2, 4968, 19, 3116, 24, 30], [16729, 12, 152, 405, 5524, 13, 16730, 200, 38, 143, 16731, 363, 6, 7404, 39, 9, 46, 334], [2707, 3964, 65, 13, 4, 2707, 3964, 16, 3905, 16732], [8298, 2190, 65, 13, 52, 603, 67, 6, 79, 252, 2, 158, 21, 7, 89, 137], [310, 16733, 13, 2, 9, 964, 267, 274, 21, 8299, 341, 1251, 55], [310, 5958, 130, 80, 1, 4099], [846, 536, 21, 2015, 16734], [846, 89, 83, 20, 443, 2977, 16735], [846, 134, 5, 7, 1900, 731, 248], [846, 93, 561, 798, 26, 134, 42, 120, 56, 481, 188], [846, 243, 928, 1], [846, 243, 928, 16736], [846, 135, 60, 7807, 5737, 21, 5, 22, 12, 71, 5738, 230, 3, 2583, 2, 83, 188], [846, 272, 900, 30, 83, 188], [846, 17, 8, 10, 1], [846, 561, 1], [846, 5959, 18, 4, 257, 9], [846, 10, 455, 5924, 8202, 1], [846, 43, 4007, 283, 188], [846, 763, 11, 1258, 6, 39, 89, 177, 60, 89, 16737, 216, 17, 100, 60, 206, 668, 252, 2410, 8300, 4, 16738], [846, 944, 32, 10, 228, 49, 319, 15, 37, 2181], [846, 16739, 16740, 397, 21, 2, 685, 748, 1095, 18, 4, 351, 1143, 16, 16741, 6622], [846, 16742, 16743, 16744, 16745, 16746, 49, 5, 16747], [16748, 4, 796, 24, 289, 297, 11, 16749], [4530, 26, 618, 39, 1, 5765, 12, 56], [327, 5869, 18, 377, 1090, 708, 98, 16750, 16751, 18, 503, 16, 8301, 16752, 11, 4, 16753, 115, 16, 16754], [327, 37, 16755, 65, 13, 2, 391, 34, 136, 2, 9, 16756, 439, 5648], [479, 2, 620, 303, 2, 4139, 258, 2, 595, 9, 100, 60, 106, 61], [16757, 493, 3529, 5, 2, 534, 462, 140, 3, 64, 24, 3182, 1600, 304, 3, 599, 1456, 3, 13, 16758], [406, 106, 619, 16, 16759, 19, 181], [2215, 4350, 12, 248, 15, 14, 32, 8302, 8, 1015, 8, 385], [1663, 1560, 2004, 4957, 32, 39, 565, 27, 2012, 52, 37, 56, 92, 251], [2270, 533, 6, 1, 3, 94, 50, 40, 89, 34, 25, 40, 339], [2270, 533, 6, 20, 9, 1500, 18, 2, 25, 5, 318, 468, 97, 418, 13, 7], [1106, 3892, 21, 10, 1567, 1162, 40, 2, 89, 1, 3, 293, 7, 40, 29, 1695, 17], [633, 17, 16, 38, 3, 94, 39, 141, 1132, 104, 255, 5960, 16760, 5867, 420, 174, 30, 6, 16761], [633, 17, 102, 37, 209, 38, 5407, 801, 181, 74, 835, 54, 4, 1371, 51, 111], [3402, 8, 89, 1, 16762, 8, 89, 624], [1421, 8, 1919, 1], [1421, 2, 2107, 8, 2116, 12, 32, 3, 16763, 3061, 87, 6, 14, 704, 74, 23, 2, 1395, 1], [16764, 752, 1], [137, 17, 59, 1547, 773, 23, 2, 16765, 838, 20, 1923], [137, 24, 8, 28, 19], [137, 60, 19, 1, 28, 169, 451], [137, 39, 9, 13, 4, 3922], [137, 2, 229, 11, 5935, 3737, 51, 6849, 2748, 225, 51, 4645, 159], [137, 178, 8, 3618, 49, 4, 101, 193, 3, 16766, 27, 10, 4823, 7, 8, 4, 352, 81, 26, 5094, 16767, 43, 1744, 381, 39, 9], [137, 6, 120, 4244, 215, 68, 215, 106, 1430, 1559, 16768, 15, 450, 1185, 15, 450, 11, 4, 16769, 16, 16770], [137, 27, 10, 169, 12, 13, 137, 27, 10, 1393, 25, 29, 442, 3, 380, 66, 61, 6, 258, 54, 88, 9, 30, 25], [333, 242, 35, 9, 23, 1061, 2, 417, 395], [333, 829, 80, 9], [333, 1138, 114, 43, 406, 333, 1138, 114, 43, 406, 1047, 27, 10, 16771, 18, 91, 39, 9, 37, 16772], [333, 919, 10, 1, 30, 310, 15, 132, 2, 9, 713], [333, 139, 1228, 2855, 5, 266, 44, 245, 298, 21, 740, 641, 16773], [2491, 1717, 3, 19, 20, 1], [2491, 1717, 1], [2491, 1717, 39, 9, 49, 3462], [2748, 12, 42, 168, 245, 16, 4, 324, 3, 168, 16774, 16775, 220, 438], [1205, 153, 2250, 6568, 143, 941], [1086, 478, 16776], [1086, 30, 1], [16777, 16778, 16779, 16780, 4, 65, 18, 20, 231, 38, 5, 96, 29, 28, 245, 16781], [16782, 16783, 386, 16, 2, 1], [950, 8303, 52, 608, 4, 117, 16784, 16, 5, 189, 32, 18, 84, 2138, 29, 505, 15, 16785, 6265], [950, 16786, 75, 547, 1412, 763, 1, 1511, 3, 150, 97, 337, 8304, 5878], [429, 2, 399, 372, 13, 8305], [429, 7, 24], [429, 7, 24, 21, 2, 112, 25], [2796, 8, 1468, 21, 5961, 3, 156, 724, 159, 524, 47, 10, 2802, 6409], [429, 2, 24, 23, 1513, 55], [8306, 134, 17, 16787, 1, 3, 28, 15, 21, 4, 16788], [8306, 134, 17, 16789, 1, 3, 28, 15, 21, 4, 16790, 16791, 205], [429, 1876, 2614, 1097, 8, 16792], [429, 273, 17, 105, 741, 97, 11, 2, 291, 1], [2084, 269, 445, 164], [2084, 269, 445, 164], [16793, 994, 109, 13, 2, 312, 21, 112, 3, 198, 44, 122, 6, 16794, 972, 112], [16795, 29, 70, 5, 43, 16796], [448, 2, 154, 323, 8307], [448, 2, 154, 323, 8307], [863, 859, 147, 9], [574, 109, 75, 806, 2, 77, 7, 48, 2, 5096, 3578, 8, 72, 71, 40, 150, 233, 107, 102, 73, 2, 1], [2905, 41, 1462, 390, 48, 1166, 18, 16797, 2306, 21, 2, 213, 2704, 3197, 23, 144], [3267, 22, 1403, 21, 22, 658, 16, 1493, 7, 12, 2619, 263], [2892, 183, 77, 49, 4, 193, 6, 61, 720, 357, 41, 106, 21, 5, 322, 9], [16798, 738, 73, 78, 421, 35, 12, 38, 40, 192, 58, 4, 45, 40, 3741, 2213, 105, 58, 13, 14, 2, 9], [16799, 2, 8308, 3764, 1095, 18, 2, 1082, 16, 16800, 4, 1864, 1650, 107, 82, 16801, 653, 8011, 12, 4, 16802], [2513, 6, 14, 79, 2, 3808, 32, 5861, 3, 196, 137, 4683, 32, 1477], [1160, 21, 24, 43, 3589, 28, 99, 239, 8292], [1463, 1034, 1275, 4, 287, 1, 38, 36, 62, 36, 64, 240, 2706], [1463, 7, 52, 63, 70, 15, 1234, 305, 179, 970, 12, 11, 15, 21, 1399, 288, 3798, 169, 835, 2020, 16803, 6, 271, 18, 68, 127, 921], [322, 30, 4581], [322, 1, 27, 110, 4153, 815], [322, 639, 1534, 349, 35, 11, 2, 1, 13], [322, 1400, 349, 35, 11, 22, 1, 13], [322, 4566, 349, 35, 11, 22, 1, 13], [322, 129, 22, 413, 232, 184, 278, 516, 468, 11, 4, 16804, 155, 213, 88, 259, 11, 16805, 3, 346, 4, 112, 8309], [322, 362, 3, 41, 97, 1, 677, 11, 10, 310, 25], [322, 804, 7, 1861, 2377, 49, 5079, 6, 72, 1073, 6, 4, 7630, 83, 73, 5, 3165, 4, 16806], [415, 61, 6, 3303, 8144, 38, 3, 94, 50, 1249, 3, 346, 10, 1], [415, 492, 725, 30, 1185, 59, 54, 1069, 11, 2, 8001, 16807, 57, 118, 5, 58, 461, 20, 388, 228], [8310, 12, 109, 2, 83], [5160, 123, 1290, 1967, 405, 325, 9], [16808, 1201, 49, 101, 934, 123, 120, 248], [1969, 389, 12, 33, 2, 1221, 30, 141, 83], [1373, 6, 64, 5, 8, 16809, 167, 15, 127, 130, 469, 2, 16810, 3, 72, 7, 16811, 7, 812, 15, 57, 5, 16812], [1373, 220, 216, 1, 26, 5, 49, 92, 10, 16813], [1367, 20, 1, 51, 32, 2926], [818, 6, 14, 2, 388, 5368, 513], [16814, 231, 9], [16815, 124, 1527, 493, 8, 478, 52, 96, 61, 6, 19, 20, 1, 211, 7, 2052], [349, 35, 18, 2, 153], [349, 35, 18, 10, 500, 70, 7, 1, 214], [349, 35, 18, 10, 500, 70, 7, 1, 5962], [349, 35, 18, 10, 2299, 70, 7, 1, 214], [349, 35, 18, 22, 5413, 590, 18, 10, 193, 337, 410, 367, 1], [349, 9, 46, 256, 6, 14, 818, 16, 9, 61, 27, 1311], [16816, 178, 2455, 439, 16817, 44, 98, 16818, 27, 2, 91, 69, 136, 16819, 265, 27, 1584, 2282, 3, 44, 166, 16820], [2617, 3550, 16821, 21, 143, 9], [929, 7, 9, 149, 40, 655, 254], [1043, 30, 291, 1716], [1043, 30, 670, 383, 7303, 7, 1], [1043, 1, 294, 1888, 13, 5, 41, 256, 6, 1392], [1043, 83], [24, 101, 16822, 155, 287, 41, 16823, 42, 146, 44, 127, 130, 7, 462], [24, 30, 9, 25, 3, 75, 19, 125, 78], [24, 30, 399, 226, 16824, 8, 84, 803], [24, 146, 14, 56, 50, 64, 164, 12, 37, 611, 55, 23, 37, 721, 5680, 888, 1476, 1374, 179, 30], [24, 13, 77, 16825, 12, 10, 24, 315], [24, 153, 66, 46, 228, 5, 46, 146, 410, 17, 1546, 768], [24, 18, 10, 476, 24, 18, 10, 6992, 1013], [24, 101, 24], [24, 29, 28, 285], [24, 101, 24, 98, 3, 28, 15, 38, 3, 87, 15], [157, 2, 16826, 24, 18, 250, 3576], [157, 2, 1013, 18, 15, 74, 15, 46, 80, 1], [157, 50, 11, 50, 507, 149, 24, 29, 28, 1982], [157, 7, 18, 474, 3, 2608, 46, 43, 183, 1, 556, 81, 6, 17, 284, 11, 10, 1832, 278, 157, 50, 30, 54, 8, 70, 50, 294], [157, 4, 786, 11, 20, 192, 8311, 661, 16, 4, 16827, 14, 501, 36, 4063], [157, 4, 1414, 108, 18, 4, 3065, 1, 3584, 55, 138, 16828], [157, 97, 402, 35, 31, 5, 2, 940, 2, 1], [157, 80, 1, 11, 4, 1244, 445, 8, 16829, 50], [157, 20, 402, 142, 1, 3, 46, 276, 512, 5], [157, 20, 1169, 108, 11, 20, 45, 1], [4265, 70, 65, 13, 2, 1, 18, 1797, 16830], [4734, 8, 7677, 76, 104, 30, 25, 4228, 91], [4734, 139, 7, 104, 18, 10, 909], [16831, 16832, 43, 7637, 43, 2125, 779, 17, 16833, 29, 64, 76, 9], [559, 665, 35, 10, 1090, 283], [559, 8312, 4, 866, 1], [559, 505, 39, 287, 218, 23, 515, 16, 32, 4, 1150, 2, 25, 146, 61, 539, 218, 5, 2, 9, 30, 916], [559, 81, 45, 5, 19, 711, 20, 944, 33, 214, 426, 43, 68, 67, 350, 69, 4, 19, 58, 5, 110, 86, 5, 49], [559, 3362, 1], [5963, 12, 37, 56, 92, 1945, 6, 570, 16834], [16835, 21, 159, 16836, 16, 1079, 446, 11, 16837, 2793, 641, 16838, 381, 527], [112, 25, 569, 5, 372, 13, 2, 1], [1108, 114, 8313, 16839, 8314, 16840, 2803, 849, 6, 159, 6296], [6146, 175, 16, 4, 115, 31, 2, 25, 396, 18, 1834, 19, 240, 233, 52, 47, 2, 1, 25, 82, 115, 378], [825, 273, 78, 6, 61, 108, 8, 16841, 32, 78, 153, 210, 477, 92, 36, 49, 3413, 18, 3085, 645, 8, 45, 1037, 16842, 8315], [117, 53, 4, 199, 1, 72, 16843, 16844, 49, 4, 199, 1, 70, 501, 16, 217, 16845], [4921, 56, 13, 94, 2302, 73, 4, 1033, 460, 94, 16846, 73, 126, 2172, 7690], [3, 103, 105, 182, 182, 134, 2, 25, 10, 32, 650, 3, 62, 21, 2, 488, 52, 58, 4, 199, 26, 2805, 556, 137, 17, 1], [53, 22, 45, 21, 4, 95, 26], [53, 3456, 16847, 728, 2, 4168, 51, 5016, 53, 284, 2092, 3456, 12, 51, 15, 361], [53, 583, 58, 66, 44, 246, 104, 16848, 583, 58, 66, 44, 246, 5618, 1543, 16849, 147, 252, 12, 417], [53, 26, 6819, 10, 25, 341, 177, 37, 29, 316, 43, 684, 11, 22, 1], [202, 1, 86, 15, 422, 6, 2427, 36, 402, 38, 36, 28, 173, 98, 2469, 1, 411, 230, 3, 719, 80, 4735], [749, 22, 12, 57, 32, 16, 10, 1, 72, 736], [3950, 592, 770, 8, 66, 204, 60, 3827], [993, 5, 196, 4730, 56, 3111], [1589, 2, 1779, 1, 2, 77, 69, 345, 12, 2, 77, 69, 8316, 74, 2, 1779, 1], [1539, 12, 1137, 2890, 5, 19, 3480], [32, 4624, 9, 67, 201, 184, 169, 26, 138], [1292, 339, 1, 37, 356], [377, 204, 11, 16850, 545, 51, 577, 201, 16851, 16, 2769, 1013, 546, 1164, 892, 951], [15, 46, 777, 6, 311, 7, 1, 102, 5083], [186, 1011, 15, 2486, 6, 72, 6, 891, 11, 84, 232, 1330, 16852, 496, 26], [9, 28, 2, 520, 8, 300, 36, 48, 2, 9, 2027, 1, 44, 2, 520, 317, 5964, 57, 582, 230, 170, 5, 188], [225, 3, 273, 2, 414, 7, 40, 47, 4, 16853, 16854, 16, 1719, 16855, 71, 195, 3, 48, 2150, 11, 24], [16856, 1319], [5, 75, 61, 329, 27, 2, 334, 83], [4106, 4193, 435, 12, 85, 3, 44, 1, 1222], [960, 888, 161, 746, 60, 9], [3, 318, 14, 183, 34, 10, 9, 46, 1070], [280, 29, 687, 27, 39, 4736, 30, 5558, 1263, 1, 165, 61, 137, 11, 60, 522], [38, 2, 9, 28, 99, 1565, 27, 482], [43, 2825, 1589, 2, 93, 570, 644, 2548, 2502, 31, 5, 67, 6, 4810, 11, 11, 882, 130, 98, 236], [1, 64, 25, 7, 41, 1], [3, 41, 1, 5678, 16857, 7875, 1501, 4, 2051, 160], [53, 107, 54, 50, 24, 8, 61, 11, 50, 30, 107, 54, 50, 30, 8, 61, 11, 50, 16858, 7, 193, 40, 266, 113, 16859], [1578, 1159, 704, 1159, 8, 4, 232, 3479, 15, 2, 93, 115, 11, 8317], [22, 1, 156, 11, 10, 1434], [53, 5, 62, 1, 14, 214, 38, 36, 14, 13, 584, 10, 373, 53], [336, 3626, 7, 25, 1441, 298, 84, 476, 13, 2, 9, 26, 10, 77, 46, 43, 9, 37, 497, 4737], [4, 25, 69, 33, 756, 10, 646, 121, 7, 2653, 47, 11, 36, 689, 1, 16860, 1642, 6, 263, 571, 61, 6, 258, 5, 7787], [29, 1513, 39, 9, 36, 107, 125, 4, 169], [1262, 435, 255, 1586, 27, 166, 1262, 435, 226, 18, 5965, 29, 627, 20, 19, 2332, 16861], [243, 457, 6, 10, 141, 30, 1081, 69, 317, 375, 69, 3, 195, 293, 15, 2, 93, 68, 181], [536, 54, 4, 774, 21, 7, 508, 1645, 7, 1216, 277, 4738], [3, 1764, 15, 46, 43, 227, 142, 16862, 80, 1, 635, 54, 16, 975, 188, 16863, 8318, 542, 6, 28, 15, 16864, 46, 43, 2874], [3, 90, 2, 308, 30, 1], [1387, 377, 176, 1954, 16865, 26], [23, 183, 37, 29, 475, 59, 17, 44, 319], [37, 78, 33, 223, 65, 722, 4, 488, 7, 22, 1, 249, 2, 138, 149, 50, 2817, 2434, 3, 300, 90, 5, 1, 1817], [23, 11, 22, 1, 4739, 3, 58, 10, 8319], [482, 1416, 94, 20, 310, 31, 5, 29, 44, 625, 9, 17, 68, 4941], [321, 22, 1, 517, 37, 1165, 7, 15, 16866], [31, 3, 706, 42, 29, 2347, 15, 6, 4, 1747, 1, 23, 238, 19, 18, 4, 702], [31, 42, 2, 1208, 1, 286, 3802, 3, 75, 728, 3199, 5], [33, 536, 10, 194, 163, 7, 1, 121, 601], [825, 1297, 1], [29, 14, 7, 3425, 30, 83], [779, 273, 17, 65, 613, 208, 950, 163, 1161, 840, 2422, 1, 147, 46, 174], [371, 2, 16867, 1, 3, 132, 5202, 25], [3, 64, 275, 670, 36, 340, 667, 9, 99, 19, 143, 2407], [16868, 3, 566, 147, 9, 396], [42, 2, 9], [40, 5430, 54, 252, 29, 44, 84, 9, 11, 493], [447, 42, 62, 39, 161, 1, 14, 1509, 49, 186, 21, 36, 25], [85, 28, 3951, 6, 111, 38, 5, 63, 756, 11, 2, 56, 63, 8, 150, 4, 199, 193], [142, 30, 1, 5966, 8320, 504, 308, 6, 1630, 5967, 5936, 106], [31, 40, 259, 51, 337, 40, 2, 141, 882, 13, 6, 359, 18, 5, 8, 14, 2, 236], [5, 46, 28, 43, 9, 6, 107, 108, 6, 4, 712, 27, 5, 31, 5, 271, 51, 5968, 5968, 321], [4041, 654, 5525, 12, 2, 3357, 479, 11, 1815, 382, 8244, 1122, 16869, 26], [2272, 1, 289, 182, 297], [7981, 8, 150, 16870], [23, 554, 30, 1, 690, 488, 272, 1878, 142, 4, 795, 30, 1], [15, 4, 237, 184, 182, 484, 722, 1816, 16, 111, 51, 229, 8, 94, 16871, 1934, 343, 3263, 758, 7, 814, 216, 709], [20, 1008, 102, 181, 1645], [20, 768, 3706, 141, 1, 30, 25], [53, 3, 87, 126, 2386, 893, 53, 2540, 1, 124, 2, 19, 4738], [15, 317, 690, 69, 3, 70, 54, 27, 11, 16872, 4, 16873, 140, 3, 101, 1713, 4, 6445, 1, 6, 2833], [55, 154, 265, 51, 8321, 86, 52, 63, 114, 17, 51, 16874, 133, 6, 229, 170, 85, 3, 28, 32, 4, 6480, 285, 1517], [306, 1051, 17, 1653, 21, 4852, 3, 124, 32, 4, 1, 18, 307], [225, 598, 13, 73, 93, 2, 115, 73, 182, 6, 1467, 60, 1, 8, 61, 21, 684, 3601], [3, 516, 10, 77, 14, 4193, 130, 2, 9], [2, 16875, 3784, 8176, 21, 16876, 212, 7886, 8322], [31, 220, 612, 8, 5, 29, 13, 7, 1, 3, 29, 13, 7, 1, 519], [31, 3, 67, 10, 500, 108, 442, 17, 278, 19, 61, 28, 36, 809, 34, 3, 46, 133, 6, 2595, 539, 4, 248], [1163, 9, 49, 20, 16877, 10, 436, 12, 32, 8323], [51, 577, 3, 72, 23, 16878, 25, 146, 258, 54, 2, 1, 1060, 38, 40, 512, 51, 36, 30], [69, 279, 69, 65, 165, 808, 759, 5711, 3407, 8, 766, 166, 5969, 2727, 509, 20, 265, 2, 1177, 42, 1310, 83], [38, 391, 3140, 5], [16879, 1557, 1129, 841, 2548, 8324, 6, 1367, 26, 26, 26], [49, 5606, 6, 13, 4, 732, 16880, 8, 26, 191, 6, 114, 15, 102, 126, 16881, 26], [314, 4720, 16882, 16883, 4699, 1916, 466, 2382, 4462, 8325, 2867, 348], [7655, 16884, 2963, 14, 37, 56, 464, 128], [25, 64, 1354, 9, 88, 208, 1003, 38, 36, 227, 54, 6, 14, 319], [112, 32, 675, 3243, 4, 9, 3, 62, 60, 16, 4, 3615, 287, 289, 182, 704], [38, 78, 44, 2, 93, 115, 26, 40, 316, 35, 2, 1, 82, 186], [16, 1234, 1306, 26, 16885, 8326, 16, 1221, 480, 26, 431, 881, 16, 1060, 2136, 7, 1281, 451, 16, 95, 69, 4437, 6, 16886, 22, 150], [151, 290, 5, 97, 180, 16887, 187, 26], [202, 732, 49, 1128, 102, 793, 7785, 219, 8327, 16888, 6, 16889, 345, 16, 674, 782], [583, 128, 53, 394, 48, 182, 107, 6, 10, 331, 361, 537, 1, 53], [1296, 5970, 1054, 283], [16890, 600, 1316, 841, 3268, 2698, 21, 8328, 763, 16, 1213], [3509, 196, 8329, 621, 8330, 289, 132, 135, 86, 15, 2, 179, 324, 21, 16891], [1378, 49, 5, 16892, 221, 18, 2, 1844, 16, 68, 6, 1654, 1], [14, 1220, 140, 5, 266, 14, 322, 1115, 83], [3, 222, 105, 438, 217, 69, 427, 5734, 357, 238, 438, 2, 8331, 723, 30, 83], [31, 289, 182, 1001, 5, 23, 4686, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 7, 20, 2, 2512, 161, 83], [648, 12, 101, 2, 1, 6, 283], [43, 77, 249, 138, 34, 4417, 32, 252, 28, 1643, 252, 101, 19, 89, 1, 478, 32, 39, 183, 77, 28, 8332], [100, 137, 2, 178, 79, 139, 14, 2, 161, 1], [32, 39, 2670, 8, 66, 96, 29, 44, 106, 21, 39, 9], [25, 14, 1160, 21, 24, 15, 46, 777, 661, 16, 5067, 69, 7, 1, 172, 85, 29, 42, 61, 28, 42, 60, 16893], [258, 1227, 11, 4, 9, 5971], [685, 1848, 41, 1, 235, 13], [38, 5, 309, 34, 2, 89, 1, 294, 11, 80, 4008], [6307, 232, 408, 157, 3243, 1752, 1489, 8, 2753, 514, 355, 1111, 360, 1957, 1013, 6, 117, 3835], [12, 4, 2166, 1, 3, 1507, 55], [16894, 1968, 16895, 159, 1186, 16896, 16897, 855, 16898, 26], [275, 86, 438, 2, 24, 12, 342, 92], [1, 54, 135, 48, 1886, 36, 653, 7706, 21, 4, 398, 16, 263, 16899], [1241, 4740, 3868, 11, 10, 4391, 1, 2935], [3, 90, 38, 2, 25, 191, 17, 3697, 4, 894, 749, 25, 16900], [29, 14, 2, 1, 6, 307, 151, 14, 2, 1104, 68, 8, 151, 2379], [2, 112, 1, 62, 40, 146, 16901, 147, 1357, 343], [1542, 200, 5, 134, 1809, 6, 17, 5, 368], [38, 2, 1, 28, 1220, 8, 3, 65, 99, 342, 6, 14, 590], [18, 186, 5, 16902, 63, 383, 114, 2, 327, 27, 20, 30, 54, 8, 14, 16903], [164, 2, 1, 140, 31, 15, 47, 2, 659, 15, 118, 14, 2495], [462, 15, 2, 392, 8333, 678, 196, 24, 863, 12, 11, 392, 16904, 78, 165, 28, 60, 138, 16905], [111, 523, 144, 21, 86, 5, 63, 119, 16906, 522, 32, 115, 8, 468, 16907, 5972, 49, 5972, 1225], [53, 8334, 16908, 16909, 5, 249, 1], [10, 2781, 41, 756, 123, 13, 16910, 252, 163, 174, 1917, 42, 44, 6, 389, 16911, 16912, 2499, 1], [60, 24, 14, 37, 631, 5, 146, 86, 59, 166, 184, 48, 6, 1266, 16913, 13, 2596, 3, 109, 1332, 4, 2248, 16914], [71, 118, 3, 65, 31, 3, 124, 1508, 661, 16, 16915, 118, 3, 14, 2404, 6, 119, 82, 2, 95, 5973, 461, 28, 1105, 16916], [3, 3215, 672, 2, 607, 16917, 215, 264, 288, 3413, 60, 338, 3, 7743, 4, 1898, 190, 4466, 16, 10, 476, 47], [22, 1, 75, 14, 16918], [19, 16919, 456, 291, 22, 25, 548, 16920, 84, 1, 31, 52, 7, 505, 27, 50], [8335, 21, 4, 16921, 3431, 16, 3775, 69, 458, 126, 337, 6, 3952, 2742, 358, 3125, 21, 1261, 188], [1497, 42, 65, 16922, 56, 163, 16923, 16924, 42], [280, 1896, 31, 5, 44, 990, 27, 217, 806, 15, 20, 148, 653, 29, 14, 2, 161, 1, 8, 316, 166, 111, 11, 254, 14, 2], [85, 277, 4217, 2838, 598, 983, 2135, 7, 40, 132, 6353, 403, 4217, 1546, 20, 11, 2, 16925, 4, 1280, 12, 562], [434, 401, 123, 4, 232, 134, 2911, 8336, 2, 154, 16926, 4, 1543, 49, 33, 2625, 2816], [3, 86, 15, 12, 1165, 54, 329, 6, 924, 2911, 8336, 21, 4, 862, 2527], [197, 3863, 22, 16927, 16928, 2828, 1742, 433, 11, 1382, 225, 47, 33, 98, 919, 21, 388, 2999, 6, 72, 188], [366, 93, 441, 27, 2, 89, 1], [719, 2, 347, 8, 172, 80, 1], [38, 98, 183, 1, 113, 17, 6, 262, 50], [250, 102, 5, 33, 2, 9, 31, 5, 63, 44, 352, 27, 2, 91, 26, 48, 44, 245, 150, 21, 170], [590, 30, 1, 1704, 1992, 1131, 35, 50, 520, 2680, 26], [105, 1070, 18, 43, 9], [53, 625, 723, 58, 3894, 13, 2, 368, 3, 5303, 90, 20, 931], [281, 3346, 16929, 43, 336, 855, 24, 45, 55], [3346, 3581, 16930, 855, 16931, 8, 43, 2125, 16932, 596, 174, 1, 16933], [2, 95, 317, 751, 140, 15, 136, 98, 729, 15, 751, 140, 15, 136, 2, 3037, 6599, 1647], [375, 38, 111, 8004, 68, 2634, 8, 3684, 47, 44, 553, 16, 254, 3, 64, 7, 83], [425, 53, 71, 234, 1, 14, 38, 5, 7025, 76, 35, 11, 4, 16934], [71, 3, 150, 137, 567, 95], [8337, 1647, 26, 275, 460, 2040, 49, 48, 21, 1566, 247, 460, 2040, 49, 9, 26, 76, 1647, 1, 49], [113, 2, 9, 43, 21, 4, 16935, 16, 20, 575, 66, 146, 139, 19, 39, 414], [1409, 41, 48, 409, 188, 89, 1, 12, 4, 101, 184, 7, 3, 13], [1, 23, 1899, 37, 23, 3249, 657, 13, 5974], [1940, 1199, 382, 3323, 16, 1410, 1173, 3367, 4009, 3, 86, 4, 1253, 12, 114, 4, 2458, 2208], [37, 85, 474, 42, 72, 179, 42, 16936, 2556, 15, 27, 1488, 427, 15, 3990], [3, 33, 131, 28, 2009, 613, 26, 44, 2, 417, 180, 331, 392, 16, 89, 1, 7, 3, 222, 19, 3241, 3, 67], [278, 516, 14, 20, 145], [16937, 12, 752, 21, 24], [1066, 3, 911, 6, 255, 2, 6686, 272, 150, 13, 2, 490, 32, 115, 615], [825, 1215, 1813, 6, 2052, 18, 1726, 1706, 140, 159, 824, 136, 98, 1775, 16938, 408, 527], [23, 2, 24], [416, 1646, 21, 10, 646, 777, 329, 27, 170, 52, 33, 2, 1, 695], [5, 8, 17, 398, 415, 60, 179, 864, 16, 45, 69, 136, 295, 165, 6, 58, 27, 126, 16939], [16940, 19, 17, 2, 120, 1, 491, 50, 8, 955, 4064, 22, 12, 57, 12, 14, 121, 92, 16941, 1876, 545], [27, 84, 1, 30, 16942, 16943, 482, 716, 55, 647], [16944, 427, 353, 2, 529, 1067, 37, 515, 16, 39, 849, 16945], [4, 111, 16, 4, 179, 49, 3463, 35, 8, 290, 895, 3000, 234, 49, 5, 18], [5817, 4300, 8338, 1520, 16946, 2913, 3104, 1925, 16947, 491, 243, 104, 16948], [2, 25, 103, 81, 142, 18, 2, 275, 27, 4, 199, 476, 52, 672, 50, 24, 16949], [86, 1349, 12, 16950, 8, 8339, 288, 16951, 49, 3271, 4394], [76, 9, 47, 896, 562, 5, 124, 6, 58, 254], [321, 267, 5, 23, 59, 6, 192, 1266, 11, 39, 9, 33, 6, 626, 980], [3, 41, 4, 799, 21, 4, 3886, 3, 62, 5, 9, 1045, 37, 19, 27, 39, 1354, 658, 16952], [66, 32, 62, 2, 1, 177, 226, 3531], [66, 32, 62, 2, 1, 226, 16953], [3, 41, 4661, 1347, 1173, 3848, 16954, 8, 851], [5975, 969, 767, 12, 56, 2706, 5924], [251, 26, 9, 13, 22, 49, 19, 15, 35, 21, 428, 334, 77, 1936], [93, 16955, 1], [273, 80, 1, 28, 18, 50, 1981, 3, 29, 67, 43, 352], [584, 2, 1221, 5976, 9, 171, 91], [810, 9, 147, 71, 3, 150], [3, 63, 113, 5, 2, 1125, 1, 29, 308, 6, 17], [1, 156, 2885, 327, 16, 2, 1303, 535, 58, 1310, 45, 13, 555, 402, 533, 133, 16956, 4548, 1, 523], [3, 227, 173, 2, 1, 112, 5760], [3, 196, 601, 119, 2, 16957, 16, 957, 2178, 354, 12, 20, 101, 16958], [89, 1], [20, 1680, 21, 4, 761, 1077, 350, 29, 100, 16959, 1224, 20, 26], [915, 11, 8340, 72, 8341, 216, 50, 386, 255, 1106, 1219, 1919, 18, 250, 115, 16, 314, 261, 26], [48, 32, 435, 5621, 287, 6, 16960, 129, 1555, 1222, 21, 4, 508, 1405, 16, 8188, 2, 1514, 52, 3800], [221, 211, 40, 1599, 35, 1176, 703, 1, 8, 3086, 68, 8342], [89, 269], [23, 328, 936, 10, 106, 23, 33, 61, 311, 2, 1, 102, 2693, 130, 3, 16961], [151, 633, 18, 2, 9], [114, 10, 586, 6, 16962, 4, 16963, 2276, 51, 4, 1201, 904, 288, 398, 10, 586, 8, 3, 1, 59, 22, 16964, 16965], [58, 334, 89, 1, 1838, 140, 3, 67, 68], [5, 175, 59, 71, 20, 105, 93, 602, 21, 2, 189, 485, 15, 140, 20, 2, 9], [20, 270, 2, 365, 1, 736], [180, 95, 136, 16966, 26, 3, 47, 669, 88, 3], [291, 9, 292, 324, 16967, 10, 3620], [2854, 21, 2252, 8343, 16968, 355, 123, 1021, 4, 95, 266, 14, 2404, 6, 635, 1046, 1188], [3, 87, 6, 167, 4, 3922, 80, 22, 197, 45, 21, 4, 19, 95], [3, 33, 7019, 10, 8344, 1177, 49, 16969, 31, 621, 65, 21, 2, 89, 1], [16, 1134, 4, 115, 3, 628, 54, 27, 45, 343, 26, 255, 10, 16970, 16971, 3318, 3368, 12, 4, 237, 106, 6, 1571, 173], [3, 13, 14, 668, 8, 32, 34, 15, 2, 1784, 44, 5786, 387, 11, 155, 406], [23, 370, 97, 414, 982, 14, 547, 5, 54, 5977, 650, 7, 97, 436, 39, 9, 171], [33, 424, 5278, 16972, 6, 10, 24, 16973, 108, 18, 11, 473, 1204], [159, 824, 72, 16974, 136, 132, 434, 2562], [285], [78, 41, 32, 4, 315, 9], [4, 184, 59, 1652, 8, 1670, 315, 12, 5918, 49, 9, 46, 43, 8146, 1], [3, 394, 3597, 24, 578, 13, 2, 1241, 8345, 1232], [5, 134, 39, 1, 4, 16975, 469, 36, 152, 208, 13, 2, 5122, 7290, 8, 122, 6, 61, 28, 7, 16976], [5, 146, 14, 2, 669, 1, 6, 100, 2, 535, 175, 28, 5, 54, 16, 16977], [75, 706, 1319, 149, 3, 75, 110, 28, 2, 253, 108], [680, 83, 23, 572, 42, 3, 5829, 5], [4458, 976, 13, 2, 1], [174, 2, 963, 1, 69, 506, 50, 24, 21, 16978, 259, 27, 50, 306, 88, 47, 1859, 311, 4, 308, 951], [92, 100, 17, 1053, 20, 306, 371, 3, 44, 50, 1636, 26, 100, 50, 62, 50, 1246, 12, 11, 2133, 506, 24, 21, 16979], [4, 244, 79, 103, 14, 6, 5190, 545, 20, 16980, 20, 352, 2202, 26, 20, 1401, 1, 3, 2559, 5, 5, 308, 3, 44, 488, 26], [1713, 17, 18, 20, 229, 5, 308, 285, 7433, 49, 1491, 16, 307, 36, 29, 67, 6, 81, 6, 4813, 160], [923, 1468, 1901, 95], [3, 90, 1900, 56], [272, 70, 5, 10, 1], [118, 14, 37, 243, 37, 239, 1, 118, 14, 2792, 71, 118, 5, 150, 31, 36, 16981, 4, 1881, 16, 6128], [509, 10, 767, 1, 57, 10, 476, 427, 5934], [39, 25, 9, 8, 39, 1, 3279], [26, 23, 362, 22, 175, 103, 1367, 5, 82, 16982, 1915, 83], [219, 7748, 12, 33, 2, 666, 16, 90, 388, 2656], [33, 124, 2, 2535, 125, 10, 500, 163, 40, 1093, 17, 693, 40, 12, 10, 500, 251, 552, 693, 3, 110, 16983, 21, 22, 1], [2, 138, 136, 2, 611, 164, 84, 343, 12, 2, 780, 84, 730, 12, 879, 84, 2233, 98, 1034, 84, 237, 228, 2, 24, 3325, 188], [31, 5, 7472, 20, 5329, 5540, 710, 211, 4, 480, 227, 875, 3, 103, 242, 102, 10, 347, 973, 18, 4, 689, 8, 1090, 95, 972], [80, 16984, 16985, 160, 613, 774, 8030, 6317, 1133, 16986, 26, 379, 16987, 738], [22, 57, 78, 9, 67], [1, 57, 2372, 12, 22], [750, 117, 2580, 8, 16988, 16989, 16990, 424, 6, 186, 18, 2908, 6, 382, 6640, 1920, 2, 1012, 888], [2262, 8346, 2, 9, 30, 25, 8, 1497, 3, 94, 170, 272, 737, 170, 13, 143, 161, 1, 52, 12], [5978, 2524, 8347, 123, 377, 1387, 288, 36, 1705, 1581, 4372, 84, 436, 26, 265], [241, 16991, 3, 75, 397, 20, 1801, 1337, 1916, 34, 3, 64, 20, 2332, 16992, 151, 1090, 5, 8348, 8348, 32, 1477], [1, 61, 6, 2791, 5, 44, 197, 11, 4, 2428, 55, 367, 2291], [29, 14, 2, 1, 6, 217, 69, 63, 54, 1, 350], [39, 379, 534, 14, 1122, 11, 4, 2808, 225, 49, 294, 7725, 1683, 304, 634, 39, 25, 258, 54, 7, 24, 107], [22, 1, 137, 99, 209, 4741, 16993], [295, 7, 4, 3053, 200, 11, 126, 608, 16, 4, 3980, 1003, 307, 4265, 1535, 642, 73, 2, 285], [2422, 25, 151, 109, 257, 147, 9, 35], [20, 3059, 12, 2, 161, 1], [2, 95, 33, 4507, 173, 10, 3716, 3220, 278, 516, 28, 5081, 123, 546, 6311, 21, 201, 115, 344, 130, 1924, 7, 361], [526, 944, 58, 1, 96, 64, 2399], [192, 102, 27, 2, 4267, 450, 35, 498, 972, 839, 349, 35, 6, 7, 489, 13, 16994, 236, 5, 29, 62, 17], [5975, 969, 767, 12, 56, 2706, 56], [22, 12, 10, 2868, 1], [7, 473, 213, 423, 82, 1899, 467, 1247, 8, 2367, 213, 206, 24, 3203, 119, 684, 853, 48, 24, 1852], [78, 14, 1955, 20, 25, 3313, 5961, 2842, 52, 54, 116, 1831, 246, 1, 2426, 1283], [3, 1100, 7, 3, 1622, 10, 2189, 2355, 33, 119, 60, 24, 8, 632, 5, 68, 16995, 559, 1532, 6, 16996, 15], [38, 5, 1849, 18, 50, 517, 88, 192, 137, 27, 50, 24, 27, 97, 3845, 3178], [156, 2, 1102, 16, 5864, 11, 4, 1211, 38, 418, 79, 1740, 9, 88, 1862, 18, 80, 138, 445, 351, 6, 4, 199, 323, 16997, 188], [3597, 216, 99, 239, 5733, 3803, 6, 48, 44, 132, 2, 9, 51, 60, 446, 11, 50, 1068], [3, 293, 10, 265, 29, 4728, 17, 123, 107, 54, 183, 3, 41, 99, 239, 893, 6, 28, 9, 7866, 27, 980], [8349, 315, 2, 104, 21, 48, 396, 84, 215, 226, 469, 52, 41, 1946], [90, 181, 4, 729, 2140], [2275, 2, 412, 7, 81, 56, 230, 4, 178, 3198], [287, 101, 137, 5876, 178, 13, 960, 888, 178, 26, 4689, 1187, 36, 29, 137, 112, 178, 13, 1693, 863, 2554, 201, 74, 16998], [7, 10, 1, 91, 3, 300], [71, 1888, 49, 5, 3, 176, 28, 511, 729, 82, 511, 111, 2979, 1261], [1646, 225, 16999, 406, 29, 107, 54, 190], [3, 90, 38, 111, 72, 5, 75, 17000, 2, 282, 71, 1, 71, 1121, 23, 101, 3292, 1024, 21, 10, 285, 1272, 15, 32, 59], [116, 295, 2394, 130, 2, 8350, 1376, 418, 69, 63, 137, 17001], [34, 88, 69, 12, 61, 6, 3548, 4, 832, 1, 8351], [38, 4, 56, 558, 12, 37, 392, 5, 63, 1240, 1469, 4116, 17002, 17003], [3, 67, 2, 1245, 269], [180, 517, 1, 156, 2379], [22, 244, 979, 12, 14, 878, 6, 14, 2, 666, 16, 7333, 24, 27, 43, 17004], [4, 673, 47, 13, 2229, 5, 25, 276, 683, 8352], [1918, 2278, 57, 2467, 46, 146, 14, 1365], [999, 12, 105, 256, 6, 382, 13, 1305, 3, 397, 27, 3512], [1410, 1137, 12, 4, 697, 3876, 16, 57, 582, 38, 5, 134, 2, 564, 25, 60, 285], [41, 13, 546, 9, 292, 482], [85, 58, 111, 44, 2, 437, 27, 315, 111, 62, 57, 19, 2021, 3, 41, 2, 437, 27, 5, 344, 9, 92, 57], [779, 121, 43, 24, 534, 1077, 10, 381, 331], [2237, 9, 46, 2395, 160, 2, 25, 69, 359, 18, 84, 77, 1212, 106, 8, 33, 291, 35, 27, 1167], [275, 156, 81, 59, 71, 18, 446, 126, 1574, 8, 1256, 49, 550, 1, 20, 395, 12, 96, 45, 1168], [8353, 4, 1132, 440, 674, 782, 1183, 641, 2586, 1215, 11, 17005], [591, 12, 8354, 1783, 2152, 12, 248], [3823, 854, 9, 5, 62, 23, 4, 91, 9], [446, 2914, 272, 430, 5, 1, 422, 1852], [3, 62, 2804, 16, 9, 11, 64, 27, 36, 25, 34, 15, 14, 4, 199, 1, 172, 25], [53, 146, 1827, 27, 280, 5974, 53, 8355, 579, 66, 146, 349, 35, 2422, 24, 177], [4, 774, 41, 22, 1, 17006], [1019, 1, 46, 45, 3, 28, 240, 314, 8, 1090, 240, 138], [33, 79, 17, 2, 158, 149, 7, 57, 42, 109, 67, 6, 72, 51, 4, 450, 16, 4, 115], [148, 1196, 11, 64, 27, 32, 76, 9, 38, 23, 27, 2165], [3, 64, 10, 730, 34, 3, 452, 110, 87, 591, 6, 429, 7, 355, 17007, 7, 9, 12, 28, 1041, 17008, 26], [3, 109, 29, 14, 238, 9, 17009, 3, 119, 66, 32, 7519, 17010], [20, 91, 1937, 149, 5, 70, 170, 150, 13, 52, 146, 3426, 27, 166, 3095, 139, 14, 2, 9, 26, 139, 17011], [721, 553, 16, 10, 253, 63, 72, 36, 19, 1002, 78, 9, 109, 70, 22, 2, 17012], [60, 16, 78, 9, 2821, 14, 37, 834, 8, 75, 110, 294, 1002, 232, 522], [237, 91, 182, 7487, 19, 50, 117, 11, 4, 887, 26, 10, 4010], [222, 5, 333, 6878, 82, 14, 2, 171, 1], [31, 3, 94, 2, 1, 107, 51, 17, 13, 22, 7, 196, 3, 41, 6210, 710, 6, 28, 35, 8, 28, 117, 17013, 4162, 116, 1817], [2928, 92, 100, 28, 22, 169, 3, 41, 7775, 41, 17, 43, 9, 33, 263], [1588, 42, 49, 96, 2, 1], [3116, 91, 12, 19, 56, 742], [178, 129, 1, 1292], [3, 67, 2, 112, 575, 43, 178, 43, 308, 43, 234, 9, 33, 17, 8, 5], [595, 88, 29, 945, 141, 312, 68, 2634], [23, 2, 104], [7, 1777, 5, 29, 791, 9, 5, 2354, 240], [55, 23, 102, 22, 17014, 1, 17015], [43, 1, 165, 122, 6, 19, 27, 10, 77, 149, 3, 103, 61, 102], [109, 1], [523, 42, 1644, 140, 174, 1644, 1], [38, 5, 65, 13, 56, 8, 217, 2558, 5], [23, 807, 3, 266, 134, 2, 1, 2, 106, 74, 921, 23, 122, 114, 279, 624], [65, 51, 97, 177, 25, 2, 104, 321, 1180, 4, 992, 26], [5, 109, 49, 2, 104, 31, 5, 72, 7, 1141, 47, 1758, 139, 194], [5816, 3711, 1295, 49, 56], [38, 159, 824, 121, 8356, 1215, 33, 99, 2762, 21, 4, 4696, 17016], [10, 238, 70, 17, 61, 6, 1860, 17017, 233, 286, 3802, 252, 1, 262, 17, 108], [22, 1, 86, 65, 13, 1350], [38, 23, 1494, 76, 1, 28, 5964], [351, 7523, 17018, 9], [31, 74, 29, 62, 5, 88, 5, 49, 48, 1073, 18, 1445, 1], [747, 155, 564, 30, 2400, 12, 2, 564, 30, 1, 7, 12, 1577, 113, 170, 71, 112, 52, 4650], [272, 257, 80, 161, 379, 30, 705, 17019, 9], [3, 13, 93, 441, 26, 89, 1, 147, 63, 694, 15, 35], [2097, 9, 2445, 7336, 17020, 5979, 17021, 3405, 17022, 17023, 4742, 17024, 26], [111, 64, 6, 122, 6, 3013, 2419, 367, 83, 3, 121, 254, 92, 57], [17025, 1, 17026, 160, 4011, 177, 14, 44, 17, 37, 2281], [105, 430, 150, 21, 2, 171, 83], [7, 1, 69, 4, 45, 11, 80, 387, 46, 45, 11, 10, 17027, 1002], [38, 7, 1253, 72, 17028, 34, 5, 94, 170, 448, 3830, 761, 27, 32, 84, 9], [38, 5, 623, 5, 1415, 4, 1253, 6, 20, 436, 661, 16, 20, 234, 9], [339, 1, 175, 45, 13, 1600, 68, 6, 81, 3608, 292, 106, 2, 115], [78, 67, 1797, 1, 1428, 89, 34, 75, 110, 349, 1595, 9], [51, 1576, 8309, 250, 232, 1199, 4703, 52, 121, 52, 452, 4732, 11, 1519, 2496, 1373, 188], [2, 1584, 213, 206, 77, 469, 8082, 54, 1059, 4012, 8, 3404, 4743, 108, 6, 108, 8, 47, 1742, 82, 1519, 21, 15], [180, 546, 132, 56, 21, 213, 92, 55, 15, 2, 1641, 4703, 92], [1206, 48, 939, 51, 32, 288, 78, 475, 59, 1206, 272, 340, 28, 9], [493, 10, 45, 35, 27, 274, 1092, 1], [801, 211, 66, 1, 30, 17029, 12, 468, 50, 148, 3306, 40, 87, 6, 157, 4, 180, 77, 1277, 108, 962], [122, 6, 17030, 17, 8, 66, 2587, 9], [23, 33, 2, 1975, 30, 252, 7, 136, 43, 9, 8, 582, 6, 14, 356, 155, 469, 11, 2, 288], [13, 2, 1165, 515, 52, 87, 2, 1720, 298, 35, 18, 240, 157, 4, 743, 35, 18, 240, 191, 2, 24, 25, 1378, 6, 97, 1, 53], [4, 1593, 12, 727, 1805, 22, 658, 326, 229, 17031, 16, 14, 56], [55, 1103, 1, 30, 156, 70, 2, 17032, 65, 51, 17, 30, 25], [38, 161, 340, 121, 324, 224, 975, 7, 3, 46, 41, 43, 1, 57, 7, 2, 148, 308, 25, 10, 879, 12, 10, 125, 26], [203, 1, 208, 13, 40, 487, 253, 895, 289, 156, 67, 2, 203, 1, 6, 253, 307], [17033, 282], [53, 257, 4, 24, 11, 37, 219, 50, 45, 96, 505, 82, 2, 449, 5897], [898, 65, 13, 52, 118, 973, 84, 17034, 1925, 129, 2, 8021, 21, 2, 1, 8, 40, 125, 50, 91, 251], [23, 3419, 80, 1, 42, 214, 73, 45], [38, 5, 175, 17035, 33, 21, 528, 26, 2, 1, 131, 1794, 4, 501, 123, 28, 17036], [70, 35, 17037, 27, 32, 10, 1, 92], [22, 12, 21, 4, 1, 69, 137, 1566, 57, 35, 9], [9, 14, 18, 60, 17038, 3650, 12, 17039, 43, 1, 7, 3193, 25, 5, 41, 201, 265, 27, 69, 484, 80, 347, 26, 96, 255, 17040], [304, 1638, 115, 21, 24, 12, 13, 14, 2306, 8, 65, 51, 32, 4, 265, 137, 619, 82, 20, 4867, 4542], [42, 182, 204, 2, 3477, 18, 4, 6126, 8, 86, 148, 57, 31, 7, 25, 47, 18, 84, 193, 6, 28, 60, 24], [3587, 7, 23, 2, 883, 781, 26, 338, 76, 9, 408, 16, 20, 4545], [85, 58, 4, 17041, 109, 179, 77, 156, 28, 4, 247, 13, 8, 1088, 18, 3961, 177, 35, 8, 142, 126, 406, 2], [2642, 678, 68, 16, 78, 8357, 9, 216, 22], [4, 17042, 92, 136, 98, 732, 1122, 2777, 535, 16, 1316, 49, 18, 4, 137, 1304, 51, 37], [3, 44, 43, 9], [17043, 146, 14, 56], [92, 52, 17044, 55, 19, 7, 9, 8, 50, 565, 35, 24], [17045, 12, 415, 4, 244, 17046, 1, 31, 5, 29, 108, 4, 19, 35], [160, 29, 302, 43, 1], [85, 78, 46, 113, 17, 379, 1021, 1574, 65, 165, 88, 588, 55, 17047, 104], [3, 150, 89, 21, 189, 7, 134, 126, 504, 4, 360, 8, 4, 1, 96, 557, 76, 13, 4564, 13, 148, 57, 127, 58], [4225, 8358, 26, 4740, 8359, 398, 124, 1, 8277, 124, 127, 130, 8360, 464], [1035, 267, 5, 10, 1214, 96, 81, 37, 2, 171, 1, 3, 29, 13], [39, 638, 1240, 108, 245, 8, 155, 1, 54, 135], [4185, 4185, 9], [22, 12, 284, 43, 4046, 479, 4282, 2, 4046, 1159, 5980, 8217, 892, 4046, 47, 17048, 574, 6477, 71, 1768, 305, 1531, 1437, 22, 12, 4674, 236], [3, 90, 94, 287, 1281, 18, 59, 71, 36, 222, 19, 495, 720, 422, 3392, 30, 83], [375, 4, 17049, 17050, 4360, 168, 3015, 12, 70, 1387, 287, 1281, 2, 190, 5104, 748, 6, 1646, 11, 17051, 1188], [39, 2317, 940, 9, 46, 334], [161, 9], [1783, 1493], [159, 925, 200, 4, 684, 1857, 1611, 4, 117, 193], [63, 14, 17052, 2018, 166, 111, 38, 36, 67, 6, 14, 1047, 2018, 4, 68, 36, 279, 1261], [3151, 5, 679, 94, 4, 120, 265, 7, 79, 5, 158, 18, 79, 16, 17053], [17054, 12, 298, 1060, 18, 7, 24], [22, 9, 62, 7, 48, 50, 347, 805], [3735, 514, 50, 1013, 51, 4, 704, 17055, 1615, 592, 15, 26, 661, 16, 33, 134, 15, 108, 52, 502, 15, 6, 50, 73, 2, 382, 3812, 951], [123, 17056, 17057, 11, 26], [10, 1, 4296, 10, 25, 10, 25], [186, 865, 12, 3275, 20, 614, 6, 175, 36, 87, 610, 865, 21, 9, 58, 1123, 54, 21, 1123, 54, 32, 19, 717], [10, 1074, 136, 201, 937, 106, 4, 17058, 16, 4, 17059, 5524, 1474, 17060, 5981, 36, 363, 6, 4, 8333, 3, 313, 95, 188], [1311, 69, 56, 126, 373, 2323, 211, 2, 17061, 17062, 12, 2, 19, 17063], [3, 75, 442, 4, 670, 565, 22, 595, 379, 720, 116, 568, 4, 2992, 21, 17064, 26], [278, 13, 6, 1222, 2, 5536, 1918, 6, 3015, 21, 305, 864, 16, 45, 7117, 970, 8, 84, 144, 7755, 709], [518, 16, 287, 2223, 1809, 829, 123, 2371, 5982, 984, 518, 16, 1033, 144, 4293, 123, 4, 17065, 17066], [68, 127, 82, 8361, 452, 14, 100, 17067, 400, 11, 3698, 2025, 140, 374, 32, 59, 596], [23, 152, 192, 10, 373, 8362, 17068, 2555, 8, 4, 101, 1058, 17069, 17070, 559, 14, 2, 24, 973, 102, 4, 692, 79, 7062], [243, 1987, 115, 180, 517, 283], [221, 19, 1255, 151, 33, 119, 24, 793, 4, 17071, 123, 4, 8363, 2318, 4584], [1582, 235, 1, 214, 51, 17, 140, 36, 65, 13, 1305, 29, 924, 17, 924, 20, 5983, 26], [1950, 498, 4, 27, 2844, 551, 408, 211, 2, 17072], [66, 502, 2, 5817, 15, 8364, 43, 127, 16, 22, 17073, 12, 8365, 56, 26], [45, 9, 448, 18, 610, 3795, 8366], [4164, 17074, 359, 27, 2, 718, 8, 33, 41, 2, 2204], [4, 883, 3459, 17075, 8, 872, 51, 922, 166, 38, 36, 94, 268, 2907, 605, 18, 2, 17076, 4688, 18, 2, 17077, 17078, 312], [3, 29, 13, 4, 1032, 117, 92, 15, 626, 17, 55, 85, 12, 15, 190], [3, 175, 13, 2, 158], [151, 105, 86, 2, 1, 12, 32, 4056], [249, 10, 138, 1, 48, 101, 49, 5, 17079, 5, 49, 85, 1443, 907, 12, 544], [3, 41, 1569, 437, 34, 2, 1, 46, 17080, 7, 568, 21, 5, 1, 25, 99], [736, 65, 51, 5, 1532, 6, 14, 2, 1, 55, 417, 122, 464, 281], [479, 68, 26, 4, 77, 747, 4, 904, 69, 46, 14, 2, 9], [31, 5, 2, 9, 18, 4, 1213, 5, 2, 9, 17081], [1264, 715, 17082, 3529, 5, 17083, 1962, 1, 176, 15, 17084], [53, 366, 125, 2, 1, 11, 1966, 8, 100, 50, 137, 451, 3, 394, 947, 40, 227, 18, 1971, 74, 60, 981, 45, 53], [148, 3636, 30, 167, 7, 9, 18, 446], [2985, 3816, 271, 27, 2, 6351, 1, 55], [5, 161, 185, 30, 1, 3, 46, 172, 125, 5], [366, 427, 2, 178, 5, 222, 28, 204, 269, 94, 269, 17085, 29, 366, 31, 20, 48, 2, 7956, 78, 49, 4, 540, 188], [31, 20, 18, 4, 699, 6, 954, 8, 96, 150, 1584], [2950, 6, 22, 17086, 5, 2, 1, 30, 25], [31, 5, 2, 95, 313, 15, 35], [25, 596, 1, 17087], [112, 25, 420, 11, 2259, 1, 25, 70, 2, 2149, 218, 36, 48, 109, 125, 4, 4744], [23, 370, 34, 60, 111, 226, 49, 33, 172, 185, 60, 915, 198, 28, 2, 8367, 1, 491, 21, 226, 265, 13], [1993, 81, 6, 20, 166, 894], [1, 14, 81, 59, 36, 498, 74, 309, 27, 155, 25, 36, 81, 1836, 1, 5, 328, 309, 13, 885, 106, 330], [77, 14, 1973, 81, 59, 17088, 17089, 1, 5, 87, 6, 430, 22, 3717, 433, 23, 59, 6, 313, 5, 251], [112, 25, 100, 2, 112, 1, 1266, 250], [2, 606, 25, 29, 64, 357, 31, 5, 46, 84, 115, 68, 17090, 17091], [2378, 1920, 12, 152, 229, 60, 232, 2, 184, 74, 268, 51, 4, 1297, 2189, 331, 390], [263, 79, 275, 9, 21, 472, 73, 2132, 8, 534, 21, 923, 210, 17092, 76, 68, 17093], [17094, 6, 44, 2, 930, 18, 254, 3, 560, 29, 1233, 7, 140, 2, 414, 5941, 6, 2, 352, 2535, 7, 196, 50, 24, 12, 458, 1561], [296, 67, 2, 202, 189, 7, 6717, 255, 1488, 8, 136, 17095, 1, 7, 2, 1601, 781, 18, 2686], [38, 217, 405, 126, 56, 1523, 11, 10, 706], [1, 75, 1056, 2, 688, 1435, 1341, 34, 67, 2, 1296, 1435, 138], [17096, 999, 50, 1, 25, 5, 94, 50, 433, 54, 551, 57, 58, 5, 58, 2208], [17097, 473, 755, 4, 215, 755, 8, 2, 470, 16, 197, 56, 33, 21, 17098], [286, 329, 27, 78, 6937, 2215, 8, 789, 1295, 2215, 248], [57, 2, 83], [155, 25, 154, 9, 12, 143, 244, 25, 206, 9], [10, 443, 1510, 16, 228, 12, 4, 68, 162, 202, 8368, 5984, 8, 4013, 120, 111, 258, 1800, 236], [120, 77, 438, 202, 189, 69, 90, 202, 2755, 8, 36, 100, 126, 185, 30, 120, 504, 81, 45, 8, 72, 312], [122, 6, 534, 1127, 17, 13, 4457, 1158, 1, 28, 11, 4, 895], [48, 59, 6, 512, 22, 24, 272, 257, 84, 231, 173, 4, 17099, 965, 188], [7, 9, 1131, 4, 413, 412, 497, 128, 78, 902], [190, 231, 8, 15, 2, 988], [3, 90, 38, 25, 28, 214, 218, 5, 19, 36, 77, 38, 109, 52, 198, 14, 243, 5, 229, 170, 7, 1, 2770], [4, 247, 13, 821, 6, 14, 284, 1, 5731, 17100, 5429, 2031, 2927, 5643, 4697, 8369, 7676, 8010, 17101], [496, 29, 505, 630, 167, 2, 3302, 129, 2, 4145, 17102, 6, 81, 56, 2208], [496, 17103, 4180, 17104, 17105, 56, 81, 98, 17106, 985, 2, 17107, 1876, 26], [496, 1098, 891, 167, 2, 8370, 419, 18, 84, 679, 8371, 51, 232, 1330, 26], [17108, 124, 4, 832, 9, 4333, 9, 65, 13, 36, 47, 11, 1197, 1002, 124], [382, 274], [17109, 512, 1291, 3593, 69, 1183, 8, 3402, 792, 170], [1600, 690, 162, 5, 61, 116, 156, 98, 1034, 255, 2, 232, 17110, 160], [1987, 115, 12, 33, 98, 1037, 1503, 21, 1, 1009], [1035, 120, 248], [38, 5, 8, 20, 228, 49, 81, 8, 7, 1, 78, 5890, 29, 19, 27, 294, 722], [38, 2, 1, 28, 5, 19, 35], [191, 84, 265, 31, 36, 1051, 98, 1232, 21, 4, 826, 52, 270, 2, 494], [79, 17, 2, 351, 95], [108, 38, 3, 47, 2, 379, 7543, 2622, 136, 1017, 6, 4, 280, 66, 96, 11, 22, 1], [191, 17111, 230, 4, 178, 31, 3944, 13, 6, 14, 2, 4745, 361, 17112, 31, 4, 232, 182, 191, 17, 3, 3694, 34, 23, 2, 523], [113, 17, 361, 71, 4402, 17113, 12, 4, 237, 629, 16, 32, 106, 88, 61, 194, 17114, 5, 17115, 2348, 261, 838], [1703, 79, 15, 4, 7258, 2269, 17116, 8, 48, 185, 24, 518, 47, 415, 127, 2424, 130, 17, 8, 857], [1895, 59, 17117, 115, 11, 2, 707, 39, 9, 506, 24, 21, 17118, 2, 429, 649], [31, 5, 46, 19, 17, 1090, 17, 74, 608, 17, 20, 1242, 12, 1555, 83], [8372, 17119, 5980, 17120, 54, 22, 9], [39, 9, 14, 19, 32, 16, 263, 956, 3, 41, 1199, 21, 32, 4, 5985, 25, 80, 1, 19, 5986, 25], [18, 60, 112, 25, 45, 60, 1, 87, 17121], [3, 29, 156, 28, 551, 8, 433, 54, 34, 38, 3, 58, 38, 200, 36, 192, 70, 207, 7454, 2050], [53, 77, 7, 19, 108, 5916, 53, 20, 215, 68, 47, 56, 37, 135], [60, 16, 5, 1, 652, 1484, 6, 255, 2045, 385], [39, 9, 54, 16, 829], [107, 28, 80, 9], [3, 156, 262, 10, 5494, 13, 757, 79, 17, 3, 41, 4, 17122], [10, 1, 41, 322, 24], [4, 237, 193, 6, 70, 2, 837, 58, 256, 12, 6, 113, 170, 52, 75, 58, 254], [4124, 106, 459, 1654, 4, 1, 168, 76, 199, 17123, 4231, 18, 32, 1654, 16, 50, 17124, 3, 75, 27, 5, 17125, 17126], [577, 3, 46, 291, 1], [38, 3464, 121, 5538, 10, 2078, 466, 1, 79, 17, 6215], [3500, 2, 206, 17127, 30, 1], [113, 76, 1, 151, 156, 14, 20, 3067], [66, 92, 62, 127, 59, 1347, 8, 71, 206, 4, 1681, 12, 130, 57, 582, 11, 26], [463, 532, 13, 8373, 8, 1, 5, 532, 13, 8374], [179, 2844, 853], [26, 5, 189, 299, 17128, 8, 3577, 77, 220, 17129, 40, 1396, 22, 1, 3935, 26], [1749, 96, 2, 368, 55, 37, 57, 58, 5, 175, 31, 5, 468], [2966, 518, 253, 123, 242, 142, 5765, 64, 254], [1862], [69, 499, 375, 39, 1], [34, 7, 20, 260, 306, 1168, 7, 46, 10, 282], [7789, 17130, 5978, 2524, 8347, 123, 377, 1387, 288, 36, 1705, 1581, 4372, 84, 436, 26, 265, 26], [53, 39, 9, 276, 107, 233, 61, 3, 150, 4798, 177, 55], [4978, 2, 9], [275, 92, 2, 115, 29, 13, 6, 58, 393, 2452, 140, 26, 5, 25, 2468, 59, 15, 13, 1, 26], [23, 11, 64, 27, 1386, 3456, 8, 17131, 3, 29, 64, 39, 9], [34, 31, 5, 2, 9, 58, 350, 3, 46, 1105, 350, 28, 15, 11, 34, 29, 505, 217, 11, 4, 4642, 14, 344, 35, 2763, 15], [159, 1163, 215, 268, 323, 103, 14, 17132, 323, 21, 4, 8258, 16, 69, 107, 35, 17133], [52, 175, 13, 2, 1, 291, 84, 548], [25, 2468, 13, 9, 247, 16, 240, 1], [576, 1, 67, 701, 48, 17134, 112, 287, 67, 538], [803, 8375, 915, 49, 1923, 8376, 8, 17135, 8376, 57, 195, 3, 61, 6, 14, 38, 5, 309, 611, 236], [29, 753, 3, 41, 4, 2565, 1], [7759, 160, 803, 232], [875, 8, 190, 17136, 1441], [95, 16, 2, 1508, 2230, 17137, 9, 228, 27, 319, 1150, 287, 14, 27, 166, 1150, 5987, 1543, 14, 27, 1543], [23, 37, 549, 235, 587, 17138, 8, 18, 503, 16, 7, 124, 6, 17139, 17, 6, 2, 828, 901], [39, 1, 49, 2972, 602, 461, 4, 1980, 55, 148], [3, 168, 6, 778, 9, 92, 15, 17140], [23, 169, 807, 91, 39, 1, 75, 58, 8051, 21, 17], [8377, 16, 10, 1, 1511, 267, 26], [17, 10, 1, 231, 12, 18, 3461, 7, 17141], [349, 35, 18, 10, 500, 70, 7, 1, 214], [2563, 11, 4, 24, 13], [2811, 375, 6, 2935, 35, 18, 17142, 8, 5988, 230, 4, 391, 303, 76, 32], [17143, 14, 17144, 5, 41, 9, 11, 511, 1890, 1803], [1904, 12, 248], [1336, 12, 1439, 6, 14, 157, 11, 4, 56, 63, 1370, 73, 1904, 6, 14, 157, 11, 2, 3239, 1370, 73, 4, 8378], [367, 3, 64, 50, 13, 24, 169, 441], [253, 17145, 3300, 33, 800, 22], [27, 17, 83], [85, 32, 39, 9, 1174, 14, 315, 92, 128], [17146, 24, 21, 4, 250, 106, 1185, 32, 3, 44, 6, 72, 12, 188, 3, 86, 3, 600, 44, 2, 154, 443, 17147, 3677], [1379, 5, 49, 417, 77, 36, 103, 14, 1, 6, 350, 31, 5, 49, 98, 1034, 77, 103, 67, 20, 1270, 53], [5206, 2774, 18, 468, 1414, 21, 10, 3919, 34, 11, 2127, 3, 514, 32, 4, 1414, 37, 3, 222, 19, 341, 952], [17148, 2, 320, 16, 39, 280, 3, 428, 279, 59, 10, 77, 8, 3, 64, 876, 15, 48, 79, 14, 2, 24, 15, 79], [159, 925, 12, 2, 2112], [29, 14, 2, 24], [2376, 1, 188], [71, 1, 65, 1497, 36, 465, 126, 323, 11, 143, 489], [17149, 26, 1002, 7, 162, 4, 9, 51], [79, 50, 841, 184, 11, 143, 17150, 100, 50, 62, 147, 24, 18, 80, 17151], [4045, 1, 90, 42, 34, 96, 253, 17152], [25, 147, 29, 28, 43, 24, 49, 1326, 4, 68, 17153, 39, 180, 74, 183, 1820, 3959, 76, 127, 4593, 88, 4], [667, 16, 42, 1, 99, 206, 21, 17154], [32, 2, 25, 87, 12, 1946, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 19, 2, 1], [43, 319], [75, 302, 553, 16, 39, 1, 29, 302, 553, 16, 39, 9], [1470, 39, 95, 17155, 94, 31, 5, 63, 1251, 4, 5441, 15, 63, 14, 2433, 110, 27, 2148, 95, 194, 17156, 26], [28, 129, 2, 1964, 1924, 12, 13, 1501, 4, 269, 8179, 5, 44, 6, 100, 61, 51, 60, 446, 11, 748, 6, 420, 17157], [22, 12, 57, 4, 158, 29, 13], [4011, 177, 1, 37, 17158, 32, 7, 3390, 26, 45, 233, 3, 293, 432, 372, 13, 50], [3, 222, 31, 3, 122, 34, 10, 169, 150, 165, 88, 245, 24, 289, 182, 124], [33, 17159, 115, 444, 232, 4123, 8, 8379, 17160], [29, 14, 2, 24, 1071, 4, 5989, 64, 4, 5989, 1512, 4, 5989], [22, 187, 12, 96, 81, 1084, 19, 63, 5, 33, 28, 2624, 2031, 330], [33, 22, 68, 387, 63, 114, 20, 1], [3, 67, 60, 2796, 9, 6449], [22, 104, 12, 2, 161, 701, 835, 19, 170], [3, 297, 57, 5, 65, 13, 48, 17161, 81, 45, 5, 1751, 65, 1], [38, 3, 467, 60, 17162, 265, 26, 1853, 174, 2, 104, 769], [17163, 12, 2, 5798, 1164, 206, 918, 197, 410, 337, 5111, 8, 52, 210, 67, 6, 662, 54, 27, 5, 903, 1082, 1432], [17164, 87, 6, 271, 11, 84, 3496, 8, 176, 471, 8380, 6, 286, 5, 29, 67, 15, 27, 4, 180, 177, 5, 1751, 17165, 30, 918], [31, 3, 29, 28, 1122, 21, 4, 1916, 66, 152, 44, 60, 437, 405, 4, 104, 847], [204, 22, 918], [31, 22, 47, 314, 261, 1905, 481, 430, 73, 9, 128], [597, 35, 11, 4, 561, 134, 17, 235, 1], [19, 147, 1], [3, 13, 665, 1229, 125, 89, 1], [15, 46, 43, 9, 11, 10, 1009], [694, 35, 100, 28, 314, 100, 28, 314, 1], [132, 429, 32, 10, 164, 57, 3285, 201, 3040, 1, 132, 1509, 32, 10, 164, 1, 46, 2, 1162, 201, 17], [22, 1, 87, 6, 14, 1410, 1173], [78, 9, 118, 105, 28, 793, 10, 682], [89, 1, 50, 764, 530, 2442, 2442, 7, 10, 323, 9, 17166, 26], [321, 121, 3296, 77, 24, 578, 13, 764, 8, 17167, 55], [3, 33, 131, 14, 703, 26, 17168, 3121, 834, 1, 41, 15, 61, 962], [242, 20, 1, 30, 562, 5, 41, 256, 6, 72, 59, 17, 844, 307, 17169, 387, 1102], [813, 4746, 4718, 5314], [5, 662, 54, 27, 2, 9, 5, 152, 227, 173, 2, 9], [20, 24, 65, 13, 15, 309, 2604, 707, 1712], [2, 4803, 7249, 11, 2, 56, 63, 6, 28, 39, 2814, 2957, 846], [2363, 12, 794, 796, 1], [3, 44, 43, 17170, 21, 111, 69, 1, 59, 3019, 36, 28, 943, 17171], [306, 1378, 582, 6, 17172, 17173, 206, 228, 8381, 5, 168, 6, 14, 17174, 17, 993, 7, 1664], [648, 2, 83, 29, 2417, 57, 5, 75, 17175], [3508, 31, 5, 46, 2, 9, 28, 35, 54, 10, 5990], [17176, 8382, 41, 50, 554, 8, 92, 23, 152, 44, 2, 158, 17177], [757, 30, 25, 1986, 1452], [2472, 945, 8, 286, 3482, 22, 9, 11, 135], [146, 176, 39, 9, 18, 446], [1074, 688, 12, 56, 194, 17, 3057, 35], [40, 1135, 8383, 6, 555, 4, 269, 8, 65, 57, 52, 200, 22, 269, 112, 483], [40, 1460, 39, 9, 71, 6, 1856], [114, 54, 4, 56, 51, 264], [38, 42, 839, 11, 4, 24], [69, 499, 90, 22, 1, 25], [140, 52, 47, 2, 187, 17178, 29, 14, 2, 838], [1238, 1016, 1347, 3353, 108, 18, 17179, 123, 850], [17, 8097, 3, 86, 151, 28, 102, 570, 390, 8, 28, 2, 93, 264, 17180, 17181, 8384, 390, 1, 48, 6134], [1193, 72, 275, 3323, 47, 565, 288, 304, 21, 98, 354, 5597], [4672, 3, 47, 122, 6, 119, 53, 2597, 5, 121, 15, 47, 1, 54, 135, 3, 229, 35, 21, 4087, 26], [169, 75, 303, 5, 64, 37, 3, 29, 389, 21, 43, 24], [69, 175, 27, 215, 264, 17182, 74, 138, 18, 36, 1238, 22, 561], [374, 1491, 16, 14, 2, 1, 11, 395], [17183, 155, 25, 12, 1160, 21, 17184, 5948], [17185, 9, 46, 338, 2, 46, 45, 25, 426, 52, 80, 46, 45, 25, 163, 5, 29, 67, 4, 166, 9, 6, 2379], [3, 29, 131, 14, 2, 9], [140, 1044, 652, 4277, 236, 3785, 130, 381, 8, 20, 17186, 4665, 37, 85, 119, 76, 26], [3, 87, 17, 2, 1, 7, 63, 856, 26, 425, 22, 12, 5946], [8, 3, 415, 19, 80, 1, 17187], [15, 2, 77, 54, 116, 69, 100, 4876, 389, 50, 21, 50, 24, 8, 105, 136, 6, 94, 170, 361, 2842, 3, 509, 22, 25, 175], [3, 86, 23, 314, 17188, 74, 40, 17189, 51, 50, 1109, 23, 17190, 3, 63, 465, 50, 3535, 233, 148, 797, 802, 1, 30, 1109], [10, 89, 1, 23, 2489, 11, 18, 326, 17191, 6886, 17, 99, 297, 17192, 33, 175, 1561], [3286, 17193, 9], [3286, 17194, 556, 114, 15, 11], [185, 30, 1109, 381, 1301, 1, 5, 214, 51, 20, 1109, 171, 9, 80, 1109, 46, 131, 14, 3776, 26], [2984, 1, 5, 318, 433, 55], [403, 9], [2664, 1, 5, 200, 15], [4, 257, 205, 1, 23, 122, 1006], [19, 2, 2003, 1, 313, 7, 30, 108, 367, 367], [5, 318, 48, 34, 4, 2522, 47, 4, 199, 416, 121, 7, 2057, 47, 56, 478, 32, 84, 8385], [576, 43, 1662, 17195, 42, 793, 100, 72, 787, 8, 42, 41, 13, 1313, 17196, 1589, 2, 9, 649, 116, 43, 1726, 760], [5, 2, 9, 31, 20, 17197, 1005, 127, 130, 4137, 2, 707], [23, 2, 1, 34, 2, 4747, 42, 150, 17], [3, 150, 13, 2586, 2363, 12, 2, 158], [321, 39, 9, 17198, 92], [4, 688, 8386, 16, 14, 2, 9], [71, 5, 157, 97, 9, 230, 97, 504, 233], [25, 103, 359, 8, 48, 110, 62, 7, 1, 2439, 7, 45, 46, 8387], [17199, 77, 4, 1064, 884, 1], [912, 147, 24, 2044, 458], [3, 113, 2, 1, 29, 10, 45, 650, 42, 17200], [39, 1, 64, 17201, 25, 3, 113, 5, 3, 156, 94, 78, 17202, 1, 54, 135, 125, 76, 26, 34, 176, 3425, 21, 965], [29, 113, 2, 77, 604, 105, 119, 24, 1027, 5, 33, 3479, 7, 196, 32, 5, 58, 12, 44, 352, 8, 5, 17203], [17204, 7510], [3, 14, 13, 1287, 1, 17205, 17206, 513, 513, 335, 3175, 335, 17207, 17208, 17209, 7, 57, 3, 299, 282, 17210, 513, 17211], [286, 447, 151, 2999, 20, 758, 6, 1154, 55, 17212, 11, 22, 9], [31, 5, 19, 11, 347, 230, 5, 146, 62, 5, 2, 9], [3, 62, 15, 47, 7, 4332, 3174, 31, 3, 28, 2256, 16, 76, 1315, 103, 5, 3083, 68, 6, 17, 7, 1], [1, 12, 185, 233, 36, 28, 359, 18, 123, 36, 91, 8, 131, 61, 290, 4, 77, 26, 43, 1, 338, 7, 25, 8, 420, 18], [2442, 447, 28, 32, 9], [5, 161, 185, 161, 1, 40, 46, 172, 27, 5, 17213, 3081, 3128], [79, 2, 77, 2, 1063, 8, 1358, 28, 1001, 34, 31, 42, 157, 8388, 11, 580, 1358, 300, 40, 2, 1235], [171, 1, 55], [3801, 518, 2903, 12, 8389, 8, 15, 107, 230, 518, 5871, 236, 8390, 3962, 15, 280, 230, 319], [1657, 27, 1, 18, 2, 186, 13], [2033, 1, 23, 152, 719, 20, 548], [71, 6, 28, 8391, 24, 11, 314, 261], [31, 39, 292, 405, 2, 323, 612, 1, 103, 105, 298, 54, 16, 1083], [31, 20, 48, 2, 141, 1], [15, 280, 230, 9, 48, 280, 230, 20, 3940, 31, 5, 258, 2, 93, 77, 40, 87, 6, 14, 157, 2037, 2049, 965], [605, 2, 77, 5, 5, 428, 109, 13, 150, 165, 130, 19, 2, 1339, 282], [164, 12, 2, 1, 8, 6794, 3740, 189, 87, 2, 77, 7, 103, 70, 76, 150, 165, 8, 547, 4218, 60, 16, 4, 1040], [1304, 16, 1, 69, 67, 10, 5991], [5910, 8164, 47, 4, 796, 9, 16, 32, 4085, 1, 4030, 50, 13, 40, 41, 2, 8089, 5870, 8, 32, 40, 200, 47, 948], [43, 1, 30, 418, 3546, 103, 182, 14, 73, 611, 73, 22, 629], [352, 18, 841, 438, 29, 196, 5, 2, 9, 304, 7922, 115, 266, 70, 5, 2, 436, 342, 327, 29, 196, 5, 243, 26, 44, 2, 1169], [262, 1, 51, 5992, 6, 70, 126, 651, 107, 573], [66, 32, 62, 2, 9, 13, 22], [38, 1, 81, 59, 126, 520, 1978], [38, 4, 17214, 1, 5, 62, 175, 59, 14, 112], [38, 5, 791, 2, 9, 8, 101, 623, 15, 787, 213, 790], [38, 5, 623, 482, 12, 2, 9], [20, 2, 24], [52, 121, 53, 13, 42, 41, 4, 169, 6, 58, 7, 53, 29, 627, 23, 48, 80, 500, 1, 3, 46, 5932], [3, 64, 10, 4495, 40, 29, 110, 366, 34, 21, 10, 1451, 1, 223, 340, 17215, 996, 17], [60, 1, 227, 18, 17, 27, 1, 7, 469, 227, 18, 980], [131, 62, 31, 2, 1, 17216, 35, 6, 17217, 2726, 747, 7, 1, 1340, 8, 157, 15, 6, 50, 3935, 31, 40, 17218, 41, 97], [31, 32, 5, 1679, 58, 12, 1, 88, 114, 97, 30, 337], [1106, 1357, 49, 342, 34, 60, 14, 65, 530, 130, 2, 1], [17219, 17220, 857, 543, 20, 995, 612, 8, 194, 4, 1, 17221, 1355, 1380, 1, 38, 80], [1468, 1901, 26, 1702, 49, 9, 1468, 1468, 1901, 56, 889, 56], [503, 473, 3107, 1, 278, 19, 1121, 8392, 1272, 8393, 306, 1375, 4748, 2132, 2591, 4501, 17222, 3219, 7668, 4676, 306], [1904, 598, 13, 2, 1], [17223, 5, 41, 32, 4, 894, 1542, 49, 5, 262, 17, 661, 16, 20, 894], [211, 2, 9, 502, 5, 235, 8, 72, 1360, 10, 17224], [55, 36, 227, 142, 6, 570, 666, 2, 24], [17225, 77, 17226, 71, 59, 28, 2, 401, 293, 74, 61, 6, 261, 293, 5, 1482, 1], [53, 15, 2, 666, 16, 1757, 18, 10, 1747, 17227, 160, 42, 67, 17, 201, 706, 42, 10, 24, 55], [570, 95, 430, 4, 1329, 111], [5, 700, 672, 174, 17228, 90, 5, 422, 586, 39, 1, 12, 109, 10, 386, 205, 17229], [70, 10, 193, 117, 6, 4, 56, 63, 27, 8394, 154, 3359, 154, 4657, 951], [1, 14, 11, 1213, 575, 1000, 13, 5, 2, 1045, 9], [39, 1, 1045, 275, 11, 3677, 49, 13, 212, 8343, 82, 258, 8395, 38, 15, 107, 6, 717], [2345, 87, 84, 17230, 1043, 30, 1], [10, 436, 58, 60, 5497, 16, 17231, 288, 751, 1829, 141, 882, 81, 8, 2, 320, 127, 17232, 47, 22, 236], [53, 9, 30, 916, 3153, 30, 25, 6838], [25, 14, 1288, 438, 275, 36, 105, 704, 5905, 5, 18, 610, 957, 17233, 7, 236, 99, 209, 3733], [2224, 107, 460, 17234, 23, 3156, 22, 17235, 1062, 17236, 23, 3156, 325, 9, 230, 7], [38, 2, 1, 41, 5, 19, 35, 34, 5, 17237, 20, 164, 6, 4, 1403, 37, 5, 146, 397, 116, 13, 5, 46, 214, 26], [252, 114, 17238, 46, 2383, 749, 97, 24], [10, 1, 131, 448, 2, 1887, 941, 272, 33, 48, 389, 4, 591, 1005, 7, 2861, 66, 32, 276, 14, 640], [25, 14, 13, 296, 28, 292, 106, 4, 24, 5, 17239, 675, 18, 5, 1154, 292, 106, 984, 12, 1527], [1070, 129, 2, 728, 3198, 1070, 129, 2, 1], [1, 64, 107, 54, 11, 775, 927, 29, 58, 22, 26], [3, 90, 38, 1, 14, 13, 17240, 17241, 1, 57, 42, 299, 3, 124, 60, 3539, 138, 11, 10, 108, 1434, 3, 47, 492], [1018, 24, 53, 2591, 443, 17242], [219, 2629, 53, 70, 50, 2, 419, 639, 57, 31, 5, 679, 28, 4, 24, 26, 15, 7973], [78, 9, 29, 867, 18, 1461, 43, 127, 932], [3, 516, 94, 1039, 243, 88, 94, 2, 9, 927, 2269, 1237, 25, 557, 9, 165, 88, 4, 68, 7, 64, 76, 8, 132, 4], [39, 25, 11, 1190, 383, 14, 238, 1023, 11, 74, 383, 14, 238, 28, 495, 6, 498, 996, 240, 74, 125, 247, 16, 42, 25, 1], [31, 22, 1, 29, 33, 61, 539, 4, 1125, 8396], [15, 196, 20, 2, 104, 55], [890, 524, 2, 1, 140, 416, 81, 59, 84, 3924, 85, 107, 51, 268, 275, 17243, 14, 72, 4, 1620], [3, 87, 60, 9, 91, 112, 45], [155, 889, 2580, 2, 1, 1030, 3295, 91, 1892, 4388, 4, 796, 9, 1818, 30, 25, 43, 1, 43, 967, 43, 792], [61, 81, 6, 32, 20, 166, 9], [3, 911, 68, 3210, 189, 3, 1373, 23, 48, 98, 3758, 837], [147, 1, 3322, 3994, 63, 249, 682, 102, 16, 10, 138], [556, 635, 17, 2, 593, 54, 135, 28, 108, 18, 10, 70, 1, 635, 13, 1892, 2477, 385], [31, 10, 1, 172, 40, 383, 2, 593, 3, 196, 23, 238, 114, 45, 6, 2, 244, 822, 1184], [17244, 121, 42, 9, 75, 14, 125, 4, 3057], [7, 24, 46, 20, 17245, 15, 383, 20, 227], [5, 638, 28, 37, 17246, 5, 1093, 17, 16, 10, 1], [98, 183, 1, 69, 1229, 483], [17247, 3, 63, 72, 12, 7, 3, 19, 9, 8, 216, 2840], [820, 16, 10, 1081, 3841, 232, 17248, 322, 8397, 727, 8398, 8, 727, 17249], [3, 75, 14, 11, 10, 4700, 1040, 129, 2, 1, 69, 868, 3965, 23, 344, 55], [2, 417, 17250, 16, 768, 11, 1342, 17251, 1695, 4, 1767, 17252, 26], [219, 52, 12, 51, 7332, 37, 52, 12, 4, 2023, 104, 41, 6, 229, 22, 494, 71, 6, 119], [73, 2, 265, 3, 477, 6, 17253, 52, 229, 17, 2, 154, 7894, 107, 82, 4, 179, 13, 307, 199, 27, 1078, 1327], [3, 64, 38, 5969, 677, 3264, 8, 32, 4, 77, 27, 56, 481, 122, 8, 17254, 76], [19, 35, 5, 8399, 181], [31, 3, 63, 114, 20, 1, 47, 40, 182, 109, 20], [15, 923, 744, 21, 391], [5, 146, 19, 183, 1, 82, 292, 975, 129, 7, 604, 105, 94, 361, 37, 5, 63, 197, 4, 17255, 54, 16, 20, 352, 1069], [17256, 81, 60, 180, 56, 6, 17257, 1103, 555, 170, 895], [31, 10, 91, 46, 1512, 17, 22, 24, 857, 12, 152, 450, 35, 11, 246, 25, 2747, 5, 63, 1083, 17], [6, 79, 1920, 1186, 98, 674, 782, 8, 17258, 140, 52, 48, 234, 27, 4, 1082, 1604, 17259], [434, 1032, 6, 167, 35, 4, 699, 22, 17260, 26, 458, 1445, 2208], [695, 7, 1, 79, 18, 8400, 21, 60, 8401, 53, 8402, 53], [3, 86, 22, 17261, 999, 4749, 12, 60, 3282, 7, 17262, 1, 67, 4, 138, 2042, 8, 41, 214, 38, 40, 596, 188], [38, 3, 72, 104, 15, 33, 196, 217, 69, 12, 19, 17263], [805, 9, 37, 1133], [601, 3, 131, 2630, 311, 22, 1, 34, 3, 29, 62, 31, 40, 1101, 4198, 74, 48], [31, 20, 19, 20, 386, 3986, 8, 5, 96, 146, 389, 21, 4, 17264, 24, 12, 963], [75, 43, 1, 70, 17, 214, 129, 2, 25, 3, 330, 124], [148, 15, 469, 74, 1547, 12, 431, 34, 148, 1, 26], [2, 520, 8, 504, 614, 6, 528, 51, 39, 9, 2780, 2, 189, 198, 105, 44, 39, 9, 528, 51, 84], [119, 50, 24, 38, 40, 214, 611, 1040, 214, 51, 5, 74, 766, 45, 33, 973, 50, 142, 8, 119, 50, 24, 35], [212, 862, 2808, 32, 883, 1586, 65, 17265, 65, 13, 4, 3532, 16, 2, 1593, 1586, 26, 2, 17266, 1586], [31, 3, 262, 463, 1452, 7, 196, 12, 15, 1498, 21, 17, 6, 107, 8, 119, 4, 24, 444, 3, 1912, 853, 17267, 26], [695, 7, 2, 1899, 3303, 104, 944], [242, 35, 1], [11, 4491, 17268, 1212, 4927, 12, 1557, 4, 250, 115, 16, 1444, 160, 1444, 115, 951], [394, 50, 24, 532, 13, 1015, 35, 5484], [3, 394, 22, 9, 24, 1402, 65, 13, 1794, 1018, 1778], [787, 1, 11, 4, 5982, 15, 2804, 1, 11, 4, 5982], [697, 17269, 10, 4010, 581, 9, 581, 17270, 581, 5434, 1145, 581, 3284, 1163, 409, 16, 8403, 1626, 54, 2, 2663, 4139], [666, 16, 992, 2891, 2971, 4, 1213, 545, 56, 3903], [405, 7, 24, 17271], [3, 1950, 38, 24, 532, 13, 17272, 1074, 292], [4010, 733, 59, 2, 17273, 8, 1, 470, 927], [66, 220, 51, 4, 460, 215, 264, 8, 1145, 17274, 22, 4010, 41, 18, 2677, 33, 1397, 8, 856, 545, 32, 4, 17275], [57, 277, 4, 1940, 72, 1], [8262, 97, 180, 723, 187, 17276, 2, 17277], [12, 7, 739, 197, 74, 24, 1872, 25, 369, 372, 13, 256, 1502, 72], [5, 12, 2, 1, 30, 399], [3, 90, 1578, 720, 36, 14, 13, 17278, 8404, 368, 8, 23, 13, 2403, 91, 3, 46, 328, 45, 6, 1323], [275, 49, 127, 640, 21, 701, 130, 1693, 49, 21, 285], [462, 333, 192, 14, 1262, 2282, 32, 39, 1983, 952, 146, 632, 562], [1765, 992, 1655, 160, 247, 56, 992, 182, 1749, 67, 2, 190, 25, 1901, 18, 4, 17279, 3, 737, 10, 306, 38, 3, 566, 170], [1085, 49, 355, 4582, 12, 5136, 843, 74, 557, 1, 243, 3072, 8405], [60, 16, 5, 2811, 198, 472, 35, 73, 112, 435, 21, 3072, 149, 814, 132, 896, 13, 1, 32, 213, 7590, 8405], [920, 619, 3757, 17280, 628, 17281, 17282, 2, 587, 68, 8, 1087, 17283, 1073, 108, 5, 643, 17284, 17285], [203, 9, 156, 131, 990, 27, 495, 78, 29, 87, 6, 14, 224, 43, 409, 16, 990], [5993, 427, 110, 1685, 15, 13, 4750, 2168, 190], [5, 1239, 1051, 4751, 6, 1231, 2254, 18, 14, 2, 2741], [2054, 29, 113, 357, 1, 3, 62, 5, 41, 2, 17286, 3, 46, 276, 113, 357], [22, 1, 46, 41, 2, 1102, 16, 1237, 695, 26], [1163, 3979, 12, 44, 352, 8, 23, 119, 4613, 15, 152, 14, 2, 434, 17287, 160, 17288, 1814], [32, 9, 17289], [31, 5, 29, 70, 50, 61, 6, 376, 211, 78, 19, 88, 20, 1952, 178, 56], [106, 21, 4, 3274, 1549], [5, 146, 62, 4, 511, 808, 2, 93, 77, 8, 93, 24], [31, 52, 29, 442, 5, 43, 4712, 282], [2267, 230, 828, 20, 11, 4, 1891, 828, 230, 2267, 604, 14, 595, 29, 14, 2, 1], [25, 109, 14, 818, 16, 44, 319, 34, 71, 239, 16, 78, 152, 316, 76, 537, 1, 337, 6, 20], [714, 163, 119, 4, 24, 51, 4, 199, 106, 12, 93], [945, 31, 42, 375, 38, 1824, 82, 759, 2732, 440, 263, 27, 7, 166, 1, 30, 25, 852, 26], [32, 4, 25, 11, 4, 360, 85, 364, 58, 1, 780, 27, 126, 228, 25], [4834, 154, 17290, 17, 233, 10, 268, 190, 1, 26], [1, 162, 364, 5, 86, 5, 61], [8406, 13, 575, 17291, 37, 3, 47, 13, 241, 43, 48, 10, 17292, 5025, 1, 614, 6, 1021, 15, 54], [1331, 608, 11, 770, 4, 377, 244, 676], [679, 5516, 41, 60, 108, 17293, 3, 318, 13, 50, 22, 3359, 17294, 24], [3, 363, 6, 1197, 155, 1197, 41, 2, 95, 521, 162, 42, 63, 28, 97, 228, 6, 821, 42, 11, 26, 28, 98, 2, 54, 4, 521, 5064], [31, 1264, 424, 960, 6, 1653, 88, 97, 9, 29, 655, 4014, 438], [38, 5, 70, 2, 675, 8, 217, 5, 90, 528, 8, 20, 86, 1600, 1, 5, 652, 1166, 6, 17295], [38, 2, 9, 72, 84, 6, 482], [29, 471, 17, 1690, 82, 256, 3, 407, 1713, 6, 5, 1395, 30, 1], [869, 20, 443, 1795, 82, 20, 730, 426, 20, 2, 1948, 1], [306, 85, 75, 42, 33, 1273, 17, 21, 4, 89, 1, 3, 195], [1267, 79, 7, 104, 2, 711], [1350, 109, 12, 56], [38, 217, 175, 39, 9, 46, 334, 34, 36, 2434, 35, 51, 4, 967, 65, 5994], [37, 2071, 33, 124, 6, 929, 2, 25, 21, 2995, 2, 379, 462, 18, 1069, 8407, 8, 1382, 8407, 11, 6825, 2152], [100, 4, 384, 17296, 5889, 11, 17297, 7423, 236], [17298, 1005, 5995, 261, 17299, 3548, 159, 1085, 129, 2651, 17300, 4492], [139, 172, 27, 2, 5811, 17, 54, 17301, 409, 16, 836, 28, 5, 2, 4854, 3, 867, 21, 1323, 409, 16, 418], [3, 90, 38, 25, 14, 17302, 32, 18, 4, 866, 13, 36, 1831, 24, 26, 44, 4, 1203, 6, 122, 26, 433, 254, 23, 93, 25, 3], [23, 59, 6, 61, 18, 26, 14, 4, 1377, 26, 2070, 60, 319], [15, 862, 26, 5, 25, 96, 2685, 657, 854, 3525, 29, 119, 5863, 78, 456, 14, 2482, 1270], [38, 4, 234, 1, 122, 6, 3400, 5, 11, 5796], [23, 238, 14, 13, 17303, 280, 41, 384, 9, 17304], [592, 60, 127, 16, 10, 2647, 190, 8408, 8, 4, 250, 395, 3, 299, 16, 47], [38, 5, 258, 54, 20, 482, 12, 2, 9], [9, 340, 1709, 514, 765, 627, 765, 4620], [22, 1, 2201, 123, 4, 593, 5996, 17305], [3, 33, 131, 340, 2, 234, 25, 6, 2, 834, 322, 231, 1354, 9, 7, 277, 2543, 1571, 1439, 7682, 992, 163, 1495, 51, 1145], [3, 64, 77, 69, 652, 1491, 6, 5997, 74, 2558, 4, 244, 17306, 1, 90, 37, 209, 92, 7, 15, 17307], [17308, 855, 17309, 17310, 3005, 17311], [22, 77, 107, 173, 521, 27, 860, 813, 8, 349, 341, 1645, 54, 16, 50, 4735, 3, 196, 107, 18, 71, 179, 26, 17312], [17, 304, 18, 5, 6, 114, 17, 6, 2060, 27, 5, 6, 28, 10, 628, 1663], [1, 5, 64, 155, 412, 34, 4, 263, 55, 53, 22, 12, 4, 178, 289, 132, 304, 21, 3, 5303, 64, 398, 16, 39], [1906, 3424, 12, 2, 1139, 608, 16, 4, 997, 36, 92, 1124, 6, 308, 6, 32, 5, 185, 3690, 2195, 40, 87, 6, 14, 191], [1378, 49, 5, 8409, 221, 18, 2, 1844, 16, 68, 6, 1654, 1], [2795, 142, 4, 606, 11, 10, 3420, 7642, 4, 1, 5638, 4, 9], [38, 5, 119, 4, 24, 37, 93, 40, 75, 829, 50, 1897], [2, 77, 62, 38, 2, 1, 13, 50, 520], [119, 50, 24, 8, 65, 51, 50, 13], [352, 18, 841, 438, 29, 196, 5, 2, 9, 304, 1638, 115, 266, 70, 5, 2, 436, 342, 327, 29, 196, 78, 243, 44, 2, 2003], [249, 138, 26, 119, 24, 12, 1880, 16, 2637, 31, 5, 86, 15, 530, 88, 485, 20, 30, 12, 99, 379, 6, 14, 19, 11, 4], [2147, 38, 5, 139, 1426, 2, 161, 1], [9, 39, 115, 14, 13], [31, 5, 29, 119, 24, 20, 1133, 8, 7935], [40, 204, 7, 1], [43, 77, 249, 138, 34, 4417, 32, 252, 28, 1643, 252, 101, 19, 89, 1, 478, 32, 39, 183, 77, 28, 554], [17313, 1, 29, 113, 170, 17314, 8410, 38, 52, 17315, 52, 41, 32, 4, 1236, 52, 87, 27, 4813], [44, 2, 228, 7, 2, 9, 34, 723, 12, 415, 17316], [304, 57, 6524, 2, 1107, 518, 21, 60, 285], [3777, 2260, 8, 479, 35, 7, 248], [34, 1, 58, 7, 99], [23, 28, 515, 16, 39, 199, 802, 43, 293, 291, 1, 43, 401, 32, 36, 131, 58, 12, 987, 8, 366, 5803], [38, 121, 1026, 1, 3, 79, 50, 8411, 17317, 149, 40, 101, 1006, 1021], [114, 2, 236, 2787, 52, 6766, 16, 5577, 71, 364, 277, 52, 1089, 1399, 744, 649], [20, 24, 37, 859, 3, 79, 15, 7542], [117, 5, 49, 44, 5, 566, 16, 4, 5849, 95, 52, 4, 68, 27, 642, 18, 84, 30], [3, 114, 2, 1, 6, 1652, 40, 165, 48, 569, 6, 246, 25, 288, 4, 3455, 96, 11, 50, 7899, 2777], [90, 339, 1], [12, 7, 17318, 17319, 251, 583, 42, 109, 152, 3264, 17320, 3236, 432, 87, 3, 948, 312, 951], [9, 12, 9, 25, 14, 214, 5080, 36, 14, 238, 2359, 4, 9, 1114], [3, 41, 43, 64, 21, 1, 74, 1, 25, 1114], [38, 2, 1, 72, 296, 64, 1323, 167, 50, 125, 4, 17321, 4611, 26, 72, 2835, 1323, 15, 197, 17322, 16, 4, 106, 1114, 4, 166, 17323, 1080], [1, 1580, 59, 784, 6, 4, 1198, 8, 96, 14, 1471, 13, 2, 4054, 1149, 1114], [1, 12, 3089, 18, 1651, 288, 36, 265, 2687, 17324, 3085, 1114], [1, 226, 36, 70, 35, 102, 16, 610, 4007, 1114, 22, 1, 47, 541, 13, 17325, 4, 166, 115], [1, 69, 366, 5068, 49, 1570, 1114], [203, 1, 29, 13, 17326, 35, 36, 1291, 11, 4, 850, 32, 7, 17327, 1114], [552, 85, 703, 1, 86, 36, 41, 30, 1114], [31, 2, 1, 100, 17, 167, 151, 338, 50, 1224, 1114], [31, 2, 1, 113, 5, 40, 41, 359, 18, 127, 130, 17328, 15, 1406, 329, 27, 7, 9, 1114], [31, 4, 24, 48, 17329, 42, 48, 4247, 117, 1114], [15, 60, 643, 183, 1, 11, 4, 360, 1114, 7, 151, 810], [39, 5054, 30, 5435, 1, 14, 854, 36, 1223, 27, 2716, 8, 60, 166, 2784, 45, 1114], [120, 9, 96, 255, 3649, 11, 341, 30, 1032, 1114], [55, 410, 5, 21, 14, 2, 171, 83], [14, 37, 1730, 35, 11, 64, 7, 5, 139, 58, 219, 21, 5, 12, 57, 848, 7937, 58, 171, 83, 3, 67, 33, 67, 1091], [32, 7, 314, 1698, 3926, 3130, 42, 2722, 6, 1268, 2, 8412, 41, 51, 50, 125, 2, 17330, 758, 8, 60, 4870, 1099], [8, 31, 2, 1, 75, 538, 2, 25, 125, 60, 1010, 8, 2, 1241, 2035, 16, 6835, 752, 88, 40, 47, 878, 17331], [29, 1161, 536, 2, 112, 17332, 536, 2, 9], [172, 9, 30, 3076, 15, 74, 17333, 831, 163, 45], [3, 105, 1048, 2, 2200], [3, 103, 48, 303, 20, 1, 43, 355, 17334, 37, 29, 110, 475, 133, 7, 17335], [60, 1, 86, 2, 17336, 1100, 1870, 70, 76, 2, 17337], [40, 137, 7622, 8, 41, 2, 4987, 5614, 17338, 22, 9, 127, 16, 2, 91, 130, 151, 182, 2305, 26], [826, 156, 4662, 2569, 13, 66, 29, 44, 43, 164, 1, 3, 146, 61, 337, 8, 2974], [826, 156, 86, 36, 2274, 1, 14, 1411, 5, 11, 521, 8, 385], [22, 1, 687, 27, 10, 586], [3, 75, 304, 6, 255, 1097, 858, 2557], [260, 269, 11, 4, 1979, 23, 345], [12, 325, 329, 53, 31, 5, 19, 125, 2, 564, 25, 5, 2, 564, 368], [31, 17339, 17340, 19, 73, 332, 73, 52, 313, 88, 52, 204, 1], [64, 5, 99, 10, 312], [403, 17341, 1152, 1082, 3159, 16, 4, 263, 17342, 1915, 12, 2, 83, 951], [6, 4, 144, 5587, 3561, 51, 4, 8325, 2118, 178, 4111, 12, 11, 4, 6713], [23, 679, 542, 6, 2793, 3257, 10, 17343, 17344, 8413, 34, 1302, 17345, 12, 330, 3073, 3458], [1, 14, 44, 43, 401, 43, 1152, 43, 2342, 26, 44, 4, 1203, 6, 72, 2211, 39, 25, 67, 12, 887, 1, 149, 7], [411, 104, 2, 2193, 12, 17346, 1084, 19, 17347, 45], [71, 78, 9, 58, 610, 877], [9, 44, 43, 164], [77, 27, 2604, 1440, 49, 17348, 33, 44, 2, 1165, 1855, 7, 341, 17349, 1028, 1, 49, 939, 8295], [345, 60, 127, 7, 2, 1899, 3303, 104, 944], [1390, 24, 655, 295, 34, 6932, 235, 8, 93, 138, 513], [10, 231, 38, 1, 772, 17, 6, 279], [15, 59, 7, 106, 16, 4, 213, 38, 32, 4, 1613, 9, 69, 3741, 36, 47, 524, 218, 16, 36, 850, 2011, 107, 108], [4, 5909, 1293, 16, 17350, 18, 4, 117, 2590, 142, 6, 2524, 17351, 198, 14, 4, 508, 17352, 8, 17353, 188], [17354, 3878, 39, 9, 49, 21, 416], [42, 146, 14, 144, 6, 2931, 521, 11, 1197], [2841, 46, 295, 34, 2, 1, 17355], [321, 155, 106, 2, 1303, 1120, 175, 256, 4, 841, 395, 6, 1088, 12, 60, 9, 533, 133, 17356, 97, 138, 18, 17, 717], [110, 51, 2, 379, 1247, 39, 9, 46, 334], [31, 10, 77, 28, 11, 2, 290, 27, 20, 77, 5, 165, 14, 542, 6, 1941, 99, 218, 272, 762, 5, 54, 88, 61, 547, 10, 1, 3776], [308, 30, 1], [1653, 4612, 156, 694, 126, 387, 38, 5, 389, 27, 7571, 13, 1, 5, 291, 483, 99, 19, 5, 134, 17, 764], [17, 20, 2, 9, 9, 5, 407, 72, 7, 2294, 1296, 862, 51, 17357, 2748, 17, 219, 20, 2, 9, 225, 18, 3956, 841, 862, 51], [38, 2, 1, 8414, 99, 637, 6, 5], [20, 712, 1, 113, 17, 1406, 537], [105, 302, 2, 3525, 37, 4636, 30, 1, 36, 33, 304, 6, 3846], [17358, 1018, 1598, 354], [1264, 227, 2, 9, 173, 2, 2255, 8, 25, 121, 1028, 93, 77, 5724], [31, 50, 402, 8, 995, 537, 71, 63, 5, 113, 31, 2, 77, 24, 1729, 230, 428, 525, 11, 50, 2477, 188], [1603, 48, 21, 17359, 60, 1, 33, 67, 42, 6, 8415, 601], [22, 25, 122, 6, 90, 18, 17, 6, 2, 1, 8, 40, 273, 22, 17360, 23, 7, 25], [3, 487, 3548, 17361, 8, 731, 233, 278, 19, 99, 239, 379, 1], [10, 1, 2, 17362, 2907], [25, 175, 59, 67, 2, 2987, 3578, 288, 134, 2731, 701, 32, 115], [1312, 24, 415, 578, 13, 4, 8416, 3793, 1564, 17363], [1, 97, 306, 114, 15, 11, 4, 30, 21, 4, 480, 1005, 1], [97, 306, 735, 30, 21, 1503, 2006, 1, 55], [890, 524, 41, 43, 497, 17364, 85, 506, 2, 1, 54, 18, 685, 871, 205, 13, 48, 110, 2, 17365, 1492, 424, 106, 6], [1, 49, 101, 17366, 38, 15, 107, 6, 17367, 38, 15, 7963, 21, 980, 2855, 36, 9, 2812], [4, 154, 905, 1890, 2566, 5402, 17368, 731, 3376, 4015, 12, 772, 6, 1252, 2, 17369, 16, 17370, 95, 26], [20, 48, 1498, 24, 177, 5998], [933, 6337, 1143, 2311, 1505, 702, 17371, 17372], [736, 39, 25, 356, 191, 3, 394, 3, 63, 349, 51, 6795, 292, 1, 27, 76], [237, 121, 123, 2834, 2, 17373, 7790, 368, 128], [8, 3, 46, 41, 106, 21, 1, 146, 176, 10, 453, 18, 10, 8225, 613], [597, 35, 13, 19, 10, 164, 164, 2, 1, 34, 40, 165, 19, 17, 117], [31, 4, 2669, 107, 6, 10, 620, 272, 14, 13, 6539, 1, 12, 2271, 73, 45], [32, 16, 7056, 5272, 3264, 677, 225, 26, 127, 26, 1, 2061], [666, 16, 1937, 1, 54, 135], [80, 17374, 1130, 216, 17375, 1130, 65, 13, 56], [25, 103, 19, 129, 2, 322, 77, 596, 50, 235, 18, 117, 21, 2, 236, 69, 101, 41, 292, 2035, 16, 93, 1277, 26], [1008, 1008, 1008, 1, 17376], [4, 179, 31, 4191, 404, 390], [71, 5, 1713, 17, 129, 6, 19, 34, 3, 63, 532, 80, 24, 82, 1117, 4, 712, 91, 46, 7, 1283, 40, 867, 88, 17377], [71, 5, 223, 436, 2, 1, 7, 100, 25, 735, 18, 50, 235, 11, 775], [258, 2, 275, 4453, 2, 9, 1665, 12, 13, 238, 258, 2, 25, 4453, 2, 17378], [2, 1, 63, 65, 13, 2, 937, 831, 125, 667, 1439, 30, 24], [3, 90, 1497, 2, 1, 2729, 913, 14, 13, 17379, 17380, 17381, 1, 1113, 42, 200, 151, 100, 2, 5186, 636, 1497, 23, 5195, 6], [584, 370, 34, 234, 1, 165, 130, 2, 436, 11, 22, 17382, 4, 3708, 340, 1821], [5283, 121, 306, 1850, 8, 129, 28, 351, 466, 2486, 18, 639, 921, 339, 32, 5, 379, 9, 27, 265, 29, 28, 68, 55], [1619, 121, 5, 48, 223, 594, 770, 650, 5, 363, 6, 2, 17383, 261, 353, 330, 7073, 50, 251, 55], [17384, 418, 64, 14, 234, 1, 1, 92, 115, 14, 44, 651, 26, 6414, 16, 14, 2, 795, 306], [34, 101, 6363, 4, 732, 2261, 12, 56], [4598, 208, 13, 40, 48, 2, 3034, 40, 132, 125, 292, 16, 4, 25, 18, 33, 22, 229, 1853, 268, 17385, 2052], [432, 191, 357, 21, 45, 26, 182, 26, 105, 44, 2, 437, 58, 45, 996, 111, 1776, 34, 148, 63, 2, 1, 28, 2, 267, 5], [26, 12, 4, 768, 747, 725, 5959, 18, 4, 257, 9], [22, 71, 32, 4, 9, 152, 14, 13, 390], [3508, 3, 46, 1070, 18, 777, 23, 17386, 18, 1406, 8, 10, 2067, 72, 52, 41, 2, 89, 1, 21, 17, 4028, 188], [110, 464, 2, 95, 63, 635, 15, 456, 1351, 18, 4347], [567, 95, 359, 1803], [3, 62, 7, 56], [128, 3, 19, 27, 26, 112, 81, 76, 1, 62, 71, 6, 44, 501], [148, 3, 90, 14, 2, 1139, 24], [8417, 32, 4, 1, 18, 5952, 61, 17387], [3, 259, 21, 606, 3595, 8, 3, 309, 21, 179, 6807, 538, 32, 1293, 553, 10, 3442, 12, 17388], [354, 851, 2519], [7015, 77, 5233, 17389, 91, 21, 530, 17390, 11, 10, 235, 3, 47, 13, 1539, 1, 600, 44, 219, 2697, 17, 8026, 21, 22, 725], [22, 45, 12, 13, 2655, 691, 423, 8, 15, 378, 195, 37, 1113, 3, 195, 11, 1773, 87, 16, 60, 24, 321, 37, 3, 349, 35, 6, 22], [22, 1, 277, 37, 17391, 73, 1066, 47, 17392, 35, 5, 2, 180, 89, 91, 345, 13, 2, 1664], [8, 12, 4, 229, 89, 30, 3288, 227, 173, 5949, 24, 8, 141, 17393, 1], [17394, 2, 1567, 1, 1008, 626, 97, 17395, 57, 1655, 884, 904, 53], [1232, 20, 154, 1074, 17396, 12, 45, 485, 151, 3046, 42, 187, 26, 3972, 3360, 1095, 18, 4, 24, 289, 346, 54, 18, 17397], [10, 177, 12, 2441, 152, 14, 1300, 32, 4, 24, 390, 472, 73, 2, 3652, 2681], [17398, 1008, 3, 64, 5, 99, 181], [159, 870, 41, 142, 6, 4, 17399, 4150, 3754, 73, 5332, 73, 2585, 200], [5, 182, 65, 51, 2, 1, 8, 33, 14, 1671, 1], [47, 33, 402, 22, 18, 10, 7769, 456, 14, 11, 93, 402, 18, 22, 95], [339, 1, 715, 339, 5999], [2, 95, 7, 1605, 275, 123, 1478, 2, 681, 3904, 27, 2409, 4336, 26], [787, 945, 151, 61, 142, 116, 8, 72, 993, 1905, 117, 11, 4, 887], [171, 1, 291, 10, 886, 363, 6, 8418, 8419, 19, 3123, 17400, 27, 2, 1220, 886, 55], [5917, 17401, 417, 197, 1], [3644, 1228, 18, 567, 95, 75, 14, 257], [3, 745, 491, 2, 1, 11, 268, 449], [7, 629, 47, 56], [1085, 49, 355, 4052, 49, 759, 3, 33, 19, 80, 1, 17402, 25, 58, 2419], [70, 2426, 4449, 8, 197, 18, 2, 356, 175, 59, 285, 3, 195, 61, 6, 70, 2, 434, 206, 462], [1362, 1678, 85, 80, 91, 67, 17, 917, 189, 555, 84, 231, 17403, 17404, 242, 1452], [554, 1, 28, 18, 4, 1195, 8, 86, 5, 614, 6, 134, 76, 20, 930, 13, 1, 5, 198, 16, 19, 2, 25, 27], [225, 11, 4268, 159, 2090, 440, 5531, 17405, 14, 3503, 17406, 17407, 17408, 21, 84, 2773, 11, 2249, 17409], [37, 22, 12, 4, 414, 69, 47, 2, 95, 88, 227, 173, 2, 414, 82, 4, 2623, 11, 17410], [20, 175, 51, 4, 17411, 111, 11, 8420, 1184, 8, 4332, 12, 305, 1, 128, 40, 253, 305, 523], [4, 247, 179, 1, 14, 554, 17412, 251, 950, 265], [7, 7838, 30, 368, 323, 41, 339, 86, 374, 1263, 128], [1210, 148, 745, 1420, 2, 1, 11, 2, 3871], [48, 32, 16, 263, 10, 312, 23, 480, 682, 27, 2, 991, 682, 1288, 649, 66, 32, 202], [857, 16, 112, 1030, 5, 321, 5, 100, 1, 30, 17413, 227, 18, 20, 25, 1154, 2562], [384, 9, 69, 300, 126, 24, 17414, 34, 42, 506, 30, 32, 115], [73, 2, 504, 5, 44, 6, 1273, 4, 488, 9, 49, 152, 14, 32, 35, 11, 84, 1511, 34, 73, 2, 520, 52, 165, 100, 76], [5, 75, 14, 13, 2231, 17, 346, 97, 17415, 1, 114, 15, 17416, 8, 45, 3, 121, 134, 17, 106, 6, 346, 80, 30, 48], [103, 8314, 61, 17417, 11, 6854, 17418, 849, 583, 33, 583, 1546, 159, 1186, 21, 1837, 2562], [1061, 3, 698, 16, 28, 1001, 38, 111, 191, 17, 31, 10, 3446, 49, 8421, 365, 3446, 652, 22, 358, 283], [39, 9, 14, 309, 21, 701], [3, 67, 2, 260, 34, 23, 379, 8, 144, 37, 43], [48, 4, 17419, 17420, 1791, 416, 34, 1058, 781, 17421, 21, 4, 232, 22, 1608], [3, 64, 2695, 34, 117, 92, 52, 56, 117, 92, 17422, 116, 166, 7, 49, 458], [4583, 32, 4209, 8, 43, 1942, 19, 7, 1], [28, 112, 3325, 19, 290, 74, 29, 137, 307, 3, 29, 137, 27, 24, 30, 956], [116, 12, 43, 2992, 21, 17423, 15, 136, 6, 298, 15, 1134, 11, 39, 283], [1993, 81, 6, 20, 166, 894], [17424, 608, 1093, 263, 4, 957, 95, 12, 2, 1814, 2318], [7, 2880, 1029, 38, 5, 555, 4, 676, 21, 217, 8, 36, 168, 4, 676, 244, 6, 1770, 13, 1, 5, 165, 108, 2812, 188], [5, 1884, 630, 140, 217, 502, 5, 2, 17425, 3, 1884, 531, 140, 1, 23, 17426, 3, 2379], [32, 9, 49, 7293, 17427, 67, 6, 72, 7186], [18, 4, 702, 374, 109, 65, 21, 4, 244, 1, 6, 1131], [11, 60, 24, 336, 197, 12, 4, 237, 507, 6, 14, 11, 22, 8422], [6393, 5, 87, 2, 202, 9, 69, 359, 18, 50, 91, 7, 197, 17428, 7, 118, 19, 5, 288, 4, 260, 11, 4, 618, 596], [7, 619, 138, 176, 384, 9, 17429], [412, 43, 9], [41, 32, 4, 1], [393, 121, 133, 10, 306, 340, 118, 16, 5654, 6, 2, 1, 28, 1771, 587, 17430], [46, 41, 106, 21, 43, 4103, 365, 228, 366, 441, 19, 9, 25, 8036, 8423], [17431, 766, 19, 32, 212, 4324, 374, 158, 36, 32, 65, 3720, 6, 307], [113, 17, 71, 5, 109, 17432, 212, 141, 104, 1326, 44, 558, 129, 126, 235, 2656], [172, 609, 30, 956, 29, 706, 17, 2, 496, 16, 5, 914, 169, 163, 72, 1542, 42, 37, 861, 1452, 836], [65, 13, 2550, 17433, 11, 7, 190, 472], [36, 29, 70, 5963, 13, 22, 1046, 252, 168, 6, 70, 5, 150, 93, 59, 912, 15, 2044, 458, 48, 79, 5, 2, 9], [883, 1317, 563, 159, 524], [2, 1, 12, 255, 2, 5133, 225, 3, 64, 17, 2, 17434], [3, 62, 20, 152, 1509, 10, 175, 37, 33, 62, 7, 20, 2, 171, 19, 1], [70, 22, 250, 115, 10, 1], [150, 13, 247, 111, 67, 5, 6, 1694, 8, 311, 102, 32, 20, 9, 37, 36, 63, 1769, 8, 192, 14, 17435], [3, 75, 114, 245, 77, 686, 7, 1191, 6, 1227, 73, 2, 1063, 74, 4, 189, 40, 438, 73, 2237, 17436], [3, 33, 19, 4, 164, 54, 22, 1], [37, 1458, 3, 86, 1164, 2, 1395, 141, 187, 8, 99, 99, 379, 6, 110, 62, 57, 112, 728, 8, 6243], [3, 29, 608, 7, 97, 4752, 8, 31, 23, 2, 660, 20, 14, 17437], [403, 3207, 7, 10, 504, 801, 11, 4, 17438, 34, 3, 210, 935, 50, 977, 3, 33, 1469, 50, 35, 94, 3, 46, 13], [19, 2, 1, 66, 105, 64, 2, 593], [1290, 3900, 122, 6, 19, 32, 39, 319], [20, 32, 1549, 101, 435, 313, 17439, 11, 126, 1034], [296, 137, 1520, 359, 18, 77, 8, 255, 3104, 1934, 3481, 2572], [3, 67, 701, 478, 40, 18, 186, 81, 59, 28, 495, 138, 631, 390, 8, 57, 50, 1200, 277, 1762, 9, 1080], [9, 109, 14, 44, 1484, 35, 17440, 2018, 5, 21, 43, 2437, 13, 57, 20, 437, 1, 1207, 17, 11, 218, 23, 514], [71, 166, 663, 113, 17, 2982, 148, 1196, 155, 4562, 98, 10, 1, 29, 110, 113, 17, 2982, 98, 40, 14, 2044, 364, 17441, 369, 409, 45], [38, 10, 1, 79, 17, 803], [13, 5, 44, 6, 14, 6261, 144, 48, 6, 94, 17442, 5942, 3724, 1970, 822, 21, 6000, 1962, 22, 61], [7, 24, 176, 79, 17, 525, 17, 11, 1885], [5, 222, 44, 547, 5516, 5, 5809, 17443, 235, 1989, 5, 652, 2066, 38, 20, 466, 839], [289, 132, 51, 197, 17444, 51, 7, 106, 121, 48, 6001, 20, 1247, 176, 4, 24, 17445], [76, 9, 107, 76, 9, 61, 15, 2, 5809, 4753], [31, 2, 25, 19, 10, 1, 147, 18, 136, 534, 233, 34, 272, 338, 622, 771, 996, 14, 3985], [272, 2070, 2, 1, 27, 365, 1291], [78, 182, 33, 132, 44, 2, 1975, 115, 8, 20, 453, 137, 2, 1765, 843, 18, 5, 8, 134, 5, 2, 17446, 16, 60, 93, 24], [3, 14, 637, 10, 387, 8, 45, 601, 37, 1, 14, 2404, 6, 1465, 2, 705, 1357, 735, 7514, 34, 40, 46, 61, 3191, 18, 17, 80], [31, 888, 1995, 47, 1880, 16, 2719, 186, 2213, 14, 68, 16, 76, 9, 72, 40, 8424, 251], [3, 64, 169, 948, 2, 1, 3, 266, 1040, 531, 8, 3, 176, 10, 476, 637, 218, 3, 63], [5384, 46, 43, 1, 88, 5, 41, 76, 17447, 1065, 18, 2203, 8, 17448], [42, 75, 227, 2, 9, 173, 2, 2255, 2039, 2316], [19, 17449, 119, 285], [25, 156, 131, 81, 59, 71, 274, 12, 641, 17450, 57, 59, 7, 24, 5, 47, 119, 215, 264, 46, 274, 6002], [17451, 40, 136, 43, 1179, 71, 239, 16, 50, 17452, 363, 344, 6, 4, 56, 26], [648, 12, 2, 1, 749], [5, 75, 1512, 2, 414, 31, 20, 1182, 319], [5, 623, 23, 61, 6, 44, 6, 28, 54, 32, 212, 8, 166, 6003, 3, 2171, 1261], [17453, 17454, 17455, 2632, 1968, 17456, 5644, 2, 17457, 2, 2061, 17458, 160], [139, 172, 865, 942, 53, 25, 7, 7, 686, 59, 30, 137, 626, 307, 7, 45, 37, 17459], [403, 177, 22, 470, 1871, 17460, 5570, 12, 18, 20, 30], [583, 270, 1972, 37, 17461, 209, 190], [29, 14, 1491, 6, 100, 20, 150, 3723, 650, 20, 2, 83], [3, 301, 217, 118, 70, 2, 323, 59, 71, 39, 9, 46, 334], [3999, 18, 446, 1146], [22, 1, 128], [1, 118, 359, 18, 2, 25, 7, 134, 50, 474, 40, 191, 21, 8, 14, 334, 6, 1619, 251, 1, 46, 45], [5, 318, 44, 2, 320, 16, 253, 1, 34, 2, 2540, 67, 6, 33, 19, 5, 4, 710, 2540, 118, 90, 20, 4884], [3, 86, 31, 4574, 486, 17462, 17463, 225, 52, 118, 396, 84, 453, 59, 48, 17464, 68, 16, 212, 183, 73, 17465, 1], [243, 928, 102, 6, 6, 400, 142, 27, 4, 1190, 18, 17466, 22, 561, 1344, 263, 11, 4, 885, 5752, 236], [18, 644, 16, 26, 293, 116, 49, 43, 95, 17467, 2037, 1566], [44, 2, 1, 46, 5734, 44, 1, 147, 46, 334, 12], [1, 14, 44, 2127, 1717], [23, 1233, 40, 41, 2, 1833, 18, 50, 24, 41, 2, 5322, 2436, 369], [5, 47, 37, 17468, 6, 14, 2, 9, 5, 210, 110, 509, 2287, 2, 1142, 255, 2, 6004, 1817], [199, 1, 81, 2353, 5, 103, 14, 4, 101, 1, 11, 20, 231, 34, 26], [22, 1, 33, 1807, 10, 314, 8, 3, 47, 314, 102, 32, 16, 39, 692], [10, 2644, 29, 67, 553, 650, 5, 2249, 4, 1612, 386], [2435, 814, 132, 1239, 2010, 73, 10, 1], [5959, 12, 1343, 7441, 10, 830, 47, 180, 17469, 22, 118, 14, 98, 3232, 2974], [57, 11, 4, 639, 19, 12, 567, 95], [75, 1175, 2037, 8, 2239, 461, 9], [28, 1], [8425, 1652, 136, 37, 239, 56, 2153], [463, 435, 49, 56, 31, 20, 2067, 12, 359, 8, 5, 29, 113, 84, 17470, 8, 421, 35, 126, 17471, 17472], [418, 118, 28, 515, 16, 2813, 2653, 79, 76, 2, 1, 8, 61, 477, 6, 8426, 81, 59, 71, 3298, 134, 50, 126, 17473], [84, 1708, 17474, 17475, 29, 100, 170, 308, 6, 350, 52, 549, 71, 5, 62, 4, 24, 936, 4016, 2208], [3, 105, 724, 15, 47, 1756, 6, 65, 13, 5, 220, 59, 6, 303, 60, 24, 8, 96, 65, 431, 288, 58, 15, 444, 794], [40, 82, 4, 3954, 40, 318, 44, 60, 9, 18, 4, 17476, 32, 675, 3243, 3194, 2887, 472, 13, 17477, 1188], [113, 5555, 11, 3372, 20, 1644, 8, 48, 202, 8, 52, 152, 79, 5, 2, 158, 27, 98, 1037, 332, 17478], [156, 1489, 6, 94, 111, 69, 56, 819, 8427, 3818, 6, 3925, 16, 819, 8427, 18, 8428, 2025, 5708], [25, 14, 13, 296, 41, 60, 9, 18, 4, 17479, 749], [291, 9, 292, 324, 54, 10, 231], [154, 2253, 11, 7, 1, 233, 686], [5, 1, 5, 46, 45, 3, 300, 5, 86, 5, 1872, 149, 5, 610, 1303], [1121, 21, 1693, 742, 2526, 31, 5, 48, 81, 59, 169, 1, 8, 692, 25, 29, 131, 465, 20, 45], [52, 137, 21, 4, 232, 117], [33, 2266, 2, 93, 4700, 1204, 122, 6, 1226, 10, 95, 4, 17480, 17481, 3037, 88, 3, 623, 7, 52, 47, 2, 1187], [552, 34, 3, 86, 25, 7, 13, 28, 235, 49, 315, 1, 57], [1765, 8429, 17482, 47, 56], [467, 60, 4464, 1, 53, 31, 15, 47, 5, 17483, 328, 4, 199, 2432, 53], [34, 40, 2, 9, 205, 117], [71, 6, 1189, 364, 459, 1928], [1156, 14, 18, 60, 497, 45, 26, 3, 61, 984, 6, 947, 9, 112, 5760], [2, 334, 77, 109, 1786, 277, 107, 27, 2, 1220, 476, 8, 5844, 101, 2, 9, 103, 100, 5, 58, 73, 5, 333, 149, 40], [1039, 2601, 317, 107, 17484, 37, 5, 165, 3587, 38, 5, 44, 630, 2, 3027, 230, 5, 450, 35, 27, 2, 9], [7, 203, 1, 1606, 474, 19, 15, 464, 3, 47, 889, 1965], [34, 31, 3, 298, 173, 7, 145, 571, 100, 5, 62], [3121, 336, 7, 1, 14, 1412, 17, 8053], [76, 45, 47, 1015, 73, 2, 1, 124, 6, 191, 21, 591, 8, 45], [5, 700, 29, 13, 17, 145, 3, 29, 109, 134, 2, 19, 71, 5, 150], [43, 1390, 17485, 1274, 4, 707, 3, 1562, 4, 247, 285, 100, 4, 351, 1433, 498, 2589, 2727], [17486, 106, 119, 24, 3, 299, 3, 47, 614, 6, 599, 119, 15, 37, 3, 450, 35, 1942, 50, 4172, 109, 4500, 66, 745], [3465, 3466, 31, 534, 49, 1491, 16, 591, 85, 277, 24, 28, 631], [53, 252, 415, 33, 86, 119, 24, 12, 249, 18, 24, 767, 53, 695], [4834, 48, 303, 1, 5020], [3404, 4743, 124, 1584, 402, 17487, 11, 84, 5183, 137, 11, 17488, 344, 3965, 26], [2638, 49, 229, 35, 713, 21, 197, 298, 355, 480, 74, 110, 627, 201, 114, 4, 56, 897, 22, 135, 46, 378, 26], [17489, 67, 2, 353], [1131, 173, 17490, 4, 95, 58, 254, 4, 1578, 58, 254, 7638, 480, 8430, 58, 254, 5, 62, 57, 8431], [5, 2, 9, 31, 5, 338, 2, 91, 331, 117, 92, 27, 2, 1980, 18], [1450, 96, 48, 404, 4, 2003, 27, 22, 8331, 30, 7426, 4496, 96, 2, 285, 43, 2297, 25, 11, 4, 192, 493, 42], [3, 33, 67, 6, 19, 1, 8, 477, 6, 17491, 17492], [39, 9, 46, 334], [31, 50, 24, 41, 129, 546, 481, 914, 15, 1923, 24, 101, 44, 1079, 259], [2204, 6, 20, 455, 1], [157, 7, 24, 18, 17, 70, 17, 67, 357, 499], [3, 62, 32, 212, 6753, 408, 69, 271, 17493, 3954, 1085, 49, 32, 18, 2793, 3396, 194, 2704, 648, 12, 2, 203, 1, 125, 2, 2189], [8432, 1012, 10, 887], [1091, 6399, 12, 37, 3392, 75, 72, 15, 602, 1154], [1775, 316, 3024, 1117, 6005, 17494, 3952, 3139, 82, 166, 123, 190, 17495, 554, 1328, 1817], [57, 4, 19, 12, 22, 1570, 158, 82, 4, 629, 2216, 8298, 58, 18, 4, 355, 4539, 21, 4, 2553, 57, 4, 948], [2, 870, 202, 287, 12, 2431, 2, 1, 7, 131, 687, 129, 155, 419, 184], [21, 4, 841, 106, 11, 4, 782, 1974, 4262, 4, 5368, 49, 11, 508, 2201, 16, 215, 507, 11, 4, 4754, 1398], [31, 22, 183, 6, 5, 5, 519, 2, 315, 25, 74, 2, 90, 30, 1], [6, 5705, 384, 1837, 2104, 11, 3830, 79, 4, 1755, 2104, 2, 3174, 17496, 2803, 2104, 382, 4, 1755, 2104, 325], [53, 161, 703, 1, 313, 136, 13, 2, 6935, 17497], [3, 29, 19, 27, 39, 9, 26, 3, 29, 19, 27, 25, 7, 172, 39, 9], [35, 27, 4, 95, 6, 1127, 18, 4, 5224, 2190], [23, 721, 3735, 200, 22, 17498, 60, 16, 42, 1, 125, 7, 68, 1390, 234, 63, 61, 3421, 26, 1390, 7, 166, 234, 5156], [1103, 2, 17499, 3045, 27, 2, 17500, 5655, 51, 4, 7531, 17501], [3, 90, 531, 21, 1426, 37, 417, 6, 39, 9, 1669, 233], [37, 1302, 13, 1823, 406, 38, 52, 1831, 24], [17502, 1386, 584, 4, 2550, 16, 4, 17503, 1350, 3525, 28, 2, 93, 327, 149, 22, 1, 46, 223, 14, 135, 17504, 1817], [825, 1215, 257, 404, 518, 11, 954, 2628, 159, 824, 11, 17505], [17506, 3163, 3184, 11, 1548, 3, 2150, 11, 4, 24], [3, 90, 38, 111, 338, 126, 56, 11, 10, 1832], [53, 5865, 39, 611, 323, 366, 1986, 86, 133, 8433, 425], [11, 4, 17, 4, 1170, 118, 119, 4, 1538, 2364, 2441, 48, 11, 4, 17, 2364, 1538, 492, 2150, 1170, 160, 98], [8, 202, 287, 87, 6, 139, 1191, 6, 943, 8, 166, 746, 73, 2731, 26, 17507, 15, 109, 46, 2, 93, 65], [3, 64, 76, 1740, 1], [243, 457, 1984, 4220, 55], [1, 5, 41, 99, 239, 1022, 11, 20, 476], [993, 17, 74, 151, 70, 5, 150, 89, 59, 254, 34, 31, 5, 19, 166, 189, 151, 79, 5, 2, 282, 8, 31, 5, 19, 17, 151, 22], [3828, 3, 210, 196, 6, 175, 22, 8434, 3, 17508, 17509, 12, 2, 83], [10, 17510, 17511, 420, 12, 17512, 1918, 21, 14, 713, 27, 2, 392, 2941, 1833, 11, 3913], [117, 92, 17513, 473, 1969, 159, 1186, 103, 14, 17514, 123, 2, 4740, 4537, 8435], [2, 320, 16, 574, 65, 51, 17, 13, 1472, 4, 19, 277, 22, 1, 86, 40, 17515, 4238, 17516, 6, 5], [29, 14, 214, 51, 17, 21, 113, 488, 14, 2091, 51, 4526, 21, 208, 13, 2, 1], [61, 309, 11, 2, 1556, 1], [243, 457, 6, 4, 7045, 104, 182], [43, 1, 3, 131, 694, 2, 19, 866], [31, 5, 75, 433, 4, 17517, 5, 318, 73, 219, 33, 61, 392, 144], [3, 29, 44, 106, 21, 39, 1133, 178, 33, 290, 17, 83], [10, 312], [79, 159, 1186, 6, 5250, 224, 17518, 22, 2428, 40, 893, 6, 1636, 608, 51, 17519], [3, 486, 2, 77, 2650, 50, 2440, 3195, 57, 7, 196, 29, 19, 50, 117, 11, 4, 24, 1140], [154, 1195, 2498, 189, 1117, 4, 606, 12, 1087, 8, 58, 2862, 2097, 17520, 543, 51, 5703, 4444, 3, 198, 683, 17521], [272, 192, 2, 19, 1492, 6, 492, 259, 8436, 55, 1141, 60, 1015, 1150, 30, 617, 35, 125, 60, 93, 138, 74, 285], [1402, 198, 44, 132, 544, 84, 1, 30], [3, 86, 17522, 110, 136, 521, 11, 4, 193, 52, 81, 56], [11, 4, 6006, 1, 66, 700, 167, 4, 199, 1, 11, 4, 6006, 1, 66, 223, 1467, 4, 199, 45, 11, 4, 6006, 1, 66, 17523, 167], [34, 289, 216, 60, 9, 710, 380, 943, 55], [3, 109, 90, 8437, 13, 40, 4653, 169, 8, 15, 48, 110, 50, 13, 1, 369], [55, 1, 208, 332, 38, 36, 271, 28, 36, 30, 257], [53, 33, 167, 15, 24, 53], [83, 66, 222, 44, 363, 6, 17524, 34, 17525], [526, 20, 2, 2157], [52, 56, 99, 570, 6, 79, 1670, 2190, 2, 1122, 912], [17526, 1894, 12, 24], [510, 6, 1036, 2521, 225, 6, 258, 159, 4961, 1922, 18, 4, 17527], [502, 50, 7, 5318, 15, 161, 3111, 842, 7761], [38, 40, 72, 40, 48, 2, 9], [1790, 16, 287, 837, 26, 3043, 8438, 7184, 26], [22, 399, 890, 1939], [23, 4, 3615, 1], [253, 10, 17528, 52, 136, 129, 17529, 1, 3, 216, 2, 2889, 17530, 10, 1, 225, 51, 4, 5273, 8439, 188], [31, 5, 5026, 8440, 6, 4, 24], [31, 2, 189, 182, 79, 17, 226, 270, 73, 1, 659, 1528, 3710, 278, 105, 182, 86, 1547, 59, 14, 27, 1167, 13, 19, 5, 3], [336, 25, 5, 2613, 138, 53, 366, 7, 3331, 1, 2613, 17531, 26], [3, 19, 80, 1, 29, 28, 214, 15, 295, 154, 3, 19, 326, 1], [3, 1131, 50, 98, 147, 24, 47, 631], [318, 94, 2, 1, 98, 627, 3, 167, 15], [1025, 35, 238, 19, 80, 1], [1, 28, 102, 186, 8, 262, 17, 108, 3, 64, 42], [66, 29, 64, 39, 9], [124, 6, 1089, 4, 95, 45, 102, 16, 10, 17532, 6135], [6, 4, 4736, 69, 1577, 79, 10, 331, 8, 49, 2187, 6, 999, 10, 306, 648, 2, 83, 4481, 11, 286, 1716], [71, 89, 42, 67, 256, 12, 8441, 31, 71, 89, 20, 103, 6, 197, 21, 4, 184, 42, 67, 427, 5158, 73, 4755, 73, 236], [11, 17533, 17534, 11, 2232, 17535, 17536, 17537, 1905, 1057, 17538, 17539, 3337, 9, 17540, 1676, 1905, 17541, 3727, 47, 17542, 1905, 3405, 8431], [17543, 54, 1369, 21, 4, 1, 7, 58, 343, 8, 1631, 155, 419, 6617], [7146, 49, 19, 17544, 7849], [10, 395, 959, 3957, 339, 72, 757, 5, 12, 17545], [2, 275, 17546, 17547, 12, 79, 2, 17548, 17549], [365, 228, 49, 43, 511, 130, 4405, 36, 741, 224, 985, 20, 5823, 1029, 34, 4685, 985, 20, 17550, 236], [1072, 467, 35, 6, 2367, 8442, 16, 591, 155, 115, 34, 36, 96, 652, 73, 640, 73, 60, 16, 5, 319], [1106, 17551, 4756, 49, 2420, 2510, 34, 58, 1838, 11, 4, 17552], [1960, 8, 725, 17553, 17554, 3045, 33, 363, 259, 18, 2088, 2562], [3119, 418, 715, 551, 9], [63, 265, 72, 209, 38, 126, 915, 389, 21, 474, 31, 52, 389, 155, 1005, 3, 75, 733, 1261], [76, 9, 46, 2531, 3, 528, 37, 332, 38, 275, 14, 32, 11, 10, 706, 34, 36, 44, 2, 830, 406, 27, 4], [29, 43, 112, 1, 67, 43, 1221, 2461], [39, 9, 46, 3462], [10, 500, 1, 176, 238, 14, 10, 244, 812, 38, 40, 79, 17, 794, 166, 115, 3, 273, 50, 134, 15, 2, 763, 1], [1, 97, 1741, 281, 3, 279, 21, 99, 64], [3, 2413, 4395, 47, 2, 8443, 43, 1, 43, 265, 32, 212, 3926, 2134, 67, 6, 14, 771, 27, 84, 4410, 435, 1020], [19, 3677, 99, 239, 131, 14, 17555, 31, 5, 191, 17, 78, 285, 23, 54, 22, 1, 244, 213], [5, 29, 62, 162, 20, 520, 12, 51, 18, 2, 1445, 264, 55, 52, 19, 166, 1, 7, 162, 52, 51], [25, 67, 2, 2699, 1202, 883, 8, 1, 67, 2, 2744, 1498, 916], [29, 194, 17, 5, 17556, 194, 20, 1, 25], [8067, 1889, 72, 2, 17557, 187, 86, 3, 72, 5505, 18, 4, 17558, 8, 753, 2739, 3, 121, 17559, 17560], [3, 2266, 10, 413, 19, 164, 1918, 21, 48, 14, 3740, 5, 75, 311, 628, 19, 17561, 74, 692, 4, 17562, 54], [232, 8444, 778, 17563, 82, 4, 8288, 21, 17564, 8445, 8, 17565, 17566], [463, 29, 67, 6, 28, 557, 13, 2, 236, 139, 472, 13, 2918, 1379, 5, 67, 6, 139, 28, 557, 13, 2, 17567], [1322, 270, 2, 368, 17], [48, 225, 83, 48, 225, 1933, 174, 2, 202, 17568, 42, 58, 62, 71, 3275, 7, 3], [55, 51, 10, 844, 8446, 20, 2, 529, 1, 17569, 221, 204, 32, 120, 17570, 12, 17571, 8446, 48], [1132, 2187, 10, 164, 744, 18, 1184, 37, 29, 453, 17, 288, 23, 2, 966, 4520, 6, 126, 971, 505, 24, 117], [4, 17572, 11, 49, 37, 144, 7, 36, 4757, 1462, 6, 28, 351, 522, 38, 17573, 330, 389, 21, 126, 522, 2061], [5, 63, 43, 1363, 298, 2, 624, 163, 770, 650, 15, 7192, 1273, 123, 378, 1086, 1143, 16, 144, 1370, 73, 17574], [574, 705, 201, 1, 59, 57, 495, 46, 200, 21, 240, 38, 1079, 106, 459, 546, 36, 46, 200, 45, 21, 7, 395], [4496, 2, 282, 71, 42, 276, 137, 211, 4, 1695, 8291, 3, 3449, 7, 3042, 447, 52, 547, 316, 268, 1499, 34, 52, 1221, 2], [40, 1189, 1321, 25, 5619, 1047, 263, 1670, 956, 148, 190, 574], [3, 29, 302, 7437, 39, 1, 8421, 39, 25, 17575, 37, 15, 48, 993, 4878, 278, 516, 33, 48, 19, 4737], [2, 1757, 259, 2, 611, 164, 84, 343, 12, 2, 780, 84, 730, 12, 879, 2233, 12, 98, 1034, 237, 228, 12, 2, 24, 8, 373, 188], [2344, 4, 3096, 6, 737, 2, 1], [321, 22, 1, 12, 2201, 123, 4, 593, 3364], [40, 168, 50, 343, 6, 313, 50, 88, 543, 50, 11, 4, 235, 88, 79, 50, 2, 1], [7, 386, 16, 2, 1, 1029, 38, 20, 294, 224, 4, 331, 27, 1568, 18, 8, 795, 18, 2, 1107, 631, 17576], [583, 52, 339, 33, 273, 84, 1246, 296, 67, 60, 8447, 207, 17577], [8365, 29, 308, 31, 5, 13, 743, 829, 20, 2, 494, 3042], [573, 3, 87, 6, 376, 6, 70, 76, 17578, 321, 37, 32, 4, 9, 271, 17579, 7424, 1417, 790], [120, 77, 7, 81, 17580, 20, 48, 342], [77, 27, 2705, 2292, 49, 9], [3, 65, 11, 4, 2772, 8, 94, 2, 24, 30, 1, 7, 400, 142, 38, 52, 17581], [40, 2, 17582, 3, 124, 2, 1960, 17583, 1209, 17584, 229, 50, 23, 98, 8246, 8, 157, 4, 24, 18, 4, 17585], [31, 52, 19, 80, 1, 42, 198, 14, 243, 13, 148, 1971, 19, 10, 1, 128], [3125, 12, 2, 19, 83], [180, 517, 9], [221, 857, 652, 1056, 2700, 11, 17586, 48, 22, 213, 283], [3429, 834, 58, 99, 209, 6, 28, 4619, 895, 7, 24, 124, 6, 44, 132, 1121], [3, 745, 124, 5999, 51, 10, 967, 11, 2, 213, 3, 29, 134, 2, 148, 133, 2, 886, 229, 13, 9, 163, 1443, 907], [91, 78, 9, 146, 497, 27, 22, 61, 905, 908, 15, 101, 2, 607, 69, 63, 428, 349, 15, 102, 34, 4, 763], [38, 3, 486, 435, 72, 17587, 27, 287, 12, 17588, 38, 3, 724, 78, 109, 122, 332, 21, 1, 701, 69, 2314], [1107, 9, 37, 3, 17589, 17], [3, 86, 4, 2193, 8, 3769, 1560, 502, 4, 1136, 2, 93, 73, 17590, 1398, 12, 33, 56], [354, 3063, 17591], [839, 860, 354, 26], [354, 17592], [354, 684, 3601, 5541], [2023, 1018, 1499, 851, 163, 354, 4758, 348, 904], [354, 1054], [354, 684, 853, 1054], [4, 1203, 16, 39, 1, 11, 6979], [39, 9, 46, 334], [17593, 16, 4, 360, 17594, 95, 8448, 17595, 26, 1127, 5984, 808, 17596, 26, 4943, 26], [2, 575, 12, 21, 201, 26, 26, 34, 5, 62, 60, 16, 5, 9, 29, 62, 71, 6, 914], [225, 51, 17597, 1, 58, 20, 5504], [1969, 7, 8449, 3048, 1480, 17598, 103, 2249, 1033, 1611, 159, 17599], [610, 4, 101, 507, 5, 63, 258, 640, 9, 8, 3084, 51, 4, 199, 106], [17600, 4042, 198, 44, 315, 646, 140, 36, 349, 625, 595, 1, 6, 20, 17601, 160, 8450, 3977, 17602], [1831, 4, 24, 117, 8, 40, 842, 5, 102, 5916], [53, 100, 61, 479, 35, 147, 1, 40, 101, 546, 831, 1821, 17603, 17604], [15, 587, 73, 4080, 285], [71, 63, 621, 90, 159, 925], [25, 14, 304, 21, 39, 480, 682, 1, 6, 2182, 6, 2, 706, 13, 188], [22, 12, 57, 582, 38, 25, 1069, 35, 183, 1], [1619, 595, 1238, 17605, 58, 143, 17606, 18, 147, 9], [10, 89, 280, 384, 9, 1136, 205], [85, 3, 47, 1967, 1071, 384, 9, 17607, 459, 1553, 35], [19, 17608, 169], [60, 275, 70, 14, 2, 9, 65, 37, 1016, 13, 148, 77, 29, 45, 2361, 80, 931, 601], [7, 202, 24, 44, 25, 854, 393], [63, 5, 187, 61, 787, 710, 461, 81, 59, 441], [4, 17609, 2532, 12, 156, 6, 79, 217, 1121, 203, 1272, 183, 74, 1375, 2, 9], [1379, 5, 29, 262, 17, 250, 66, 29, 262, 51, 17610, 7, 85, 20, 1045, 8, 419, 5, 185, 83], [463, 3056, 99, 8451, 1, 5, 1238, 99, 209, 242, 4, 19, 35], [296, 346, 10, 8452, 219, 3, 346, 17611, 1428, 242, 4, 19, 35, 5, 1779, 1], [250, 3, 1338, 10, 310, 88, 3, 262, 20, 1], [9, 103, 14, 319], [71, 1, 14, 38, 1520, 781, 114, 126, 758, 17612], [31, 3, 41, 256, 6, 72, 6, 5, 151, 410, 5, 444, 88, 29, 14, 2515, 59, 10, 175, 83], [31, 3, 124, 8453, 8, 10, 77, 124, 8454, 3, 118, 44, 8453, 26, 14, 419, 426, 3, 1138, 19, 27, 291, 283, 28, 20, 169, 562], [31, 289, 182, 1001, 5, 23, 4686, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 7, 20, 2, 2512, 161, 83], [31, 289, 1001, 5, 23, 727, 370, 7, 20, 2, 161, 1, 27, 43, 1237, 16, 5736], [15, 589, 73, 286, 38, 77, 175, 59, 3509, 32, 921, 66, 29, 134, 2, 19, 83, 3509, 12, 1504, 359, 6007], [39, 1682, 1164, 206, 1, 109, 41, 7, 4134, 2872, 25, 1285, 86, 59, 192, 2, 754, 2658, 23, 328, 27], [225, 4759, 20, 96, 2, 9, 7, 12, 1284, 44, 2, 417, 115], [1, 103, 687, 27, 5, 21, 954, 1204, 8, 88, 14, 13, 463, 62, 57, 3, 46, 152, 687, 27, 1323, 1, 57], [1, 27, 43, 1169, 74, 30, 29, 110, 28, 2, 1420, 82, 1566, 20, 68, 16, 4, 177, 3448, 5, 28, 2, 17613], [3, 29, 134, 2, 19, 57, 10, 500, 12, 17614, 1, 427, 10, 437, 1046], [23, 48, 1395, 247, 111, 49, 33, 2512, 141, 1], [945, 31, 42, 375, 38, 1824, 82, 759, 2732, 440, 263, 27, 7, 166, 1, 30, 25, 852], [38, 1, 81, 59, 126, 1214, 1978], [1, 58, 2, 17615, 397, 51, 22, 460], [422, 944, 19, 4, 111, 69, 2131, 18, 126, 421, 38, 4, 480, 227, 1343, 1352, 7, 45, 1], [3, 394, 3, 167, 7, 812, 13, 2, 178, 3273], [25, 139, 134, 39, 9, 701, 71, 59, 800, 573, 681, 661, 16, 800, 39, 470, 927, 8455], [26, 14, 2, 9, 12, 2, 17616, 143, 85, 77, 157, 1177, 2973, 11, 36, 1618, 38, 36, 28, 6423, 253], [68, 106, 17, 8, 22, 1380, 1, 47, 194, 2, 629], [3, 486, 4, 7967, 34, 3, 33, 299, 40, 47, 2, 9], [25, 4592, 315, 826, 134, 25, 24, 8, 36, 17617, 2234], [3088, 2673, 213, 206, 96, 1459, 9], [3, 131, 376, 34, 23, 619, 27, 22, 158, 55, 122, 6, 662, 170], [8184, 5, 47, 533, 56, 13, 3, 452, 258, 3217], [709, 210, 62, 362, 52, 2, 141, 83, 4928, 6319, 18, 4, 166, 402, 5, 17618, 7, 189, 62, 4017], [219, 71, 499, 103, 120, 574, 28, 263, 6, 627, 305, 6880, 722, 166, 130, 6, 1622, 2, 322, 406, 16, 236], [7570, 23, 114, 17619, 1666, 82, 92, 962, 80, 9, 8, 133, 6, 635, 17, 173, 43, 1478, 74, 635, 17, 129, 4, 17620], [3, 44, 48, 194, 820, 201, 16, 4, 7832, 23, 37, 129, 76, 319, 3, 29, 110, 279], [31, 5, 63, 1240, 294, 11, 20, 3261, 74, 20, 472, 1, 5, 49, 122, 6, 332], [3981, 44, 41, 6, 14, 4, 247, 974, 386, 16, 1, 182, 3, 17621, 32, 5983, 15, 48, 98, 1016, 401], [3, 293, 3, 216, 39, 1616, 348, 117], [31, 20, 175, 44, 105, 1001, 621, 88, 5, 175, 13, 2, 141, 83], [333, 404, 15, 32, 22, 213], [38, 388, 902, 224, 27, 4, 3196, 2652], [183, 111, 1041, 3097, 1041, 9, 1041, 326, 1041, 17], [52, 109, 157, 6008, 1, 17622], [128, 3, 90, 7, 9, 330], [425, 1, 41, 10, 310], [25, 4563, 8279, 38, 15, 107, 6, 28, 60, 24], [39, 2317, 940, 9, 46, 334], [38, 42, 192, 623, 7, 482, 12, 2, 9], [38, 5, 28, 987, 82, 4, 17623, 1, 11, 4, 712], [120, 56, 6009, 3795, 292], [1, 14, 13, 584, 2, 17624], [1, 11, 848, 261, 14, 13], [71, 6, 28, 8391, 24, 11, 314, 261], [24, 30, 25], [945, 31, 42, 375, 38, 1824, 82, 759, 2732, 440, 263, 27, 7, 166, 1, 30, 25, 852], [22, 1, 51, 4, 1483, 1471, 13, 1753, 2234], [22, 4, 296, 137, 1520, 359, 18, 77, 8, 255, 3104, 1934, 3481, 2572], [923, 168, 6, 14, 2, 2368, 21, 2749, 15, 12, 92, 1129, 472, 13, 20, 4547, 9, 921], [3, 293, 2, 95, 45, 18, 20, 231, 83], [20, 2, 1, 7, 154, 3256, 267], [1555, 111, 81, 37, 209, 45, 13, 69, 4, 19, 49, 5, 1], [38, 482, 227, 54, 6, 14, 2, 9], [227, 35, 59, 6, 14, 112, 17625, 27, 10, 1, 21, 4, 696, 3098, 390, 2008, 3398, 740], [22, 1, 86, 40, 342, 8, 44, 32, 4, 189, 129, 50, 17626, 174, 365, 2117, 33, 13, 174, 1349, 52, 29, 110, 13, 42, 411], [462, 31, 20, 24, 372, 13, 22, 333, 167, 10, 17627, 3, 87, 5, 21, 2, 4154, 1969], [50, 1096, 517, 30, 2462, 59, 15, 2, 17628, 8456, 71, 1, 71, 57, 78, 2513, 21], [147, 25, 564, 280, 52, 753, 17, 13, 2, 1], [900, 25, 1156, 125, 900, 1, 2712, 17629], [23, 2, 28, 169, 25, 37, 143, 9, 64, 17], [31, 42, 436, 2, 1, 913, 40, 3149, 17630, 1138, 436, 143, 329, 1], [31, 127, 913, 473, 25, 63, 72, 765, 6010, 80, 1, 42, 17631, 14, 2209, 50], [564, 1, 156, 131, 122, 201, 137, 2, 112, 25, 13, 2, 564, 1, 143, 71, 42, 28, 557, 163, 311, 1394], [17632, 273, 17, 38, 84, 2328, 28, 1363, 52, 33, 223, 429, 35, 8, 19, 25, 1, 128], [5, 113, 17, 23, 681, 13, 5, 113, 155, 166, 83, 107, 18, 8457], [2356, 1137, 227, 2, 9, 173, 2, 2255, 8, 4004, 227, 2, 2255, 173, 2, 9, 3, 300, 22, 45, 63, 582], [4, 529, 49, 8, 15, 1790, 16, 17633, 48, 17634, 1919, 53, 17635, 382, 1223, 1755, 2749, 26], [57, 329, 27, 39, 1, 3290], [39, 9, 17636], [19, 42, 1, 293, 3, 29, 94, 42, 1, 218, 3, 118, 64, 21, 42, 6, 113, 17, 6, 10, 17637], [1, 2907, 4, 324, 2561, 140, 36, 2561, 283], [23, 48, 110, 179], [1, 14, 13, 19, 3612, 34, 3612, 17638, 13, 19, 283], [7, 9, 17639, 17640], [367, 23, 1105, 5, 123, 4, 193, 5, 472, 83], [1829, 115, 461, 17641, 12, 2, 115, 17642, 17643, 4057], [9, 103, 14, 319], [154, 821, 35, 51, 17644, 7256, 2311, 2555, 72, 17645, 21, 5633, 8, 3172, 4, 17646, 6, 44, 2, 17647, 26], [23, 152, 70, 22, 1436, 959, 10, 1, 2199], [2026, 3, 94, 8250, 17648, 70, 2, 137, 3, 67, 6, 7729, 265, 1419, 132, 2, 17649, 267, 159, 17650], [191, 4, 3798, 6, 2992, 17651, 12, 13, 191, 144, 6, 2992, 17652], [5641, 7636, 382, 4, 154, 79, 16, 3384, 178, 288, 28, 204, 17653], [8458, 1294, 1124, 8459, 221, 8460, 35, 11, 22, 368, 175, 47, 2, 7280], [1504, 54, 116, 2, 388, 12, 2600, 102, 27, 2, 402, 286, 468, 11, 2, 5806, 2465, 2199], [78, 146, 139, 2870, 39, 183, 9, 235, 35], [29, 43, 414, 67, 2, 91, 7, 208, 13, 2, 1], [3, 191, 325, 1, 6, 28, 17, 591, 546, 1204, 892, 162, 5652, 12, 15], [10, 674, 1460, 17, 2353, 2637, 52, 121, 4, 95, 19, 4, 17654, 88, 52, 273, 17, 52, 1467, 2, 77, 37, 332, 50, 5674, 1327], [31, 174, 17655, 8, 96, 87, 174, 915, 4403, 6, 58, 1216, 174, 2, 141, 1], [39, 591, 1611, 49, 144, 73, 1066], [9, 3, 41, 1368, 36, 546, 74, 165], [44, 2, 930, 551, 1], [31, 3, 167, 5, 125, 7, 5830, 1, 3, 394, 97, 481, 788], [37, 230, 5, 255, 2, 4165, 28, 80, 24, 11, 536], [25, 29, 453, 958, 9], [171, 1], [22, 1, 510, 6, 4, 489, 27, 2, 2085, 833, 1, 5, 686], [17656, 76, 1682, 7, 107, 54, 22, 696, 37, 56], [8461, 3755, 92, 136, 2, 606, 619, 232, 1330, 226, 211, 170, 678, 1055, 44, 560, 124, 17657, 2552, 26], [4760, 435, 191, 21, 8462, 17658, 24, 30, 1, 191, 21, 5346, 112, 435, 49, 54, 116, 197, 21, 287, 26, 428, 1188], [540, 6, 14, 2, 3598, 160, 43, 1230, 160, 43, 1286, 160, 697, 343, 160, 42, 28, 6, 5480, 435, 173, 126, 989, 560, 351, 949], [533, 133, 4, 244, 1, 34, 5, 46, 133, 385], [5, 1300, 7, 1], [4, 1170, 2559, 5, 6, 271, 423, 82, 4, 6700, 103, 5, 4, 931, 8081, 26], [38, 97, 291, 101, 112, 1, 741, 224], [354, 17659], [1830, 3188, 396, 4, 742, 178, 38, 52, 121, 757, 23, 2857, 130, 2, 17660], [38, 161, 1441, 121, 17661, 6379, 1, 72, 8463, 6, 17, 40, 113, 2, 1380, 1, 8, 40, 72, 296, 146, 17662, 10, 5046, 383], [38, 5914, 17663, 7, 25, 56], [31, 2, 1, 222, 14, 550, 27, 19, 2, 91, 62, 52, 136, 2, 77, 40, 2, 9, 7, 254], [737, 2, 1, 43, 4007], [1962, 1824, 17664, 33, 17665, 1945, 3372, 6, 4, 2527, 17666, 17667, 41, 4, 796, 7242, 36, 29, 404, 182], [1655, 70, 5, 86, 59, 19, 2, 666, 16, 89, 1, 5521, 70, 5, 4608, 898, 70, 5, 131, 86, 8464], [430, 2, 1, 1431, 10, 714, 6605, 18, 4, 1868], [161, 185, 30, 1, 3, 29, 19, 27, 5], [560, 33, 140, 5, 249, 138, 317, 196, 5, 44, 6, 208, 13, 2, 711], [101, 144, 8, 586, 694, 997, 1639], [9, 14, 11, 326, 754, 8, 41, 4, 1203, 6, 114, 2, 406, 91, 7, 45, 284], [139, 1365, 80, 653, 370, 30, 1, 29, 357, 279, 4628, 5, 372, 4131], [3, 1702, 2, 320, 16, 45, 8, 3, 33, 528, 149, 39, 9, 60, 3953], [15, 268, 511, 184, 5, 9, 198, 62, 140, 2, 320, 16, 5, 9, 86, 2346, 62, 17], [25, 1394, 36, 142, 1, 21, 2, 1, 69, 142, 6, 1431], [159, 925, 2131, 1350, 21, 4736, 84, 8465, 20, 2, 1395, 1718, 27, 89, 2675], [926, 1286, 8, 1229, 207, 5, 65, 13, 2, 181], [5, 62, 39, 9, 3438, 3439], [38, 5, 8, 20, 177, 2048, 2, 9, 26], [23, 515, 16, 203, 9, 79, 943, 17668, 1, 80, 203, 30, 75, 110, 3777, 129, 8, 881, 20, 1109, 17669, 188], [10, 453, 12, 37, 1891, 2, 95, 33, 1780, 173, 4, 234, 16, 10, 1643], [5683, 56, 30, 17670, 8466, 97, 1729], [32, 1, 12, 2349], [4400, 5899, 12, 56], [38, 5, 94, 482, 800, 74, 844, 60, 9], [3, 47, 330, 899, 38, 891, 5110, 37, 3, 124, 2804, 16, 2530, 34, 244, 213, 12, 61, 6, 14, 727, 5759, 6911], [42, 113, 263, 5, 172, 17671, 277, 24, 1402, 109, 547, 97, 2189, 632], [898, 121, 15, 237, 38, 52, 121, 2597, 208, 127, 13, 1, 39, 17672], [23, 2, 1, 20, 2, 83, 20, 306, 2, 1, 21, 44, 2, 1, 20, 586, 2, 1, 21, 19, 2, 83, 92, 69, 965], [3, 90, 38, 1, 1580, 133, 71, 36, 1214, 157, 15, 142, 8467, 88, 36, 419, 749], [204, 240, 32, 51, 469, 3, 3122, 4, 360, 103, 14, 2, 165, 507, 38, 1, 13, 50, 309, 1045, 26], [1192, 5, 4695, 1, 3, 318, 14, 149, 10, 2827, 37, 2409, 2356, 454, 318, 94], [7522, 1, 407, 542], [113, 170, 7, 5, 2603, 17673, 48, 6, 56, 4, 17674, 288, 122, 6, 492, 15, 13, 2, 2490, 17675], [515, 16, 799, 27, 39, 9, 34, 10, 138, 48], [9, 168, 17676, 33, 8468, 919, 73, 2, 196, 6, 7890, 125, 76, 14, 2, 1989, 36, 70, 15, 598, 73, 31, 36, 124, 43, 829, 709], [7, 71, 25, 28, 359, 962, 40, 308, 11, 174, 231, 426, 40, 11, 3594, 59, 50, 9, 6011, 34, 40, 113, 50, 3036, 1360], [287, 86, 36, 49, 17677, 37, 36, 14, 11, 3594, 59, 126, 373, 9, 6011, 29, 616, 173, 126, 17678, 94, 722, 4, 340], [2352, 317, 17679, 30, 111, 1838, 31, 5, 29, 397, 4, 19, 35, 21, 630, 26, 139, 14, 2, 24], [1657, 27, 1, 18, 186, 13], [68, 334, 504, 12, 783, 127, 130, 2, 2860, 319], [3142, 1815, 2048, 7, 1, 58, 11, 488, 14, 3882], [469, 1, 28, 4, 17680], [8469, 41, 60, 183, 9, 221, 8, 76, 8470, 3686, 1607, 46, 70, 43, 2058, 8471, 16, 240, 5121, 5, 46, 17681], [22, 1, 2201, 123, 4, 593, 5996], [1628, 16, 93, 77, 216, 2, 186, 26, 3086, 2, 9, 21, 4, 701, 36, 29, 3634, 82, 126, 17682], [17683, 39, 9, 21, 8472, 166, 324, 29, 64, 39, 9, 1047, 51, 160, 17684], [32, 39, 9, 67, 12, 667, 93, 138, 26, 701, 17685, 17686], [195, 3, 4, 101, 25, 7, 19, 2, 17687, 772, 50, 6, 17688, 40, 407, 110, 17689, 5, 48, 2, 17690, 996], [3, 41, 60, 859, 138, 82, 2, 3977, 2, 3899, 201, 7938, 2, 17691, 17692, 3071, 32, 11, 4, 199, 2861, 23, 48, 2, 17693, 33, 72], [3, 380, 10, 17694, 56, 140, 553, 16, 76, 41, 17695, 6012], [3, 62, 31, 10, 1214, 421, 35, 545, 17, 151, 671, 4, 796, 9, 16, 32, 106, 17696, 19, 621, 69, 65, 10, 193, 426, 278, 14, 725], [10, 481, 914, 363, 82, 378, 6, 1079, 11, 68, 17697, 23, 48, 2, 9, 33, 64, 352, 8473], [8450, 64, 6, 119, 24, 51, 126, 1402, 17698, 160, 6012], [37, 10, 3036, 19, 22, 3977, 34, 141, 277, 40, 62, 40, 33, 1339, 17699, 71, 10, 24, 17700, 6012], [263, 391, 28, 127, 137, 130, 247, 25, 8473], [1345, 77, 44, 4, 237, 24, 160, 17701], [57, 7, 2409, 190, 184, 4, 2286, 33, 229, 6, 1920, 4761, 3, 75, 375, 94, 68, 16, 212, 230], [225, 12, 4, 101, 115, 5, 9, 28, 2, 433, 21, 14, 2, 902], [78, 72, 1542, 5, 438, 161, 5664, 13, 2424, 9, 33, 18, 2, 8474, 3395], [3, 33, 19, 80, 1, 4229, 3, 122, 48, 6, 205], [773, 7378, 3, 19, 80, 1, 361, 123, 17702], [76, 17703, 1], [149, 1, 23, 4671], [663, 96, 11, 4, 199, 1251, 73, 17704, 1712, 990, 27, 4, 199, 17705, 376, 27, 4, 199, 319, 119, 82, 4, 199, 17706], [18, 10, 779, 5, 2, 9, 3272, 5, 2, 1, 3272, 31, 5, 28, 11, 2, 1873, 3, 394, 5, 1431, 3272], [349, 35, 13, 65, 51, 10, 845, 1], [17707, 98, 4752, 710, 106, 22, 213, 52, 2909, 217, 793, 1343], [15, 550, 21, 1486, 1620, 6, 382, 3031, 34, 31, 2017, 382, 1620, 123, 1463, 6, 44, 2, 138, 11, 84, 476, 3944, 28, 2], [19, 1716, 36, 640, 21, 17708, 36, 415, 19, 747, 17709], [212, 613, 386, 16, 1, 99, 17710, 251], [17711, 31, 42, 375, 38, 1824, 82, 759, 2732, 440, 263, 27, 7, 166, 1, 30, 25, 852, 53], [155, 115, 3, 267, 10, 25, 847, 21, 341, 1919, 8, 10, 17712, 3136, 6, 2464, 6, 39, 283], [215, 264, 47, 431, 444, 25, 47, 127, 475, 133, 263, 130, 17713, 13, 7, 32, 4, 817], [64, 68, 16, 5, 1857, 235, 9, 17714], [321, 85, 195, 3, 156, 17715, 515, 34, 3, 105, 376, 23, 13, 2, 154, 2475, 16, 144, 43, 974], [3, 454, 38, 15, 41, 1252, 6, 14, 2, 1139, 1], [66, 32, 62, 22, 25, 2, 2200, 25, 41, 1203, 18, 1610], [159, 925, 12, 2, 19, 900], [1082, 16, 39, 275, 78, 4001, 506, 24, 4113, 4005, 843, 32, 7, 188, 29, 14, 902], [3, 1725, 122, 6, 547, 217, 54, 31, 3, 75, 1389, 4006, 3, 67, 6, 13, 126, 3961, 327, 13, 17716, 151, 313, 22, 1], [3, 86, 23, 1812, 6, 927, 406, 8, 400, 81, 133, 1, 7, 66, 603, 124], [17717, 83], [324, 44, 1527, 9, 3453], [1676, 5238, 17, 1057, 17718, 483, 9, 855, 17719, 3783, 5979, 1057, 2445, 17720, 17721, 12, 6749, 4762], [3, 33, 592, 98, 354, 11, 10, 17722, 12, 15, 20, 267, 21, 65, 211, 15, 17723], [2, 95, 2715, 18, 307], [15, 47, 32, 1343], [18, 22, 4, 345, 4144, 8475, 12, 17724, 8, 382, 305, 5026, 6, 4, 6782, 82, 5397, 98], [460, 16, 529, 33, 1575, 2, 202, 252, 11, 4, 5135, 4, 460, 16, 1317, 18, 287, 33, 1575, 250, 182, 414, 11, 388], [38, 23, 633, 3, 519, 61, 17725, 17726, 8, 168, 180, 324, 74, 3, 61, 179, 5440, 8, 81, 13, 23, 8476, 519, 193, 3], [149, 1403, 62, 31, 246, 1, 79, 80, 25, 3643, 8, 52, 1182, 15, 32, 286, 152, 421, 17727], [217, 51, 4, 1478, 244, 676, 12, 8088, 17, 123, 44, 2, 3127, 61, 51, 17728, 3, 86, 278, 311, 2, 1, 21, 2, 6417], [15, 1455, 17, 71, 1310, 15, 12, 21, 77, 6, 14, 4674, 1, 38, 4652, 14, 33, 73, 1016, 21, 76, 6, 14, 1975, 26, 17729, 4762], [3, 62, 71, 11, 4, 1029, 111, 63, 2305, 1047, 3095, 37, 919, 17, 21, 48, 302, 5, 14, 19, 35, 224, 319], [3, 29, 13, 77, 17730, 132, 224, 25, 109, 14, 2209, 2227, 285], [15, 568, 6, 50, 2121, 8, 50, 235, 426, 15, 17731, 12, 180, 680, 1], [19, 2651, 5, 17732, 56, 7858], [10, 520, 427, 1166, 6, 134, 2, 77, 84, 17733, 7, 9, 62, 148, 219, 57, 3747, 4, 1032, 12, 18, 40, 17734], [1126, 87, 39, 292, 3444, 17735, 1472, 8477, 3529, 5, 4082], [31, 10, 675, 1001, 5, 2694, 23, 370, 2936, 15, 266, 582, 361, 3258, 378, 26, 201, 49, 308, 6013, 20, 2, 24, 17736, 20, 306, 90, 5], [31, 10, 175, 1001, 5, 1121, 139, 14, 2, 2512, 24, 1272, 19, 20, 150], [1436, 620, 1, 1436, 1436, 620, 1, 1436, 620, 1, 1436, 1436, 620, 1, 546, 546, 546, 8, 787, 1805, 1243, 83], [429, 2, 1361, 85, 29, 60, 16, 5, 9, 192, 429, 1809, 829], [72, 1063, 211, 1392, 20, 3461], [4, 3624, 5, 49, 4, 2245, 20, 3467, 37, 33, 14, 2, 1], [183, 111, 1041, 3097, 1041, 9, 1041, 326, 1041, 17], [694, 5880, 28, 32, 4, 1], [99, 239, 93, 419, 77, 99, 239, 9, 3073], [3, 222, 14, 270, 2, 1, 117, 615, 34, 151, 17737, 2542], [1, 119, 214, 17738, 2794, 8, 58, 4, 8108, 856, 7, 85, 36, 24, 156, 1729], [4, 17739, 582, 6, 50, 26, 46, 777, 1128, 130, 2, 89, 1, 7, 514, 15], [38, 3, 47, 141, 3, 375, 973, 17740, 11, 618, 73, 402, 5458, 3292, 2, 382, 4749, 17741, 17, 16, 157, 10, 402, 35, 2812], [1031, 24, 1, 5, 4, 409, 7, 41, 17742], [64, 2, 1, 7, 105, 208, 1991], [232, 982, 110, 2361, 6, 229, 35, 6, 3814, 720, 33, 4200, 4, 8478, 2055, 8317], [3, 249, 2, 1055, 138, 3, 249, 2, 703, 138, 3, 249, 2, 104, 138, 3, 249, 2, 158, 138, 3, 249, 4, 138, 7, 1093, 17], [1313, 4713, 17, 966, 2467, 1883, 17743, 1369, 4713, 17, 75, 598, 6, 253, 39, 4, 434, 17744, 4763, 353], [3, 86, 247, 435, 359, 140, 374, 1812, 6, 7, 154, 24, 17745], [4, 3155, 3155, 41, 6, 4, 120, 574, 15, 99, 713, 128, 36, 672, 22, 9, 17746, 26], [1830, 3188, 12, 17747, 721, 217, 121, 15], [702, 1250, 346, 5, 1], [53, 17, 8, 10, 994, 41, 6, 2587, 9, 1749, 2281], [1, 5, 165, 137, 545, 22, 717, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1327, 888], [53, 1035, 3, 172, 90, 38, 22, 1, 29, 729, 10, 79, 8479, 53, 1035, 3, 90, 50, 30], [23, 18, 61, 37, 1, 4919, 17748], [3, 75, 397, 22, 171, 19, 1], [3, 195, 7, 1765, 228, 69, 509, 20, 262, 88, 157, 4, 310, 142, 6, 58, 256, 8, 627, 6, 1257, 444, 445, 236], [39, 206, 9, 12, 6612, 7, 8, 1300, 36, 17749], [57, 49, 5, 17750, 221, 18, 2, 1844, 16, 68, 6, 1654, 1], [3142, 1815, 2048, 7, 1, 58, 11, 488, 14, 3882], [262, 1, 51, 5992, 70, 126, 301, 107, 3602], [71, 183, 1, 114, 1142], [53, 17751, 66, 124, 9, 13, 7, 1497, 3, 47, 11, 6638, 36, 32, 124, 5123, 143], [1, 19, 19, 8480, 61, 709, 8481, 19, 709, 8481, 19, 8480, 33, 265, 6894, 17752, 1764, 83], [1739, 56, 17753, 1593, 12, 2295, 6, 1975], [10, 646, 67, 6, 157, 18, 98, 1034, 17754, 33, 6, 28, 17755, 57, 582, 38, 5, 100, 24, 829, 5, 5], [503, 1654, 992, 27, 43, 9, 17756, 17757, 17758, 17759, 17760, 1080, 17761, 17762, 361, 17763, 17764, 17765], [5461, 2622, 382, 4395, 17766, 84, 8482, 51, 4, 8483, 17767, 123, 17768, 17769, 17770], [3465, 3466, 6014, 31, 40, 113, 17, 6, 61, 262, 10, 166, 9, 34, 40, 68, 16, 10, 9, 58, 3, 176, 262, 50, 53, 26], [422, 23, 194, 2321, 1259, 17771, 16, 76, 47, 7153, 34, 2321, 1159, 6015, 5926, 407, 637, 6, 17, 1259, 17772], [3465, 3466, 6014, 31, 40, 113, 17, 6, 61, 262, 10, 166, 9, 34, 40, 68, 16, 10, 9, 58, 3, 176, 262, 50, 53, 26], [296, 44, 352, 27, 2, 320, 16, 189, 34, 23, 48, 2, 17773, 3, 63, 506, 1144, 6, 111, 8, 48, 14, 2, 692, 5309, 1449, 9], [31, 97, 77, 262, 108, 981, 5, 146, 167, 50, 27, 4, 2236, 69, 499, 5, 17774, 194, 7, 1, 28, 127, 2145, 130, 17775], [5, 182, 79, 20, 500, 288, 20, 19, 20, 234, 1, 447, 23, 152, 58, 7, 790], [288, 4, 435, 103, 1725, 14, 17776, 8, 144, 4, 287, 103, 2052, 3392, 8, 5666, 8226, 8, 17777, 26], [53, 1733, 4108, 63, 268, 294, 612, 650, 36, 49, 1279, 53], [7, 21, 4, 942], [17778, 2702, 17779, 252, 44, 2, 17780, 20, 144, 38, 20, 8484], [29, 302, 39, 9], [320, 16, 8485, 26, 9, 26], [39, 9, 13, 25, 7, 1049, 169, 48, 81, 59, 15], [3, 13, 71, 3, 592, 54, 7, 5, 63, 92, 4477, 1126, 1088, 539, 2, 1839, 3371, 18, 1610, 5, 86, 278, 465, 1261, 188], [148, 39, 1, 11, 848, 261, 65, 1262, 483, 11, 39, 677], [427, 15, 356, 7, 4, 111, 69, 79, 17, 203, 183, 2, 835, 185, 2, 187, 2, 1, 2225, 49, 4, 199, 68, 1545, 1261], [3, 67, 2, 112, 575, 43, 178, 43, 308, 43, 234, 9, 33, 17, 8, 5], [3415, 847, 22, 75, 14, 112, 8486, 6, 179, 6, 14, 112, 55], [31, 5, 1252, 17781, 103, 442, 5, 44, 4, 4724, 1804, 16, 31, 5, 109, 58, 74, 58, 48], [377, 197, 2465, 1682, 2953, 1938, 204, 38, 126, 3, 8487, 6016], [23, 48, 542, 6, 94, 78, 9, 175, 3145, 213, 154, 986], [1558, 105, 3, 14, 4418, 3, 29, 41, 43, 25, 26, 21, 10, 206, 9, 19, 32, 76], [6627, 307, 410, 4, 203, 1, 69, 203, 34, 86, 40, 834, 8, 2, 180, 595], [6008, 9, 28, 43, 8221, 160, 17782, 17783], [17784, 2618, 44, 43, 409, 89, 1, 12, 2843, 101, 184, 2310, 2618, 3498, 160, 17785, 17786], [8, 18, 4, 2588, 115, 274, 121, 2237, 9, 49, 21, 8472], [215, 226, 17787, 250, 226, 571, 13, 174, 2519, 11, 794, 4562, 52, 41, 42, 1112, 13, 2092, 17788], [85, 97, 25, 14, 8488, 39, 963, 30, 1], [546, 348, 446, 21, 5], [455, 540, 85, 3, 46, 41, 43, 77, 149, 3, 46, 105, 592, 48, 378, 1, 69, 238, 28, 169, 125, 17, 32, 78, 9, 13], [855, 1, 300, 765, 1148], [2, 77, 62, 38, 2, 1, 13, 50, 520], [19, 987, 1, 63, 5, 867], [3, 79, 10, 1757, 4, 6017, 140, 37, 239, 1, 363, 142, 18, 254], [20, 1242, 12, 1555, 140, 5, 49, 2, 838], [2, 77, 175, 463, 318, 14, 179, 31, 42, 316, 522, 82, 619, 173, 4, 3099, 43, 42, 318, 14, 185, 31, 42, 389, 3100, 21, 2], [2262, 12, 37, 17789, 2, 161, 1], [179, 30, 5625], [12, 15, 2, 2672, 31, 2, 25, 33, 131, 119, 24], [31, 5, 29, 13, 10, 175, 27, 10, 4492, 11, 847, 3050, 333, 538, 15, 34, 29, 382, 15, 74, 70, 1864, 8489], [17790, 1920, 12, 17791, 19, 56], [9, 14, 61, 539, 2214, 38, 36, 252, 11, 865, 426, 166, 275, 17792, 273, 4, 199, 45, 36, 32, 87, 6, 14, 116], [642, 296, 103, 156, 58, 57, 12, 3146, 6, 1367, 4, 732, 111, 8, 2024, 641, 3157, 2551, 6, 305, 236], [3, 64, 2, 89, 1, 27, 2, 764, 552, 85, 34, 2, 4951, 7, 2, 1828, 12, 643, 73, 19], [23, 2438, 1694, 140, 39, 9, 46, 334], [17793, 1362, 215, 264, 1087, 51, 2507, 3202, 463, 2, 1, 30, 17794, 26], [17795, 5, 2, 104, 21, 543, 2, 1194, 1487, 33, 41, 257, 17796, 6, 292, 11, 17797], [22, 118, 105, 582, 51, 2, 17798, 2276, 229], [3, 46, 238, 94, 158, 645, 11, 2, 4168], [66, 75, 14, 431, 31, 5, 152, 14, 2, 141, 1, 32, 4, 106], [37, 31, 50, 645, 29, 1849, 612, 7, 196, 50, 17799, 12, 56, 188, 3, 33, 566, 1305], [31, 40, 317, 114, 15, 11, 4, 30, 113, 4, 1, 604, 17800], [800, 31, 5, 19, 217, 1], [3, 105, 2467, 7, 413, 8490, 18, 2, 1, 1839, 7, 47, 61, 17801, 13, 10, 1, 656, 4039], [3, 33, 2313, 2, 9], [1644, 207, 347, 3, 842, 158, 792], [159, 925, 12, 4, 91, 55], [701, 645, 46, 21, 3109, 1047, 5, 3881, 65, 9], [23, 48, 72, 40, 2, 9, 34, 40, 132, 18, 127, 7506, 130, 17802, 17803], [66, 146, 28, 2256, 16, 56, 30, 1285, 1609], [57, 582, 6, 4, 206, 1319, 4, 17804, 1155], [25, 801, 13, 2, 161, 1, 55], [10, 1346, 30, 387], [1290, 3900, 200, 2, 1, 420], [31, 5, 113, 50, 4, 138, 93, 40, 223, 131, 122, 113, 50, 15, 963, 40, 223, 131, 94, 21, 8342, 2, 9, 223, 14, 2, 1188], [447, 3, 41, 180, 402, 55, 23, 2, 180, 1, 3543, 55, 23, 48, 276, 44, 969, 402], [99, 239, 1, 8491, 8492, 18, 126, 17805, 75, 316, 295, 6, 4, 1879, 34, 947, 13, 8, 98, 1074], [15, 13, 4, 189, 7, 191, 21, 20, 518, 8, 88, 72, 5, 183, 8, 2, 1, 38, 5, 72, 43], [112, 17806, 10, 145], [3, 29, 1950, 1762, 9, 51, 8493], [526, 4, 268, 269, 1883, 124, 105, 6, 79, 246, 77, 2030, 36, 41, 17807, 3074, 88, 17], [42, 2, 1, 2279], [29, 1, 88, 28, 214, 38, 3, 139, 122, 55], [8494, 2, 1, 445, 2111, 2, 414, 17808, 2, 1, 445, 4570, 2, 414, 167, 170, 1, 1551, 70, 35, 97, 453, 1533, 67, 1533, 2], [38, 1, 72, 7, 20, 138, 178, 12, 185], [7, 9, 17809, 3, 566, 40, 134, 1158, 25, 93, 30, 2342, 128], [1, 162, 42, 132], [432, 157, 45, 433, 2, 1], [31, 5, 48, 2345, 5, 2345, 2692], [53, 177, 827, 11, 147, 1, 1831, 1255, 5937, 166, 17810, 1806, 97], [522, 14, 17811, 7, 1173, 36, 867, 7, 1, 18, 1147, 21, 4, 449, 1002, 8495], [3524, 231, 9, 14, 44, 32, 4, 17812, 200, 22, 6, 42, 1002, 653, 3460, 17813, 265, 903, 3332, 2608], [338, 97, 265, 17814, 149, 42, 131, 4764, 1452, 3, 90, 42, 17815, 9], [93, 24, 103, 70, 2, 25, 1266, 705, 45, 14, 129, 2693, 130, 2, 1454, 496], [15, 46, 295, 6, 7, 1, 102], [53, 2074, 53, 1314, 71, 247, 16, 39, 9, 816, 12, 17816], [3, 137, 125, 24, 48, 39, 25], [25, 14, 18, 135, 27, 39, 2216, 3990, 30, 175, 59, 71, 6, 557, 287, 8, 39, 1045, 702, 653, 3460, 9, 14, 17817], [1573, 34, 89, 1, 1827, 35, 390, 556, 61, 284], [245, 91, 69, 748, 2, 688, 1435, 1799, 51, 4741, 12, 2, 24, 83], [82, 398, 4356, 1995, 8, 7635, 2890, 55, 53, 127, 1150, 505, 1, 451, 18, 4, 17818], [31, 5, 458, 2, 587, 828, 8, 15, 671, 1097, 230, 5, 1056, 15, 20, 2, 83], [1079, 106, 459, 546, 2, 1, 152, 62, 31, 40, 2, 9, 74, 48], [31, 5, 47, 2, 9, 1157, 604, 14, 2, 9, 740], [128, 2, 9, 237, 919, 12, 1360, 33, 8468, 649, 988, 5, 14, 2, 9, 33, 17819, 15, 550, 6, 1124, 15], [40, 119, 24, 34, 29, 119, 3223], [5, 9, 29, 655, 4, 538, 5, 191, 21], [39, 9, 227, 173, 17820, 33, 37, 42, 63, 94, 126, 30, 26, 126, 872, 11, 4, 199, 6767, 251, 15, 332, 197, 17821], [38, 42, 64, 50, 553, 16, 76, 9, 17822], [10, 2644, 29, 10, 2644, 29, 10, 2644, 29, 67, 553, 650, 5, 41, 17823, 1612], [4, 9, 78, 778, 67, 17], [5, 19, 2, 77, 1363, 88, 954, 1204, 26, 5, 96, 46, 17824, 146, 912, 1394, 30, 2741], [198, 16, 132, 2, 8496, 508, 85, 12, 116, 43, 8496, 18, 4, 17825, 17826], [6, 14, 2293, 25, 49, 4, 796, 3112, 39, 6018, 36, 14, 27, 1, 33, 6, 44, 217, 6, 157, 45, 11, 126], [150, 49, 2, 1, 6, 19, 17827], [1253, 6, 4, 17828, 665, 2, 93, 2449, 44, 9, 12, 17829, 4, 450, 36, 58, 295, 21, 5, 2164], [2133, 427, 2, 93, 620, 51, 17830, 442, 4, 45, 5, 94, 18, 886, 7, 620, 12, 248], [101, 2, 202, 91, 63, 70, 5, 150, 17831, 6, 2, 9, 27, 2, 17832, 6019, 8, 43, 1152, 2431, 140, 40, 136, 2, 203, 30, 8], [786, 152, 404, 8, 7, 32, 23, 72, 21, 4, 264], [17833, 1730, 630, 224, 17, 100, 17, 605, 4, 2752, 18, 20, 548, 735, 20, 17834, 17835, 8, 578, 4, 1744, 1060, 236], [27, 39, 1, 721, 3, 704, 39, 19], [5, 1, 17836, 3, 299, 3, 47, 4, 101, 68], [1723, 38, 4, 435, 49, 81, 400, 20, 1, 73, 11, 4, 1825, 8, 477, 6, 22, 1262, 972], [3, 3292, 5, 13, 2, 260, 4138, 8, 92, 5, 107, 51, 17, 13, 7175, 39, 228, 46, 334], [13, 43, 1, 5, 210, 70, 4, 17837], [151, 471, 138, 327, 6, 20, 1, 705, 26], [1073, 6, 2118, 17838, 1094, 29, 107, 27, 43, 9, 45, 25, 22, 1094, 5, 103, 28, 1012], [57, 78, 35, 6, 3055, 10, 1734, 18, 5321, 125, 2, 89, 1], [81, 59, 5, 90, 435, 8, 328, 27, 1757, 34, 61, 28, 5, 2, 3976, 65, 418, 7, 168, 2, 1882, 18, 1, 411], [53, 161, 1, 5, 46, 17839, 63, 105, 1228, 82, 4, 2089, 917], [53, 1826, 4303, 14, 2613, 17, 3, 14, 131, 1396, 18, 50, 17840, 124, 7, 1, 17841, 213, 148, 17842, 906, 2], [21, 4, 215, 607, 449, 10, 226, 132, 1224], [1625, 583, 65, 13, 4, 1040, 16, 492, 2, 9, 12, 255, 170, 142], [33, 149, 495, 157, 8388, 11, 580, 16, 15, 78, 550, 27, 14, 79, 2, 1], [10, 1119, 261, 463, 29, 81, 17843, 17, 17844, 20, 32, 17845], [38, 5, 119, 522, 7, 99, 341, 8, 192, 1238, 13, 2, 144, 8497], [245, 1, 7, 113, 5, 296, 1975, 29, 58, 4548, 28, 542, 21, 4, 237, 17846, 814, 182, 41], [1, 21, 69, 3212, 53, 23, 2, 1263, 78, 1, 75, 113, 17, 4087], [1, 90, 960, 888, 26, 316, 35, 40, 249, 138, 99, 28, 1303, 26, 78, 1, 249, 138, 26, 17847, 28, 2, 262, 108, 3887], [3, 29, 44, 43, 17848, 17849, 455, 17850, 319, 3, 33, 41, 2, 500, 3, 67, 108, 26], [25, 405, 459, 314, 261, 26, 28, 2, 401, 51, 1653, 533, 133, 4088, 10, 17851, 128, 550, 1862, 17, 35, 2, 354, 17852], [38, 80, 310, 61, 102, 11, 521, 26, 4, 826, 72, 4764, 7, 56, 2235, 34, 15, 68, 16, 4, 323, 18, 80, 1523, 26], [5, 1, 49, 37, 3423, 251], [5, 28, 551, 27, 2, 1, 8, 42, 122, 8, 1071, 50, 30, 40, 28, 32, 1001, 219, 919, 17, 1, 3, 299, 42, 220, 2, 9], [1, 75, 1056, 2, 688, 1435, 1341, 34, 67, 2, 1682, 1435, 138], [3, 262, 10, 500, 288, 40, 47, 27, 50, 1214, 37, 36, 63, 290, 3, 47, 13, 463, 65, 342, 8352, 26, 3, 46, 297, 4, 1, 11], [554, 1, 28, 18, 4, 1195, 8, 86, 5, 614, 6, 134, 76, 20, 930, 13, 1, 5, 198, 16, 19, 2, 25, 4737], [180, 3081, 12, 7315, 8, 17853, 1381, 478, 52, 79, 416, 161, 83, 5, 4, 161, 1, 3081, 5, 4, 161, 1], [3085, 7478, 2171, 59, 1258, 34, 32, 5, 9, 375, 170, 21, 12, 366, 2, 866], [71, 6, 799, 27, 6949, 1450, 17854, 54, 17855, 619, 17856, 17857, 14, 2, 24], [96, 122, 6, 167, 22, 8498], [65, 785, 10, 17858, 3, 29, 86, 289, 328, 7, 371, 10, 17859, 1177, 41, 60, 9, 30, 25, 11, 15, 3, 911], [3344, 287, 33, 44, 4, 434, 24, 8, 436, 1970, 120, 77, 373, 4, 138, 249, 8, 202, 17860], [5004, 7323, 37, 56], [3, 79, 531, 203, 5508, 37, 17861, 1, 13, 5, 29, 79, 17, 15, 747, 10, 895], [23, 48, 156, 2, 1, 601, 3, 376], [1, 14, 13, 61, 81, 6, 97, 166, 1, 1, 5, 12, 10, 166, 1], [7, 158, 216, 4, 45, 54, 16, 10, 6583], [69, 375, 22, 1], [216, 2426, 6020, 8, 5793, 21, 5961, 8, 194, 17862, 27, 10, 3428, 177, 243, 1445, 1, 1817], [2270, 81, 99, 80, 9, 90, 18, 2, 25, 19, 224, 1394, 97, 9, 13, 7], [674, 159, 8, 4714, 55], [1, 41, 17, 208, 284, 73, 286, 713], [4, 4376, 49, 96, 56, 3021, 821, 21, 4, 169, 52, 29, 110, 279, 59, 14, 18, 2, 93, 404, 3117], [39, 9, 29, 134, 2, 19, 31, 5, 41, 2, 77, 74, 48], [55, 304, 2, 691, 23, 94, 214, 961, 17863, 78, 139, 122, 6, 719, 923, 108, 82, 4, 9], [63, 17864, 382, 17865, 8372, 11, 199, 193, 73, 52, 382, 1403, 2423, 8, 17866, 103, 52, 17867], [3, 195, 2, 870, 442, 7, 95, 16, 2, 1508, 2230, 612], [2939, 21, 770, 26, 17868, 66, 157, 11, 127, 1422, 90, 1387, 56, 173, 305, 2315, 2169, 26, 8499], [22, 25, 12, 2, 172, 104], [593, 12, 2, 1133, 17869, 35, 8, 79, 7, 1, 2, 282], [3665, 6, 232, 8500, 17870, 828, 7156, 8500, 3665, 337, 480, 17871, 6625, 21, 2, 17872], [395, 71, 203, 1, 14, 11, 575, 230, 4, 322, 287, 100, 94, 4, 729, 55], [34, 20, 96, 2, 104], [158, 49, 37, 609], [4, 17873, 808, 2378, 8, 3477, 12, 112, 19, 7, 104], [792], [92, 3, 146, 191, 1, 21, 677, 18, 3928], [1, 59, 6, 192, 7, 3145, 213, 154, 986, 17874, 5, 75, 17875, 4, 518, 18, 7, 24, 17876], [1417, 151, 563, 5, 116, 8, 23, 48, 2, 181, 11, 488, 2911, 29, 134, 50, 45], [1, 5, 46, 28, 553, 205, 3, 13, 180, 971, 37, 3, 63, 1071, 76], [851, 163, 853, 354, 4758, 684, 853], [354, 3063, 904], [354, 684, 853, 1054], [354, 684, 853, 1799], [354, 3063, 1942], [540, 6, 14, 2, 3598, 160, 43, 1230, 160, 43, 1286, 160, 697, 343, 160, 42, 28, 6, 5480, 435, 173, 126, 989, 560, 351, 949, 1865], [38, 166, 77, 255, 1493, 36, 65, 342, 26, 4264, 34, 38, 3, 255, 76, 3, 65, 13, 2, 2005, 16, 2, 692, 3880, 69, 8501], [4, 540, 314, 261, 12, 37, 19, 332, 12, 140, 4715, 105, 216, 2, 6021, 21, 393, 722, 3389, 8502, 5, 150, 17, 19], [642, 72, 52, 2083, 34, 277, 48, 150, 17877, 211, 468, 3048, 8503, 17878], [31, 20, 504, 12, 2819, 130, 5, 15, 50, 1680, 6, 114, 4, 56, 54, 26, 290, 102, 621, 7, 421, 173, 5], [17879, 136, 969, 3932, 714, 1], [289, 1649, 7, 15, 2448, 14, 4, 1, 3000, 343, 29, 110, 1912, 126, 5566, 7, 81, 4, 247, 45], [7, 1, 183, 17880], [321, 17881, 61, 707, 6, 213, 461, 94, 17, 8, 40, 96, 4, 17882, 5, 339, 30, 1, 75, 61, 201, 346, 79, 27], [29, 28, 2802, 859, 161, 25, 17883, 2268, 56, 1726, 17, 31, 5, 67], [38, 25, 191, 17, 3697, 4, 9, 4765], [4396, 348], [4229, 29, 58, 22, 275, 300, 126, 237, 228, 12, 4, 832, 1, 11, 4, 360], [41, 543, 54, 16, 3931, 521, 426, 3, 528, 51, 2, 189, 8, 79, 170, 2, 24, 21, 202, 54, 155, 106, 52, 17884], [19, 20, 1, 70, 50, 79, 17, 17885], [13, 2629, 370, 23, 48, 2, 77, 7, 9, 224, 8, 136, 352, 27, 787, 3556, 3095], [29, 627, 71, 4004, 47, 2595, 11, 50, 517, 352, 2050, 502, 50, 2, 235, 1104, 130, 7, 24, 8, 21], [17886, 42, 79, 17, 2, 368, 296, 121, 5, 220, 208, 13, 2918, 2236, 5, 33, 79, 17, 68, 1590, 7930, 35, 368], [31, 2, 189, 1657, 27, 97, 77, 7, 33, 25, 14, 956, 31, 40, 1657, 108, 40, 2, 9], [31, 5, 146, 81, 45, 59, 246, 25, 6, 28, 24, 5, 17887], [5, 454, 85, 3, 79, 5, 1, 188, 5, 454, 85, 3, 79, 5, 1, 17888], [5030, 3168, 1488, 445, 8194, 17889, 17890, 17891], [378, 93, 77, 12, 783, 2472, 1], [536, 54, 3082, 8, 1964, 10, 153], [383, 62, 17892, 6, 10, 153], [5, 600, 14, 388, 31, 5, 157, 2717, 658, 18, 2796], [40, 315, 52, 315, 40, 2, 9, 40, 554, 52, 506, 692, 36, 366, 441, 36, 551, 69, 279, 338, 111, 771, 15], [1316, 294, 102, 404], [7, 9, 129, 1271], [62, 4, 1, 230, 5, 79, 630, 1886, 15, 25, 700, 132, 172, 15], [10, 206, 91, 136, 2, 120, 5265, 310, 218, 52, 2, 1298], [10, 24, 12, 5505, 17893, 38, 40, 756, 18, 10, 618, 27, 4420, 861, 6, 876, 4, 534, 12, 19, 589, 38, 40, 277, 254], [192, 102, 125, 2357, 3, 47, 807, 92, 3, 41, 2, 535, 25, 1, 69, 67, 17], [162, 136, 22, 132, 32, 213, 34, 96], [87, 2, 142, 1, 6, 316, 17, 1421], [4, 1940, 72, 20, 2, 838], [5, 166, 25, 2, 79, 35, 2, 1, 6, 290, 2, 1, 576, 48, 17, 23, 17894, 7, 843, 37, 40, 63, 150, 162, 23, 107, 82], [15, 46, 777, 6, 311, 7, 1, 102], [8337, 1647, 26, 275, 460, 2040, 49, 48, 21, 3040, 247, 460, 2040, 49, 9, 26, 76, 1647, 1, 49], [17895, 24], [20, 2, 17896, 2, 1094, 7271], [53, 48, 65, 21, 64, 68, 115, 1627, 258, 307, 444, 17897, 172, 1019, 9, 17898, 3, 2778], [267, 8504, 408, 445, 4, 788, 17899, 1149, 6, 4, 1643, 741, 163, 1771, 600, 421, 10, 1006, 34, 8505, 8025, 103], [2597, 81, 127, 130, 1, 39, 17900, 225], [243, 457, 114, 2, 5467, 11, 7, 190, 17901], [5, 41, 25, 8, 3, 41, 1, 34, 3, 67, 350, 17902], [886, 3618, 17903, 456, 308, 8506, 14, 2, 1894, 14, 2, 2352, 38, 36, 63, 2759, 5891, 4832, 1, 26, 1897, 26, 17904], [116, 490, 1621, 17905, 3885, 17906, 8, 88, 116, 1621, 17907, 454, 17908, 48, 7, 116, 393, 329, 27], [4283, 56, 63, 18, 4, 3811, 17909], [340, 11, 143, 24, 201, 1204, 13], [12, 6484, 17910, 144, 17911, 386], [3, 1138, 302, 1, 69, 86, 36, 8507, 340, 18, 89, 77, 489], [272, 303, 147, 1, 2, 756, 5663, 1, 259, 17912, 201, 4533], [2, 575, 277, 48, 139, 2, 9, 82, 14, 2, 282], [1, 103, 113, 5, 15, 32, 59, 4, 4678, 194, 10, 1, 114, 1727, 1142, 33, 6, 28, 7, 117, 1121], [17913, 17914, 382, 17915, 31, 3, 345, 103, 3, 14, 17916, 32, 10, 17917, 527], [20, 98, 589, 187], [219, 485, 20, 2, 835, 5, 185, 183, 1859, 1], [267, 1], [37, 148, 185, 217, 87, 6, 400, 7, 1, 142, 26, 1365, 6, 50, 7, 12, 2, 1145], [2126, 27, 17, 8, 113, 17, 23, 681, 23, 2, 4106, 1], [78, 1, 69, 167, 35, 4, 1483, 65, 21, 154, 754, 87, 6, 167, 35, 4, 1198, 212, 17918, 48, 311, 15], [22, 12, 37, 185, 71, 5, 223, 436, 2, 1, 7, 100, 25, 735, 18, 50, 235, 11, 775], [43, 21, 5, 9], [1048, 7, 9, 2, 17919, 1771, 371, 40, 309, 21, 701, 4250, 1], [211, 445, 755, 8, 603, 885, 1447, 3, 67, 6, 935, 10, 3078, 34, 3, 380, 151, 33, 1385, 21, 376], [4144, 61, 392, 4835], [58, 5, 182, 33, 94, 217, 1024, 8, 86, 6268, 57, 2, 2826, 34, 51, 4, 199, 106, 5, 75, 753, 426, 42, 75, 3656], [38, 1753, 17920, 1597, 3611, 54, 21, 5016, 8240, 7, 38, 3, 724, 9, 46, 17921, 45, 289, 297], [23, 54, 22, 1, 99], [66, 29, 1950, 1762, 9], [5, 63, 101, 79, 4, 8508, 104, 31, 20, 2, 8508], [17, 17, 479, 17, 69, 12, 2, 1104, 816, 1297, 866, 74, 3429, 834], [135, 3, 195, 542, 6, 2910, 59, 1661, 8, 381, 8, 1516, 8, 287, 69, 75, 806, 126, 2267, 8, 28, 1176, 16, 489, 9, 2], [7507, 886, 1211, 2193, 16, 2595, 539, 56, 11, 17922, 17923, 6, 157, 202, 8, 953, 4302, 6, 2987, 17924, 26], [23, 18, 10, 344, 8509, 37, 85, 118, 3, 303, 5, 2, 315, 30, 2799, 1538, 1, 20, 330, 17925, 26], [20, 2, 1, 8, 357, 13, 5], [39, 9, 14, 3089, 21, 6022, 1872, 5244, 21, 1192, 17926, 2044, 21, 7, 17927, 17928, 129, 21, 3749], [1035, 52, 588, 1, 52, 588, 26, 588, 5746, 7, 10, 260, 10, 720, 33, 62, 26, 14, 8510, 7, 17], [982, 14, 51, 4, 489, 3, 328, 132, 11, 4, 489, 8, 486, 1, 4736, 2, 856, 140, 36, 124, 2, 720, 73], [8, 1302, 3, 372, 13, 2, 823, 8161, 5178, 16, 14, 82, 4263], [2262, 2, 171, 203, 1485, 835], [32, 5, 58, 12, 19, 83], [1480, 17929, 12, 4, 17930, 386, 16, 2, 1, 289, 182, 8511], [159, 1085, 63, 5, 17931, 27, 3015, 17932, 17933, 73, 17934, 211, 7, 1129, 7251, 103, 1389, 48, 136], [31, 116, 47, 98, 4517, 4519, 1105, 69, 204, 212, 69, 5328, 90, 18, 17935, 1120, 26, 4468, 118], [84, 63, 3, 303, 5, 2, 17936, 362, 37, 3, 13, 4, 193, 20, 17937, 229, 102, 20, 5579], [33, 131, 157, 522, 11, 1, 24, 8, 114, 431, 3591, 29, 28, 85, 1, 29, 13, 522, 11, 126, 1549], [55, 51, 4, 1, 7, 208, 13, 36, 419, 34, 92, 44, 6, 448, 406, 27, 36, 25, 736], [15, 20, 77, 228, 7, 5, 146, 194, 54, 4905, 212, 4, 1, 7, 14, 238, 5997, 50, 6, 338, 350], [20, 2, 104, 31, 5, 182, 124, 4, 960, 1756, 17938, 6023], [404, 524, 26], [2, 9, 12, 152, 14, 2, 9, 43, 690, 57], [77, 103, 609, 20, 262, 1253, 88, 28, 2361, 38, 5, 134, 166, 1, 4018], [53, 1083, 22, 27, 2, 356, 1787, 53, 25, 146, 167, 126, 234, 1, 27, 22, 11, 2812], [295, 103, 139, 2, 9, 82, 61, 6, 4, 3941], [31, 5, 299, 3098, 8512, 47, 284, 27, 3967, 304, 1062, 1971, 26, 80, 17939, 242, 7, 1, 142, 390], [22, 12, 71, 5, 119, 17940, 211, 17], [32, 39, 77, 72, 357, 63, 157, 240, 35, 27, 2165, 29, 43, 25, 67, 2, 1, 73, 2, 504, 1720, 7, 45], [17941, 11, 22, 1, 3575, 813, 1919, 26, 860], [244, 395, 3, 94, 175, 7, 1, 45, 18, 1227, 23, 753, 5], [22, 179, 17942, 45, 17943], [10, 260, 24, 12, 99, 926, 1185], [31, 5, 2, 9], [36, 5662, 7, 1, 4, 6024, 489], [40, 10, 1267, 1, 4, 68, 3, 498, 1267, 2047], [48, 5073, 7, 234, 145, 45, 27, 588, 17944], [31, 5, 146, 25, 74, 2200, 333, 271, 54, 10, 706, 23, 515, 16, 78, 1041, 77], [171, 1], [10, 9, 3011, 12, 129], [5, 156, 183, 6, 2, 1, 7, 29, 13, 5], [75, 157, 10, 302, 11, 43, 1], [75, 302, 553, 16, 39, 9], [31, 2, 9, 134, 10, 161, 17945, 2, 387, 13, 7, 40, 1741, 79, 17, 37, 66, 63, 61, 756, 4, 1], [827, 409, 16, 1, 30, 25, 999, 2, 2901, 275], [31, 5, 90, 17, 3, 29, 2800, 154, 2370, 1, 3, 29, 259, 6, 333, 5, 2534], [3, 75, 105, 176, 43, 1, 149, 3, 157, 76, 9, 54], [333, 17946, 139, 72, 993, 7, 926, 3514], [17947, 1309, 5841, 2241, 1360, 57, 42, 58, 641, 4, 3725, 42, 313, 15, 167, 15, 430, 254, 317, 690, 31, 4, 232, 49], [3, 33, 131, 62, 38, 49, 66, 152, 61, 19, 45, 35, 26, 61, 19, 35, 1], [8398, 194, 17948, 70, 4, 167, 8, 88, 382, 1239, 123, 313, 2, 1736, 18, 17949, 26], [955, 18, 22, 1, 17950], [2, 414, 33, 1087, 51, 17, 149, 23, 467, 2, 828, 51, 1474, 195, 1, 23, 18, 19, 7047], [44, 17951, 100, 7, 9, 316, 68, 177, 6, 4, 17952, 8, 194, 57], [33, 38, 3, 299, 1748, 3032, 487, 14, 1046, 16, 2, 24, 52, 28, 1462, 11, 5415, 21, 290, 2, 395, 69], [219, 1, 4096, 121, 69, 121, 201, 275, 75, 70, 2, 260, 612, 7, 32, 307, 26], [1533, 40, 47, 2, 1774], [3, 29, 279, 71, 209, 3, 90, 2, 77, 151, 105, 79, 50, 2, 9, 1, 659, 74, 245, 16, 7, 45, 55], [871, 690, 3973, 747, 2483, 3689, 59, 718, 2460, 26], [5, 300, 20, 142, 163, 4, 2166, 163, 5, 271, 58, 141, 1, 45, 13, 7], [1965, 24, 767, 160], [18, 10, 193, 6, 19, 20, 83], [19, 24, 7, 85, 4766, 100, 17, 410, 4, 25, 220, 81, 59], [316, 15, 1], [2649, 377], [70, 155, 1, 150, 17953], [42, 322, 34, 147, 24, 41, 2, 947, 1721, 1634, 18, 15, 1177, 1884, 32, 19, 35], [112, 1516, 398, 39, 1927, 56, 34, 4, 391, 1927, 41, 17, 8513, 26], [66, 1387, 44, 43, 2388, 17954, 8514, 66, 49, 1341, 1044, 1828, 7, 5523, 7340, 435, 287, 26, 1334, 951], [26, 47, 803, 96, 14, 98, 2362, 17955, 11, 17956, 74, 33, 70, 17957, 11, 84, 4892, 13, 2, 93, 181, 1188], [8, 21, 4, 1665, 3, 86, 4369, 17958, 12, 2, 838, 4, 3016, 16, 4, 1593, 12, 33, 2091, 51, 22, 3461], [3840, 12, 2, 838, 10, 446, 12, 2431, 444, 416, 136, 2440, 2050, 1514, 1525, 242, 4, 19, 562], [4, 101, 184, 127, 2083, 130, 5431, 3840, 14, 2, 187, 12, 2453, 3171, 1475, 1918, 21, 1167], [116, 12, 2, 2006, 1495, 51, 4, 5285, 17959, 8, 36, 1338, 17960, 15, 2, 2793, 4621, 5, 19, 3300, 57, 2, 6785], [15, 332, 6, 14, 4, 1104, 91, 38, 4, 166, 395, 12, 14, 270, 2, 187], [85, 277, 17961, 44, 6, 14, 11, 4, 17962, 52, 270, 2, 24], [32, 64, 10, 312], [17963, 6934, 3326, 2632, 5275, 17964, 17965, 6936, 17966], [39, 1294, 9, 58, 48, 242, 4, 19, 35, 27, 126, 19, 17967], [159, 925, 103, 883, 11, 2, 154, 7970, 73, 98, 4689, 2081, 17968, 37, 57, 244, 7608, 3490, 73, 4, 3835, 16, 188], [108, 6, 39, 9, 1000], [1397, 596, 2, 535, 16, 9, 7, 13, 9, 7, 13, 25, 7, 29, 208, 13, 319], [218, 738, 73, 42, 192, 58, 4, 17969, 45, 596, 2, 9, 40, 20, 77, 3704], [3, 101, 14, 65, 13, 23, 19, 1, 3, 29, 205], [3, 273, 17970, 234, 1, 596, 4608, 49, 127, 863, 130, 42, 17971, 34, 23, 2791], [3, 454, 31, 4, 9, 49, 152, 134, 923, 108, 6, 4, 1334, 22, 213], [31, 3, 41, 9, 88, 3, 362, 75, 258, 162, 3, 157, 5965, 55], [31, 42, 75, 799, 596, 57, 66, 61, 8034, 88, 3, 41, 1, 493, 35, 3, 41, 98, 2121, 776], [15, 37, 5891, 7, 4, 9, 28, 6, 472, 35, 73, 9, 21, 3072], [10, 857, 16, 1983, 368, 136, 396, 17972, 129, 4, 2654], [25, 75, 110, 150, 35, 18, 2, 1, 11, 2, 327, 461, 4, 77, 42, 172, 28, 214, 251], [422, 3, 146, 311, 22, 3137, 8515, 1623, 102, 2713, 3, 79, 10, 500, 26, 72, 19, 42, 42, 6688, 83, 55], [74, 4, 3, 47, 376, 17973, 109, 1, 42, 1705, 82, 5143, 6, 17974, 8516, 251], [40, 48, 2, 9, 218, 40, 124, 352, 230, 280, 55], [40, 48, 2, 9, 218, 40, 48, 17975, 6, 42, 1669], [37, 4, 414, 3, 799, 27, 12, 122, 50, 237, 6, 70, 17976, 2, 89, 8517, 2080, 14, 1182, 39, 952, 55], [4, 438, 2149, 37, 963, 54, 135, 381, 45, 889, 248], [39, 9, 276, 258, 2, 193, 6, 255, 60, 17977, 3, 17978], [42, 1303, 25, 1606, 4, 178, 123, 1429, 35, 4, 1990, 18, 4, 285, 160, 1486, 1939, 17979], [287, 32, 129, 770, 49, 17980, 4, 1884, 16, 285], [379, 1252, 1875, 608, 1148, 91, 596, 84, 373, 17981, 86, 316, 508, 24, 6, 4, 1879, 12], [3763, 3975, 12, 2, 158], [5, 75, 14, 2, 9, 72, 7, 246, 77, 2, 282, 20, 398, 9, 15, 2055, 922, 166, 897], [2077, 567, 95, 473, 691, 17982, 15, 330, 17983], [503, 1011, 16, 4, 115, 160, 31, 5, 67, 6, 14, 17984, 51, 98, 5010, 8160, 160, 29, 255, 2, 190, 1925], [169, 754, 9, 8, 17985], [486, 60, 1, 262, 8, 484, 37, 3, 694, 142, 10, 1371, 8, 17986, 10, 828, 51, 876, 2017, 172, 8518, 176, 965], [221, 559, 14, 2, 1, 59, 20, 895, 429, 2, 607, 5627, 8, 28, 20, 1808, 30, 108, 6, 5063, 1556, 709], [221, 7650, 318, 44, 5322, 13, 2, 8519, 274, 34, 4, 252, 65, 13, 52, 47, 17987, 123, 2, 17988, 269, 951], [221, 192, 17, 73, 20, 1764, 781, 244, 2501, 843, 137, 430, 433, 788, 4, 95, 1131, 30, 198, 1057], [1, 25, 55], [57, 47, 7, 5, 175, 3, 75, 6800, 602, 6, 509, 15, 129, 32, 20, 17989, 1473, 8, 24, 8520, 17990, 2825], [3, 47, 11, 2, 2737, 1143, 4925, 34, 66, 79, 15, 2, 460, 493, 8, 206, 159, 4, 3986, 47, 156, 4119, 4, 17991], [17992, 4, 4426, 3054, 269, 124, 378, 6891, 2561, 52, 920, 4, 1602, 26, 4, 1602, 1252, 17993, 101, 11], [169, 129, 4, 237, 24], [477, 186, 33, 140, 17994, 1034, 33, 253, 60, 185, 187, 277, 48, 196, 3, 67, 1836, 633, 102, 27, 20, 3458], [1202, 883, 12, 2751, 81, 21, 8521, 282], [19, 1, 28, 17995], [], [31, 5, 63, 19, 10, 1, 88, 40, 46, 1163, 368], [38, 2, 1, 7, 469, 1189, 17, 92, 32, 35, 18, 10, 138], [3, 58, 48, 44, 1, 1169], [284, 504, 1326, 64, 5, 1363, 26, 41, 4, 237, 24, 26], [334, 24, 12, 237, 24, 26, 1027, 42, 62, 7, 32, 20, 26], [22, 1, 41, 2, 112, 164, 3881, 73, 2, 1245], [3, 14, 11, 4, 24, 13], [3, 2171, 413, 178, 761, 18, 71, 17996, 242, 142, 17997, 268, 264, 11, 2, 17998, 239, 16, 5, 103, 382, 1305, 34, 52, 47, 109], [3, 64, 689, 283, 274, 547, 17, 1140], [22, 1, 12, 1439, 51, 17999, 18000], [132, 56, 53, 4, 315, 890, 2894, 675, 49, 28, 206, 18001], [17, 1720, 10, 347, 5404, 4, 1941, 22, 9, 223, 430, 18002], [1365, 6, 2, 77, 71, 42, 29, 44, 9], [1202, 1401, 14, 2413, 18003, 135, 8, 954, 1, 103, 2052, 11, 20, 18004, 5, 148, 117, 272, 3076, 7, 45, 25], [38, 186, 992, 706, 17, 126, 56, 1827], [1403, 1584, 27, 2, 8522, 26, 1, 2367, 27, 2, 3654], [6, 547, 3753, 365, 3068, 26, 2563, 160, 448, 178, 496, 2202, 16, 2563, 26, 134, 18005, 190, 1092, 211, 1537], [237, 228, 14, 2, 9, 4739, 18006, 9, 15, 35, 18007, 3336, 14, 2, 9, 20, 37, 8476, 20, 57, 329, 125], [291, 9, 156, 131, 687, 42, 46, 672, 32, 115, 220, 42, 28, 7, 2548, 82], [48, 626, 6, 2771, 1999, 2, 1, 18008, 18009, 763, 18, 8523, 18010], [245, 1, 69, 87, 2, 1816, 6, 290, 12, 1113, 2004, 3028, 26, 669, 453, 26, 247, 13, 103, 1694, 3396], [31, 2, 77, 400, 18, 20, 231, 8, 20, 1359, 568, 173, 50, 24, 8, 40, 498, 20, 1359, 13, 2, 1450, 40, 2, 18011], [3, 64, 191, 109, 341, 703, 1, 38, 374, 18012], [40, 87, 2, 91, 48, 43, 24, 2756], [78, 811, 4872, 139, 1955, 451, 278, 96, 14, 4209, 51, 39, 9, 5074], [39, 9, 308, 8, 4625, 103, 28, 6, 4, 1529, 16, 254], [22, 1, 2201, 123, 4, 593, 5996, 53, 19, 544], [22, 3759, 45, 46, 342, 51, 1284, 78, 60, 171, 9, 61, 54, 11, 775, 65, 13, 1429, 8, 4, 1324, 18013, 26], [15, 46, 2357, 6, 311, 7, 1, 1724], [55, 773, 194, 6, 476, 5, 13, 38, 3, 844, 5, 104], [939, 273, 6, 107, 6, 50, 331, 6, 290, 50, 8, 266, 110, 458, 4, 676, 369, 939, 30, 9], [1, 64, 10, 18014], [151, 313, 2, 8524, 51, 50, 1, 30], [3, 29, 8525, 224, 43, 9, 43, 3, 29, 1994, 11, 580, 16, 43, 1, 1027, 211, 40, 28, 102, 10, 138, 3, 14, 13, 18015, 4, 580], [93, 24, 107, 27, 2, 1220, 30, 476, 26, 2, 284, 30, 764], [18016, 383, 79, 50, 1152, 260, 2, 161, 45, 1, 113, 4, 360, 85, 29, 5], [69, 121, 5, 47, 342, 18017, 214, 1, 107, 1550, 17], [6, 155, 2946, 3, 44, 182, 204, 3, 195, 370, 964, 18018, 7, 174, 1, 30, 510, 173, 10, 331, 4486], [38, 5, 309, 18, 567, 95], [31, 5, 86, 289, 132, 98, 1242, 1, 713, 33, 14, 721, 289, 271, 2066, 18, 292, 16, 4, 3371, 6025, 224, 52], [648, 2, 1, 10, 25], [32, 39, 9, 33, 67, 60, 4018], [3, 294, 11, 823, 2635, 3450, 6, 748, 114, 54, 22, 1, 107, 191, 17, 18019, 21, 2918, 18020, 3, 65, 7, 1045], [1208, 1813, 6, 14, 1341, 1724, 49, 5, 265, 17, 37, 36, 424, 102, 4458, 5, 141, 4146, 18021, 83], [17, 99, 4246, 61, 6, 94, 7, 154, 1260, 16, 4, 673, 390], [316, 50, 657, 39, 18022, 80, 9, 103, 28, 18023], [1614, 26, 1, 41, 842, 8, 137, 2791, 26], [29, 43, 25, 67, 2, 291, 1], [159, 870, 424, 4, 18024, 3468, 102, 84, 781, 4489, 36, 44, 6, 1845, 15, 895, 18025], [1612, 329, 685, 1848, 2555, 18026, 160, 8526, 21, 2, 93, 561, 448, 8, 256, 1037, 18027], [3, 75, 806, 43, 2267, 34, 39, 1, 75, 806, 307], [5, 4, 25, 11, 314, 261, 69, 41, 1750, 173, 18028, 8, 3433, 173, 56, 63], [10, 1, 165, 308, 6, 17, 127, 130, 473, 481, 8, 3, 75, 1855, 15, 151, 19, 309], [2, 1, 103, 72, 393, 21, 701], [19, 27, 2, 89, 1, 5, 223, 87, 60, 169, 161, 774], [3, 29, 594, 31, 32, 39, 9, 72, 36, 28, 169, 85, 364, 36, 18, 186, 27, 7, 1133, 45, 1, 15, 787], [3, 679, 623, 7, 39, 1, 33, 131, 94, 17, 142, 131, 94, 17, 616], [3, 70, 1, 635, 13, 1892, 18029, 205], [3, 87, 2, 154, 1], [3, 87, 2, 112, 1], [3, 101, 1181, 1262, 9], [11, 473, 213, 39, 9, 46, 223, 14, 45, 34, 2, 138, 235], [18030, 273, 17, 23, 6, 781, 6, 14, 27, 68, 1], [55, 41, 39, 9, 11, 36, 150], [55, 15, 356, 205, 218, 155, 9, 7, 81, 45, 3, 749, 3236, 7, 45, 46, 781], [55, 7, 199, 1, 3, 47, 431, 27, 47, 47, 142, 6, 400, 17, 35, 11, 28, 17, 204, 11, 28, 18, 186, 11, 81, 59, 254], [1267, 3, 157, 667, 16, 39, 9, 18, 4, 5802, 188, 37, 79, 17, 18031, 1], [199, 1, 7, 47, 142, 27, 55, 39, 161, 9, 356], [199, 1, 7, 1877, 17, 223, 96, 14, 135, 6, 119, 10, 138, 38, 36, 94, 7, 536], [76, 199, 9, 7, 47, 19, 10, 138, 227, 18, 17, 55, 8241, 205], [39, 1, 137, 398, 234, 34, 28, 440, 11, 4, 848], [5, 1, 46, 2], [29, 113, 20, 234, 1, 20, 730, 624, 7, 553, 16, 126, 3023], [703, 77, 24, 14, 93, 913, 2, 663, 42, 29, 150, 295, 34, 285, 1002, 947, 446, 18, 4, 5432, 21, 703, 3403], [18032, 6246, 18033, 18034, 18035, 18036, 42, 5979, 18037, 9, 18038, 18039, 18040, 18041, 5179, 3284, 4343], [71, 195, 3, 614, 6, 498, 21, 5, 8, 5, 41, 1, 1427, 108, 930], [7, 2771, 1650, 47, 2, 18042, 7444, 3580, 31, 52, 430, 254, 284, 31, 52, 405, 15, 88, 665, 2, 6, 88, 28, 2382], [3, 75, 397, 2, 861, 35, 83, 156, 41, 2, 764, 21, 43, 2437, 3, 29, 62, 69, 505, 78, 34, 271, 364, 82, 657, 17], [3150, 18043, 382, 1122, 136, 8527, 18044, 379, 18045, 26, 18046, 1883, 26, 18047, 2241, 2], [18048, 5, 362, 49, 2, 537, 1, 5386, 20, 586, 122, 6, 2559, 5], [18049, 180, 517, 9, 27, 18050, 802, 2456, 2106, 18051, 517, 9, 27, 2519, 1169], [116, 12, 295, 329, 27, 3528, 6026, 33, 149, 40, 29, 65, 13, 3034, 78, 146, 2, 2029], [419, 462, 1259, 1354, 9], [2, 234, 1, 216, 22], [405, 32, 39, 319], [55, 2881, 80, 53, 128, 3, 19, 27, 26, 112, 81, 76, 1, 62, 1188, 188], [64, 22, 1, 18052], [2, 5756, 1, 75, 58, 1573, 21, 17, 34, 421, 10, 548, 74, 644, 17, 35, 233], [53, 71, 5, 810, 21, 1278, 34, 42, 48, 2, 9, 8, 71, 23, 61, 6, 538, 42, 31, 20, 7826, 291, 18053], [1065, 47, 739, 1065, 4956, 1259, 1011, 8, 7, 8109, 1623, 32, 248, 247, 1589], [38, 5, 100, 61, 16, 32, 20, 9, 21, 68, 77, 34, 40, 450, 35, 1426, 2, 9, 99], [449, 82, 1903, 318, 14, 4, 215, 178, 6, 65, 3998, 6, 11, 2, 3871, 31, 295, 499, 891, 655, 7, 264], [162, 10, 201, 443, 18054, 51], [18055, 1585, 136, 3433, 559, 2, 269, 8528, 173, 1535, 18056, 1517], [425, 241, 336, 40, 176, 15, 1058, 18057, 2287, 2, 1142, 31, 42, 2, 236, 53], [222, 105, 438, 217, 27, 190, 1022], [59, 6, 61, 54, 27, 32, 39, 341, 1, 951], [170, 20, 677, 49, 1498, 27, 307, 50, 8529, 18058, 170, 18059, 18060, 773, 85, 22, 9, 471, 17, 22, 56, 30, 677, 622], [197, 54, 27, 4, 9], [86, 49, 89, 21, 95, 1945, 527, 527], [159, 824, 317, 44, 245, 127, 1086, 460, 6, 1344, 34, 52, 222, 671, 2, 6986, 21, 2, 408, 18061], [92, 61, 114, 54, 4, 56, 26, 225, 3, 47, 34, 267, 48, 267, 462, 26], [25, 255, 782, 26, 3649, 26, 1, 255, 1615, 26, 18062, 55, 22, 46, 57, 18063, 1456, 38, 52, 121, 4767, 18064], [2, 2869, 12, 2, 643, 30, 306, 129, 8530, 31, 20, 787, 20, 33, 2, 1, 27, 2, 260], [3, 90, 179, 1229, 1395, 183, 1, 1, 5, 330, 183, 188, 85, 4, 5814, 5, 146, 6, 14, 1229, 99], [17, 73, 2, 93, 228, 18065, 8, 5997, 174, 9, 18066], [39, 1, 208, 1595, 163, 86, 6452], [8103, 8, 3, 3639, 922, 166, 123, 72, 2398, 2607, 13, 15, 70, 17, 55, 7420, 101, 395, 550, 27, 17, 8531], [403, 187, 3, 346, 5, 99], [403, 187, 3, 346, 350], [3, 29, 137, 59, 4, 269, 5, 44, 6, 1845, 22, 45], [42, 63, 204, 3137, 34, 48, 10, 25, 18067, 69, 152, 114, 279, 16, 10, 9, 7999], [18068, 8425, 1652, 136, 37, 239, 56, 2153], [3, 538, 212, 25, 69, 538, 126, 77, 26, 29, 389, 76, 9, 43, 701, 26, 2002, 6, 5], [5, 196, 13, 4, 232, 200, 22, 213, 38, 36, 18069, 2, 6754, 2160, 129, 2, 1408, 298], [53, 613, 774, 8, 95, 91, 223, 14, 51, 3098, 6027, 390, 53, 60, 25, 41, 7133, 35, 123, 4, 5888, 38, 3, 596], [14, 1229, 179, 26, 18070, 652, 1248, 184, 6, 307, 3, 373, 69, 3, 195, 26, 162, 3, 107, 82, 295, 6, 14, 1811, 16], [22, 1, 183, 11, 395], [128, 15, 103, 44, 2, 699, 16, 18071], [4, 49, 1052, 1911, 8, 116, 427, 110, 2, 637, 18072, 26], [272, 1, 170, 54, 55], [5, 75, 14, 183, 8, 2, 1096, 19, 4768, 479, 2, 1784, 83], [18073, 71, 239, 158, 49, 11, 10, 1333, 3, 18074, 20, 719, 7, 1454, 96, 14, 44, 17, 669], [5, 156, 72, 66, 29, 64, 39, 9, 478, 80, 77, 2, 1774], [22, 1, 12, 99, 112, 5998, 26, 18075], [31, 2, 419, 2418, 222, 509, 39, 175, 116, 222, 14, 2, 1258, 8532, 808, 2418, 8, 91, 34, 2418, 49], [32, 1625, 583, 9, 18, 4, 1706, 55], [1, 64, 18076, 8403, 34, 38, 15, 106, 6, 114, 143, 138, 4, 460, 2055, 2784, 18077, 30, 1], [128, 78, 419, 9, 271, 554], [550, 92, 23, 61, 6, 5119, 18078, 21, 18079, 1, 22, 25, 122], [1056, 4, 2897, 8, 4, 6929, 18080, 401, 1852, 818, 16, 5], [1249, 3, 210, 110, 196, 6, 382, 170, 34], [139, 14, 2, 141, 1, 8], [10, 1179, 16, 2, 2093, 12, 119, 1321, 354, 661, 16, 957, 18081, 8, 1823, 102, 470, 4, 851, 18082, 1598, 15, 11, 7618, 188], [4, 250, 115, 16, 261, 514, 1607, 72, 280, 5, 62, 18083, 17, 4540, 1, 30, 562], [1, 64, 263, 55], [552, 85, 20, 443, 45, 282, 680], [44, 5, 1, 328, 20, 18084, 225], [37, 8533, 49, 30, 74, 24], [162, 10, 1, 82, 4, 4587, 2456, 815, 7998], [55, 1505, 46, 4, 324, 53, 148, 5, 47, 1505, 76, 1, 53], [60, 1, 14, 627], [681, 872, 8, 207, 387], [1059, 66, 303, 3564, 8, 18085, 48, 4769], [25, 63, 58, 699, 6160, 2300, 8534, 34, 75, 70, 18086, 172, 1711, 7, 2, 161, 3224], [18087, 2740, 233, 18088, 233, 18089, 2740, 233, 18090, 233, 18091, 2740, 233, 18092, 188, 2060, 18093, 2740], [8535, 37, 56, 128], [55, 7, 18094, 91, 18095, 1, 340, 18096, 15], [25, 131, 1, 59, 2, 460, 78, 62, 10, 1636, 762, 51, 10, 676], [31, 42, 29, 67, 20, 548, 2085, 88, 29, 536, 21, 2, 25, 69, 1182, 9], [23, 59, 10, 6028, 1, 1230], [39, 1, 37, 19, 185, 251], [3528, 1630, 1484, 13, 2, 1682, 213, 206, 1745, 177, 1, 1471, 13, 98, 1074, 18097, 34, 25, 61, 284, 129, 4235, 40, 43], [1, 64, 448, 76, 8177, 327, 229, 2, 3414, 5609, 3098, 8, 169, 1666, 1, 5, 4013], [1, 94, 2, 406, 16, 2, 535, 294, 18, 4, 2458, 612, 8, 1787, 15, 18098, 53, 1, 32, 36, 58, 12, 61], [3, 124, 270, 2, 1621, 1907, 16, 175, 1977, 391, 175, 1304, 2225, 15, 284, 71, 239, 25, 175, 33, 13, 17, 92], [3, 375, 3, 47, 44, 310, 352, 27, 2, 120, 1, 8, 40, 121, 50, 24, 578, 13, 3451, 8, 18099, 1499, 46, 18100], [31, 22, 25, 1264, 424, 960, 888, 6, 4079, 22, 196, 78, 1321, 9, 29, 655, 76, 4014, 438, 26], [1518, 2069, 24, 415, 578, 13, 631, 381, 40, 136, 2, 1864, 30, 8, 4, 1, 65, 13, 1748, 3032, 40, 37, 18101], [10, 77, 273, 17, 40, 47, 18, 50, 1230, 3, 3469, 863, 859, 50, 9, 30], [7, 2326, 21, 2, 9, 31, 5, 419, 357, 63, 113, 5, 57, 6, 58, 117, 117], [5, 5940, 3628, 3, 41, 18102, 51, 307, 1, 72, 23, 4148, 5230, 3414, 65, 13, 18103, 18104], [610, 156, 14, 208, 13, 2, 1, 321], [103, 20, 1, 58, 22, 21, 5], [2928, 12, 48, 1923, 5529, 29, 8435, 17, 83], [221, 66, 75, 3618, 318, 44, 6, 728, 1529, 5, 2881, 53, 23, 2, 180, 1, 8, 818, 55, 100, 17, 6260], [167, 4, 1, 579, 627, 4, 1, 34, 3, 440, 10, 265, 18, 50, 172, 231], [148, 18105, 3485, 18106, 10, 25, 33, 70, 362, 5, 3485, 5911, 236, 8536], [18107, 6163, 18108, 3485, 5911, 236, 8536, 18109, 18110], [183, 9, 64, 6, 290, 128, 26, 36, 46, 41, 553, 6, 468], [134, 263, 305, 1789, 812, 66, 363, 54, 116, 26, 424, 7, 3199, 26, 424, 794], [29, 627, 66, 146, 114, 54, 56, 8, 87, 18111, 18112, 5790], [8369, 1274, 9, 658, 117, 224, 4, 18113], [1678, 1, 124, 6, 349, 10, 343, 6, 18114, 55, 37, 57, 58, 5, 175, 31, 5, 468], [14, 117, 38, 42, 131, 19, 2, 89, 9, 99, 74, 2, 9, 42, 210, 109, 131, 19], [31, 3, 119, 4, 24, 8, 15, 578, 13, 18115, 3, 2498, 37, 42, 75, 113, 574, 3, 672, 42, 31, 3, 46, 8537], [31, 52, 113, 42, 7, 42, 41, 60, 93, 24, 34, 52, 105, 122, 6, 167, 7943, 57, 7, 196], [6602, 47, 109, 2, 24, 1000, 52, 100, 60, 161, 25, 756, 170, 8, 114, 84, 18116, 206, 235, 386, 170, 11, 580, 16, 84, 779], [55, 25, 13, 2596, 85, 118, 22, 1, 58, 22, 53, 3, 547, 20, 730, 420, 8, 4, 3640, 603, 976], [358, 3125, 352, 103, 857, 44, 42, 86, 42, 13, 2, 1, 2, 161, 99, 1572], [2330, 31, 42, 44, 2, 3181, 27, 39, 154, 979, 1820, 7, 68, 9, 152, 61, 113, 326, 40, 19, 398], [275, 798, 1263, 11, 395, 14, 37, 56], [25, 19, 5, 42, 2, 1, 30, 8205, 147, 46, 1465, 18117, 42, 1, 216, 45, 4745, 2, 1465, 325], [32, 4, 9, 62, 922, 166], [3, 5659, 32, 42, 18118], [4, 503, 3274, 21, 38, 5, 79, 2, 25, 2030, 1121, 296, 96, 349, 127, 9, 130, 8410], [1028, 3429, 2594, 23, 152, 19, 4, 832, 1, 390, 21, 5, 321], [286, 336, 1], [7, 38, 5, 72, 1539, 1, 46, 41, 43, 4877], [39, 1, 46, 45, 26, 24, 12, 10, 2387, 2712, 3, 64, 1921, 441, 3, 90, 2068], [375, 32, 4, 56, 18, 4, 1352, 16, 20, 347, 66, 4436, 15, 26, 157, 5914, 4, 2006, 37, 15, 150, 13, 20, 206, 347, 2562], [53, 1350, 12, 2, 3260, 917], [2695, 12, 1054, 35, 27, 60, 1, 74, 256, 149, 52, 48, 137, 13, 2695, 4578, 274, 3742, 18119], [68, 25, 82, 4, 722, 273, 17, 68, 184, 278, 105, 627, 8538, 91, 56, 12, 246, 91, 18120], [153, 121, 4075, 491, 97, 803, 54, 913, 157, 240, 163, 143, 7965, 52, 96, 7, 25, 38, 52, 46, 725], [119, 3672, 28, 283, 6, 14, 2293, 3, 29, 58, 519, 16, 8394], [78, 9, 8, 78, 2633, 30, 481, 18121, 251], [1123, 54, 6, 10, 779, 149, 40, 46, 878, 43, 9], [1614, 13, 12, 22, 1, 18122, 686], [4766, 18123, 45, 3, 18124, 37, 357, 86, 1963, 47, 459, 493, 21, 1713, 2356, 1137, 6, 4, 315, 153, 2545], [278, 516, 687, 26, 70, 35, 88, 290, 26, 421, 35, 149, 640, 1, 64, 6, 94, 243, 337, 948], [1672, 129, 319], [23, 1096, 34, 3, 1373, 42, 23, 165, 130, 7, 1], [53, 93, 24, 44, 2, 25, 13, 53, 2123, 184, 289, 182, 297, 18], [18125, 2, 161, 1], [704, 8539, 4123, 12, 51, 4, 232, 178, 255, 2, 4376, 1100], [128, 148, 22, 1, 37, 56, 128], [25, 14, 1070, 59, 36, 845, 11, 489, 364, 42, 255, 76, 9, 21, 25, 32, 10, 845, 489, 845], [42, 67, 2, 25, 6, 33, 1049, 32, 84, 332, 1845, 169, 18, 42, 9, 61, 1692, 7, 4117, 7, 437, 55], [3, 207, 10, 1119, 1291, 202, 27, 2, 5822, 8, 2103, 10, 436, 1034, 33, 37, 40, 62, 57, 2, 158, 138, 150, 2226], [3, 502, 35, 79, 10, 436, 2, 158, 985, 352, 21, 8540], [290, 129, 2, 9, 12, 68, 16, 4, 4914, 184, 5, 63, 58], [18, 158, 115, 66, 2552, 158, 5543, 123, 48, 8541], [37, 597, 4, 1, 18126, 160, 1429, 18127], [1785, 21, 39, 9, 3, 41, 26, 5, 46, 4, 101, 68, 321], [2739, 50, 30, 203, 485, 50, 24, 963, 26, 15, 3087, 50, 91, 6, 18128, 5680, 1754, 12, 404, 51, 164, 951], [632, 35, 83], [341, 18129, 248], [225, 256, 12, 8542, 740, 7, 199, 184, 12, 248, 244, 707, 15, 12, 8543, 244, 213, 15, 18130], [3, 300, 1, 616, 129, 25, 69, 29, 442, 11, 3557, 126, 343], [273, 5, 18131, 12, 127, 130, 56], [97, 257, 56, 25, 19, 69, 29, 13], [2043, 184, 151, 105, 134, 2, 1, 18132, 548, 18133, 441, 18134, 169, 18135, 186, 18136, 2676, 5060], [1017, 6, 76, 234, 236, 7, 62, 36, 4, 234, 236, 66, 87, 127, 16, 97], [2363, 349, 9], [38, 78, 41, 4, 199, 260, 779, 8, 623, 7, 1, 12, 4, 112, 3996], [32, 3, 67, 21, 10, 18137, 12, 2, 180, 517, 9, 40, 146, 180, 517, 37, 3, 79, 50, 180, 517], [601, 3, 227, 10, 310, 18, 1229, 6, 175, 33, 6, 465, 4, 95, 18138], [8544, 91, 16, 4511, 160, 1393, 16, 83], [66, 32, 62, 7, 68, 395, 7, 222, 72, 393, 8, 5, 33, 65, 51, 76, 86, 1322, 144, 4053], [31, 97, 228, 156, 1174, 28, 5, 6, 18139, 125, 97, 25, 74, 58, 593, 45, 125, 18140, 1, 109, 46, 97, 228], [21, 213, 268, 408, 1095, 18141, 8, 18142, 44, 121, 36, 58, 184, 1320, 117, 8096, 288, 2743, 8, 166, 49, 18143, 10, 236], [1, 86, 40, 62, 474, 5378], [5, 75, 333, 4646, 8, 5, 18144, 295, 93, 107, 82, 44, 111, 69, 72, 5453, 73, 98, 2532, 18, 20], [5, 62, 71, 11, 3947, 761, 4, 237, 2532, 21, 3947, 171, 2321, 63, 107, 35, 27, 12, 18145], [800, 4, 247, 1107, 45, 33, 149, 2, 89, 1, 175, 15], [31, 5, 303, 1683, 21, 3773, 4681, 36, 33, 1020, 5, 11, 98, 8505, 56, 63, 8, 2878, 5, 82, 98, 18146, 173, 18147], [2007, 1085, 12, 474, 51, 4, 8378, 18148, 155, 83], [8, 23, 7, 1, 69, 317, 18149], [23, 20, 1, 142, 21, 766], [37, 15, 1395, 6, 81, 59, 203, 1, 34, 15, 431, 6, 81, 59, 703, 1, 1027, 3, 62, 1628, 16, 834, 9, 18, 4, 18150], [5, 176, 20, 1, 26, 151, 271, 18, 10, 18151], [1250, 458, 676, 38, 76, 1250, 12, 1376], [135, 12, 2, 18152, 40, 72, 120, 49, 33, 1893, 1376, 202, 7517, 944, 26], [369, 22, 1, 372, 144], [1053, 1913, 904, 59, 20, 234, 9, 8, 169, 37, 40, 62, 15, 1798], [33, 41, 1474, 11, 567, 95, 1084, 45], [128, 7, 1, 486, 4, 1651, 26, 65, 35, 51, 4, 180, 1464, 163, 88, 623], [38, 97, 234, 9, 137, 99, 209, 26, 32, 5, 67, 12, 235, 18153], [3, 101, 119, 18154, 351, 24, 160, 161, 340], [7, 18155, 203, 1, 367, 2958, 40, 19, 53, 4, 18156, 160, 161, 340], [2023, 1, 1523, 12, 328, 324, 82, 161, 340, 160, 161, 340], [147, 693, 3, 29, 687, 125, 1019, 1, 55, 176, 15, 4742, 18157, 2042], [96, 2585, 1129, 282], [1331, 8, 377, 2769, 448, 1638, 175, 155, 691, 6, 1624, 3408], [61, 337, 1], [1, 987, 6, 393, 728, 18158, 1, 2, 987, 6, 4202, 6, 114, 17, 6, 4, 1065], [278, 105, 471, 10, 265, 6, 2440, 261, 140, 88, 36, 118, 105, 1924, 179, 775, 261, 290], [23, 37, 807, 31, 217, 118, 471, 17, 2, 635, 7728, 27, 348, 3951, 6, 15, 13, 36, 58, 11, 4, 4327, 178, 794], [4047, 168, 4, 1067, 1983, 368, 11, 2, 7240, 4818, 289, 105, 132, 127, 18159], [1, 151, 450, 20, 19, 1068, 5, 2, 4310], [4000, 8213, 462, 57, 277, 20, 24, 578, 13], [18160, 4, 18161, 18162, 47, 7979, 1395, 8, 18163, 73, 3172, 6, 159, 69, 33, 8545, 6029, 1210, 18164], [251, 42, 41, 1206, 92, 3, 741, 10, 1735, 54, 6, 150, 60, 1241, 8, 22, 1, 30, 18165, 136, 4, 1203, 6], [6647, 18166, 2908, 1283, 18167, 2146, 18, 18168, 2, 115, 14, 18169, 27, 2, 1055, 95, 11, 18170, 8439, 188], [3, 64, 326, 432, 90, 39, 1], [398, 4, 1059, 26, 26, 64, 18171, 643, 1], [3, 90, 38, 2, 1, 72, 40, 29, 279, 31, 50, 25, 291, 8, 52, 41, 295, 61, 21, 18172, 208, 13, 2, 365, 6007], [28, 32, 39, 536, 13, 1783, 23, 3334, 8, 80, 1, 13, 18173, 3010, 8546], [119, 24, 12, 18174, 326, 24, 46, 4048], [639, 16, 7554, 3304, 1883, 69, 363, 6, 2810, 6, 671, 377, 6303, 2788, 123, 1331, 188, 2545], [18175, 7131, 10, 18176, 2114, 4, 9, 49, 21, 326, 10, 25], [6, 18177, 20, 1357, 487, 14, 1112, 123, 268, 56, 63, 18178], [2219, 64, 54, 135, 1426, 2, 1774, 33, 100, 4, 360, 62, 42, 152, 14, 2, 1583, 3168, 658, 797], [496, 18, 81, 56, 288, 231, 985, 225, 18179, 26], [1379, 20, 18180, 29, 13, 74, 81, 6, 7, 8042, 5, 29, 81, 6, 7, 18181], [19, 2, 9, 538, 2, 414, 64, 2, 462], [8547, 18182, 2, 9, 30, 25, 8, 1497, 3, 94, 170, 272, 737, 170, 13, 143, 161, 1, 52, 12], [22, 1, 137, 18183, 11, 18184, 18185, 265], [417, 260, 1571, 83], [221, 117, 3206, 4, 101, 864, 16, 30, 814, 182, 41, 12, 38, 15, 714, 291, 785, 4, 3316, 1010], [529, 120, 670, 1462, 202, 1404, 75, 304, 634, 202, 670, 1462, 8413, 88, 465, 76, 83], [4770, 2046, 11, 4, 866, 603, 2150, 11, 50, 24, 37, 3, 6613, 6, 50, 971, 1083, 22, 27, 2, 3619, 2665], [174, 2, 161, 1, 31, 5, 29, 44, 20, 509, 3642, 18], [5, 14, 1921, 10, 138, 1], [3, 2563, 11, 794, 24, 1671], [20, 2, 570, 95], [408, 44, 18186, 5, 375, 22, 2707, 3964, 15, 330, 445, 6, 984, 96, 43], [12, 44, 43, 18187, 4742, 3908, 18, 20, 18188, 698, 16, 13, 159, 524, 105, 182, 28, 245, 1987], [18189, 2, 1, 8, 37, 49, 1323, 8, 3, 3052, 196, 760], [2453, 12, 2, 643, 1, 5250, 30, 18190, 18191], [206, 1, 64, 44, 2, 18192], [2694, 66, 49, 48, 4, 3838, 2936, 66, 49, 48, 4, 3836, 3258, 66, 148, 362, 46, 43, 18193, 7503, 69, 279, 1261], [38, 20, 2, 1595, 11, 5337, 5, 75, 64, 1311, 140, 326, 227, 173, 9, 18, 18194], [18195, 407, 43, 9, 30, 25, 51, 32], [75, 553, 16, 76, 9, 3398, 36, 5662, 7, 1, 4, 6024, 489], [58, 3, 19, 50, 74, 1090, 50, 3, 90, 203, 964, 834, 1], [3, 29, 397, 11, 493, 51, 489, 4, 3332, 107, 4005, 17, 2073, 190, 2454, 113, 2, 1, 28, 129, 135, 18196], [23, 48, 4693, 7, 1951, 3269, 1], [15, 4, 247, 589, 45, 11, 4, 360, 38, 2, 1, 192, 533, 133, 256, 88, 72, 18197], [852, 396, 50, 164, 8, 363, 108, 6, 84, 206, 1, 4385, 40, 41, 76, 1, 197, 709], [18198, 9, 38, 3, 150, 13, 15], [56, 3792, 39, 997, 1607, 49, 2996, 3792], [1387, 1143, 5523, 5798, 1334, 11, 5784, 261, 1334, 1276, 1524, 565, 26, 935, 977, 122, 18199, 951], [18200, 8548, 3096, 18201, 11, 290, 2651, 18202, 66, 198, 14, 417, 6, 18203, 318, 505], [1, 29, 58, 22], [1, 5, 2, 1774, 536, 80, 706, 63, 3, 28, 2, 154, 253, 26], [3, 301, 3, 124, 2, 635, 18204, 37, 38, 3, 479, 35, 9, 3, 222, 113, 31, 36, 1604, 18205, 1, 2, 9, 40, 276, 405, 173], [1, 162, 5, 94, 2, 3322, 74, 3994, 11, 7, 327, 3322, 3994, 12, 37, 1023, 26], [15, 32, 501, 8, 178, 444, 3, 44, 6, 491, 2, 1], [91, 1, 5, 88, 19, 562, 151, 1276, 78, 331, 142, 361, 9, 26, 7, 85, 5895, 1578, 20, 112, 994, 9], [91, 19, 567, 95], [832, 1, 210, 404, 6331, 19, 4, 18206, 151, 303, 80, 1728], [80, 1, 29, 2438, 17, 52, 131, 1794, 17], [75, 14, 100, 76, 1208, 9, 780, 27, 80, 18207], [78, 492, 9, 278, 18208, 492, 6924], [2811, 380, 18209, 66, 29, 13, 6, 14, 191, 85, 220, 65, 4629, 15, 79, 5698, 1, 7732, 66, 33, 65, 22, 596], [5, 1, 49, 940, 2, 6030], [18210, 12, 1440, 27, 918], [5, 41, 9, 3, 41, 956], [34, 100, 2, 8159, 191, 2, 418, 6, 134, 170, 60, 8549, 71, 78, 9, 72, 15, 1002, 7, 71, 5, 70, 50, 271, 74, 18211], [2356, 1137, 4295, 16, 4, 1164, 205, 18212, 46, 43, 18213, 397, 2531, 747, 84, 908, 8, 1, 538, 7], [249, 80, 734, 567, 95], [78, 9, 889, 8513], [38, 5, 46, 124, 24, 11, 2, 341, 6031, 26, 3272], [1954, 142, 83, 881, 10, 1473, 26, 151, 15, 20, 138, 102, 26, 18214, 15, 6, 20, 7195, 371, 5, 131, 14, 2], [10, 1747, 117, 92, 2564, 2564, 2564, 2786, 175, 2564, 2564, 2564, 26, 60, 1, 533, 188], [29, 43, 25, 67, 43, 291, 30, 1, 34, 15, 284, 71, 2, 1, 103, 58, 32, 40, 63, 6, 165, 2, 291, 30, 25], [7, 24, 12, 105, 20, 15, 33, 20, 227, 375, 7, 26], [38, 20, 234, 1, 122, 6, 1420, 5, 11, 775], [25, 81, 127, 130, 1, 39, 4669, 100, 7, 2258, 11], [28, 19, 5, 529, 4299, 837, 19], [69, 18, 5327, 2145, 412, 12, 389, 871, 6, 56, 4, 7183, 1577], [2207, 6453, 12, 700, 276, 14, 248, 4, 25, 40, 216, 15, 27, 12, 2030], [7, 50, 1791, 21, 48, 191, 230, 40, 1415, 50, 518, 205, 26, 171, 1], [1, 680, 797, 65, 51, 22, 45, 26], [180, 517, 903, 2844, 231, 43, 343, 74, 40, 2, 282], [3, 75, 19, 27, 8550, 283], [14, 2, 77, 27, 2, 453, 2, 2550, 27, 521, 26, 2, 1, 7, 317, 134, 2, 1066], [1673, 14, 2, 1, 18215, 160, 6032, 193, 6, 28, 20, 280, 6, 58, 2180], [18216, 403, 681, 8551, 215, 201, 18217, 18218, 2517, 24, 8551, 215, 18219], [3415, 186, 103, 2792, 4, 19, 54, 16, 2, 9, 37, 705], [154, 2253, 12, 96, 56], [3, 101, 255, 1349, 140, 3, 13, 15, 2, 1, 41, 343], [38, 217, 12, 1012, 4, 1205, 18220, 4, 18221, 3572, 8, 7, 113, 5, 474, 5, 87, 6, 62, 1261], [421, 1382, 18222, 2803, 825, 1215, 2249, 18223, 1611, 159, 824, 951], [2491, 1717, 15, 114, 2, 320, 6, 311, 7, 1, 102], [2740, 460, 49, 56, 26, 3, 29, 313, 76, 26], [211, 2, 358, 115, 51, 197, 1, 18224, 763, 50, 995, 18, 17, 55], [73, 2, 203, 25, 3, 46, 182, 2405, 2, 1383, 102, 393, 34, 4, 6506, 16, 10, 18225, 29, 43, 1, 86, 23, 352], [8552], [1490, 352, 14, 44, 5, 131, 204, 7, 1, 117, 88, 26, 116], [23, 33, 2, 1696, 399, 69, 5939, 84, 169, 26, 651, 288, 1532, 271, 54, 16, 1885], [272, 257, 27, 24, 35, 13, 1410, 18226, 167, 15, 27, 2, 4634, 3, 29, 87, 2, 1777, 1817], [1699, 30, 1, 42, 65, 13, 2, 1617, 593, 30, 42, 2, 341, 542, 537, 236], [147, 71, 42, 405, 15, 5927, 236, 191, 59, 17, 2713, 622, 756, 18, 10, 138, 236, 74, 7067, 59, 17, 622, 18227, 30, 593], [1, 223, 58, 827, 1, 4771], [18228, 3, 114, 1180, 112, 606, 25, 45, 114, 1180, 123, 172, 125, 42, 777, 30, 9, 18229, 4615], [3, 46, 5939, 43, 9, 3, 41, 18230, 4615], [432, 150, 1019, 18231, 74, 2365], [1028, 1009, 169, 18232, 47, 2, 3027, 1807, 147, 1243, 51, 933, 2414, 1, 30, 11, 84, 373, 620, 447, 18233], [22, 1, 456, 340, 82, 18234, 360], [85, 1, 1580, 59, 14, 284, 13, 7, 342, 7, 13, 2, 25, 1580, 59, 71, 2362, 52, 12], [3730, 18235, 4145, 16, 4, 213, 219, 655, 4, 875, 26, 190, 5895, 1578, 18236, 31, 52, 167, 97, 15, 276, 18237, 4387, 32], [18238, 1041, 123, 18239, 1123, 54, 10, 312, 18240, 6033], [69, 58, 1, 114, 17, 21], [1413, 490, 2271], [31, 5, 101, 883, 175, 11, 293, 7, 5, 103, 1579, 28, 18241, 1640, 8, 176, 15, 562], [1, 680], [8, 3, 299, 3, 124, 2, 437], [4, 6315, 18242, 2505, 132, 2, 89, 1], [18243, 472, 3668, 1, 366, 2, 866, 8, 32, 16, 2, 2547, 374, 4, 247, 18244, 6956, 16], [124, 6, 1338, 10, 18245, 19, 4, 18246], [1084, 19, 385, 85, 12, 2, 178, 641, 2, 2540, 3470, 3347, 786, 412, 37, 2138, 8528], [12, 416, 18, 4, 786, 18247, 11, 2334, 57, 4, 19], [7, 19, 1914, 18248, 178, 720, 301, 7, 56, 30, 1439, 412, 105, 18249, 3, 1646, 7, 36, 563, 11, 4, 19], [79, 10, 386, 3808, 110, 538, 120, 574, 103, 14, 8553, 545, 350, 79, 170, 18250, 415, 63, 28, 102, 596], [7, 1, 311, 17, 1724, 8466], [5657, 13, 202, 77, 1147, 160, 4204, 1840, 77, 1903, 26, 928, 26, 120, 1, 18, 4, 696, 18251], [85, 58, 1, 90, 18, 246, 1, 575], [211, 1, 28, 143, 138, 36, 14, 18252], [2779, 3, 105, 938, 10, 25, 2763, 246, 1, 26, 31, 4, 25, 182, 121, 60, 45, 13, 7, 7, 25, 6029], [93, 24, 114, 20, 453, 102, 4, 1784, 8, 1040, 16, 744, 164], [15, 2, 320, 2245, 6, 100, 61, 16, 2, 77, 31, 5, 258, 54, 40, 132, 134, 4, 24, 54, 13, 7960, 558, 51, 2, 457, 18253], [38, 3, 72, 18254, 3, 29, 5210, 196, 9, 74, 8554, 15, 222, 14, 2, 518, 16, 2823], [31, 5, 109, 131, 333, 20, 91, 94, 170, 333, 276, 227, 5, 962, 34, 5, 62, 1, 46, 109, 57, 36, 18255], [4, 2593, 408, 49, 32, 4, 199, 395, 6, 307, 470, 18256, 4142, 18257, 2, 4142, 1792], [7, 57, 3, 79, 4, 1, 8, 572, 31, 5, 19, 27, 217, 271, 8, 290, 40, 167, 965], [4, 101, 184, 7, 187, 81, 59, 47, 17, 345, 59, 4, 2924, 18258, 62, 295, 8464], [56, 170, 21, 226, 79, 509, 20, 45, 6, 17, 1, 7, 32, 5, 41], [40, 41, 4, 481, 16, 2, 104, 26, 26], [100, 17, 70, 22, 1891, 3, 29, 87, 43, 19, 481, 3, 29, 87, 553, 16, 5, 5813, 30, 9, 99, 14, 228], [160, 85, 58, 42, 86, 15, 37, 332, 18259, 18260, 1082, 1211, 106, 18, 247, 2539, 38, 15, 596], [18261, 1032, 12, 944, 2143, 726, 71, 12, 15, 152, 14, 1369, 256, 225, 8, 603, 5898, 1445], [4223, 15, 7, 68, 18262, 22, 399], [38, 3, 70, 4, 1010, 466, 173, 4, 56, 2960], [38, 5, 119, 522, 7, 99, 341, 8, 192, 1238, 13, 2, 144, 8497], [543, 4, 931, 459, 325, 1], [1733, 2, 18263, 18264, 5645, 17, 18265], [31, 5, 64, 50, 869, 20, 1, 37, 5, 176, 2279], [39, 9, 46, 334], [8, 31, 5, 46, 2, 236, 28, 35, 54, 10, 941, 331], [1969, 9, 38, 1, 28, 7, 4286, 1997, 36, 58, 45, 13, 22, 26], [3, 46, 41, 43, 437, 418, 784, 18, 18266, 6, 4, 654, 6, 14, 319, 33, 4698, 97, 1457, 51, 4, 1909, 38, 97, 107, 108], [497, 175, 5, 29, 13, 1, 125, 752, 343, 97, 844, 276, 14, 392, 16, 22, 26], [160, 5, 2, 24, 3, 94, 80, 8555], [3, 195, 2, 2203, 654, 18267, 34, 2614, 2, 818, 1546, 1120, 696, 236], [275, 156, 733, 59, 60, 45, 25, 46, 58, 117, 18268, 1, 29, 44, 3058], [621, 8, 416, 63, 44, 10, 18269, 19, 7, 282], [1140, 38, 5, 421, 35, 27, 20, 1214, 8, 5, 146, 349, 54, 20, 206, 9, 420, 13], [352, 18, 841, 438, 29, 196, 5, 2, 9, 304, 1638, 115, 266, 70, 5, 2, 436, 342, 327, 29, 196, 78, 243, 44, 2, 2003, 717], [7, 189, 69, 20, 37, 173, 8, 69, 12, 1577, 98, 1034, 6, 5, 317, 134, 2, 148, 59, 5, 2239, 174, 24], [391, 1, 294, 224, 818, 27, 126, 554, 504, 13, 36, 41, 50, 554], [119, 24, 12, 2744, 1, 14, 122, 6, 1396, 20, 19, 833], [3, 87, 2, 498, 74, 309, 1], [31, 7, 25, 4255, 107, 6, 4, 689, 25, 152, 1505, 170, 21, 84, 18270, 8, 84, 236, 236, 9], [33, 149, 3, 13, 2, 846, 82, 6034, 449, 892, 29, 196, 23, 1509, 5, 1, 5, 33, 29, 65, 73, 93, 73, 5, 168, 6], [1403, 547, 22, 1], [22, 1, 995, 132, 539, 787, 213, 16, 3393], [441, 18271, 130, 2, 2297, 1, 11, 4, 489], [219, 148, 77, 5, 2, 89, 1, 92], [38, 2, 1, 509, 20, 1253, 34, 317, 2182], [23, 2, 1, 38, 23, 807], [3, 118, 105, 14, 27, 217, 7, 1491, 6, 113, 25, 8, 1, 220, 2780, 3, 65, 13, 2, 1564, 19, 459, 1188], [42, 65, 13, 98, 32, 202, 18272, 18273, 26, 27, 43, 1953, 18, 7, 1, 8, 535, 879, 3266, 5416, 177], [3, 301, 15, 47, 7493, 6, 61, 224, 491, 1, 38, 36, 72, 185, 45], [31, 52, 75, 465, 7, 24, 737, 88, 15, 46, 631, 602], [53, 3075, 300, 36, 63, 58, 165, 88, 5, 94, 126, 244, 1, 2059, 53], [8286, 6873, 37, 56, 128], [315, 77, 109, 58, 28, 127, 24, 130, 25], [8, 1143, 6968, 8556, 852, 2858, 1248, 1191, 6, 18274, 26], [2, 25, 223, 14, 2, 25, 23, 370, 26, 2, 9, 223, 14, 2, 9, 1804, 26], [1264, 47, 1671, 1379, 245, 16, 5, 1, 110, 86, 59, 1183, 17, 11, 4, 18275], [18276, 109, 19, 249, 22, 7393, 251, 71, 200, 36, 28, 117, 108, 6, 56, 11, 68, 658], [18277, 1], [2207, 41, 2, 203, 30, 34, 166, 130, 4, 1, 65, 13, 2, 18278, 1127], [554, 18279, 18280, 1621, 1680, 6, 1132, 384, 69, 79, 50, 1485, 27, 8557, 175, 527], [5689, 1701, 65, 13, 2, 4631, 50, 8, 4163, 700, 1342, 123, 1359, 8, 45, 7, 85, 3900, 266, 182, 70, 50, 147, 1102], [351, 2519, 115, 51, 18281, 1, 556, 679, 28, 2, 438, 54, 2, 25], [38, 2, 1, 192, 65, 51, 482], [1565, 1093, 7, 5, 982, 122, 6, 44, 352, 27, 95], [2737, 17, 30, 9, 41, 98, 1074, 34, 15, 102, 30, 1], [2, 95, 317, 751, 140, 15, 136, 98, 729, 15, 751, 140, 15, 136, 2, 18282], [164, 2, 83, 814, 41, 6, 61, 54, 8, 543, 809], [26, 38, 2, 25, 29, 279, 31, 5, 338, 15, 149, 52, 146, 246, 1, 52, 47, 515, 16, 3386, 545, 769], [75, 43, 1, 113, 17, 2, 25, 48, 588, 444, 40, 542, 6, 113, 17, 71, 364, 52, 50, 26, 15, 822, 6, 22, 45], [5507, 2, 18283, 42, 171, 158], [5, 29, 64, 50, 31, 5, 176, 2, 535, 166, 9, 18, 4, 234], [252, 215, 115, 19, 15, 294, 54, 7, 1], [3263, 49, 56], [7, 57, 1201, 49, 2195, 627, 4, 4281, 26, 56, 4328, 15, 59, 70, 111, 150, 13, 36, 49, 2, 820], [57, 61, 142, 24], [354, 14, 2814], [31, 5, 29, 534, 175, 20, 33, 2, 180, 24], [75, 557, 39, 9, 13, 462, 4672], [724, 2, 89, 1, 34, 40, 47, 716, 981], [3, 566, 18284, 29, 64, 1323, 123, 3005, 18285, 51, 197, 3902, 233, 45, 8558, 73, 2, 1, 233], [180, 264, 51, 18286, 18287, 18288, 1186, 1726, 135, 51, 1212, 18289, 1060, 360, 1957, 178, 26], [18290, 18291, 33, 2, 2751, 226, 21, 2, 181, 18292], [3, 58, 48, 64, 39, 9], [18293, 12, 2, 902, 250, 52, 79, 17, 2, 3839, 88, 52, 121, 10, 548, 75, 14, 759, 74, 6150, 15, 146, 14, 190, 74], [5, 1595, 30, 1], [56, 81, 123, 239, 26, 90, 123, 60, 26, 3325, 380, 71, 239, 19, 3, 134, 15, 882, 130, 68, 26], [278, 516, 14, 82, 2, 18294, 88, 259, 11, 179, 30, 4207, 1890, 27, 158, 8, 158, 18295, 3200, 18296], [192, 345, 8, 1509, 170, 711, 3, 67, 6, 4280], [48, 152, 582, 4, 1894, 158, 28, 1722, 562, 52, 62, 254, 18297, 136, 6, 821, 6, 18298, 34, 85, 325], [805, 4, 2886, 18299, 1415, 7407, 6, 286, 215, 264, 11, 84, 373, 337, 8, 22, 104, 4685], [2612, 3956, 12, 152, 14, 4, 237, 707, 4811, 339, 1], [1950, 163, 1443, 907, 536, 1015, 35, 1, 227, 6, 3380, 18300], [31, 5, 29, 94, 4, 3084, 808, 7910, 4, 494, 5398, 8, 98, 5933, 11, 3654, 8, 1719, 18301, 80, 188], [3463, 16, 4, 1260, 16, 4, 673], [336, 5534, 47, 56, 862, 47, 37, 56, 797], [3, 29, 594, 71, 37, 239, 732, 63, 90, 18, 642, 21, 2002, 27, 2, 18302, 357, 113, 39, 18303, 393, 1261], [3, 41, 1474, 2877, 22, 106, 83], [3, 273, 42, 133, 58, 7, 53, 60, 638, 103, 72, 8, 389, 393, 6, 28, 4, 3514, 1002, 456, 14, 5], [4549, 100, 17, 113, 78, 749, 60, 1, 11, 2719, 14, 18304, 26], [1098, 891, 8, 4, 2336, 1939, 18305, 27, 2, 2690, 8559, 194, 26], [371, 18306, 1098, 891, 18307, 18308, 178, 1259, 49, 2700, 247, 4291, 747, 4743, 18309, 4012, 1569, 98], [8560, 283], [52, 98, 4752, 2257, 56, 919, 21, 2, 91], [3, 67, 217, 3, 63, 79, 10, 373, 461, 246, 1, 18310, 708, 18, 170, 18311], [41, 22, 1, 51, 197, 214, 27, 17, 426, 50, 500, 1, 18, 10, 138], [6553, 26, 269, 224, 18, 644, 16, 496, 26], [53, 4936, 18312, 251, 25, 29, 62, 5, 34, 103, 313, 1751, 18, 20, 226, 21, 4, 24, 5, 1188], [155, 89, 1, 107, 27, 2156, 2246], [5, 614, 6, 176, 20, 9, 82, 258, 54, 59, 922, 166], [221, 36, 248, 18313, 22, 91, 3834, 84, 1188, 3862, 23, 1823, 32, 97, 3585], [18314, 18315, 510, 6, 94, 17, 3045, 1146, 52, 121, 3, 47, 2, 1288, 838, 7, 19, 5564], [116, 2764, 132, 2, 1695, 22, 18316, 371, 1059, 4012, 47, 1695, 6, 4, 232, 21, 1600, 43, 18317, 6347], [1335, 25, 101, 79, 5, 2, 1, 38, 5, 569, 4, 910, 59, 240, 74, 36, 29, 28, 36, 193], [526, 736, 237, 184, 5, 103, 194, 1185, 18318, 18319, 12, 2, 3126, 1, 18320, 1561, 170, 8, 1561, 4, 18321, 26], [65, 51, 32, 212, 365, 30, 19, 177, 30, 1773, 21, 2, 1013, 30, 56, 30, 365, 30, 408, 54, 116], [26, 18322, 18323, 216, 17, 151, 6, 110, 409, 760, 529, 209], [4115, 165, 18324, 82, 50, 18325, 152, 28, 906, 35], [3, 44, 6, 1463, 13, 23, 2, 587, 548, 1, 8, 311, 5, 102, 11, 98, 5816, 461, 2, 710, 299, 38, 428, 3], [79, 143, 2980, 2980, 282], [5, 46, 276, 114, 2, 327, 205, 48, 626, 6, 23, 11, 2, 1688, 18326, 205, 1, 47, 294, 705], [8561, 2038], [4, 360, 452, 14, 73, 501, 31, 9, 210, 6312], [3, 506, 8542, 3, 19, 9, 8, 70, 323, 133, 4, 385, 3, 1505, 25, 21, 36, 197, 8, 29, 150, 329, 133, 4, 385], [3501, 1199, 1969, 159, 1186, 6035, 404, 8313, 18327], [3368, 12, 2, 141, 1, 38, 47, 4, 215, 106, 5, 566, 59, 3368, 18328, 1480, 157, 32, 84], [43, 1, 30, 418, 3546, 103, 182, 14, 73, 611, 73, 22, 629], [32, 3, 94, 129, 610, 18329, 1094, 5834, 7, 37, 18330, 110, 21, 18331], [55, 10, 1842, 16, 302, 12, 37, 834, 615, 31, 23, 4, 796, 1, 814, 182, 4772, 604, 62, 85, 4960], [1073, 6, 93, 2183, 337, 16, 4, 93, 2183, 63, 3, 19, 20, 1], [66, 157, 2, 388, 11, 4, 120, 331, 15, 152, 14, 4, 4582, 1728], [18332, 18333, 1876, 6721, 6, 18334, 18335, 4901, 18336, 18337, 236, 41, 626, 16, 353, 55, 26], [15, 46, 295, 6, 311, 7, 1, 102], [108, 11, 22, 1], [22, 1, 363, 392, 18, 144], [38, 3, 70, 4, 1010, 466, 173, 4, 56, 63], [38, 20, 122, 6, 2344, 4, 3096, 6, 737, 2, 1], [421, 159, 824, 3908, 8562, 5243, 21, 2, 18338], [18339, 1], [38, 217, 310, 568, 102, 11, 4, 18340, 3, 67, 6, 756, 1117, 4, 930, 8, 635, 543, 147, 83], [3509, 196, 8329, 393, 8330, 3, 156, 299, 15, 47, 2, 179, 324, 21, 18341], [182, 338, 17, 224, 20, 1, 571, 28, 50, 18342], [122, 37, 332, 6, 2344, 4, 3096, 6, 737, 2, 1], [5055], [36, 2455, 3275, 1, 11, 4, 489, 1737], [2, 1, 2, 28, 7515, 2713, 3, 430, 150], [148, 9, 3248, 25, 58, 3, 18343, 43, 1, 42, 48, 28, 366, 54, 390], [31, 3, 200, 366, 3, 118, 48, 14, 1921, 9, 3101, 882, 36, 525, 19, 18], [31, 80, 9, 18344, 100, 50, 1668, 19, 50, 228, 74, 50, 734], [2287, 20, 2522, 31, 5, 258, 54, 4, 64, 16, 20, 164, 506, 8563, 24, 18, 2789, 26], [1243, 18345, 151, 114, 4, 18346, 72, 19, 50, 117, 11, 4, 24], [5, 41, 25, 8, 3, 41, 283], [20, 2, 19, 285, 8, 43, 22, 427, 2, 675, 5, 5801, 141, 83], [159, 1186, 59, 6, 70, 84, 679, 1575, 4017, 2483, 18347, 135, 51, 8564, 314, 2119, 26], [18348, 293, 8565, 18349, 139, 11, 51, 1186, 8564, 8456, 34, 96, 43, 3039], [96, 304, 21, 159, 1186, 6, 114, 4, 1706, 11, 18350], [2265, 420, 142, 4, 1304, 11, 1662, 8, 9, 749, 3, 330, 62, 18351, 8, 2599, 2935, 12, 3463, 55], [339, 1, 4745, 1440], [8566, 1402, 145, 188, 1843, 8566, 27, 4750, 1327, 188, 604, 633, 15, 54], [47, 2281, 483, 215, 264, 34, 242, 7, 1, 142, 125, 2224], [171, 1], [31, 42, 46, 70, 451, 21, 17, 6, 3896, 2794, 6, 42, 2, 1, 37, 18352, 7462, 31, 52, 82, 2, 2339, 43, 1561], [1312, 1022, 49, 559, 190], [11, 4533, 7436, 5544, 12, 2, 1055, 83], [2816, 18353, 18354, 151, 229, 5, 71, 6, 901, 2, 828, 18355], [404, 5464, 371, 3707, 16, 56, 363, 6, 154, 2253, 18356, 18357], [10, 443, 6036, 12, 18358, 10, 577, 443, 12, 2, 5532, 18359, 36, 49, 4, 884], [5, 2, 24, 1, 8, 3, 543, 20, 30, 11, 3794, 34, 20, 497, 73, 19, 8, 66, 87, 7, 6876, 11, 1641, 361], [38, 732, 708, 12, 33, 2, 18360, 18361, 1257, 5, 196, 33, 6, 4446, 2810, 4214, 1488, 5354, 4427, 18362], [243, 457, 1], [159, 2244, 18363, 2142, 18, 1755, 36, 86, 36, 1159, 4, 18364, 1317], [2726, 4, 1266, 54, 16, 76, 104, 1372, 18365, 12, 7976, 75, 94, 45], [542, 6, 1300, 39, 1, 8, 23, 48, 110, 470, 193, 18366, 10, 5744], [22, 1, 12, 1772, 18367, 22], [6637, 657, 54, 305, 4058, 1206, 18368, 390, 4, 269, 82, 4, 18369, 2348, 18370], [3, 61, 18, 8328, 1193, 155, 115, 92, 293, 6, 94, 2, 761, 59, 20, 718, 1714], [8, 40, 2687, 170, 27, 212, 387, 964, 8, 40, 1955, 170, 18371, 26, 949, 27, 7, 481, 3, 33, 62, 15], [367, 4, 95, 175, 11, 4, 561, 49, 64, 34, 375, 57, 20, 465, 12, 95, 968, 135, 28, 60, 728, 332, 95], [22, 171, 1, 18372, 43, 690, 57, 2, 91, 72, 4, 101, 193, 286, 1786, 538, 5, 12, 31, 42, 555, 54, 352], [48, 32, 202, 77, 49, 179, 464], [3, 75, 304, 634, 42, 26, 97, 520, 421, 35, 7, 25, 208, 13, 52, 373, 4, 24], [34, 15, 60, 89, 1, 18, 2789, 188, 5, 318, 258, 68, 16, 80, 253, 18, 116, 99], [60, 16, 78, 9, 37, 475, 59, 78, 1256, 78, 911, 78, 124, 2, 3074, 128], [1154, 1360, 46, 777, 6, 311, 7, 1, 2235, 3630, 7840, 1536, 18373], [267, 5, 6, 4, 18374, 1607, 5971, 21, 4719, 11, 4, 190, 897, 66, 32, 109, 1512, 15], [18375, 18376, 536, 903, 229, 17, 20, 2964, 1010, 5, 8567], [1215, 6971, 18377, 8293, 18378, 3994, 551, 269, 384, 18379, 32, 435, 18380, 32, 2551, 6, 440], [1302, 4, 1254, 343, 1839, 21, 1991, 1, 12, 6, 65, 13, 5, 514, 2, 290, 27, 2, 441, 18381], [1243, 1700, 190, 1092, 1222, 21, 3968], [359, 18, 2, 93, 414, 12, 13, 119, 54, 16, 4, 56, 661, 61, 54, 21, 7148], [960, 1754, 124, 2, 18382, 127, 1768, 1199, 3, 424, 54, 4, 56, 215, 1477], [1147, 57, 35, 5, 183, 1], [68, 91, 56, 12, 246, 91, 3940], [465, 2, 1, 113, 2, 761, 8, 32, 42, 63, 86, 12, 308, 308, 308], [945, 31, 174, 2, 5459, 30, 1], [49, 5, 11, 6037, 22, 110, 219, 18383, 18384, 2005, 1458, 3020, 103, 14, 18385, 619, 18386, 1036, 2539, 82], [107, 738, 18, 2, 1, 25, 18387], [38, 391, 465, 8568, 351, 230, 8569], [22, 1, 12, 19, 6038, 2936, 57, 12, 2, 1355, 7, 2162, 5, 11, 473, 324], [3, 132, 28, 169, 3, 46, 475, 133, 2, 236, 43, 690, 4, 6039, 272, 156, 28, 4, 18388, 26], [933, 77, 49, 342], [6, 8494, 21, 257, 35, 246, 1], [22, 1888, 2666, 1, 33, 294, 11, 4, 489, 400, 20, 3533, 18389, 541, 30, 142], [243, 457, 1554, 104], [112, 18390, 5, 752, 73, 19], [52, 136, 2, 438, 282], [1123, 54, 6, 4, 104, 69, 424, 2, 937, 8, 68, 1142, 18, 10, 3692, 26], [159, 2244, 198, 1918, 6, 1289, 460, 7030, 151, 644, 35, 563, 37, 52, 63, 1365, 84, 4445, 4898], [41, 1569, 851, 140, 2, 1, 672, 1155], [106, 6, 61, 6, 4, 2851, 8, 70, 109, 93, 451, 37, 3, 63, 208, 13, 3, 29, 62, 4, 1, 7, 1764, 18, 17, 371], [22, 109, 71, 1, 14, 8232, 8141], [1720, 4, 19, 5251, 5, 144, 864, 16, 385, 19, 6702, 73, 1066, 36, 4406, 142, 2693, 88, 188], [31, 5, 18391, 20, 2, 19, 711, 3, 19, 293, 32, 16, 5, 5251, 28, 19, 999, 8, 3701, 82, 18392], [18393, 198, 139, 8350, 496, 178, 51, 4, 1247, 16, 18394, 19, 139, 137, 13, 1549], [31, 2, 25, 533, 45, 59, 17, 98, 5, 224, 2662, 116, 2066, 5, 2, 172, 1, 98, 3, 29, 19, 27, 5, 112, 5525], [22, 9, 30, 2286, 41, 167, 8, 595, 4, 1938], [8570, 9], [53, 38, 3, 94, 2, 77, 125, 50, 25, 3, 14, 13, 1, 394, 3, 63, 2788, 82, 5, 34, 3, 46, 110, 223, 58, 254, 1821], [53, 18, 8571, 798, 46, 542, 21, 581, 233, 3, 41, 667, 89, 1, 35, 581, 7325, 1587, 1821, 18395, 30, 25, 128], [53, 40, 1014, 17, 7, 24, 3558, 3, 1161, 906, 1732, 315], [3, 19, 27, 32, 18396, 4624, 32, 10, 312], [3, 2898, 50, 518, 8, 592, 40, 47, 2, 9], [3, 90, 38, 1, 72, 1678, 46, 4636, 55, 200, 3, 72, 3, 47, 1174, 14, 342], [101, 183, 77, 63, 3866, 322, 1, 44, 43, 402, 55], [80, 25, 118, 19, 27, 5, 291, 74, 48, 31, 36, 109, 80, 956, 5, 2, 1, 31, 5, 101, 19, 27, 80, 4010, 38, 36, 1080], [3, 745, 124, 352, 11, 1115, 188, 2, 1, 222, 471, 17, 2, 1217, 8, 278, 430, 10, 879], [37, 721, 159, 1279, 27, 7607, 8, 4058, 7, 4009, 77, 12, 422], [261, 2, 1], [10, 215, 1, 47, 18397, 510, 11, 143, 941, 238, 1454, 143, 961, 18398, 18399, 4008, 47, 292, 115, 211, 147], [296, 105, 81, 6, 18400, 18401, 1283, 27, 18402, 296, 90, 18403, 18404, 2655, 111, 38, 3, 79, 76, 18405], [6040, 228, 26, 6040, 9], [22, 1620, 189, 12, 2, 19, 285], [232, 8572, 893, 821, 18406, 420, 4543, 6, 250, 1095, 512, 3999, 8, 313, 84, 8573, 11, 4, 1398, 18407], [71, 179, 77, 192, 126, 290], [31, 42, 72, 42, 523, 2039, 308, 8, 523, 415, 5940, 545, 174, 164, 365, 1, 3614], [13, 31, 20, 2, 1, 373, 15, 8, 14, 2, 83, 34, 33, 218, 5, 41, 60, 2847, 1217, 11, 60, 175, 317, 196, 20, 18408], [3, 62, 57, 207, 10, 682, 1437, 5, 63, 139, 27, 4, 1565, 1093, 83], [38, 2598, 2599, 121, 296, 79, 2, 1, 2, 1, 2, 9, 2, 9, 2, 414, 2, 6282, 3, 724, 52, 47, 6041, 2180, 52, 47, 4479], [31, 20, 2, 9, 29, 772, 2550, 18409], [10, 639, 14, 18, 60, 56, 91, 3, 191, 50, 744, 5, 18410, 67, 60, 169, 40, 72, 6180, 23, 8574, 34, 107, 18411], [6042, 200, 22, 1, 72, 64], [2814, 2649, 269, 1306, 11, 2, 2258, 12, 4, 5950, 18412, 496, 604, 94, 22, 696, 951], [18413, 5, 113, 17, 3, 1863, 203, 1, 7, 532, 13, 18414], [2811, 114, 1895, 119, 24, 176, 20, 767, 18415, 5215], [3, 29, 19, 125, 365, 9, 32, 3, 881, 12, 18416], [26, 18417, 134, 22, 68, 6, 4, 341, 1434, 9], [34, 78, 70, 4, 5423, 2496, 6, 44, 352, 18, 4, 250, 438, 34, 40, 56, 57, 698, 16, 1436], [93, 24, 12, 13, 2, 692], [4, 863, 18418, 6712, 109, 11, 7, 9, 526], [1937, 49, 270, 2, 83], [3, 330, 62, 5, 56, 31, 14, 2292, 12, 18, 4, 1304, 16, 184, 5, 67, 11, 2, 2461, 102, 4609], [18419, 12, 10, 145], [15, 589, 38, 574, 253, 6, 18420, 13, 1, 8071, 47, 122, 6, 14, 7102], [29, 14, 2, 104, 1112, 20, 476, 38, 5, 7811, 3927, 74, 8414, 3, 41, 2, 18421, 2777, 6, 176, 870, 1034], [5406, 9, 1857, 18422], [50, 14, 1376, 427, 4, 2029, 15, 7, 2138, 7, 343, 8, 7, 1127, 4083, 40, 1389, 6, 8016, 1428, 239, 184, 329, 596], [96, 7000, 32, 16, 10, 206, 9, 4, 237], [53, 3530, 114, 22, 327, 21, 17, 3118, 463, 86, 4, 1, 276, 19, 27, 22, 6043, 53, 18423], [70, 362, 50, 815, 54, 1967, 114, 2, 327, 16, 50, 973, 18, 17, 13, 4, 234, 1, 58], [2392, 8, 15, 29, 70, 42, 2, 9, 15, 550, 6, 44, 352, 18, 250, 438, 358, 73, 4, 150, 12, 5423], [33, 2246, 53, 1678, 85, 3, 19, 80, 1664, 3, 18424, 63, 5, 72, 108, 6, 4894], [825, 1215, 2205, 159, 824, 12, 4, 884, 18425, 1575, 11, 770, 8, 15, 4, 231, 16, 305, 183, 5873, 26], [3, 262, 1, 51, 5992, 2059, 70, 36, 301, 107, 573, 1707], [65, 51, 42, 92, 42, 554, 185, 1, 55], [37, 515, 16, 78, 9, 134, 2, 1123, 54, 6, 78, 3804, 81, 133, 40, 46, 878, 43, 9], [3, 6044, 402, 6719, 646, 18426, 1190, 1, 66, 2734], [3, 64, 24], [1, 20, 144, 435, 7, 867, 198, 255, 1277, 99], [9, 14, 214, 51, 5, 149, 20, 25, 67, 5, 129, 50], [69, 41, 106, 6, 14, 4065, 384, 894, 7, 46, 1287, 43, 127], [3, 8575, 1, 27, 358, 392, 3446], [3699, 8576, 492, 123, 4, 18427, 7, 47, 648, 34, 4, 1172, 780, 27, 254], [1, 14, 300, 36, 24, 1933, 93, 4019], [71, 6, 28, 1], [3, 41, 43, 1489, 11, 1888, 703, 1263, 1, 3, 13, 10, 287, 27, 60, 30, 26, 1443, 188], [7, 45, 222, 421, 5, 142, 31, 5, 468, 2, 93, 77, 3, 380, 5, 87, 2, 89, 1, 6, 107, 224, 8, 70, 15, 35], [186, 337, 3444, 12, 2, 6045, 38, 5, 1344, 20, 98, 8577, 4, 3468, 12, 2, 1187, 247, 111, 29, 623, 1305], [5, 330, 62, 36, 61, 6, 1599, 21, 17, 585, 1, 14, 542, 6, 294, 54, 4, 676], [296, 210, 506, 10, 24, 21, 18428, 47, 18429], [32, 7, 1349, 227, 5, 1, 173, 1766], [53, 39, 1, 18430, 18431], [3, 44, 37, 239, 938, 59, 7, 352, 6142, 3, 64, 64, 64, 17, 60, 1963, 8, 31, 7, 640, 252, 1525, 15, 52, 56], [326, 3616, 326, 1, 26, 326, 27, 4, 45, 7, 164], [92, 38, 2, 1, 122, 6, 249, 4, 1882, 7, 38, 40, 28, 543, 54], [960, 888, 2, 9, 140, 40, 19, 445, 252, 66, 94, 18, 886, 60, 16, 5, 9, 44, 19, 1369, 252, 7, 29, 110, 41, 2, 886, 188], [519, 1, 365, 315, 74, 365, 243], [18432, 18433, 469, 79, 17, 2, 2691, 18434], [119, 7, 24, 82, 4, 108, 8, 1099, 268, 714, 5522], [31, 7, 24, 93, 18435, 1897, 38, 2074, 119, 254], [1362, 79, 2507, 3202, 2, 757, 30, 1590], [365, 3446, 49, 550, 31, 36, 65, 905, 34, 60, 16, 5, 1, 65, 13, 5, 152, 114, 1861, 31, 5, 5785, 99, 996], [1449, 128, 1973, 34, 23, 625, 703, 37, 1, 29, 13, 17], [247, 16, 39, 25, 61, 291, 21, 39, 9], [536, 97, 1], [100, 17, 113, 42, 1746, 1, 133, 2, 1078, 226, 6671, 3, 46, 5305, 21, 43, 24, 8, 10, 138, 46, 351], [10, 757, 4053, 178, 870, 2117], [3, 75, 304, 6, 94, 4, 154, 1260, 16, 4, 3875], [3594, 12, 2, 1], [3, 33, 29, 94, 4, 446, 11, 4691, 1606, 4, 1180, 16, 167, 4, 24, 361, 33, 21, 528, 3621, 8, 725], [15, 156, 4, 419, 9, 69, 708, 36, 46, 81, 74, 19, 357, 69, 8368, 429, 35, 554], [91, 3, 118, 14, 243, 73, 2, 203, 1, 11, 2765, 31, 3780, 28, 18436, 15, 223, 2926, 6, 61, 28, 170, 8, 151, 14, 243, 596], [37, 148, 549, 16, 7, 148, 308, 18437, 77, 65, 13, 1074, 38, 36, 1708, 107, 102, 1, 139, 308], [186, 47, 18438, 38, 25, 168, 6, 61, 11, 18, 1839, 18439, 15, 33, 3805, 175, 8, 9, 801, 36, 67, 18440], [1076, 95], [55, 18441, 136, 9], [3, 41, 60, 1613, 24, 68, 106, 8, 4, 1, 148, 1196, 124, 17, 133, 6, 7877, 124, 60, 3, 124, 6, 3469], [151, 421, 2, 1, 142, 13, 4, 24, 40, 1437], [3464, 223, 204, 147, 9, 55], [31, 5, 61, 6, 19, 18, 1651, 51, 577, 14, 2, 1125, 48, 2, 723, 2655, 213, 802, 3519, 57, 36, 41, 22, 9, 18442, 5716, 1202], [39, 1, 14, 471, 565, 34, 14, 346, 17, 2859, 132, 478, 5, 75, 14, 1877, 17], [281, 354, 649, 219, 3, 6044, 58, 2643, 496, 21, 84, 856, 738, 3, 63, 229, 5, 71, 6, 168, 18443, 8, 7, 2299], [313, 15, 35, 13, 2, 1421, 28, 7810, 11, 7, 24, 13, 2, 2217], [1, 18444, 136, 132, 2, 18445, 4426, 8, 66, 63, 48, 1800, 170, 245, 6745, 946], [32, 4, 169, 11, 4, 360, 487, 28, 5, 2, 112, 83], [90, 38, 1, 14, 1412, 7, 180, 3212, 11, 36, 1473, 45, 65, 18446, 1133], [43, 7882, 23, 18, 2, 2093, 3, 64, 2107, 769, 19, 5, 9, 119, 2, 6376], [3, 41, 9, 3, 41, 625, 9], [1292, 38, 50, 24, 165, 130, 5, 772, 15, 6, 14, 53], [3, 2053, 14, 475, 133, 43, 83], [71, 179, 77, 5515, 116, 18447, 3, 222, 345, 117, 92, 241, 10, 274, 26], [620, 1], [557, 93, 77, 13, 2, 1235, 8, 557, 9, 13, 1439], [31, 10, 386, 182, 227, 54, 315, 272, 44, 6, 28, 84, 306, 8, 100, 22, 25, 62, 57, 2, 24, 150, 13], [10, 138, 12, 79, 2362, 534, 3835, 140, 15, 156, 257, 4, 24, 562], [10, 138, 12, 79, 8375, 140, 1, 64, 15, 38, 10, 991, 3486, 18448], [10, 138, 12, 79, 342, 575, 140, 15, 57, 32, 1, 109, 2197], [10, 138, 12, 79, 8578, 140, 1, 105, 131, 8579, 10, 8580], [10, 138, 12, 79, 8578, 140, 1, 105, 67, 6, 8579, 10, 8580], [10, 138, 12, 79, 1672, 2408, 140, 1, 64, 15, 11, 126, 476, 34, 90, 15, 11, 126, 809], [57, 1045, 9, 216, 22], [10, 138, 12, 79, 8195, 18449, 140, 1, 665, 15, 230, 36, 741, 15, 2073], [10, 138, 12, 79, 1248, 675, 140, 60, 1, 28, 505, 38, 15, 568, 99, 6046], [211, 97, 77, 294, 11, 97, 967, 8, 136, 9, 21, 97, 956], [5, 9, 87, 6, 139, 472, 78, 265, 73, 3967, 8, 992, 7, 78, 18450, 161, 25, 33, 67, 6, 14, 2, 863, 920], [1, 14, 2367, 1313, 208, 1850, 313, 4, 24, 13, 36, 6034, 227, 35, 13, 36, 1727, 34, 75, 433, 4513, 378], [890, 524, 1912, 8063, 822, 16, 3334, 27, 22, 282], [1602, 8, 319], [15, 2, 8415, 63, 3, 107, 18451, 101, 31, 7, 1, 18452], [1723, 379, 72, 7, 637, 6, 18453, 783, 16, 169, 194, 4773, 8, 754, 220, 3318, 82, 84, 331, 215, 312], [1123, 54, 6, 4, 1, 86, 126, 520, 12, 334, 140, 155, 106, 5, 536, 126, 310, 15, 72, 18454, 3655, 188], [268, 89, 1, 134, 17, 235, 51, 4, 199, 1301, 8142, 55, 26, 3493], [1, 42, 132, 1812, 6, 22, 21, 201, 213, 695], [69, 12, 40, 151, 290, 50, 5494, 88, 22, 1, 11, 10, 521, 131, 2159, 10, 2569, 102, 18455, 18456], [38, 2, 1, 1088, 18, 10, 25, 327, 13, 2080, 37, 4843, 3, 410, 240, 1887, 1857, 108, 8, 14, 13, 18457], [101, 1, 657, 135, 12, 4, 68, 23, 18458], [66, 32, 87, 6, 14, 18459, 116, 12, 1628, 127, 61, 18, 11, 22, 360, 130, 78, 4774, 30, 279, 6, 62, 1261], [26, 66, 592, 20, 646, 159, 54, 197, 18, 4, 2417, 225], [22, 33, 11, 232, 1145, 1486, 4127, 12, 18460, 82, 178, 211, 18461, 592, 18, 84, 833, 26], [3975, 3084, 27, 875, 18, 4, 1650, 1117, 4, 848, 21, 4, 8581, 466, 178, 12, 1469, 18462], [8582, 1201, 449, 11, 18463, 404, 2, 178, 7, 1559, 13, 2, 18464, 18465, 3347, 18466, 922, 166, 8, 468, 236], [31, 20, 412, 12, 56], [18467, 8, 18468], [8583, 6, 18469, 160, 3676, 18470, 1650, 134, 2696, 4, 18471, 18472, 885, 137, 18473, 8584], [18474, 2453, 18475, 656, 35, 4, 56, 11, 580, 16, 4, 4083, 1469, 4, 178, 21, 4, 27, 18476, 440, 11, 6982], [42, 1, 222, 1161, 28, 170, 6, 303, 32, 384, 18477, 1156, 125, 17], [135, 71, 20, 18478, 137, 54, 529, 136, 212, 158, 139, 1275, 922, 166, 25, 4, 450], [139, 4001, 35, 39, 1321, 30, 1], [583, 4, 185, 158, 11, 1103, 109, 510, 54, 116], [603, 18479, 1856, 73, 98, 206, 18480, 266, 28, 5, 24, 4883, 1270, 257, 254], [204, 1430], [2523, 1005, 8, 4756, 32, 2379, 71, 277, 508, 2201, 16, 215, 507, 150, 1753, 18481], [502, 943, 38, 4, 1186, 424, 389, 311, 7, 204, 4, 3983, 113, 4, 19, 910, 21, 469], [39, 595, 1, 49, 700, 18482, 8, 1165, 3295, 36, 343, 6, 43, 1764, 1674, 117, 2704], [159, 2244, 8138, 184, 66, 442, 11, 49, 3381, 148, 18483], [3, 375, 137, 4, 7257, 445, 1510, 27, 26, 4, 24, 1056, 32, 18484, 461, 307, 19, 1167], [19, 2, 25, 8, 2, 1], [31, 5, 13, 8585, 8586, 5182, 8587, 5181, 3226, 18485, 3931, 18486, 18487, 18488, 8588, 18489, 4805, 5180, 18490, 426, 6047, 18491, 18492, 6048, 18493, 3931, 18494, 1793, 1561], [31, 2, 1, 72, 23, 18495, 40, 2, 18496, 1176, 1], [3, 67, 2, 866, 1421, 8, 24], [456, 48, 623, 71, 209, 178, 196, 6, 32, 16, 263, 18497, 4, 137, 7236, 178, 2, 1608, 8385], [25, 81, 127, 130, 1, 39, 2124], [19, 7, 968, 2952, 5410, 7151, 157, 170, 11, 2691, 3374, 19, 84, 30, 70, 170, 2792], [22, 12, 71, 5, 2552, 3822, 7469], [4094, 24, 12, 4, 237, 24], [60, 1, 14, 1646, 21, 4, 115, 5, 338, 20, 2400], [2621, 505, 18498, 311, 4, 3488, 3759, 385, 247, 16, 4, 287, 175, 59, 15, 376, 771, 155, 312], [37, 383, 29, 14, 1148, 1027, 42, 105, 636, 57, 20, 1, 58, 128], [52, 912, 2, 1, 163, 694, 139, 821, 1292], [3, 134, 2, 2204, 6, 39, 1, 2739, 36, 18499, 99], [1, 42, 2891, 2150, 238, 14, 2, 9, 2287, 2, 43, 1865, 1142, 229, 1357, 26], [58, 391, 438, 166, 391, 74, 12, 7, 45, 315, 6, 78], [3, 64, 10, 5379, 2709, 99, 209, 6, 936, 15, 18, 2, 1, 27, 43, 343], [3, 139, 279, 59, 3059, 38, 3, 1649, 391, 162, 28, 2603, 230, 17], [267, 5, 4097, 21, 114, 54, 4, 2563, 24, 3, 64, 15], [37, 52, 144, 8, 18500, 57, 2, 1223], [66, 47, 255, 752, 59, 2, 449, 18501, 1712, 1071, 97, 3368, 149, 15, 2033, 9, 2033, 9, 26], [245, 418, 7, 28, 11, 2, 290, 211, 4, 1247, 899, 12, 2, 9], [21, 155, 89, 1, 116, 12, 2, 25, 69, 557, 76, 13, 45, 26, 478, 36, 18502, 3, 131, 188], [738, 73, 20, 77, 94, 25, 3949, 3892, 18, 1, 30, 40, 198, 67, 6, 338], [5, 1870, 2, 9, 31, 495, 79, 5, 1155], [682, 2454, 109, 47, 4, 215, 2098, 21, 4129, 4701, 474, 499, 12, 716, 56, 615], [627, 20, 1413, 1851, 18503, 159, 115, 2081, 6, 14, 1943, 8, 2660, 11, 225, 18504, 26], [371, 5, 487, 176, 10, 138, 5751, 20, 476, 51, 577, 176, 10, 226, 54, 16, 254, 78, 60, 9, 21, 1798], [3, 63, 175, 59, 119, 60, 24, 34, 4, 1029, 2, 414, 175, 59, 249, 1270, 40, 2, 9, 659, 709], [631, 24, 12, 4, 237, 24], [186, 134, 1, 18505, 1535, 16, 57, 2, 575, 12, 152, 2305, 31, 78, 3866, 22, 25, 46, 1506, 6], [57, 4, 19, 7158, 268, 95, 27, 68, 18506, 26], [8589, 846, 16, 1059, 4012, 8, 3404, 4743, 160, 154, 1648, 232, 18507, 335], [78, 25, 46, 702, 1000, 78, 109, 14, 1506, 51, 39, 1, 18, 135, 88, 38, 36, 1189, 42, 42, 208, 13, 42, 47, 137], [74, 995, 447, 3, 41, 180, 402, 55, 23, 2, 180, 1, 3543, 55, 23, 48, 276, 44, 969, 402], [1064, 697, 115, 11, 6037, 2192, 54, 8023, 14, 2, 353, 51, 18508, 390, 8406], [3, 301, 10, 915, 1048, 17, 2, 347, 4038, 111, 1, 59, 48, 28, 57, 347, 36, 67, 38, 36, 67, 15, 8, 15, 351], [189, 69, 175, 45, 6, 28, 2, 666, 16, 443, 49, 18, 4, 199, 822, 73, 9], [243, 923, 82, 825, 1297, 18509, 18510, 8, 159, 3138, 647, 513, 281, 991, 326, 26], [31, 6653, 124, 2, 285, 7, 57, 3, 65, 13, 11, 4, 2428], [3194, 2887, 12, 248, 1604, 248], [5766, 451, 12, 56, 483, 8, 589], [4111, 1], [65, 51, 32, 4, 418, 253, 8, 113, 17, 52, 46, 41, 319], [3, 33, 131, 654, 21, 4, 1665, 7, 3, 29, 44, 245, 319, 160], [18511, 10, 19, 226, 18, 5, 100, 240, 62, 5, 64, 4, 177, 18512, 3, 454, 71, 239, 1, 216, 2, 2638, 7, 1608], [38, 4, 25, 27, 4, 3196, 2652, 868, 60, 56, 2355], [2, 705, 3245, 18, 4, 95, 8, 4, 1578, 4, 95, 49, 8590, 18513, 18514, 4, 1578, 49, 18515, 18516, 8484], [53, 40, 136, 2031, 26, 12, 96, 204, 470, 5, 9, 53, 383, 218, 5, 44, 2031, 29, 8591], [2051, 51, 13, 5, 70, 4, 18517, 13, 43, 1, 3, 29], [2, 320, 16, 1, 13, 6, 7991, 34, 48, 27, 1946, 36, 157, 126, 1393, 150, 8, 548, 18, 4, 2658], [488, 20, 24, 48, 7, 93, 31, 546, 25, 124, 15, 34, 553, 16, 76, 49, 96, 27, 42], [31, 5, 62, 80, 24, 532, 13, 989, 85, 364, 118, 5, 400, 116, 98, 100, 2, 25, 714, 5, 1, 44, 43, 1898, 720], [435, 614, 6, 1273, 7, 36, 77, 65, 13, 2, 864, 16, 45, 27, 43, 1631, 34, 2, 183, 25, 63, 28, 2, 65, 55, 422, 1], [60, 9, 65, 165, 461, 36, 830, 18518], [85, 46, 43, 419, 1544, 28, 301, 2, 243, 639, 115, 13, 78, 58, 39, 1, 18, 1544, 115], [326, 64, 3194, 2887, 149, 7, 1039, 19, 102, 6485, 147, 10, 83], [408, 49, 2951, 6, 563, 35, 51, 5506, 8592, 18, 18519, 410, 18520, 6, 56, 81, 8, 18521, 1914, 18522, 14, 2513, 255], [57, 93, 1, 647], [418, 304, 1062, 126, 343, 12, 32, 2085, 142, 6, 61, 905, 11, 126, 954, 34, 1, 59, 4, 379, 3324, 3269, 82, 1809], [191, 18523, 4068, 85, 4, 2192, 12, 1343, 50, 1257, 6248, 116, 1578, 11, 18524], [89, 1, 12, 4, 101, 184, 7, 3, 13], [3, 86, 3, 41, 143, 95, 2094], [18525, 337, 18526, 482, 47, 50, 24, 93, 17, 69, 482, 241, 105, 453], [1, 29, 357, 279], [773, 1], [33, 18527, 6, 10, 9, 69, 23, 1122, 250, 657, 21, 1354, 658], [2647, 89, 1], [38, 5, 61, 539, 50, 310, 8, 258, 54, 40, 2, 9], [78, 66, 168, 6, 44, 6, 114, 406, 18, 112, 1651, 8, 2885, 76, 9, 539, 4, 5981, 583], [31, 2, 1, 81, 45, 6, 17, 23, 152, 735, 10, 3845, 8, 6709, 50, 1256, 102], [31, 5, 28, 1001, 123, 175, 20, 2, 1], [7, 1, 12, 537], [4, 101, 77, 7, 279, 59, 14, 2, 189, 3105, 49, 9], [38, 2, 1, 72, 20, 291], [78, 203, 1, 27, 969, 815, 65, 13, 2799, 18528], [515, 16, 141, 1, 780, 27, 20, 3041, 28, 20, 373, 3043, 18529], [18530, 3, 210, 196, 6, 313, 20, 1523, 11, 4, 56, 3718, 3118], [31, 5, 708, 4730, 12, 20, 443, 992, 23, 560, 1233, 5, 194, 4, 3732, 18, 20, 351, 106, 104], [1963, 37, 818, 6, 14, 2, 9], [38, 5, 70, 2, 257, 27, 2, 3936, 11, 521, 8, 4, 826, 72, 7534, 70, 7, 56, 30, 257, 8, 151, 1332, 1323, 2208], [3777, 136, 129, 349, 136, 343, 119, 50, 24, 735, 50, 30], [3, 1061, 90, 287, 69, 1, 26, 733, 59, 2, 25, 137, 496, 178, 38, 52, 96, 70, 106, 21, 18531], [275, 72, 4065, 2, 930, 2826, 26, 36, 150, 13, 36, 157, 2, 1731, 11, 80, 235], [101, 193, 3, 67, 2, 275, 6, 1112, 35, 31, 3, 13, 50, 4, 763, 16, 5, 9, 3, 67, 6, 94, 470, 927, 327, 18, 4, 909], [5, 63, 14, 2, 93, 77, 32, 5, 67, 8, 212, 9, 96, 152, 28, 263, 25, 701, 82, 106, 6, 106], [33, 62, 42, 63, 96, 61, 54, 8, 558, 60, 1, 12, 93, 602, 21, 3651, 4, 18532, 7, 107, 27, 558, 18533], [1, 5, 626, 6, 100, 15, 102, 80, 803, 407, 43, 4243, 80, 779, 124, 127, 548, 130, 97, 803, 1, 809], [495, 113, 39, 291, 1, 271, 11, 36, 507], [243, 457, 104], [18534, 2221, 6, 608, 1328, 231, 164, 1355, 11, 1616, 348, 1548, 18535, 251, 48, 21, 2, 348], [89, 1, 18536, 176, 15, 3897, 78, 62, 78, 75, 19, 18537], [38, 4, 1810, 387, 1, 47, 238, 157, 35, 2, 580, 27, 17], [3511, 69, 18538, 101, 104, 72, 60, 24, 45, 13, 7, 3, 5248], [3, 209, 2689, 22, 1621, 759, 8, 190, 2423, 2134, 6, 393, 2948, 297, 371, 7, 1579, 1608, 48, 110, 637], [3, 46, 105, 124, 2, 339, 812, 105, 103], [3, 44, 43, 9], [1033, 6, 842, 4286, 18539, 73, 503, 1222, 16, 862, 159, 1186, 6035, 18540, 3022, 440, 32, 11, 596, 717], [1386, 124, 2, 2263, 949, 47, 156, 93, 6, 61, 141, 881, 16, 1602, 91, 8, 40, 18541, 6, 2325], [336, 66, 96, 562, 32, 4, 1165, 517, 1, 1922, 478, 74, 336, 1171, 66, 2473], [33, 1131, 2, 1149, 129, 8404, 235, 140, 52, 2, 187], [38, 5, 405, 32, 20, 9, 21, 68, 395, 8, 78, 29, 450, 35, 612], [18542, 20, 1], [39, 9, 28, 472, 35, 73, 9, 21, 923, 33, 6, 58, 57, 36, 156, 58, 155, 166, 1477], [741, 6, 2702, 711, 20, 1056], [504, 903, 2435, 1982, 236, 903, 60, 1091, 1982, 29, 468, 20, 2435, 24, 238, 28, 60, 1091, 24, 26, 450, 35, 27, 43, 1145], [601, 275, 49, 33, 19, 144, 1669, 3, 300, 3, 33, 67, 6, 543, 78, 11, 4, 8593], [22, 391, 12, 1071, 2, 402, 16, 2337], [245, 323, 27, 1655, 11, 15, 12, 56], [3730, 18543, 250, 1120, 6, 14, 1251, 11, 775, 27, 2, 5607, 8, 2, 120, 83, 8594, 1188], [155, 8595, 18544, 3107, 12, 56, 78, 64, 702, 7667, 3687], [9, 64, 1459, 166, 9, 18, 186], [3, 394, 15, 2714, 130, 7, 85, 58, 5, 86, 32, 287, 49, 9, 48, 32, 16, 263, 49, 319, 26], [128, 5, 146, 497, 5, 1, 96, 203], [4, 489, 2040, 175, 993, 246, 25, 1, 215, 1477, 55, 1875, 18545, 5, 4, 175, 26, 6049, 7, 596], [38, 5, 400, 142, 8, 623, 5, 109, 29, 41, 1], [7842, 1014, 2, 2340, 460, 8, 2503, 1286, 27, 18546, 84, 508, 1405, 16, 313, 7, 460, 47, 6, 19, 1, 54, 116], [20, 77, 9, 228, 152, 1069, 50, 6, 359, 18, 350, 2, 1888, 25, 27, 2763, 192, 2863, 18, 50, 11, 4, 489, 26, 36], [29, 308, 6, 17, 1, 23, 134, 5, 10, 548], [268, 9, 687, 133, 69, 19, 69, 21, 2299, 3751, 16, 169, 55, 57], [211, 42, 714, 98, 668, 1], [526, 5, 373, 2, 3313, 2751, 1], [38, 5, 1144, 675, 18, 20, 228, 11, 4, 1, 114, 15, 6, 6046], [38, 3, 309, 18, 567, 95], [211, 39, 229, 78, 1, 18547, 163, 454, 42, 3, 72, 717, 184, 3, 72], [552, 69, 502, 7, 1, 10, 226, 552, 69, 502, 7, 1, 10, 226, 74, 518, 2733, 2216, 6050], [4, 215, 1, 3, 19, 47, 2, 1223, 1871], [1, 66, 18548, 19, 69, 29, 13, 3, 29, 13], [202, 24, 1093, 17, 16, 2313, 990, 120, 24, 1093, 17, 16, 3063, 8, 1223, 77, 24, 1093, 17, 16, 1232, 18549], [124, 6, 572, 84, 1, 30], [3, 454, 31, 6692, 276, 14, 214, 3, 424, 36, 1], [23, 33, 72, 51, 68, 446, 11, 10, 164, 18550, 424, 8, 1354, 10, 1, 2, 213, 790, 3, 19, 84], [301, 3, 222, 28, 551, 5547, 34, 10, 9, 30, 7841, 1492, 549, 8, 4, 166, 68, 440], [221, 52, 2, 1], [8, 52, 96, 266, 28, 43, 1, 53, 583, 369, 2582], [31, 3, 41, 4222, 8, 10, 77, 41, 8454, 88, 3, 96, 41, 4222, 149, 7, 1, 198, 44, 2, 3629], [60, 16, 78, 1, 75, 110, 632, 22, 18, 80, 148, 235], [274, 148, 7, 68, 3976, 83], [1615, 2268, 2665, 248, 26], [3, 90, 18551, 8308, 5101, 7, 202, 435, 49, 3605, 74, 18552, 202, 287, 49, 179, 8, 18553, 6, 965], [234, 9, 403, 22, 12, 10, 520, 17], [55, 25, 101, 208, 417, 38, 36, 86, 24, 12, 4, 5051], [1824, 592, 54, 5, 75, 79, 18554, 2, 4817, 172, 2607, 13, 5, 63, 596, 7624], [38, 482, 290, 20, 234, 9, 26, 404], [3, 64, 10, 504, 40, 14, 45, 18, 78, 319], [2219, 7455, 121, 4760, 25, 119, 517, 112, 25, 333, 36, 1, 432, 28, 18555], [3, 3449, 76, 441, 435, 7, 1236, 42, 2, 535, 106, 88, 2589, 2177, 1997, 97, 13, 148, 24, 5, 238, 137, 2, 6465], [23, 238, 366, 60, 961, 11, 7, 1, 55], [3, 33, 67, 4, 169, 2859, 1070, 18, 39, 9], [380, 69, 18556, 80, 1], [101, 11, 49, 408, 61, 6, 1, 59, 2, 665, 54, 404, 22, 2501], [3, 150, 13, 196, 77, 49, 4, 101, 109, 109, 334, 5987, 1416, 258, 17, 2, 1, 7, 505, 10, 150, 55], [773, 51, 577, 7, 1, 341, 874, 128], [29, 81, 747, 10, 108, 3, 90, 7, 24, 45], [3, 19, 20, 1, 2, 1612, 106, 57, 4, 19, 20, 1, 41, 18, 50, 453, 10, 172, 8596], [2207, 5792, 7, 1], [113, 39, 9, 7, 36, 146, 3057, 35, 68, 921], [38, 2, 179, 77, 122, 6, 509, 11, 521, 18557, 26, 805], [2321, 276, 4737, 6015, 34, 22, 2333, 12, 89], [39, 1105, 49, 172, 144], [18558, 355, 4052, 49, 18559, 5, 46, 152, 62, 38, 80, 1, 503, 4, 1790], [18560, 7, 4, 177, 103, 14, 2160, 224, 4, 360, 21, 18561, 2160, 8, 15, 103, 450, 11, 4, 18562, 73, 2, 1073, 236], [5, 44, 2, 504, 139, 191, 39, 9, 6, 14, 20, 18563], [5, 63, 14, 703, 8, 96, 14, 183, 139, 208, 13, 14, 4537, 12, 681, 171, 1, 26], [93, 115, 27, 39, 201, 1], [27, 581, 1, 1327], [856, 269, 856], [18564, 2190, 121, 3, 47, 315, 8, 1995, 47, 2, 2986, 4733, 50, 989, 47, 43, 5694, 94, 8597, 8, 2925, 18565], [33, 146, 1093, 482, 5, 41, 43, 9, 26], [31, 3, 47, 2, 503, 8598, 4140, 3, 118, 5696, 2347, 7, 4, 446, 16, 10, 2160, 12, 6, 44, 352, 8438, 832, 1, 16, 922, 18566], [4, 231, 5, 70, 38, 5, 94, 2, 9, 122, 6, 2892, 18, 186], [1801, 6, 5, 5, 185, 83], [1613, 1, 345, 36, 46, 41, 43, 18567, 1, 485, 5, 1419, 509, 60, 16, 76, 5343, 7863, 18568, 80], [369, 200, 22, 1, 58], [1, 5, 380, 15], [1678, 85, 20, 37, 93, 51, 22, 1537, 149, 42, 400, 18, 20, 4013, 158, 30, 137, 32, 18569], [1416, 70, 362, 3, 41, 22, 1777, 73, 93, 73, 4, 24, 12, 23, 614, 6, 349, 54, 38, 3, 912, 25, 2034], [1140, 1154, 3, 2836, 2, 395, 469, 11, 4683, 2782, 8, 52, 121, 3, 2836, 13, 2, 158], [916, 4, 2426, 3939, 2107, 125, 4, 5826, 353, 205], [296, 19, 20, 1, 149, 40, 502, 17, 2, 4699, 40, 363, 142, 1547, 13, 18570, 18571], [42, 318, 14, 2, 104, 31, 42, 349, 459, 4, 24, 6, 912, 1669], [9, 14, 28, 1394, 88, 420, 6, 166, 620, 469, 326, 258, 54, 36, 2, 9, 649], [247, 575, 450, 140, 1, 131, 114, 2068, 82, 126, 1045, 30, 419, 228], [8469, 41, 60, 183, 9, 221, 8, 76, 8470, 3686, 1607, 46, 70, 43, 2058, 8471, 16, 240, 5121], [3, 70, 4, 24, 18572], [31, 1, 49, 640, 34, 5, 7485], [33, 140, 5, 8384, 18573, 317, 196, 5, 63, 208, 13, 983, 56, 8, 14, 351, 82, 208, 13, 2, 2576, 1044, 14], [3, 300, 7, 2200, 63, 48, 8599, 34, 3, 64, 50, 764, 4229], [7, 9, 18574, 41, 4, 172, 1203], [7, 9, 46, 45], [22, 9, 300, 6, 274, 7, 177, 172, 18575], [23, 2, 675, 44, 9, 46, 45, 23, 33, 65, 21, 4, 250, 77, 3, 64, 38, 23, 11, 39, 283, 7], [44, 9, 501, 634, 5, 468, 7, 77, 7, 5, 109, 67, 129, 76, 9, 233], [3, 150, 13, 43, 690, 71, 209, 16, 2, 9, 40, 12, 31, 4, 117, 25, 157, 50, 11, 50, 507, 40, 223, 396, 26], [7, 8600, 629, 65, 13, 56, 15, 109, 1639], [2, 77, 175, 463, 318, 14, 179, 31, 42, 316, 522, 82, 619, 173, 4, 3099, 43, 42, 318, 14, 185, 31, 42, 389, 3100, 972], [2041, 296, 1851, 244, 18576, 324, 2254, 57, 11, 18577, 522, 18578, 18579, 5, 29, 7852, 82, 17, 27, 2812], [18580, 4692, 1, 58, 165, 8, 139, 14, 37, 185, 149, 78, 9, 49, 185, 130, 97, 18581], [432, 13, 1, 7, 58, 2274, 45, 33, 14, 344, 35, 579, 100, 17, 62, 1287], [3, 72, 31, 2, 77, 41, 1212, 481, 74, 127, 8, 40, 787, 74, 3984, 40, 2, 9, 22, 68, 48, 35, 21, 1726], [737, 2, 83, 1, 64, 402, 2645, 18, 126, 809], [41, 2, 89, 30, 1, 33, 1846, 18, 10, 138], [43, 68, 273, 17, 4, 2388, 12, 4, 884, 507, 6, 14, 2, 1, 122, 6, 28, 32, 1393, 18582, 1059], [871, 14, 13, 6051, 7353, 1183, 263, 18583, 6051, 3339, 1183, 18584, 6051, 95, 1183, 18585, 18586, 18587], [66, 75, 438, 31, 20, 61, 6, 14, 2, 141, 1, 59, 474], [225, 4, 115, 1, 100, 227, 364, 35, 26], [53, 432, 13, 170, 52, 589, 3, 3430, 52, 62, 3, 29, 3182, 7, 25, 2, 8601, 181, 18, 3917], [15, 132, 19, 1, 34, 2, 1235, 63, 28, 10, 106], [57, 3, 62, 5, 608, 204, 260, 382, 4, 2848, 1705, 20, 193, 173, 3582, 88, 4677, 20, 5599, 26, 18588], [232, 18589, 681, 1098, 891, 3254, 11, 8594, 731], [333, 1, 23, 2, 18590, 2251], [180, 517, 1, 180, 517, 1, 4960], [4, 193, 18591, 208, 12, 33, 7961, 18592, 16, 76, 49, 1830, 3188, 4011, 177, 2989, 1064, 18593, 936], [8, 272, 176, 6052, 13, 3, 64, 22, 1], [1], [84, 236, 84, 236, 15, 102, 6, 197, 66, 61, 15, 18594, 2, 2388, 1947, 1185, 26], [19, 1995, 18595, 7, 269, 317, 1642, 11, 4, 120, 331], [19, 718, 4701, 7392, 1202, 12, 162, 15, 3916], [3, 41, 167, 18, 225, 23, 108, 1, 18596], [583, 8, 66, 299, 66, 220, 4, 101, 68, 27, 2, 6673, 18597], [1656, 18598, 2056, 18599, 37, 209, 21, 39, 354, 8204, 466, 18600, 26], [6042, 4, 8285, 16, 22, 18601, 12, 18602], [22, 1, 59, 6, 28, 3009, 1558, 526], [31, 5, 86, 186, 198, 396, 4, 95, 3468, 6, 2, 2188, 1582, 1935], [863, 42, 29, 61, 619, 174, 1686, 132, 18, 392, 21, 201, 707, 42, 2733, 685, 269], [4, 372, 16, 631, 24, 3198], [155, 4015, 12, 2, 1245, 4015, 31, 20, 48, 2, 285], [38, 9, 81, 45, 59, 166, 1928, 151, 33, 338, 22, 1184], [141, 25, 64, 70, 126, 504, 65, 185, 1182, 166, 1, 8, 37, 18, 2, 112, 25, 118, 105], [3, 41, 952, 857, 23, 27, 60, 275, 228, 69, 29, 62, 7, 23, 1191, 6, 76, 73, 283], [1335, 286, 447, 80, 1, 182, 41, 54], [1335, 1, 2462, 133, 3, 87, 10, 538], [1335, 42, 3049, 34, 367, 277, 1, 466, 54, 1144, 341, 381, 11, 147, 1], [325, 1, 131, 366, 32, 305, 441], [2987, 24, 12, 24, 7, 70, 5, 109, 86, 133, 70, 50, 1418, 24, 7, 70, 5, 86, 59, 14, 2, 18603], [31, 40, 834, 8, 5, 28, 50, 554, 40, 152, 671, 203, 8, 5, 152, 14, 4, 25, 27, 4, 180, 1], [243, 457, 3085, 18604, 4, 18605, 2112, 227, 5125, 225, 26], [18606, 2, 5733, 1], [8602, 2929, 1609, 2182, 6, 111, 79, 170, 98, 674, 18607], [19, 1, 313, 593], [50, 24, 3160, 31, 40, 63, 1083, 129, 1313, 1971, 1083], [78, 37, 56], [5, 144, 31, 5, 72, 18608, 29, 61, 4500], [4, 1747, 723, 140, 32, 4, 9, 54, 117, 92, 415, 28, 19, 74, 893, 99], [155, 106, 1364, 1, 107, 18], [869, 174, 1, 74, 499], [18609, 25, 18610, 121, 18611, 9], [43, 352, 1, 3, 101, 67, 4, 2609, 1, 18612], [24, 177, 29, 67, 1317], [1655, 168, 6, 14, 93, 230, 52, 41, 173, 22, 1008, 181, 45], [97, 24, 1116], [367, 1963, 1, 80, 171, 30, 41, 137], [3641, 9], [3, 105, 704, 2, 18613, 1], [116, 2, 511, 808, 2, 659, 8, 2, 836, 2, 659, 103, 376, 27, 3721, 2, 1, 103, 376, 27, 18614, 34, 693], [3, 109, 90, 701, 5233, 319, 293, 36, 32, 309], [5, 2, 9, 31, 5, 134, 20, 518, 6, 246, 25, 288, 5, 41, 2, 91], [78, 14, 138, 498, 8, 3267, 39, 9, 7, 85, 470, 16, 2133, 150, 13, 36, 5969, 102, 22, 685, 871, 45], [5, 9, 131, 175, 8, 81, 59, 1805, 88, 293, 2288, 165, 105, 94, 50, 730, 18615, 61, 6, 3259, 8, 105], [19, 4, 703, 1, 11, 4, 489, 160], [36, 49, 398, 283], [3, 29, 110, 998, 10, 18616, 15, 12, 57, 15, 12, 1], [10, 306, 1135, 8383, 6, 555, 22, 269, 26, 65, 57, 52, 200], [22, 257, 655, 4793, 2, 89, 1, 26, 2, 558, 16, 7352, 4, 1084, 8007], [3, 90, 1, 69, 14, 528, 27, 36, 5366, 7, 45, 12, 939, 73, 19, 6, 18617, 13, 1112, 20, 476, 282], [10, 1147, 1, 176, 50, 30, 35, 8, 231, 142], [10, 3471, 1, 91, 3, 46, 110, 167, 15, 478, 33, 714, 429, 50, 24, 33, 6, 400, 8, 28, 4, 2538, 631], [23, 2, 1078, 205, 43, 5499, 9], [4, 488, 7, 32, 78, 9, 525, 554, 125, 43, 1013, 18, 97, 714], [23, 2, 18618, 236, 8, 2, 2639], [38, 36, 298, 54, 16, 138, 1077, 4, 285, 71, 58, 344, 252, 62, 31, 126, 138, 12, 969], [31, 3, 222, 14, 2978, 18, 1681, 117, 92, 5, 62, 15, 118, 14, 232, 1330], [31, 5, 458, 2, 828, 8, 29, 1056, 15, 5, 49, 57, 12, 1370, 73, 2, 141, 1], [1094, 8231, 2769, 6053, 906, 51, 6005, 1599, 949, 35], [124, 6, 547, 10, 18619, 420, 1], [1436], [2443, 1616, 18620, 12, 4, 654, 18621, 2261, 16, 24, 6535], [3088, 4908, 213, 206, 8, 96, 1459, 1541], [39, 9, 14, 208, 2360, 26, 5, 62, 57, 571, 100, 6223], [154, 213, 4017, 1, 14, 13, 188, 26], [217, 69, 708, 374, 2, 89, 1, 982, 28, 1001, 37, 7992], [71, 3, 119, 4, 24], [39, 9, 46, 334], [800, 31, 5, 94, 4, 1187], [1], [18, 22, 115, 18622, 4, 852, 8603, 568, 984, 21, 292, 27, 2, 294, 1259, 2886, 6, 450, 84, 6298, 178, 167, 6054], [6050, 12, 2, 181], [3730, 8, 18623, 28, 43, 24, 37, 3, 29, 62, 85, 36, 156, 81, 59, 7, 385, 5912, 105, 1041, 621, 77, 18624], [1017, 80, 1], [29, 302, 9, 36, 46, 334], [55, 443, 493, 205, 4842, 5, 72, 43, 6, 590, 24, 2263, 1137, 5893], [3510, 887, 188, 70, 4166, 78, 146, 632, 562, 522, 8, 352, 61, 402, 163, 3913], [834, 355, 1006, 11, 1907, 74, 336], [61, 73, 8041, 21, 923, 128, 183, 1], [15, 568, 82, 18625, 6, 4580, 53, 3, 64, 1323, 6, 53, 19, 5, 3, 90, 1323, 53, 3, 87, 1323, 6, 53, 19, 2235, 82, 53, 20, 10, 4017], [10, 455, 1, 26, 10, 234, 1, 214, 410, 17, 3, 222, 123, 134, 201, 19], [18626, 39, 1], [4439, 18627, 26, 4, 763, 16, 39, 24, 165, 934, 22, 108, 8604, 3168, 103, 14, 295, 34, 18628, 18629, 8], [7587, 991, 682, 25, 19, 165, 130, 480, 682, 8605, 4, 2146, 11, 4, 1, 231, 26], [53, 39, 9, 28, 554, 33, 6, 157, 60, 45, 13, 18630, 18631, 11, 36, 798, 1618], [425, 369, 25, 18, 135, 109, 144, 26, 23, 364, 54], [31, 2, 9, 12, 81, 6, 20, 91, 40, 48, 4, 437, 52, 1437, 4, 488, 7, 9, 150, 1073, 4704, 18, 71, 52, 208, 18632], [203, 1, 49, 7800], [39, 1, 791, 25, 69, 41, 164, 1355, 11, 865, 185], [128, 39, 25, 208, 13, 161, 1], [420, 147, 4020, 9, 8606, 17, 6055, 214, 18633], [2, 8607, 2311, 11, 18634, 3045, 2526, 2311, 4, 1012, 16, 1480, 524, 288, 18635, 382, 254, 26], [11, 4, 1698, 360, 6474, 857, 196, 6475, 82, 202, 4182, 15, 179, 18, 263, 8, 4207, 18, 76, 281, 26], [23, 37, 19, 328, 27, 3, 19, 90, 5, 189, 8, 20, 3380, 3547, 12, 56, 8, 526, 1986, 4, 19, 35], [28, 39, 56, 30, 25, 459, 10, 1330], [139, 253, 1983, 952, 8, 97, 266, 28, 2238], [875, 2671, 25, 26, 78, 154, 1, 18636, 147, 3417, 2271, 147, 85, 36, 176, 1042, 15], [3, 29, 1276, 18637, 364, 3, 65, 13, 555, 2, 6200, 8, 14, 2, 161, 83, 45, 3781, 604, 14, 4394], [5, 61, 108, 8, 5697, 27, 2, 77, 20, 2, 1063, 5, 100, 50, 974, 20, 2, 1063, 55], [76, 1, 700, 124, 6, 389, 1904, 947, 937, 6, 3045, 473, 691], [159, 925, 28, 15], [253, 22, 181, 15, 84, 457, 225], [22, 120, 177, 1912, 18638, 11, 567, 95, 23, 37, 328, 27, 18639], [1183, 2995, 2187, 382, 8, 2352, 245, 414, 74, 3698, 69, 1038, 48, 616, 11, 493, 27, 305, 3064, 2], [1132, 235, 8608, 18640, 18641, 1803, 3291, 2052, 11, 786, 18642], [1292, 52, 346, 4, 45, 54, 7, 9, 2585], [211, 352, 2, 1, 14, 13, 2236, 57, 49, 8609, 8, 5, 13, 18643, 915, 149, 3, 46, 349, 3217], [3, 61, 6, 114, 4, 56, 54, 8, 2, 2297, 25, 1796, 10, 148, 1439], [374, 379, 462, 5, 41, 9], [2359, 50, 284, 177, 5, 318, 48, 182, 258, 246, 1047, 48, 39, 537, 1790, 19, 460, 9, 54, 135], [1446, 1151, 18, 60, 947, 45, 2359, 50, 31, 40, 216, 5, 7, 243, 11, 68, 264, 149, 39, 9, 21, 326, 1446], [638, 81, 127, 130, 1, 39, 6018], [3, 253, 32, 16, 39, 144, 18, 186, 140, 374, 32, 2, 666, 16, 2541, 26, 3, 87, 1080, 188], [326, 41, 51, 68, 1, 18, 765, 3961, 909, 69, 41, 2, 260, 26, 15, 28, 43, 18644, 78, 19, 35, 128, 965], [234, 1, 74, 455, 1, 5, 96, 46, 4, 101, 83], [3, 64, 71, 789, 77, 44, 789, 24], [93, 24, 103, 396, 20, 1068], [1504, 808, 296, 87, 18645, 8, 757, 23, 4843], [119, 15, 27, 1778, 1749, 146, 1471, 35, 50, 24, 767, 205, 413, 6258, 1947, 24], [3, 41, 1, 98, 3, 62, 60, 18646, 19, 78], [22, 1, 12, 43, 547, 51, 32], [128, 7, 2039, 124, 17, 309, 2550, 9, 87, 6, 28, 2, 186, 55], [19, 32, 16, 1655, 1, 53, 18647, 53], [18648, 6813, 18649], [275, 14, 2367, 208, 1494, 26, 227, 35, 13, 36, 1850, 26, 313, 4, 24, 13, 36, 1727, 188, 34, 96, 75, 433, 8610], [19, 5, 1, 23, 896, 2057, 154], [31, 5, 63, 741, 68, 714, 11, 20, 24, 8, 150, 32, 445, 1842, 26, 20, 96, 926], [10, 347, 3380, 12, 56], [6, 10, 500, 7, 1, 63, 44, 350], [326, 554, 26, 5, 1, 936, 43, 106], [15, 2778, 1573, 6, 311, 147, 1, 18650, 160, 5223], [88, 52, 33, 41, 99, 5770, 26, 4, 9, 64, 2021, 82, 88, 18, 52, 216, 76, 84, 18651, 7118], [39, 9, 300, 177], [3, 150, 370, 21, 143, 275, 7, 29, 28, 57, 36, 655, 288, 39, 9, 1, 28, 557, 13, 1235], [5, 753, 17, 250, 1], [2406, 14, 270, 2, 368, 17], [1045, 186, 1, 14, 13, 3178], [32, 10, 1, 1252], [11, 293, 16, 4155, 127, 287, 1331, 458, 377, 1056, 261, 26], [2, 791, 808, 2, 91, 8, 414, 111, 18652, 18653, 57, 12, 3035, 2, 95, 82, 1603, 10, 1799, 23, 11, 2061], [2068, 1011, 21, 111, 378, 741, 402, 11, 8300, 201, 741, 402, 11, 1508, 292, 92, 5, 49, 13, 1187, 1268, 20, 3675], [1656, 1753, 4154, 31, 1044, 37, 18654, 71, 107, 36, 75, 14, 95, 241, 23, 370, 47, 7, 99, 2326, 21, 5], [3, 94, 5, 361, 210, 1575, 95, 21, 2315, 4469, 7, 2385, 3, 380, 3, 33, 114, 22, 351, 851, 21, 18655], [3, 299, 15, 47, 1234, 140, 16, 4, 372, 18, 4, 4451, 34, 15, 47, 33, 95, 4435, 82, 4, 8210], [447, 18656, 739, 18657, 18658, 20, 746, 24, 371, 8193], [159, 824, 404, 1033, 4590], [219, 328, 6, 69, 7367, 729, 18659, 5052, 190, 8, 378, 355, 1092, 37, 750, 22, 3359], [495, 28, 10, 916, 60, 24, 218, 22, 25, 29, 28, 43, 30, 37, 571, 87, 68, 16, 10, 9, 6, 1099, 11, 10, 25], [25, 290, 11, 4, 2808, 8, 374, 79, 8339, 26, 1673, 62, 71, 6, 18660, 34, 116, 2, 18661, 11, 18662, 8, 357, 3800], [105, 302, 2, 1, 69, 136, 2, 1241, 2159, 16, 2291, 1145, 1623], [7274, 1977, 3053, 18663, 382, 7341, 6344, 406], [1098, 891, 188, 2, 521, 18664, 2, 434, 18665, 2, 841, 4302, 3713, 16, 3285, 18666, 6, 14], [23, 626, 6, 468, 5, 149, 3, 62, 5, 28, 283], [32, 5, 9, 12, 96, 276, 14, 9, 2199], [8, 99, 752, 6, 19, 723, 9, 164, 99, 752, 6, 255, 723, 754], [71, 1, 71, 71, 12, 22, 422, 26], [3, 33, 3676, 18, 24, 25], [211, 4, 1247, 16, 1850, 15, 59, 1789, 1228, 1152, 893, 8, 1601, 18667, 48, 347, 754, 4724, 489], [38, 5, 3215, 72, 18668, 2, 449, 5897, 26, 1, 42, 33, 67, 6, 229, 97, 30, 251], [1409, 41, 43, 6478, 1, 12, 4, 101, 184, 7, 3, 13], [18669, 7, 1, 60, 1018, 1, 64, 18670, 160, 6056, 6057], [6042, 200, 22, 1, 72, 64, 26], [147, 179, 45, 46, 1252], [23, 6, 4, 446, 162, 151, 114, 2, 3969, 8, 48, 1, 59, 254], [3, 33, 29, 594, 4, 4389, 1890, 16, 14, 2, 9, 34, 308, 59, 254, 13, 637, 20, 645, 74, 33, 14, 59, 7, 164], [43, 7, 109, 582, 53, 69, 317, 13, 15, 38, 2, 1107, 89, 1, 167, 5, 35, 33, 6, 725], [3, 29, 538, 1573, 59, 2, 1, 149, 1004, 133, 855, 9], [3, 64, 2, 1, 125, 667, 417, 1022, 163, 767], [10, 1], [275, 103, 780, 27, 2, 189, 69, 136, 2, 504, 34, 266, 780, 27, 2, 419, 189, 149, 52, 136, 18671, 239, 894], [185, 1, 75, 806, 4, 1050], [3, 8611, 424, 22, 211, 3, 672, 2, 2297, 1, 24, 4, 166, 115], [3, 90, 114, 2, 45, 51, 775, 507, 426, 3, 150, 13, 2, 104, 38, 23, 507, 4, 3316, 1010, 18, 4, 3316, 930], [1436, 12, 19, 18672, 4513, 201, 48, 276, 547, 17, 349, 1, 4, 18673], [3816, 2, 161, 1, 22, 25, 54, 135, 856], [247, 16, 78, 275, 723, 73, 19, 88, 78, 454, 85, 25, 101, 81, 59, 1412, 352, 426, 116, 777, 499, 6, 81, 1261], [1202, 4, 101, 507, 162, 2, 1, 276, 14, 793, 4, 1879, 249, 2, 25, 138, 288, 52, 119, 1283, 27, 84, 5983], [78, 37, 705, 6, 72, 111, 18674, 18675, 1, 3, 64, 1904, 50, 3260, 50, 3898, 8, 57, 40, 397, 21], [267, 2564, 445, 257, 212, 2191, 92, 442, 3, 29, 134, 2, 19, 59, 350, 23, 3349, 1129, 283, 267, 445, 5487, 188], [154, 6, 4, 178, 34, 73, 3, 594, 15, 4, 250, 1585, 16, 1520, 12, 18676, 412, 208, 127, 13, 2, 1, 2618, 14, 2276], [18677, 56, 51, 15, 5078, 462, 31, 5, 448, 2, 406, 8, 29, 28, 51, 577, 1313, 25, 6, 443, 15, 88, 5, 965], [18678, 216, 2206, 95, 58, 2, 18679, 805], [984, 64, 21, 39, 9], [2567, 2057, 382, 1005, 18680, 21, 3812, 8612, 1842, 641, 5190, 8503, 26], [263, 1714, 3416, 664, 73, 1239, 1191, 6, 202, 111, 211, 775, 4445, 26], [2878, 240, 54, 16, 1294, 74, 33, 313, 240, 11, 4, 56, 136, 4468, 18, 4, 298, 6058, 26], [99, 239, 1148, 77, 49, 419, 8, 99, 239, 9, 49, 3073], [18681, 31, 10, 91, 46, 1512, 17, 22, 24, 857, 12, 152, 450, 35, 11, 246, 25, 2747, 5], [36, 708, 1, 76, 10, 206, 9], [963, 30, 9], [463, 146, 44, 18682, 97, 109, 87, 12, 18683, 18684, 1301, 232], [39, 9, 46, 334], [1, 124, 17, 8, 10, 347, 32, 4, 193, 19, 35, 124, 6, 3864, 2, 1, 54, 527, 1895], [39, 9, 46, 45], [1163, 24, 578, 13, 2617, 3550, 18685, 1546, 4047, 6170, 339], [76, 9, 37, 148, 417], [22, 1, 41, 2, 481, 13, 2684, 3472], [29, 359, 31, 40, 2, 142, 1], [2605, 1, 2603, 17, 5, 46, 2, 1078, 5, 2, 18686], [228, 2, 818, 18687, 163, 18688, 646, 18689, 18690, 18691, 47, 1012, 123, 377, 2054, 547, 1839, 951], [993, 1, 28, 2840, 160, 2, 443, 25, 493, 38, 2, 77, 338, 84, 30, 21, 246, 91], [463, 183, 4882, 463, 2, 9, 4882, 160, 2, 25, 69, 33, 41, 1189, 34, 266, 1273, 15], [280, 230, 9, 160, 2, 280, 27, 43, 9], [1, 175, 18692, 264, 7535, 13, 36, 200, 256, 1101, 1030, 14, 9], [695, 1, 57], [2510, 327, 16, 56, 1856, 27, 56], [42, 9, 61, 6, 1860, 22, 561, 13, 78, 407, 912, 15, 2044, 458, 21, 25, 59, 445, 755, 892], [38, 97, 234, 9, 238, 208, 35], [3, 192, 172, 27, 1, 69, 442, 474, 126, 4759, 18693, 442, 4, 1496, 4759, 36, 1679, 6916], [18694, 41, 625, 9], [18695, 34, 66, 70, 15, 8, 22, 1, 400, 18, 4, 2022, 8, 227, 18, 684, 1247, 4, 629, 8, 191, 263, 31, 220, 807, 13, 66, 652, 965], [31, 5, 1189, 17, 23, 33, 61, 6, 1233, 20, 24, 12, 56, 8, 5, 220, 58, 17, 2, 3002], [93, 561, 18696, 18697, 44, 2, 628, 16], [5, 1, 222, 105, 14, 3155, 18698, 170, 113, 5, 52, 64, 170, 60, 3155], [40, 2, 171, 1, 251], [3, 41, 332, 138, 21, 32, 2695, 283, 3, 28, 32, 36, 518, 3, 29, 79, 2695, 283, 128], [23, 304, 21, 32, 16, 5, 141, 1, 7, 1545, 59, 2514, 6, 192, 569, 35, 59, 642, 8, 84, 8613], [3321, 2188, 121, 4767, 11, 10, 1783, 21, 2, 154, 2947, 3, 380, 15, 1498, 6, 72, 52, 1597, 84, 508, 21, 2, 154, 3895], [38, 1264, 121, 296, 29, 87, 20, 24, 83, 23, 18, 10, 373, 4902], [38, 2316, 121, 296, 46, 2, 1854, 34, 29, 842, 17, 2806, 12, 4, 2466, 3082, 244, 6, 28, 887, 26], [38, 2976, 4, 3541, 121, 6059, 2, 554, 1, 8, 113, 10, 228, 3, 124, 2, 8614], [4, 843, 16, 2127, 886, 12, 70, 4148, 1, 598, 1677, 26, 18699, 112, 287, 27, 112, 18700, 173, 18701, 15, 2], [2326, 124, 17, 86, 2830, 47, 2, 89, 1], [105, 302, 2, 1, 7, 114, 705, 30, 1306], [357, 279, 1], [2, 77, 175, 463, 318, 14, 179, 31, 42, 316, 522, 82, 619, 173, 4, 3099, 43, 42, 318, 14, 185, 31, 42, 389, 3100], [14, 2, 9, 427, 2, 923, 1980], [5, 135, 93, 323, 18, 4, 2099, 34, 15, 46, 59, 1531, 15, 18702, 133, 9, 437, 204, 4415, 420, 1414], [53, 1, 146, 309, 5404, 18703, 3943], [2725, 2310, 4, 95, 5451, 91, 64, 18704, 18705, 95, 27, 18706, 18707, 2624, 305, 18708, 338, 39, 850, 2136, 4572], [5437, 17, 174, 8615, 2228, 239, 77, 58, 42, 81, 3608, 18709, 3, 174, 234, 917, 18710, 59, 17, 37, 3, 62, 15, 5956, 26], [25, 14, 13, 8616, 19, 116, 61, 4, 8617, 4775, 14, 431, 386, 8618, 91, 19, 4775, 1, 73], [38, 20, 3400, 20, 314, 1228, 11, 567, 95, 8, 309, 68, 1952, 423], [114, 54, 4, 56, 51, 264], [90, 2, 291, 1, 8, 25], [31, 169, 47, 10, 77, 278, 1509, 7, 83], [3, 79, 22, 4, 18711, 2196, 18712, 74, 2, 548, 18713, 15, 2, 26, 2], [3, 90, 38, 2676, 139, 26, 191, 31, 23, 96, 2687, 13, 367, 42, 86, 3, 41, 35, 26, 192, 1042, 1406, 27, 10, 164, 1], [31, 2, 663, 109, 13, 5, 1930, 405, 32, 126, 9, 3075, 26, 3093, 8, 1841, 101, 18, 1834], [29, 475, 59, 10, 206, 1, 74, 10, 244, 1], [5141, 7, 2, 587, 30, 1391], [18714, 19, 2301, 387, 1], [536, 15, 54, 5, 146, 2876, 3559, 26, 2, 3745, 18, 4, 1529, 16, 7, 1, 7, 431], [14, 2, 9, 196, 172, 2, 320, 16, 111, 48, 81, 6, 2, 320, 16, 111, 78, 3177, 14, 44, 45, 1223, 35], [3, 454, 31, 3, 63, 3046, 2, 1, 18715, 10, 663, 106], [53, 368, 1, 1287], [53, 5, 2247, 638, 11, 7, 1, 47, 60, 9, 18716, 18717, 3, 146, 58, 18718, 163, 45], [18719, 1, 3717, 11, 1584, 3699, 340, 337, 112, 738], [3, 75, 302, 2, 1, 3, 75, 302, 531], [38, 482, 79, 6209, 4799, 11, 20, 310, 8, 20, 234, 9, 729, 11, 2, 1745, 3369, 26, 114, 20, 18720, 26], [33, 18721, 18722, 1335, 2074, 1674, 54, 125, 10, 3269, 54, 288, 2074, 18723, 9, 82, 143, 108], [77, 472, 13, 9, 8, 454, 85, 93, 189, 652, 1252, 6, 7726], [631, 26, 1097, 24], [352, 18, 841, 438, 29, 196, 5, 2, 9, 304, 1638, 115, 266, 70, 5, 2, 436, 342, 327, 29, 196, 78, 243, 44, 2, 2003], [99, 239, 1148, 77, 49, 419, 8, 99, 239, 9, 49, 3073], [11, 126, 3734, 3233, 118, 44, 5063, 18724, 11, 378, 18, 1121, 33, 37, 209, 1288, 18725, 3233, 56, 81, 771, 118, 18726], [3, 300, 23, 2, 417, 77, 444, 5, 58, 256, 7, 633, 17, 18727, 88, 4, 1, 107, 897], [18728, 18729, 92, 14, 4407, 82, 7356, 179, 1440, 173, 18730, 347, 21, 18731, 840, 6, 18732, 989, 18733, 2562], [284, 184, 59, 4, 24, 7, 5, 198, 62, 70, 362, 42, 62, 1817], [933, 77, 49, 3641, 18734], [3142, 44, 1815, 2048, 7, 1, 58, 11, 488, 14, 1070], [39, 9, 46, 334], [3, 300, 3, 486, 127, 88, 292, 1, 756, 22, 77], [2620, 233, 3856, 18735, 22, 104, 2620], [18736, 10, 18737, 70, 20, 24, 8619], [18738, 66, 29, 64, 39, 9], [1, 30, 25, 708, 6, 14, 80, 774, 88, 28, 18, 1751, 233, 32, 1, 30, 5274, 63, 309, 981], [77, 13, 50, 70, 15, 332, 21, 4, 763, 16, 263, 26, 8, 42, 454, 85, 42, 1, 28, 1459], [32, 3, 182, 58, 12, 19, 1, 26, 914, 2396], [421, 18739, 3, 1725, 86, 59, 57, 168, 6, 14, 8, 47, 27, 6060, 1178, 8, 2, 8151], [31, 4164, 5295, 47, 470, 4, 91, 84, 803, 47, 3944, 18740, 18741, 5116, 21, 44, 84, 226, 11, 84, 2747], [22, 1, 299, 40, 222, 311, 10, 138, 102], [3, 44, 6, 1279, 27, 159, 52, 1251, 8620], [944, 8621, 2, 946, 21, 159, 3050, 12, 2, 946, 21, 1997, 8, 8622], [274, 1236, 212, 5289, 1, 96, 122, 6, 176, 18742, 3620, 8185], [1472, 10, 368, 3, 195, 18743, 3, 2975], [2794, 26, 319, 1258, 26, 18744, 31, 5, 220, 2, 8519, 5877, 18745, 118, 42, 14], [20, 144], [18746, 1708, 49, 48, 216, 21, 416, 1, 14, 65, 1765], [10, 1213, 46, 28, 7782, 478, 24], [39, 9, 103, 365, 13, 36, 109, 5814, 27, 5, 34, 14, 90, 18, 5, 1267], [3, 64, 71, 7320, 12, 18747, 18748], [85, 118, 3, 14, 11, 2, 575, 39, 9, 61, 96, 58, 76], [39, 9, 12, 593], [78, 9, 46, 2274], [4, 237, 193, 6, 2438, 2, 18749, 16, 18750, 24, 12, 6, 255, 4773, 18, 20, 1697, 18751, 560, 168, 4, 324, 1465], [162, 12, 326, 28, 22, 993, 50, 117, 11, 4, 887, 854, 82], [31, 60, 141, 19, 104, 1218, 11, 10, 522, 3, 300, 6, 274, 278, 1516, 20, 19, 1291, 102], [4228, 178, 2260, 391, 124, 6, 1606, 15], [1, 1484, 13, 5882, 18752, 211, 52, 672, 32, 4, 8416, 3793, 29, 2690, 3, 64, 350, 1188], [1, 396, 1552], [31, 3, 41, 1541, 410, 68, 16, 10, 1541, 31, 48, 2815, 26, 105, 72, 15, 361], [71, 5, 1160, 129, 60, 24, 5, 105, 124], [4973, 15, 2394, 130, 2, 1], [3, 301, 3, 118, 778, 2, 9, 26], [3, 46, 1182, 3883, 171, 1], [5, 86, 40, 1677, 145, 34, 40, 109, 590], [3, 716, 346, 18753, 3, 168, 6, 14, 1014, 147, 1, 55, 105, 11, 521, 128], [273, 10, 337, 77, 1, 5, 394, 48, 396, 18, 5075], [463, 974, 10, 18754, 1078, 491, 9, 11, 4, 8623, 21, 81, 108, 160, 18755, 1], [762, 7, 1, 931, 54, 50, 481, 55, 2534, 321, 968, 108, 98, 739, 18, 7, 1], [22, 1, 510, 6, 4, 489, 27, 2, 2085, 833, 1, 5, 686], [4003, 2, 260, 108, 1, 293, 36, 204, 170, 230, 202, 2142, 2861], [58, 3, 608, 204, 18756, 2140, 103, 3, 96, 382, 18757, 286, 367], [1679, 44, 17, 801, 51, 1, 8, 18758], [7, 1, 47, 65, 21, 393, 6, 61, 35, 50, 18759], [2311, 4816, 396, 338, 56, 18760], [773, 411, 5, 391, 541, 1, 23, 322, 362, 5, 44, 2, 1104, 138, 130, 20, 520], [66, 33, 122, 788, 98, 3989, 6, 2, 1145, 11, 325, 1, 23, 96, 54, 261, 280, 244, 449, 23, 54, 7820, 277], [33, 229, 23, 48, 137, 11, 22, 1, 68, 2784, 420, 272, 1999, 11, 22, 1], [61, 290, 641, 4, 18761, 31, 5, 3064, 56, 90, 76, 37, 209, 5, 29, 44, 4, 2138, 6, 58, 254], [642, 12, 1166, 937, 16, 1775, 2525, 692, 3880, 8, 2769, 6, 3963, 305, 458, 18762, 144], [18763, 201, 292, 445, 71, 239, 158, 49, 11, 10, 1333, 3, 18764, 20, 18765], [22, 1, 559, 211, 98, 755, 16, 197, 135, 369], [23, 11, 22, 1, 13, 2, 663], [3454, 3530, 114, 22, 327, 21, 17, 3118, 463, 86, 4, 1, 276, 19, 27, 22, 6043, 26], [2, 77, 175, 463, 318, 14, 179, 31, 42, 316, 522, 82, 619, 173, 4, 3099, 43, 42, 318, 14, 185, 31, 42, 389, 3100], [38, 3, 150, 13, 52, 1182, 39, 9, 3, 33, 616, 108, 110, 2222, 130, 230], [174, 19, 120, 56], [18766, 72, 6801, 170, 4, 179, 18767, 12, 96, 2167], [404, 7013, 27, 2, 18768, 3221, 16, 4, 232, 6, 114, 4, 1957, 11, 4, 4440], [551, 3929, 27, 10, 743, 482, 1, 1904], [1316, 44, 2, 8120, 79, 98, 18769, 347, 18770, 34, 31, 5, 861, 268, 7750, 11, 98, 684, 853, 5551, 8, 79, 15, 2, 3314], [5, 63, 382, 1995, 642, 496, 34, 4, 18771, 12, 92, 2540, 11, 493, 16, 1875, 21, 18772, 951], [66, 54, 325, 1], [2904, 220, 4690, 21, 7, 508, 1405], [60, 1, 14, 13, 584, 750, 82, 5021, 576, 9, 20, 3857, 130, 5, 86], [747, 155, 112, 1, 116, 2, 1, 30, 25, 7, 200, 50, 329, 34, 216, 50, 5225], [25, 8, 1, 146, 559, 125, 143, 169, 7463, 31, 3, 63, 914, 15, 4340, 15, 46, 602], [3, 258, 15, 1943, 71, 1670, 72, 6061, 18773, 661, 16, 6061, 368, 425], [267, 6, 1826, 2090, 21, 433, 1738, 22, 18774, 18775, 10, 508, 1841, 12, 6, 5474, 305, 18776, 6, 18777, 188], [1755, 4776, 21, 159, 1186, 18778, 8624, 616, 18779, 52, 655, 98, 2553, 21, 84, 137, 3731, 26], [43, 1, 3, 33, 29, 13, 5], [3, 72, 31, 2, 77, 41, 1212, 481, 74, 127, 8, 40, 787, 74, 3984, 40, 2, 9, 18, 1190], [15, 2, 6309, 5, 171, 19, 158], [18780, 62, 3870, 3, 33, 363, 102, 18, 84, 30, 23, 328, 27, 7, 104], [19, 1297, 122, 6, 113, 17, 18781, 177, 18782, 3, 363, 673, 45, 252], [2, 115, 790, 8, 78, 96, 4001, 1350, 56, 30, 5346], [2804, 16, 1362, 2205, 2507, 56, 81, 211, 4, 178, 776], [355, 408, 7228, 2446, 466, 28, 1750, 123, 781, 788, 95, 671, 573, 732, 2580, 26], [28, 542, 21, 4, 7678, 548, 8, 508, 18783, 27], [4322, 7, 145, 41, 625, 536, 58, 20, 1162, 18784], [148, 37, 239, 365, 25, 26, 1], [23, 626, 16, 18785, 24, 99, 93, 55], [1, 2147, 72, 40, 87, 352, 117, 92, 1, 25, 2147, 72, 52, 1917, 117, 92], [564, 252, 769, 53, 1, 680, 797, 65, 51, 22, 45, 53], [100, 2, 25, 122, 17, 122, 17, 23, 2, 19, 32, 4, 9, 11, 84, 730], [338, 4, 1, 6, 4, 1], [292, 446, 18, 2, 1, 13, 8625, 18786, 35, 11, 143, 489, 13, 8625, 18787], [3, 46, 1573, 6, 311, 7, 1, 102], [99, 239, 1, 48, 602, 1235], [63, 217, 229, 18788, 22, 175, 1, 572, 17], [18789, 4498, 162, 126, 373, 1607, 81, 56, 59, 71, 702, 16, 2, 6263, 116, 1231, 412, 12, 18790], [69, 87, 1347, 38, 5, 41, 7758], [825, 1215, 114, 18791, 16, 946, 159, 824, 114, 18792, 1215, 404, 710, 1067, 1817], [111, 87, 6, 139, 14, 1, 4949], [4, 247, 681, 287, 289, 704, 44, 2752, 931, 515, 387, 26, 2066, 18793, 4, 18794, 4, 68, 69, 62, 1261], [2, 320, 16, 39, 9, 14, 359, 18, 36, 25, 19, 166, 956, 78, 177, 165, 28, 78, 2, 112, 1, 7, 2778], [32, 7603, 9, 41, 722, 3364, 11, 8157, 3831, 25, 55, 1002, 4861], [5300, 2100, 2100, 200, 5, 51, 577, 8626, 4, 8627, 38, 5, 1014, 7, 30, 11, 2, 5157], [292, 247, 2269, 120, 111, 2271, 1121, 255, 18795, 1272, 512, 35, 261, 1375, 79, 5, 2, 158, 18, 2106], [10, 803, 273, 17, 48, 6, 438, 2, 91, 27, 1221, 402, 4615, 519, 52, 317, 58, 332, 4135, 74, 52, 2, 18796], [371, 66, 18, 4, 5825, 40, 168, 6, 156, 191, 6, 6, 94, 10, 138, 527, 18797, 1481, 147, 2682, 231, 9, 340], [4, 112, 540, 693, 40, 502, 35, 742, 47, 140, 16, 3040, 3, 79, 50, 56, 6, 50, 231, 163, 191, 21], [68, 69, 75, 176, 84, 1, 57, 698, 16, 91, 75, 18798, 731], [3, 105, 2467, 7, 31, 42, 67, 2, 1882, 18, 33, 1481, 2, 25, 369, 1], [3, 90, 39, 18799, 2301, 8628, 1, 12, 152, 450, 35, 519, 2, 391, 74, 2, 1818, 13, 155, 166, 5441], [3, 195, 2, 1172, 8629, 4, 18800], [40, 117, 5, 2238, 31, 5, 119, 4, 24, 5, 318, 73, 219, 119, 4, 809, 951], [296, 100, 581, 2827, 662, 18801, 6264, 18802, 18803, 32, 11, 581, 18804, 296, 176, 2, 2827, 8263, 18805, 2597, 1442, 51, 581, 18806], [2146, 7, 593, 49, 726], [15, 140, 5, 75, 3777, 17, 5, 75, 303, 17, 8, 5, 75, 70, 17, 173, 20, 158], [2, 18807, 3605, 2205, 2, 5668, 8458, 69, 4, 112, 18808, 135, 527], [417, 481, 820, 18, 183, 1, 12, 4, 18809], [3, 29, 279, 205, 353], [66, 258, 18810, 66, 258, 4, 9], [245, 77, 7, 81, 59, 352, 18, 685, 871, 12, 2, 9], [2707, 18811, 12, 2, 24], [2728, 39, 9], [2259, 35, 18, 7, 18812, 7, 1, 29, 70, 2, 372], [3047, 3016, 3847, 1742, 18813, 34, 1063, 12, 550, 26], [225, 200, 10, 343, 8, 18814, 52, 156, 122, 6, 70, 17, 65, 13, 2, 2319], [2033, 1, 23, 152, 719, 20, 548], [2, 2089, 1, 103, 113, 5, 474, 5, 87, 6, 465, 31, 5, 33, 8009, 40, 2023, 67, 20, 91, 40, 5463, 2], [3, 124, 39, 342, 141, 1245, 226, 21, 10, 500, 13, 30, 269, 18815, 26, 18816, 3, 33, 29, 62, 162, 7, 2410, 188], [108, 11, 2949, 261, 38, 5, 220, 493, 3159, 326, 499, 47, 20, 83], [1504, 11, 4, 360, 60, 1, 12, 748, 1085, 21, 1227, 37, 40, 317, 65, 13, 4, 1045, 1, 51, 4, 1294], [186, 136, 2, 95, 73, 15, 3468, 7, 85, 38, 5, 1344, 20, 98, 8577, 8, 20, 337, 3444, 12, 2, 6045, 85, 195, 3, 383], [4, 25, 69, 41, 1705, 12, 2, 104, 31, 52, 3046, 33, 298, 68, 361, 8, 194, 97, 18817, 33, 13, 4, 4805], [3, 592, 2, 18818, 51, 4, 1333, 225, 1243, 800, 8, 151, 1750, 15, 35, 10, 24, 5215, 18819], [22, 1034, 639, 198, 44, 1750, 2, 3184, 6810, 35, 50, 24, 26, 18820, 170, 6, 989, 38, 52, 47, 2, 18821, 18822, 951], [10, 746, 4219, 18, 5, 236, 469, 361, 53, 6505, 133, 147, 1781, 26], [40, 2, 1263, 18, 34, 40, 33, 2, 9, 82, 10, 4614], [20, 48, 117, 21, 22, 3629, 57, 85, 219, 20, 18823, 12, 33, 29, 14, 2, 1, 252, 2290, 18, 2, 18824, 29, 340], [61, 171, 1, 58, 20, 171, 856], [321, 60, 16, 78, 1, 811, 8, 58, 48, 623, 15, 8630, 8630], [552, 31, 12, 109, 2, 91, 34, 40, 362, 12, 2, 56, 8338], [22, 25, 1264, 65, 51, 84, 684, 853, 13, 3153, 30, 684, 853, 5, 46, 73, 587, 73, 18825], [28, 6, 618, 1, 8, 101, 651, 243, 7077], [171, 9, 54, 135, 420, 51, 2, 4777, 7207, 11, 18826, 5001], [3, 64, 10, 180, 517, 1], [85, 78, 46, 58, 1573, 38, 4, 203, 1, 756, 18, 17, 78, 2, 840], [327, 74, 15, 210, 3693, 74, 20, 4, 234, 83], [1502, 516, 259, 27, 56, 130, 70, 15, 197, 27, 2, 93, 414], [375, 38, 5, 41, 20, 1562, 4406, 18827, 8, 5, 1559, 32, 858, 1077, 8, 1442, 51, 20, 1464, 8, 1244, 54, 57], [486, 2, 91, 11, 2, 190, 18828, 3184, 26, 1141, 18829, 27, 98, 18830, 57, 2, 1270], [78, 1, 12, 365, 73, 385], [10, 3251, 8631, 88, 470, 78, 9, 575, 55], [18831, 40, 61, 14, 2, 9, 18832], [221, 9, 34, 4, 260, 49, 2901, 55, 37, 18833, 96, 41, 50, 746, 2, 18834], [22, 158, 1356, 229, 12, 1765], [44, 68, 12, 18835, 44, 2, 320, 16, 1, 598, 1040], [3, 29, 279, 71, 322, 5, 49, 31, 20, 395, 12, 56, 435, 49, 61, 6, 557, 5, 18836, 7, 48, 4579], [332, 201, 176, 4, 9, 102, 17], [674, 2927, 258, 18837, 11, 56, 63], [38, 2, 1, 72, 8463, 6, 482], [7059, 1], [22, 413, 449, 47, 56], [19, 125, 263, 8, 88, 66, 2587, 9], [3, 2053, 19, 27, 2, 291, 1], [31, 20, 2, 89, 1, 18838, 5, 255, 4773], [91, 92, 39, 9, 62], [39, 9, 46, 334, 1151, 36, 4380], [22, 413, 449, 47, 56], [9, 46, 45, 71, 18839, 1, 49], [31, 2, 1, 122, 6, 28, 284, 740], [8, 5388, 18840, 305, 1097, 858, 2368, 3245, 105, 114, 212, 5, 64, 21, 4351, 21, 36, 63, 14, 223, 11, 2, 18841], [38, 5, 44, 2, 93, 77, 72, 43, 6, 9], [31, 20, 504, 317, 13, 7, 1, 88, 29, 81, 6, 7, 83], [38, 5, 94, 2, 9, 81, 6, 482, 34, 40, 48, 110, 18, 20, 822], [29, 134, 2, 91, 4, 24, 444, 52, 134, 5, 2, 3924], [119, 20, 414, 24, 12, 93, 21, 4, 4401], [3, 67, 6, 735, 68, 811, 4048, 26, 656, 414, 24, 390, 6, 966, 396, 50, 164, 26, 1535, 59, 435, 1115], [847, 227, 591, 173, 18842, 610, 227, 912, 1, 173, 18843], [352, 488, 2, 320, 16, 287, 72, 28, 126, 30, 3148, 150, 165, 130, 28, 126, 24, 18844], [1, 49, 37, 6384, 241, 10, 274], [31, 220, 438, 29, 14, 2, 2512, 1, 38, 3, 2532, 1834, 3, 772, 6, 14, 2532, 895], [31, 5, 433, 35, 4, 1180, 27, 2, 341, 1148, 77, 149, 4, 419, 164, 27, 9, 12, 18, 20, 453, 5, 49, 33, 3520, 171, 3656], [22, 1, 47, 37, 2376], [38, 42, 61, 539, 482, 310, 26, 116, 43, 9, 18, 116], [241, 15, 1445, 356, 106, 5, 165, 388, 18845], [91, 247, 16, 5, 490, 487, 383, 35, 11, 559, 80, 401, 31, 5, 592, 54, 97, 900, 529, 37, 242, 794, 810, 562, 25, 64], [31, 3, 167, 97, 25, 1, 23, 370], [298, 2, 1036, 12, 19, 2, 1, 5, 8537, 88, 495, 499, 107, 11, 8, 19, 4, 83, 7, 2, 5081, 569, 16], [199, 9, 298, 108, 1806, 5, 45, 59, 17, 14, 4, 199, 9, 1174, 19, 5, 199, 25, 1806, 42, 45, 14, 4, 4039], [3, 62, 5, 44, 17, 572, 34, 244, 449, 1], [38, 4, 6060, 1178, 107, 102, 8, 5, 96, 67, 6, 14, 116, 573, 64, 3781], [60, 1, 101, 342, 38, 36, 476, 637, 7, 872, 12, 57, 19, 78, 35, 680, 1022], [228, 16, 136, 100, 17, 62, 7, 2707, 12, 727, 18846, 84, 2627, 136, 223, 3784, 8, 52, 12, 8632], [160, 5998, 1700, 237, 2884, 9, 1454], [2206, 8633, 12, 98, 674, 18847, 3, 2053, 442, 71, 52, 12, 6498, 2, 4665], [1137, 2890, 46, 2455, 5037], [39, 1928, 251], [105, 302, 2, 1, 7, 122, 6, 14, 2, 234, 1], [36, 72, 284, 77, 41, 4, 237, 24], [11, 4, 18848, 215, 4862, 18849, 3, 63, 1240, 3587, 245, 232, 1146], [3, 46, 525, 10, 402, 2292, 171, 30, 693, 80, 1, 30, 338, 143, 1195, 139, 215, 264, 4, 455, 47, 784], [18850, 2134, 159, 18851], [3, 62, 3, 41, 93, 24], [3, 29, 67, 80, 1, 40, 146, 14, 18852], [169, 1926, 1, 23, 8634, 15, 2177, 143, 4621, 4563, 51, 585, 379, 1247, 61, 7867, 827, 389], [29, 182, 14, 1811, 16, 69, 5, 49, 650, 5, 2, 282], [5, 77, 14, 1682, 81, 59, 296, 90, 376, 5788, 233, 219, 1, 5, 165, 303, 2, 148, 2799, 5693], [75, 110, 113, 2, 1, 403, 461, 86, 5, 238, 28, 51, 980, 1522, 78, 2075, 3714, 28, 112], [139, 733, 59, 14, 419, 9, 66, 44, 1104, 437, 135, 1315, 13, 1653, 317, 1759, 1418, 211], [39, 9, 46, 334], [78, 208, 13, 20, 24, 200, 256, 1579, 140, 2, 25, 5561, 210, 349, 897, 576, 52, 33, 210, 349, 54], [5, 75, 113, 2, 1, 45, 38, 36, 28, 2, 401], [38, 5, 61, 6, 2, 1197, 460, 8, 5, 29, 94, 245, 1], [38, 5, 8, 20, 177, 2048, 2, 9], [76, 9, 49, 4141, 34, 2, 93, 414, 103, 156, 14, 2, 93, 2013], [215, 800, 5, 1, 14, 1075], [151, 1405, 509, 20, 1253, 33, 37, 5, 62, 3, 509, 15, 8, 210, 18853, 3, 63, 14, 2, 1, 13, 760], [434, 192, 4, 561, 10, 1246, 856, 1227, 173, 4, 1637, 1879, 8, 502, 1227, 2, 417, 18854, 447, 40, 2, 3375], [15, 46, 295, 6, 311, 7, 1, 1724], [53, 3, 516, 1429, 102, 88, 19, 9, 1249, 7, 45, 723, 134, 17, 2, 436, 2374, 425, 141, 14, 13, 188], [31, 5, 114, 20, 77, 108, 211, 40, 359, 18, 5, 20, 2, 141, 83], [128, 71, 25, 14, 27, 4, 234, 9], [39, 9, 46, 334], [122, 37, 332, 6, 2344, 4, 3096, 6, 737, 2, 1], [38, 42, 8, 174, 177, 2048, 2, 9], [3, 33, 131, 466, 10, 2103, 11, 20, 343, 8, 1448, 4, 1, 117, 54, 16, 350], [51, 22, 3344, 18855, 847, 333, 2182, 6, 50, 26, 5, 2, 9, 21, 22], [252, 1484, 13, 2, 1562, 1347], [100, 971, 901, 1480, 332, 18856], [57, 27, 32, 39, 24, 227, 943, 173, 18857, 1092, 713], [351, 1466], [3, 301, 8635, 28, 22, 9, 423, 82, 17], [52, 43, 1592, 2159, 15, 82, 217, 3714, 3847, 4, 382, 18858, 12, 895], [128, 321, 18859, 100, 17, 258, 2, 512, 883, 37, 3, 222, 301, 2, 1, 118], [18860, 35, 9, 142, 31, 97, 1, 75, 3398, 88, 794, 9, 223, 2150], [22, 1, 18, 3088, 2, 1021], [57, 15, 18861, 9, 18862, 18863, 2, 25, 28, 11, 384, 2138], [71, 637, 3, 195, 6, 491, 2, 1], [3685, 18864, 216, 84, 373, 324, 6, 3683, 102, 4648, 25, 47, 248, 3, 90, 76, 1177, 73, 2, 4441], [2231, 17, 157, 10, 265, 35, 11, 97, 476, 83, 272, 227, 22, 45, 173, 2, 4819, 8275], [20, 1214, 12, 291, 1], [5, 41, 206, 1, 4436, 76], [3, 222, 599, 14, 345, 68, 691, 28, 35, 2726, 10, 231, 26, 294, 54, 4, 712, 13, 1, 227, 5842, 552, 15, 6030], [4681, 95, 26, 1508, 1552], [18865, 16, 1, 49, 9, 1030, 10, 779], [168, 324, 270, 73, 138, 8, 24, 11, 1321, 2535, 12, 33, 99, 18866, 21, 307], [4152, 4, 77, 16, 20, 651, 12, 2, 9, 8, 4, 189, 16, 20, 651, 46, 385, 488, 16, 164], [77, 29, 100, 2, 189, 557, 5, 13, 2, 190, 3473, 5, 49, 2, 1106, 3473], [53, 31, 3, 29, 262, 5, 43, 127, 7, 218, 5, 2, 723, 1, 33, 37, 78, 9, 18867], [7, 2, 727, 417, 1280, 18868, 92, 427, 856, 209, 127, 501, 130, 7440], [671, 2, 587, 548, 1, 407, 109, 57, 3, 893, 6, 58, 27, 10, 164, 34, 135, 3, 195], [1, 64, 1518, 2069, 8, 1350, 218, 36, 569, 6, 155, 77, 4547, 9], [4, 2880, 1029, 38, 20, 396, 11, 4, 1198, 8, 20, 1757, 235, 1878, 539, 4, 935, 16, 20, 18869], [708, 766, 820, 16, 50, 42, 333, 19, 50, 6, 6955, 74, 2752, 50, 789, 24, 27, 2, 7640, 634, 40, 2020, 6, 14, 20, 2009], [18870, 77, 587, 913, 2, 9], [1673, 14, 2, 185, 19, 1664, 160, 17, 6, 185, 19, 1], [50, 24, 64, 15, 38, 3, 569, 11, 18871], [370, 7, 3, 510, 173, 20, 24, 13, 2, 2909, 3725], [274, 32, 2, 25, 302, 3, 75, 302, 7, 743, 218, 31, 7, 1, 1873, 23, 19, 75, 302, 25, 36, 1, 41, 36, 138], [15, 48, 73, 1016, 73, 1502, 86, 6, 258, 98, 18872, 269, 1927, 51, 4, 215, 8636], [53, 38, 2, 203, 1, 67, 5, 8, 2, 703, 1, 75, 867, 777, 21, 5, 39, 9, 46, 807, 53, 58], [241, 3, 1560, 2970, 35, 616, 108, 9], [321, 5, 19, 4, 45, 54, 16, 10, 578, 1852, 27, 7, 83], [139, 5533, 630, 83, 4, 101, 408, 5, 44, 12, 18, 20, 18873], [78, 96, 28, 78, 231, 257, 18874, 1002, 5, 96, 114, 327, 27, 2, 231, 392, 16, 24, 18875, 18876, 2, 659], [7, 69, 171, 1], [1, 12, 37, 1490, 8637, 1490], [1312, 554, 82, 147, 381, 11, 4, 689, 147, 778, 7149, 112, 356, 1], [987, 11, 4, 18877, 16, 1564, 27, 32, 10, 89, 1], [5, 72, 1295, 20, 1078, 72, 157, 54, 1989], [31, 3, 124, 6, 479, 2, 970, 16, 4, 674, 782, 2556, 3, 118, 479, 2206, 18878], [39, 9, 46, 334], [23, 679, 1056, 1869, 23, 61, 6, 44, 6, 901, 22, 1149, 16, 2289, 6, 430, 35, 6, 5, 3095, 1611, 18879], [60, 9, 259, 383, 6, 167, 4, 489, 155, 696, 233], [1, 72, 18880, 6496, 27, 474, 23, 342, 74, 336, 1397, 125, 10, 280, 26, 249, 84, 138, 74, 336, 1345, 3681, 709], [40, 121, 3, 505, 50, 150, 92, 40, 438, 18881], [21, 25, 69, 708, 6, 64, 24, 73, 209, 73, 78, 58, 78, 198, 14, 2098, 21, 1719, 1132, 8, 18882, 3416], [4044, 29, 1838, 38, 5, 70, 50, 8076, 155, 89, 184, 40, 72, 317, 4558, 218, 5, 41, 4, 285], [52, 64, 17, 5149, 2, 5409, 52, 64, 17, 48, 5149, 2, 5409], [597, 17, 35, 38, 143, 1, 28, 135], [91, 13, 58, 625, 184, 3, 146, 114, 10, 1100, 102, 6, 7, 312], [37, 78, 25, 109, 64, 39, 9, 27, 25, 2561, 18883, 694, 4, 866, 165, 130, 5, 8, 40, 1039, 92], [354, 8638], [243, 457, 10, 141, 1984, 4220], [29, 616, 54, 125, 80, 25, 129, 1541], [39, 1, 12, 10, 386, 55], [3, 63, 58, 1406, 93, 34, 23, 156, 276, 14, 2, 18884, 18885], [8, 25, 29, 14, 62, 4, 511, 74, 67, 6, 442, 7, 4, 1, 428, 183], [3, 300, 6, 274, 8261, 12, 2, 18886, 8639, 26, 583, 23, 2, 1], [8640, 18887, 1487, 136, 6, 14, 2, 8641, 88, 244, 1487, 211, 7, 136, 6, 14, 2, 2563, 8641, 100, 137, 269], [3, 41, 692, 8, 1420, 21, 5, 83], [752, 1, 298, 18888], [1267, 1232, 216, 2575, 885, 13, 22, 37, 25, 28, 906, 8, 44, 6, 303, 126, 1, 1074, 8638, 6, 70, 35], [73, 11, 1849, 50, 517, 18, 246, 91, 7421, 362, 2811, 5, 431, 27, 20, 77, 856, 27, 166, 312], [425, 18889], [3, 195, 417, 3, 195, 2792, 34, 3, 103, 96, 100, 2, 1, 62, 57, 35, 18890], [4, 395, 3297, 210, 28, 2, 180, 517, 282], [4, 395, 3297, 12, 2, 838], [38, 3, 465, 2, 260, 345, 51, 2, 3450, 3, 63, 599, 150, 10, 24, 2131, 2, 676, 637, 8, 313, 54, 4, 223, 1127], [8, 40, 502, 22, 25, 235, 288, 3, 47, 973, 244, 6, 50, 288, 40, 124, 2, 1214, 40, 2, 9, 18, 4, 702], [302, 43, 91, 1293, 43, 83], [2, 177, 1159, 4, 18891, 1175, 1578, 123, 1175, 18892, 168, 11, 2, 1355, 151, 105, 28, 245, 24, 140, 3, 62, 71, 6], [2859, 475, 133, 2, 1, 69, 46, 475, 133, 17], [61, 3421, 8, 382, 17, 68, 115, 151, 506, 602, 16, 22, 4031, 6, 484, 4, 1106, 1386, 5189, 7834, 8, 219, 94, 69, 315], [31, 44, 9, 96, 1110, 5, 26, 5, 96, 44, 60, 632, 6, 58, 161, 663], [31, 5, 67, 6, 303, 393, 5, 33, 81, 6, 4, 1529, 1, 8, 88, 4, 1529, 1, 81, 6, 17, 58, 5, 62, 57, 3, 195], [18893, 18894, 223, 44, 6, 70, 441, 348, 38, 15, 18895, 11, 143, 1308, 4161, 34, 143, 941, 61, 2349, 280, 7, 933], [22, 175, 47, 2, 5737, 941, 8, 3, 906, 5753, 319], [85, 77, 14, 37, 18896, 38, 36, 24, 2729, 4573, 7, 385, 70, 4, 2487, 2427, 27, 254, 66, 556, 18897], [719, 2, 25, 1, 29, 719, 2, 25, 2518], [4032, 1], [31, 68, 127, 2283, 1718, 1, 59, 4, 1032, 3, 103, 2280, 76, 142, 26, 204, 76, 27, 698, 140, 416, 12, 18898], [486, 2, 91, 11, 2, 190, 1100, 51, 4, 1630, 7006, 1185, 52, 47, 662, 54, 244, 6, 2, 4778, 18899], [22, 269, 18, 10, 108, 176, 18900, 2715, 11, 10, 4416], [2023, 1], [3, 198, 28, 2, 401, 51, 4, 18901, 2051, 2312, 518, 371, 4, 101, 3667, 12, 14, 2, 966, 838], [552, 71, 111, 63, 33, 48, 44, 2, 401, 8, 271, 51, 337, 32, 115, 194, 886, 15, 47, 37, 723, 21, 17, 6, 58, 15, 201, 115, 552, 236], [945, 31, 5, 49, 3097, 56, 69, 13, 6, 644, 184, 18, 739, 601], [4, 18902, 18903, 56, 18904, 18905, 2370, 18906, 7907, 18907, 18908, 951], [6062, 124, 4, 2387, 401, 11, 4, 3434, 3, 41, 2, 1180, 6, 14, 4, 8642, 16, 4, 154, 1648, 2527, 160, 1098, 891, 951], [2, 1060, 68, 11, 4, 6063, 232, 1228, 688, 298, 11, 1529, 16, 2588, 6, 114, 18909, 1337, 129, 355, 18910, 4, 18911, 424, 18912], [421, 1688, 4679, 8643, 4635, 103, 821, 27, 4, 232, 21, 4770, 213, 18913, 18914, 3252, 1940, 18915], [421, 5840, 1309, 159, 870, 12, 772, 6, 1273, 1094, 401, 2950, 6, 2798, 26, 871, 1193, 439, 26], [1098, 891, 28, 15, 328, 18916, 8644, 1694, 4442, 18, 981, 18917, 8, 201, 298, 8581, 232, 114, 18918, 1337, 11, 2588, 18919], [1098, 891, 338, 1519, 73, 68, 16, 4, 2387, 232, 1269, 3252, 513], [1098, 891, 679, 178, 51, 232, 1330, 103, 14, 841, 52, 182, 137, 116, 27, 232, 3753, 82, 5298, 951], [29, 65, 92, 34, 4, 524, 49, 11, 508, 2201, 16, 841, 507, 11, 4, 4754, 7835, 4, 2886, 18920, 26], [21, 4, 215, 106, 4, 2216, 114, 4, 1194, 51, 232, 4409], [18921, 4472, 503, 725, 3150, 382, 8645, 2079, 2, 469, 155, 1313, 6, 787, 213, 18922, 439], [2533, 91, 8489, 658, 18923, 433, 8584, 8646, 8647, 18924, 433, 3717, 8646, 8647, 7771, 983, 13, 236], [8648, 450, 11, 154, 6892, 1098, 891, 294, 102, 2, 3273, 51, 232, 1330], [232, 2273, 18925, 626, 6, 257, 4097, 18926, 4126, 18927, 2102, 8649, 292, 523, 3999, 18928, 2102, 201, 8649, 292, 523, 2562], [37, 1316, 44, 821, 2911, 4717, 26, 18929, 18930, 3912, 136, 15, 36, 96, 67, 4779, 6064, 1059, 4012, 4601, 18931], [40, 2, 9, 40, 183, 40, 2, 1, 40, 22, 40, 7, 233, 34, 5, 438, 50, 333, 114, 2, 7036], [1053, 11, 8145, 18932, 21, 40, 3149, 32, 18933, 1191, 6, 120, 73, 353, 26, 18934, 2208], [23, 33, 65, 21, 2, 1, 7, 63, 555, 17, 142], [3080, 12, 2, 1], [3, 64, 89, 1, 7, 10, 19, 437], [326, 7, 96, 18, 1126, 179, 74, 554, 18935], [2683, 18936, 147, 18937, 147, 1], [1, 18938], [364, 1, 55], [13, 1061, 31, 5, 49, 2091, 6, 14, 224, 217, 140, 16, 71, 36, 65, 20, 56], [53, 22, 1, 131, 14, 6033, 82, 732, 586, 37, 89, 53], [2216, 2841, 9], [194, 685, 871, 27, 32, 7, 90, 11, 126, 1009, 122, 8, 301, 89, 18, 8650, 52, 108, 1, 139, 90], [3, 90, 38, 111, 191, 69, 5, 238, 65, 93, 21, 1, 531, 680], [1258, 83], [463, 29, 28, 952, 114, 279, 4, 1091, 4016, 1623, 7, 136, 132, 1525, 11, 4, 215, 473, 213], [107, 495, 333, 28, 17, 2, 5204, 103, 6, 119, 24, 21, 15, 31, 87, 2305], [2, 821, 51, 18939, 18940, 2, 219, 1370, 1501, 446, 808, 1398, 8, 1684, 8612, 38, 8640, 26], [39, 9, 46, 334], [24, 131, 168, 18941, 18942, 21, 126, 18943, 18944, 18945, 168, 10, 2426, 853, 873, 18946], [75, 302, 2, 1, 69, 100, 4, 3313, 167, 984, 40, 317, 279, 59, 50, 8651, 415, 756, 18, 4, 5970, 820, 709], [3801, 518, 2903, 12, 8389, 8, 15, 107, 230, 518, 5871, 236, 8390, 3962, 15, 280, 230, 319], [31, 50, 1618, 72, 3518, 274, 63, 1105, 986, 40, 2, 282], [4, 3624, 5, 49, 4, 2245, 20, 3467, 37, 33, 14, 2, 1], [57, 317, 204, 5, 70, 5, 2, 83], [369, 12, 18947, 200, 5, 528, 630, 6, 376, 1], [955, 18, 2, 5518, 83], [57, 277, 18948, 196, 6, 60, 16, 5, 1, 55, 292, 707], [18949, 441, 12, 37, 18950, 281, 3, 47, 122, 6, 28, 314, 1, 23, 48, 122, 6, 227, 5, 962], [2406, 81, 179, 20, 5925], [2, 9, 443, 493, 12, 1673, 1105, 17, 5, 29, 62, 57, 3, 132, 18951, 221, 3, 4771, 2, 320, 16, 1270], [211, 3, 19, 20, 1], [3241, 2, 77, 191, 5, 21, 547, 113, 7, 1, 6, 191, 4179, 7795, 371, 7, 50, 18952], [75, 302, 2, 1, 69, 100, 4, 3313, 167, 984, 40, 317, 279, 59, 50, 8651, 415, 756, 18, 4, 5970, 820, 16], [31, 3, 139, 10, 347, 37, 7, 5, 63, 294, 1117, 4, 606, 3, 165, 94, 60, 2734, 54, 16, 5, 1981, 6, 2170, 1, 1981], [43, 1, 30, 418, 3546, 103, 182, 14, 73, 611, 73, 22, 629], [3463, 16, 4, 1260, 16, 4, 673], [22, 1, 317, 62, 57, 40, 18953], [120, 77, 31, 20, 202, 520, 317, 79, 5, 1619, 88, 1, 5, 46, 7, 3108], [1152, 482, 237, 467, 7806, 591, 37, 50, 24, 578, 13, 800, 26, 18954, 1232], [174, 2, 104, 31, 5, 396, 20, 226, 6, 20, 1451, 33, 37, 5, 63, 28, 1451, 2518, 22, 46, 2283, 25, 19, 80, 457], [38, 20, 11, 775, 27, 20, 234, 9], [6050, 5, 49, 37, 417, 64, 5, 99, 816, 513], [2559, 565, 49, 21, 24, 23, 33, 152, 743, 5, 142, 8, 719, 20, 1106, 2137], [95, 19], [762, 18955, 69, 116, 8639, 1576, 69, 1576, 8652, 241, 1576, 8652, 1073, 6, 2709, 572, 1327, 1], [23, 37, 3357, 32, 80, 1, 62, 307, 247, 39, 25, 1500, 219, 51, 577, 36, 62, 17], [3804, 121, 43, 24, 534, 1077, 10, 381, 331, 7, 57, 41, 280, 4714, 1020, 1077, 4, 381, 1381], [3, 33, 131, 14, 551, 18, 1706, 61, 3191, 11, 7, 1], [31, 40, 317, 62, 57, 18956, 18957, 7, 1], [21, 6000, 3, 75, 110, 72, 1378, 2857, 130, 1426, 431, 684, 18958, 461, 495, 1342, 15, 6, 2, 18959, 2929, 43, 1, 965], [134, 17, 18960, 86, 42, 134, 240, 24, 18961, 5, 122, 254], [78, 72, 1542, 5, 438, 161, 5664, 13, 2424, 9, 33, 18, 2, 8474, 3395], [37, 239, 3093, 9, 11, 4, 4139, 15, 2, 1143, 337, 160], [3, 62, 246, 418, 3, 103, 105, 512, 1404, 3908, 22, 68, 793, 2536, 187], [85, 12, 116, 2, 24, 801, 18, 10, 909], [1, 1256, 14, 18, 3238, 2928, 18, 669, 2817, 7277, 8, 24, 18, 5338], [3, 94, 4, 284, 44, 2096, 35, 18, 18962, 5059, 8, 44, 420, 18, 6, 168, 5421], [48, 339, 1], [3, 107, 102, 13, 2, 966, 1, 34, 31, 3, 13, 5, 3, 103, 599, 58, 393, 21, 350], [107, 201, 18963, 18964, 18965, 15, 29, 110, 3813, 34, 5, 171, 30, 9, 223, 19, 224, 18966, 20, 931, 1041, 3269], [66, 32, 62, 20, 19, 2, 1, 117, 92, 55], [1796, 20, 2902, 4201, 1], [1], [3, 375, 3, 122, 6, 365, 999, 2, 1, 230, 8, 40, 47, 193, 99, 870, 1737, 233, 3, 1559, 13, 2, 1], [53, 5, 2, 3417, 18967, 9, 23, 18968], [25, 38, 82, 53, 63, 3, 28, 2, 18969, 6, 296, 41, 9, 340, 53], [43, 538, 21, 2, 1, 40, 152, 503, 17, 1804], [52, 1028, 7, 1], [421, 232, 8444, 1103, 1297, 11, 2, 292, 412, 799, 3783, 2831], [31, 212, 18970, 406, 28, 245, 127, 858, 23, 61, 6, 87, 2, 18971, 6, 5427, 76], [37, 342, 513, 933, 18972], [200, 944, 719, 10, 923, 354], [23, 569, 18, 236, 25, 1002, 9, 638, 415, 29, 2595, 905, 1907, 343, 18973], [4, 18974, 5432, 5651, 159, 824, 21, 1837, 1546, 165, 21, 18975, 951], [75, 304, 21, 4, 6, 3164, 4, 5628, 390, 18, 43, 690, 71, 89, 4, 3838, 49, 220, 152, 257, 4, 95], [33, 2, 449, 892, 78, 9, 407, 249, 138, 92, 78, 32, 2657, 51, 15, 18976], [18977, 720, 25, 2, 468, 36, 1, 129, 2, 1, 7, 48, 110, 783, 15], [425, 22, 1, 47, 134, 235, 11, 4, 108, 16, 2, 18978, 40, 165, 61, 364, 3421], [5, 299, 5, 124, 602, 343, 21, 2, 8653, 1], [4, 2135, 573, 761, 747, 20, 443, 1621, 1219, 2381, 527], [4154, 1], [53, 427, 1206, 2, 409, 16, 18979, 576, 25, 15, 2, 3671, 10, 1, 12, 82, 1271, 40, 18980], [19, 1346, 11, 8654, 16, 4330, 156, 19, 17, 562, 1, 30, 18981, 1716], [108, 11, 4, 115, 38, 898, 47, 18982, 8, 52, 216, 7, 323, 27, 84, 1, 504, 3, 121, 52, 47, 152, 14, 2, 18983], [34, 75, 357, 51, 78, 8655, 2221, 54, 2457, 17], [345, 71, 5, 223, 436, 2, 1, 7, 100, 25, 735, 18, 50, 235, 11, 775], [987, 12, 179, 444, 120, 111, 58, 254, 1443, 907, 2755, 12, 5668, 26, 2744, 444, 36, 67, 6, 18984, 16, 254, 2208], [18985, 68, 16, 76, 187, 8656, 33, 14, 165, 51, 2049, 3944, 257, 42, 51, 1879, 18986, 18987, 20, 436, 165, 26, 404, 2], [18988, 135, 617, 23, 48, 2, 1018, 834, 905, 343, 275, 18989], [31, 5, 477, 6, 39, 1130, 18990, 5182, 5181, 3226, 5180, 8586, 8585, 8587, 1793, 3931, 5785, 18991, 18992, 6047, 8657, 8588, 253, 17, 26, 416], [6065, 1154, 5, 86, 5, 63, 493, 17, 35, 3, 486, 2, 89, 1, 11, 3067, 8658, 8659], [3530, 114, 22, 327, 21, 17, 3118, 8459, 18993, 9, 223, 13, 7, 2918], [4275, 16, 4, 202, 77, 51, 10, 261, 49, 179, 483, 18994], [71, 58, 1, 1702, 474, 34, 96, 28, 359, 18, 256, 48, 1401, 35], [3, 62, 40, 2, 9, 31, 40, 442, 11, 18995, 272, 70, 2, 821, 21, 760], [1702, 49, 2278, 18996, 18997, 11, 979, 49, 56], [24, 12, 24, 18998, 7, 71, 37, 239, 16, 78, 260, 734, 4663, 8, 42, 869, 50, 82, 4, 18999], [31, 20, 177, 421, 35, 27, 5, 8, 136, 2, 154, 504, 2, 535, 115, 790, 88, 116, 47, 256, 5, 210, 62, 1261], [2, 414, 2806, 6, 2, 91, 12, 14, 2, 9], [3, 1999, 19000, 18, 4, 930, 211, 1, 168, 15, 3, 46, 124, 7, 209, 302, 11, 275, 371, 1620, 19001, 704, 5426], [31, 3, 65, 51, 10, 1, 40, 165, 242, 35, 46, 43, 687, 27, 638, 11, 4, 606, 74, 685, 1848], [31, 97, 1, 500, 12, 2, 25, 42, 86, 12, 564, 42, 318, 14, 564, 21, 44, 2, 564, 25, 206, 1], [31, 2045, 638, 63, 110, 28, 10, 1, 701, 403, 63, 44, 15], [638, 13, 32, 76, 927, 1, 18, 798, 327, 638, 29, 64, 240], [1123, 54, 6, 32, 76, 1, 69, 29, 373, 43, 1953, 45, 8, 96, 65, 165, 130, 32, 78, 1, 27, 474, 19002], [39, 1, 653, 3460, 1484, 102, 13, 8, 126, 5146, 1484, 102, 610, 4709], [39, 1, 103, 644, 5, 35, 4, 1029, 5, 139, 19, 27, 76, 8, 36, 214], [78, 1, 41, 6, 683, 4, 511, 808, 13, 8, 64], [78, 1, 471, 19003, 6, 4, 6836, 130, 28, 214, 38, 36, 51, 97, 676], [5, 171, 1, 96, 86, 322, 12, 474, 19004, 65, 165, 130, 1904, 53, 19005, 415, 62, 40, 58, 99, 34, 380], [958, 522, 27, 20, 19006, 1054, 228, 140, 36, 64, 20, 522], [39, 9, 46, 41, 777, 18, 97], [8660, 56, 91, 52, 257, 17, 6, 4, 93, 1216, 1404], [23, 243, 21, 4, 19007, 1556, 8, 1864, 1773, 189, 5328, 18, 135, 2, 93, 3876, 16, 57, 48, 6, 14, 8, 57, 3, 2314], [17, 8, 22, 1, 600, 48, 14, 4, 237, 16, 228, 34, 22, 1112, 40, 672, 7, 26], [928, 19008, 19009, 19010, 4769, 3103, 26, 4, 514, 2142, 16, 1658, 668, 770, 410], [53, 23, 61, 6, 4, 629, 22, 696, 123, 2542, 43, 4495, 43, 1, 43, 25, 33, 1566, 53, 26], [60, 1, 627, 5, 44, 6, 14, 2, 228, 6, 176, 2, 228], [3, 33, 131, 1624, 20, 645, 26, 605, 26, 735, 10, 193, 142, 6, 20, 24, 33, 37, 3, 63, 150, 155, 1102, 16, 631, 18, 10, 8661], [685, 1848, 41, 1, 235, 13], [18, 4, 8199, 410, 19011, 27, 107, 35, 18, 2, 536, 440, 7, 9, 771], [23, 32, 968, 8, 24, 13, 11, 10, 2518, 8, 32, 1757, 8, 2240, 13, 11, 706], [71, 4, 1, 1340, 28, 1965], [194, 2, 95, 2715, 18, 20, 347, 211, 5, 33, 41, 15, 1089], [693, 277, 155, 275, 86, 155, 25, 36, 107, 1117, 12, 11, 64, 596, 76, 1, 3, 222, 338, 42, 366, 2, 866, 26, 627], [1335, 1, 28, 54, 384, 150, 8, 28, 60, 154, 138, 53], [22, 25, 121, 757, 273, 17, 40, 1415, 2, 25, 2177, 19012, 91, 3, 299, 15, 47, 1899, 2177, 257, 80, 19013, 80, 917, 128], [3, 14, 11, 80, 1, 24, 13], [1, 139, 5389], [38, 20, 455, 1, 228, 94, 5, 51, 2, 460, 188], [37, 3, 222, 430, 2, 657, 27, 470, 39, 24, 54, 135], [100, 2, 1, 122, 17, 122, 17, 272, 2246, 50, 6, 4, 413, 663, 730], [339, 23, 4, 45, 1], [37, 38, 4, 2670, 167, 1296, 5752, 571, 87, 4, 832, 19014, 26, 5823, 9, 6, 14, 51, 7434, 134, 10, 340], [2, 9, 30, 25, 103, 105, 396], [19015, 19016, 2906, 8662, 2790, 19017, 159, 2090, 19018, 3638, 244, 8426, 4003, 8, 2225, 3884, 316, 7, 409], [613, 6757, 156, 1174, 2788, 2, 83, 13, 52, 2, 1], [1040, 3224, 12, 19019, 7, 85, 1, 119, 7651, 522, 38, 2214], [22, 229, 198, 14, 79, 6008, 952, 3, 46, 297, 64, 478], [3, 47, 11, 50, 288, 50, 158, 47, 11, 116, 1955, 1283], [3, 90, 38, 1, 28, 2, 91, 8, 192, 175, 45, 13, 4868, 100, 17, 139, 175, 13, 22, 230, 52, 204, 17, 53], [3, 44, 984, 9], [3, 566, 5, 125, 7, 1, 7, 19020, 19021], [65, 51, 7, 1, 193, 129, 116, 1509, 10, 186], [40, 2, 9, 31, 50, 1451, 11, 8663], [15, 19022, 129, 135, 1, 34, 2, 320, 16, 45, 14, 61, 142], [4206, 814, 132, 1105, 15, 3781, 19023, 662, 5, 158, 5947], [92, 1, 152, 86, 33, 140, 374, 791, 374, 165, 130, 155, 275, 7, 1591, 251], [31, 5, 152, 19, 10, 77, 88, 29, 349, 50, 343, 25, 3, 1135, 4014, 21, 7, 1, 1349], [58, 5, 67, 6, 465, 4, 910, 74, 49, 5, 101, 65, 6, 465, 57, 70, 5, 150, 32, 1097, 8, 858, 1077, 3, 1668, 910], [19024, 28, 2, 19, 56, 63, 18, 20, 1643], [111, 69, 118, 946, 21, 159, 824, 8, 1995, 8050, 49, 85, 305, 7733, 200, 48, 157, 2, 117, 6, 946, 11, 305, 3350], [2, 112, 25, 223, 1226, 84, 1, 4, 178, 48, 298, 15, 18, 50], [4929, 38, 42, 893, 18, 61, 6, 2, 460, 8, 42, 29, 8, 42, 223, 18, 186, 143, 244, 115, 26, 94, 147, 7, 9, 200], [278, 28, 2, 504, 31, 3, 124, 9, 1000, 19025], [958, 12, 48, 279, 749, 108, 364, 35, 1], [7, 1029, 4, 24, 99, 93, 26, 42, 146, 981, 7, 2863, 142], [72, 147, 45, 361, 89, 1, 90, 291, 5582, 1002, 34, 5, 724, 7, 6948], [22, 1, 33, 1807, 10, 314], [63, 3, 28, 2, 993, 1323, 6, 39, 1, 82, 32, 16, 10, 25, 69, 29, 64, 9, 36, 28, 43, 19026], [275, 2330, 29, 13, 6, 58, 393, 2452, 140, 5, 25, 2468, 59, 15, 13, 1], [44, 2, 112, 1, 123, 20, 234, 8, 555, 15, 142, 21, 5, 12, 2, 1236, 21, 1798], [570, 95, 28, 4, 138], [1473, 1473, 1473, 1473, 2108, 1473, 91, 3, 70, 4, 832, 1, 471, 17, 677], [49, 4, 250, 6, 2774, 22, 213, 9, 21, 14, 3785, 130, 215, 213, 319, 5, 62, 69, 5, 1563], [105, 2277, 873, 27, 2, 2682, 81, 1407, 27, 2, 95, 74, 70, 420, 27, 2, 2218], [38, 9, 79, 166, 9, 2731], [295, 12, 329, 125, 271, 142, 135, 6, 197, 51, 4, 19027, 141, 453, 1, 87, 201, 172, 139, 14, 19028], [28, 22, 1, 54, 16, 10, 331], [267, 21, 609, 17, 1716, 23, 1020, 619], [78, 462, 182, 44, 18, 2, 1686, 503, 74, 256, 26, 26, 26, 13, 68, 16, 20, 628, 47, 33, 497, 619, 4, 758, 8, 5, 717], [2, 77, 175, 463, 318, 14, 179, 31, 42, 316, 522, 82, 619, 173, 4, 3099, 43, 42, 318, 14, 185, 31, 42, 389, 3100, 21, 2, 340], [31, 5, 614, 6, 14, 2, 91, 29, 14, 2, 83], [43, 1294, 3, 407, 551, 484, 3, 47, 3527, 18, 76, 319], [200, 4, 232, 70, 4, 1408, 8, 5854, 2552, 891, 6262, 404], [25, 12, 9, 201], [74, 20, 2, 1298], [743, 829, 81, 27, 19029, 3399, 3391, 18, 19030, 66, 523, 4, 1260, 16, 4, 673], [20, 1242, 12, 1555, 140, 5, 49, 2, 187], [189, 471, 17, 2, 327, 16, 20, 24, 77, 422, 8529, 327, 16, 19031, 1084, 45, 57, 5652, 3, 67, 6, 94, 4, 534], [234, 9, 156, 404], [23, 7, 409, 16, 1, 6, 113, 5, 23, 18, 10, 193, 62, 3, 33, 41, 11, 4, 1306], [1, 340, 175, 474, 36, 94, 6, 340, 19032, 15, 109, 611], [31, 10, 175, 182, 1001, 5, 19033, 23, 370, 19034, 15, 266, 582, 361, 19035, 378, 26, 201, 49, 308, 19036, 20, 2, 19, 24], [584, 227, 129, 2, 154, 4796, 43, 127, 2087, 8, 4683, 21, 986, 12, 96, 2, 711], [1074, 473, 1], [61, 1127, 1], [57, 104, 733, 59, 3070, 2873, 10, 25, 76, 45, 578, 13, 4, 6025, 18, 2837, 5209, 8664, 26], [31, 3, 1988, 20, 327, 7, 196, 706, 17, 9], [53, 31, 5, 64, 50, 869, 20, 1, 37, 5, 176, 19037], [5, 404, 60, 8, 468, 60, 358, 73, 5, 28, 15, 18, 5, 46, 2, 83], [403, 5, 208, 13, 2, 2602, 18, 7272, 66, 86, 20, 19, 804, 5, 2703, 83], [112, 145, 129, 135], [168, 6, 14, 27, 1243, 25, 787, 16, 240, 41, 4682, 787, 16, 240, 227, 24, 4, 166, 546, 157, 11, 197], [463, 532, 13, 8373, 8, 1, 5, 532, 13, 8374], [462, 31, 2, 25, 156, 131, 61, 54, 8, 460, 155, 696, 26, 52, 339, 234, 9, 1495], [2, 2869, 12, 2, 643, 30, 306, 129, 8530, 31, 20, 787, 20, 33, 2, 1, 27, 2, 2727], [3709, 49, 21, 1549, 45, 582, 799, 27, 15], [480, 682, 1, 359, 18, 126, 91, 991, 682, 1, 3565, 2295, 2827, 2334, 1959, 103, 311, 20, 138, 102, 26, 120, 19038], [8665, 1054, 12, 248, 99, 7857], [31, 50, 343, 12, 50, 26, 40, 103, 167, 5, 27, 2, 757, 3, 1048, 15, 37, 15, 8323, 26], [247, 202, 9, 51, 2358, 65, 13], [19039, 48, 175, 13, 2, 1, 679], [128, 78, 60, 181], [4766, 2347, 7, 5, 222, 14, 2, 864, 16, 24, 21, 2, 535, 755, 88, 1555, 211, 7, 295, 342, 2], [55, 1, 814, 157, 5482, 18, 10, 971, 26, 19040, 11, 10, 2747, 1502, 1622, 10, 1109], [19041, 6, 19042, 293, 151, 94, 10, 237, 1, 26, 7, 118, 70, 10, 921], [96, 4, 2387, 175, 1269, 1, 298, 18, 1393, 48, 2326, 233, 2, 1, 103, 72, 19043, 31, 4, 518, 188], [19, 5, 1, 31, 3, 121, 15, 47, 15, 47], [527, 3510, 684, 19044, 31, 23, 119, 393, 390, 414, 15, 19045, 70, 15, 165, 11, 2, 188], [23, 122, 6, 433, 10, 3815], [375, 11, 2, 19046, 50, 228, 49, 48, 19047, 1930, 100, 50, 14, 2, 1774], [55, 217, 19, 80, 1], [151, 14, 7, 1, 225], [1, 5, 41, 17, 3, 1885, 3, 64, 5, 99, 233, 114, 20, 551, 30, 6, 19048], [3463, 16, 4, 1260, 16, 4, 673, 1042, 2, 451], [116, 2, 1, 18, 186, 27, 19049, 253, 34, 40, 484, 1305], [90, 45, 13, 22, 1, 75, 70, 2, 2576, 3455, 34, 63, 114, 2, 286, 16, 2, 1887, 941, 26], [354, 4568], [39, 1, 14, 322, 26, 185], [6235, 2083, 1, 6236, 3, 44, 22], [1870, 19050, 16, 120, 617, 69, 122, 99, 332, 6, 229, 36, 13, 263, 8567], [1087, 54, 3051, 18, 368, 51, 531, 123, 531, 2916, 1414, 73, 19051, 189, 5, 156, 44, 10, 895], [5, 1521, 683, 71, 6, 2338, 218, 1, 64, 1054], [2842, 11, 5415, 2, 269, 11, 2, 1444, 3184, 5412, 11, 98, 8666, 527], [5, 2, 1], [99, 239, 1148, 77, 49, 419, 8, 99, 239, 9, 49, 3073], [1336, 19052, 323, 3296, 8, 8667, 12, 2, 681, 323, 59, 2, 2752, 1972], [111, 2077, 106, 907, 6, 14, 1093, 36, 220, 104, 2, 213, 892, 99], [447, 34, 69, 28, 127, 1, 994], [77, 109, 216, 14, 2, 9, 5901, 18, 186], [3, 90, 409, 256, 37, 4585, 26, 495, 2182, 27, 19053, 1, 23, 556, 409, 4, 199, 184, 1547, 171, 1], [183, 9, 14, 4, 8668, 233, 42, 87, 6, 1438, 102, 26, 869, 630, 2224], [85, 32, 39, 9, 14, 2722, 2847, 224, 36, 1643, 3, 293, 2, 1578, 7350, 36, 30], [23, 2, 284, 812, 3197], [160, 39, 1202, 9, 1897, 51, 474, 2, 25, 19054, 50, 758, 40, 1897, 13, 411], [57, 5, 94, 12, 57, 5, 28, 23, 2, 189, 27, 2, 64, 16, 19055, 8, 2, 87, 21, 3113, 159, 524], [65, 51, 22, 104], [1749, 109, 417, 38, 5, 28, 6, 62, 4064, 903, 40, 2, 1, 34, 604, 28, 168, 6, 254], [58, 3, 44, 106, 21, 39, 9], [38, 3, 70, 2, 1010, 466, 11, 4, 56, 63], [945, 31, 5, 204, 2, 1, 27, 20, 138], [78, 48, 152, 56, 2802, 19056, 3, 2742, 545, 76, 32, 4, 817, 36, 110, 100, 17, 635, 4, 2185, 445, 3017, 36, 29, 2125], [3, 90, 94, 111, 1, 59, 126, 4541, 3, 745, 110, 122, 4, 1672, 2408, 1418, 91, 5, 29, 44, 15, 22, 19057], [32, 4, 7521, 11, 1197, 1231, 56, 13, 78, 75, 110, 70, 787, 2412, 1194, 19058, 41, 68, 19, 401], [1, 175, 19059, 7104, 8669, 91, 401, 74, 112, 5500, 6, 139, 14, 2, 9, 74, 460, 155, 3270, 383, 2, 19060], [247, 5479, 9, 919, 1121, 15, 33, 1788, 1272, 10, 228, 460, 37, 3, 460, 1375, 435, 58, 15, 99, 2591, 8, 2712, 7479, 3219, 3, 47, 80], [271, 1498, 8, 375, 31, 42, 2, 77, 8, 42, 18, 174, 1230, 29, 61, 6, 2, 460, 19061, 383, 271, 337, 42, 3680, 73, 45], [175, 59, 174, 520, 266, 28, 170, 102, 2106, 259, 7, 25, 146, 899, 204, 6054, 1315, 1, 242, 35], [85, 118, 42, 100, 174, 77, 110, 61, 6, 2, 460, 461, 42, 7, 144, 55, 42, 456, 67, 6, 28, 359, 18], [154, 213, 5957, 366, 127, 441, 70, 127, 169, 19, 127, 1], [1386, 427, 2, 19062, 1, 7, 308, 8, 19063, 17], [1163, 280, 216, 54, 27, 98, 183, 418, 51, 2, 8670, 288, 551, 37, 92, 52, 1370, 73, 2206, 95, 140, 52, 167, 19064], [1163, 504, 359, 18, 17, 37, 3, 1476, 876, 23, 438, 50, 306, 92, 37, 92, 7, 1, 12, 10, 795, 19065, 160, 1094, 19066], [603, 19067, 16, 1334, 11, 19068, 44, 105, 132, 6, 261, 253, 123, 3843, 11, 19069, 8055, 11, 19070, 8, 8671, 11, 19071, 1517], [186, 136, 2, 95, 73, 15, 3468, 7, 85, 38, 5, 1344, 20, 98, 1711, 8, 20, 337, 3444, 12, 2, 6045, 85, 195, 3, 188], [2017, 3031, 19072, 3708, 493, 1852, 480, 5656, 5753, 335, 565, 16, 4054, 885, 335, 234, 1, 473, 335, 19, 2096, 984], [355, 341, 6020, 2771, 27, 4, 6953, 19073, 11, 889, 1743, 470, 106, 229, 19074], [5831, 19075, 1480, 1173, 5951, 123, 19076, 79, 15, 2, 187, 288, 19077, 466, 51, 15, 444, 15, 679, 204, 188], [280, 19, 5, 21, 338, 55, 43, 34, 44, 2, 434, 106, 35, 116, 8, 29, 911, 59, 4, 280, 108, 236], [3, 29, 62, 85, 39, 1, 4089, 5, 48, 110, 356, 10, 25], [839, 860, 354], [38, 217, 113, 17, 3, 198, 139, 14, 2, 1], [284, 95], [3499, 112, 1564, 2043, 1357, 8, 2, 7766, 4524], [359, 8, 44, 9, 28, 3905, 416, 198, 67, 6, 1912, 2, 446, 162, 374, 2424, 602, 6, 271, 1148, 26], [29, 182, 14, 1811, 16, 69, 5, 1563, 650, 5, 2, 1774, 88, 14, 1811, 83], [1, 1256, 14, 19078, 343, 8, 4276, 1631, 533, 133, 1256, 18, 3238, 251, 400, 142, 230, 3, 735, 10, 3845, 9], [38, 5, 405, 32, 20, 9, 21, 20, 77, 8, 40, 72, 40, 29, 67, 2, 575], [29, 14, 27, 2, 1983, 368, 7, 33, 65, 1639, 258, 2, 93, 414, 7, 113, 5, 38, 20, 5791, 8, 842, 5, 6], [234, 25, 28, 24, 8, 455, 25, 28, 2469], [29, 990, 129, 43, 812], [70, 225, 80, 1], [1759, 1366, 12, 19079, 21, 20, 2, 141, 1], [1, 1419, 41, 54, 16, 50, 2412], [71, 15, 578, 19080, 19081, 1], [1017, 6, 21, 84, 1096, 858, 7284, 216, 362, 52, 407, 28, 2434, 425], [40, 599, 33, 157, 4, 413, 56, 558, 18, 425], [92, 2, 115, 111, 258, 4, 19082, 8, 8672, 184, 6, 1, 2195, 15, 8114], [4, 1990, 12, 329, 83], [19083, 19084, 4780, 116, 2, 544, 95, 3395, 17, 131, 3001, 15, 19085, 57, 17, 370, 19086, 4102, 6007], [31, 2, 252, 598, 19087, 88, 52, 415, 12, 37, 33, 628, 15, 11, 4, 5246], [13, 19088, 91, 85, 78, 1, 255, 2675, 6, 261], [15, 204, 17, 38, 1, 86, 7, 33, 426, 36, 41, 2, 702, 481, 914, 7, 36, 48, 2, 9], [112, 25, 1585, 31, 42, 405, 4, 866, 42, 146, 433, 7, 83, 42, 29, 110, 28, 6, 167, 15], [38, 10, 77, 29, 262, 17, 108, 3, 33, 2974, 3, 29, 262, 166, 1, 426, 3, 29, 67, 50, 262, 166, 25, 38, 3, 717], [53, 773, 416, 303, 60, 19089, 348, 740, 82, 10, 1319, 53, 36, 29, 5211, 3094, 340], [2, 1304, 16, 5877, 4034, 19090, 8340, 4397, 1219, 8673, 19091, 2, 414, 7, 62, 162, 40, 67, 6], [3, 62, 97, 228, 1806, 42, 338, 17, 21, 93, 34, 19, 76, 90, 30, 9, 1059], [1153, 57, 310, 42, 41, 55, 1482, 158], [31, 42, 65, 93, 11, 4954, 8, 963, 92, 3, 62, 7, 24, 132, 785, 60, 45], [3454, 46, 172, 43, 1, 27, 2369, 2369, 11, 50, 971, 288, 23, 19092, 4, 19], [10, 1246, 90, 4, 3489, 19093, 4781, 3, 41, 51, 4, 967, 19094, 40, 208, 35, 3, 157, 7, 1, 18, 21, 4, 4349], [5147, 7592, 700, 41, 4, 9, 493, 35, 21, 84, 781, 211, 4, 178, 321], [19095, 74, 790, 97, 24, 276, 113, 17, 4, 910, 100, 293, 15, 48, 288, 23, 11, 15, 149, 272, 204, 42], [1097, 7, 24, 35], [7, 3315, 665, 35, 1093, 17, 16, 7, 106, 11, 1197, 38, 3, 1807, 2, 2986, 34, 11, 10, 2145, 3, 47, 19096, 398, 2586], [356, 71, 111, 69, 114, 126, 2554, 1201, 2025, 727, 944, 49, 1120, 288, 212, 69, 137, 19097, 49, 382], [31, 10, 675, 1001, 5, 1121, 23, 370, 1272, 15, 266, 582, 361, 1375, 378, 26, 201, 49, 308, 2591, 20, 2, 24], [23, 2441, 19098, 82, 19099, 149, 284, 8, 1176, 83], [22, 1170, 11, 19100, 33, 1159, 51, 19101, 19102, 123, 1824, 19103, 160, 527], [1208, 13, 584, 108, 1, 53, 128], [4021, 1], [23, 48, 72, 40, 2, 659, 34, 50, 443, 1691, 16, 5636, 12, 285], [71, 239, 9, 58, 3, 44, 2268, 1701, 523, 709, 709, 709, 709, 26, 26], [3, 29, 279, 59, 283, 9, 14, 173, 15, 27, 36, 148, 653], [556, 167, 22, 1, 27, 2, 402, 16, 3451], [482, 3051, 19104, 17, 584, 238, 430, 2, 19105, 482, 584, 1808, 4035, 17, 757, 15, 2, 19, 19106], [341, 1434, 715, 9], [648, 12, 2, 1], [3, 301, 2, 1, 118], [25, 359, 18, 4, 247, 334, 247, 681, 287, 27, 19, 56], [58, 3, 375, 2, 178, 404, 1429, 6, 117, 215, 850, 51, 232, 1330, 7, 192, 2, 1145], [38, 3, 309, 114, 10, 3974, 6, 4, 489, 37, 1, 63, 987, 18, 15, 23, 157, 4, 501, 108, 11, 4008], [4777, 9, 10, 915, 33, 440, 36, 152, 14, 223, 21, 1313, 19107, 4777, 422, 4777, 9, 23, 1808, 483, 19108, 951], [933, 2414, 2576, 483], [53, 53, 5120, 1329, 2374, 19109, 7, 1, 12, 2, 2944], [2314, 3745, 28, 79, 98, 674, 782, 317, 13, 15], [25, 14, 11, 20, 1253, 13, 26, 14, 18, 186, 13, 19, 1, 107, 18, 25, 678, 68, 5, 223, 14, 898, 74], [3, 210, 349, 1, 11, 2949, 2119, 10, 915, 487, 1800, 4, 19110, 207, 874, 27, 4, 4782, 18, 4, 108], [19, 129, 20, 3014, 24, 122, 6, 28, 60, 127, 24, 103, 450, 5, 35, 27, 43, 24], [19111, 4, 286, 54, 16, 95, 36, 43, 1363, 1183, 5, 51, 358, 3414, 7220, 3360, 29, 253, 5, 5724], [75, 442, 5, 1, 258, 22, 19112, 19113], [22, 12, 85, 159, 925, 12, 98, 4429], [1542, 58, 5, 156, 255, 19114, 149, 23, 542, 21, 20, 4008, 1], [3, 210, 61, 329, 38, 3, 192, 81, 6, 5, 3, 363, 329, 38, 3, 302, 20, 1, 30], [38, 5, 11, 2, 775, 507, 8, 97, 234, 9, 107, 459, 43, 162], [118, 5, 45, 18, 2, 1, 31, 40, 191, 5, 13, 7, 4574, 4626, 1002, 151, 114, 10, 138, 8, 61, 2247], [3, 29, 197, 21, 2741, 1002, 4, 1803, 16, 2, 112, 91], [2, 320, 16, 78, 9, 322, 444, 2, 25, 19115, 7, 19116], [3, 29, 279, 71, 209, 24, 3, 28, 3, 96, 41, 6, 1429, 10, 5991], [3, 454, 71, 239, 16, 78, 9, 41, 19117, 352, 2050, 2492, 8, 19118], [31, 5, 41, 6, 44, 155, 9, 5, 94, 5, 2, 669, 2400], [19119, 1652, 136, 37, 239, 56, 2153], [186, 9, 33, 511, 1, 67, 6, 262, 74, 706, 32, 921, 9, 23, 122, 6, 19, 19120], [38, 5, 192, 13, 2, 9, 5, 29, 109, 13, 140, 40, 134, 5, 4, 24, 18, 2, 2447, 19121], [2896, 1522, 23, 152, 345, 155, 106, 43, 1], [19122, 137, 79, 16, 19123, 3963, 56, 81, 11, 4, 1858, 4, 19124, 103, 58, 4, 763], [19, 27, 76, 9, 10, 25, 3464, 3, 90, 15, 124, 6, 14, 170, 26, 91, 965], [832, 1380, 1], [104, 3, 47, 11, 4, 489, 8, 116, 47, 22, 93, 541, 83, 7952, 124, 1052, 1022, 1000, 3, 47, 1075], [642, 46, 868, 27, 39, 1928], [243, 187, 558], [77, 3, 62, 5, 41, 9, 17], [4011, 177, 56, 92, 34, 23, 48, 152, 208, 13, 3, 105, 4596, 7, 8544], [241, 5, 210, 167, 17, 1567, 1567, 160, 1, 69, 41, 167, 11, 4, 3447], [241, 5, 346, 19125, 19126, 69, 41, 1568, 11, 4, 231], [477, 135, 1, 359, 18, 36, 836, 34, 14, 3887, 7538, 38, 36, 1, 359, 895], [22, 1, 51, 197, 223, 70, 17, 491, 50, 235, 102, 50, 172, 833], [80, 558, 1192, 34, 5, 96, 183, 9, 242, 35], [3, 63, 448, 2, 406, 16, 6167, 51, 13, 473, 11, 4, 561, 8, 4, 141, 25, 103, 443, 8, 800, 7, 9], [53, 31, 5, 46, 133, 7, 1012, 178, 24, 25, 242, 35, 19127, 1190], [8674, 1283, 438, 27, 80, 91, 83], [14, 7358], [38, 814, 41, 473, 74, 688, 9, 155, 68, 16, 76, 94, 50, 91, 73, 19128, 85, 5, 29, 44, 352, 27, 76, 727, 7509, 160], [37, 3, 424, 2, 2472, 406, 27, 170, 8, 52, 672, 32, 4, 348, 3, 216, 34, 52, 4, 154, 774, 26], [26, 78, 1, 1551, 192, 2470], [9, 64, 4606, 166, 9, 6011, 7, 71, 5, 2004, 62, 69, 14, 19129], [10, 175, 407, 109, 59, 350, 34, 31, 4, 845, 1023, 88, 3855, 7, 1, 35, 8, 255, 254], [7, 10, 1], [19130, 19131, 10, 436, 12, 2, 7986, 5977, 8675, 1281, 18, 27, 20, 3354, 11, 50, 5774, 8, 94, 236], [321, 20, 48, 2, 5509, 5, 19, 27, 17, 38, 5, 8, 97, 1, 173, 15], [94, 4, 4896, 7, 162, 4, 1280, 12], [504, 90, 76, 1565, 1], [71, 705, 20, 1, 103, 262, 246, 25, 38, 40, 214, 51, 5], [3, 90, 38, 111, 86, 23, 214, 74, 611, 149, 23, 48, 8676, 336, 23, 1397, 83], [23, 497, 73, 19, 34, 151, 96, 227, 35, 18, 174, 1, 30], [535, 2, 1662, 19132, 89, 1, 957, 2882, 429, 19133, 3, 29, 134, 2, 1561, 273, 5, 23, 2, 1080], [237, 186, 990, 32, 106, 47, 38, 79, 54, 19134, 9, 30, 21, 359, 18, 50, 1197, 1214, 27, 60, 5920], [186, 865, 12, 3275, 20, 614, 6, 175, 36, 87, 610, 865, 21, 9, 58, 1123, 54, 21, 1123, 54, 32], [32, 4, 455, 1, 49, 28, 543, 6, 4, 1189, 55], [549, 30, 1487], [15, 422, 6, 56, 19135, 3, 745, 297, 245, 7425, 408, 301, 6066, 74, 3068, 2018, 5630, 19136], [43, 352, 1, 3, 101, 67, 4, 833, 1, 26], [1176, 83], [47, 284, 59, 876, 41, 6, 62, 876, 40, 47, 2, 83, 1559, 3860, 123, 10, 19137], [22, 1262, 18, 20, 373, 45, 12, 21, 4, 942], [1967, 114, 2, 1306, 33, 6, 19, 80, 1], [34, 19138, 464, 78, 9, 12, 3458, 29, 19, 137, 19139], [3, 79, 32, 287, 1, 28, 129, 15], [491, 15, 18, 50, 19140, 4, 1, 87, 2, 19141, 8677, 50, 30], [3, 1025, 35, 27, 2, 3293, 977, 23, 587, 158, 103, 14, 2989, 37, 2996], [377, 197, 2465, 4770, 2953, 1938, 1581, 503, 8386, 204, 38, 19142, 859, 8487, 6016, 1188], [17, 58, 5, 506, 245, 7187, 1366, 2904, 50, 2958, 212, 49, 1682, 8442, 56, 558, 17, 19143, 444, 3332, 4005, 17], [55, 3, 29, 87, 923, 6, 472, 13, 2, 1989, 3, 62, 2542, 744, 12, 246, 19144], [37, 36, 398, 47, 506, 24, 8, 58, 1751, 612, 8, 36, 976, 54, 37, 36, 157, 922, 166, 18, 1626, 110, 464, 4], [9, 59, 6, 912, 136, 1981, 2486], [38, 20, 280, 191, 21, 2, 227, 38, 5, 59, 6, 28, 60, 24], [5, 44, 43, 1179, 71, 239, 348, 446, 5, 103, 28, 3, 5, 3436, 137, 27, 10, 343, 74, 2650, 10], [345, 1132, 283, 345, 13, 5, 200, 38, 803, 4634, 2364, 1108, 49, 2353, 6, 114, 829, 16, 654, 8324], [3918, 19145, 4, 19146, 1086, 8678, 16, 90, 1, 99, 203, 6, 28, 11, 19147, 930, 5855, 26], [177, 363, 843, 74, 557, 51, 159, 19148, 6858, 48, 1176, 149, 32, 159, 502, 54, 47, 109, 93, 1468, 8, 123, 19149], [318, 44, 2, 165, 1180, 31, 66, 157, 60, 56, 63, 54, 1271], [370, 1, 15, 114, 127, 130, 1640, 6, 257, 307], [7, 136, 388, 2290, 32, 129, 15, 649, 551, 63, 168, 8155, 6, 28, 142], [32, 78, 252, 7, 33, 443, 22, 12, 2, 104, 251], [105, 1690, 103, 19150, 52, 12, 2, 4962, 386, 16, 2, 1], [3, 63, 175, 296, 29, 1181, 19151, 8, 10, 500, 223, 1411, 17, 72, 3518, 1, 25, 1181, 4393, 7819], [15, 19152, 17, 71, 111, 81, 4, 19153, 56, 59, 19154, 88, 227, 224, 8, 14, 19155, 251, 111, 415, 58, 15], [679, 19156, 19157, 70, 3947, 2348, 883, 2, 414, 395, 16, 207, 8, 3953, 69, 3993, 73, 19158, 26], [19, 144, 19159], [2, 202, 91, 191, 17, 2398, 120, 177, 58, 5, 13, 4707, 3522, 3, 452, 168, 7, 324, 19160, 3, 121, 6274, 12, 2, 1961], [60, 202, 189, 51, 10, 261, 191, 31, 116, 220, 207, 8679, 11, 4, 19161, 1360, 862, 91, 5, 63, 168, 245, 8679, 5], [57, 409, 16, 387, 4031, 58, 388, 287, 168, 19162], [287, 733, 7, 19163, 12, 1923, 367, 2774, 1, 5, 204, 15, 27, 3918], [85, 134, 2, 1, 97, 548, 38, 40, 516, 44, 2, 5047], [49, 5, 1748, 4309, 140, 20, 2, 2143, 315, 187], [286, 447, 3, 29, 62, 57, 329, 596, 4, 3211, 7, 64, 39, 5400, 9, 37, 148, 5810], [36, 198, 14, 1811, 16, 4353, 151, 14, 419, 21, 164, 230, 3, 19, 596, 2, 530, 104, 30, 120, 720], [2, 2216, 492, 2, 9, 33, 756, 11, 4, 2535, 6, 492, 39, 9, 2042], [128, 4379, 1], [3, 67, 6, 338, 34, 52, 121, 52, 47, 61, 6, 119, 10, 24, 160, 92, 23, 1491, 6, 61, 8, 338, 10, 534, 771, 27, 170], [583, 52, 210, 33, 79, 76, 1, 82, 57, 3, 222, 94, 15, 65, 13, 1974, 273, 4, 1816, 19164, 5, 1, 188], [19165, 6559, 154, 419, 12, 248, 50, 1943, 19166, 3533, 8, 5850, 44, 6, 134, 15, 35, 8, 61, 878, 20, 265, 8, 1105], [4, 540, 5, 79, 847, 2, 269, 12, 140, 5, 724, 52, 47, 48, 20, 207], [1379, 44, 9, 1110, 5, 5, 96, 2, 161, 1590], [71, 133, 60, 16, 5, 1, 14, 287, 21, 3072], [1, 28, 423, 27, 99, 209, 747, 126, 685, 871, 7245, 3357, 18, 186, 8, 610, 34, 564, 8, 291, 73, 19, 3], [38, 217, 316, 35, 20, 166, 9, 11, 580, 16, 482, 26], [27, 20, 1, 7471], [38, 5, 238, 28, 1, 18, 6434], [5475, 306, 215, 264, 3, 47, 187, 491, 38, 5, 262, 17, 59, 2902, 19167, 370, 3, 210, 28, 108, 6, 5, 444, 43], [46, 783, 15, 20, 24, 532, 13, 19168, 6067, 769], [5340, 6, 908, 19, 177, 339, 1], [105, 297, 2, 25, 28, 528, 51, 38, 52, 41, 84, 959, 108, 8, 15, 47, 98, 2, 18, 7, 83], [40, 363, 32, 4, 193, 6, 337, 5111, 33, 6, 114, 2, 2258, 327, 3, 90, 5, 9, 26], [31, 40, 136, 463, 62, 10, 226, 48, 10, 8624, 11, 50, 1618, 5, 62, 40, 2, 9], [39, 9, 109, 46, 334], [38, 32, 80, 9, 167, 5, 35, 51, 143, 199, 7398], [434, 761, 16, 57, 15, 109, 13, 6, 14, 2, 2691, 19169, 51, 4, 2691, 849, 11], [48, 173, 19170, 6, 1268, 39, 1, 74, 8605], [80, 1, 12, 1192, 1151, 10, 1, 2, 3119], [2297, 77, 41, 7, 2263, 24], [203, 319, 2723, 5867, 309, 615], [1638, 3265, 80, 1, 27, 17, 947, 3265, 7, 5114, 27, 17], [19, 25, 1, 91, 23, 168, 6, 15], [1, 14, 1494, 11, 3389, 940, 81, 59, 296, 346, 19171, 576, 1, 5, 346, 1851], [23, 11, 80, 689, 151, 700, 19, 80, 9], [197, 18, 7588, 451, 14, 11, 2851, 738, 153], [60, 16, 5, 9, 37, 339, 3, 44, 6, 421, 15, 142, 6950, 1907], [631, 24, 70, 4, 138, 1878, 54], [1, 14, 13, 8417, 10, 548, 1041, 371, 19172, 3, 64, 5, 19173, 1, 427, 7, 225], [800, 31, 5, 94, 2, 590, 9, 18, 20, 19174], [3, 75, 1181, 43, 1565, 812], [77, 27, 93, 24, 49, 2201, 123, 3364, 15, 2, 488], [556, 70, 2, 863, 420, 125, 2, 1, 1997, 66, 398, 223, 14, 344, 358, 73, 40, 58, 827, 3, 273, 136], [3, 380, 15, 431, 6, 33, 294, 224, 27, 97, 815, 54, 11, 2, 19175, 503, 4564, 31, 39, 9, 46, 1070, 71, 63, 3], [31, 3, 94, 2, 1, 294, 224, 255, 57, 1350, 124, 18, 272, 1071, 2, 815, 8, 9, 3, 1038, 5, 6, 28, 214, 66, 63, 290, 2763], [112, 25, 63, 806, 8680, 1581, 245, 1, 74, 245, 25], [19176], [77, 131, 9, 224, 8, 227, 35, 34, 223, 3709, 4, 45, 6618], [286, 19177, 31, 2, 1, 124, 538, 21, 50, 373, 148, 481, 40, 452, 255, 7, 45, 11, 5796], [108, 11, 4, 1080, 28, 554, 47, 2, 180, 799, 92, 39, 1, 28, 554, 26, 15, 13, 1378, 499, 154, 53], [101, 24, 25, 452, 19, 27, 2, 418, 31, 40, 136, 3070, 19178], [38, 5, 86, 5, 19179, 1, 5, 19180, 26, 3, 62, 4, 3544, 3, 3385, 3, 3385, 3, 3385, 5, 62, 7, 3, 3385, 3, 3385, 3], [3, 195, 414, 465, 17, 83], [19181, 1217, 102, 2, 3948, 1372, 226, 2393, 36, 29, 196, 45, 6, 5, 1046], [5683, 805, 5, 2, 104, 31, 5, 182, 2503, 2, 1888, 3401, 26, 424, 20, 1286], [9, 14, 44, 1313, 1074, 1548, 8, 445, 2035, 16, 19182], [68, 93, 77, 12, 783, 2, 1721, 1, 903], [28, 5213, 5, 19, 24], [28, 5213, 8, 137, 17, 23, 5294, 1], [38, 40, 113, 5, 1993, 1420, 68, 16, 20, 6136, 26, 5, 428, 58, 15], [1734, 19183, 506, 2, 1, 54], [800, 6, 492, 2, 171, 1], [219, 278, 64, 6, 271, 8, 1858, 34, 20, 2, 966, 1], [18, 22, 115, 19184, 1682, 11, 19185, 19186, 2790, 440, 263, 21, 7, 19187, 11, 4, 2623, 160, 651, 10, 651, 160, 2208, 188], [4, 395, 3297, 12, 173, 180, 517, 1], [4833, 855, 193, 236], [38, 166, 77, 255, 1493, 36, 65, 342, 26, 4264, 34, 38, 3, 255, 76, 3, 65, 13, 2, 2005, 16, 2, 692, 3880, 69, 725], [583, 37, 4, 4756, 191, 50, 6, 791, 170, 8, 40, 605, 4, 166, 189, 117, 11, 580, 16, 50, 1395, 30, 1, 26], [22, 12, 37, 4344, 1321, 658, 466, 12, 21, 4, 95], [19188, 27, 10, 1], [66, 146, 14, 5056, 27, 2, 697, 6121, 19189, 356, 26, 48, 99, 7029, 62, 71, 6, 7920, 14, 93, 51, 352, 34, 48, 2, 282, 1188], [25, 109, 49, 4, 154, 1150, 1], [74, 3044, 16, 251, 42, 158, 26, 174, 451, 2968], [31, 40, 182, 132, 18, 2, 489, 4720, 40, 2, 282], [309, 528, 3053, 4236, 382, 5801, 91, 642, 2386, 496], [884, 175, 182, 5109, 2657, 2081, 6, 372, 529, 382, 1457, 11, 2, 419, 175], [702, 7614, 1193, 34, 159, 824, 33, 3908, 8, 8562, 5243, 6, 5640, 946, 755, 11, 7613, 19190, 26], [8565, 19191, 19192, 3627, 19193, 382, 8681, 278, 8, 1392, 446, 16, 19194], [38, 1, 122, 6, 14, 356, 188, 7, 28, 5, 257, 35, 112, 705], [271, 242, 39, 9, 4177], [44, 6, 61, 27, 4, 1650, 433, 6, 20, 619, 6068, 11, 7, 7812], [31, 3, 311, 32, 10, 9, 102, 21, 42, 26, 66, 139, 533, 5, 1632, 17, 60, 154, 9, 19195], [68, 115, 127, 444, 4214, 15, 103, 628, 17, 11, 4, 2723, 219, 14, 542, 21, 4, 2178, 66, 103, 631, 305], [3465, 3466, 6014, 31, 40, 113, 17, 6, 61, 262, 10, 166, 9, 34, 40, 68, 16, 10, 9, 58, 3, 176, 262, 50, 26], [7, 45, 21, 4, 95], [242, 35, 9, 30, 25], [85, 5, 1465, 5740, 5, 9, 30, 25], [1, 2815], [55, 91, 1, 242, 4, 19, 5921], [55, 91, 1, 2815, 23, 2141, 1267], [55, 85, 5, 238, 14, 1744, 277, 1], [91, 22, 9, 2056, 271, 114, 32, 115], [286, 447, 1], [19196, 3486, 655, 6, 28, 565, 7, 25, 124, 6669, 204, 648, 12, 2, 1], [77, 29, 100, 2, 252, 557, 5, 13, 2, 190, 3473, 5, 49, 2, 1106, 3473], [48, 2, 68, 3454, 105, 486, 2, 1, 51, 2, 19197, 2341, 1009], [38, 217, 800, 2, 1, 3, 90, 6041, 10, 1747], [4, 180, 1, 11, 4, 108, 16, 2, 1143, 16, 77, 12, 1370, 73, 4, 19198], [736, 422, 5, 41, 2, 446, 116, 116, 118, 14, 625, 1, 3786, 8, 3246, 1926, 7, 25, 2812], [296, 90, 7, 9, 19199, 26, 22, 45, 1144, 17, 35], [10, 586, 12, 2, 9, 19, 170], [25, 5756, 26, 1, 12, 99], [8682, 26, 288, 23, 51, 15, 162, 136, 223, 4, 180, 19200, 3004], [7177, 245, 837, 122, 6, 19201], [15, 2, 8683, 2, 8684, 2407, 19202], [78, 9, 87, 6, 28, 54, 2760, 116, 37, 209, 127, 6, 164, 130, 14, 2, 172, 5468, 61, 28, 5948], [19203, 101, 186, 25, 279, 133, 1031, 285, 76, 473, 25, 3, 19, 225, 46, 19204], [4456, 19205, 41, 1695, 8, 88, 36, 4404, 170, 4, 727, 244, 4413, 2, 158, 75, 176, 2, 401], [14, 2, 158, 427, 2, 207, 15, 2, 654, 16, 453], [1504, 11, 4, 179, 15, 2, 158, 28, 565, 129, 3914], [1489, 31, 174, 1388, 1544, 46, 19206, 65, 11, 4, 2772, 51, 4, 171, 1], [5, 63, 303, 1778, 545, 19207, 189, 71, 78, 1, 276, 2624, 1090, 125, 1357, 1013], [4611, 6009, 21, 8685, 1546, 2249, 2651, 1344, 1453, 6, 114, 54, 360, 56, 1188], [305, 1129, 95, 160, 4, 732, 1582, 1935, 160, 12, 98, 19208, 2475, 1875, 4838], [1108, 67, 6, 1316, 522, 4476, 82, 4, 807, 600, 1913, 8686, 19209], [2, 1815, 3582, 1470, 19210, 7, 1, 11, 488, 14, 3882], [8267, 8268, 136, 19211, 19212, 678, 134, 50, 268, 511, 207, 8687, 68, 387, 12, 875, 4, 166, 12, 4729], [4, 3470, 3951, 6, 874, 16, 978, 353, 220, 2647, 157, 116, 37, 7, 4, 874, 222, 14, 4239, 82, 1503, 1308], [3, 94, 5, 1411, 17, 282], [74, 181, 149, 31, 5, 448, 5, 592, 170, 1252, 73, 219, 25, 69, 448, 718, 6, 94, 31, 2, 25, 1887, 19213], [15, 105, 59, 4, 9, 52, 1182, 15, 156, 59, 4, 488, 7, 52, 1182, 39, 9], [1322, 270, 2, 368], [29, 28, 20, 1277, 11, 2, 19214, 33, 114, 76, 102, 8, 100, 10, 1200, 1717, 224, 11, 20, 24, 7334], [200, 7, 1, 182, 28, 54, 16, 8688, 193], [31, 814, 132, 464, 57, 289, 132, 539, 5, 118, 44, 227, 173, 2, 2536, 1, 123, 92, 34, 23, 8631, 26, 394], [57, 15, 13, 14, 2, 587, 548, 187], [3, 87, 10, 24, 672, 92], [80, 779, 37, 179, 40, 168, 2390, 971, 73, 5794], [3665, 173, 269, 904, 6, 563, 19215], [4000, 8, 5653, 8075, 18, 39, 9, 41, 17, 759, 11, 4, 1672, 482, 86, 16, 17, 19216, 6069, 3425, 383], [116, 101, 68, 482, 51, 4, 450, 16, 4, 921, 149, 40, 498, 21, 17, 2186, 5, 166, 283], [7, 24, 37, 631, 40, 146, 1015, 6537, 113, 10, 624], [3, 29, 279, 69, 2598, 216, 7, 323, 21, 15, 96, 56], [477, 187, 225, 46, 80, 115], [336, 3, 90, 120, 111, 92, 371, 52, 65, 13, 2, 391, 3, 86, 52, 33, 450, 2331], [1029, 16, 910, 39, 9, 4, 910], [933, 111, 2464, 44, 434, 19217, 1970, 70, 15, 2245, 6, 3587, 4, 4365, 16, 2, 437, 88, 4117, 254], [3299, 392, 16, 39, 409, 319, 291, 1], [31, 40, 156, 132, 2, 391, 40, 2, 19218, 43, 193, 224, 760, 50, 250, 106, 119, 874, 29, 114, 50, 19219, 1517], [946, 74, 309, 1], [2403, 61, 81, 6, 174, 9, 371, 42, 29, 131, 262, 108, 163, 1931], [4118, 363, 82, 373, 2105, 6, 373, 1820, 8, 560, 364, 12, 7, 2543, 58, 1226, 2, 521], [38, 5, 94, 2, 1, 25, 1411, 5], [584, 8270, 903, 100, 17, 14, 2, 9, 11, 5772], [19220, 903, 6, 468, 68, 231, 3353, 6, 4, 19221, 1453, 16, 2, 19222, 8689, 19223, 1, 41, 19224], [2237, 9, 46, 2395, 903, 287, 16, 22, 979, 2053, 14, 8245], [38, 20, 310, 568, 102, 11, 521, 8, 4, 826, 72, 4764, 7, 56, 2235, 34, 15, 2, 323, 82, 20, 1523, 903, 26], [39, 1, 12, 3953, 54, 135], [317, 109, 65, 108, 51, 126, 19225, 60, 184, 33, 65, 165, 11, 4, 56], [78, 109, 772, 2, 1369, 1164, 206, 25, 6, 96, 742, 59, 999, 9, 8, 204, 84, 639, 336], [186, 57, 22, 196, 3, 107, 1524, 11, 4, 264, 106, 1002, 376, 32, 115, 9, 32, 1477], [93, 24, 46, 19226, 5757, 318, 1571, 5, 35, 6, 455, 9, 82, 234, 19227, 7, 101, 196, 5, 28, 19, 127], [20, 24, 456, 48, 429, 1368, 34, 23, 419, 26], [2391, 546, 973, 18, 4, 1352, 13, 2, 19228, 53, 379, 1095, 274, 510, 344, 21, 4, 952], [15, 12, 19229, 6773, 114, 2, 65, 51, 60, 19230, 56, 2481], [1775, 2525, 12, 48, 2, 5380, 15, 2, 8690], [31, 2, 77, 75, 70, 2, 2496, 4006, 6, 438, 5, 74, 48, 113, 7, 1, 6, 543, 19231], [31, 97, 77, 1390, 4, 24, 230, 61, 54, 27, 50, 77, 256, 2625], [29, 122, 99, 19, 27, 17, 26, 41, 2, 937, 8, 268, 1, 140, 3, 103, 113, 76, 8493, 3, 1373, 3, 103], [19232, 601, 5, 33, 87, 2, 1029, 6, 1512, 2, 19233, 1802, 1072, 27, 19234, 2078, 5292, 26], [226, 10, 386, 19235, 3077, 16, 4, 673, 12, 4, 1064, 237, 629, 289, 182, 297, 11, 10, 1119, 1068], [4, 19236, 19237, 47, 2, 2934, 445, 73, 15, 2430, 201, 5720, 574, 26, 3086, 378, 16, 4, 19238, 26, 19239], [345, 204, 17, 27, 739, 7, 24, 345, 21, 547], [41, 39, 9, 18, 10, 138, 13, 4363, 7561], [65, 179, 34, 15, 197, 26], [1670, 12, 37, 342, 13, 65, 51, 170, 32, 1110, 140, 52, 41, 354], [32, 1, 8259, 5, 33, 146, 3317, 15, 152, 582, 37, 38, 15, 277, 1627, 505, 19240], [326, 227, 173, 1034, 22, 1608, 65, 57, 814, 1, 44, 328, 6, 2012], [38, 5, 8, 20, 177, 2048, 2, 9], [38, 5, 122, 6, 113, 2902, 7, 2673, 451, 47, 56], [4371, 47, 2, 9, 1062, 40, 41, 1457, 444, 40, 47, 542, 6, 1385, 142, 27, 6056, 6057, 69, 122, 492, 50, 37, 239, 2586], [6004, 48, 19241, 8691, 9, 4306, 2287, 2, 1142, 255, 2, 6004, 26], [69, 502, 22, 1, 7, 209, 4593], [38, 25, 67, 1, 13, 2684], [71, 933, 111, 19242, 683, 1011, 82, 4, 237], [9, 9, 46, 777, 34, 319], [3, 90, 38, 111, 86, 23, 214, 74, 611, 149, 23, 48, 8676, 336, 23, 1397, 83], [20, 1242, 16, 17, 12, 2711, 1555, 1], [14, 54, 135, 290, 1, 13, 15, 1899], [1241, 54, 16, 865, 8, 3, 41, 10, 19243, 1, 14, 13, 3799, 20, 518, 378, 13, 4, 19244, 8692], [219, 116, 19245, 368, 8, 116, 463, 63, 65, 21, 7, 1400, 8573, 34, 5, 266, 258], [2252, 377, 639, 69, 67, 6, 14, 250, 275, 19246, 12, 19247, 247, 67], [32, 2397, 25, 58, 12, 477, 6, 19248, 8, 19, 166, 25, 1, 288, 122, 6, 555, 18, 6, 126, 373, 27, 43, 169, 98], [29, 572, 17, 140, 5, 86, 2, 448, 12, 59, 19249, 191, 307, 13, 2, 5896, 5, 4612, 30, 83], [3, 90, 38, 104, 81, 45, 18, 135, 88, 572, 17, 37, 3, 75, 8167, 1, 3, 103, 1053, 5, 2, 3210, 27, 10, 1680, 98], [25, 28, 791, 8, 192, 5740, 419, 1, 251, 5, 1, 67, 1166, 8, 4014, 438, 8, 96, 419], [237, 821, 182, 4, 19250, 12, 1624, 159, 3138, 573, 1991, 19251, 26], [482, 61, 262, 20, 9, 17], [38, 133, 473, 1, 41, 612, 8, 299, 16, 2, 540, 6, 70, 36, 520, 708, 76], [22, 1, 1256, 541, 13, 4, 1450, 3468], [680, 1], [53, 10, 24, 1015, 1978, 53], [53, 15, 1310, 29, 14, 2, 6172, 475, 59, 14, 1459, 53, 290, 17], [19252, 2, 1, 80], [39, 1, 37, 19253], [3363, 21, 4, 9, 2194, 21, 4, 77, 6070, 21, 4, 2937, 839, 311, 21, 4, 659, 4783, 21, 4, 1383, 43, 6071, 43, 725], [29, 62, 71, 5, 232, 408, 477, 6, 5189, 155, 1477, 1064, 19254, 33, 4019, 1528, 1528, 1528, 3710, 2099, 163], [10, 1, 611, 541, 13, 2, 3044, 16, 356], [38, 5, 134, 32, 97, 9, 35, 21, 7, 68, 77, 8, 15, 29, 197, 54], [31, 2, 25, 122, 6, 1099, 11, 10, 1, 19255], [39, 1, 157, 126, 931, 11, 22, 19256], [22, 81, 2568, 19257, 483], [38, 2, 89, 1, 191, 5, 6, 107, 129], [38, 5, 8, 20, 177, 2048, 2, 9], [38, 20, 310, 568, 102, 11, 521, 8, 4, 826, 72, 4764, 7, 56, 2235, 34, 15, 2, 323, 82, 20, 1523, 26], [321, 52, 1014, 7, 1], [155, 106, 1364, 1, 107, 18], [22, 265, 857, 41, 4, 24, 211, 7, 178], [354, 1448], [18, 3884, 4, 120, 56, 234, 16, 17, 12, 7432], [38, 2, 1, 191, 6, 119, 20, 809], [84, 466, 4465, 112, 287, 58, 22, 26, 8, 112, 104, 100, 240, 58, 4059, 251], [2, 9, 101, 279, 59, 4, 92, 4, 1152, 12, 8543], [6, 28, 27, 2, 9, 5, 33, 87, 6, 14, 342, 44, 4020, 472, 20, 30, 102, 19258, 74, 81, 2, 93, 1537], [1050, 8693, 906, 2052, 6, 382, 3015, 8694, 2807, 11, 5510, 160, 26], [75, 134, 39, 9, 2, 1435, 218, 1930, 122, 6, 114, 1634], [15, 10, 646, 696, 1], [297, 39, 25, 468, 15, 32, 129, 2, 339, 1], [22, 1, 33, 1807, 10, 314], [1192, 1151, 1020, 35, 1315, 8, 42, 67, 6, 81, 59, 305, 575, 2161, 1315, 1, 242, 35, 66, 146, 351, 22, 25, 250], [221, 80, 504, 2, 83, 3, 293, 40, 41, 4, 19259], [53, 7, 1, 131, 609, 10, 262, 304, 634, 40, 28, 102, 197, 53, 1787, 22], [1293, 19260, 123, 4, 440, 12, 8282, 597, 35, 69, 49, 5, 61, 201, 442, 159, 2244, 8, 8548, 74, 3703, 64, 8, 1327], [2364, 12, 1135, 123, 120, 19261, 36, 156, 28, 2, 664, 6, 58, 126, 537, 197], [3843, 8671, 16, 39, 9, 14, 365, 315], [695, 4340, 38, 1, 94, 2, 19262, 27, 2, 53, 175, 18, 4, 909], [3454, 57, 5927, 1, 216, 22], [4, 1357, 4298, 4006, 4, 815, 49, 56, 74, 48], [219, 116, 511, 808, 19263, 19264, 8, 307, 289, 156, 2467, 642, 12, 1387, 377, 5091, 26], [3, 90, 2, 1, 147, 208, 13, 2, 916], [66, 32, 62, 2, 957, 231, 1, 226, 5098], [66, 32, 62, 2, 104, 226, 3531], [2403, 61, 81, 6, 174, 9, 371, 42, 29, 131, 262, 108, 163, 1931], [3, 64, 22, 1217, 40, 33, 13, 2574, 1, 55, 3, 29, 134, 2, 19, 20, 183, 8695, 152, 58, 59, 15], [1, 448, 32, 409, 16, 352, 1531, 327, 27, 548, 1217, 34, 100, 622, 28, 50, 11, 7, 1531, 22, 1, 733, 2], [5699, 18, 1], [3, 566, 180, 517, 1, 75, 114, 43, 26], [3094, 12, 2, 19265, 6805, 15, 1337, 6, 243, 434, 352, 1964, 5568, 8, 5933, 3971, 27, 284, 283, 8, 596], [3363, 21, 4, 9, 2194, 21, 4, 77, 6070, 21, 4, 2937, 839, 311, 21, 4, 659, 4783, 21, 4, 1383, 43, 6071, 163], [31, 5, 75, 94, 38, 5, 44, 2, 112, 414, 123, 19266, 539, 834, 8, 19267, 88, 485, 5, 58, 655, 39, 9, 26], [3953, 159, 925, 469, 1048, 19268, 930, 51, 98, 1647, 1519, 178, 11, 293, 16, 430, 2, 337, 298, 3725], [116, 12, 2, 2494, 678, 506, 19269, 7018, 21, 1245, 381, 79, 757, 19270], [31, 164, 402, 5, 2, 341, 1295, 122, 313, 15, 51, 268, 942], [38, 2976, 4, 3541, 121, 6059, 2, 554, 1, 8, 113, 10, 228, 3, 124, 2, 8614], [38, 19271, 121, 6278, 17, 2, 104, 149, 3, 90, 2, 887], [38, 3321, 8696, 121, 4767, 11, 10, 1783, 21, 2, 154, 2947, 3, 380, 15, 1498, 6, 72, 52, 1597, 84, 508, 21, 2, 154, 8697, 2208], [38, 2316, 121, 296, 46, 2, 1854, 34, 29, 842, 17, 2806, 12, 4, 2466, 3082, 244, 6, 28, 887, 26], [38, 2316, 121, 296, 46, 2, 1854, 34, 29, 842, 17, 2806, 12, 4, 2466, 3082, 244, 6, 28, 887, 26], [39, 9, 99, 4716], [4359, 12, 7, 2, 590, 9, 3, 532], [1362, 73, 36, 512, 2, 864, 16, 1010, 173, 4, 56], [795, 423, 82, 4, 186, 19272, 23, 61, 6, 618, 149, 3, 146, 14, 35, 51, 3219, 146, 61, 14, 2, 388, 1034, 51, 10, 263], [747, 7, 6072, 11, 20, 387, 3, 63, 94, 4, 1, 11, 5], [], [17, 306, 63, 5, 70, 17, 2, 8008, 19273, 19274, 19275, 6, 19276, 19277, 368, 306, 57, 4, 19, 200, 5, 33, 3800], [309, 981, 1, 53, 7, 939, 4340, 53], [1410, 1137, 12, 4, 697, 3876, 16, 57, 582, 38, 5, 134, 2, 564, 25, 60, 24], [3105, 568, 54, 6, 32, 4, 287, 27, 126, 45, 612, 140, 39, 322, 1, 28, 193, 99, 209, 1789, 21, 14, 342, 596], [75, 176, 5821, 21, 39, 319, 3, 62, 165], [3, 47, 542, 6, 998, 10, 1119, 610, 2565, 38, 3, 592, 54, 68, 16, 10, 798, 1562, 47, 506, 24, 18, 2789, 21, 19278, 1561], [23, 61, 6, 100, 4, 24, 54, 13, 290, 264], [2, 1387, 19279, 1112, 4, 190, 883, 16, 5258, 19280, 27, 50, 19281, 6, 1367, 50, 19282, 26], [4, 19, 3, 191, 22, 1, 31, 40, 47, 44, 2, 93, 115, 8, 4, 1, 121, 2406, 14, 6288, 23, 7525], [1004, 57, 5, 1, 72, 59, 17], [98, 1401, 21, 4, 7026, 4702, 19283, 12, 3895, 382, 111, 69, 168, 2039, 539, 19284, 188], [15, 37, 148, 341, 11, 22, 1], [26, 140, 7902, 12, 2, 19285, 8, 140, 6330, 103, 105, 168, 292, 4218, 38, 52, 63, 168, 7883], [1539, 1, 12, 33, 544, 19286, 160, 19287], [25, 2468, 13, 9, 23, 376, 205], [3, 64, 14, 334, 6, 68, 395, 19, 44, 9], [296, 46, 238, 719, 97, 347, 34, 3, 200, 119, 4, 286, 8106, 436, 887], [37, 22, 673, 63, 28, 2, 3059, 34, 3, 75, 19288], [354, 250, 5, 1717, 15, 88, 19289, 1210, 2678, 15, 5932], [168, 57, 3260, 5, 2201, 4, 1932, 118, 14, 727, 8607, 31, 43, 95, 3457, 1030, 212, 7, 3457, 4184], [1147, 47, 270, 2, 1, 1185], [19290, 6, 4, 9, 309, 21, 701], [1140, 57, 2, 666, 16, 181], [43, 1592, 59, 254, 3, 196, 15, 342, 2878, 224, 56, 63, 8, 44, 19291, 953, 177, 3590], [3, 486, 2, 434, 19292, 201, 850, 1712, 2, 848, 1247, 19293, 8, 84, 1313, 1164, 206, 386, 41, 936, 123, 688, 918, 51, 4, 19294], [38, 5, 8, 20, 177, 2048, 2, 9], [22, 4, 296, 137, 1520, 359, 18, 77, 8, 255, 3104, 1934, 3481, 2572], [39, 2317, 940, 9, 46, 334], [3, 41, 1569, 437, 8, 4, 1, 566, 17, 79, 50, 2, 1, 37, 92, 3, 44, 19295], [8698, 77, 671, 8699, 526, 3, 64, 20, 845, 8698, 189, 671, 8699, 919, 17, 4721, 94, 42, 19, 283, 3, 188], [39, 9, 46, 334], [2344, 4, 3096, 6, 737, 2, 1], [6677, 725, 26, 151, 1071, 4, 2947, 26, 1087, 993, 50, 117, 11, 4, 24], [3, 29, 44, 98, 1074, 37, 3, 44, 6, 3969, 609, 39, 9], [66, 29, 64, 39, 9], [38, 2100, 2100, 533, 45, 26, 42, 679, 594, 50], [38, 5, 94, 2, 1, 25, 1411, 5], [2033, 1, 23, 152, 719, 20, 548], [1153, 3, 96, 194, 268, 26, 2, 470, 435, 26, 219, 4, 206, 68, 27, 159], [31, 42, 62, 71, 6, 1374, 6073, 174, 2, 89, 1], [116, 99, 209, 3093, 283, 332, 6, 107, 1117, 77, 69, 652, 6420, 685, 8, 1565, 27, 4646], [42, 63, 119, 32, 4, 2626, 5, 67, 174, 24, 96, 248], [32, 39, 104, 448, 231, 59, 6, 28, 4, 341, 753], [101, 1709, 209, 2, 1, 63, 19296], [15, 70, 4, 24, 19297, 15, 46, 10, 171, 30, 299, 7, 47, 2, 19298, 26], [32, 3, 94, 142, 10, 909, 12, 927, 120, 1], [467, 19299, 19300, 8, 119, 6074, 339, 140, 23, 2, 1677, 83], [247, 16, 39, 25, 61, 291, 21, 39, 9], [31, 20, 1252, 26, 5, 86, 245, 344, 189, 33, 67, 6, 14, 20, 19301, 5, 185], [32, 1058, 16, 39, 9, 28, 342, 21, 19, 261, 114, 21, 182, 8, 597, 17, 4, 19, 35, 22, 85, 3, 75, 397, 1188], [85, 7, 1, 541, 32, 11, 4, 347, 42, 62, 50], [43, 3, 46, 43, 1, 26, 43, 3, 46, 43, 1431], [31, 20, 61, 6, 14, 2, 1, 8, 48, 107, 6, 4, 229, 140, 60, 1130, 405, 88, 8700, 127, 6075, 712, 21, 17, 11, 7], [3, 47, 1570, 3860, 505, 26, 10, 24, 5958, 130, 2, 25, 682, 11, 4, 1444, 106], [2659, 15, 2, 1], [38, 5, 465, 2, 9, 81, 45], [3508, 31, 5, 46, 2, 9, 28, 35, 54, 10, 5990], [19302, 173, 4, 24, 18, 2, 1198, 521, 971, 19303], [31, 3, 498, 35, 6, 20, 1, 11, 39, 8013, 774, 1557, 630, 2, 419, 916], [4, 19, 5, 65, 51, 1, 3527, 5102, 19304, 173, 392, 19305, 19306, 722, 4, 19307], [826, 387, 18, 20, 373, 1010, 17, 1, 3, 101, 44, 387, 21, 143, 1010, 4357, 1278, 19308], [586, 85, 49, 20, 387, 37, 19309, 3, 366, 441, 19310, 29, 308, 6, 17, 5, 220, 345, 140, 5, 49, 2, 711], [57, 9, 205, 649], [38, 5, 672, 4, 24, 34, 2805, 86, 40, 47, 223, 113, 1311], [53, 1, 75, 28, 4, 8701, 140, 36, 44, 129, 546, 7231, 16, 1142, 19311], [78, 275, 64, 78, 2, 1699, 25, 74, 2, 865, 4138], [3, 1868, 562, 5, 3419, 27, 10, 206, 83, 23, 3419, 27, 80, 154, 1], [25, 81, 127, 130, 1, 39, 19312], [43, 25, 182, 191, 230, 52, 167, 519, 481, 914, 29, 690, 78, 557, 32, 1, 4, 199, 769, 1961], [19313, 2, 206, 261, 236, 205], [296, 293, 22, 1, 46, 2, 19314], [945, 21, 3233, 1988, 21, 2, 1, 25], [945, 21, 4, 112, 25, 1988, 21, 4, 1, 25], [2210, 39, 9, 13], [71, 4, 19, 63, 60, 111, 48, 28, 1996, 378, 18, 567, 1187, 3, 33, 41, 1474, 288, 366, 2, 172, 19315], [1829, 112, 91, 152, 176, 15, 112, 27, 84, 952, 2516, 242, 35, 23, 48, 1806, 42, 59, 166, 287, 453, 174, 624], [2560, 19316, 49, 3176, 61, 8702, 20, 24, 142, 5, 804, 1], [22, 1, 981, 2560], [53, 1230, 29, 139, 295, 34, 2, 1355, 1567, 100, 17, 578, 7, 2570, 3, 394, 42, 578, 13, 19317, 26], [268, 2935, 6, 227, 56, 173, 1278], [1697, 114, 2, 65, 51, 4, 19318, 4733, 4, 1057, 8703, 3252], [63, 756, 173, 250, 507, 1146, 31, 5, 86, 36, 103], [8311, 2205, 355, 1111, 19319, 19320, 891, 6047, 8704, 7730, 7895, 19321, 3999, 6145, 4717, 1327, 8445, 8705, 8706, 19322, 2838, 8707, 965], [404, 679, 1228, 19323], [404, 7995, 18, 2, 419, 123, 1098, 891], [26, 107, 11, 6, 637, 54, 4, 178, 135, 11, 4, 8708], [7768, 4, 4916, 16, 8643, 4635, 18, 1697, 1051, 6, 5, 123], [19324, 129, 404, 1316, 257, 4, 120, 1111, 11, 546, 4195, 19325], [2254, 6, 1098, 891, 69, 103, 192, 51, 8642, 11, 84, 4284, 8, 679, 8709, 178, 26], [2774, 8706, 7, 19326, 1095, 167, 11, 4, 3389, 12, 167, 988, 19327, 11, 84, 2184], [19328, 568, 2846, 361, 52, 1337, 102, 4, 178, 27, 2, 2102, 21, 4, 710, 344, 264, 8, 15, 7606], [28, 4, 1194, 542, 21, 225, 1537], [5705, 11, 3232, 8648, 450, 1098, 891, 637, 84, 215, 178, 11, 4440, 27, 2, 26, 26], [375, 38, 66, 19329, 98, 8709, 178, 6, 2552, 8461, 3755], [94, 97, 134, 4, 2, 19330, 1337, 11, 4, 8710, 27, 2, 2288, 337, 298], [229, 20, 608, 985, 27, 26, 5, 222, 14, 18, 4, 19331, 11, 106, 6857, 26], [4, 1994, 15, 480, 11, 8711, 11, 2552, 16, 1098, 8712], [106, 6, 1846, 11, 4, 6063], [4297, 19332, 73, 19333, 11, 2367, 19334, 8713, 19335, 4, 2580, 8, 241, 221, 250, 507, 96, 4378, 11, 4, 6063], [220, 5, 772, 393, 752, 16, 5806, 11, 84, 679, 19336], [5, 600, 345, 211, 194, 4, 1098, 891, 1401], [68, 5151, 121, 19337, 12, 8714, 412, 247, 19338, 134, 4, 232, 2, 8707, 539, 5167, 222, 1099, 6, 8705, 31, 87, 776], [15, 46, 295, 6, 311, 7, 1, 102], [3, 293, 19339, 12, 1859, 11, 2, 607, 213, 4483, 7923, 12, 1228, 7098, 21, 5217, 8, 19, 1], [202, 1, 14, 13, 6076, 3, 273, 5, 48, 6, 28, 10, 343, 8619], [22, 1, 2314, 363, 889, 3774, 473, 51, 2000], [53, 428, 3, 114, 7, 108, 5, 25, 46, 2395, 23, 334, 1154, 336, 664, 336], [88, 71, 78, 41, 135, 340, 411, 664], [3, 87, 1361, 591, 8, 2, 3932, 668, 1, 199], [139, 14, 2, 9, 37, 3, 63, 64, 5, 964], [5, 9, 46, 783, 468, 376, 129], [139, 345, 5, 24], [53, 39, 9, 46, 334, 53, 3878, 1, 40, 2, 9], [92, 2, 115, 1, 103, 990, 545, 5, 129, 256, 7, 136, 295, 6, 58, 545, 76, 1, 80, 183, 30, 407, 2, 19340, 2], [7037, 639, 39, 9], [31, 3, 124, 2, 831, 21, 155, 106, 3, 309, 18, 567, 95], [1142, 178, 144], [2116, 12, 7745, 3544, 37, 31, 2, 77, 12, 2, 9, 38, 40, 467, 40, 905, 2, 9, 2656], [151, 204, 22, 1, 43, 5191], [5, 62, 32, 39, 1, 69, 448, 327, 21, 8691, 49, 11, 4, 1306, 13, 2511, 19341, 11, 4679, 19342, 211, 52, 592, 54, 19343], [5, 519, 315, 74, 344, 29, 81, 6, 17, 1, 333], [3, 90, 38, 574, 72, 9, 652, 3462, 36, 614, 6, 14], [6231, 1], [15, 32, 2579, 18, 4, 275, 797, 1326, 7, 71, 15, 12, 27, 39, 9, 34, 4, 3052, 287, 19, 596], [53, 622, 585, 19344], [477, 6, 159, 1908, 569, 4, 910, 26, 88, 19345, 11, 4, 4408, 2964, 1714, 51, 26], [7, 80, 1, 40, 10, 1, 99], [250, 184, 3, 65, 51, 12, 57, 18, 2, 1, 995], [5, 1, 1948, 233, 78, 67, 1544, 115, 99, 148, 55], [78, 25, 46, 43, 3244, 78, 638, 60, 1928], [25, 23, 33, 429, 1361, 26, 795, 897, 5, 1743, 1, 29, 107, 51, 17], [46, 43, 169, 74, 43, 9, 11, 4, 360, 63, 1794, 15], [38, 20, 826, 157, 5, 11, 2, 1143, 27, 2, 666, 16, 144], [5, 41, 1, 8, 3, 29, 44, 25, 188, 3, 67, 350], [203, 83, 57, 50, 410, 26], [71, 1, 71], [63, 5, 2337, 2250, 80, 4586, 6, 139, 2, 1, 3069, 7597, 8, 96, 1506, 35, 7598], [3, 328, 363, 125, 2, 9, 230, 2224, 37, 69, 195, 3, 6, 1105], [1710, 2, 9, 345, 6, 622, 300, 40, 46, 6052, 102, 163, 96, 44, 2, 234, 25], [1218, 143, 199, 178, 6, 9, 13, 143, 199, 754, 169, 316, 863, 37, 66, 13, 2, 8485], [3825, 100, 2894, 9, 30, 167, 7, 292], [19346, 89, 5, 266, 167, 2, 77, 887], [463, 13, 20, 1255, 141, 4831, 2403, 1, 65, 57, 23, 119, 149, 16, 1323], [462, 477, 43, 25, 67, 6, 1385, 142, 51, 2, 379, 19347, 32, 5, 1, 345, 59, 14, 419, 92, 103, 14, 436, 11, 378], [884, 629, 5, 63, 86, 16, 408, 7, 19, 56, 2676, 14, 448, 45, 7, 65, 13, 2, 4723], [1], [2895, 286, 336, 53, 17, 8, 49, 89, 1, 107, 19, 27, 6077], [1, 103, 134, 126, 24, 6, 4, 413, 2227, 34, 266, 134, 2, 25, 2, 864, 16, 2343], [33, 140, 3, 86, 20, 595, 29, 196, 3, 67, 5, 5, 7081, 6, 10, 387, 48, 10, 548, 83], [3, 41, 169, 3, 29, 87, 42, 1], [326, 86, 3, 28, 9, 8, 86, 272, 4295, 34, 1061, 23, 11, 10, 967, 454, 133, 31, 10, 306, 70, 190, 74, 85], [25, 39, 115, 103, 294, 546, 1634, 6, 28, 60, 285], [3, 90, 38, 3920, 574, 72, 19348, 3152, 427, 112, 3920, 4799, 19, 174, 994, 2313, 8715, 5, 1, 5099, 3152, 3], [638, 303, 19349, 303, 19350, 1002, 29, 192, 22, 9, 2355], [1071, 17, 60, 1, 288, 42, 35, 116, 128, 241, 8, 2, 2758, 647, 8716, 513], [134, 17, 1058, 301, 3, 301, 3, 301, 3, 301, 5, 118, 1], [10, 56, 12, 783, 127, 130, 5], [20, 77, 555, 10, 138, 13, 2, 19351, 829, 162, 20, 1, 25, 66, 829, 50], [19352, 1, 66, 49, 4, 19353, 6289], [358, 73, 10, 1, 64, 17], [53, 3, 86, 10, 301, 510, 573, 162, 78, 90, 30, 1, 51, 2229, 19354], [6062, 704, 607, 111, 11, 1086, 7, 3, 974, 127, 130, 159, 19355, 19356, 8717], [65, 3998, 6, 400, 142, 27, 970, 642, 21, 305, 19357, 8271, 3129, 22, 1461, 236], [48, 32, 202, 77, 49, 179, 26], [23, 322, 362, 10, 1152, 500, 520, 12, 18, 135, 8718, 11, 246, 1, 19358, 23, 3952], [10, 381, 12, 152, 14, 2, 1, 8719, 21, 362, 43], [281, 1592, 15, 200, 5, 94, 32, 76, 1, 5, 124, 51, 4, 1345, 1194, 116, 220, 1709, 239], [33, 13, 5, 5, 349, 32, 76, 1345, 1], [15, 550, 19359, 23, 48, 11, 4, 179, 1046], [5, 29, 62, 485, 60, 1, 13, 2, 91, 11, 2, 5401], [251, 8, 2794, 99, 828, 56, 483, 450, 16, 761], [5, 75, 114, 43, 68, 83], [22, 8443, 1, 122, 6, 72, 40, 236, 21, 19360, 19361, 1, 19362, 181], [5, 638, 109, 86, 80, 19363, 80, 1, 2531, 3014, 80, 25, 103, 4341, 50, 2797, 163, 266, 113, 97], [85, 32, 179, 418, 146, 532, 13, 19364, 74, 7, 6078, 45, 2787, 26, 481, 197], [10, 1, 89, 40, 82, 4, 2339], [3, 75, 302, 585, 931, 3, 75, 302, 39, 5578, 3, 75, 302, 39, 9], [22, 2200], [85, 277, 357, 442, 17, 38, 3, 72, 23, 2, 2699, 19365, 369, 43, 5, 46, 9], [5, 87, 68, 4223, 149, 23, 48, 50, 1214, 5, 10, 1], [19366, 7, 37, 342, 6, 17, 258, 2, 438], [100, 17, 400, 22, 30, 18, 5, 1, 5, 8, 890, 165, 3356], [162, 364, 6509, 3316, 476, 30, 19367, 14, 4784, 9], [425, 1, 47, 3, 81, 6, 5, 34, 23, 81, 6, 5, 11, 10, 5555, 768], [969, 30, 1286, 1], [5, 132, 4, 234, 9, 526], [39, 9, 152, 14, 1985, 11, 1382, 27, 4, 24], [9, 1467, 22, 180, 335, 335, 8, 40, 41, 1203, 6, 86, 40, 165, 88, 263, 1, 44, 43, 497], [432, 14, 594, 71, 32, 5, 9, 405, 78, 879, 51, 469, 34, 38, 2, 1, 18, 20, 30, 5, 75, 465, 2, 3018, 633], [4, 231, 5, 70, 230, 5, 113, 2, 1, 59, 1227, 19368, 3, 70, 147, 231, 99, 209], [5, 185, 161, 30, 1, 3, 46, 172, 27, 19369], [53, 57, 4, 19, 47, 329, 27, 17, 86, 3, 63, 436, 22, 3106], [25, 103, 19, 1533, 93, 119, 97, 24, 88, 61, 337, 6, 36, 1, 13, 46, 45, 582], [36, 18, 2, 1, 221, 36, 67, 2, 1], [31, 42, 63, 719, 50, 40, 2, 9], [4224, 43, 446, 11, 14, 1176, 218, 2643, 9, 21, 326, 1517], [42, 1, 723], [5, 724, 3, 19, 7, 1, 8, 5, 210, 3818], [470, 78, 1, 234, 9, 8, 29, 110, 1507], [90, 6, 421, 4, 1199, 34, 42, 2238, 280, 2, 391, 2, 3545, 50, 815, 11, 4, 1444, 8, 192, 79, 1227, 1753], [47, 998, 22, 327, 444, 3, 623, 2, 2610, 11, 4, 108, 2306, 472, 13, 2, 25, 27, 8135, 18, 1, 23, 1817], [544, 38, 174, 172, 8, 50, 24, 1116, 34, 42, 44, 109, 93, 19370, 2208], [143, 1, 41, 626, 8, 487, 114, 15, 43, 1091, 34, 97, 177, 47, 19371, 972, 147, 19372, 19373, 26], [68, 334, 504, 12, 783, 127, 130, 68, 2860, 319], [3, 3850, 608, 8720, 1603, 34, 151, 105, 139, 79, 10, 228, 104], [236, 236, 236, 1, 2721, 445, 19374, 444, 8721], [3, 58, 48, 19, 27, 7, 1, 40, 2053, 176, 50, 645, 637], [29, 453, 10, 144, 30], [31, 814, 101, 297, 10, 2022, 48, 10, 618, 88, 5, 10, 9], [71, 3, 468, 22, 6511, 46, 468, 15, 5, 869, 15, 425, 6512, 238, 366, 7, 9, 6, 84, 653], [10, 779, 273, 17, 31, 2, 1, 995, 537, 50, 24, 537, 149, 97, 995, 4, 250, 184, 7, 167, 4, 591, 38, 5, 19375], [3, 75, 397, 43, 1208, 19376, 573, 761], [26, 2042, 5405, 1, 271, 67, 6, 290, 216, 76, 112, 214, 3, 81, 10, 45], [3, 90, 5, 2089, 9, 78, 41, 37, 209, 5906], [3, 90, 2141, 1], [40, 2, 89, 1, 100, 28, 6, 15, 117, 423, 26], [26, 15, 611, 149, 25, 103, 44, 2, 93, 77, 26, 58, 50, 329, 15, 332, 258, 2, 93, 1, 54, 135, 19377], [66, 491, 1], [53, 504, 14, 5994, 5055, 66, 29, 67, 4100], [19378, 125, 7, 45, 9], [24, 103, 156, 14, 10, 1988, 2207, 323, 13, 71, 58, 5, 48, 13, 2, 323, 7, 33, 72, 24, 19379, 3751, 16, 817], [151, 1053, 2, 6003, 21, 42, 9], [31, 5, 75, 119, 24, 7, 41, 343, 18, 15, 23, 48, 110, 362, 5, 109, 62, 71, 6, 119, 285], [91, 3, 33, 363, 82, 984, 160, 947, 112, 705, 3, 46, 43, 9, 4, 19, 25, 299, 22, 47], [313, 17, 2, 866, 1], [22, 1, 456, 14, 139], [9, 54, 135, 506, 24, 21, 60, 154, 3649, 5, 19380], [2, 77, 62, 38, 2, 1, 13, 50, 520], [31, 50, 24, 41, 129, 546, 481, 914, 15, 1923, 24, 101, 44, 1079, 259], [146, 119, 50, 24, 37, 93, 40, 627, 138, 107, 7335, 44, 50, 81, 6, 1227, 13, 2079, 1051, 138, 27, 170, 19381], [19382, 19383, 208, 332, 8, 32, 4, 89, 19384, 2430, 35, 6, 14, 56, 19385, 160], [4, 1104, 4, 2667, 4, 1104, 4, 9], [39, 1, 137, 18, 326, 412], [622, 9, 33, 64, 6, 2870, 365, 133, 78, 259, 18, 39, 685, 1848], [19, 1, 28, 19386], [3, 1668, 6, 19, 32, 39, 1, 48, 140, 374, 1016, 34, 140, 23, 332], [68, 91, 56, 12, 246, 91, 436], [45, 13, 22, 85, 9, 235, 14, 19, 35, 4, 67, 685, 871, 30, 575], [1763, 646, 229, 4, 1, 11, 2, 320, 16, 956, 3, 1560, 5688, 3, 1560, 204, 4169, 789, 31, 3, 47, 68, 16, 84, 1432], [3, 724, 2, 1, 11, 1197, 69, 1597, 4, 24, 21, 8722, 19387], [3, 44, 43, 9, 720, 3, 29, 87, 212, 464, 3, 87, 6, 479, 588, 108, 35], [128, 325, 1, 171, 5778], [53, 300, 6002, 183, 913, 2, 83, 52, 65, 13, 2, 8723, 8, 4411, 1223, 19388, 22, 427, 2181, 34, 3, 309, 1432], [1, 3, 29, 19, 62, 5], [1, 30, 19389, 424, 1861, 3069], [25, 14, 11, 7, 24, 13], [326, 708, 36, 6040, 27, 1983, 952, 34, 32, 4, 183, 1, 28, 554, 26, 26, 26, 26, 495, 5389], [23, 2413, 7, 60, 16, 78, 1, 28, 554, 1405, 140, 19390, 829, 26, 893, 340, 19391, 49, 2471], [31, 3, 124, 2, 831, 21, 155, 106, 3, 19, 174, 1], [3, 44, 2, 1246, 6, 86, 59, 78, 86, 23, 475, 59, 5, 9, 19392], [2231, 17, 113, 78, 1, 256, 117, 4897], [3, 90, 585, 537, 331, 2446, 259, 1, 15, 2, 320, 16, 76, 54, 116], [176, 174, 1, 18, 2, 4149, 26], [53, 85, 7288, 1396, 13, 7, 53, 19393, 368], [3, 113, 2, 1, 61, 8, 28, 10, 226, 2292, 18, 50, 5589, 37, 3, 63, 150, 93, 38, 23, 2111, 15, 82, 747], [19, 987, 1, 63, 5, 867], [631, 24, 27, 43, 532, 2, 663], [19394, 31, 5, 2, 9, 5, 2, 9, 23, 48, 556, 2196, 1803, 15], [40, 3467, 4, 25, 40, 1562, 18, 19, 2, 1149, 77, 37, 36, 32, 44, 6, 14, 319], [31, 5, 67, 17, 6, 1459, 60, 127, 1], [38, 391, 465, 8568, 351, 230, 8569], [9, 223, 14, 8724, 39, 9, 75, 14, 302], [924, 15, 18, 4, 190, 2677, 425], [1903, 66, 103, 94, 1, 472, 35, 13, 31, 4, 4584, 220, 8168, 1353, 70, 35, 18, 60, 19395, 27, 1286, 19396], [28, 79, 183, 123, 2, 1, 7, 168, 6, 4429, 350, 19397, 219, 19398], [3, 86, 31, 3, 124, 9, 3, 118, 113, 76, 6531, 4, 199, 45, 23, 99, 1810, 6, 14, 238, 1868, 45, 35, 26], [18, 274, 78, 9, 165, 28, 102, 10, 186], [741, 123, 84, 234, 8, 29, 134, 84, 24, 35, 26, 26], [1, 5, 380, 15, 53, 10, 24, 342, 156, 644, 17, 35, 21, 2, 93, 6515, 87, 60, 5943, 19399, 5], [53, 22, 836, 53], [53, 31, 5, 191, 17, 155, 1, 315, 48, 17, 23, 32, 19400, 369, 12, 32, 1719, 31, 5, 29, 453, 17, 191], [246, 629, 7, 152, 70, 5, 938, 20, 1], [3, 29, 279, 59, 553, 16, 39, 1], [53, 5775, 119, 10, 30, 371, 119, 24, 46, 1082, 3883, 53], [15, 8725, 38, 77, 208, 179], [77, 72, 1662, 13, 463, 41, 99, 239, 5834, 139, 100, 186, 8, 798, 902, 350, 3, 29, 62, 39, 19401], [151, 105, 594, 71, 111, 63, 365, 98, 1119, 575, 3, 75, 110, 365, 2, 1687, 6, 2, 1, 7, 3, 19], [23, 48, 61, 54, 10, 193, 201, 70, 362, 1, 62, 295, 188, 33, 389, 701], [26, 344, 53, 6, 922, 84, 373, 34, 39, 9, 669, 53], [160, 38, 97, 228, 3390, 5, 13, 36, 80, 1, 4039, 497, 364], [2805, 2482, 2805, 172, 6055, 1042, 9], [38, 4, 24, 37, 631, 5, 465, 7, 45, 737, 3178], [52, 13, 17, 110, 127, 218, 52, 62, 3, 146, 1], [32, 5, 9, 597, 35], [80, 9, 103, 28, 1300], [38, 2, 1, 113, 17, 23, 183], [2500, 129, 1], [91, 23, 19402, 8, 32, 3, 94, 12, 78, 9, 7, 249, 138, 81, 59, 50, 13, 91, 29, 1985, 18, 50, 19403, 26], [221, 2585, 49, 37, 209, 165, 5, 19, 144], [60, 16, 5, 187, 1632, 17, 1946], [432, 67, 4, 24, 31, 15, 107, 125, 343], [3, 90, 584, 10, 373, 8615, 30, 1], [1, 5, 183, 73, 19, 49, 5, 2, 19, 718, 28, 19404, 231, 73], [151, 258, 5, 2, 19405, 34, 15, 43, 24, 45, 8, 7, 47, 60, 24, 45], [21, 32, 212, 194, 7, 37, 19406, 65, 51, 22, 664, 92, 55], [58, 217, 329, 21, 4, 508, 540, 7, 36, 200, 5, 329, 103, 101, 316, 127, 1864, 648, 26, 2548, 173, 20, 5224], [3, 44, 1064, 43, 2731], [8196, 828, 5, 196, 104, 19407, 19408, 863, 91], [8392, 47, 4, 832, 1, 16, 10, 4989], [3, 64, 38, 4, 95, 49, 5511, 11, 4, 561], [1258, 54, 88, 104], [57, 78, 443, 4186, 229, 4626, 12, 1441, 1974, 152, 44, 6, 955, 2, 1], [3, 90, 2, 584, 10, 373, 3105, 53, 30, 1], [3, 29, 14, 475, 59, 39, 1208, 689, 30, 9, 34, 36, 475, 59, 17, 1168, 85], [3, 29, 594, 3, 29, 110, 19, 27, 39, 1, 34, 23, 37, 3789, 6, 76, 464], [105, 623, 4, 3568, 106, 5, 1, 25, 12, 936], [2452, 30, 542, 30, 9], [53, 39, 9, 41, 127, 481, 130, 2, 19409], [1364, 1, 1364, 1], [524, 207, 387, 49, 109, 759, 793, 2, 5815, 16, 19410], [111, 28, 79, 32, 409, 16, 1, 129, 451, 55, 5, 62, 71, 4675, 7, 12], [42, 146, 14, 2, 2169, 1, 6, 498, 123, 246, 275, 331, 65, 21, 2, 25, 7, 46, 20, 251], [3, 29, 594, 71, 1, 258, 4, 106, 6, 475, 59, 57, 246, 1, 12, 58], [85, 58, 39, 9, 86, 15, 342, 6, 114, 406, 605, 5370], [251, 25, 12, 8726, 144, 425, 31, 5436, 407, 3068, 2242, 2824, 14, 4051], [286, 447, 492, 169, 13, 2, 9], [7, 9, 12, 259, 464], [3, 29, 279, 59, 553, 16, 39, 1], [4250, 6, 4, 9, 309, 21, 4018], [469, 2, 9, 156, 2, 9], [31, 2, 1, 86, 23, 475, 59, 50, 7, 1, 19411], [954, 1149, 954, 1], [584, 641, 3918, 3, 86, 435, 8, 287, 198, 14, 19412, 2, 1, 7, 29, 62, 45, 59, 3918], [55, 21, 57, 55, 5, 1877, 263, 242, 35, 1], [479, 688, 9, 100, 19413], [17, 260, 3, 867, 482, 57, 21, 1283, 17, 7, 1, 5, 132, 262], [46, 43, 6814, 11, 22, 1, 26], [31, 2, 1, 175, 59, 2, 25, 8, 52, 72, 52, 29, 780, 27, 50, 52, 308, 7, 1, 46, 175, 21, 295], [87, 60, 684, 853, 8, 354], [101, 4, 339, 1, 157, 18, 21, 186, 233], [3, 90, 38, 177, 176, 778, 2, 1, 7, 557, 76, 13, 36, 245, 25], [38, 25, 122, 6, 208, 332, 34, 109, 14, 1, 216], [53, 5, 4259, 27, 291, 145, 5, 276, 14, 291, 145, 19414, 25, 19415], [132, 1174, 430, 35, 7170, 24], [3, 29, 14, 19, 27, 357, 149, 247, 16, 39, 1, 41, 365, 11, 36, 1009, 26, 8, 25], [38, 5, 86, 59, 204, 2, 1], [2262, 2790, 2004, 41, 4, 5875, 1, 182, 148, 1196, 19416, 148, 1196, 7, 19417], [4766, 29, 14, 525, 43, 5851, 24, 21, 76, 1221, 30, 2518, 383, 14, 5, 252, 55], [19418, 92, 25, 75, 167, 42, 1, 493, 8, 191, 57, 42, 1042, 19419], [204, 39, 1, 61, 481, 21, 481], [3, 90, 2, 1, 7, 208, 13, 40, 75, 14, 7851, 28, 20, 3, 87, 2, 91, 30, 18], [280, 110, 27, 8072, 19420, 3, 96, 28, 127, 24, 130, 5], [85, 277, 326, 484, 13, 144, 38, 15, 1234, 55], [5, 165, 1646, 3, 29, 471, 20, 677, 54, 1], [71, 239, 1, 44, 428, 223, 6, 4, 489, 11, 2, 1951, 3691, 26, 2809, 18], [3, 67, 22, 1983, 368, 19421, 6, 14, 129, 37, 1026, 19422, 75, 1053, 2, 1355, 27, 4512, 19423, 6464, 92], [53, 3, 301, 3, 47, 1348, 11, 2, 511, 979, 149, 78, 33, 70, 10, 24, 1006, 505, 26, 8499, 30, 1334, 26], [162, 12, 717, 9], [2206, 95, 7476], [25, 14, 54, 135, 64, 32, 36, 19424, 2, 43, 988], [53, 25, 1, 28, 19425], [31, 5, 191, 17, 155, 1, 2506, 573, 147, 573, 147], [4, 199, 9, 12, 96, 51, 15], [447, 7, 9, 47, 728, 928, 8, 215, 264], [201, 239, 161, 2456, 1], [497, 1], [252, 2, 9, 124, 17, 3345, 18, 10, 101, 327], [667, 9, 14, 366, 6, 65, 342, 1, 42, 165, 6073, 7, 45, 936, 441], [243, 457, 6, 10, 1018, 3211, 64, 42, 9], [53, 112, 1, 69, 109, 807, 266, 14, 54, 135, 687, 27, 1, 18, 186, 344, 19426], [53, 1249, 34, 2, 145, 75, 44, 2, 1975, 2535, 27, 217, 19427, 103, 14, 9, 2911, 55], [38, 103, 5, 189, 338, 7, 1133, 24, 771, 28, 7, 19428, 285], [1, 14, 365, 483], [3465, 3466, 22, 9, 299, 40, 47, 37, 2643], [10, 4547, 158, 12, 107, 54], [4575, 459, 135, 9], [53, 171, 368, 23, 751, 6, 5, 1], [22, 9, 105, 79, 17, 13, 40, 121], [57, 2, 89, 1, 6, 2, 1235, 27, 1487], [38, 42, 94, 2, 1, 7, 29, 13, 42, 65, 51, 42], [15, 46, 295, 6, 311, 7, 1, 1724], [1, 14, 86, 36, 49, 1933, 54, 135, 13, 43, 20, 33, 98, 744, 1696, 610, 1], [613, 774, 8, 95, 91, 223, 14, 51, 3098, 6027, 390], [89, 1, 134, 17, 235, 13, 19429, 26], [234, 19430, 525, 1722, 35, 2473, 78, 95, 165, 7383, 562], [3, 113, 5, 393, 18, 22, 1, 3, 165, 28, 2, 267, 350, 19, 329, 545, 5, 171, 30, 3, 131, 14, 1303, 30, 292, 1523, 75, 523], [32, 39, 1, 365, 31, 5, 191, 17], [19431, 71, 209, 23, 150, 5, 42, 75, 3426, 27, 77, 69, 313, 4, 285, 23, 33, 152, 156, 114, 4, 1432], [346, 97, 99, 158], [10, 2196, 803, 12, 253, 22, 1, 172, 9, 7, 168, 6, 14, 10, 228, 22, 12, 908], [19432, 3, 29, 131, 2910, 2739, 10, 250, 1268, 118, 14, 7, 23, 2, 270, 2, 1, 1522], [3, 90, 2, 2159, 534, 30, 83, 269, 94, 269, 58, 30, 1], [357, 279, 59, 2841, 6521, 6522, 279, 133, 10, 1081, 9], [841, 572, 1, 1287], [17, 4906, 1], [2147, 2041, 1141, 34, 38, 3, 349, 35, 15, 954, 166, 153, 125, 97, 1737, 45, 13, 7, 204, 17], [23, 2, 900, 30, 1], [22, 12, 112, 164, 40, 67, 6, 134, 42, 24, 37, 89, 40, 214, 51, 42, 1027, 42, 19, 15, 35], [601, 42, 146, 242, 142, 32, 794, 501, 8, 28, 794, 6079, 19433, 28, 183, 18, 39, 9, 8, 119], [2, 9, 223, 14, 2, 9, 8, 147, 579, 38, 2, 25, 291, 76, 9, 208, 356], [300, 17, 163, 19434, 143, 101, 153, 69, 46, 41, 143, 1588, 19435, 117, 116, 125, 4022, 321], [5, 81, 45, 34, 80, 1434, 46, 45, 80, 1, 46, 45, 80, 164, 46, 45, 25, 5, 33, 2, 46, 45, 73, 312], [4814, 24, 6080, 130, 97, 5943, 128], [32, 39, 1, 26, 638, 27, 36, 3488, 1543, 2059], [1153, 59, 20, 19436, 31, 19437, 19438, 121, 20, 226, 11, 19439, 2, 19440, 5, 1870, 2, 9], [1136, 3479, 3092, 3094, 41, 19441, 825, 1215, 41, 8727, 3, 96, 44, 43, 319, 225, 33, 132, 2, 89, 921], [1212, 54, 16, 546, 155, 1, 11, 1652, 65, 93], [1292, 821, 14, 356, 130, 2, 1], [566, 2, 1, 72, 23, 183, 34, 136, 25, 267, 511, 5, 72, 5, 19442, 52, 29, 557, 17, 43, 511], [182, 131, 262, 495, 8, 14, 13, 1, 309, 3, 293, 5, 29, 597, 35, 5, 702, 142, 537, 19443], [39, 1, 25, 487, 259, 10, 587, 19444], [78, 9, 64, 1231], [19445, 321, 26, 1993, 1089, 4, 2417, 11, 4, 2258, 88, 107, 19446, 8, 119, 22, 887], [19, 43, 278, 14, 525, 8399, 11, 116, 13, 744, 158], [3, 300, 15, 4, 1139, 1, 7, 86, 36, 4, 832], [571, 431, 73, 1, 37, 31, 2, 1, 29, 13, 17, 15, 2, 395, 437, 26], [22, 57, 247, 16, 78, 9, 87, 6, 1124, 26], [18, 274, 3, 14, 86, 7, 26, 55, 111, 51, 261, 14, 229, 17, 22, 399, 496, 26, 23, 13, 52, 1303, 6462], [29, 122, 579, 137, 17, 151, 9, 42, 2222], [39, 9, 611, 91], [78, 1, 14, 13, 1913, 65, 1727], [890, 524, 12, 248], [71, 5, 338, 97, 91, 544, 21, 2, 291, 1, 247, 39, 742, 25, 18, 60, 9, 45], [3, 191, 6, 28, 17, 1106, 2132, 68, 106, 37, 52, 1051, 17, 190, 19447], [2642, 715, 695, 7, 57, 42, 41, 82, 22, 4551, 14, 8533, 4, 490, 32, 7, 257, 874], [53, 38, 5, 405, 32, 20, 9, 21, 4, 329, 68, 8, 5, 146, 316, 240, 108, 53, 3596], [53, 146, 194, 39, 9, 53, 3, 300], [53, 2842, 11, 1094, 19448, 91, 231, 473, 213, 6, 164, 11, 3259, 21, 19449, 783, 16, 1616, 348, 26], [910, 340, 273, 3, 44, 19450, 9], [2694, 2, 112, 25, 118, 105, 14, 505, 8, 345, 129, 24, 36, 210, 28, 21, 268, 2654, 57, 716, 315, 45, 12, 7], [6013, 101, 24, 25, 69, 249, 138, 345, 59, 217, 14, 11, 126, 844, 175, 4, 395, 88, 345, 361, 59, 4], [1403, 333, 29, 100, 22, 1, 204, 10, 5537], [8, 78, 25, 383, 134, 35, 4, 1982, 3, 454, 71, 78, 150, 509, 4, 7567, 5777, 483, 932, 1265, 78, 133, 6, 4762], [164, 6, 752, 6, 14, 2900, 657, 214, 51, 1], [1, 383, 64, 6, 28, 17, 4592], [24, 13, 77, 148, 12, 10, 24, 315], [53, 245, 1, 7, 136, 182, 124, 2, 19451, 27, 17, 46, 536, 45, 34, 10, 186, 19452], [2809, 704, 2, 161, 1, 125, 2, 358, 226, 3177, 124, 127, 3210, 913, 5993, 3, 61, 3342, 1427, 24, 1028], [31, 5, 96, 157, 20, 3442, 11, 580, 16, 20, 150, 233, 88, 367, 1, 20, 96, 1133], [38, 40, 4404, 50, 24, 19453, 680, 5868], [4, 419, 164, 12, 167, 21, 8152, 13, 3, 29, 110, 67, 319], [3, 300, 39, 1, 86, 126, 96, 11, 4954], [3, 442, 116, 2, 689, 11, 2056, 149, 4, 1377, 41, 2, 89, 83], [91, 33, 7046, 26, 4477, 22, 145, 19454, 13, 23, 108, 11, 2248, 940, 58, 1697, 19455, 819], [177, 3, 47, 656, 11, 76, 8728, 64, 76, 148, 3921], [2560, 31, 66, 2126, 88, 23, 1099, 256, 834, 11, 20, 24, 33, 2, 2559], [85, 58, 78, 25, 1182, 7, 7461, 1, 3, 29, 94, 71, 78, 63, 182, 114, 2, 1, 7, 448, 927, 327, 686], [31, 5, 75, 58, 74, 72, 2045, 45, 11, 580, 16, 80, 1, 88, 29, 58, 15], [25, 14, 430, 764, 8, 772, 2, 1, 6, 2020, 2804, 16, 370, 6, 1244, 54, 57, 84, 2029, 43], [3575, 10, 931, 21, 2601, 301, 1026, 347, 26, 1], [3, 29, 131, 465, 19456, 226, 107, 459, 4, 19457, 2747, 52, 487, 14, 2361, 88, 176, 84, 2215, 236], [161, 185, 30, 812, 3, 46, 19, 27, 5], [57, 4, 511, 808, 2, 455, 26, 2, 234, 1, 45, 78, 398, 28, 1090, 308, 26, 138], [247, 16, 4, 1, 52, 1181, 48, 206, 602, 6, 28, 2, 278, 37, 57, 7, 113, 5], [6081, 11, 60, 19458, 1], [31, 23, 89, 1484, 422, 78, 1484, 13, 7213, 78, 41, 575, 1, 162, 588], [3, 454, 31, 3, 410, 1312, 3, 14, 13, 3, 67, 19, 118, 3, 14, 329, 74, 5, 2, 14, 68, 4227, 73, 1], [39, 1, 75, 58, 777, 21, 350], [352, 18, 841, 438, 29, 196, 5, 2, 9, 304, 1638, 115, 266, 70, 5, 2, 436, 342, 327, 29, 196, 78, 243, 44, 2, 2003], [11, 2, 575, 116, 152, 14, 1, 4710, 130, 20, 74, 25, 58, 165, 130, 20, 916, 7, 162, 4, 2928], [3, 195, 37, 1176, 16, 1, 69, 63, 3565], [19459, 29, 475, 1, 101, 208, 3907, 38, 36, 44, 495, 6, 8729, 76, 35, 15, 431, 205, 3, 41, 5, 31, 393], [316, 1444, 3583, 22, 2673, 2718, 51, 1212, 195, 45, 12, 21, 4, 19460, 4, 19461, 459, 135, 280], [5, 44, 43, 1237, 16, 4245, 37, 108, 102, 126, 108, 174, 2, 161, 1, 8, 23, 546], [11, 293, 16, 4155, 127, 287, 1331, 458, 377, 1056, 261], [31, 3, 124, 2, 831, 21, 155, 1364, 4261, 289, 514, 278, 14, 68, 613, 1], [3, 29, 279, 57, 245, 16, 5, 1, 72, 7987, 12, 1772], [39, 9, 46, 334], [63, 217, 258, 4, 19462, 408, 69, 81, 56, 6, 17, 8, 273, 17, 52, 293, 66, 29, 450, 35, 13, 5993, 113, 170, 23], [1583, 19463, 299, 56, 115, 47, 1147], [60, 16, 5, 1, 49, 8730, 36, 49, 1666, 19464], [3, 75, 397, 2, 993, 39, 3487, 30, 812], [326, 238, 19, 4, 244, 25, 1, 48, 4086, 7, 84, 1, 12, 4, 244, 25, 1], [71, 58, 111, 48, 623, 4, 1280], [33, 683, 7, 116, 47, 2, 19465, 1688, 1086, 2491, 6, 19466, 159, 7783, 188], [23, 48, 4, 409, 16, 189, 6, 1, 59, 71, 341, 15, 12, 34, 15, 59, 6, 14, 1474, 8, 23, 96, 1513, 3899], [32, 3, 67, 21, 1987, 115, 12, 2, 180, 517, 282], [243, 457, 181, 177], [19467, 12, 144, 29, 477, 6, 876], [29, 28, 17, 192, 18, 5, 1295, 235, 541, 30, 1], [149, 23, 73, 351, 73, 2, 95, 92, 8, 22, 95, 5, 63, 48, 396], [85, 58, 5, 79, 247, 189, 7, 81, 45, 6, 5, 7248, 88, 5, 198, 168, 246, 324, 8033], [31, 3, 1266, 18, 20, 24, 29, 14, 238, 1849, 15, 11, 13, 36, 58, 11, 4, 4723, 218, 31, 42, 28, 554, 794], [5, 41, 25, 26, 3, 41, 1, 34, 3, 67, 2419], [19468, 1], [53, 92, 3, 62, 85, 25, 44, 234, 10, 1, 723, 53], [159, 1186], [23, 4, 101, 395, 69, 13, 190, 3205, 3, 150], [1678, 85, 274, 216, 2122, 6, 2566, 8140], [38, 2, 77, 316, 35, 10, 2731, 38, 23, 122, 6, 28, 6, 62, 4235], [26, 26, 3, 49, 2277, 305, 1210, 1638, 1698, 2154, 190, 4692, 752, 8731, 129, 19469, 57, 47, 20, 14], [560, 73, 820, 16, 10, 1525, 115, 2006, 8434, 66, 28, 19470, 22, 2814, 5700, 1538], [526, 19471, 43, 3051, 135, 1826, 887, 19472, 24, 162, 49, 1323, 55], [1678, 57, 7, 19473, 265, 79, 17, 51, 13, 378, 11, 4, 561, 191, 17, 31, 3, 67, 6, 167, 4, 19474], [3, 62, 15, 46, 93, 34, 39, 9, 276, 58, 57, 36, 19475], [71, 40, 28, 32, 4, 1], [264, 13, 22, 3, 301, 498, 702, 11, 4, 5764, 167, 4, 19476, 11, 4, 620, 1276, 3244, 27, 2, 1], [31, 19477, 2062, 906, 7, 129, 4583, 21, 4, 178, 78, 2062, 121, 4583, 56, 26, 52, 41, 57], [213, 16, 119, 8, 96, 43, 2189, 127, 16, 19478, 38, 5, 119, 24, 15, 547, 80, 2189, 632, 22, 12, 725], [3, 67, 60, 1672, 2474, 1672, 19479, 26, 50, 306, 14, 44, 76, 1, 19480], [33, 486, 217, 498, 2, 2295, 288, 255, 4582, 4, 1, 12, 191, 6, 28, 167], [770, 12, 13, 2, 6082, 388, 19481, 84, 2103, 224, 3555, 19482, 52, 698, 16, 356, 34, 560, 20, 188], [1017, 267, 21, 4, 253, 1612], [411, 185, 83, 274, 2629, 19483, 17, 88, 385], [101, 19, 25, 118, 131, 1475, 6, 780, 27, 39, 1208, 30, 1, 2205, 495, 69, 136, 132, 142, 21, 76, 32, 2], [467, 6, 4, 215, 405, 1089, 8732], [261, 19484, 114, 807, 265, 1255, 26, 313, 11, 56, 140, 126, 1255, 8733, 652, 1135, 562, 3622, 1226, 240, 26], [3, 195, 43, 1363, 103, 6, 708, 584, 33, 13, 5, 33, 3480, 73, 10, 2221, 4866], [171, 1, 49, 68, 184, 3622, 105, 671, 7691, 7, 112], [1, 51, 19485, 19486, 65, 2, 161, 19487, 19488, 19489, 219, 8412, 1025, 35, 13, 19490, 1025, 35, 13, 19491], [72, 1472, 8477, 107, 82, 2, 2930, 8734, 600, 5, 105, 1924, 57, 2, 494, 395, 568, 539, 8, 600], [19492, 298, 19493, 100, 2578, 298, 7, 839, 448, 8, 44, 8735, 859, 7, 1, 6, 1458], [3, 150, 89, 21, 39, 379, 77, 7, 49, 330, 319], [91, 71, 5, 19494, 18, 32, 39, 9, 38, 20, 101, 342, 27, 70, 35, 18], [32, 39, 148, 1, 18, 10, 310, 493], [37, 4, 466, 200, 694, 142, 4, 699, 26, 592, 2, 905, 1251, 2024, 646, 26, 4, 5632], [1219, 501, 160, 468, 50, 1919, 317, 196, 116, 652, 166, 193, 6, 635, 26], [19495, 1], [46, 81, 201, 10, 19496, 163, 2, 449, 250, 184, 40, 72, 12, 162, 933, 98, 5466], [113, 20, 1, 7, 23, 7, 25, 92], [1103, 20, 96, 2, 1, 5, 249, 158, 293, 5, 309], [56, 119, 56], [55, 23, 19497, 33, 2, 294, 56, 63], [8171, 289, 124, 254, 23, 405, 3217, 19498, 986, 584, 328, 27, 365, 283, 4, 19499, 32, 16, 254, 19500, 8206, 11, 1700, 19501], [107, 35, 51, 19502, 159, 1186, 2483, 1124, 52, 600, 44, 132, 329, 59, 4, 1393, 19503, 761, 82, 22, 596], [31, 5, 448, 2, 3769, 1492, 2161, 1157, 491, 19504, 2, 339, 3505], [556, 929, 32, 39, 1, 11, 580, 16, 17, 143, 10, 77], [15, 716, 2169, 71, 39, 1, 18, 8736, 14, 7972, 26, 14, 208, 37, 1133, 483], [1488, 255, 1, 87, 6, 632, 364, 35], [19505, 2449, 75, 302, 2, 1, 226, 19506, 43, 3810], [5, 8, 80, 1, 421, 35, 8, 40, 192, 6284, 51, 246, 25, 40, 223, 21, 93, 2549], [403, 19507, 1033, 21, 5, 570, 95, 1344, 263, 2199, 15, 4, 710, 1445, 16, 19508, 951], [26, 1, 44, 17, 2922], [2, 1, 7, 29, 13, 5, 156, 223, 86, 5, 2030], [22, 1, 383, 1807, 10, 314, 8, 3, 47, 102, 32, 16, 39, 19509], [31, 5, 100, 20, 77, 28, 974, 8, 5, 29, 58, 295, 5, 198, 16, 132, 1348, 2, 1, 218, 101, 1, 25, 6083], [50, 231, 37, 148, 19510, 3, 62, 50, 24, 578, 13, 8737, 8, 32, 10, 164, 1487, 3596], [277, 14, 18, 10, 138, 70, 245, 16, 78, 9, 150, 3789, 31, 37, 2410, 8738, 20, 413, 164, 233, 267], [24], [58, 3, 44, 106, 21, 39, 9, 43, 43, 43, 43, 43, 43, 19511, 43, 43, 43], [8538, 91, 56, 12, 246, 91, 19512, 1365, 1740, 27, 803, 8094], [1083, 16, 215, 264, 113, 17, 6, 258, 50, 2, 1189, 741, 8, 1358, 70, 2, 19513, 6, 512, 2, 95, 142], [6010, 1, 7, 29, 420, 38, 5, 72, 919, 17, 12, 57, 329, 11, 22, 3434], [1, 66, 76, 177], [6783, 6, 4492, 263, 494, 29, 61, 224, 65, 21, 184, 6, 14, 1001, 2195, 15, 33, 5, 19514, 72, 4, 8660], [1657, 27, 1, 18, 186, 13], [339, 1200, 1013, 6, 249, 138, 2047, 8, 2, 339, 19515, 4888, 21, 2, 9, 542, 21, 1869, 951], [247, 826, 2362, 126, 1531, 116, 1226, 27, 8677, 8, 116, 14, 2, 187, 247, 49, 187], [294, 13, 2, 180, 1, 615], [60, 25, 208, 13, 344, 35, 1], [31, 20, 152, 366, 441, 88, 58, 5, 34, 2116, 12, 33, 185, 5, 104, 49, 28, 127, 185, 467, 15], [78, 9, 14, 65, 37, 89, 11, 20, 830, 88, 3, 65, 51, 4, 763, 16, 20, 327, 8, 42, 183, 73, 45], [3, 150, 13, 4, 455, 540, 1, 96, 44, 1116, 5487, 11, 862, 12, 140, 36, 3052, 29, 62, 71, 6, 1089, 15, 19516], [6212, 7, 368, 160, 18, 4, 8005, 859], [57, 2, 1482, 141, 269], [53, 85, 326, 854, 3, 29, 477, 2080, 29, 1, 42, 223, 683, 68, 115], [4493, 181, 5, 96, 44, 20, 460, 390], [101, 112, 25, 62, 43, 690, 71, 807, 5, 49, 5, 165, 100, 39, 1, 431, 102, 26], [148, 19517], [7, 269, 12, 82, 286], [4, 1944, 3, 28, 4, 882, 3, 134, 2, 19, 990, 1, 333, 1394, 228, 1, 680, 2087, 151, 433], [800, 31, 174, 138, 103, 955, 2, 1], [1, 2979], [55, 44, 42, 297, 38, 2071, 8, 84, 6812, 826, 192, 44, 2, 1719, 575], [1, 680, 797, 65, 51, 22, 45], [22, 12, 3580, 463, 7282, 2597, 37, 12, 22, 24, 371, 66, 19518, 8739], [1, 424, 1861], [313, 17, 11, 56], [19519, 54, 978, 5100, 22, 317, 110, 578, 13, 19520], [3, 424, 4, 9, 6, 2183, 1065], [85, 5, 505, 10, 150, 1325, 19521, 5, 349, 32, 4, 9, 125, 4, 417, 1349], [15, 156, 978, 104, 7, 41, 60, 45, 6, 72, 128, 5, 11, 64, 27, 60, 148, 3107, 55, 172, 3097], [20, 2, 144], [1103, 317, 227, 954, 1062, 19522, 52, 216, 473, 840, 2693, 130, 1362, 6140, 1480, 74, 1187, 286, 14, 108, 2346, 208, 13, 52, 19523], [6065, 1154, 5, 86, 5, 63, 493, 17, 35, 3, 486, 2, 89, 1, 11, 3067, 8658, 19524], [3530, 114, 22, 327, 21, 17, 3118, 463, 86, 4, 1, 276, 19, 27, 22, 6043], [22, 2183, 292, 115, 206, 34, 3, 119, 4559, 1164, 206, 24, 37, 3, 198, 14, 595, 117], [38, 5, 861, 11, 4, 848, 16, 4, 2309, 34, 94, 2, 89, 1, 1397, 123, 4, 3672, 19525], [455, 1, 72, 296, 90, 2, 471, 17, 2, 327, 30, 1590, 14, 729, 155, 419, 68, 16, 2335, 19526, 3972], [176, 20, 830, 9], [71, 5, 19, 21, 1278, 34, 5, 48, 2, 9], [26, 3, 67, 6, 14, 1207, 27, 341, 158, 3484], [242, 35, 1, 416, 697, 4, 193, 36, 1563], [252, 277, 84, 504, 306, 56, 50, 7853, 19527, 6, 617, 19528], [57, 2, 45, 19529], [68, 16, 10, 19530, 1761, 10, 826, 8, 348, 8, 217, 121, 463, 122, 6, 1845, 348, 19531], [558, 593, 1, 26, 134, 240, 235, 2320, 25, 5, 530, 26, 20, 165, 102, 1923], [3, 41, 32, 39, 9, 19532, 38, 3, 294, 785], [63, 66, 333, 139, 81, 59, 71, 60, 5632, 104, 6432, 12, 643, 5, 171, 8740], [5, 9, 46, 41, 43, 19533], [10, 653, 3460, 136, 268, 822, 23, 2, 2933, 864, 16, 45, 69, 655, 43, 64, 1625, 142, 230, 17, 1, 3, 195, 5], [23, 105, 137, 567, 95, 361, 182, 19, 7, 178], [2, 25, 63, 13, 68, 327, 26, 42, 1, 7389, 6, 19534, 229, 19535, 1, 204, 4354], [42, 9, 49, 889, 339, 7, 134, 1017, 6, 574, 13, 78, 798, 19536], [42, 541, 21, 2, 900, 61, 28, 2, 401, 1], [15, 7357, 71, 517, 8, 19, 30, 39, 1, 2305, 36, 259, 6, 14, 2181], [76, 843, 25, 8525, 18, 4, 24, 80, 5, 134, 17, 68, 115, 151, 2669, 18, 7, 24, 4874], [92, 4, 2003, 1, 317, 3768, 6, 32, 287, 34, 32, 287, 44, 2, 161, 1, 11, 240], [116, 12, 295, 329, 27, 3528, 6026, 33, 149, 40, 29, 65, 13, 3034, 78, 146, 2, 8741], [4, 5475, 734, 1923, 1, 109, 86, 3, 75, 3084, 10, 373, 811, 8742, 231], [10, 2170, 1362, 28, 6294, 4241, 21, 79, 2286, 2, 104, 57, 58, 78, 2393], [8531, 136, 2, 115, 102, 8, 21, 3621, 235, 6, 232, 1330, 6, 662, 27, 1098, 8712, 1962, 1309, 51, 2743, 12, 415, 19537], [298, 35, 18, 2, 25, 28, 6, 4731, 9, 19538], [80, 22, 2033, 587, 45, 37, 19539, 163, 21, 4, 95, 15, 284], [622, 114, 22, 169, 66, 276, 313, 2, 460, 18, 7, 24], [78, 60, 1], [148, 3, 19, 1, 3, 380], [19540, 9, 29, 279, 71, 203, 36, 1563, 36, 32, 96, 255, 3294, 1286, 8, 2723, 19541], [128, 3, 44, 2366, 5392, 2186, 5], [13, 148, 1, 221, 19542, 17], [394, 158, 23, 304, 21, 4, 347, 1250], [31, 40, 79, 17, 183, 8, 192, 6875, 17, 3141, 278, 298, 13, 2, 639, 19, 24, 801, 21, 10, 306, 6, 547, 2562], [92, 7, 923, 12, 1026, 3400, 333, 594, 1305, 66, 49, 2, 2755, 48, 2, 1980, 6, 382, 8, 4675, 1817], [1575, 1033, 4776, 1733, 863, 201, 2249, 1289, 19543, 202, 26], [1575, 1033, 4776, 159, 524, 21, 16, 2249, 6035, 2803, 1005, 19544, 26], [1575, 1033, 4776, 159, 8644, 6, 4408, 19545, 2249, 1289, 1480, 19546, 26], [64, 109, 12, 1380, 185, 187, 16, 2, 5748], [369, 12, 177, 24, 128, 5, 3226, 25, 549], [3787, 2097, 12, 68, 16, 212, 19547, 111, 52, 1, 59, 7, 149, 19548], [57, 98, 3423, 1], [78, 708, 5, 67, 2, 93, 26, 334, 77, 34, 176, 780, 27, 9, 13, 23, 1075], [3, 454, 31, 212, 408, 11, 819, 150, 13, 159, 524, 211, 7395, 349, 4, 466, 5027], [159, 925, 12, 4, 2166, 25, 1524], [11, 4, 1152, 315, 2755, 103, 14, 1557, 431, 123, 770, 1328, 8, 661, 16, 2322, 116, 103, 14, 19549], [661, 16, 475, 133, 69, 7, 1, 19, 85, 29, 5, 28, 5, 60, 169], [32, 1, 131, 58, 12, 990, 129, 25, 632, 364, 35, 2, 28, 97, 8743, 344], [4922, 1939, 382, 8597, 27, 327, 27, 1332, 2104, 26], [3, 29, 13, 1, 638, 8, 36, 29, 13, 17, 35], [3, 118, 105, 840, 129, 2, 1, 7, 46, 588, 25, 1353, 91], [38, 98, 1555, 1, 3449, 42, 21, 43, 540], [219, 92, 23, 345, 13, 2, 141, 1], [57, 2, 83], [4, 3824, 1759, 1366, 21, 348, 12, 2211, 16, 4824], [694, 839, 483, 3, 110, 41, 1, 298, 211, 17], [576, 321, 2005, 38, 5, 121, 7, 15, 47, 20, 1979, 2032, 8, 20, 1, 7, 10, 1054], [1, 46, 45, 9, 46, 1776], [206, 120, 111, 733, 59, 2315, 19550, 12, 13, 4, 232, 14, 1917, 7, 781, 70, 99, 209, 169], [93, 77, 114, 19551, 707, 230, 36, 420, 7776, 101, 9, 756, 82, 25, 6, 2461, 29, 687, 27, 17, 22, 12, 19552], [29, 844, 2, 1, 82, 20, 722, 6, 307, 250, 16, 32, 3, 29, 134, 2, 1066, 710, 16, 32, 3, 29, 2800, 8, 2540, 3], [5, 41, 25, 26, 3, 41, 1], [5949, 1, 11, 19553, 19554], [19555, 295, 329, 27, 202, 77, 44, 314, 138, 1911, 305, 24, 859, 25], [63, 3, 400, 18, 20, 231, 400, 18, 2, 341, 7596, 1, 26], [38, 482, 751, 1360, 46, 777, 6, 311, 7, 1, 2235, 27, 99, 209, 19556], [151, 905, 491, 4, 45, 5751, 1312, 7, 1, 81, 6, 1572], [154, 19557, 19558, 11, 19559, 19560, 19561, 1112, 12, 2, 1875, 761, 6], [39, 9, 2778, 334], [57, 698, 16, 360, 58, 66, 259, 11, 162, 1, 49, 28, 3766, 6, 70, 126, 971, 1104, 371, 38, 58, 287, 67, 2], [19562, 1992, 30, 37, 19563, 6428, 1, 294, 224, 545, 1349], [24, 96, 578, 13, 1653, 4746, 3, 119, 2626, 744, 36, 37, 93], [6, 42, 1, 69, 44, 7900, 142, 5839, 406, 2754, 357, 136, 106, 6, 788, 36, 310, 224, 6, 94, 31, 42, 110, 19564], [3, 96, 14, 3061, 98, 354, 5597, 2436], [2203, 7994, 1], [3, 415, 195, 1288, 144], [3, 64, 38, 72, 757, 23, 986], [441, 46, 2, 692, 15, 2, 19, 6909, 1], [583, 219, 652, 5, 33, 2, 19, 187, 513], [23, 48, 556, 2020, 2, 25, 6, 4616, 2174, 103, 3, 2020, 2, 1, 6, 14, 10, 7632, 19, 78, 299], [109, 22, 12, 57, 2515, 170, 117, 92, 2364, 65, 19565, 6, 569, 27, 1050, 8693, 740, 195, 1261], [23, 52, 109, 52, 18, 4, 310, 81, 6, 246, 1, 288, 5, 397, 11, 4, 848, 16, 2, 148, 1194, 19566, 26], [289, 509, 4, 4327, 178, 1296, 106, 3, 195, 56], [19567, 12, 248, 2106, 12, 165, 97, 815, 56], [1232, 8744, 72, 14, 315, 12, 2, 2006, 82, 274, 73, 820, 16, 2483, 6, 506, 1074, 6, 19568], [23, 13, 4, 2640, 19569, 34, 21, 284, 1], [10, 19570, 1918, 10, 455, 1, 1018, 1598, 2837, 1232], [122, 6, 2077, 2575, 885, 34, 10, 310, 2, 1], [5, 318, 14, 2, 1132, 31, 5, 1475, 6, 56, 770, 708, 71, 1765, 8, 1893, 15, 12, 478, 5, 1813, 6, 338], [10, 2509, 18, 2453, 1085, 296, 394, 52, 46, 41, 43, 9, 19571], [1670, 19572, 12, 70, 1, 1808, 117, 2704], [60, 435, 72, 374, 1491, 16, 44, 1246, 426, 36, 29, 67, 76, 6, 227, 173, 9, 74, 8700], [20, 508, 1405, 12, 6, 70, 1946, 2855, 1502, 3809, 4744, 3035, 3547, 7, 428, 1869], [137, 24, 28, 19], [693, 39, 25, 18, 22, 9, 45], [23, 99, 322, 21, 22, 26, 78, 161, 1, 63, 44, 4, 1949, 45, 26], [92, 5, 33, 1093, 17, 85, 3, 90, 350], [60, 111, 49, 402, 2, 904, 16, 1052, 8, 32, 36, 63, 58, 12, 1, 59, 71, 4033, 15, 1437], [482, 1993, 81, 6, 20, 894, 17], [2257, 1, 81, 4, 247, 45], [75, 1175, 659, 461, 42, 83], [8745, 85, 58, 25, 28, 6, 1181, 36, 3075, 228, 34, 38, 77, 1181, 50, 3075, 228, 40, 2, 9, 55], [19573, 19574, 19575, 19576, 19577], [2, 334, 77, 1786, 277, 107, 27, 2, 1220, 476, 26, 19578, 2, 9, 103, 100, 5, 58, 73, 5, 333, 149, 40], [19579, 168, 6, 5696, 56, 19580, 69, 2171, 1177, 160, 1979, 19581, 2415, 394, 66, 266, 465, 6084, 56, 19582], [243, 6538, 457, 6, 10, 455, 9, 8, 3635, 11, 2672], [3, 90, 38, 111, 191, 69, 5, 238, 65, 93, 21, 1, 531, 680], [17, 1929, 2179, 2179, 1929, 161, 1], [1441, 109, 557, 1704, 13, 7, 84, 1, 749], [250, 115, 16, 2750, 421, 672, 470, 2, 2477, 16, 348, 26, 194, 688, 1510, 16, 731, 8, 7113, 27, 26], [681, 1842, 207, 53, 3, 29, 64, 39, 1, 8, 5, 982, 519, 53], [305, 3842, 2153, 12, 19, 19583, 52, 317, 62, 71, 6, 28, 82, 19584, 6, 19585], [1, 42, 564, 19586, 28, 27, 4, 106, 8, 429, 7, 30, 22, 70, 17, 716, 611, 26], [6076, 49, 171, 43, 1148, 11, 19587, 1, 242, 35, 20, 11, 314, 261, 208, 13, 22, 12, 61, 6, 14, 4, 395, 5, 19588], [31, 20, 77, 12, 1917, 8, 19589, 50, 19590, 87, 6, 683, 71, 6, 139, 14, 2, 285, 4381, 35], [296, 29, 471, 8462, 1546, 2, 1, 125, 56, 677], [19591, 1, 53, 237, 193, 6, 359, 18, 2, 959, 53], [1210, 7, 342, 20, 306, 878, 5, 6, 14, 2, 2822, 141, 187], [3, 109, 87, 6, 114, 10, 1085, 207, 1178, 102, 1168, 3, 146, 139, 86, 326, 277, 45, 27, 93, 2768], [1, 14, 2020, 21, 64, 26, 2928, 38, 5912, 105, 134, 15, 6, 3721, 648, 1], [3, 1702, 2049, 8, 33, 62, 151, 491, 2, 1, 27, 2, 872, 18, 10, 1511], [2190, 12, 944, 2, 83, 29, 313, 20, 402, 224, 13, 2, 473, 213, 206, 426, 256, 210, 61, 1777, 55], [1309, 888, 72, 781, 266, 87, 4608, 6, 28, 108, 18, 1345, 253, 1939, 1576, 8604, 516, 1930, 137, 6, 236], [2962, 103, 48, 4712, 19592, 937, 216, 82, 355, 480, 1683, 1222, 211, 190, 480, 220, 19593, 26], [5, 86, 40, 89, 219, 10, 1, 5929], [38, 1, 72, 6473, 25, 19, 4, 19594, 22, 32, 3, 19595, 26, 5947], [1971, 121, 52, 41, 2, 1, 82, 4, 6490, 49, 152, 44, 19596, 1, 11, 143, 19597, 11, 126, 1618, 92], [567, 95, 12, 19598, 736], [38, 3, 70, 4, 1010, 466, 173, 4, 56, 63], [25, 148, 8746, 3194, 2887, 41, 32, 39, 1, 28, 122], [15, 13, 1527, 1, 11, 1966, 7, 276, 741, 123, 80, 234, 31, 5, 616, 102, 1896, 205, 22, 2778, 43, 308], [4, 19599, 96, 14, 11, 2471, 196, 4, 1603, 1742, 11, 8747, 12, 19600, 4749, 1605, 12, 478, 6, 3963, 3827], [75, 227, 2, 9, 173, 2, 331, 436, 19601], [56, 63, 49, 156, 2389, 154, 451, 82, 4, 6085, 1655], [8, 111, 72, 1519, 12, 723], [1, 7, 472, 13, 22, 24, 578, 13, 341, 381, 591, 8, 89, 19602], [3, 75, 397, 5, 296, 29, 262, 8748, 30, 283], [203, 1, 584, 4790], [10, 992, 226, 118, 14, 158], [57, 202, 8, 190, 8, 48, 61, 6, 404, 22, 213, 329, 4, 729, 12, 3339, 19603], [158, 343, 1506, 82, 22, 1, 69, 124, 2, 2328, 18, 4, 108, 16, 50, 40, 911, 82, 5755, 892], [23, 2, 762, 4, 24, 54, 13, 290, 264], [19, 27, 263, 8, 88, 66, 2884, 9], [32, 260, 49, 1348, 1792, 140, 36, 107, 54, 16, 4, 3431, 11, 19604], [32, 15, 114, 12, 68, 275, 6, 396, 7, 25, 34, 15, 114, 947, 25, 6, 396, 7, 9], [1, 14, 197, 8, 176, 751, 13, 40, 46, 105, 912, 2, 420], [8749, 8749, 55, 90, 470, 4, 111, 116, 55, 804, 30, 9, 55, 1490, 30, 522, 647, 3, 96, 204, 7, 45, 277, 513], [38, 2, 9, 28, 459, 493, 2217, 534], [55, 33, 37, 42, 104, 62], [19, 987, 1, 63, 5, 867], [52, 62, 1537, 52, 33, 152, 70, 15, 73, 969, 16, 2, 3516, 73, 19605, 47, 378, 16, 2314, 5657, 9, 102, 756, 26], [795, 35, 173, 4, 7069, 1, 8147, 3, 222, 168, 256, 6, 2726, 10, 30, 27], [2211, 5, 87, 11, 164, 12, 1149, 1, 8, 164, 19606, 160, 1620, 1652, 654], [19607, 113, 17, 52, 317, 119, 24, 8, 32, 16, 4, 2547, 3, 29, 249, 138, 6129, 160, 2485, 2421, 1814], [296, 1849, 1685, 4804, 18, 10, 138, 230, 3, 61, 54, 218, 3, 29, 67, 39, 1, 6, 430, 2, 5142, 53, 160, 6939], [1163, 250, 2008, 2496, 3, 216, 11, 1197, 47, 6, 303, 2, 1802, 1072, 53, 160, 1814, 31, 7291], [1320, 101, 184, 7, 19608, 136, 1460, 17, 12, 7, 11, 488, 39, 9, 46, 2395, 160, 6086, 5311], [4095, 157, 358, 332, 138, 142, 305, 977, 4, 577, 5, 222, 58, 12, 735, 2, 141, 24, 53, 160, 19609], [5, 62, 40, 2, 391, 38, 40, 191, 21, 435, 3811, 489], [128, 550, 92, 100, 1636, 4000, 24, 112, 25, 62], [665, 45, 35, 8, 28, 19610, 120, 56, 64, 22, 19611], [69, 67, 6, 14, 725, 19612, 253, 253, 1], [1, 208, 13, 40, 105, 297, 2, 231, 4781], [8750, 363, 82, 14, 2, 180, 203, 1431, 6, 2, 703, 83, 519, 193, 52, 295, 34, 2, 8091], [19613, 38, 6456, 532, 36, 373, 24], [5, 1649, 7, 23, 4, 112, 76, 166, 1, 12, 963], [1, 14, 705, 6, 72, 53, 100, 17, 349, 54, 10, 6383], [3529, 39, 9, 2395, 163, 709, 709, 709, 709, 709, 709, 26, 26, 26, 26], [29, 70, 17, 349, 54, 4, 19614, 9], [922, 106, 3, 58, 15, 21, 97, 3, 70, 7, 89, 24, 5596], [4778, 1576, 4, 4778, 141, 269, 74, 19615, 8751, 534, 1854, 4, 761, 4, 91, 27, 4, 190, 1100, 317, 67, 5], [1998, 12, 3190, 6, 19616, 20, 24, 19617, 8, 1757, 73, 19618, 73, 7772], [3, 67, 6, 119, 73, 209, 24, 73, 3, 63, 230, 8540, 160, 19619, 160, 5936], [60, 287, 33, 2128, 1236, 27, 2, 1984, 1468, 24], [33, 119, 978, 353, 11, 19620], [23, 270, 2, 1, 6, 350, 85, 58, 5, 741, 224], [19621, 1051, 6, 263, 21, 5633, 1036, 19622], [31, 753, 17, 20, 2, 141, 1, 1027, 5, 487, 806, 10, 175, 55], [19, 39, 19623, 1, 36, 32, 4, 199], [299, 5, 220, 376, 1, 439], [32, 15, 114, 12, 68, 1, 30, 269, 74, 1044, 6, 19, 35, 155, 481, 1258, 8, 19624], [8752, 109, 12, 208, 13, 2, 666, 16, 1150, 8728, 75, 1475, 6, 19625, 98, 1575, 5, 19626, 12, 970], [5006, 8753, 56, 81, 210, 3242, 1311, 34, 5006, 8753], [5, 62, 10, 4946, 1360, 46, 843, 31, 40, 783, 1732, 34, 19, 250, 843, 790, 2579, 18, 4, 19627, 16, 4, 285], [57, 275, 58, 18, 186, 1121, 1580, 133, 2928, 1272, 79, 166, 275, 9, 1375, 323, 1788, 2591, 733, 133, 3186, 3219, 19628], [5, 146, 14, 2, 109, 669, 1, 6, 100, 495, 175, 1001, 5, 19629, 31, 5, 105, 704, 4, 395], [1493, 21, 164, 439], [2123, 68, 1667, 26, 6061, 368], [3, 3006, 201, 141, 1, 30, 688, 1164, 206, 129, 2, 707, 892, 21, 212, 513], [177, 28, 640, 8, 19630, 21, 2, 77, 43, 24, 28, 30, 25], [8650, 121, 31, 3, 1112, 10, 231, 8, 338, 33, 10, 387, 8754, 151, 44, 3435, 16, 1], [429, 2, 1361, 85, 29, 5, 9, 192, 1872, 60, 1809, 829], [308, 62, 52, 29, 14, 723, 11, 19631, 3616, 7, 1582, 235, 282], [79, 17, 206, 1698, 34, 23, 19632, 612, 27, 1579, 8, 942], [549, 16, 1, 1, 59, 166, 283], [3, 87, 2, 1], [180, 1, 107, 6, 4, 489, 472, 219, 27, 1165, 962], [2398, 1, 685, 19633, 3, 64, 15, 19634, 311, 3350, 82, 2702, 4781, 527, 410], [3, 29, 194, 4, 1259, 1698, 229, 140, 3, 44, 1104, 1473, 130, 32, 16, 212, 2519, 1, 649], [1, 23, 48, 2515, 59, 350], [111, 49, 627, 7, 4, 2326, 747, 4, 2669, 12, 144, 281], [17, 38, 495, 72, 1133, 19635, 12, 56, 26], [159, 925, 28, 446, 21, 22, 26], [3, 600, 14, 2, 1, 34, 577, 3, 176, 15, 1798], [567, 95, 2420, 92, 5, 63, 137, 268, 95, 51, 469, 3131, 2245, 27, 268, 111, 55], [33, 2, 141, 3857, 1], [243, 457, 6, 4, 19636, 25, 346, 5, 8, 253, 10, 154, 1024, 2252, 187], [31, 20, 137, 567, 95, 19637, 1129, 3396, 3035, 19638, 6, 492, 259], [4, 3863, 16, 463, 72, 43, 6, 590, 24, 2263, 1137, 4837, 136, 132, 2914], [31, 5, 46, 2, 2345, 20, 2345, 2692], [162, 32, 10, 408], [526, 3, 47, 3927, 8, 486, 1319, 175, 4, 5414, 649, 81, 59, 955], [3, 300, 6, 274, 60, 189, 49, 1104, 1, 130, 77], [9, 258, 2, 193, 6, 8498, 43, 690, 57], [4, 91, 69, 5443, 19639, 19640, 47, 255, 2, 232, 2486], [71, 63, 621, 90, 159, 925], [3, 29, 44, 2, 1250, 6, 10, 347, 7, 1, 1797], [4535, 19641, 176, 4, 190, 4118, 19642, 277, 4, 421, 16, 4, 2160, 8, 19643, 12, 7679, 2234, 115, 21], [53, 252, 415, 33, 86, 119, 24, 12, 249, 18, 24, 767, 53, 8755, 311, 15, 54, 1707], [71, 202, 1, 484, 38, 36, 1988, 323, 107, 18, 3795, 1121, 26], [230, 3, 3860, 76, 3, 935, 10, 3078], [503, 3790, 1, 343, 142, 6, 50, 30], [23, 6010, 155, 264, 35, 11, 10, 154, 331, 233, 149, 1, 3, 197, 6, 332, 996, 22, 154, 331, 233], [105, 6081, 169, 173, 2, 291, 1, 233], [23, 2, 431, 30, 25, 19644, 2510, 31, 2, 663, 29, 13, 19645, 5, 519, 90, 74, 214, 1027, 80, 1, 1668], [3, 257, 4, 24, 35, 35, 35, 35, 3123], [15, 457, 3, 301, 5, 239, 180, 517, 9, 3733, 45, 272, 227, 35, 21, 20, 457, 99], [48, 2, 4774, 1103, 2, 1], [66, 29, 67, 43, 703, 1, 28, 54, 66, 67, 180, 517, 1], [2017, 1278, 227, 142, 1320, 19646, 380, 5, 222, 72, 52, 210, 62, 38, 6, 236, 26, 26, 26, 105, 3306, 26], [642, 204, 4, 1347], [15, 12, 219, 1370, 7, 608, 19647, 6, 942, 22, 5584, 1188], [8756, 12, 54, 18, 4, 3811, 1134, 96, 65, 21, 84, 19648, 19649, 1908], [55, 40, 572, 5, 141, 1, 39, 2124], [8, 31, 5, 46, 2, 9, 28, 35, 54, 10, 941, 331], [110, 31, 5, 90, 4, 232, 116, 12, 43, 193, 5, 75, 13, 1098, 891, 52, 12, 68, 16, 4, 19650, 8, 247, 538, 137], [53, 31, 3, 448, 2, 406, 16, 10, 414, 32, 5, 9, 756, 102, 2, 4688, 390, 1821], [251, 57, 2, 282, 5, 33, 487, 2761], [38, 2, 1, 987, 18, 5, 11, 4, 489, 8, 5, 1702, 4, 396, 11, 50, 1434], [18, 4, 1194, 11, 305, 548, 57, 31, 883, 1098, 891, 883, 11, 19651, 6, 5913], [22, 381, 13, 1993, 18, 113, 240, 3, 672, 20, 1, 30, 5723, 36, 46, 105, 1679, 442, 20, 171, 3115, 26], [128, 9, 92, 2, 115], [19652, 742, 2114, 7, 1, 63, 249, 10, 138, 19653, 742, 2114, 7, 1, 63, 249, 10, 138], [19654, 487, 4901, 22, 252, 69, 67, 6, 28, 19655, 56, 19656, 56, 7, 290, 47, 248], [19657, 1, 19658], [1, 10, 138, 12, 80, 1283], [94, 20, 24, 26, 395, 146, 14, 56, 31, 2, 25, 139, 81, 6, 5, 211, 352], [128, 2, 9, 443, 658, 12, 1354, 658, 42, 46, 62, 850, 9, 227, 173, 1444, 1039], [3114, 862, 5, 175, 7, 3967, 220, 248, 279, 6, 19659, 160, 19660, 5460, 1605, 3033, 465], [1552, 531, 98, 1947, 3132, 2167, 1778, 2787, 27, 1085, 19661, 8, 3310, 949, 4628, 57, 33, 265, 15, 1753, 2115], [19662, 1, 4, 19, 15, 4204, 8, 66, 49, 614, 6, 255, 202, 42, 75, 400, 27, 6077], [6443, 300, 40, 2, 89, 1], [55, 19663, 68, 115, 36, 152, 44, 2, 44, 2, 2889, 2161, 16, 17, 4693, 143, 45, 54, 16, 60, 24, 11, 10], [55, 3, 14, 1831, 143, 45, 459, 667, 285, 151, 105, 14, 2, 8751, 24, 5635, 1000], [3, 29, 28, 85, 111, 1, 59, 98, 753, 38, 5, 105, 81, 6, 76], [1, 58, 15, 65, 13, 3, 279, 163, 709, 709, 709, 709, 709, 709, 26, 26, 26, 26], [20, 19664, 878, 20, 265, 6, 14, 2, 1055, 285, 93, 3629], [39, 9, 109, 118, 400, 11, 20, 231, 8, 208, 13, 36, 4509, 4, 360, 11, 4, 575, 132, 172, 102, 4, 413], [743, 49, 19, 1490, 157, 142, 20, 4009, 19665, 8, 19666, 2360, 3, 131, 61, 402, 6, 402, 27, 32, 4, 7051, 24, 30, 3432, 188], [48, 33, 149, 16, 9, 61, 6, 865, 149, 16, 19, 35, 9, 3049, 163, 70, 76, 79, 5, 235, 19667], [805, 928, 211, 244, 5, 13, 7, 80, 386, 2, 181], [734, 121, 43, 24, 534, 1077, 16, 10, 381, 1728], [48, 2, 1793, 408, 2174, 11, 4, 1507, 34, 993, 5, 19668, 12, 2, 950, 2469, 21, 393, 211, 2317], [105, 505, 20, 504, 6, 70, 2, 9, 243], [185, 609, 1, 139, 123, 8757, 11, 4, 19669, 6, 608, 2, 434, 3023, 188], [3, 502, 10, 518, 6, 22, 89, 30, 1, 2, 607, 115, 19670, 121, 151, 79, 5, 38, 3, 70, 15, 2247, 23, 192, 6, 86, 794], [1379, 20, 2537, 12, 2, 1, 646, 12, 2, 2600, 338, 240, 398, 771, 8, 1475, 27, 20, 19671, 160, 5794], [19672, 1121, 119, 4, 24, 1272, 257, 4, 24, 35, 1375, 1918, 6, 4, 24, 123, 119, 15, 361, 140, 15, 37, 1639], [3, 67, 6, 114, 4, 106, 390, 6, 3317, 32, 16, 4, 500, 9], [40, 168, 6, 14, 127, 501, 73, 2, 9, 5926, 154, 5, 12, 6, 1531], [23, 2424, 602, 6, 119, 24, 38, 15, 106, 99, 119, 30, 12, 33, 19673], [97, 1, 1950, 313, 1407, 5769, 18, 4, 2306, 8, 733, 59, 4, 19674, 69, 107, 2230, 2018, 97], [5, 62, 20, 183, 38, 98, 673, 47, 5357, 73, 2, 91, 1562, 8, 814, 105, 132], [22, 1, 107, 35, 8, 349, 50, 815, 3101, 57, 58, 5, 58, 26, 4, 127, 4, 2721], [22, 25, 4705, 712, 532, 13, 89, 24], [2002, 6, 1098, 19675, 237, 232, 182], [29, 19, 27, 42, 9], [38, 1264, 121, 8758, 207, 2680, 3, 842, 4738, 8759], [245, 443, 102, 190, 1623, 32, 16, 15], [3, 58, 62, 68, 184, 205, 1, 36, 107, 26, 2631], [25, 276, 81, 1, 276, 4232], [19676, 19677, 456, 70, 166, 177, 150, 13, 56], [195, 3, 4, 101, 68, 1118, 94, 39, 9, 19678, 36, 139, 175, 21, 292, 6, 445, 449, 8, 107, 8760, 27, 4, 199, 64, 175, 133], [2363, 41, 2007, 1085, 927, 39, 9, 46, 334, 1336, 7, 46, 2007, 1085, 205], [2408, 1553, 12, 19679, 123, 2830, 1992, 26, 86, 2775, 12, 206, 19680, 23, 723, 123, 50, 206, 1100, 30, 429, 19681], [58, 3, 28, 6, 479, 4, 4216, 69, 7467, 17, 18, 19682, 19683, 38, 4, 1205, 258, 4, 2614, 16, 4, 1, 69, 2036], [3, 33, 131, 1078, 39, 19684, 26, 498, 19685], [26, 19686, 3, 86, 469, 217, 136, 19687, 3701, 82, 2116, 8, 12, 8726, 144, 111, 982, 19688], [19689, 19690, 16, 1276, 3092, 936, 173, 4, 234, 16, 217, 331, 21, 44, 2, 95, 5973, 18, 126, 19691, 19, 95], [585, 3, 63, 532, 254, 15, 33, 59, 4374, 19692, 4, 19693, 35, 8, 349, 54, 2, 19694, 1965, 35, 7501, 5100, 10, 697, 177, 19695], [8761, 6513, 39, 1802, 19696, 64, 6, 385, 982, 44, 748, 4, 392, 8762], [264, 106, 19697, 23, 19698, 19699, 615, 2, 91, 16, 19700, 3, 507, 2, 95, 1508, 173, 10, 1178, 16, 19701, 8, 3, 105, 58, 448, 2763], [1, 19702, 38, 36, 131, 233, 136, 1710, 1, 48, 129, 135], [15, 65, 13, 52, 255, 2, 56, 558], [29, 1189, 4, 91, 225, 11, 5451, 5, 600, 87, 6, 119, 20, 24, 740], [1798, 52, 119, 20, 24, 444, 42, 6572, 37, 85, 42, 75, 2753, 4, 3002], [503, 473, 593, 1356, 2694, 651, 8379, 2936, 95, 1508, 3258, 2660, 1083, 7, 36, 29, 259, 123, 6013, 978, 1145], [3508, 31, 5, 46, 2, 9, 28, 35, 54, 10, 5990], [2588, 940, 1, 2251], [29, 453, 17, 23, 33, 129, 135, 1532, 6, 1226, 174, 1, 71, 6, 4551], [10, 154, 213, 5957, 12, 6, 19, 174, 1, 862, 106], [5, 362, 58, 44, 2, 322, 231, 21, 2, 1224], [8, 3, 29, 44, 245, 4593, 19703, 11, 5, 6776, 20, 4, 508, 540, 85, 22, 823, 12, 11, 22], [58, 48, 8, 3, 3383, 58, 48, 1191, 6, 50, 73, 20, 1063], [4052, 87, 2312, 6, 28, 262, 82, 9], [2775, 30, 1590], [21, 112, 22, 178, 12, 19704, 56, 100, 58, 692, 8, 28, 1131], [5, 1034, 62, 7, 1191, 6, 2, 77, 73, 1063, 317, 70, 20, 138, 245, 1104, 117], [26, 19705, 5264, 43, 19706], [1542, 78, 58, 4, 1057, 1611, 31, 78, 48, 152, 19707, 218, 66, 29, 19708, 26, 3339, 1009, 6, 3083, 2186, 159], [19709, 634, 4, 95, 543, 60, 19710], [280, 5, 33, 216, 17, 67, 7, 236, 110, 127, 57, 213], [55, 10, 1789, 46, 43, 162, 1196, 93, 34, 3, 62, 4, 117, 91, 21, 4, 401, 233, 7, 236, 417, 464], [3, 328, 124, 474, 5, 9, 182, 67, 19711, 6, 10, 5230, 25, 596, 4, 169], [31, 3021, 61, 6, 4, 1450, 36, 96, 276, 14, 56, 650, 3021, 28, 1101, 2930, 19712, 170, 19713, 11, 2, 5040, 2134], [164, 2, 1], [22, 1960, 19714, 19715, 16, 28, 2060, 232, 408, 6, 1567, 4779, 6064, 12, 5564, 527], [70, 362, 5, 114, 20, 3736, 54, 18, 19716, 2176, 1185, 3, 2603, 2, 19717, 8, 7, 1, 124, 15, 3305], [3, 983, 514, 10, 453, 31, 5, 258, 15, 61, 3421, 8, 176, 15, 1], [1960, 2155, 12, 68, 183, 386, 16, 2, 1], [3, 301, 2, 1, 118, 113, 17, 256, 7, 3, 29, 62, 59, 10, 916, 19718], [105, 440, 1443, 907, 408, 33, 227, 173, 319, 599, 590, 1383, 7, 1463, 6, 13, 19719], [19720, 3, 47, 11, 2, 56, 558, 19721], [447, 34, 19722, 47, 4514, 163, 210, 131, 61, 19723, 13, 2, 1, 52, 440, 4, 1013, 73, 1709], [3, 94, 5, 189, 543, 22, 358, 343, 104, 54, 20, 161, 496, 178, 412], [37, 5, 152, 442, 8591, 1224, 74, 2, 6052, 3881], [3, 63, 94, 4315, 2351, 1399, 108, 163, 5697, 11, 2, 1825, 16, 163, 2845, 712, 27, 84, 104, 343, 32, 11, 84, 231, 854, 201, 19724], [3, 96, 528, 51, 8229, 14, 626, 16, 19725, 394, 52, 47, 345, 13, 2, 1, 38, 52, 41, 84, 315, 30, 2292], [452, 453, 484, 35, 6, 179, 30, 19726, 19727, 33, 6, 491, 4, 45, 54, 16, 8380, 8, 194, 170, 397, 116, 8, 33, 2177], [268, 377, 687, 129, 3318, 6476, 103, 70, 20, 115], [463, 4379, 9, 75, 58, 4548, 174, 117, 19728, 247, 3, 58, 12, 3209, 60, 8763, 6067, 18, 254, 166, 45, 46, 5833], [38, 5, 949, 35, 10, 2273, 19729, 12, 6, 543, 4, 676, 242], [567, 95, 70, 17, 33, 1131, 10, 310, 173, 10, 231], [8257, 915, 49, 4, 68, 69, 1, 4, 247, 59, 126, 1334, 19730], [15, 7230, 8, 20, 91, 12, 27, 84, 166, 83, 2, 5981, 8, 5, 109, 2053, 19, 4546], [15, 1, 2526, 16, 4, 213], [559, 8312, 4, 866, 1], [3, 14, 4101, 1, 288, 1, 14, 4101, 150], [29, 157, 4, 24, 18, 2, 8764, 774], [204, 17, 38, 1, 44, 2, 511, 112, 164, 3059, 155, 148, 1147, 1522], [3771, 1684, 26, 4, 2529, 699, 16, 642, 3350, 19731], [162, 49, 36, 92, 5286, 3234, 19732, 19733, 2867, 352, 19734, 19735, 2322, 365, 7263, 92, 1024, 19736, 19737], [1276, 1115, 83], [4, 68, 66, 109, 13, 66, 75, 5462, 34, 31, 5, 41, 4, 68, 5, 109, 13, 88, 5, 2, 811, 83], [77, 183, 3592, 9, 57, 22, 88, 964], [1153, 71, 342, 5, 49, 7, 45, 29, 690, 31, 5, 41, 2, 56, 4884], [341, 102, 4, 1160, 135, 4722, 19738, 250, 19739, 1593, 382, 1122, 1581, 2, 154, 988, 1121], [38, 4, 1316, 8, 1111, 28, 612, 184, 1326, 61, 8765, 7409], [169, 12, 4, 832, 1, 3, 62], [38, 4, 24, 37, 93, 5, 75, 349, 897, 1269], [31, 42, 41, 1984, 476, 42, 63, 119, 10, 24], [4723, 9, 356, 483, 426, 1930, 96, 14, 13, 2080, 13, 22, 926, 30, 887, 110, 205, 4, 252, 132, 19, 21, 2655, 691, 596], [42, 96, 11, 174, 150, 8, 52, 11, 60, 154, 24], [993, 32, 4, 703, 952], [230, 1112, 35, 19740, 2504, 141, 3839, 1050, 19741, 867, 4, 1177, 21, 19742, 26, 3489, 2391, 26], [3, 44, 98, 2091, 16, 1], [400, 322, 70, 1, 214, 322, 209], [3613, 30, 9, 3, 90, 2165, 156, 258, 45, 34, 75, 258, 2, 91, 6, 438, 240], [2, 269, 27, 2, 3074, 123, 8515, 19743], [40, 1112, 470, 16, 50, 231, 8, 40, 96, 127, 4153, 130, 32, 16, 5, 9, 19744], [10, 228, 4, 862, 4993, 136, 4, 19745, 8, 19746, 3146, 21, 8521, 19747, 1550, 20, 5764, 717], [3, 33, 592, 54, 7, 19748, 12, 1803, 21, 19749, 887], [1, 81, 133, 765, 133, 2177, 497, 54, 18, 61, 54, 5, 1, 33, 72, 147, 149, 15, 28, 587, 8, 42, 1, 717], [19750, 19751, 3410, 6, 2085, 1212, 213, 206, 788, 4751, 18, 4, 193, 6, 4, 56], [2403, 61, 81, 6, 174, 9, 371, 42, 29, 131, 262, 108, 163, 1931], [3, 300, 66, 11, 22, 1115, 92, 1], [2, 77, 175, 463, 318, 14, 179, 31, 42, 316, 522, 82, 619, 173, 4, 3099, 43, 42, 318, 14, 185, 31, 42, 389, 3100, 21, 2, 8766], [2403, 61, 81, 6, 174, 1, 371, 40, 80, 1562, 163, 1931], [42, 600, 86, 23, 2, 1, 34, 73, 738, 73, 5, 28, 6, 62, 17, 42, 623, 7, 250, 1268, 49, 117, 8, 3, 195, 2, 1], [2351, 3277, 19752, 6, 4, 19753, 10, 1, 2, 1698, 3244, 40, 14, 624, 1872, 1318], [42, 58, 623, 38, 5, 72, 2612, 10, 500, 8136, 55, 19754, 15, 70, 5, 598, 13, 2, 2504, 141, 187, 7, 75, 598, 6, 855], [92, 100, 28, 6041, 5, 233, 5, 19755, 5416, 183, 19756, 541, 1, 3, 103, 48, 3609, 10, 106, 6188], [753, 17, 83, 3, 266, 345, 59, 254], [1, 55], [1028, 782, 4294, 1028, 3627, 19757, 1028, 159, 19758, 1028, 219, 19759, 1028, 4118, 19760], [932, 91, 26, 52, 8767, 2150, 11, 4, 24, 21, 112], [55, 416, 2, 161, 1], [85, 4115, 1733, 690, 92, 127, 130, 182, 527], [9], [349, 2, 544, 95, 82, 10, 19761, 8335, 6, 14, 54, 16, 4, 341, 2192, 15, 3459, 51, 17, 27, 15, 4481, 387, 19762], [31, 80, 1, 101, 19, 27, 5, 7254, 16, 20, 169, 1180, 49, 245, 25, 27, 60, 169, 63, 19, 50], [354, 3063, 904], [354, 3063], [5, 63, 191, 630, 31, 5, 302, 19763, 7927, 8, 19764, 74, 5, 63, 946, 367, 8, 105, 86, 59, 4, 187, 182, 2], [116, 318, 14, 2, 535, 1984, 4220, 18, 4, 4304, 34, 36, 32, 137, 19765, 120, 91, 1641], [31, 2, 19766, 113, 5, 52, 317, 119, 24, 19767, 6, 44, 352, 33, 6049, 528, 73, 42, 157, 20, 754, 18, 528, 73, 42, 1080], [365, 30, 1, 321, 55], [38, 5, 477, 6, 2, 1, 733, 59, 2, 25, 7, 46, 110, 7560], [364, 12, 2, 260, 1487, 1, 42, 223, 44, 57, 5, 223, 2912, 260, 1487], [90, 2, 1, 7, 298, 50, 476, 26], [1585, 58, 24, 30, 45, 3937, 13, 1053, 50, 64, 19768, 1053, 358, 19769, 59, 71, 814, 105, 1559, 22, 193, 340], [12, 37, 2571, 478, 37, 8028, 267, 5, 21, 477, 6, 17, 1], [3464, 19770, 2, 811, 144, 55], [31, 3, 47, 8002, 18, 98, 2339, 8, 222, 101, 316, 68, 184, 3, 118, 316, 8003, 7, 1, 136, 474, 11, 7, 3458, 188], [112, 228, 29, 28, 1001, 38, 5, 79, 76, 1, 9, 74, 2639, 36, 872, 8, 79, 5, 256, 127, 19771], [3, 150, 13, 119, 24, 117, 19, 92], [4, 101, 717, 1533, 1, 198, 14, 640, 21], [470, 4, 1, 7, 72, 19772, 452, 110, 61, 3, 4480], [24, 37, 93, 124, 6, 492, 7, 45, 21, 790], [2, 275, 103, 1870, 1233, 5, 44, 9, 31, 40, 258, 5, 3666], [13, 3, 62, 3, 63, 14, 2, 1, 601, 34, 60, 111, 87, 6, 62, 126, 822], [3, 64, 24], [34, 88, 116, 4, 190, 1053, 18, 4, 202, 19773, 188], [48, 1003, 185, 1, 19774, 4114, 19775], [3, 94, 4, 199, 9], [4, 4885, 4910, 16, 4, 1398, 12, 328, 92, 471, 7, 4375, 1, 6, 2810], [19776, 1650, 79, 1271], [3, 208, 13, 432, 19777, 636, 147, 1], [39, 9, 14, 208, 35], [56], [1208, 12, 56], [80, 1, 3959, 17, 235, 288, 3, 194, 93, 19778], [1378, 63, 1689, 58, 6, 229, 2957, 27, 4, 494, 19779, 19780, 5919, 19781], [363, 6, 398, 1255, 140, 16, 20, 1, 30], [34, 3, 46, 214, 51, 50, 19782, 586, 7, 4, 237, 148, 24, 3, 182, 124], [3394, 5, 104], [3, 90, 38, 2676, 139, 26, 191, 31, 23, 96, 2687, 13, 367, 42, 86, 3, 41, 35, 26, 192, 1042, 1406, 27, 10, 164, 1, 157], [10, 2371, 1581, 14, 2, 3227, 1, 8, 7, 15], [3, 86, 2378, 122, 6, 72, 84, 24, 12, 99, 19783], [241, 19784, 27, 4, 19785, 5, 134, 68, 4726, 148, 59, 4, 19786, 19787, 16, 4, 2678, 5, 49, 19788, 7008], [53, 6, 39, 9, 23, 8768], [31, 5, 134, 7, 2917, 245, 299, 51, 32, 5, 103, 623, 15, 70, 43, 4166, 51, 1284, 333, 86, 1261], [85, 19789, 65, 13, 52, 133, 6, 506, 4, 247, 179, 168, 347, 16, 862], [38, 52, 1730, 84, 1291, 224, 10, 3609, 288, 23, 70, 1283, 190, 1085, 5175, 393, 1309, 2, 188], [15, 4, 192, 16, 246, 190, 1925, 658, 390, 71, 59, 2, 21, 32, 4, 1925, 408, 188], [19790, 18, 11, 4, 195, 255, 20, 875, 856, 2, 1280, 26, 751, 2, 259, 4810, 545, 17, 951], [63, 5, 79, 217, 2, 529, 88, 79, 76, 7370, 368, 11, 4, 199, 1355, 461, 468, 19791], [111, 395, 37, 5, 62, 161, 1910, 41, 9], [2200, 78, 575, 46, 45, 34, 2, 3863], [77, 109, 14, 3235, 27, 36, 252, 1636, 76, 73, 3147, 368, 23, 370, 34, 7, 103, 105, 635, 27, 307], [5, 982, 1, 59, 393, 444, 20, 11, 2, 1850, 395, 1143, 1858], [1625, 142, 6, 17, 1, 3, 195, 20, 1830], [77, 29, 100, 2, 189, 557, 5, 13, 2, 190, 3205, 42, 49, 2, 1106, 3205], [17, 100, 122, 2, 1700, 3185, 16, 10, 250, 115, 16, 197, 4, 587, 281, 221, 117, 3, 19, 20, 347, 8, 20, 1], [4, 95, 619, 10, 4867, 1371, 44, 193, 99, 209, 6, 81, 59, 21, 250, 184, 11, 4, 561, 19792], [242, 35, 1, 55], [3, 29, 86, 3, 110, 132, 11, 2, 112, 19793, 299, 36, 47, 112, 34, 36, 220, 33, 56], [16, 2384, 642, 1165, 54, 308, 6, 28, 8727, 19794, 5232, 277, 15, 70, 92, 648, 15, 2, 1, 951], [360, 1833, 862, 5629, 19795, 382, 2484, 27, 19796, 3893, 19797, 19798, 26], [234, 9, 2618, 101, 119, 234, 2417, 972, 367, 49, 57, 367, 119, 19799, 8769], [369, 47, 898, 191, 263, 6, 349, 129, 37, 52, 63, 28, 10, 8589, 1, 23, 19800, 19, 5, 898], [23, 33, 542, 6, 28, 2957, 37, 3, 63, 563, 4, 154, 1835, 16, 46, 45, 1, 19801], [3890, 49, 19802, 168, 4, 2039, 6, 382, 4, 4688, 3019, 73, 19803, 74, 944, 8534, 4, 965], [17, 8, 49, 11, 305, 190, 7736, 19804], [158], [369, 22, 1, 291, 50, 1291, 19805, 106, 40, 167, 4, 45, 26], [3992, 2, 104], [14, 2, 93, 4402, 479, 35, 56, 647], [1, 14, 19806, 54, 833, 13, 351, 1745, 522, 4112, 51, 4, 1483, 8, 61, 6, 618, 155, 264, 454, 85, 36, 46], [20, 2, 285, 5, 44, 127, 19807, 752, 11, 20, 830, 130, 19, 3, 134], [4, 4754, 47, 56, 215, 658, 1047, 4, 4754, 5135, 19808, 222, 70, 2, 1408, 842, 31, 36, 44, 2, 434, 8645, 48, 8770], [2886, 25, 23, 635, 66, 6087, 1, 43, 308], [31, 40, 41, 4, 2765, 4173, 2359, 7, 9], [139, 1453, 97, 265, 6, 114, 39, 406, 42, 122, 6, 941, 25, 2492, 125, 42, 1746, 9], [243, 923, 1, 19809], [3, 394, 116, 49, 625, 388, 69, 33, 41, 889, 633, 51, 7, 2543, 2786], [23, 1061, 1003, 60, 16, 42, 189, 44, 182, 297, 2, 24], [229, 17, 20, 285], [128, 57, 10, 25, 33, 273, 17, 9, 39, 4669, 36, 1886, 4, 1790, 6048], [399, 7723, 124, 2765, 304, 21, 170, 51, 84, 331, 811, 19810, 55], [53, 31, 5, 182, 124, 98, 2828, 5, 41, 19811, 24, 53, 526, 128], [3, 96, 46, 41, 4, 106, 21, 2, 1, 6, 14, 208, 4252], [156, 2, 203, 1, 11, 4, 2848, 1251, 34, 105, 2, 252, 11, 2, 19812], [2364, 263, 4785, 123, 1132, 6088], [1711, 830, 11, 10, 844, 27, 984, 253, 24, 2856, 29, 67, 1317, 26], [4739, 1, 6991, 42, 37, 341, 1, 4739], [8771, 105, 4786, 26, 8772, 69, 56, 155, 166, 3159, 105, 4786, 8773, 8774], [3465, 3466, 1379, 2, 189, 81, 6, 473, 77, 12, 52, 2, 9, 74, 277, 52, 44, 894], [37, 221, 12, 4, 19, 237, 8, 3, 118, 109, 90, 259, 31, 3, 210, 62, 876, 10, 89, 1, 1512, 2980], [3366, 731, 265, 13, 6, 429, 739, 353, 11, 4, 261, 92], [10, 1307, 3369, 107, 54, 38, 3, 28, 224, 10, 730], [32, 4, 1, 69, 79, 17, 2, 9, 11, 314, 261, 41, 13, 8722, 265, 3448], [4062, 8775], [4062, 8775], [31, 1502, 791, 8776, 8777], [8776, 8777], [418, 86, 7, 44, 352, 27, 2, 189, 21, 707, 1870, 70, 170, 126, 520, 233, 1, 200, 5, 191, 170], [128, 36, 32, 56, 230, 26, 211], [1095, 18, 10, 2941, 467, 2154, 3, 1124, 7, 3, 195, 11, 488, 2, 339, 83], [75, 304, 6, 119, 8, 94, 10, 228, 316, 18, 212, 148, 190, 4080, 188], [53, 57, 2, 193, 21, 1098, 891, 6, 637, 84, 232, 1330, 19813], [19, 760, 40, 165, 19814, 10, 1511, 20, 2, 1262, 91, 8, 86, 119, 24, 12, 19815], [184, 6, 375, 601, 14, 2, 1, 12, 5833, 741, 6, 20, 8778, 19816, 2288, 856, 460, 49, 93, 972], [782, 6089, 415, 19, 32, 39, 9, 52, 415, 118, 14, 31, 52, 407, 2, 5112], [1327, 12, 21, 187, 42, 12, 21, 174, 2, 187, 163, 12, 21, 48, 362, 42, 62, 22, 34, 174, 2, 187, 965, 12, 21, 227, 224, 83, 174, 2, 187], [32, 39, 9, 156, 533, 45, 59, 116, 3042, 65, 1, 31, 20, 152, 81, 45, 6, 17, 151, 14, 243, 6, 737, 5, 11, 80], [43, 20, 2, 158, 61, 479, 10, 1984], [5, 500, 1, 87, 6, 623, 26], [3, 62, 162, 3, 118, 14, 390, 31, 3, 47, 11, 3, 63, 394, 7, 1, 223, 14, 1722, 390], [5, 94, 50, 677, 40, 456, 44, 257, 50, 373, 24, 35, 2002], [19817, 1047, 211, 19818, 19819, 8393, 47, 33, 73, 56, 73, 421, 1758], [23, 48, 113, 5, 6, 13, 1057, 875, 74, 19820, 355, 139, 346, 4, 3461, 33, 29, 79, 76, 56, 26, 113, 17, 5], [139, 19, 79, 39, 2112, 248, 218, 4, 503, 2526, 16, 305, 979, 19821, 82, 4, 19822], [52, 19823, 317, 19824, 52, 13, 2297, 9, 52, 13, 1613, 9, 52, 13, 19825, 73, 358, 73, 36, 1758], [29, 14, 370, 9, 14, 279], [15, 201, 184, 11, 22, 360, 7, 3, 46, 297, 7, 2, 19826, 26, 2, 1, 7, 3, 87], [695, 158, 12, 626, 37, 3957, 49, 614, 6, 14, 54, 225, 55, 55], [3, 90, 38, 206, 1, 255, 754, 39, 379, 9, 14, 255, 13, 271, 80, 30, 11, 80, 1247, 1143], [3, 90, 38, 1, 987, 6, 981, 323], [3, 87, 60, 19827, 1643, 13, 217, 69, 47, 1348, 8, 1871, 6, 119, 285, 217, 69, 12, 98, 19828, 38, 15, 1266, 6, 8661], [1490, 30, 9, 156, 41, 10, 226, 11, 36, 2747], [28, 27, 4, 404, 412, 9], [7, 1, 1103, 914, 6, 13, 688, 52, 46, 5088, 134, 2133, 688, 1164], [85, 58, 9, 156, 67, 6, 107, 3409, 38, 36, 210, 44, 6, 338, 11, 4, 250, 507], [267, 21, 14, 202, 11, 8420, 8, 92, 1584, 213, 206, 5, 4846, 19829, 386, 16, 2, 1], [185, 19, 158, 5892, 5, 4751, 185, 2309, 2132, 269, 711], [19830, 25, 14, 37, 1160, 21, 24, 10, 89, 367, 60], [10, 244, 1, 146, 114, 17, 54, 33, 19831], [25, 81, 127, 130, 1, 39, 4669], [155, 77, 249, 1270, 29, 100, 7, 1, 902, 350], [31, 52, 191, 1378, 5, 59, 6, 7953, 211, 78, 28, 328, 19, 5, 2, 282], [4510, 53, 3, 62, 68, 236, 11, 5476, 69, 64, 446, 54, 7, 416, 499, 12, 2, 1989, 1821], [3, 156, 936, 10, 106, 18, 1555, 1], [32, 3, 94, 18, 10, 1747, 12, 1206, 1206, 1206, 3, 90, 261, 1206, 1206, 60, 186, 9, 1142, 1206, 1206, 349, 54, 1069], [2228, 23, 2, 9, 31, 3, 101, 19, 201, 19832, 1, 218, 36, 47, 237, 228], [31, 20, 77, 366, 441, 4, 19833, 2131, 20, 1, 21, 2, 1080, 34, 7, 575, 1487, 6, 97], [583, 40, 100, 559, 2, 607, 25, 19834, 1805, 2746, 24], [984, 319], [2, 414, 105, 359, 650, 2, 91, 3087, 50, 6, 58, 2021, 435, 101, 359, 21, 154, 24], [3, 29, 58, 777, 21, 43, 1, 7, 40, 452, 58, 21, 17], [23, 346, 2, 607, 184, 3, 109, 87, 11, 10, 164, 1074, 688, 2575, 885, 5204, 60, 1, 8, 2, 154, 1832], [31, 3, 28, 954, 74, 127, 800, 7, 2146, 3, 28, 984, 283, 100, 1385, 22, 469, 8, 21, 32], [31, 42, 208, 13, 2, 9, 211, 66, 291, 35, 23, 48, 329, 21, 86, 42, 220, 2, 9, 32, 1738], [31, 20, 228, 12, 2, 9, 42, 2, 9, 776, 95, 16, 2, 1508, 2230, 612], [31, 20, 77, 94, 7, 246, 77, 13, 5, 50, 226, 12, 1539, 368, 444, 3022, 19835], [435, 101, 359, 21, 285, 287, 359, 218, 36, 86, 36, 44, 201, 8779], [31, 43, 1, 262, 42, 117, 92], [31, 42, 514, 32, 20, 1], [139, 538, 287, 69, 1124, 6, 44, 2, 9, 3011], [139, 19836, 20, 77, 685, 871, 42, 1, 30, 25], [139, 936, 262, 18, 1, 69, 46, 238, 19, 42], [42, 2, 104, 31, 42, 1136, 35, 3521, 1421], [42, 2, 9, 31, 5, 44, 1334, 8, 20, 96, 3262], [287, 69, 87, 6, 14, 157, 11, 126, 507, 49, 248, 5, 49, 2, 1044, 48, 2, 1245, 1, 1769], [78, 1, 41, 6, 139, 842, 423, 4, 25, 69, 109, 279, 59, 78, 21, 39, 25, 69, 29, 134, 2, 19], [20, 77, 300, 42, 359, 444, 42, 19, 2, 1, 21, 112, 88, 15, 2612, 71, 222, 6657], [85, 49, 24, 2729, 37, 2091], [28, 2, 77, 27, 93, 343, 26, 42, 29, 67, 2, 1, 7, 41, 2329, 30, 343, 26, 80, 265, 223, 450, 35, 44, 5520, 25], [5, 1, 70, 474, 2, 575, 19837], [55, 3, 44, 98, 2065, 27, 532, 19838, 19839, 19840, 3341, 93, 5263, 19841], [275, 14, 2367, 208, 1494, 26, 227, 35, 13, 36, 1850, 26, 313, 4, 24, 13, 36, 1727, 188, 34, 96, 75, 433, 8610], [29, 436, 2, 9, 26, 450, 35, 13, 39, 201], [48, 32, 202, 77, 49, 179], [3, 146, 1189, 39, 9, 230, 36, 44, 2, 1180, 6, 1189, 17], [960, 888, 41, 1, 1265, 14, 2, 9, 12, 2, 2184, 27, 3919, 279, 5022], [22, 47, 4, 247, 529, 1, 11, 4, 19842], [63, 3, 316, 246, 1, 100, 44, 2, 7685], [2, 520, 8, 504, 614, 6, 528, 51, 39, 9, 2780, 2, 189, 198, 105, 44, 39, 9, 528, 51, 84, 19843], [77, 443, 493, 1993, 81, 6, 80, 894], [272, 28, 1039, 48, 187, 69, 1624, 645, 21, 3721, 1385, 21, 295, 34, 4, 19844, 511, 165, 5, 8, 17, 128], [881, 10, 19845, 301, 5, 19846, 3, 65, 19847, 3, 65, 1639, 18, 10, 19848, 18, 10, 236], [800, 21, 180, 517, 1], [247, 56, 923, 1468, 16, 32, 817, 29, 1726, 17, 18, 22], [321, 3, 105, 297, 37, 239, 183, 1, 11, 68, 406, 230, 251, 26, 12, 7, 8158], [19849, 3, 67, 60, 354, 8, 5824], [233, 3, 131, 683, 71, 6, 2457, 109, 93, 37, 3, 63, 14, 11, 4, 19850], [648, 2, 1], [21, 32, 5, 1, 7, 86, 20, 2, 1983, 368, 333, 113, 7, 6, 19851, 19852], [424, 22, 1, 292, 707, 6, 157, 2, 5133, 18, 1737], [155, 106, 2, 202, 414, 72, 2229, 368, 3, 19853], [25, 2468, 13, 1820, 34, 478, 36, 14, 4, 19854, 3487, 205, 3, 29, 7709], [38, 40, 107, 539, 27, 4, 677, 34, 36, 56, 34, 40, 41, 180, 815], [15, 568, 82, 1059, 6, 1, 3, 64, 5, 6, 3, 90, 5, 3, 87, 5, 6, 19, 5, 20, 10, 474, 6, 5], [38, 7, 68, 185, 1, 429, 35, 18, 20, 19855], [1419, 514, 11, 8504, 11, 1652, 26, 390, 11, 2921, 3749, 49, 983, 56], [841, 229, 2146, 3, 1597, 24, 21, 19856, 151, 2761], [5, 2, 104, 31, 5, 168, 3373, 140, 112, 25, 484, 551], [22, 1, 109, 243, 40, 41, 19857, 253, 82, 28, 543, 54, 16, 2, 420, 347, 123, 50, 2362, 1214, 8, 603, 19858], [3, 90, 38, 111, 114, 2, 406, 8, 14, 13, 53, 29, 453, 4, 2015, 53, 336, 1, 571, 453], [182, 271, 337, 82, 261, 8, 65, 51, 4, 2670, 8, 72, 221, 212, 1, 11, 1436, 117, 92], [57, 3, 301, 3, 63, 58, 155, 106, 3, 115, 137, 567, 95, 26, 2881], [31, 40, 63, 694, 436, 7, 83], [155, 275, 475, 59, 14, 137, 26, 155, 25, 475, 40, 2, 282, 37, 295, 34, 178, 103, 340, 137, 125, 7, 453], [7941, 4, 409, 16, 1, 7, 61, 6, 865, 6, 563, 435], [39, 1, 29, 64, 357, 26, 4, 236, 12, 21, 326], [3, 131, 194, 2, 158, 216, 230, 1503], [116, 24, 1631], [28, 2256, 16, 20, 500, 28, 2256, 16, 20, 9, 66, 29, 87, 43, 4732], [2, 535, 12, 1829, 19859, 48, 1829, 535, 26, 2918, 48, 1829, 535, 26, 19860, 48, 1829, 535, 26, 19861, 43, 9, 43], [32, 575, 107, 545, 1500, 30, 9, 2087, 5866, 19862, 32, 760, 101, 112, 535, 528, 51, 4, 45], [120, 1, 404, 361, 251, 3, 19, 90, 5], [1, 28, 15, 71, 5, 259], [15, 133, 7, 106, 220, 3, 150, 13, 132, 2, 332, 197, 414, 8056, 2, 1740, 9, 123, 264, 58], [155, 1, 27, 50, 30, 54, 18, 610, 1618, 14, 13, 998, 51, 4241, 21, 1177, 2697, 19863], [2, 112, 9, 103, 105, 100, 5, 227, 50, 173, 2, 331, 8148, 1358, 100, 5, 62, 57, 15, 12, 230, 5, 192, 430, 19864], [78, 1, 29, 62, 71, 6, 14, 228], [76, 166, 1, 46, 41, 295, 18, 17, 3, 63, 113, 123, 71, 20, 96, 19, 27, 6595], [993, 174, 19865, 17, 94, 827, 174, 1254, 1, 65, 19866, 1002, 19867], [463, 146, 14, 2404, 6, 176, 2, 1, 18, 50, 995, 74, 1358, 14, 18, 50, 1981, 27, 4, 244, 6184], [31, 3, 41, 106, 6, 555, 10, 310, 4, 413, 106, 66, 44, 2637, 80, 24, 56], [38, 5, 44, 2, 77, 264, 8, 5, 867, 21, 97, 1, 1335], [1558, 425, 128, 5, 158, 420, 1428, 1026], [2121, 37, 180, 3, 456, 1124, 3, 41, 155, 540, 6, 150, 13, 23, 7, 1], [38, 5, 9, 223, 683, 710, 507, 29, 28, 2, 5870], [53, 7, 46, 10, 3106, 22, 12, 4, 199, 91, 7, 67, 6, 14, 19868], [19869, 213, 16, 2331, 8, 36, 86, 158, 505, 10, 150, 649, 120, 111, 49, 2181], [3077, 16, 4, 1260, 16, 4, 673, 16, 4, 1763, 79, 95, 16, 4, 1058, 1374, 19870, 16, 4, 268, 2681, 7379, 16, 4, 19871, 11], [40, 79, 17, 953, 12, 7, 32, 40, 44, 18, 17, 205, 23, 2, 818, 3344, 1, 362, 13, 22, 138, 205, 282], [3, 90, 9, 30, 1225], [1409, 41, 48, 409, 188, 89, 1, 12, 4, 101, 184, 7, 3, 13], [3, 103, 1161, 376, 18, 2, 24], [39, 9, 46, 334, 19872], [3, 90, 94, 2, 417, 4334, 125, 2, 669, 25, 233, 14, 13, 77, 622, 144, 523, 2075, 19873, 62, 622, 6361, 44, 17], [3, 33, 131, 338, 22, 1, 21, 2, 696], [31, 5, 1500, 5, 33, 87, 60, 2741], [2071, 556, 44, 4, 1150, 1, 19874, 160, 8, 52, 29, 279, 128, 335, 48, 51, 32], [2684, 3472, 1623, 12, 59, 14, 2, 419, 9, 30, 25, 55], [53, 22, 1, 112, 530, 26, 53, 585, 87, 50], [23, 549, 16, 1, 1, 59, 166, 1], [1993, 81, 6, 20, 894], [4, 1016, 193, 54, 288, 5, 275, 79, 76, 9, 191, 31, 36, 67, 3079, 27, 36, 4746, 26], [4, 2099, 12, 248], [31, 2, 1, 29, 208, 284, 129, 5, 40, 29, 109, 67, 350], [3278, 87, 6, 139, 14, 2, 141, 1, 8, 253, 17, 18, 610], [91, 60, 564, 145, 38, 3, 258, 170, 23, 753, 364, 54, 84, 30], [55, 38, 1, 238, 497, 27, 17, 13, 58, 42, 636, 69, 3, 195, 23, 4, 639, 19875, 19876, 9, 3, 881, 4, 971], [23, 1553, 18, 8549, 4, 24, 8, 441, 12, 33, 2, 8557], [559, 15, 27, 7, 5, 41, 9, 45, 5, 46, 41, 2, 41, 148, 8319, 2866, 183, 30], [119, 10, 24], [160, 5, 46, 2, 89, 1, 31, 5, 41, 89, 6090, 26], [3, 636, 42, 131, 694, 545, 2, 1, 13, 17], [3, 105, 124, 2, 25, 1041, 82, 17, 26, 11, 748, 6, 114, 170, 82, 17, 52, 456, 48, 2753, 26, 176, 7, 11, 453, 1], [8780, 19877, 19878, 502, 268, 190, 1092, 26, 355, 1092, 288, 6091, 2, 4702, 1141, 11, 19879], [19880, 47, 2, 83, 149, 3, 121, 2028], [4638, 1, 41, 4, 237, 19881], [183, 1, 13, 6, 687, 2, 5781], [3, 64, 202, 845, 149, 3, 63, 1141, 76, 27, 393, 34, 3, 560, 87, 60, 207, 845], [5127, 518, 16, 263, 175, 220, 732, 788, 4, 95, 6, 1437, 2743, 48, 37, 1572], [186, 12, 3411, 4, 45, 54, 16, 12, 3312, 19882, 16, 154, 8134, 1024, 458, 225, 8, 3411, 5908, 236], [296, 64, 1224, 65, 51, 32, 39, 19, 1224, 19883, 23, 2, 111, 19884], [31, 5, 79, 2, 781, 2, 8552, 38, 52, 2089, 123, 19885, 8, 2, 19886, 8659, 38, 52, 56, 81, 5, 318, 14, 2, 1561], [6855, 19887, 19888, 2055, 5951, 27, 2697, 8781, 2494, 117, 211, 5544, 4630, 19889, 26], [470, 16, 15, 103, 14, 59, 71, 5, 3086, 179, 11, 19890], [5304, 57, 181], [19891, 157, 7, 6092, 7929, 18, 7, 1407, 1, 1624, 15, 53], [23, 298, 13, 2, 1, 1486, 19892, 2773, 1263, 8, 2660, 6, 239], [31, 5, 672, 10, 24, 29, 182, 122, 6, 974, 17, 26, 1481, 25, 3, 1599, 5], [3, 90, 77, 7, 14, 13, 53, 3, 75, 81, 6, 5, 5, 41, 99, 239, 19893, 1, 162, 97, 8351, 2802, 51], [25, 772, 5, 6, 349, 22, 54, 38, 36, 191, 3697, 4, 9, 4765], [4, 25, 27, 43, 1152, 156, 44, 4, 247, 1541], [58, 295, 73, 98, 19894, 8066, 7, 4, 384, 1332, 6, 168, 7, 641, 4, 4432], [4078, 262, 10, 310, 22, 1, 33, 1807, 10, 4074], [1350, 12, 1254, 405, 859, 18, 5, 1], [134, 17, 235, 26, 605, 80, 1, 5, 2, 151, 25], [4639, 505, 3, 29, 94, 71, 111, 156, 44, 76, 9, 26], [38, 5, 410, 2, 1, 36, 105, 81, 133, 5, 32, 16, 2, 2547], [20, 96, 2, 24], [1252, 77, 49, 156, 4, 247, 19895, 288, 39, 5208, 65, 1, 294, 224, 86, 126, 4, 45], [33, 297, 22, 141, 190, 25, 69, 259, 11, 2, 19896, 7, 60, 284, 385], [485, 32, 39, 365, 1, 103, 1463, 6, 14, 112, 21, 923], [261, 317, 110, 959, 20, 8782, 15, 959, 174, 19897, 19898, 959, 10, 3136, 6, 176, 1954, 8, 48, 491, 2, 1], [2770, 77, 227, 93, 189, 173, 4324, 8, 2770, 189, 227, 93, 287, 173, 283], [3, 90, 94, 111, 27, 169, 1049, 15, 18, 185, 45, 5, 29, 87, 1474, 886, 26, 2, 6036, 1686, 5, 816], [31, 66, 438, 28, 2256, 16, 97, 500, 151, 28, 2256, 16, 10, 9, 66, 29, 87, 43, 4732], [1008, 181, 49, 92, 19899, 140, 434, 770, 8, 1503, 11, 4, 731, 49, 398, 19900], [19901, 3, 301, 5, 118, 139, 14, 2, 282], [1809, 829, 198, 14, 19902, 21, 60, 16, 5, 9], [189, 51, 460, 14, 801, 2237, 9, 46, 2395, 34, 36, 551, 26, 359, 18, 36, 1661, 27, 2, 77, 69, 65, 13, 4450], [503, 292, 308, 77, 113, 18, 186, 1121, 10, 706, 29, 197, 1272, 85, 12, 10, 186, 753, 111, 1375, 23, 48, 2, 9], [1017, 6, 32, 212, 77, 69, 49, 2194, 35, 11, 2, 466, 11, 126, 618, 304, 21, 7, 1929, 7921, 61, 6, 376, 1, 52], [5, 1, 27, 2, 1833, 1473, 87, 6, 139, 936, 169, 18, 1865, 8, 33, 303, 60, 1686, 503, 13, 4, 763, 16, 4, 8252], [75, 33, 113, 17, 393, 1, 23, 68, 3076, 423, 82, 2898, 51, 32, 106], [3, 300, 3, 279, 133, 474, 34, 39, 1], [19, 76, 9, 3, 44, 1104, 437, 13, 58, 5, 867, 51, 20, 331, 55], [19, 76, 9, 3, 44, 1104, 437, 13, 58, 5, 182, 867, 51, 20, 331, 128], [55, 57, 2, 365, 1], [1822, 27, 10, 1, 18, 22, 150, 93], [26, 9, 18, 19903, 1540, 14, 541, 2922, 533, 133, 19904, 2969, 19905, 19906], [3, 67, 396, 8, 1110, 8, 6, 512, 102, 11, 32, 2634, 531, 13, 4, 207, 8783, 82, 2, 6093, 16, 5234], [159, 925, 2957, 6, 1202, 883, 435, 1011, 352, 2105, 4, 2008, 2105], [116, 101, 13, 68, 144, 19, 918, 7, 277, 8, 52, 2, 185, 30, 500], [19, 104], [4918, 12, 2, 711, 33, 3411, 170, 18, 212, 2306], [85, 12, 15, 156, 4, 1, 27, 43, 169, 43, 7400, 43, 5941, 6, 393, 5977, 7, 44, 4, 3644, 1911], [322, 1, 12, 156, 1506, 785], [1019, 9, 46, 334, 410, 19907, 321], [1344, 17, 21, 19908, 43, 19, 2096, 1344, 1], [32, 81, 19909, 680, 1], [182, 65, 51, 2, 1, 175, 8, 47, 13, 757, 4053], [356, 71, 825, 1215, 4637, 159, 824, 16, 396, 84, 1531, 18, 2049, 825, 1531, 49, 19910, 123, 19911], [744, 3, 227, 127, 173, 2, 587, 2536, 83], [3229, 714, 176, 10, 24, 631, 43, 267], [167, 7, 1, 27, 2, 1149], [19912, 85, 39, 1, 840, 37, 332, 129, 2, 25, 38, 103, 36, 623, 374, 152, 632, 35, 26, 3709, 4, 902], [140, 837, 13, 1201, 5072], [3156, 43, 293, 21, 39, 9], [181], [24], [23, 48, 72, 23, 21, 22, 34, 233, 2577, 103, 19, 718, 34, 266, 100, 36, 1, 1882, 76, 142, 5, 5053, 1133, 55], [5, 146, 14, 344, 3998, 27, 9, 188, 113, 76, 57, 5, 67, 82, 756, 188], [2712, 970, 2858, 26, 84, 436, 49, 11, 1382, 225, 6, 8784, 21, 1033, 159, 824, 11, 84, 3173, 21, 1837], [19913, 2524, 535, 1965, 1524, 11, 19914, 19915], [73, 1593, 6053, 191, 19916, 19917, 21, 246, 19918, 100, 5620, 725, 19919, 18, 4675, 26], [19920, 876, 38, 66, 592, 50, 40, 47, 37, 1339, 8, 3, 122, 6, 3009, 50, 6, 4, 1832, 40, 47, 290, 108, 8, 4, 1, 47, 5550], [19921, 339, 5, 75, 14, 3907, 8, 14, 2, 9, 51, 4, 199, 817], [9, 103, 14, 9, 26], [514, 10, 19922, 8, 592, 15, 11, 20, 504, 24], [378, 115, 142, 8592, 127, 115, 27, 54, 1616, 2, 104], [148, 15, 1319], [20, 175, 1093, 17, 16, 4, 106, 38, 66, 200, 4, 354, 5695, 298, 410, 5143, 11, 4, 561], [571, 28, 10, 1790, 18, 325, 172, 181, 112, 81, 25, 35], [19923, 8785, 2, 981, 1], [112, 607, 184, 1128, 130, 1453, 2, 1514, 27, 2, 171, 1], [8786, 427, 2, 234, 9, 426, 1302, 40, 4923, 23, 328, 27, 1068, 32, 39, 707, 90, 50, 21, 43, 2437], [20, 144, 602, 6, 14, 6094, 34, 1996, 3, 44, 2, 438, 6, 316, 5, 18, 21, 20, 457], [359, 46, 43, 2465, 9, 3888, 102, 2, 2295, 12, 2, 2465, 3, 46, 105, 297, 2, 1, 840, 26, 1351, 18, 43, 138], [78, 9, 28, 520, 33, 6, 175, 59, 980, 88, 421, 35, 6, 797, 170, 18, 135, 55], [19924, 46, 43, 9], [49, 5, 265, 33, 514, 10, 3428, 8436, 114, 2, 2758, 6, 7, 83], [23, 37, 669, 272, 61, 1509, 170, 92, 425, 42, 811, 1], [189, 27, 207, 387], [33, 486, 3077, 16, 4, 1260, 16, 4, 3875, 68, 16, 4, 165, 420, 289, 297, 22, 1608, 3, 210, 62, 31, 3, 67, 4, 673, 74], [3, 47, 59, 6, 14, 13, 19925, 42, 3480, 34, 3718, 2790, 58, 42, 110, 87, 6, 191], [3, 150, 2, 320, 16, 574, 56, 81, 4761, 21, 32, 372, 4, 199, 34, 3, 86, 245, 19926, 20, 48, 2545, 173, 2464, 6, 372, 2812], [19927, 3297, 2, 7108, 8, 66, 19928, 5, 2100, 19929, 26], [1656, 354, 57, 22, 3, 465, 59, 2, 2829, 2304, 176, 20, 365, 2463, 2304, 54, 16, 10, 8305, 1799, 64], [1083, 22, 175, 27, 4, 2123, 327, 11, 97, 1651, 694, 22, 1, 192, 15, 32, 26], [1], [48, 155, 275, 12, 2, 3340, 60, 16, 78, 9, 49, 33, 8787, 16, 983], [53, 8, 19930, 10, 45, 1001, 19931, 102, 19932, 19933, 61, 249, 2, 19934], [53, 403, 19935, 15, 72, 23, 5715, 2285, 48, 1150, 7719, 23, 48, 626, 16, 19936, 90, 240, 4758], [3, 29, 67, 4, 24, 31, 15, 70, 17, 67, 6, 389, 20, 1005, 8, 48, 376, 10, 1461, 561, 423, 29, 1606, 10, 1068], [277, 621, 62, 16, 2, 93, 1245, 19937, 11, 19938, 19939, 3889, 534, 26, 942, 267], [221, 3, 29, 86, 7, 19940, 405, 254, 5, 982, 110, 675, 1261], [221, 19941, 952, 49, 2, 184, 34, 71, 239, 344, 120, 435, 58, 5, 62, 69, 49, 32, 4, 199, 8, 37, 723], [1357, 1663, 49, 614, 6, 14, 2, 77, 395, 19942, 34, 78, 9, 28, 76, 33, 6, 114, 2, 1142], [38, 5, 136, 2, 19943, 119, 2, 348], [4501, 23, 48, 1491, 6, 935, 20, 977, 740, 410], [355, 745, 514, 2, 1957, 51, 232, 1330, 371, 19944, 360, 1957], [29, 100, 2, 5184, 61, 6, 19945, 19946, 1206, 6, 56, 19947, 3172, 6, 642, 2154, 21, 19948, 8788, 26], [3080, 12, 270, 2, 187], [23, 105, 194, 4227, 548, 361, 5, 187, 29, 67, 2964], [38, 111, 1053, 2, 2202, 16, 10, 3687, 7, 192, 27, 584, 48, 2004, 1001, 34, 22, 47, 33, 48, 6179, 7, 187], [3, 293, 4, 232, 178, 317, 28, 1234, 54, 1146, 15, 61, 6, 14, 2, 1101, 19949, 8, 1537, 891, 19950], [263, 4785, 123, 3047, 19951, 123, 19952, 123, 6095, 2882, 4708, 8789, 26], [263, 4785, 123, 1132, 6088, 8790, 123, 4136, 26, 8791, 123, 6095, 384, 4708, 8789, 26], [263, 4785, 123, 1132, 6088, 8790, 123, 4136, 26, 8791, 123, 6095, 384, 4708, 6, 4426, 26], [219, 3, 137, 567, 95, 92, 8, 3, 29, 62, 85], [1656, 416, 168, 19953, 19954, 15, 48, 197, 5, 4627, 83], [26, 3637, 1163, 879, 368], [3, 62, 69, 6616, 533, 133, 128, 857, 48, 10, 9], [10, 455, 1, 8, 10, 234, 1, 214, 51, 17, 34, 3, 222, 134, 268, 19], [37, 3, 94, 43, 68, 4719, 11, 4, 186, 2669], [20, 96, 18, 4, 234, 9, 411], [19955, 12, 127, 179, 88, 4, 19956], [148, 77, 42, 12, 2, 344, 9], [19957, 19958, 19959, 26, 19960, 19961, 14, 19962, 19963, 19964, 19965], [219, 3, 1559, 370, 21, 50, 230, 34, 7, 47, 3176, 96, 464, 12, 2, 1, 69, 266, 122, 7, 125, 188], [923, 8234, 2, 19966, 9, 8, 50, 1078, 803], [1, 4208, 960, 132, 588, 5, 651], [1, 43, 23, 81, 6, 50], [3, 394, 40, 2, 154, 1648, 232, 6850], [19967, 1693, 69, 259, 11, 4, 620, 8, 303, 1734, 793, 2633, 382, 77, 69, 168, 743, 8, 61, 19968, 69, 12, 127, 3976], [19969, 12, 21, 1, 1669, 3, 19970, 19971], [701, 19972, 8792, 124, 4, 237, 24, 11, 4, 3434, 578, 93, 2117], [71, 209, 277, 20, 436, 631, 24, 67, 246, 1270, 235], [203, 1, 7, 86, 36, 342], [4958, 1170, 14, 10, 306], [38, 8105, 1076, 52, 81, 13, 2, 179, 202, 91, 8, 3, 109, 29, 110, 86, 52, 1649, 19973, 23, 528, 410], [3, 467, 8673, 19974, 8, 36, 72, 1958, 29, 1247, 219, 513, 5, 65, 13, 20, 787, 513, 236], [31, 2, 414, 279, 59, 5, 1358, 28, 214, 129, 141, 2823, 31, 5, 75, 806, 7, 5, 655, 2, 282], [295, 3, 90, 127, 130, 2, 3308, 1], [482, 103, 156, 14, 482, 26, 110, 38, 482, 12, 48, 482, 7, 96, 482, 26, 3962, 5, 9, 63, 420, 224, 333], [38, 5, 400, 244, 97, 77, 8, 97, 234, 1, 262, 5, 2398, 1059, 53], [814, 132, 58, 99, 209, 1436, 2569, 9], [984, 2548, 21, 39, 9], [39, 9, 49, 334, 2491, 1717], [23, 2788, 32, 20, 1, 51, 10, 19975], [31, 5, 19976, 111, 37, 8451, 88, 61, 5165, 173, 2, 8793, 371, 5, 67, 6, 14, 2, 141, 1779, 1, 37, 19977], [53, 37, 3, 339, 671, 2, 19978, 1, 38, 23, 7634], [2958, 2184, 205, 19979, 19980, 19981, 19982, 236, 19983, 5, 44, 671, 154, 19984, 19985, 37, 122, 21, 775], [19986, 2231, 7, 1, 907, 11, 20, 844, 68, 127, 106, 19987], [3, 301, 3, 47, 68, 16, 212, 77, 69, 189, 13, 43, 690, 19988, 3, 222, 255, 1513, 8, 10, 343, 35, 8, 36, 118, 8794], [31, 3, 47, 2, 95, 5, 118, 14, 4, 841, 395, 278, 45, 962], [773, 280, 5, 636, 71, 22, 45, 61, 66, 11, 22, 1, 2531, 483, 298, 351, 4, 841], [351, 4, 19989, 66, 11, 22, 1, 2531, 250, 572, 19990, 263], [134, 17, 235, 26, 605, 80, 25, 5, 2, 151, 1], [223, 204, 17, 1, 25, 29, 14, 2, 77, 59], [3, 636, 22, 1, 2, 593, 40, 131, 563, 10, 734, 92], [66, 600, 74, 600, 48, 14, 56, 51, 114, 406, 612], [5960, 1319, 53, 31, 40, 157, 35, 27, 5, 15, 140, 40, 64, 5, 92, 70, 15, 783, 50, 3871, 64, 50, 108], [3, 195, 37, 417, 34, 23, 270, 2, 1, 233, 332, 201, 1365], [71, 5, 112, 29, 157, 43, 169, 18, 5, 25, 1177, 34, 4516, 303, 2, 1, 4725, 33, 6, 167, 4, 4316], [39, 1, 131, 19, 17, 218, 147, 1361, 41, 384, 314], [97, 1, 41, 19991, 34, 208, 13, 36, 29, 914, 149, 97, 19992, 922, 166, 695], [194, 4, 2901, 16, 6727, 7, 252, 69, 137, 7269, 456, 14, 28, 2, 3435, 16, 24, 615], [53, 93, 24, 396, 97, 164, 53], [189, 72, 29, 255, 645, 31, 5, 29, 41, 43, 30, 19993, 94, 5, 24, 294, 224, 11, 4020, 758, 461, 245, 19994], [394, 5, 266, 410, 240, 277, 3153, 276, 14, 894, 242, 562, 5, 2, 9], [20, 2, 181, 21, 168, 7, 19995, 769, 5, 49, 68, 16, 10, 237, 228, 26, 116, 12, 105, 2, 7575, 1029], [4285, 19996, 1996, 151, 14, 309, 27, 5, 189, 8, 22, 236], [3, 29, 67, 43, 593, 2, 593, 12, 2, 77, 7, 75, 28, 19997, 17, 662, 27, 4, 166, 141, 9, 255, 50, 14], [5, 1, 30, 25], [23, 322, 362, 33, 79, 7, 252, 2, 104], [9, 705, 6, 72, 36, 63, 19, 495, 499, 1214, 34, 57, 277, 7, 58, 21, 5, 34, 70, 5, 65, 89, 67, 2, 851], [31, 19998, 8795, 3837, 18, 1103, 11, 2, 232, 2486, 8, 88, 1120, 123, 4844, 11, 580, 16, 5407, 19999, 118, 2798, 20000, 188], [3, 118, 516, 19, 2, 203, 418, 130, 1166, 2, 158, 173, 10, 1728], [321, 5, 56, 114, 80, 30, 108, 6, 1197], [111, 14, 13, 82, 482, 6, 69, 49, 5, 112, 705, 3, 14, 13, 1, 29, 137, 27, 17, 151, 311, 5], [217, 103, 64, 20, 1, 30, 15, 266, 14, 17, 34, 217, 103, 64, 5], [32, 16, 2, 2547, 32, 39, 1, 13, 1520, 225, 55], [339, 1, 48, 67], [38, 174, 27, 174, 228, 8, 2, 1, 42, 398, 90, 294, 722, 53, 263, 73, 163], [4, 648, 16, 19, 129, 2, 93, 77, 12, 4, 1, 5, 450, 35, 27], [6131, 23, 8796, 8, 10, 848, 226, 20001, 20002], [78, 271, 1345, 24, 1634, 34, 1813, 6, 157, 245, 4438, 173, 829, 20, 373, 20003, 34, 20004, 3604, 766, 20005], [1, 57, 5, 299], [1, 5, 48, 342, 5, 33, 20006], [5, 44, 2, 154, 520, 155, 20007, 364, 5, 1042, 9], [4625, 2, 95, 21, 442, 22, 385], [3, 47, 255, 1857, 1100, 230, 5, 339, 1], [69, 8488, 39, 9, 20008], [38, 3, 94, 2, 322, 77, 3, 14, 13, 7174, 1300, 18, 39, 9], [7, 1, 41, 2, 355, 20009, 5609, 8, 45], [648, 12, 2, 1, 33, 70, 362, 7, 1, 12, 3877], [289, 560, 297, 2, 320, 16, 7, 4095, 1033, 8, 220, 21, 159, 8797, 1401, 678, 70, 17, 67, 6, 20010], [7, 65, 211, 5, 33, 157, 2, 1, 11, 126, 507], [4, 199, 111, 7, 14, 79, 111, 9, 14, 4, 455, 68, 249, 138, 21, 2, 20011, 475, 133, 350], [164, 6, 752, 6, 14, 20012, 28, 42, 60, 24, 14, 243], [23, 1933, 129, 44, 2, 1, 15, 46, 110, 356, 20013], [48, 101, 350, 8, 7, 2332, 1216, 966, 4701], [5, 124, 17, 51, 296, 90, 7, 1, 3182], [447, 384, 9, 284], [112, 1, 5138, 20014, 70, 362, 5, 28, 60, 110, 38, 36, 1591, 55], [34, 3, 29, 1481, 27, 291, 1], [155, 106, 3, 107, 54, 23, 105, 27, 20015, 1], [31, 5, 191, 17, 155, 1, 315, 48, 17, 23, 32, 1719], [267, 159], [5, 75, 258, 57, 5, 541, 21, 218, 5, 99, 624, 20016, 201, 74, 292, 1, 51, 2, 106, 8, 32, 4, 4787], [3, 90, 1208, 275, 7, 259, 21, 20017, 13, 61, 400, 142, 1504, 26, 61, 28, 1677, 9], [41, 6, 555, 2, 20018, 114, 1142, 27, 8102, 486, 2, 666, 16, 89, 30, 95, 16, 8798, 8, 1245, 2, 19, 20019, 20020, 369], [20021, 408, 81, 56, 59, 4, 620, 16, 8, 88, 1752, 21, 4, 13, 36, 20022], [357, 67, 43, 24, 1727, 166, 25, 328, 124, 230], [8799, 33, 121, 6, 17, 52, 299, 20023, 18, 4, 257, 2402, 47, 72, 20024, 18, 4, 20025, 22, 413, 106, 20026], [23, 113, 5, 1390, 24, 12, 2030], [43, 3995, 23, 48, 20027, 20028, 3, 33, 44, 19, 1288, 437, 8, 20, 2, 1, 8, 2, 838], [10, 386, 20029, 2835, 388, 44, 3757, 6, 176, 82, 28, 355, 20030], [31, 3, 63, 119, 60, 1107, 1, 30, 3, 63, 119, 2207, 8800], [3, 90, 5, 171, 1, 7, 300, 7, 6, 14, 243, 5, 87, 6, 14, 2, 11, 2, 3924, 78, 1061, 87, 6, 20031, 164], [23, 28, 56, 81, 123, 2, 885, 213, 206], [19, 329, 545, 39, 1, 713], [1360, 2, 675, 1, 1720, 97, 3620], [53, 15, 10, 24, 48, 20, 53, 3, 86, 22, 146, 14, 10, 443, 927, 406, 20032], [1, 21, 69, 3212, 53, 23, 2, 1263, 78, 1, 75, 113, 17, 4087, 26], [15, 20033, 34, 153, 13, 17, 72, 20034], [85, 58, 275, 86, 15, 342, 99, 14, 1395, 483, 32, 4, 106, 8, 196, 21, 43, 540, 7, 45, 46, 342, 1], [4013, 25, 14, 44, 32, 4, 9], [3, 301, 4, 1, 118, 26], [25, 103, 359, 18, 2, 77, 88, 1509, 50, 8, 79, 50, 2, 9, 21, 420, 962, 81, 133, 40, 502, 35, 99, 705], [275, 64, 719, 217, 520, 7, 48, 342, 78, 9, 87, 60, 2366, 26, 164, 1487], [26, 5, 652, 2, 83], [8172, 41, 6, 44, 7660, 2, 320, 16, 20035, 230, 5, 63, 751, 13, 2, 20036], [17, 38, 20, 1, 443, 10, 175], [38, 20, 51, 4, 20037, 8, 36, 113, 5, 20, 7722, 103, 14, 542, 11, 1313, 20038, 369, 1, 15, 132, 20039], [20, 270, 2, 494], [37, 69, 67, 6, 113, 4, 2421, 448, 7, 159, 824, 12, 2, 1033], [23, 270, 2, 1, 23, 332, 6, 806, 23, 5192, 8, 3, 44, 98, 2497, 370, 6, 4, 111, 69, 157, 35, 27, 15], [57, 3, 109, 67, 12, 60, 348, 82, 20040, 684, 20041, 10, 177, 8, 2, 2708, 545, 5843, 7, 372, 20042, 20043], [202, 77, 9, 149, 36, 19, 25, 21, 169, 2806, 8, 171, 45, 13, 7], [91, 39, 9, 37, 4716, 68, 691, 18, 4, 412, 244, 691, 36, 46, 27, 5307], [3, 64, 38, 1, 313, 20044, 33, 3033, 23, 58, 256, 117], [53, 23, 345, 53, 7, 1, 61, 332], [3391, 191, 1378, 6002, 136, 124, 6, 799, 27, 7, 698, 16, 20045, 113, 4, 1779, 141, 1, 6, 79, 20046, 20047, 98], [20048, 20049, 2813, 6915, 20050, 20051, 129, 8, 28, 19, 11, 4, 30, 5, 161, 703, 1, 3, 64, 509, 703], [53, 53, 53, 20052, 340, 20053, 11, 4, 1986, 7129, 757, 827, 42], [1, 25], [1, 14, 54, 135, 119, 24, 127, 130, 25], [1314, 26, 3, 346, 5, 1], [31, 5, 150, 146, 460, 155, 696, 21, 1182, 272, 33, 1233, 5, 4573, 5221, 11, 20054, 2271], [3, 75, 105, 176, 43, 1, 149, 3, 157, 76, 20055, 54], [23, 68, 16, 212, 104, 69, 90, 4, 324, 588], [1267, 44, 43, 9, 8, 10, 164, 12, 98, 1432], [3, 363, 6, 20056, 225, 8, 4, 5747, 124, 757, 66, 29, 506, 1018, 1054, 4098, 2290, 32, 129, 50, 231, 38, 40, 65], [3, 90, 2, 156, 131, 366, 34, 46, 41, 43, 169, 73, 3948, 13, 680, 20057], [289, 101, 194, 20058, 16, 22, 56, 8, 3, 150, 13, 3, 33, 936, 60, 4907, 691, 16, 10, 164, 7, 3, 63, 105, 28, 340], [38, 60, 1, 1657, 27, 482], [75, 227, 2, 9, 173, 2, 2401, 519], [2574, 1], [801, 13, 2, 141, 1, 805], [122, 37, 332, 6, 2344, 4, 3096, 6, 737, 2, 1], [64, 942], [3, 597, 35, 11, 4, 848, 16, 4, 264, 8, 901, 4, 1685, 1402, 344, 82, 4, 20059, 370, 3995], [1019, 9, 14, 183, 483, 81, 133, 1379, 3, 67, 80, 520, 3, 222, 44, 4100, 1, 5, 65, 13, 2, 520], [42, 29, 13, 17, 34, 97, 1, 58], [127, 494, 462, 20060, 7, 10, 3461], [79, 15, 20061, 31, 42, 67, 34, 19, 43, 10, 91, 317, 87, 6, 14, 1565, 74, 44, 1, 73, 6096, 39, 9, 2778], [162, 39, 1, 51], [22, 1454, 96, 356, 73, 45, 6, 17, 2228, 239, 158, 49, 11, 10, 20062], [8, 31, 5, 65, 21, 10, 151, 14, 18, 39, 1, 453], [15, 46, 295, 6, 311, 7, 1, 102], [495, 79, 98, 20063, 140, 39, 1, 309, 21, 701], [59, 6, 728, 22, 1, 27, 27, 305, 681, 1647, 768], [20064, 107, 194, 17, 298, 2120, 657, 4, 742, 178, 13, 10, 226, 47, 1499, 3885, 11, 22, 1, 1188], [1019, 9, 14, 896, 35], [82, 10, 1924, 39, 1, 46, 45, 10, 433, 32, 89, 18, 20065], [71, 5, 436, 147, 1, 8801, 25, 19, 82, 10, 4727, 8801, 25, 896, 37, 613, 32, 1019, 7966, 9, 18, 10, 138], [3, 29, 19, 27, 1, 25, 3, 101, 19, 25, 1], [3, 90, 2, 1, 7, 86, 36, 284], [3, 90, 1497, 9, 308, 8, 72, 3, 19, 240], [3, 87, 2, 334, 1, 48, 43, 2666, 1], [23, 556, 35, 10, 558, 37, 23, 311, 5, 669, 9, 102], [272, 349, 35, 119, 4, 24, 8, 1598], [105, 44, 265, 123, 2, 408, 1, 31, 37, 670, 55], [43, 106, 6, 137, 125, 1], [1017, 32, 10, 112, 408, 69, 63, 304, 8, 48, 67, 17, 6, 157, 54, 56, 13, 166, 992], [598, 13, 1019, 1, 46, 334], [39, 1, 46, 10, 1], [5206, 87, 6, 453, 36, 20066, 1, 22, 4, 7064, 139, 448, 45, 88], [2, 1, 28, 5720, 253, 40, 2, 900, 8, 192, 35, 2, 20067, 8, 255, 1691, 11, 775], [2, 93, 414, 107, 224, 155, 292, 283, 2, 93, 91, 107, 20068, 42, 28, 4, 446], [107, 22, 616, 23, 2209, 234, 283, 78, 124, 78, 106, 4, 413, 850], [15, 60, 93, 234, 1, 54, 135, 29, 100, 357, 113, 42, 511], [5713, 39, 9, 14, 3517, 148, 5, 614, 6, 14, 7, 916, 71, 5, 28, 2070], [247, 16, 475, 59, 65, 13, 2, 282, 276, 3709, 15, 38, 42, 28, 5837, 218, 42, 346, 54, 18, 2, 320, 16, 501], [68, 93, 414, 12, 783, 2, 1721, 89, 20069, 3, 96, 131, 19, 2, 1721, 1], [112, 1, 262, 42, 8432, 42, 6675, 230, 36, 79], [1321, 1, 14, 302, 638, 8, 100, 76, 8802, 39, 9, 62, 165], [139, 2357, 11, 39, 9], [22, 1, 12, 554, 856, 50, 548, 54, 21, 17, 8, 23, 18, 8803, 23, 98, 1034], [85, 202, 287, 72, 584, 276, 28, 17, 2, 120, 6196, 13, 120, 189, 48, 381, 1, 776, 78, 37, 171], [1, 5, 2884, 9, 2884, 9], [43, 9, 43, 482, 43, 20070, 43, 295], [20071, 3, 46, 41, 43, 952], [99, 89, 23, 2, 812], [53, 8, 23, 48, 861, 562, 5, 25, 33, 64, 1233, 1, 67, 78, 38, 66, 33, 14, 417, 53], [43, 660, 3314, 12, 48, 59, 3760, 15, 59, 212, 2185, 8, 212, 20072, 139, 194, 1940, 8052], [289, 156, 67, 6, 58, 2, 2088, 1112, 34, 23, 99, 24, 37, 4307, 550, 71, 59, 22, 20073, 2903, 725, 8, 3, 103, 448, 2, 1112], [20, 1176, 1], [236, 103, 599, 58, 393, 6, 72, 36, 41, 2, 25, 797], [32, 10, 1, 1104, 130, 17, 36, 162, 1366, 5285, 37, 3, 75, 1023, 36, 45, 278, 65, 171, 483], [10, 228, 49, 32, 171, 9, 69, 3, 29, 110, 13], [78, 275, 109, 14, 431, 27, 2209, 9, 30, 25, 3573, 487, 14, 307], [186, 198, 1476, 4, 141, 759, 95, 20074, 8, 33, 1239, 396, 15, 6, 2, 644, 16, 20075], [105, 61, 392, 144], [4, 3624, 5, 49, 4, 2245, 20, 3467, 37, 33, 14, 2, 1], [23, 48, 20076, 74, 20077, 23, 33, 497, 1], [1322, 270, 2, 368, 17], [23, 270, 2, 3227, 1, 15, 681], [469, 3, 114, 10, 1865, 102, 29, 191, 17, 6, 58, 45, 21, 42, 1, 426, 469, 7, 1865, 107, 102, 3, 195, 2670, 54, 16, 164, 3, 195, 58], [38, 166, 77, 255, 1493, 36, 65, 342, 26, 4264, 34, 38, 3, 255, 76, 3, 65, 13, 2, 2005, 16, 2, 692, 3880, 69, 8501], [261, 12, 37, 8804, 23, 33, 122, 6, 433, 4, 521, 8, 28, 54, 22, 1], [120, 186, 38, 36, 28, 11, 98, 2469, 26, 3, 1560, 1, 491, 50, 173], [19, 2, 637, 3974, 1, 157, 17, 27, 4, 1308, 100, 17, 4481, 313, 60, 3484, 591, 17, 8, 134, 17, 338], [366, 667, 1], [20078, 3, 67, 378, 3556, 20079, 445, 89, 9, 82, 143, 20080, 8, 2, 595, 30, 20081, 1, 34, 20082, 553, 16], [3, 195, 37, 333, 8, 818, 6, 44, 132, 2347, 4, 508, 20083, 16, 4, 5345, 21, 20084, 160, 5920, 378], [432, 110, 191, 1613, 1, 21, 677, 4197, 19, 78], [2152, 860, 8805, 4769, 3103, 26, 514, 2142, 1658, 668, 195, 8806, 4284, 1961, 2816], [11, 2152, 860, 8805, 4769, 3103, 8806, 4284, 1961, 1817], [15, 6, 4, 446, 7, 3, 29, 934, 194, 4303, 2027, 52, 1577, 277, 7, 8, 15, 633, 17, 1724, 139, 14, 2, 1], [1140, 120, 111, 695, 4362, 38, 40, 72, 3051, 28, 22, 887, 26], [2356, 1137, 1392, 7, 5, 63, 227, 2, 9, 173, 2, 20085], [5, 588, 196, 538, 4, 488, 7, 3, 29, 67, 5, 20086, 74, 393, 27, 2, 1, 7, 168, 6, 13, 5], [38, 2, 1, 122, 6, 1657, 27, 10, 4023, 2059, 3, 14, 13, 3884], [616, 11, 64, 12, 2495, 15, 616, 54, 16, 64, 7, 2, 83], [23, 494, 73, 2, 1058, 831, 1005, 8, 10, 250, 1680, 6, 50, 107, 54, 47, 3227, 583, 109, 105], [57, 20087, 471, 17, 7, 148, 1280, 2, 1567], [29, 137, 178, 27, 2, 77, 69, 63, 137, 165, 83], [3, 29, 62, 2, 1, 11, 4, 360, 7, 708, 36, 99, 624, 21, 2, 25, 36, 109, 19, 2047], [1183, 978, 215, 331, 18, 4, 440, 123, 4, 2720, 8, 40, 41, 207, 20088, 198, 44, 8511, 55], [3, 90, 38, 3, 468, 256, 8, 10, 306, 72, 219, 3, 380, 15, 407, 7, 1768, 13, 1, 5, 514, 17, 11, 2, 7915, 1961], [116, 47, 2, 635, 7, 47, 1467, 173, 32, 4, 1371, 8, 3, 79, 15, 144, 34, 88, 3, 299, 6, 531, 20089, 23, 20090], [434, 24, 103, 44, 5, 58, 45, 5, 118, 86, 5, 118, 105, 58], [78, 182, 47, 11, 4, 347, 27, 97, 3804, 230, 8, 5, 751, 155, 323, 107, 11, 8, 40, 14, 13, 1, 5, 62, 7, 8807], [573, 164, 23, 98, 1393, 4193, 1], [3, 44, 1527, 9], [2033, 1, 23, 152, 719, 20, 548], [3098, 8512, 390, 1, 3453], [23, 270, 2, 1, 128, 3, 109, 33, 72, 57, 18, 10, 453, 464, 75, 547, 15], [5299, 21, 10, 228, 23, 2, 190, 2758, 11, 4021, 678, 12, 3213, 21, 4, 20091, 252], [55, 85, 36, 238, 70, 1963, 54, 201, 340, 22, 89, 1, 40, 12, 2668, 669, 15, 70, 17, 214, 8, 40, 19, 13, 2, 2248, 20092], [3500, 804, 233, 13, 1, 662, 27, 574, 97, 1247], [5, 63, 498, 21, 2, 25, 97, 413, 164, 154, 24, 19, 15, 35, 11, 68, 264], [1, 333, 3, 29, 110, 70, 10, 373, 522], [9, 14, 79, 9, 9, 38, 36, 62, 36, 33, 73, 209, 16, 2, 9, 73, 4, 166, 9, 36, 79, 2, 282], [5952, 309, 2, 535, 16, 213, 1712, 1126, 11, 4, 20093, 186, 51, 4, 1692, 489, 313, 68, 51, 4, 180, 517, 9], [590, 1, 14, 13, 1163, 226, 12, 20094, 20095, 524, 28, 8808, 15, 8808, 117, 20096], [1322, 671, 2, 112, 1, 18, 22, 347, 20097, 160, 1050, 18, 17, 48, 279, 4006, 74, 48, 6392, 16, 1441, 70, 169, 18, 2160], [5887, 3, 122, 18, 1374, 1927, 21, 4, 1554, 1112, 51, 7, 512, 314, 73, 19, 102, 441, 348, 26], [53, 32, 10, 9, 271, 214, 51, 17, 3, 176, 240, 341, 380, 36, 41, 2, 4421, 53], [3, 150, 89, 21, 32, 4, 774, 7, 3701, 82, 20098, 3293, 18, 4, 5478, 212, 1, 20099, 4, 2802], [20100, 9, 1083], [296, 87, 2, 189, 7, 63, 157, 17, 11, 10, 8272, 1, 7, 86, 374, 4015, 978], [155, 77, 568, 785, 50, 9, 3011, 50, 1554, 213, 11, 1197], [25, 41, 2, 77, 85, 4, 19, 5, 191, 77, 6, 262, 20101, 91, 9], [5, 9, 28, 459, 402], [5, 287, 49, 48, 1060, 20102, 20103, 5, 63, 829, 20, 373, 764, 8, 157, 630, 11, 507, 42, 171, 1], [15, 3533, 83], [38, 5, 65, 13, 56, 8, 217, 2558, 5], [1, 5, 380, 15], [20104, 46, 2357, 2177, 19, 7, 1, 797], [410, 20105], [6072, 6072, 141, 883, 3, 19, 20, 1, 8, 1796, 20, 347], [1, 25, 2561, 12, 32, 5, 63, 20106], [80, 1, 57, 4540, 226, 1, 3, 131, 19, 97, 83, 20107, 20108, 184, 40, 72, 6, 17, 20109, 1517], [354, 20110], [289, 81, 99, 209, 56, 21, 8809, 6, 468, 3195], [20, 2, 838, 1464, 565, 7], [367, 367, 3, 62, 32, 59, 4, 1793, 20111, 15, 47, 10, 1179, 20, 7854], [5, 41, 25, 26, 3, 41, 1], [215, 106, 8810, 510, 6, 20112, 3, 8810, 8, 26, 8, 2, 91, 11, 2, 759, 269, 725], [32, 39, 9, 1428, 1696, 16, 1134], [485, 78, 9, 30, 25, 198, 192, 1557, 77, 150, 20113, 86, 59, 31, 2, 25, 12, 58, 57, 20, 58], [4, 2234, 1844, 16, 4519, 20114], [7, 4, 409, 16, 1, 7, 3, 90], [5, 141, 185, 30, 1, 3, 46, 19, 27, 5], [53, 367, 40, 12, 179, 368], [53, 40, 68, 16, 4, 2272, 287, 289, 182, 5593, 1501, 808, 2, 8448, 8, 2, 20115], [1387, 377, 1938, 1177, 1683, 18, 2795, 4358, 6, 2810, 8, 20116], [19, 40, 2, 339, 1], [10, 500, 273, 17, 469, 40, 67, 17, 6, 28, 50, 2, 2006, 7, 118, 114, 50, 1238, 423, 37, 3, 41, 7, 1, 2, 7373], [1573, 19, 1, 28, 169], [3588, 174, 2, 89, 1], [3, 109, 58, 28, 1110, 6, 94, 10, 89, 1, 2556, 11, 1255, 744, 36, 156, 70, 17, 528], [20117, 180, 312, 312], [97, 123, 14, 20, 20118], [3, 64, 17, 60, 142, 30, 283], [3, 301, 3, 124, 322, 207, 387, 26], [523, 42, 1644, 140, 174, 2, 20119, 1], [31, 20, 2, 1554, 8, 814, 19, 20120, 16, 4, 177, 11, 4, 1526, 20121, 20, 2, 282], [53, 322, 1, 2999, 2528, 20122, 1558], [13, 83, 5, 330, 62, 4, 8054, 15, 32, 21, 5039], [8811, 8811, 97, 1], [53, 12, 5, 2, 77, 74, 2, 189, 12, 5, 10, 306, 74, 12, 5, 10, 586, 53, 23, 2, 4647, 391], [3, 442, 4, 106, 21, 20123, 111, 6, 14, 1355, 6, 989, 21, 3382, 20124, 641, 6097, 20125], [101, 98, 2420, 4536, 1, 2353, 50, 4660, 11, 775, 233, 20126, 6001, 84, 183, 2220, 11, 2060, 951], [1193, 57, 42, 2197, 34, 4530, 20127, 12, 20128, 20129, 11, 1548, 16, 20130], [20131, 9, 29, 20132, 20133, 9, 11, 50, 8381], [78, 65, 19, 144, 27, 78, 1286, 142, 6, 20, 20134], [38, 5, 62, 5, 799, 27, 9], [3208, 67, 3610, 6, 1367, 876, 22, 252, 273, 80, 30, 18, 3312, 6039, 6, 100, 22, 1, 2305], [29, 182, 14, 1491, 6, 957, 1, 2014, 574, 156, 772, 5, 6, 14, 13, 584, 370, 31, 3, 41, 20135, 74, 584, 370, 6, 725], [3, 267, 155, 1383, 11, 4, 1814, 69, 114, 7, 795, 3998, 20136, 207, 1372, 11, 50, 8687, 7, 68, 882, 395], [28, 2083, 123, 1176, 283], [107, 18, 232, 100, 176, 22, 178, 61, 66, 456, 404], [98, 20137, 667, 35, 57, 2753, 196, 21], [286, 221, 8460, 35, 11, 22, 1], [5, 79, 17, 2, 24, 1715, 189, 100, 94, 71, 20138, 8812, 117, 8813, 8, 20139, 8812, 440, 8813, 150, 59, 7], [1920, 752, 18, 160, 5641, 160, 6705, 292, 862, 7818, 20, 190, 682, 8, 355, 343, 5, 65, 13, 2, 20140, 26], [18, 4, 247, 6350, 8341, 182, 11, 4, 3375, 26, 2139, 5237, 12, 84, 83, 26], [78, 44, 2604, 511, 395, 8, 292, 511, 1, 5, 1218, 178, 6, 8, 308, 1978, 34, 66, 87, 6, 632, 35, 8526], [93, 561, 6, 5, 99, 4696, 537, 1], [11, 678, 3, 20141, 8685, 3788, 8814, 4198, 8735, 950, 2530, 16, 620, 358, 2142, 73, 2, 377, 1871, 20142, 1188], [6295, 1755, 20143, 159, 1186, 43, 2153, 4508, 21, 1775, 2525, 20144], [32, 39, 2300, 8, 1, 5, 96, 29, 28, 57, 23, 3774], [218, 1, 64, 1421], [38, 161, 1441, 121, 85, 134, 2, 1, 97, 548, 38, 40, 516, 44, 2, 4735], [1, 510, 129, 221, 66, 1014, 2, 460], [34, 88, 361, 3, 46, 105, 475, 133, 43, 1, 2174, 25], [20145, 1997, 49, 152, 61, 2360], [15, 1135, 21, 101, 20146, 1634, 8, 4, 1, 156, 44, 10, 1946], [22, 1, 12, 472, 21, 1860, 4, 489, 4, 1198, 8, 6, 1300, 3288, 26], [2166, 175, 3, 297, 225, 26, 391, 1, 49, 8084, 21, 8724, 469, 23, 20147, 6, 4, 138, 3, 61], [39, 1, 410, 595, 20148, 20149], [31, 5, 79, 10, 306, 2, 1, 20, 28, 762, 20150, 779], [8771, 105, 4786, 20151, 8772, 69, 56, 155, 166, 3159, 105, 4786, 8773, 8774], [3, 86, 23, 1812, 6, 927, 406, 8, 400, 114, 133, 1, 7, 66, 603, 124], [3, 65, 51, 155, 1, 30, 7, 294, 722, 17], [9, 156, 72, 36, 2, 20152, 1, 411, 8, 498, 22, 138, 20153], [53, 71, 58, 5, 359, 18, 22, 53, 40, 33, 13, 245, 166, 275, 27, 2, 24, 37, 69], [31, 20, 24, 47, 2, 1177, 278, 509, 35, 18, 15], [3, 94, 78, 678, 68, 16, 78, 234, 1, 216, 22], [159, 255, 287, 754], [25, 32, 59, 352, 92, 2124, 2186, 5, 1, 3, 383, 67, 495, 69, 223, 165, 17, 73, 2, 379, 287], [5, 63, 58, 393, 5, 67, 11, 164, 33, 29, 14, 2, 19, 1], [3823, 62, 133, 2478, 11, 4, 179, 119, 7577, 873, 292, 106, 2, 921, 161, 3451, 161, 20154, 161, 3160, 161, 20155], [57, 344, 189, 114, 2, 406, 16, 943, 927, 11, 2, 341, 20156, 181], [8297, 5660, 98, 4640, 494, 1693, 12, 137, 4, 2370, 70, 170, 4, 250, 4640, 494, 1693, 6, 137, 2, 1337, 20157], [51, 22, 446, 155, 8681, 11, 1382, 136, 946, 398, 21, 8, 641, 159, 8815], [2382, 518, 292, 21, 5004, 2890, 172, 7, 1, 35], [17, 26, 66, 11, 22, 1, 544], [826, 122, 6, 5515, 179, 226, 18, 4, 841, 115, 16, 20158], [8572, 5445, 154, 20159], [19, 20, 6019, 1, 23, 2, 320, 3785, 130, 5], [13, 39, 1, 7, 44, 875, 387, 4414, 343, 265, 18, 126, 798, 81, 59, 1163, 1152, 7533], [38, 36, 121, 164, 2, 812, 36, 109, 1456, 254], [53, 960, 156, 14, 3365, 24, 807, 1, 65, 51, 17, 105, 807, 26], [6486, 24, 20160, 1, 238, 735, 10, 20161, 21, 20162, 20163], [31, 5, 13, 211, 20164, 1180, 49, 3, 86, 20, 2, 711], [274, 12, 2, 232, 5709], [73, 994, 168, 6, 72, 2406, 14, 2, 1779, 141, 1, 8, 119, 4, 19, 20165], [351, 95], [3, 19, 20, 1, 71, 5, 150], [22, 3378, 16, 20166, 134, 4, 20167, 6, 98, 1331, 1736, 109, 20168, 10, 3491, 543, 126, 370, 971, 951], [3, 20169, 61, 6, 137, 567, 95, 8, 88, 3, 309, 230, 28, 68, 8, 375, 71, 209, 3, 90, 254], [583, 8303, 20170, 28, 906, 11, 2, 1621, 159, 20171, 6098, 211, 159, 107, 6, 2152, 21, 225, 2982, 465, 26], [32, 23, 854, 12, 42, 1, 118, 20172, 125, 794, 7625, 20173, 218, 42, 86, 52, 32, 2188, 163, 45, 34, 88, 42, 733], [728, 54, 27, 20, 968, 54, 1873, 54, 27, 20, 949, 54], [2961, 1382, 1837, 825, 1215, 12, 1337, 159, 824, 123, 2043, 7166], [303, 4, 77, 1216, 5, 20174, 30, 1], [20175, 23, 559, 10, 401, 8, 61, 6, 683, 6, 671, 2, 20176, 92, 3, 62, 57, 20, 86, 219, 48, 4282, 23, 61, 6], [5, 35, 159, 524], [267, 6, 3, 44, 683, 193, 127, 130, 3, 182, 67, 6, 62, 59, 4425], [20177, 1145, 20178, 1400, 18, 126, 3817, 8, 45], [1, 14, 13, 1379, 5, 107, 129, 220, 48, 20179, 34, 15, 582, 26, 40, 1390, 1, 724, 1287], [3, 29, 113, 1, 3, 229, 1], [22, 427, 1289, 1046, 53, 71, 58, 1, 20180, 8768, 34, 96, 28, 359, 18, 256, 48, 20181], [113, 2, 77, 6, 20182, 3945, 1358, 208, 13, 5, 33, 543, 50, 11, 4, 24], [835, 659, 187, 1, 25], [19, 90, 609, 30, 1], [85, 134, 2, 1, 98, 1435, 38, 40, 516, 44, 4124], [1071, 50, 517, 11, 580, 16, 25, 7, 67, 50, 1071, 50, 517, 11, 580, 16, 1, 7, 67, 5], [5, 440, 2358, 2521, 250, 115, 149, 20, 2, 1, 2756], [53, 403, 4, 1280, 12, 562, 110, 1033, 49, 539, 27, 350, 53, 384, 49, 20183], [3, 96, 259, 27, 293, 7, 68, 115, 2, 341, 613, 177, 103, 616, 11, 64, 27, 17, 110, 464, 23, 56], [15, 8816, 1], [33, 6, 1385, 15, 469, 8, 21, 32, 678, 510, 250, 4, 813, 74, 4, 1711, 4, 1711, 1546, 2434, 123, 2, 95, 7, 47, 48, 2, 813], [1325, 23, 2037, 4, 3028, 189, 23, 2, 1851, 20184, 30, 1], [200, 42, 719, 212, 1178, 281, 185, 158], [22, 427, 60, 2930, 6, 14, 3433, 224, 32, 20185, 814, 146, 1845, 4, 117, 6, 79, 17, 2, 83], [2748, 215, 264, 22, 20186, 47, 3858, 173, 4, 1012, 16, 2, 1544, 2742, 20187, 730, 6, 1120, 4, 250, 312], [135, 20, 250, 65, 51, 159, 20188, 73, 3335, 20189, 11, 18], [2, 395, 87, 33, 1058, 184, 6, 14, 1786, 243, 11, 4, 360, 217, 6, 64, 256, 6, 58, 8, 256, 6, 236], [65, 51, 78, 1, 21, 4, 1388, 608, 176, 28, 554, 30, 1], [38, 9, 150, 13, 126, 846, 210, 28, 602, 443], [241, 10, 93, 58, 3, 90, 1745, 1225, 19, 20190], [325, 1, 383, 1807, 10, 314], [1428, 239, 20191, 20192, 602, 462], [5, 62, 2, 77, 12, 2, 9, 31, 50, 610, 427, 2440], [69, 165, 201, 340, 4, 20193, 20194, 86, 2353, 15, 66, 1, 2353, 84, 3547, 8, 52, 801, 20195], [12, 2, 24], [375, 11, 7724, 38, 4, 232, 220, 11, 3814, 8, 4, 1816, 47, 1801, 3561, 661, 16, 8361, 20196, 3, 64, 20197], [20, 7384, 2, 232, 408, 604, 1124, 15, 60, 115], [232, 20198], [482, 61, 81, 6, 20, 166, 9, 17], [8817, 27, 10, 1529, 1], [180, 651, 149, 7, 969, 1487, 45, 12, 21, 4, 942], [3, 1373, 4, 215, 184, 5, 131, 58, 12, 14, 2, 1, 6, 10, 746, 11, 580, 16, 307, 29, 3873, 4, 4600, 233], [2287, 20, 2522, 31, 5, 258, 54, 4, 64, 16, 20, 164, 506, 8563, 24, 18, 2789, 26], [53, 53, 56], [8744, 113, 1697, 229, 1288, 144, 222, 197, 21, 8143, 20, 783, 57, 20, 783], [1123, 54, 6, 32, 4, 1, 69, 29, 44, 6, 472, 470, 927, 6, 28, 2, 91, 4018, 271, 1677], [31, 174, 588, 15, 3990, 111, 49, 8767, 167, 18, 42, 149, 174, 2441, 3666, 34, 31, 42, 1657, 108, 15, 2, 437, 1], [23, 613, 83], [20199, 41, 1, 51, 337, 3861, 798, 13, 188], [10, 443, 493, 37, 750, 136, 6, 14, 3744, 1380, 456, 249, 140, 5, 75, 182, 14, 98, 20200, 216, 17, 5312], [1210, 78, 60, 9, 90, 18, 7, 77, 7, 65, 13, 2, 252], [38, 5, 94, 482, 800, 74, 844, 60, 9], [77, 2326, 1379, 3, 72, 680, 3, 29, 428, 196, 1732, 88, 29, 2143, 72, 680, 5, 171, 83], [366, 93, 441, 27, 2, 89, 1], [5300, 2100, 2100, 200, 5, 51, 577, 8626, 4, 8627, 38, 5, 1014, 7, 30, 11, 2, 5157], [66, 1273, 4, 82, 4, 26, 66, 1611, 4, 26], [5, 2, 9, 3, 33, 299, 5, 220, 342, 7, 85, 3, 605, 5], [20201, 582, 305, 261, 103, 33, 14, 5596, 13, 24], [37, 48, 542, 21, 4, 3145, 213, 154, 986, 175, 908, 6, 107, 5, 4, 199, 9, 5, 47, 215, 213, 497, 4, 19, 54], [22, 12, 2, 573, 498, 74, 309, 1], [411, 9, 584, 818, 6, 14, 1644, 20202, 160, 818, 1644, 732, 584, 818, 6, 14, 5925, 160, 529], [3, 94, 111, 175, 1378, 31, 4, 2669, 107, 6, 10, 20203, 1, 4, 2669, 46, 43, 2160], [3377, 20204, 1124, 18, 1940, 1199, 7, 770, 136, 2, 664, 2029], [31, 20, 77, 210, 2521, 54, 7300, 6, 303, 5, 4, 1074, 688, 20, 2168, 2168, 12, 2455], [278, 61, 284, 31, 39, 978, 13, 76, 1071, 10, 779, 13, 760, 3, 46, 61, 54, 13, 43, 1, 26], [1379, 3, 47, 2, 77, 13, 7, 42, 118, 415, 119, 10, 887, 160, 20205], [148, 3, 90, 2, 1, 7, 13, 6, 687, 8, 45], [10, 25, 109, 122, 6, 492, 84, 1, 55], [639, 115, 12, 163, 1913, 4273, 78, 1, 479, 78, 265, 35, 82, 80, 779, 331, 37, 42, 63, 44, 20206, 16, 4529, 163, 610, 1145], [3, 67, 2, 284, 1, 36, 14, 334, 483], [26, 272, 119, 7, 24, 32, 2009], [78, 9, 37, 589], [1051, 6, 5, 123, 89, 1, 8, 93, 441], [148, 3, 41, 1, 8818, 2114], [3, 75, 14, 475, 133, 43, 1, 149, 7, 1, 222, 14, 1504, 249, 138], [3, 266, 64, 5, 3, 75, 64, 5, 650, 7, 24, 41, 60, 889, 863], [15, 2349, 31, 2, 275, 359, 15, 37, 2625, 40, 155, 409, 16, 9, 116, 12, 34, 31, 2, 189, 359, 116, 32, 39, 8377], [20, 4, 796, 187, 3, 62], [7871, 306, 317, 44, 45, 61, 962, 186, 1, 44, 15, 1284], [22, 12, 727, 589, 6, 17, 23, 152, 4482, 54, 16, 589, 426, 3, 195, 2, 141, 1], [1, 14, 208, 511, 20207, 15, 431], [38, 1, 1624, 3912, 59, 5, 26], [9, 14, 13, 584, 2, 20208], [960, 1754, 12, 70, 4014, 937, 82, 11, 2565, 5732, 82, 50, 1537, 8, 5, 32, 79, 50, 171, 1, 40, 2, 148, 8788], [485, 357, 13, 5, 140, 20, 2, 1], [40, 1796, 10, 45, 57, 2, 141, 20209], [3, 300, 2, 1290, 25, 168, 6, 131, 14, 2, 20210, 265, 4225, 8358, 26, 4740, 8359, 398, 124, 1], [3, 75, 397, 6, 14, 224, 179, 3403], [60, 1, 87, 6, 28, 2, 164], [23, 2, 20211, 180, 517, 368, 369, 55], [15, 8819, 8, 17, 8, 3120, 96, 35, 11, 22, 1, 55], [88, 23, 2, 1229, 8163, 1, 55], [250, 3, 87, 60, 24, 390], [3891, 12, 37, 209, 165, 38, 5, 44, 602, 353, 6, 20212, 11, 15, 6, 70, 15, 173, 2, 8715], [250, 102, 19, 20, 83, 8, 4, 3076, 5, 20213], [5, 113, 97, 624, 6, 585, 1, 37, 3, 75, 302, 97], [3902, 26, 9, 7, 20, 197, 1927], [2834, 127, 130, 68, 193, 6, 682, 2, 7767, 20214, 20215, 642], [57, 118, 42, 58, 233, 20216, 7, 1, 142, 4, 2458], [15, 3213, 7, 416, 86, 23, 2, 1, 230, 36, 110, 563, 17], [20217, 2950, 6, 22, 175, 123, 642, 456, 44, 132, 98, 674, 782], [4, 115, 3, 44, 1891, 682, 103, 14, 4, 115, 23, 4, 7779, 20218, 1, 1524], [10, 931, 2832, 415, 60, 236, 224, 4, 1825], [162, 4, 77, 3, 222, 1440, 22, 1743, 27, 3, 62, 42, 54, 116, 9, 559, 137], [1956, 81, 127, 88, 1, 39, 2124], [825, 1297, 46, 110, 491, 84, 1, 7, 332], [69, 1251, 4, 8590, 190, 3437, 18, 390], [159, 925, 12, 2957, 6, 2, 1202, 20219, 3, 75, 14, 4, 101, 68, 86, 40, 63, 58, 2, 320, 2058], [1157, 4, 3254, 95, 3457, 4, 20220, 1028, 26], [60, 95, 652, 1456, 6, 14, 3254], [55, 8, 20, 1680, 47, 1, 58, 3, 13, 554], [4331, 1608, 569, 16, 8820, 7, 213, 24, 47, 8821], [39, 9, 67, 10, 20221], [1656, 274, 70, 17, 2, 95, 37, 3, 63, 635, 750, 750, 750, 423], [31, 2689, 6, 14, 8214, 70, 17, 2, 339, 1, 821, 17, 562, 58, 3, 28, 2, 351, 20222, 4364], [38, 5, 113, 4, 8757, 5747, 267, 5, 34, 7, 1, 29, 72, 1163, 20223], [2564, 20224, 343, 14, 13, 584, 48, 207, 23, 20225], [36, 318, 14, 79, 473, 710, 16, 850, 34, 126, 323, 49, 292, 691, 16, 56], [477, 135, 5, 681, 1, 23, 59, 6, 19, 5, 35, 27, 60, 3544], [11, 4, 232, 1122, 712, 36, 124, 2, 1139, 406, 16, 3627, 8223, 27, 4, 1253, 1539, 12, 4, 1631, 220, 65, 20226], [298, 20227, 20228, 232, 20229], [7, 4, 232, 44, 1159, 1763, 344, 20230, 875, 192, 8, 1212, 16, 1079, 569, 6, 84, 20231, 11, 2, 658, 16, 4745, 20232], [39, 1, 46, 1798], [3059, 426, 740, 688, 707, 19, 416, 69, 121, 66, 452, 20233, 1392, 5, 1, 329, 26], [48, 59, 5, 1298, 3, 346, 5, 13, 284], [20234, 12, 3400, 1], [111, 69, 1841, 18, 682, 3008, 21, 438, 217, 49, 19, 144, 8, 20235], [91, 3429, 834, 32, 18, 202, 886, 122, 6, 28, 7, 24, 108], [1153, 59, 78, 1, 80], [584, 528, 37, 332, 973, 12, 4, 20236, 16, 20237, 20238], [1108, 825, 1215, 136, 132, 20239, 2249, 1033, 159, 8815, 26], [32, 794, 89, 1, 87, 6, 61, 6, 2341, 11, 20240, 1146], [23, 2, 141, 8732, 752, 8, 2716, 2526, 16, 4, 213], [1, 121, 3, 308, 99, 209, 1, 5, 46, 783, 113, 4, 910, 99], [1249, 3, 440, 32, 10, 9, 771], [38, 1, 1624, 3912, 59, 5], [53, 53, 66, 502, 1, 256, 6, 14, 214, 59, 26], [3, 14, 1500, 38, 9, 14, 1506, 6, 17, 13, 23, 556, 492, 76, 1, 42, 165, 28, 54, 135, 8, 28, 15], [269, 94, 269, 58, 9], [3, 90, 2, 171, 83], [24, 22, 24, 7], [1, 5, 210, 1090, 307, 5, 191, 10, 6, 303, 5, 2, 2183, 4711, 43], [1, 5, 48, 107, 26], [7, 19, 35, 38, 2, 1, 5, 1181, 142, 81, 1834, 88, 27, 9, 36, 708, 36, 29, 1181, 2181], [55, 1, 298, 97, 1130, 2360, 5, 62, 23, 7751, 90, 2, 291, 3162, 3, 90, 240], [57, 5, 1, 1332, 6, 623, 12, 39, 25, 29, 109, 14, 420, 18, 36, 96, 14, 19, 27, 7, 199, 1], [403, 29, 79, 170, 2, 1], [324, 82, 20241, 5, 75, 492, 155, 2072, 5, 41, 6, 100, 76, 3467], [5, 59, 6, 28, 32, 4, 9, 92, 55], [29, 1253, 17, 20, 518, 8, 113, 17, 6, 262, 8822, 23, 48, 20, 1, 55], [10, 443, 4989, 2530, 47, 38, 10, 306, 592, 10, 4654, 16, 954, 20242, 88, 47, 4666, 882, 16, 2, 1, 21, 1314, 68], [480, 20243, 20244, 947, 5654, 3470, 21, 20245], [789, 557, 51, 1255, 225, 160, 20246, 8823, 20247, 20248, 26, 348, 8823, 1903, 160, 75, 304, 188], [4, 437, 27, 144, 1132, 12, 36, 86, 20249, 26, 2389, 196, 20250, 17, 27, 474, 3, 20251], [12, 1723, 6099, 2, 9, 21, 4731, 84, 138, 12, 1723, 6099, 152, 44, 3264, 677, 12, 1723, 6099, 882, 16, 2, 2773, 1263], [85, 39, 9, 208, 13, 36, 48, 28, 19, 26, 249, 138, 34, 3, 46, 72, 295], [3, 62, 42, 797, 9, 20252, 11, 1907], [120, 1, 64, 4595], [38, 20, 91, 79, 5, 2, 1, 38, 78, 687, 52, 29, 86, 5, 109, 2, 1, 5, 33, 896, 13, 68], [66, 46, 228, 9], [4275, 16, 25, 2666, 8, 208, 13, 1, 5, 46, 2820], [37, 818, 16, 20253, 40, 96, 2, 9, 205], [891, 6, 20254, 82, 521, 6, 248], [69, 67, 6, 497, 18, 2852, 596, 17, 26, 313, 3534, 51, 1, 114, 4, 294, 16, 1898], [3097, 49, 431, 140, 36, 28, 109, 20255, 59, 166, 3097, 14, 3542, 59, 184, 36, 652, 3542, 1261, 188], [20256, 16, 20257, 6, 2336, 4, 250, 190, 1586], [139, 868, 1, 5, 62, 23, 3478], [3, 90, 15, 38, 2, 1, 62, 3, 29, 19, 27, 50, 26, 40, 109, 122, 6, 81, 6, 17, 13, 66, 431, 3309, 1, 1449, 5, 29], [40, 47, 13, 296, 29, 61, 6, 3349, 3965, 36, 49, 179, 8, 111, 28, 20258, 128, 3, 47, 13, 3522, 4, 45, 372, 6919], [87, 10, 138, 20259, 378, 1, 3, 87, 659], [38, 3, 465, 98, 183, 1, 81, 59, 246, 183, 1, 188], [42, 1, 46, 389, 10, 20260, 19, 5], [38, 3321, 8696, 121, 4767, 11, 10, 1783, 21, 2, 154, 2947, 3, 380, 15, 1498, 6, 72, 52, 1597, 84, 508, 21, 2, 154, 8697, 1817], [38, 2316, 121, 296, 46, 2, 1854, 34, 29, 842, 17, 2806, 12, 4, 2466, 3082, 244, 6, 28, 3514, 26], [38, 2976, 4, 3541, 121, 6059, 2, 554, 1, 8, 113, 10, 228, 3, 124, 2, 20261], [2204, 6, 1, 5, 380, 15, 3903, 45, 12], [52, 1426, 2, 1], [291, 43, 110, 464, 642, 12, 197, 18, 15, 1, 43, 3, 41, 256, 808, 37, 43], [1005, 5995, 382, 4335, 770, 21, 346, 4, 112, 3996], [230, 3, 298, 82, 2, 145, 151, 468, 4, 290], [588, 99, 22, 581, 145], [3534, 5, 2, 9, 31, 5, 330, 41, 154, 213, 4017, 893], [221, 1, 26], [552, 85, 3, 64, 703, 77, 36, 41, 93, 24], [55, 241, 20262, 1, 12, 5, 109, 107, 26, 71, 713, 5, 276, 14, 2042], [183, 1, 857, 1570, 17, 2584, 6921], [40, 121, 3, 41, 6, 239, 9], [3, 6073, 120, 5580, 158], [567, 95, 12, 3193], [3, 90, 38, 111, 191, 69, 5, 238, 65, 93, 21, 1, 531, 680], [89, 1], [7, 512, 240, 35, 45, 12, 431, 34, 2451, 60, 45, 3, 63, 137, 11, 580, 16, 1, 10, 20263, 60, 20264, 45, 3, 2036, 188], [496, 20265, 311, 20266, 98, 7744, 16, 5739, 20267, 20268, 1781, 7799, 3371, 20269, 26], [41, 473, 7199, 102, 7252, 21, 508, 1645, 21, 4, 570, 95, 225, 168, 20270, 51, 20271], [41, 3642, 6774, 18, 20, 508, 43, 2029], [53, 10, 1340, 65, 93, 20272, 9, 11, 80, 2015], [20273, 14, 13, 15, 46, 295, 6, 311, 7, 1, 3802, 15, 46], [1264, 1684, 12, 2, 1980, 48, 2, 382, 16, 2, 5380, 77, 3, 90, 6, 58, 22, 34, 1264, 12, 2, 1044, 48, 2, 1980, 34], [7, 71, 3, 484, 5, 1], [5717, 11, 4, 5856, 214, 130, 2, 1], [2219, 3658, 70, 356, 20274, 84, 8824, 716, 2278, 8824], [44, 2, 434, 115, 5, 64, 3007, 673, 513], [1044, 49, 4932, 3857, 6, 8825, 130, 8825, 49, 6, 20275, 34, 66, 49, 32, 3875, 44, 2, 434, 115, 5, 7241, 20276], [847, 64, 5, 34, 416, 499, 86, 20, 2, 117, 838], [24], [1158, 241, 2203, 20277, 3041, 860, 1721, 16, 95, 11, 20278, 160, 341, 1211], [3, 46, 41, 43, 20279, 1, 12, 4, 101, 184, 7, 3, 13], [164, 2, 1, 34, 7, 4, 101, 64, 3, 62], [1940, 1199, 2336, 382, 275, 3091, 69, 424, 820, 11, 2483, 641, 1331], [2231, 10, 758, 61, 1, 15, 8098, 369, 12, 329, 27, 5, 53], [38, 5, 839, 11, 4, 24], [75, 442, 3, 428, 204, 2, 20280, 251, 5, 2, 1, 7, 47, 415, 581, 25, 8713], [78, 25, 86, 3, 33, 662, 224, 20, 967, 58, 295, 1, 3, 14, 28, 1407, 99], [77, 3, 131, 1028, 10, 138, 102, 8, 313, 15, 51, 20, 285], [3, 157, 10, 1286, 18, 68, 645, 51, 2, 106, 33, 13, 5, 3095, 34, 88, 3, 119, 2, 20281, 1263, 24, 11, 10, 8087], [38, 42, 714, 2, 89, 480, 682, 1], [15, 13, 4, 294, 544, 34, 27, 882, 3137, 8, 127, 81, 942, 4390, 1183, 26], [31, 97, 418, 156, 28, 173, 15, 125, 166, 1, 42, 146, 113, 50, 7, 45, 46, 635, 8, 15, 20282], [1, 456, 44, 2, 20283, 26, 14, 1342, 6, 847, 88, 20284, 6019, 74, 3898, 71, 22, 1, 28, 11, 26], [25, 433, 35, 93, 77, 21, 319], [287, 118, 157, 35, 27, 727, 141, 64, 73, 358, 73, 4, 91, 44, 20285, 1, 14, 27, 291, 3452], [28, 542, 21, 8747, 5819, 115, 26, 112, 259, 2691, 5107, 8, 1172, 160, 241, 10, 1517], [1003, 71, 180, 16, 2, 24, 5410, 1437], [105, 279, 59, 71, 246, 1, 486, 307, 3, 62, 69, 3, 195], [10, 1, 70, 20, 1, 65, 13, 3568], [22, 1, 136, 2, 989, 6100, 18, 22, 25, 8826, 251], [23, 3890, 1920, 4761, 33, 5829, 2, 190, 1092, 34, 3, 210, 94, 170, 719, 2, 1686, 82, 4, 3564, 1714, 8, 458, 739], [26, 4698, 4297, 123, 3388, 4880, 244, 1837, 159, 8797, 26], [679, 1726, 20286, 8080, 362, 62, 71, 6, 56, 2, 20287], [1591, 2929, 7072, 7188, 7243, 20288, 2929, 20289, 31, 5, 79, 2, 1021, 51, 22, 446, 33, 72, 3808, 218, 15], [3, 86, 15, 106, 6, 316, 54, 4, 6082, 269], [37, 383, 29, 14, 1148, 1027, 42, 105, 636, 57, 20, 1, 58, 128], [20290, 156, 18, 10, 909, 14, 179], [67, 17, 6, 4476, 1, 14, 72, 393, 6, 14, 142], [38, 111, 72, 1934], [1678, 45, 63, 421, 5, 142, 31, 5, 468, 2, 93, 77, 3, 380, 5, 87, 2, 89, 1, 6, 107, 224, 8, 70, 15, 1452], [156, 280, 25, 28, 284, 11, 245, 1032, 53, 22, 1032, 12, 2967, 20291, 66, 276, 28, 1327], [71, 42, 533, 6, 9, 133, 20292, 42, 533, 6, 9, 133, 20293], [1, 14, 3888, 37, 3929, 3199, 20294, 26, 88, 52, 61, 28, 2, 154, 1, 26, 36, 122, 61, 28, 2, 154, 25, 6, 122, 6, 627, 59, 4], [7, 1029, 220, 42, 228, 1674, 2, 1, 51, 7653, 21, 79, 20295, 58, 42, 92, 193, 106, 15, 12, 333, 3356, 54, 10, 231, 774, 4734], [261, 12, 37, 8804, 23, 33, 122, 6, 433, 4, 521, 8, 28, 54, 22, 1], [3, 195, 114, 5, 20296, 2737, 17, 108, 158], [729, 5, 310, 9, 3, 566, 20297], [20, 48, 4, 1544, 57, 155, 20298, 64, 6, 20299], [543, 50, 11, 4, 187], [99, 239, 104, 18, 135, 7, 86, 36, 63, 1636, 17, 123, 10, 250, 226], [3, 301, 3, 47, 2, 95, 37, 3, 222, 1577, 45, 18, 4, 111, 3, 90, 513], [221, 3, 62, 15, 3699, 6101, 4, 68, 162, 52, 1124, 6, 257, 3259, 8, 308, 1261], [252, 3, 124, 2, 496, 16, 39, 95, 51, 10, 197, 172], [57, 27, 189, 8, 203, 1, 3, 103, 1113, 105, 594], [3, 222, 105, 780, 224, 27, 217, 499, 91, 13, 7, 33, 20300, 20, 653, 73, 2, 234, 282], [132, 10, 455, 399, 371, 3632, 1651, 1142], [75, 196, 256, 6, 217, 38, 36, 2111, 35, 4656, 1], [63, 5, 28, 387, 2031, 82, 509, 99, 239, 1486, 20301, 20302, 675], [20303, 3, 514, 10, 1178, 160, 20304, 11, 155, 19, 1510, 16, 7932, 2369, 13, 148, 1, 28, 1372], [57, 78, 9, 35, 6], [2, 77, 175, 463, 318, 14, 179, 31, 42, 316, 522, 82, 619, 173, 4, 3099, 43, 42, 318, 14, 185, 31, 42, 389, 3100, 21, 2, 340], [183, 1, 136, 1009, 18, 50, 402, 21, 50, 835, 193], [1087, 10, 150, 59, 653, 2485, 48, 6, 86, 21, 943, 1, 12, 20305], [31, 3, 498, 35, 6, 20, 1, 11, 39, 20306, 1557, 630, 2, 419, 25, 26], [20, 1, 38, 10, 20307, 480, 35, 26], [1, 262, 17, 5726, 250, 74, 2180], [20308, 908, 3243, 3, 87, 6, 28, 17, 2, 89, 1], [242, 20, 158, 30, 2599], [151, 105, 366, 441, 27, 20309, 1404, 52, 1713, 7, 1307, 20310, 8827, 8, 3, 19, 90, 7, 20311], [3, 72, 158, 27, 64], [20312, 230, 9, 1030, 418, 27, 43, 20313, 160, 1666], [1163, 500, 504, 113, 111, 3, 506, 1515, 8, 20314, 800, 31, 40, 2, 1664, 160, 20315, 2940], [296, 121, 4537, 3856, 4865], [15, 20316, 4, 4602, 5471, 12, 750, 4342, 130, 4, 3983], [2774, 21, 20317, 4, 7281, 21, 1937, 20318, 8828, 8766], [3, 8545, 442, 7, 435, 65, 2504, 73, 45, 27, 2, 179, 30, 3074], [4833, 855, 453, 80, 373, 148, 624, 1], [1614, 22, 1, 1200, 1363, 130, 60, 25, 138], [371, 3, 62, 20, 454, 43, 353, 3443, 12, 48, 2, 507, 6, 303, 3443, 392, 16, 3255], [3, 29, 1190, 1467, 236, 3, 383, 1190, 1467, 39, 9], [3021, 103, 14, 2, 1, 31, 52, 338, 8, 219, 1103, 12, 383, 2, 1, 1804, 55], [601, 3, 477, 26, 5620, 76, 206, 1623, 1725, 73, 3, 63, 26, 20319, 539, 32, 76, 1, 6, 70, 362, 3, 176, 35, 27], [20320, 82, 1328, 306, 136, 201, 352, 2050, 18, 6139, 128, 9, 30], [115, 201, 16, 20321, 20322, 5858, 20323, 381, 28, 98, 1561, 6, 215, 3165, 6, 20324, 20325, 14, 4, 237, 20326, 899, 236], [53, 3, 603, 920, 22, 595, 355, 1, 20327, 148, 1002, 55], [36, 56, 464], [2991, 3208, 21, 72, 4, 163, 324, 362, 34, 29, 70, 675, 59, 50, 1719, 4009, 29, 14, 248], [1243, 1691, 16, 242, 20, 1, 30, 35], [563, 17, 8, 10, 1, 410], [3, 62, 1, 69, 506, 24, 21, 5613], [1, 58, 3, 1182, 5, 149, 5, 156, 598, 6, 14, 11, 10, 624], [4501, 30, 29, 87, 43, 127, 20328, 38, 4, 1, 467, 40, 627, 474, 4, 727, 244, 115, 15, 105, 996], [42, 46, 8248, 2179, 1], [19, 4, 2651, 654, 66, 103, 204, 212, 187], [610, 87, 6, 139, 14, 2, 1], [3, 90, 2, 1, 7, 1577, 79, 1227, 2030, 7, 45, 12, 37, 589, 91], [336, 1, 5, 46, 33, 223, 61, 102, 18, 17, 8, 33, 67, 17, 108, 473, 691, 3026, 23, 137, 2686, 444, 3022, 1649], [24, 25, 29, 28, 43, 24, 25], [38, 4, 2323, 1125, 313, 5, 60, 24, 8, 5, 29, 430, 15], [3, 194, 10, 253, 405, 13, 635, 38, 36, 192, 94, 45, 7, 216, 76, 1917, 55, 114, 3451, 1], [10, 734, 2462, 133, 39, 265, 460, 127, 130, 126, 915, 364, 2574, 85, 118, 5, 86, 15, 422, 21, 5, 6, 24, 429, 51], [154, 1648, 1, 14, 13, 1558, 20329], [3, 3087, 10, 1246, 1802, 1072, 6, 4, 2001, 22, 2428, 23, 559, 5735, 27, 10, 154, 20330, 3811, 5708], [172, 8437, 120, 12, 270, 2, 1], [243, 1147, 283, 33, 67, 5, 6, 62, 5096, 5, 8829, 29, 182, 19, 627, 71, 1455, 8, 870, 5, 1563], [20331, 63, 8, 103, 19, 35, 4, 20332, 2823, 6470, 35, 283], [53, 219, 46, 22, 133, 2, 1, 188, 26, 53, 321], [4734, 547, 416, 54, 27, 1107, 938, 8, 4630, 1216, 34, 43, 68, 63, 3828, 170, 7950, 256, 46, 117, 1261], [31, 5, 4231, 102, 2, 189, 2558, 33, 140, 5, 44, 2, 520, 20, 2, 1], [633, 11, 1306, 92, 536, 21, 190, 5420], [92, 79, 142, 20, 991, 8, 20, 587, 8, 14, 148, 159, 524], [21, 320, 16, 434, 20333, 536, 54, 20334, 8, 5976, 27, 232, 1085, 225, 82, 947, 2748, 6, 5343, 2748, 5827, 26], [55, 22, 12, 85, 3, 29, 19, 27, 37, 239, 20335, 79, 50, 2, 1063], [3, 44, 43, 9, 720, 3, 29, 87, 212, 464, 3, 87, 6, 479, 588, 108, 35], [262, 217, 1678, 24, 47, 37, 8574, 26, 6253, 329, 8742, 8, 1083, 22, 27, 126, 20336, 951], [31, 7, 57, 70, 39, 203, 1, 376, 51, 264], [45, 25, 29, 7355, 92, 5, 41, 712, 21, 625, 677, 82, 9, 20337, 151, 20338], [18, 177, 23, 2, 144, 601, 32, 4, 106, 2064], [1, 1794, 17], [42, 2, 3218, 5, 2, 1353, 177, 5, 451, 12, 3770, 3, 1038, 5, 72, 256, 108, 3, 7351, 20, 1102], [3, 86, 571, 20339, 4934, 2801, 11, 3079, 409, 20340, 1, 63, 14, 20341, 8, 20342, 21, 4, 9, 20343], [2684, 3472, 1257, 6, 1704, 1992, 3453, 188, 7, 25, 3432, 4, 910, 18, 65, 30, 1, 128, 188, 3, 724, 217, 47, 152], [4, 20344, 1098, 891, 168, 6, 167, 4, 8370, 419, 11, 84, 679, 1330, 20345, 20346, 527, 513, 2562], [469, 51, 2, 20347, 856, 3, 122, 6, 58, 4, 1329, 6, 1268, 22, 1, 8, 3, 2131, 10, 138, 18, 4, 20348, 20349], [4237, 20350, 75, 397, 4237, 1, 11, 979, 36, 1229, 589, 8, 36, 81, 99, 20351], [3, 3457, 21, 5, 5, 4360, 20352], [2, 9, 223, 14, 2, 9], [300, 39, 9, 46, 41, 295, 18, 17], [3, 90, 2, 1, 7, 86, 40, 4, 45, 1, 5, 339, 73, 4, 19], [8758, 207, 2680, 3, 842, 4738, 8759], [20353, 7136, 125, 165, 904, 330, 1, 20354, 78, 4959, 8830, 32, 143, 193, 35], [8269, 3263, 12, 192, 6, 175, 4, 2039, 374, 2967], [3, 101, 20355, 1285, 20356, 1274, 56, 6, 2759, 253], [3, 41, 79, 2, 104, 21, 303, 77, 782, 37, 92, 23, 152, 19, 7, 395, 11, 4, 30], [23, 101, 108, 149, 3, 29, 131, 94, 4, 177, 468, 6, 56], [20357, 1249, 289, 297, 5, 11, 5853, 51, 4, 269, 904, 34, 3, 47, 99, 624, 28, 257, 35, 55, 66, 198, 81, 127, 877], [990, 1, 174, 24, 532, 13, 990], [4596, 7, 1096, 24, 20358], [174, 24, 532, 13, 3239, 1402], [46, 41, 106, 21, 185, 1], [888, 1995, 24, 532, 13, 45], [4, 101, 184, 5, 87, 11, 164, 49, 20359, 758, 8, 354], [1, 5, 2476], [3, 41, 186, 1126, 26, 20360, 4, 1156, 2785, 196, 20361, 42, 2, 327, 233, 1, 5, 165, 2077, 10, 830], [232, 210, 67, 2567, 1920, 37, 52, 821, 27, 4, 3836, 201, 213, 1712, 3836, 44, 216, 20362, 20363], [7657, 7658, 168, 84, 154, 8831, 343, 6, 81, 1399, 54, 16, 2, 190, 1092, 113, 4, 6091, 296, 195, 34, 2, 2792, 1526], [15, 2, 8683, 2, 8684, 20364], [29, 41, 2, 437, 737, 2, 1], [19, 143, 4623, 5115, 19, 1656, 9, 20365], [15, 2, 95, 15, 2, 2185, 15, 2, 1602, 20366, 20367, 2, 635, 1044], [3, 131, 14, 4, 540, 42, 65, 142, 51, 20, 310, 26, 872, 88, 2, 347, 298, 80, 30, 129, 9], [1915, 2, 1, 15, 109, 12], [29, 119, 24, 444, 40, 229, 5, 4, 20368], [19, 3613, 30, 1, 3, 300, 55], [293, 5, 41, 57, 5, 67, 83], [945, 20369, 3504, 20370, 3, 103, 105, 438, 2, 275, 27, 246, 145, 226, 18, 50, 55, 26, 369, 26], [3, 44, 478, 6, 2291, 4, 2725, 16, 119, 2, 3132, 4568, 461, 65, 13, 3, 33, 440, 159, 925, 1728], [23, 2, 883, 2906, 91, 531, 3, 64, 7, 180, 1], [135, 107, 1319, 1221, 6173], [120, 574, 103, 79, 953, 918, 8, 708, 36, 114, 126, 401, 34, 44, 2196, 4269, 1356, 8832], [31, 2, 1308, 616, 11, 4, 1932, 8, 357, 12, 224, 277, 15, 70, 245, 3370, 31, 7286, 665, 423, 8, 101, 56, 259, 4, 188], [576, 1762, 46, 43, 899, 9, 42, 6044, 1299, 445, 1091, 188], [10, 2863, 178, 20371, 37, 3, 146, 119, 4, 24, 13, 2, 6793, 20372], [6592, 3173, 21, 247, 685, 1503, 478, 27, 253, 4, 1219, 2483], [23, 152, 728, 54, 27, 10, 968, 54, 8, 20, 152, 1873, 54, 27, 20, 949, 54], [9, 14, 13, 1993, 81, 6, 68, 16, 20, 20373, 3, 14, 13, 463, 49, 68, 16, 10, 894], [3, 62, 187, 2877], [159, 2467, 71, 6, 176, 212, 20374, 7295, 26], [50, 24, 271, 631, 38, 40, 224, 17, 146, 735, 15, 634, 40, 4026, 88, 105, 230], [20375, 12, 270, 2, 141, 1, 52, 317, 110, 13, 4, 77, 8, 52, 28, 253, 3, 3662, 10, 164, 6, 76, 8, 3, 4762], [2, 334, 77, 109, 1786, 277, 107, 27, 2, 1220, 476, 8, 5844, 101, 2, 9, 103, 100, 5, 58, 73, 5, 333, 149, 40, 1080], [469, 361, 95, 16, 2, 20376], [3, 44, 2, 1106, 858, 68, 26, 2, 7909, 3171, 1155, 5672, 49, 2, 454, 184], [20377, 47, 2, 1, 20378, 205], [303, 17, 957, 2178, 354, 8, 5, 63, 14, 10, 520], [1266, 11, 50, 24, 47, 64], [221, 3, 536, 10, 3084, 3, 44, 19, 7229, 200, 5, 536, 31, 5, 220, 14, 2, 161, 1, 25], [37, 620, 480, 12, 2, 159, 4057, 629, 123, 527], [734, 2643, 46, 3462, 5, 46, 1856, 6, 113, 84, 455, 1, 133, 84, 234, 1], [78, 25, 12, 319], [38, 84, 9, 299, 15, 47, 129], [3, 90, 1617, 30, 1, 13, 188, 15, 99, 570, 21, 5, 6, 14, 32, 8833, 400, 364, 142, 20379], [4029, 10, 20380, 267, 5, 37, 209, 362, 196, 2, 320], [43, 87, 6, 3426, 27, 166, 287, 116, 101, 68, 16, 17, 8, 2355, 23, 7, 1], [5, 4, 20381, 395, 18, 10, 909, 34, 5, 156, 37, 2307, 23, 549, 16, 15], [3, 255, 1493, 32, 1444, 358, 37, 43, 6734, 634, 850], [23, 44, 2, 438, 51, 232, 1194, 88, 28, 605, 20382], [5, 49, 4, 796, 268, 231, 1, 3, 44, 182, 4772, 5, 266, 410, 50], [111, 2020, 6, 94, 287, 481, 34, 4, 691, 374, 297, 7, 414, 12, 92, 2, 9, 241, 550], [38, 2, 2089, 9, 28, 214, 1, 242, 35, 5, 47, 550, 27, 14, 710, 32, 22, 106, 92, 32, 16, 2547, 15, 2, 8741], [1, 175, 14, 1671, 296, 131, 249, 60, 138, 53, 88, 14, 1671, 53, 497, 15, 33, 2, 323, 53, 1, 57, 323, 12], [3, 14, 37, 1075, 38, 78, 14, 175, 296, 131, 1, 7, 63, 694, 10, 441, 20383, 32, 264, 6623, 13, 369, 698, 16, 1911], [141, 1], [7, 9, 37, 3334], [60, 16, 5, 9, 41, 37, 209, 6, 72, 27, 37, 141], [1959, 24, 14, 13], [1378, 49, 5, 8409, 221, 18, 2, 1844, 16, 68, 6, 1654, 1], [10, 1228, 18, 567, 95, 12, 2714, 130, 4, 20384, 1228, 117, 92], [85, 14, 1864, 38, 5, 63, 14, 1531, 19, 872, 5, 681, 1], [302, 43, 1], [1216, 291, 1394, 456, 48, 6308, 8, 958, 4649, 661], [2236, 239, 9, 15, 198, 14, 98, 20385], [54, 135, 471, 9, 656, 102, 8755], [3, 407, 157, 18, 1681, 21, 2, 1, 48, 6, 13, 307, 3, 148, 21, 362, 20386], [159, 824, 1337, 825, 1215, 11, 2, 1382, 1837, 849, 162, 155, 946, 103, 690], [482, 31, 3, 404, 5, 29, 28, 43, 24, 390, 17, 20387], [3734, 3593, 16, 1012, 12, 20388, 2252, 377, 69, 304, 21, 15, 188, 20389, 84, 8440, 6, 6156, 26], [15, 168, 6, 14, 2, 1898, 6, 14, 20390, 27, 685, 871, 36, 79, 15, 2734, 55], [52, 56, 1249], [31, 3, 220, 6, 72, 14, 10, 504, 118, 5, 442, 7, 3, 405, 32, 10, 9, 21, 5], [20391, 1353, 18, 265, 13, 1360, 1428, 1097, 135, 57, 4, 19, 12, 329, 27, 20392, 219, 7, 1, 648, 412, 125], [36, 372, 13, 5166, 187], [31, 20, 20393, 208, 13, 20, 212, 1247, 48, 13, 20, 20394, 15, 48, 2383, 7, 20395, 1029, 38, 3, 299, 22, 175, 47, 1261], [31, 5, 86, 20, 91, 359, 5, 114, 170, 6, 7, 1, 331, 8, 94, 31, 84, 3251, 3084], [7773, 11, 22, 1774, 133, 6, 728, 2335, 2368, 229], [2320, 40, 37, 183, 69, 12, 7, 9], [10, 24, 5931, 1368], [20396, 11, 97, 1340, 7, 9, 259, 55], [97, 161, 171, 30, 1, 2859, 20397], [136, 136, 112, 226, 12, 20398, 162, 78, 28, 39, 179, 30, 226, 82], [542, 6, 70, 225, 10, 83], [11, 4, 56, 3, 6662, 33, 405, 1763, 154, 323], [1285, 5014, 5, 811, 101, 4, 3412, 8012, 167, 350, 3, 61, 6, 28, 10, 2691, 6, 421, 20, 833, 5, 386, 16, 2, 1], [1748, 3032, 404, 2553, 21, 249, 10, 466, 5, 544, 381, 6102, 138, 386, 16, 2, 1], [10, 3, 683, 4, 2965, 82, 7, 20399, 180, 95, 34, 3, 421, 84, 19, 833, 26], [597, 35, 5, 171, 386, 16, 2, 1], [1687, 5, 49, 92, 1239, 180, 106, 24], [4470, 20400, 24, 340, 13], [88, 42, 44, 4, 589, 8834, 17, 3, 1038, 1323, 30, 1, 156, 238, 959, 2, 180, 30, 20401, 6068, 30, 7044, 77, 31, 5], [85, 58, 25, 1385, 21, 1016, 1, 13, 29, 78, 131, 1, 7, 1611, 5, 6, 165, 20402], [155, 1, 41, 2, 25, 7, 40, 223, 156, 19, 2047, 43, 690, 3779], [32, 39, 1, 1504, 3927, 13, 2, 5035], [2798, 136, 3030, 20403, 18, 20404, 30, 605, 21, 8207, 159, 6, 4606, 4, 908, 4, 1935, 200, 6, 3954, 4258], [155, 91, 75, 44, 2, 89, 83, 34, 11, 22, 823, 31, 5, 41, 20405, 1278, 26, 523, 103, 6, 61, 162, 20406, 20407, 5], [155, 106, 5, 376, 27, 268, 287, 11, 2, 115, 15, 1392, 22, 823, 136, 2, 437, 2342, 1, 59, 126, 653, 596], [31, 20, 91, 12, 243, 11, 84, 244, 575, 20, 19, 35, 193, 49, 2, 1236, 1], [15, 2, 41, 148, 1898, 1, 125, 1744, 30, 138, 249, 1970, 49, 48, 1039, 20408], [358, 714, 2610, 9, 14, 349, 102, 126, 4392, 661, 16, 3459, 51, 1, 36, 122, 6, 249], [43, 91, 136, 182, 2828, 2, 260, 110, 31, 52, 44, 50, 6079, 18, 254, 2828, 1, 103, 738, 563, 274, 26, 36, 260, 6, 231, 2812], [111, 69, 523, 1288, 6103, 62, 38, 6, 257, 126, 265, 26, 38, 6, 81, 6, 980, 489, 9, 26, 2406, 123, 20409, 198, 163], [4, 3732, 8539, 63, 249, 24, 288, 18, 503, 16, 143, 360, 34, 38, 36, 139, 137, 26, 143, 1721, 523, 223, 36, 20410], [22, 1, 125, 2, 260, 191, 17, 6, 1868, 930, 37, 4, 730, 222, 14, 2780, 3, 121, 757, 10, 730, 407, 612], [186, 730, 3, 1373, 6, 157, 10, 2160, 2951, 35, 225, 73, 738, 73, 3, 44, 22, 24, 7312, 77, 3, 389, 21, 2312], [38, 315, 77, 249, 24, 82, 2, 1, 69, 33, 424, 2, 893, 340, 1515, 4, 166, 115, 7, 196, 4, 4289, 9, 672, 893], [5, 49, 69, 5, 543, 15, 125, 3633, 536, 80, 20411, 31, 8024, 26, 20412, 30, 1, 3140, 42, 15, 1547, 2], [53, 17, 8, 581, 145, 11, 4, 20413, 20414, 5921, 584, 135, 18], [147, 45, 56, 2, 758, 2660, 123, 725, 1217, 6390, 20415, 92, 26], [4, 178, 257, 1369, 20416, 11, 819, 20417, 20418, 527, 160, 22, 1, 1369, 670, 75, 14, 725], [53, 277, 7681, 44, 5674, 18, 50, 24, 3182], [8, 31, 5, 46, 2, 9, 28, 35, 54, 10, 941, 20419], [1625, 583, 65, 13, 4, 1040, 16, 492, 2, 9, 12, 255, 170, 142, 26], [2, 1, 103, 19, 125, 2, 544, 257, 586, 73, 358, 73, 52, 8835, 50, 536], [37, 12, 20, 24, 128], [1385, 142, 12, 21, 24], [232, 20420, 124, 2, 20421, 1984, 3240], [82, 390, 53, 163, 324, 74, 20422, 12, 127, 20423, 415, 4, 68, 5, 266, 1175, 54, 5, 19, 4036], [4, 1990, 16, 24, 11, 8836, 136, 92, 20424, 6, 68, 20425, 1149, 8, 2, 4142, 20426, 3532, 27, 2850, 4746], [70, 225, 10, 1], [8837, 2301, 1914, 2675, 12, 96, 5758, 18, 5, 9, 11, 4, 247, 1621, 681, 3810], [22, 1, 33, 1807, 10, 314, 8, 3, 47, 314, 102, 32, 16, 39, 692], [5717, 200, 48, 1465, 20427, 31, 2, 1, 5, 29, 13, 107, 51, 5, 13, 7, 26, 5, 96, 400, 80, 30, 20428, 2022, 7], [3, 273, 5, 6, 753, 7, 1, 34, 5, 46, 131, 477, 3938, 26], [1128, 478, 42, 563, 2, 95, 27, 2, 417, 4450, 8, 20, 13, 20429, 59, 42, 65, 20430, 55], [324, 61, 82, 1059, 6, 1, 3, 64, 5, 6, 3, 90, 5, 3, 87, 5, 6, 627, 5, 20, 10, 474, 6, 20, 2766], [26, 19, 39, 1], [10, 451, 578, 568, 82, 179, 202, 77, 6, 2214, 120, 2449], [3, 103, 290, 2, 1, 21, 1670, 7, 10, 20431, 117, 116, 46, 43, 68, 780, 27, 10, 120, 1018, 405], [20432, 20433, 20434, 1525, 4, 1623, 20435, 951], [22, 265, 12, 255, 8838, 1568, 8, 2, 29, 1513, 10, 1008, 20436, 8, 23, 13, 338, 60, 24, 21, 4, 763, 16, 263, 252], [171, 1, 1606, 2, 3271, 93, 2557], [31, 97, 1, 214, 113, 136, 151, 157, 136, 373], [1386, 3456, 10, 101, 1], [3, 90, 38, 1150, 1, 122, 6, 114, 423, 217, 20437], [1, 14, 122, 4, 329, 1, 26, 29, 110, 14, 20438], [189, 14, 13, 6104, 19, 7, 368, 34, 839, 1077, 36, 346, 7, 1063, 96, 64, 7, 1063, 26, 67, 7, 1063], [2095, 620, 16, 4, 20439, 1065, 51, 20440, 20441, 2190, 20442, 47, 4, 930, 16, 4, 20443, 69, 20444, 7697, 26], [31, 20, 504, 317, 13, 7, 83, 5, 29, 81, 6, 7, 83], [22, 1, 33, 121, 296, 293, 15, 1979, 13, 286, 22, 850, 53, 92, 71, 11, 4, 428, 19, 58, 5, 772, 7, 6, 582], [43, 1, 42, 220, 48, 1348, 27, 1212, 1381, 16, 20445, 8, 2391, 18, 97, 231, 7, 48, 97, 905, 231], [206, 931, 127, 13, 379, 83], [945, 31, 42, 2, 291, 1, 27, 3320, 578], [101, 702, 653, 3460, 25, 294, 224, 20446, 59, 1, 52, 19, 36, 44, 256, 6, 1392, 6, 574], [7, 7401, 1574, 178, 12, 21, 143, 942], [5, 124, 17, 51, 3510, 5863], [171, 1], [2, 95, 387, 1535, 16, 225, 20447, 267, 21, 4, 434, 1651, 197], [22, 1, 33, 1807, 10, 314, 26, 3, 47, 102, 32, 16, 1019, 20448], [20449, 482, 751, 1360, 46, 1573, 6, 311, 7, 1, 2235, 27, 99, 209, 20450], [66, 156, 1, 59, 4, 4534, 352, 38, 220, 1805, 33, 73, 8554, 48, 32, 34, 2, 2850, 20451, 3016, 51, 15], [392, 644, 20452, 4, 215, 20453, 82, 2738, 991, 3645, 215, 2861, 69, 4, 673, 18, 4290, 26], [20454, 20455, 3005, 855, 20456, 20457, 9, 186, 2445, 20458, 6548, 527], [1219, 2381, 277, 48, 2223, 4, 1838, 16, 20459, 8, 20460], [773, 141, 1, 78, 25, 20461], [162, 143, 9, 6058, 3718, 785, 51, 20462, 11, 20463, 20464, 59, 6, 728, 325, 20465], [44, 126, 132, 245, 1193, 16, 98, 20466, 4121, 7, 227, 673, 8782, 598, 13, 7, 698, 16, 921], [592, 873, 353, 1799, 11, 4, 7412, 2, 213, 20467, 672, 76, 2656, 31, 3, 309, 390, 39, 103, 14, 4, 884, 1432], [5506, 3366, 6, 159, 925, 5, 220, 114, 4595, 159, 925, 3, 407, 114, 254, 3, 124, 6, 389, 21, 254, 527, 188], [31, 2, 25, 63, 113, 9, 52, 1041, 52, 2, 112, 25, 26], [222, 105, 605, 35, 6, 2, 1, 74, 253, 35, 14, 4460, 48, 10, 1833, 16, 1289, 5, 9, 65, 4966], [159, 824, 1813, 6, 108, 142, 82, 20468, 1183, 18, 1755], [38, 4, 24, 37, 93, 26, 42, 627, 6, 349, 54], [242, 4, 19, 35, 171, 1], [116, 103, 14, 1345, 3164, 985, 22, 1343], [550, 550, 7328, 5919, 95], [3, 90, 2, 296, 29, 262, 8748, 409, 1], [1916, 35, 1, 25], [3, 19, 174, 1, 211, 3, 41, 20469], [2596, 77, 7, 24, 20470, 23, 20471, 129, 25], [3249, 657, 2613, 1229, 19, 9, 123, 4, 20472, 161, 20473, 2665, 18, 10, 161, 25, 12, 2, 2544, 1443, 907, 1621], [39, 593, 176, 72, 32, 25, 67, 12, 20474, 1, 369, 499, 277, 20, 291, 4577, 867, 30, 44, 6, 102], [378, 251, 8216, 26, 57, 2, 172, 2121, 20475], [3372, 12, 4016, 22, 1164, 4, 215, 201, 449, 136, 8839, 99, 239, 1346, 11, 126, 4339, 7494, 502, 76, 286, 99], [463, 49, 2967, 17], [15, 32, 36, 62, 5, 1, 105, 152, 340, 243, 253, 39, 685, 2555], [5, 67, 2, 341, 481, 5, 67, 2, 5044, 5, 165, 14, 1348, 173, 4985, 83], [8723, 2, 9, 233], [57, 5, 96, 58, 35, 10, 312], [3, 131, 119, 441, 348, 34, 88, 3, 191, 10, 653, 31, 3, 109, 131, 1049, 20476, 755, 194, 2, 20477, 18, 3678, 2874], [3, 301, 36, 216, 2, 9, 5017, 26, 278, 14, 13, 229, 17, 4, 9, 5017, 230, 438, 2, 77, 26], [1, 103, 19, 2, 25, 27, 169, 62, 52, 46, 303, 50, 385, 34, 266, 19, 2, 291, 25, 7, 118, 134, 50, 84], [23, 109, 4037, 3, 81, 6, 416, 23, 750, 82, 14, 2, 861, 35, 83], [5, 168, 6, 14, 4, 45, 34, 92, 5, 46, 45, 1], [52, 2, 918, 48, 2, 25], [60, 39, 1, 41, 6022, 8, 29, 110, 44, 347, 18, 4, 20478, 100, 771, 8840], [162, 5, 28, 4, 681, 20479, 1715, 189, 119, 24, 233], [2790, 1, 8382, 405, 20, 265, 102, 225, 6839, 1, 3, 29, 41, 265, 2790, 48, 43, 127, 1, 3, 3761, 240, 26], [6079, 715, 39, 1], [39, 9, 41, 43, 497], [13, 38, 20, 2, 9, 71, 58, 42, 376, 51, 264], [1588, 20480, 472, 73, 190, 20481, 103, 231, 1338, 21, 20482, 8235, 16, 1745, 522, 20483, 26], [20484, 1043, 1, 1009, 11, 4, 6075, 2380], [38, 3, 313, 423, 20485, 3271, 173, 4, 56, 63], [53, 495, 258, 22, 1, 26, 19, 876, 40, 46, 124, 43, 93, 138, 19, 27, 22, 203, 916, 1817], [89, 1, 28, 11, 351, 264, 51, 4167, 4891, 3833], [9, 18, 10, 20486], [87, 2, 89, 1, 69, 62, 71, 201, 557, 2, 4643, 2291, 117], [7, 1, 46, 3462], [3, 44, 105, 801, 37, 209, 13, 2, 141, 1, 33, 82, 2, 19, 496, 178, 23, 338, 20487, 20488], [3867, 7731, 8465, 103, 44, 2, 20489, 106, 893, 126, 20490, 159, 75, 20491], [53, 19, 5, 72, 1, 3, 103, 204, 5, 53], [1, 662, 11, 4, 2141, 20492, 3406, 20493, 75, 3, 258, 2, 93, 189, 20494], [5, 189, 49, 32, 4, 237, 64, 5, 312, 1902], [1815, 1470, 44, 8839, 7, 174, 2, 161, 1], [243, 1328, 3513, 135, 17, 27, 28, 542, 6, 1, 491, 2, 20495], [2721, 1503, 416, 650, 20, 2, 19, 1, 88, 599, 33, 2631], [71, 209, 2543, 200, 159, 925, 4497, 602, 6, 204, 268, 8, 2, 470, 435, 3, 380], [22, 1, 12, 4, 2877, 1207, 51, 1653, 26], [6660, 7, 30, 38, 42, 94, 7, 1, 69, 47, 533, 45, 18, 186, 11, 7264], [68, 268, 1058, 1763, 71, 239, 158, 49, 11, 10, 1333], [22, 12, 4, 164, 158], [200, 7, 1, 182, 28, 54, 16, 8688, 193], [57, 1, 122, 6, 204, 2598, 2599, 1822], [757, 30, 25, 1986, 1452, 26], [2203, 796, 4386, 29, 627, 59, 1084, 69, 33, 1525, 98, 1455, 20496], [158, 2, 3850, 1262, 2284], [174, 1413, 186, 9], [378, 201, 292, 20497, 71, 239, 158, 49, 11, 10, 1333, 3, 20498, 20, 719], [18, 22, 115, 862, 4, 1316, 3865, 54, 16, 4, 7672, 2, 20499, 3516, 6, 26], [3, 29, 62, 85, 3, 61, 18, 7, 2519, 231, 1, 1610, 40, 28, 17, 926, 155, 106], [10, 481, 299, 2242, 28, 98, 1037, 2102, 376, 34, 10, 1209, 1389, 6, 597, 35, 201, 2102, 20500, 10, 1209, 2, 83], [159, 2244, 18, 1755, 36, 442, 3393, 427, 129, 2244, 12, 2, 4774, 1997, 20501, 8, 529], [31, 3, 47, 642, 278, 79, 2, 1160, 4703, 26, 935, 852, 2858, 833, 18, 259, 886, 33, 201, 229, 39, 353, 3, 196, 624], [267, 5, 20502, 21, 70, 20, 4750, 4, 1366, 16, 2, 19, 3983, 3, 64, 134, 531, 4, 20503, 20504, 155, 1091], [553, 16, 10, 1, 1105, 17, 36, 64, 17, 29, 86, 36, 118, 13, 17, 31, 3, 47, 245, 166, 193], [1, 14, 13, 2582, 34, 96, 14, 11, 326, 624], [60, 77, 14, 168, 923, 73, 98, 919, 6, 208, 13, 9, 8, 28, 423, 27, 15, 251], [3, 46, 152, 262, 250, 1027, 3442, 1], [31, 66, 438, 42, 29, 110, 146, 475, 133, 17, 81, 6, 166, 9, 1027, 3, 46, 41, 245], [40, 121, 3, 67, 2, 91, 69, 63, 479, 17, 35, 985, 352, 1, 5, 811, 3, 479, 5, 35, 51, 32, 1069, 1990, 314, 73, 286], [234, 9, 100, 70, 263, 1239, 17], [200, 7, 1, 82, 2923, 182, 100, 15, 61], [200, 212, 1, 82, 2923, 182, 1478, 2, 20505], [4552, 109, 54, 430, 2, 2011, 288, 50, 386, 65, 54, 4, 1371, 13, 4, 8666, 269, 288, 326, 843, 74, 8532], [53, 10, 409, 2, 1, 2374, 128, 2875], [77, 1993, 81, 6, 20, 166, 894, 178, 99, 870], [66, 259, 11, 2, 360, 392, 16, 2770, 9, 26, 183, 25, 191, 21, 1420], [38, 42, 27, 80, 455, 1, 8, 5, 94, 80, 234, 1, 11, 775], [11, 166, 1199, 20, 1, 867, 21, 307], [567, 95, 12, 114, 129, 10, 1068, 3, 63, 465, 4, 95, 1780, 155, 106, 256, 568, 2625], [22, 1, 41, 4, 7823, 1067, 8, 4383, 1356, 18, 50], [20506, 2139, 5237, 1304, 32, 4, 184, 1108, 44, 572, 11, 4, 3048, 527, 52, 12, 236], [219, 66, 362, 73, 20507, 62, 71, 6, 20508, 23, 509, 4, 56, 117, 92, 8, 603, 474, 289, 566, 18, 4, 8362], [5538, 10, 6105, 593, 4868, 65, 13, 174, 2659, 396, 138, 6, 6105, 296, 1456, 57, 3, 121, 368], [53, 20509, 20510, 123, 898, 12, 2967, 267, 5], [202, 77, 44, 105, 132, 173, 307, 3, 380, 149, 3, 29, 79, 76, 9, 506, 692, 74, 512, 25, 709, 2411], [78, 20511, 47, 860, 19, 147, 24, 25, 11, 4, 759, 277], [20512, 8756, 103, 338, 4, 1033, 460, 11, 20513, 53, 241, 7405, 3, 293, 37, 1915, 109, 12, 2, 1], [53, 196, 77, 49, 33, 2293, 283, 53], [678, 360, 1833, 412, 49, 377, 1752, 21], [416, 156, 72, 77, 49, 109, 2822, 988, 60, 177, 49, 19, 3423, 2822, 187, 15, 12, 428, 20514], [3253, 95, 2094, 8841, 292, 93, 821, 292, 89, 821, 8, 292, 727, 89, 821], [20515, 12, 2, 187], [85, 78, 9, 11, 270, 2, 1867, 6, 14, 419, 639], [365, 1, 403, 77, 17], [33, 17, 74, 49, 116, 2, 320, 16, 175, 82, 871, 390, 59, 1575, 264, 522, 21, 4, 1665, 873, 26, 353], [215, 299, 230, 618, 11, 5594, 66, 124, 2, 5572, 8842, 11, 2636, 940, 8, 3, 946, 21, 8843, 485, 3, 1342, 6, 84, 6194], [24, 24, 24, 3, 532, 97, 20516, 133, 2, 1634, 423], [3, 44, 984, 9, 425], [99, 239, 1, 12, 2762], [41, 20517, 9], [25, 46, 45, 34, 9, 27, 138], [159, 255, 4, 29, 4919, 18, 17, 1736, 4261, 155, 384, 198, 229, 35, 11, 8752, 11, 3168, 255, 7], [469, 3, 28, 2, 587, 828, 11, 10, 402, 116, 46, 43, 20518, 69, 3, 195, 3, 75, 869, 10, 388, 234], [1123, 54, 6, 32, 5, 77, 7, 255, 212, 1084, 1501, 645, 34, 41, 2, 24, 7, 392, 16, 2998], [878, 20519, 7, 161, 1, 222, 856, 321], [425, 1307, 8746], [3, 64, 89, 1, 7, 10, 172, 437], [590, 9, 255, 788, 4751, 7, 2194, 35, 8, 227, 202, 13, 931, 16, 2172, 294, 11, 76], [80, 77, 24, 1116, 22, 175, 1729, 116, 12, 43, 249, 184, 73, 2, 1148, 1, 11, 20520], [110, 20521, 159, 925, 1322, 420, 20522, 20523], [53, 53, 25, 780, 27, 4, 329, 1, 53, 53], [20524, 20, 3505], [43, 5, 185, 388, 20525, 20526, 277, 48, 196, 5, 63, 28, 7307, 6, 20, 759, 4684, 20527, 20528], [180, 517, 1, 20529, 53, 30, 8844], [3, 168, 4, 324, 187, 727, 1394], [1254, 114, 129, 174, 1, 1209, 27, 10, 8029, 8, 20530], [18, 4, 1398, 2679, 116, 207, 343, 3648, 22, 456, 14, 4, 2466, 1835, 1269], [538, 4, 91, 27, 4043, 8, 2, 1190, 16, 1, 6, 253, 254], [958, 20, 150, 34, 31, 20531, 60, 9, 45, 176, 15, 6, 2915], [1025, 35, 20532, 23, 133, 6, 70, 22, 115, 10, 1], [10, 1745, 685, 871, 1090, 12, 11, 966, 7219, 129, 4, 20533, 16, 95, 2094, 26, 1815, 544, 1072, 11, 4, 2190, 11, 188], [19, 5, 35, 19, 2937, 30, 187], [20534, 314, 261, 12, 4, 247, 144, 314, 261, 1269], [22, 1, 122, 6, 134, 10, 138, 2, 4639], [195, 3, 329, 996, 3345, 51, 384, 153, 18, 841, 3576, 69, 14, 3246, 163, 4, 7468, 20535, 20536, 30, 163], [3, 200, 168, 6, 303, 201, 3401, 163, 255, 398, 384, 1, 51, 4, 199, 20537, 30, 55], [23, 2298, 20538, 133, 39, 614, 6, 14, 20539, 606, 153, 525, 20540, 163, 765, 30, 251, 315, 20541, 611], [36, 46, 2445, 636, 3, 47, 11, 7, 1], [38, 20, 1040, 129, 217, 88, 623, 5, 41, 9, 233], [602, 27, 4, 453, 19, 8, 433, 17, 4, 19, 8845, 838], [31, 5, 29, 134, 20, 1214, 235, 20, 2, 564, 1, 8, 52, 415, 359, 18, 5, 27, 2, 1, 4, 249, 84, 45, 2813], [39, 9, 46, 334], [101, 2738, 62, 4, 511, 808, 388, 8, 120, 248], [100, 61, 232], [2, 9, 12, 431, 27, 14, 20542, 8, 1874, 18, 4, 702, 37, 7, 111, 29, 79, 50, 57, 40, 1437, 2, 282], [3554, 825, 1215, 1813, 6, 1726, 159, 824, 140, 16, 2, 969, 408], [154, 830, 267, 6, 340, 354], [3169, 43, 690, 71, 239, 106, 265, 19, 17, 129, 3, 103, 105, 671, 3, 285, 3, 1373, 5, 760], [101, 112, 1, 249, 138], [29, 14, 6034, 18, 135, 8, 72, 2211, 10, 228, 8, 416, 3, 62, 136, 2, 20543, 219, 83, 1068], [6, 7, 145, 61, 253], [375, 7, 68, 1, 30, 5, 672, 54, 215, 449], [128, 145, 22, 12, 186, 10, 20544, 1, 75, 14, 1036, 13, 10, 1382, 1], [22, 145, 47, 840, 129, 326], [148, 10, 145, 234, 1, 41, 170, 70, 50, 2, 1799], [351, 10, 145], [3, 191, 57, 4, 857, 16, 2, 8015, 120, 77, 8, 22, 145, 121, 2941], [3, 424, 80, 401, 1], [3637, 3, 440, 10, 1010, 11, 4, 4076, 163, 10, 145, 28, 60, 1054, 142, 116, 2032], [4, 193, 22, 145, 33, 20545, 51, 22, 629, 47], [22, 145, 121, 50, 767, 1015, 30, 286, 128], [6, 7, 187, 69, 121, 40, 266, 574, 69, 168, 2446, 2318, 140, 15, 3044, 20546, 1, 100, 17, 3388, 693], [1290, 20547, 4797, 26, 96, 1571, 7, 9], [148, 162, 5, 18, 331, 1462, 51, 26, 2573, 11, 1118, 1, 13], [32, 78, 1, 1490, 20548], [55, 4, 1887, 14, 37, 112, 18, 325, 1], [219, 3, 33, 41, 20549, 7, 12, 20, 481, 914, 12, 2043, 74, 2037, 15, 314, 8, 5, 2, 9], [1409, 13, 78, 156, 4328, 48, 110, 238, 14, 356, 2310, 1315, 1, 3, 58], [1079, 546, 92, 20, 44, 10, 20550, 1212, 885, 28, 7, 24, 672, 5, 26], [66, 32, 62, 171, 1, 13, 22], [20551, 634, 3, 309, 1, 442, 4325], [150, 4, 7055, 616, 2136, 5467, 224, 17, 8, 194, 4, 207, 338, 616, 13, 6418, 207, 20552, 2265], [75, 227, 2, 9, 173, 2, 7845], [23, 1174, 258, 17, 2, 1039, 409, 48, 2, 9, 4840], [3, 67, 4741, 851, 384, 1, 58, 372, 93, 1315], [53, 48, 3539, 43, 9, 53], [5, 63, 857, 113, 69, 2, 835, 123, 57, 1, 255, 38, 15, 4666, 1097, 3829], [31, 3, 47, 6, 109, 14, 344, 3907, 1, 103, 90, 17, 91], [20, 2, 141, 1, 8, 23, 344, 35, 6701], [5, 9, 49, 3479], [2, 953, 1, 165, 404, 4, 3437], [797, 1245, 20553, 12, 258, 54, 2, 342, 189, 136, 319, 3, 1870, 468, 20554, 3, 29, 4546], [2170, 1356, 18, 275, 49, 56, 26], [55, 571, 192, 402, 54, 6021, 26, 3969, 149, 5, 1, 131, 14, 17, 37, 89], [151, 19, 2, 1, 112, 705], [60, 16, 78, 9, 63, 1049, 20555, 18, 5015, 44, 2, 5491, 4735, 27, 2, 1141, 3748, 44, 20, 1574, 328, 34, 29, 20556], [378, 93, 77, 12, 783, 2472, 1, 26, 111, 96, 1332, 6, 623, 7], [7419], [3, 100, 39, 1, 2481, 7, 33, 351, 2040, 26], [4, 606, 46, 61, 43, 6542, 39, 9, 21, 3109, 38, 5, 41, 217, 112, 5, 555, 18, 6, 980], [463, 29, 67, 6, 137, 4443, 20, 2, 368, 1600, 3, 266, 137, 19, 2025, 16, 2112, 7, 178, 12, 45, 3], [15, 356, 38, 659, 72, 2080, 33, 214, 149, 23, 1843, 5956, 15, 13, 43, 1, 218, 42, 428, 59, 6661, 591, 2499], [42, 2, 546, 18, 4, 20557, 1844, 485, 149, 5, 339, 9], [183, 1, 700, 37, 20558, 40, 541, 51, 4, 138, 8, 466, 35, 637, 51, 4, 199, 106, 288, 2482, 51, 4, 199, 106], [69, 6, 924, 21, 4, 232, 20559, 22, 213, 4, 20560, 2081, 4, 1206, 20561, 133, 4, 781], [38, 5, 623, 5, 41, 43, 9], [53, 366, 125, 2, 1, 11, 1966, 8, 100, 50, 137, 451, 3, 394, 947, 40, 227, 18, 1971, 74, 60, 981, 45, 53, 112, 45], [8, 976, 11, 64, 27, 24, 52, 105, 110, 20562], [3, 14, 13, 8616, 19, 135, 107, 4, 8617, 4775, 14, 431, 386, 8618, 91, 19, 4775, 1, 30], [3, 1, 59, 4658, 184, 55], [642, 2, 83], [85, 12, 2696, 341, 73, 286, 8, 88, 599, 473, 691, 790, 15, 172, 3560, 4937, 35, 11, 22, 1], [3, 47, 235, 250, 155, 106, 21, 350, 26, 34, 92, 23, 24], [1481, 32, 5, 319, 430, 2, 6100], [148, 1059, 3121, 1115, 19, 27, 339, 1], [124, 2, 1562, 18, 2, 1, 27, 2, 91, 3, 122, 6, 229, 50, 7, 3, 222, 557, 50, 165, 34, 3, 105, 124, 43, 1640], [138, 103, 44, 1, 506, 126, 373, 639, 20563, 20564, 138, 51, 760, 138, 7, 36, 62, 427, 20565], [78, 5643, 1, 146, 497, 86, 78, 1904], [369, 52, 20566, 18, 22, 1, 2374, 151, 311, 84, 45], [39, 9, 46, 334], [3, 1415, 7, 1, 2, 3826, 231, 1, 64, 3826, 231], [31, 42, 46, 105, 124, 2, 8273, 626, 20, 24, 56, 462], [19, 470, 4, 1, 51, 8301, 20567, 3, 101, 19, 125, 2, 607], [31, 5, 62, 52, 136, 2, 504, 29, 14, 7, 141, 1, 538, 15, 8, 420, 962], [463, 157, 10, 518, 18, 20568, 71, 63, 3, 139, 22, 20569, 76, 7876, 151, 70, 32, 76, 9, 20570], [31, 516, 6106, 2, 1, 147, 6106, 20571, 913, 6106, 147, 1, 69, 122, 6, 5699, 163, 14, 2, 587, 835, 163, 143, 2646, 3, 5616, 2445, 65, 51], [9, 175, 14, 13, 157, 7, 138, 11, 10, 977, 3, 266, 955, 88, 38, 5, 191, 76, 59, 15, 36, 72, 15, 2, 323, 9, 3375], [140, 374, 32, 19, 268, 213, 206, 208, 13, 3, 266, 453, 14, 1318, 1, 3, 103, 4939, 5], [351, 1466], [29, 67, 2, 93, 77, 9, 12, 84, 2154], [40, 2, 9, 20572, 20573, 1460, 17], [31, 2, 1, 72, 20574, 40, 2, 9], [1518, 2069, 4730, 26, 2453, 20575, 32, 41, 612, 163, 220, 13, 2231, 28, 4, 247, 144, 19, 343, 311, 4811], [3400, 80, 1, 13], [574, 82, 4, 2743, 61, 171, 332, 38, 36, 3056, 36, 14, 13, 463, 45, 2607, 3, 14, 13, 1301, 187, 75, 45], [19, 5, 252, 81, 45, 6, 10, 228, 3, 103, 257, 20, 30, 1], [336, 39, 1, 35, 4828, 620, 26], [1910, 2, 1, 26, 216, 3500, 70, 4, 1289, 8396, 3572], [1910, 2, 1, 26, 227, 18, 10, 2106, 27, 50, 530, 20576], [69, 100, 1910, 28, 551, 102, 16, 50, 30, 134, 7, 1, 20577, 64, 7951], [19, 2, 1, 8, 86, 16, 17], [33, 2, 666, 16, 388, 4532, 21, 1058, 344, 115], [1478, 2, 20578, 109, 70, 17, 3061, 98, 684, 587, 1178, 16, 24, 195, 3, 117, 252], [20, 2, 19, 494], [1320, 56, 20579], [162, 49, 32, 4, 20580, 18, 85, 265, 79, 943, 5448, 8, 20581, 39, 115], [5, 87, 6, 51, 577, 48, 14, 2, 1, 20582, 6, 438, 17], [3, 3469, 671, 4, 796, 1, 38, 23, 3955, 13, 3, 33, 87, 6, 14, 1041, 279, 16, 128], [116, 43, 270, 184, 73, 99, 209, 24, 26], [32, 3, 182, 191, 21, 47, 3971, 3971, 26, 24, 34, 2448, 20583], [5, 75, 938, 3476, 20584, 52, 2, 2730, 52, 273, 263, 48, 6, 64, 39, 319], [392, 144, 20585, 924, 981, 5383, 1881, 18, 1444, 8422], [82, 2, 20586, 20587, 20588, 12, 33, 2, 382, 21, 4, 20589, 16, 4, 20590, 2879], [31, 20, 152, 56, 81, 10, 1663, 29, 72, 15, 11, 580, 16, 10, 237, 228], [6614, 20591, 274, 3, 90, 782, 20592, 802, 30, 4310, 30, 20593, 30, 24, 30, 1], [8, 433, 7, 1], [31, 68, 16, 20, 253, 506, 24, 34, 907, 18, 186, 13, 36, 41, 32, 4, 2366, 8, 521], [31, 5, 19, 2, 1, 7, 19, 155, 25, 11, 20, 654], [6, 2238, 22, 1, 30, 25, 3967], [57, 41, 17, 173, 1519, 219, 101, 2, 535, 127, 115, 634, 32, 39, 2112, 103, 14, 2690, 26], [5889, 4539, 859, 32, 2622, 11, 22, 496, 3973, 123, 377, 82, 26], [53, 5, 24, 792, 21, 101, 253, 3862, 53], [53, 3, 454, 71, 209, 24, 1748, 3032, 20594], [11, 20, 373, 45, 92, 24, 57, 2, 675, 1502, 450, 35, 33, 13, 32, 4, 763, 43, 229, 813, 45, 639, 1534], [31, 5, 1279, 72, 65, 2226, 1829, 269, 69, 1642, 11, 98, 1644, 20595, 7201], [267, 5, 8846, 1627, 105, 14, 4, 4787, 26], [20596, 1, 1995, 642, 20597, 198, 946, 21, 1033, 527], [3065, 620, 1], [878, 657, 112, 153, 43, 20598], [2221, 372, 93, 3617, 34, 432, 44, 43, 9, 37, 66, 75, 114, 7, 498], [5974, 133, 6, 1764, 18, 39, 9], [2423, 99, 53, 1583, 73, 2, 413, 12, 56, 1488, 3638, 12, 248, 137, 2301, 8, 8527, 5976], [920, 135, 82, 10, 331, 5069, 23, 716, 726, 55], [4922, 363, 392, 144, 60, 106, 892, 427, 20599, 4, 20600, 52, 33, 726, 26], [742, 1, 700, 626, 16, 8192, 581, 55], [999, 2, 236, 2724, 55], [590, 55, 30, 55, 1], [8847, 30, 282], [8847, 30, 6, 24, 1781, 27, 8848, 1761, 35, 50, 1556, 20601], [20602, 2178, 125, 7565, 579, 2, 417, 2178, 949, 20603], [1410, 1173, 1], [1410, 1173, 12, 2, 1, 26, 84, 436, 12, 185, 21, 271, 123, 84, 8170], [1410, 1173, 124, 7, 1, 16, 4, 20604, 8, 4, 2110, 32, 11, 68, 929], [2410, 8792, 20605, 10, 3979, 136, 4698, 2079, 2, 643, 1376, 6822, 3, 29, 62, 71, 7, 643, 34, 15, 716, 20606], [20607, 301, 3, 124, 127, 1778, 21, 4613, 55], [509, 4, 4788, 1719, 4009, 1548, 114, 17, 108, 201, 20608, 105, 627, 717, 294, 118, 72, 29, 298, 1036, 18, 76, 20609, 1885], [542, 6, 1846, 54, 325, 1], [542, 6, 61, 28, 10, 860, 354], [112, 25, 8, 89, 1, 44, 201, 184, 11, 6881, 20, 398, 609, 73, 19, 26, 1776, 16, 5, 62, 7, 20, 1065, 8, 20610], [112, 1641, 781, 28, 4728, 38, 36, 313, 256, 11, 4, 56, 63, 8, 346], [112, 1, 69, 109, 807, 266, 14, 54, 135, 687, 27, 1, 18, 186, 344, 4576], [112, 64, 332, 6, 258, 38, 39, 1, 122, 6, 365, 15, 27, 17], [112, 153, 1342, 1156, 153, 20611], [112, 25, 87, 2, 112, 83, 33, 495, 3, 63, 497, 2047], [112, 25, 100, 112, 1, 107], [112, 25, 100, 112, 1, 1266, 250], [112, 25, 569, 1, 42, 165, 20612], [112, 25, 557, 17, 27, 538, 8, 20, 2, 24, 916], [112, 312, 8849, 27, 17, 8, 3, 29, 134, 2, 8849, 69, 29], [112, 385, 92, 31, 4, 1, 67, 60, 4953, 74, 256, 7, 5835], [112, 45, 3, 64, 119, 285], [112, 81, 3, 109, 46, 3850, 302, 2, 1, 371, 610, 8, 186, 3086, 3357], [112, 81, 48, 14, 680, 74, 777, 4, 413, 4887, 1658, 721, 558, 56, 22, 213, 553, 16, 4, 412, 44, 2, 1180, 70, 15, 6, 4, 1408], [109, 20613, 20614, 74, 3490, 4462, 3233, 12, 2, 1353, 229, 21, 8, 4, 4706, 107, 18, 58, 5, 67, 93, 877], [109, 46, 2357, 6, 311, 7, 1, 102], [109, 1], [109, 1, 988], [109, 3061, 10, 7495, 2632, 1635, 693, 20615, 117, 92], [109, 4174, 6, 100, 54, 4, 388, 234, 16, 10, 467, 2, 320, 16, 828, 8, 751, 60, 823, 20616], [109, 131, 61, 2295, 20617, 4, 1254, 3044, 16, 20618, 48, 3767, 48, 3567, 2513, 4, 1, 1511], [3704, 292, 755, 6, 258, 1010, 197, 12, 726, 20619, 2628, 1605, 20620], [20621, 20622, 8694, 377, 1050, 527], [6107, 310, 756, 54, 4, 1198, 556, 311, 22, 1, 102], [6107, 626, 3958, 1], [3642, 3, 96, 375, 7, 106, 5868, 440, 17, 2, 4375, 768, 20623, 52, 47, 7850, 79, 17, 2, 236, 8, 2049, 55], [355, 1111, 408, 1, 4, 8668, 59, 117, 20624, 126, 6591, 7684, 82, 167, 76, 54, 99], [355, 1, 27, 17, 991, 682, 228, 1275, 533, 133, 107, 8, 28, 17], [2286, 679, 79, 15, 38, 15, 98, 1291, 466, 34, 212, 9, 210, 914, 4, 402, 466, 11, 4, 3418, 1537, 888], [1321, 852, 2351, 794, 1602, 7, 263, 388, 6024, 20625], [20626, 20627, 11, 968, 665, 3181, 27, 50, 1031, 24, 20628], [375, 7, 1293, 12, 116, 6, 6021, 5, 48, 1224, 350], [375, 38, 3, 121, 5552, 49, 104, 22, 449, 5553, 20629, 7, 27, 635, 7576], [375, 38, 3, 273, 78, 133, 10, 4780, 48, 541, 54, 2, 535, 449, 4607, 648, 2, 9, 41, 84, 809], [375, 38, 3, 118, 3143, 416, 11, 4709, 1317, 140, 3, 58], [375, 38, 202, 77, 54, 518, 11, 580, 16, 385, 584, 1079, 6214, 463, 1212, 185, 917], [20630, 18, 10, 20631, 115, 38, 3, 3087, 2, 5669, 8, 10, 1, 1201, 2, 714, 1835], [3383, 211, 17, 162, 10, 1], [1108, 652, 4, 101, 529, 11, 4469, 66, 44, 529, 1033, 776, 34, 29, 137, 4, 20632, 664, 20633], [3820, 3387, 20634, 20635, 65, 858, 51, 4, 1760, 8733, 21, 978, 3329, 20636], [800, 6, 2238, 22, 104, 138, 61], [20637, 159, 2244, 57, 4136, 397, 21, 49, 3381, 148, 184, 13, 20638, 20639], [2202, 4, 1316, 49, 107, 2, 2388, 2142, 16, 4, 2942, 654, 11, 360, 1317, 3, 527], [20640, 4726, 27, 15, 1239, 2318, 3343, 8720, 575, 2285, 20641, 2415, 34, 295, 12, 644, 11, 1771, 51, 1284], [825, 12, 48, 2, 83], [4439, 12, 270, 2, 1, 38, 15, 107, 6, 77], [498, 11, 7, 5203, 1, 15, 530], [498, 10, 4783, 27, 22, 1], [498, 125, 10, 206, 252, 233, 325, 153, 20642], [1350, 33, 1300, 245, 1], [1350, 456, 41, 4, 1084, 20643, 16, 24], [1350, 443, 184, 59, 120, 331, 1550, 10, 970, 14, 202, 3873, 20644, 20645], [20646, 4502, 28, 22, 1, 54, 10, 706], [3463, 35, 152, 28, 2714, 8, 2714, 15, 32, 1443, 8, 628, 2855, 3, 46, 119], [694, 7, 441, 1, 1448, 7, 30, 9], [694, 5548, 1], [5562, 4498, 11, 4, 263, 49, 248, 36, 134, 4498, 11, 7470, 2, 89, 2439], [5562, 18, 3794, 8073, 12, 2, 285], [3661, 20647, 2, 19, 1298, 20648, 373, 84, 809], [3661, 20649, 12, 2, 24], [20650, 118, 28, 1176, 1168, 52, 2, 1], [1085, 207, 1178, 101, 5, 3095], [20651, 109, 1699, 17, 897, 4, 229, 8, 4, 2013, 18, 7, 1895, 15, 106, 6, 901, 60, 20652], [1085, 14, 355, 20653, 14, 1104, 29, 113, 80, 803, 5, 172, 2, 158], [2363, 2, 1, 21, 48, 2182], [2363, 41, 2007, 1085, 927, 39, 9, 46, 334, 1336], [2363, 262, 17, 108, 5, 816], [20654, 20655, 379, 77, 6302, 18, 20656, 16, 1086, 1675, 11, 3002, 20657, 4132, 20658, 1190], [657, 18, 5, 9], [3363, 21, 4, 9, 2194, 21, 4, 77, 6070, 21, 4, 2937, 839, 311, 21, 4, 659, 4783, 21, 4, 1383, 43, 6071, 43, 352], [5980, 20659, 37, 248, 15, 20660], [945, 139, 14, 2, 9, 4809, 3, 67, 292, 177], [945, 38, 3, 94, 5, 294, 35, 3, 86, 9], [945, 21, 2, 20661, 20662, 572, 1, 99], [20663, 12, 48, 183, 20664], [8349, 313, 20665, 1196, 159, 20666, 20667, 824, 1438, 8717, 2483, 1086, 11, 1382, 381, 20668], [1585, 518, 68, 105, 20669, 2, 1, 82, 143, 1926, 234], [1585, 518, 268, 29, 302, 357, 1047, 2, 1, 27, 2, 2956, 481], [20670, 2, 1, 20671], [298, 11, 97, 1251, 1131, 97, 9, 19, 18, 97, 2022], [298, 15, 11, 50, 24, 13, 2, 1780, 20672], [298, 15, 35, 250, 39, 9, 107, 790], [298, 54, 27, 4, 6192, 1, 20673], [298, 7, 25, 5, 29, 67, 7, 25, 34, 3, 87, 2, 89, 1, 7, 2394, 130, 17], [2685, 37, 209, 178, 3, 19, 224, 26, 3231, 2, 812], [298, 2744, 702, 18, 2390, 39, 1, 165, 215, 17, 634, 1147, 74, 3471], [2567, 1920, 124, 2, 2257, 658, 34, 12, 20674, 44, 2, 93, 8663], [3053, 20675, 7, 9], [8850, 9, 6, 3909, 201, 17], [1017, 21, 176, 17, 7548, 38, 23, 2, 187], [1017, 6, 32, 4, 9, 304, 35, 21, 7, 1929, 7150, 1, 333, 7, 25, 29, 64, 5], [1017, 4, 379, 1, 26, 275], [1017, 6, 2325, 219, 20676, 1520, 740, 78, 49, 137, 20677, 543, 126, 7161, 23, 322, 362, 22, 181, 12, 137], [1017, 6, 10, 20678, 39, 49, 142, 1, 29, 19, 27, 980], [1017, 6, 10, 443, 158, 6, 197, 18, 4, 20679, 33, 375, 244, 106, 191, 21, 4, 20680, 29, 719, 254], [1017, 6, 4, 595, 1, 51, 2000, 33, 615, 3988, 17, 51, 4, 2303, 20681], [1017, 6, 22, 9, 390, 802, 90, 30], [1017, 7, 112, 1], [1017, 6, 147, 1, 30, 25, 11, 3372, 69, 131, 204, 17], [1017, 6, 10, 4679, 2934, 68, 16, 4, 607, 16, 4, 112, 77, 18, 2852], [1017, 6, 10, 306, 510, 337, 6, 1672, 8, 348], [1017, 6, 10, 206, 20682, 6, 10, 154, 9], [1017, 6, 4, 774, 145, 271, 70, 859, 522, 38, 66, 314, 483], [94, 3, 273, 78, 4004, 47, 555, 50, 30, 35, 7, 1, 46, 41, 43, 2630, 481, 8851], [471, 78, 1, 30, 1127, 27, 263, 66, 46, 257, 1914, 4093, 32, 658, 3, 29, 131, 137, 76, 399], [45, 3, 67, 2, 1, 37, 89, 7, 278, 119, 50, 11, 580, 16, 50, 265], [8457, 333, 61, 262, 20, 953, 1, 140, 23, 48, 556, 799, 6985, 1133, 30], [251, 485, 36, 29, 131, 14, 428, 8740, 1379, 5, 44, 631, 24, 5, 982, 44, 2, 1015, 5812], [20683, 382, 1119, 642, 20684, 11, 1206, 4626, 160, 341, 1211], [495, 333, 316, 54, 16, 10, 3716, 712, 8, 2010, 17, 21, 256, 20685, 3, 197, 332, 21, 495, 313, 17, 11, 4, 248], [1709, 189, 212, 175, 49, 3282, 14, 1834, 8, 31, 4, 1, 296, 6, 185, 57, 40, 20686, 88, 40, 48, 185, 15, 7, 40, 317, 67, 42], [411, 20687, 20688, 149, 52, 2, 104, 70, 1237, 92, 117, 20689, 700, 112, 20690, 55], [139, 262, 39, 9, 93, 561], [1008, 1, 23, 686, 26], [611, 7, 77, 65, 35, 6, 960, 37, 1572, 13, 148, 40, 41, 1303, 82, 14, 2, 9, 8, 70, 352, 20691, 66, 87, 6, 258, 165, 2773, 20692], [20693, 1, 66, 20694], [121, 5, 2, 196, 1], [8848, 645, 1624, 2044, 73, 40, 114, 2, 180, 968, 839, 11, 20695], [5826, 353, 21, 1283, 649, 611, 20696], [2002, 1218, 18, 10, 2170, 13, 2, 530, 83], [2002, 2, 112, 153], [1620, 12, 402, 142, 2004, 43, 1592, 11, 2, 937, 213, 10, 577, 443, 2220, 270, 2, 141, 1], [1620, 12, 270, 2, 1, 3661, 41, 11, 2, 290, 140, 16, 5], [199, 1, 36, 14, 32, 11, 10, 231, 133, 71, 36, 487, 58, 15, 14, 4, 199, 1, 32, 18, 84, 138], [199, 9, 121, 3, 487, 28, 15, 238, 543, 254], [199, 9, 27, 36, 30, 54, 390, 152, 14, 751, 20697, 64, 986, 11, 4, 561], [199, 153, 238, 14, 224, 17, 233, 4, 199, 153, 7, 168, 6, 142, 17], [199, 111, 2450, 59, 20698, 8, 45, 11, 1210, 49, 914, 142, 4, 115, 444, 15, 107, 54, 20699, 2191], [199, 540, 42, 65, 13, 3490, 2301, 27, 76, 20700, 85, 4, 19, 58, 158, 208, 37, 511, 38, 77, 49, 20701], [199, 45, 34, 20, 3579, 205, 188, 53, 31, 10, 500, 131, 61, 19, 10, 3996, 600, 274, 14, 27, 876, 46, 10, 9, 43, 20702], [4787, 7, 47, 108, 38, 3, 592, 531, 477, 6, 214, 20703, 1443, 20704, 1527, 1, 11, 3281], [20705, 5960, 20706, 20707, 236, 20708], [1828, 63, 19, 117, 102, 20709, 187], [486, 473, 479, 35, 2, 5187, 102, 4, 1352, 27, 50, 8166, 1302, 10, 20710, 20711, 3700, 12, 870, 27, 7, 1155], [486, 2, 1454, 16, 1362, 79, 2507, 3202, 463, 2, 1, 30, 1590], [486, 348, 18, 4, 2635, 5667, 1102, 173, 68, 8, 3469, 2, 20712, 16, 1964, 8, 3550, 167, 10, 20713, 6020, 20714, 5090, 5, 8675], [486, 10, 381, 20715, 22, 275, 381, 4, 166, 921, 92, 4, 275, 12, 304, 619, 10, 676, 21, 2, 705, 1553, 562, 10, 381, 28, 1], [486, 22, 89, 1, 225], [486, 22, 141, 1554, 236, 27, 57, 65, 13, 3787, 381, 7809, 20716, 45, 20717, 37, 2026, 3, 486, 50, 3, 121, 2236, 20718, 128], [486, 1058, 1262, 435, 18, 2, 20719, 26, 7, 1, 47, 1240, 420, 128, 57, 4, 286], [72, 23, 329, 34, 3, 63, 557, 7, 24, 117], [72, 15, 361, 3201, 5, 1, 1911, 49, 25, 7, 459, 78, 2025], [72, 15, 6, 17, 38, 3, 3013, 5, 24, 19], [72, 15, 32, 59, 4, 9, 38, 15, 32, 59, 8809, 110, 38, 23, 27, 10, 9, 3, 113, 240, 32, 59, 5], [72, 10, 4622, 226, 9], [72, 10, 19, 226, 9], [72, 57, 97, 67, 34, 31, 23, 419, 8, 3, 44, 4, 2746, 6, 44, 2, 138, 11, 10, 30, 8, 24, 51, 4, 199, 106, 272, 114, 254], [72, 57, 5, 67, 59, 34, 7, 1, 136, 1952], [72, 5, 64, 7, 1, 37, 209, 151, 204, 80, 30, 11, 580, 16, 50], [72, 5, 64, 7, 1, 37, 209, 151, 204, 5, 117, 11, 580, 16, 50], [20720, 20721, 28, 50, 24, 19, 8, 735, 123, 268, 20722], [3663, 2, 664, 618, 20723, 20724, 8, 3408, 527, 2, 456, 94, 21, 7087, 1246, 16, 20725], [939, 1, 18, 186, 105, 410, 4, 25, 4, 44, 2, 1562, 18, 156, 18, 60, 20726, 45], [261, 20727, 20728, 8807, 3830, 725, 1961, 20729, 271, 271, 1188, 271, 236, 271, 20730, 271, 337], [261, 179, 73, 19], [261, 249, 127, 138, 130, 4, 9, 69, 2377, 254], [3142, 44, 1815, 2048, 7, 1, 58, 11, 488, 3744, 20731], [1215, 5311, 258, 154, 193, 6, 788, 17, 4, 95, 922, 1537, 3, 62, 15, 4, 117, 420, 34], [1215, 273, 17, 51, 197, 225, 52, 67, 6, 107, 129, 6, 28, 17, 551, 8, 88, 20732, 10, 5614, 151, 204, 5, 1], [3628, 41, 4, 9, 233, 15, 292, 16, 240, 18, 1706, 3, 454, 71, 239, 11, 4, 5856], [3628, 306, 298, 32, 84, 1, 423], [801, 13, 2, 161, 1], [801, 169, 129, 9, 25, 5, 46, 19, 45], [3081, 20733, 65, 13, 2, 1126, 391], [1785, 4, 1067, 20734, 8, 20735, 8, 28, 2, 666, 16, 111, 20736, 4, 199, 402, 16, 675, 288, 44, 43, 1179, 85, 5291, 1332], [8131, 532, 13, 1116, 30, 24, 321], [3788, 8814, 1575, 22, 1608, 2, 2154, 808, 2, 666, 16, 287, 20737, 8, 20738, 8852], [20739, 12, 314, 18, 534, 628, 1315], [710, 106, 39, 20740, 1, 41, 18, 10, 1203, 22, 2428], [5719, 137, 13, 319], [710, 82, 4, 450, 57, 15, 152, 14, 349, 4, 3229, 1], [710, 82, 4, 450, 57, 15, 152, 14, 349, 4, 3229, 83], [94, 272, 139, 28, 18, 22, 135, 186, 687, 27, 5, 20741, 12, 2, 20742, 7, 3, 29, 48, 19, 27], [94, 1, 1606, 1201, 1362, 29, 137, 43, 148, 8280, 519, 5, 47, 65, 6, 14, 844, 21, 185, 74, 97, 734, 2, 282, 74, 6094], [94, 17, 498, 54, 16, 7, 7305, 18, 20, 207, 886, 1464], [94, 10, 312, 225, 495, 69, 594, 4, 451, 13, 17], [94, 25, 36, 14, 214, 8, 32, 39, 9, 61], [94, 4, 4896, 7, 162, 4, 1280, 12], [94, 268, 16, 84, 1, 11, 4, 20743, 57, 52, 58, 21, 2, 259, 26], [94, 38, 5, 1135, 76, 1, 389, 701, 34, 38, 5, 291, 5, 105, 844, 37, 19, 240, 8, 176, 15, 8491, 3144], [94, 85, 39, 24, 87, 126, 743], [94, 5, 181, 11, 885, 755], [94, 5, 18, 4, 234, 20744], [20745, 15, 2, 595, 20746, 204, 317, 396, 4, 2831, 16, 126, 20747, 678, 12, 111, 715, 715], [6211, 52, 330, 62, 52, 2, 104, 128], [94, 246, 1519, 412, 33, 70, 17, 131, 1177, 10, 840, 117, 615], [94, 8633, 494, 535, 791, 109, 12, 20748, 36, 28, 6, 259, 126, 679, 213, 27, 1805, 8, 27, 20749], [94, 37, 239, 339, 1, 1315], [94, 183, 1, 28, 554, 100, 17, 62, 7, 25, 20750, 19, 393, 27, 2, 285, 2116, 12, 43, 1363, 4, 4982, 5, 47, 1160], [598, 13, 143, 207, 617, 14, 525, 11, 143, 193, 5938, 3, 33, 854], [297, 3057, 119, 2, 816, 18, 1706, 194, 7, 385, 8, 28, 3148, 11, 4, 848, 16, 2, 5062, 20751, 31, 3, 46, 20752], [297, 15, 32, 230, 1, 41, 2, 91, 34, 40, 3869, 18, 4, 702], [297, 153, 107, 35, 188, 3, 297, 153, 616], [506, 500, 7253, 348, 11, 580, 16, 20753, 6, 554, 2282], [3048, 12, 98, 2705, 260, 61, 108, 82, 162, 5, 20754], [471, 17, 98, 20755, 8, 151, 175, 85, 20, 2, 24], [471, 7, 1, 2, 3826, 1511, 1, 64, 3826, 231, 513], [20756, 4, 1827, 6, 3438, 3439, 6, 10, 206, 9], [1526, 2930, 1], [1415, 1179, 11, 6, 20757, 36, 101, 598, 6, 131, 555, 20758, 11, 417, 1032, 66, 87, 6, 298, 382, 4412, 11, 89, 1032, 264], [686, 938, 1184, 71, 239, 823, 323, 844, 2109, 20759], [686, 938, 57, 58, 120, 177, 349, 35, 18, 1, 3909], [944, 31, 20, 259, 51, 217, 507, 21, 351, 4, 577, 5, 222, 58, 12, 547, 176, 15, 656], [944, 509, 20760, 13, 1177, 1594, 17, 127, 130, 247, 4528, 5843], [944, 144, 12, 2, 109, 356, 2392], [5559, 27, 10, 20761, 72, 15, 13, 2, 120, 265, 367, 10, 3250, 12, 1741, 130, 20, 42, 49, 2, 835, 37, 333, 204, 80, 653, 902, 1, 30], [7814, 2, 1, 34, 12, 2, 112, 20762, 2186, 7549], [4770, 3632, 25, 268, 6028, 282], [6574, 12, 560, 2, 3667, 6, 14, 98, 377, 77, 160, 176, 4, 435, 754, 2336], [352, 198, 14, 2, 7695, 11, 2, 3924, 25, 136, 105, 328, 393, 21, 5, 8514, 478, 5, 96, 134, 170, 4, 20763], [352, 27, 1703, 3, 67, 2767, 3, 67, 8222, 10, 77, 134, 17, 93, 24, 32, 4, 817], [643, 1688, 659, 714, 8, 2105, 50, 24, 18, 4, 795, 3565, 50, 1402, 20764], [643, 30, 190, 1006], [643, 1, 564, 399], [20765, 96, 11, 1, 706], [8853, 31, 888, 1995, 47, 1880, 16, 2719, 186, 2213, 14, 68, 16, 76, 9, 72, 40, 8424, 251], [1691, 16, 3399, 20766, 722, 1052, 4392], [7413, 238, 290, 1, 11, 143, 4604, 163, 242, 40, 131, 304, 1062, 1158, 1, 549, 6, 122, 6, 1571], [20767, 19, 5, 11, 97, 285, 5, 62, 57, 3, 1456, 8455], [6841, 427, 544, 20, 32, 144, 8093], [1390, 24, 236, 28, 686, 2867, 20768], [1619, 24, 631, 4, 961, 20769, 631], [40, 600, 14, 171, 73, 2, 8784, 34, 110, 4470, 382, 642, 26], [40, 2, 89, 1, 5037, 34, 40, 210, 44, 6, 28, 39, 180, 30, 20770, 810], [40, 2, 95, 21, 7, 188, 45, 47, 974, 88, 920, 619, 163, 440, 50, 91, 6, 28, 900, 18], [40, 2, 537, 1, 8, 3, 20771, 44, 2, 1592], [40, 2, 391, 31, 68, 234, 16, 50, 235, 12, 1941, 54], [40, 2, 9, 149, 20, 520, 67, 50, 40, 939, 149, 40, 29, 81, 45, 13, 78, 40, 183, 149, 5, 29, 13, 50, 632, 35], [40, 2, 573, 900, 1, 3, 538, 50], [40, 896, 20772, 224, 42, 218, 40, 168, 6, 76, 184, 42, 75, 20773, 172, 125, 20774, 20775, 46, 45, 14, 4, 250, 6, 114, 2, 1956, 1], [40, 896, 13, 2, 9, 3, 29, 67, 50, 278, 516, 33, 366, 10, 3094], [40, 14, 18, 60, 112, 45, 163, 271, 18, 60, 497, 45, 233, 1782, 32, 10, 153, 4, 101, 68, 3, 63, 497, 125], [40, 14, 86, 40, 313, 7, 24, 108, 37, 93, 8, 32, 40, 58, 12, 313, 97, 879, 4642, 102], [40, 132, 2, 9, 32, 850, 34, 738, 73, 4, 616, 1032, 167, 1358, 415, 627, 59, 32, 7, 8, 14, 2, 93, 77, 1404, 7, 4, 4753], [40, 394, 48, 157, 17, 18, 50, 2046, 3, 41, 1, 18, 4, 2046], [40, 1, 8854, 86, 40, 373, 154, 1648, 20776], [40, 1276, 7, 1], [40, 279, 1000, 1512, 876, 55, 2, 1977, 1, 12, 2, 1045, 1664], [40, 107, 6, 1550, 8, 4, 24, 99, 93, 40, 146, 420, 6, 4, 620, 5908, 292, 707, 211, 78, 250, 19, 74, 15, 46, 276, 1869], [40, 29, 28, 1217, 444, 211, 3, 558, 1217, 49, 24, 45], [40, 29, 131, 19, 17, 40, 131, 19, 10, 20777, 113, 50, 13, 379, 7147, 19, 147, 1], [40, 110, 124, 2, 9, 2439], [40, 1596, 2, 379, 145], [40, 19, 27, 17, 149, 3, 46, 43, 1, 26], [40, 172, 125, 2, 379, 145], [40, 28, 2, 666, 16, 169, 1049, 15, 32, 18, 692, 8855, 27, 50, 1, 105, 616, 11, 64], [40, 134, 423, 7, 24, 13, 1394, 396], [40, 276, 65, 129, 39, 1, 13, 1067, 8, 20778], [40, 152, 429, 7, 24, 21, 2, 112, 5274], [40, 41, 1462, 21, 8856, 4744, 641, 170, 1035, 1, 2129], [40, 41, 30, 22, 1, 41, 1443, 22, 1, 41, 20779, 22, 1, 135, 595, 22, 1, 135, 89, 40, 32, 4, 193, 4260], [40, 41, 155, 145, 541, 13, 1301], [40, 41, 17, 13, 19, 7, 1], [40, 136, 1172, 926, 11, 50, 114, 337, 558, 17, 8, 10, 306, 49, 33], [40, 11, 4, 1483, 40, 466, 1, 303, 256, 21, 17], [40, 12, 48, 2, 20780, 40, 2, 236], [40, 33, 131, 298, 224, 4, 620, 8, 70, 2530, 7, 40, 63, 1240, 375, 8, 278, 1166, 50, 81, 59, 24, 20781], [40, 33, 67, 50, 24, 672, 40, 46, 276, 262, 42, 108, 5859, 69, 67, 6, 662, 54], [40, 1874, 3410, 11, 10, 1340, 20782, 5, 49, 37, 148, 20783, 121, 757, 20784, 12, 129, 4066], [40, 62, 10, 500, 1, 40, 86, 40, 41, 244, 40, 948, 2, 1190, 16, 25, 1014, 7, 24, 102, 20785], [40, 62, 7, 23, 7, 145], [40, 13, 757, 5, 62, 3, 41, 244, 6202], [40, 13, 6, 687, 37, 3, 1415, 147, 1, 6, 997, 261], [40, 70, 17, 131, 114, 184, 981, 34, 3, 75, 110, 302, 2, 9], [40, 456, 48, 62, 3, 41, 129, 5942, 253, 3290, 22, 1, 146, 28, 4, 19, 35, 459, 22, 8249, 5971, 797, 40, 8857, 10, 1884], [40, 2999, 7, 20786, 1530, 101, 4, 832, 16, 1], [40, 121, 773, 20787, 20788, 161, 1, 55], [40, 121, 429, 63, 42, 70, 15, 1234, 3, 121, 1, 23, 2, 591, 20789, 3, 316, 143, 2971, 151, 70, 5, 2150], [40, 121, 40, 29, 13, 4, 488, 7, 3, 366, 20790, 219, 370, 20791, 3, 29, 13, 4, 488, 7, 20, 2, 9], [40, 121, 6, 316, 2, 1, 16, 588, 328], [40, 72, 50, 24, 1031, 188, 3, 1863, 94], [40, 72, 40, 63, 58, 7, 199, 184, 73, 473, 1], [40, 72, 40, 67, 2, 25, 13, 17, 34, 7, 1, 214, 149, 40, 75, 14, 10, 1039], [40, 72, 7, 40, 47, 791, 219, 37, 12, 17, 40, 72, 50, 24, 1031, 3, 131, 94], [40, 72, 3, 208, 511, 40, 86, 7, 15, 76, 89, 1, 576, 1059, 15, 33, 5, 8, 4, 299, 16, 5, 14, 10, 20792], [40, 1415, 17, 68, 108, 34, 3, 46, 110, 509, 254, 149, 24, 101, 24, 8, 3, 28, 15, 38, 3, 87, 1770], [40, 958, 50, 1774, 40, 62, 5222, 51, 577, 3, 293, 40, 2019, 128], [40, 372, 13, 2, 95, 1170], [40, 2482, 18, 10, 138, 218, 23, 2, 322, 1], [40, 533, 45, 7, 1, 65, 13, 2, 6068], [40, 4, 540, 23, 705, 6, 1598, 54, 18, 2, 83], [40, 86, 40, 89, 34, 10, 1, 5929], [40, 1014, 7, 24, 11, 2, 2120, 3, 67, 50, 6, 313, 15, 11, 2, 20793, 205], [40, 273, 17, 7, 40, 64, 17, 3, 65, 51, 8, 121, 1, 139], [40, 273, 17, 302, 43, 1, 8, 194, 80, 774], [40, 56, 1000], [40, 122, 6, 28, 5, 6, 1505, 4, 1466, 34, 92, 4, 1, 11, 2991], [40, 753, 17, 211, 3, 121, 3, 345, 194, 3077, 16, 4, 673, 3454], [40, 168, 6, 19, 125, 6360, 99, 20794, 52, 62, 7, 1, 82, 193, 108], [40, 131, 81, 4564, 34, 88, 44, 2, 20795, 233, 19, 5, 1, 8, 3, 293, 42, 1001], [40, 47, 13, 272, 87, 5, 6, 1053, 2, 4320, 1, 1053, 630, 2, 2093, 15, 156, 4, 206, 111, 122, 6, 1431, 1], [40, 454, 85, 23, 173, 50, 38, 32, 39, 9, 14, 173, 17], [40, 4, 1250, 6, 360, 5772, 3881, 12, 270, 2, 24, 8719, 6085], [40, 2, 171, 83, 1419, 33, 121, 988, 1037, 45, 4658, 55, 575, 1487, 26], [40, 46, 14, 2, 1, 40, 33, 515, 16, 20, 3282, 50, 764, 2018, 5, 12, 1095, 2619, 71, 5, 557, 876], [40, 857, 2, 1754, 95], [40, 33, 214, 218, 50, 180, 1109, 65, 13, 98, 1076, 95, 281], [20796, 108, 676, 311, 96, 61, 3566, 2698], [8858, 33, 13, 241, 212, 20797, 20798, 20799, 33, 1575, 39, 268, 206, 120, 20800, 26], [20801, 405, 5, 2, 535, 1037, 831, 18, 7, 282, 28, 50, 2, 20802, 20803, 1049, 169, 6, 70, 169], [1994, 18, 76, 9], [1994, 18, 76, 9, 100, 240, 62, 7, 5, 298, 45], [1994, 18, 76, 9, 100, 240, 62, 5, 298, 45], [20804, 3968, 47, 2, 89, 1, 38, 40, 47, 10, 1247, 73, 2411], [45, 3, 44, 4830, 8, 2065, 1, 8, 284, 500, 1, 211, 307, 10, 164, 12, 454], [45, 12, 19, 144, 43, 68, 67, 6, 94, 22, 45], [45, 12, 56], [45, 7, 8595, 72, 1360, 6080, 130, 10, 20805], [45, 162, 4, 315, 1, 51, 107, 14, 2866, 77, 390], [4219, 18, 32, 10, 206, 9], [512, 147, 25, 163, 84, 20806, 1], [512, 3010, 100, 80, 9, 1941, 17], [512, 54, 125, 80, 153, 5, 143, 409, 6, 313, 143, 3402], [512, 7, 25, 26, 84, 2279, 1], [512, 7, 25, 98, 84, 2279, 1, 26], [512, 5, 8, 20, 2279, 1], [752, 729, 2140, 5541, 20807, 6695, 6840, 103, 642, 168, 268, 969, 95, 6, 2148, 2334, 4948, 11, 4, 1684], [565, 54, 6, 10, 455, 1, 8, 10, 234, 1], [198, 61, 6, 74, 7, 227, 170, 173, 98, 673, 20808, 1082], [198, 3, 14, 475, 7, 2, 462, 747, 10, 1478, 12, 81, 6, 2, 1170], [198, 3, 772, 93, 24, 74, 93, 34, 48, 93, 21, 5, 24, 82, 2, 20809, 8430], [198, 3, 114, 2, 1966, 464, 99, 204, 2, 382, 95, 74, 336], [198, 3, 113, 22, 9, 69, 40, 65, 13, 20810], [1521, 157, 144, 4312, 18, 585, 20811], [982, 14, 20812, 1116, 24, 198, 105, 14, 672], [1123, 54, 6, 1059, 64, 7, 83], [1123, 54, 6, 416, 7, 157, 35, 27, 10, 144, 809, 3, 1512, 254], [1123, 54, 6, 5, 2376, 3423, 2365, 23, 114, 22, 565, 21, 20813, 447, 5], [2204, 6, 2444, 8, 22, 20814, 20815, 18, 10, 193, 6, 20816, 6, 780, 27, 179, 77, 197, 51, 2176, 615], [2204, 7, 112, 1], [2204, 6, 10, 8571, 149, 40, 46, 878, 43, 9], [2204, 6, 22, 1, 21, 753, 17, 13, 3, 210, 1649, 5, 13, 10, 327, 33, 6, 2186, 76], [2204, 6, 10, 455, 1, 26, 10, 234, 7556], [1123, 54, 6, 32, 10, 4391, 1], [1123, 54, 6, 10, 142, 30, 1, 69, 105, 134, 2, 25, 2, 332, 106], [229, 215, 264, 47, 2188, 267, 6, 416, 69, 510, 897, 31, 5, 210, 107, 54, 20, 2, 1633, 650, 5, 220, 51, 968, 20817], [1306, 6770, 7, 9], [5208, 18, 1], [20818, 485, 15, 2, 3664, 1, 184], [242, 4, 19, 35, 8, 559, 14, 270, 2, 24, 4242], [242, 4, 19, 35, 5, 19, 187], [242, 4, 19, 562, 3, 1415, 10, 746, 2, 406, 16, 2, 1951, 348, 8, 40, 47, 13, 296, 7, 2, 20819, 13, 3, 301], [242, 35, 95, 15, 618, 817], [242, 35, 1, 3, 407, 152, 20820], [242, 35, 1, 3761], [242, 35, 1, 5, 257, 102, 6, 20, 6562], [242, 35, 83, 23, 122, 6, 376], [242, 35, 104], [242, 35, 9], [242, 80, 3145, 213, 154, 986, 541, 30, 35, 83], [242, 80, 20821, 541, 30, 35, 20822, 1], [2815, 104, 6, 7451, 424, 76, 2, 288], [933, 77, 3198], [933, 2414, 372, 171, 73, 45, 5, 62, 295, 133, 20823], [933, 3851, 1003, 8, 3988, 5057, 548, 22, 47, 37, 148, 681, 3, 603, 345], [3090, 26, 8859, 292, 4412, 16, 1033, 4377, 11, 292, 449, 160, 871, 2776, 527], [3090, 26, 8859, 292, 4412, 16, 1033, 4377, 11, 292, 449, 160, 871, 2776, 527], [2745, 340, 633, 17, 102, 1035, 3, 2053, 397, 1, 13, 7, 251], [20824, 1296, 755, 46, 43, 1774, 439, 22, 20825, 1853, 8560, 8, 5022, 372, 112, 93, 6, 20826], [549, 16, 465, 3540, 265, 1, 59, 126, 2229, 37, 20827, 20828, 20829, 43, 68, 8316], [549, 16, 20, 490, 20830, 20831, 2794, 715, 591], [234, 1, 49, 339, 154, 575, 20832, 5851, 6, 4, 437, 5, 330, 44, 27, 20, 4590, 2013], [234, 9, 87, 657, 5069, 36, 156, 137, 185, 9, 323, 108, 6, 108], [8173, 603, 41, 906, 27, 4, 1384, 1307], [20833, 16, 5568, 82, 20834, 20835, 408, 26, 3798, 73, 489, 628, 1688, 8860, 6326, 11, 5686, 1141], [3121, 576, 3, 64, 180, 3341, 9, 277], [1482, 1, 45, 105, 376, 8516], [1310, 453, 9], [2431, 4680, 799, 27, 2, 3013, 37, 3, 33, 108, 423, 38, 187, 28, 1210, 530, 2018, 3040, 396, 2, 320, 11, 4, 722, 607, 213, 1249], [20836, 377, 1143, 8079, 292, 4637, 16, 14, 2735, 16, 4, 1422, 527], [371, 2, 320, 16, 5, 161, 1, 67, 6, 1299, 4, 20837, 2039, 173, 32, 10, 175, 151, 58, 7, 45, 108], [371, 2, 20838, 1, 66, 132, 76, 25], [371, 1, 64, 1275, 17, 123, 10, 500, 504, 226, 37, 209, 272, 192, 1275, 76, 4, 226, 16, 25, 36, 19], [371, 534, 735, 943, 32, 4, 106, 36, 198, 14, 434, 51, 5684, 24], [371, 10, 77, 13, 6, 687, 3, 1415, 7, 1, 6, 997, 261], [371, 638, 12, 313, 1341, 18, 22, 34, 7, 199, 25, 564, 25, 1, 47, 28, 19, 123, 166], [371, 5, 502, 17, 4, 24, 7, 30, 28, 6080], [371, 5, 9, 131, 14, 1133], [419, 207, 91, 65, 972, 2, 419, 120, 2013, 203, 3351, 23, 25], [419, 13, 2, 831, 19, 1, 13, 23, 20839, 20840, 1151], [4721, 12, 2996], [2537, 121, 61, 6, 376, 3, 121, 1, 15, 305, 340, 115, 3, 46, 376], [400, 18, 10, 231, 3656, 42, 2, 1188, 230, 3, 119, 143, 24, 3, 72, 10, 6646], [400, 4, 19, 142, 1, 411, 78, 208, 13, 15, 317, 28, 587, 11, 20841], [400, 771, 194, 120, 418, 43, 1286, 858, 2708, 1289, 8861, 227, 35], [400, 51, 4, 904, 51, 197, 194, 294, 544, 8, 32, 39, 19, 2264, 1389, 6, 107, 11, 26, 227, 18, 126, 1282, 4605, 847, 3050], [400, 18, 4, 2609, 934, 2, 8862, 4, 2233, 1276, 248], [400, 18, 4, 2609, 934, 2, 8862, 4, 2233, 1276, 248], [400, 35, 135, 244, 6, 4, 2323, 284, 1, 26, 40, 176, 3436, 912, 54, 4089], [20842, 33, 1750, 13, 885, 354, 142, 84, 977], [703, 77, 14, 44, 7, 146, 61, 2, 535, 657, 24], [20843, 1840, 521, 4, 763, 16, 22, 449, 19, 147, 1], [4794, 8, 4, 20844], [5267, 87, 6, 61, 108, 6, 20845, 52, 114, 32, 4, 319], [20846, 3447, 2981, 2401], [491, 2, 9, 27, 2, 8850, 7971, 20847, 10, 866, 18, 50, 30], [491, 10, 9, 27, 2, 20848, 365, 70, 434, 1054], [491, 4, 1, 12, 20849, 62, 828, 407, 7, 89], [20850, 30, 412, 106, 6, 192, 147, 1, 1926], [1099, 11, 7, 9, 706, 13], [1099, 11, 4, 24, 13, 2, 7727], [1099, 11, 20, 1, 706, 13], [3207, 20851, 161, 8863, 3133, 133, 15, 1, 71, 622, 1244], [3207, 145, 34, 5, 62, 3, 64, 240, 834], [1339, 609, 11, 32, 10, 1434, 107, 135, 161, 1, 3, 67, 1339, 3915], [1339, 609, 11, 32, 10, 1434, 107, 50, 161, 1, 3, 67, 1339, 3915], [20852, 129, 9], [659, 3, 46, 868, 61, 258, 2, 120, 4393, 8, 207, 2, 172, 5242], [659, 30, 1235, 1578, 83], [659, 4623, 593, 9], [659, 8, 9, 49, 20853, 126, 7817], [737, 39, 9, 18, 36, 30, 13, 66, 1809, 39, 1], [1131, 2, 8864, 418, 8, 299, 40, 47, 1342, 6, 37, 3, 1559, 2899, 34, 88, 790, 2048, 52, 210, 62, 4, 236], [4271, 93, 1, 131, 1420, 17], [1737, 20854, 73, 20855, 110, 28, 2, 1783, 1525, 18, 7], [1737, 177, 5, 372, 33, 13, 76, 9, 552, 85, 326, 14, 90, 18, 4, 5013, 4194, 2550], [251, 233, 15, 48, 1, 15, 1, 30, 145], [251, 90, 7, 9], [251, 581, 145], [251, 494], [251, 42, 158, 26, 174, 451, 2968], [251, 5, 651, 3, 47, 2, 104, 583, 10, 651, 425, 192, 82, 4, 1529, 35, 26], [1936, 61, 137, 20856, 90, 137, 27, 217, 51, 337, 18, 7, 56, 30, 5839, 3129, 20857, 2686, 1651, 12, 4, 2167], [872, 51, 4, 1, 69, 90, 350], [872, 51, 4, 9, 69, 90, 350], [366, 93, 441, 27, 2, 89, 1], [366, 93, 441, 27, 89, 1, 8, 134, 2, 93, 77, 89, 6090], [366, 5559, 145, 57, 42, 196], [366, 667, 1], [366, 20858, 1], [366, 125, 2, 1, 11, 1966, 8, 100, 50, 137, 451, 3, 394, 947, 40, 227, 18, 1971, 74, 60, 981, 45], [1921, 18, 1229, 7, 103, 44, 80, 30, 20859, 34, 20860, 5, 229, 35, 32, 4, 9, 192, 5984], [1921, 20861, 498, 657, 975, 125, 2, 1, 37, 89, 34, 40, 29, 196, 295], [366, 2444, 41, 17, 314, 73, 4411, 24], [20862, 3210, 123, 5510, 20863, 5084, 4585, 3701, 793, 20864, 1585, 527], [5953, 2, 112, 534, 1], [2218, 20865, 11, 36, 20866, 39, 9, 46, 334], [1690, 17, 1, 20867], [3308, 9], [3476, 27, 4, 9], [37, 3, 330, 29, 19, 27, 252, 34, 3, 14, 8865, 8, 23, 4245, 1167, 34, 22, 1, 1501, 2, 2658, 8714, 16, 1400, 20868], [37, 3, 1389, 6, 484, 6, 4, 93, 2000, 162, 4, 207, 617, 29, 61, 426, 15, 522, 1184], [37, 3, 1244, 54, 85, 289, 132, 2, 1, 5938], [37, 3, 380, 3, 67, 6, 14, 179, 10, 586, 47, 950, 188, 48, 11, 2366, 74, 11, 1911, 10, 7793, 47, 20869, 52, 47, 434, 91, 205], [37, 3, 380, 23, 18, 1690, 92, 37, 1690, 17, 283, 20870, 26, 43, 20871], [37, 3, 380, 32, 77, 49, 20872, 1, 8, 20873, 39, 6018, 251, 78, 49, 20874, 110, 62, 57, 3330, 1437, 364, 459, 135], [37, 3, 124, 6, 1999, 22, 1139, 30, 2418, 3904, 619, 10, 20875, 5713, 76, 1, 220, 214, 73, 19], [37, 3, 176, 431, 34, 11, 4, 108, 16, 10, 453, 23, 13, 200, 855, 9, 33, 107, 18, 10, 663, 2084, 13, 1676, 384], [37, 3, 216, 20876, 73, 2, 752, 311, 21, 2775, 7488, 11, 3377, 310], [37, 3, 297, 22, 2557, 15, 20877, 3, 131, 28, 254, 3, 146, 28, 254, 15, 72, 1163, 520, 12, 10, 1, 27, 60, 20878], [37, 3, 3741, 10, 261, 47, 637, 34, 7, 1, 12, 458, 8, 23, 337], [37, 3, 66, 146, 258, 2, 154, 331, 140, 4, 1351, 1403, 14, 2, 1, 34, 66, 28, 2, 20879, 165, 331, 37, 15, 32, 93, 55], [37, 23, 51, 8, 5362, 12, 28, 84, 343, 207, 117, 1782, 307, 8866], [37, 289, 132, 322, 5909, 59, 4, 431, 1032, 316, 59, 98, 20880, 16, 95, 11, 1670, 2327, 8, 20881], [37, 20882, 72, 20883, 103, 404, 8, 88, 568, 211, 20884, 21, 58, 4, 199, 2432, 128, 51, 5], [37, 3840, 1, 146, 52, 2, 2072, 773, 40, 1135, 8, 20885, 29, 924, 4, 83, 40, 470, 4329], [37, 195, 3, 4, 101, 353, 35, 137, 84, 4290, 20886, 5, 513, 18, 22, 1445, 264], [37, 1302, 17, 26, 3399, 948, 26, 3, 14, 33, 948, 155, 25, 434, 34, 78, 1, 48, 20887, 26, 533, 747, 20888, 186], [37, 51, 197, 225, 3, 41, 79, 2, 353, 30, 83, 55], [37, 339, 3, 4704, 2, 320, 18, 71, 21, 92, 3, 70, 739, 10, 1, 115, 6, 921], [37, 1, 512, 17, 2, 65, 15, 165, 14, 2, 3221, 1442, 74, 28, 6267, 11, 4, 20889], [37, 303, 246, 657, 36, 122, 6, 242, 263, 142, 133, 98, 755, 892, 34, 66, 96, 11, 22, 83, 570, 48, 713, 253], [37, 1110, 21, 22, 120, 56, 2546, 460, 390], [37, 1110, 21, 740, 26, 1445, 26, 88, 33, 14, 2, 1810, 1, 18, 7892], [37, 750, 289, 101, 297, 292, 89, 1, 3348, 133, 3098, 6027, 233, 369, 12, 35], [37, 750, 225, 155, 106, 3, 122, 6, 2163, 98, 4367, 82, 4, 6821, 18, 186, 4, 2555, 20890, 369, 12, 20891, 58, 92, 4, 187], [37, 19, 640, 21, 2, 6977, 7, 36, 1073, 2, 19, 2736, 27, 458, 20892, 281, 19, 43, 548, 30, 24, 1947], [37, 2307], [37, 721, 3, 592, 2, 93, 77, 8, 29, 44, 6, 799, 27, 39, 1060, 30, 9, 36, 44, 20893, 20894], [37, 3, 1048, 2904, 21, 10, 460, 51, 2592, 1457, 8, 4, 462, 502, 17, 2, 537, 65, 33, 92, 3, 510, 108, 8, 1048, 56, 558], [37, 31, 3, 124, 2328, 1356, 8, 2, 2189, 278, 28, 32, 4, 1], [37, 31, 2, 77, 28, 551, 8, 277, 60, 9, 20895, 999, 92], [37, 12, 4, 1067, 20896, 31, 217, 1668, 6, 477, 6, 1443, 907, 8, 208, 2, 2045, 193, 15, 149, 16, 84, 1489, 48, 849], [37, 1176, 16, 10, 915, 8, 20897, 223, 6, 388, 27, 8867, 21, 4, 696, 3, 1419, 223], [37, 383, 29, 14, 1148, 1027, 42, 105, 636, 57, 20, 1, 58, 128], [37, 33, 497, 9], [37, 100, 94, 57, 5, 65, 13, 11, 4, 195, 461, 4, 546, 4007, 8, 207, 1372, 7165, 20, 253, 49, 309, 6, 62], [37, 239, 1, 11, 68, 1355], [37, 239, 1, 86, 374, 37, 209, 2394, 130, 36, 49], [37, 239, 9, 792, 5, 118, 44, 299, 66, 220, 96, 11, 3393], [37, 239, 2762, 283, 4, 1564, 1887, 12, 1524], [37, 239, 804, 111, 11, 4, 179, 51, 22, 817], [37, 209, 21, 14, 4, 412, 6, 257, 36, 49, 56], [37, 209, 127, 61, 18, 34, 3016, 317, 400, 219, 27, 307, 10, 388, 730, 82, 4257, 7375, 127, 202, 88, 3032], [37, 209, 120, 56, 51, 22, 20898, 20899], [37, 10, 4780, 12, 8634, 51, 10, 166, 4780, 8, 3, 37, 23, 13, 1472, 5, 533, 6, 218, 15, 48, 986, 88, 40, 131, 20900, 13, 43, 1], [37, 10, 1246, 297, 159, 20901, 938, 18, 2472], [37, 10, 171, 30, 801, 19, 4, 786, 11, 22, 180, 30, 20902, 1207, 731, 8868], [37, 10, 480, 47, 102, 26, 676, 47, 637, 306, 294, 11, 227, 480, 18, 26, 113, 17, 6, 114, 56, 54, 11, 4, 561, 26, 88, 294, 3829, 480, 18], [37, 10, 306, 273, 17, 40, 157, 10, 20903, 20904, 11, 4, 248, 4, 1096, 164, 16, 2, 3119, 27, 2, 670, 3995, 23, 322, 20905], [37, 25, 131, 14, 1, 8, 45, 255, 2847, 8, 45, 251, 78, 25, 315], [37, 158, 109, 442, 8346, 33, 1921, 18, 2, 1321, 932, 113, 17, 92, 26, 151, 2489, 102, 21, 4, 264], [37, 92, 46, 357, 41, 2, 409, 5, 32, 13, 89, 1, 20906, 85, 80, 260, 734, 105, 453], [37, 92, 132, 3897, 12, 56, 1027, 4632, 121, 37, 422], [37, 92, 52, 131, 308, 52, 2, 948, 675, 5894, 146, 413, 1, 34, 2779, 1174, 687, 125, 17, 26, 45, 13, 8657, 57, 1587], [37, 111, 135, 3083, 20907, 6, 1090, 126, 692, 20908, 3, 3083, 140, 3, 28, 169, 8, 3, 492, 4541, 20909, 1], [37, 633, 3, 911, 7, 3774, 1, 20910, 40, 502, 6097, 50, 798, 20911, 19], [37, 112, 15, 8869, 55], [37, 626, 21, 20912, 90, 20913, 154, 20914, 152, 86, 23, 22, 2066, 77, 34, 109, 23, 4, 4638, 1, 1930, 182, 563], [37, 549, 16, 5, 365, 30, 9], [37, 60, 1, 788, 17, 102, 21, 100, 50, 5041, 16, 6589, 2385], [37, 60, 24, 29, 853, 38, 36, 1266], [37, 4, 2370, 429, 12, 4, 6781, 7791, 3, 86, 52, 20915, 428, 204, 4, 3995, 218, 20916, 47, 2, 308, 359, 83], [37, 22, 171, 1, 124, 98, 1242, 133, 369, 3, 448, 18, 10, 610, 4, 106, 15, 424, 6, 1053, 2, 448], [37, 515, 34, 306, 12, 70, 17, 271, 35, 444, 40, 12, 1056, 467, 246, 5646, 40, 165, 901, 7, 45], [37, 6, 4, 203, 8357, 2382, 778, 1, 7, 33, 1087, 51, 17, 82, 50, 912, 30, 1536, 4542, 19, 102, 8, 28, 2, 112, 401], [37, 6930, 6, 5, 1, 1929], [37, 47, 890, 524, 81, 133, 20917, 38, 52, 121, 2237, 9, 46, 334, 53], [37, 66, 49, 48, 110, 268, 392, 178, 173, 4, 658, 8, 4, 20918, 1545, 12, 330, 11, 392, 2471], [37, 804, 71, 4, 324, 20919, 12, 1248, 11, 166, 823, 478, 11, 22, 823, 15, 2, 1191, 6, 20920, 13, 1472, 22, 2607], [37, 57, 31, 40, 2, 9, 11, 50, 8870, 31, 40, 70, 5, 243, 420, 50, 6, 2616, 8, 14, 243, 21, 4, 763, 16, 78, 2124], [37, 78, 134, 20921, 6, 8871, 478, 200, 32, 34, 45, 18, 5486, 422, 2365, 422], [37, 78, 9, 96, 20922, 11, 4, 5588, 74, 336], [37, 1157, 3, 920, 173, 2, 252, 3, 363, 6, 314, 261, 27, 26, 52, 168, 6, 14, 703, 73, 2384, 92, 6458, 199, 1534, 69, 935, 10, 515, 213, 1712], [37, 5, 29, 67, 6, 94, 4, 573, 164, 761, 16, 732, 2580, 8411, 1810, 20923, 26, 20924, 5, 131, 194, 837, 512, 2617], [37, 5, 275, 150, 13, 15, 422, 6, 472, 13, 2, 9, 251, 3, 33, 293, 3, 29, 44, 2, 1246, 333, 274], [37, 5, 96, 29, 249, 138, 74, 119, 24, 11, 862], [37, 750, 8, 2044, 49, 313, 1, 1023, 129, 26, 3, 456, 14, 4, 101, 68, 69, 20925, 15, 65, 1489, 6, 307], [37, 3, 63, 28, 173, 256, 637, 7317, 4, 392, 95, 16, 5591, 3294, 20926, 106, 6, 70, 10, 20927, 20928], [37, 59, 22, 567, 95, 178, 2932], [37, 49, 4, 3352, 129, 11, 2484, 478, 74, 57, 3, 196, 2939, 1201, 57, 139, 65, 51, 17, 13, 57, 49, 5, 494], [20929, 2538, 12, 109, 2, 813, 1567, 1], [20930, 3, 301, 60, 24, 205, 57, 277, 20, 2189, 532, 13], [685, 871, 448, 59, 8860, 685, 871, 20931, 3, 2618, 105, 100, 4, 324, 20932, 2052, 244, 6, 10, 1126, 8215, 957, 509, 15, 83], [685, 1848, 103, 1606, 2, 1, 1537], [1568, 4, 24, 13, 23, 5196], [20933, 12, 420, 4, 823, 545, 84, 20934, 84, 4043, 12, 6, 20935, 305, 7310, 823, 8, 28, 110, 545, 3743], [1221, 153, 1326, 471, 4, 90, 785, 4, 1, 1176, 610, 153, 1500, 18, 97, 406, 1546], [1221, 25, 1326, 471, 4, 90, 1014, 4, 1], [1597, 441, 6, 2, 1, 69, 152, 14, 2, 20936, 394, 1358, 44, 2, 25, 4607], [8635, 316, 17, 60, 24], [60, 1673, 1501, 986, 1], [60, 1714, 275, 33, 1, 59, 474, 233], [60, 2801, 3838, 388, 3838, 408, 1125, 54, 191, 31, 20937, 43, 5, 3049, 8872, 52, 13, 4], [60, 377, 448, 2, 1618, 16, 4, 900, 1826, 20938, 27, 20939, 20940, 20941, 75, 267, 20942, 602, 21, 4, 8559], [60, 49, 20943, 8, 60, 49, 1106, 60, 49, 759, 8, 60, 49, 33, 190], [60, 1, 25, 11, 20944, 33, 1999, 17, 27, 591, 8, 920, 423], [60, 1, 49, 20945, 5, 63, 1189, 50, 2, 2860, 106, 8, 40, 96, 67, 4, 138], [60, 1, 1240, 538, 943], [60, 1, 1189, 178, 14, 99, 686], [60, 1, 33, 44, 43, 1640, 27, 435, 4045, 485, 20, 4, 437, 4747, 15, 75, 32, 14, 305, 1791, 55], [60, 1, 87, 6, 28, 2, 164], [60, 1, 1786, 46, 45], [60, 202, 111, 259, 11, 98, 1119, 511, 360, 162, 474, 12, 8737, 8, 853, 4319, 114, 102, 4, 1085, 207, 20946], [60, 79, 15, 20947, 3, 79, 15, 20948, 54, 272, 806, 10, 624, 163, 762, 147, 24, 54], [60, 20949, 21, 5, 9], [60, 77, 86, 14, 2, 1, 8, 44, 98, 764, 12, 3666, 69, 364, 216, 5, 86, 7], [60, 189, 51, 1767, 41, 191, 57, 84, 503, 292, 443, 451, 2526, 49, 8, 4, 250, 184, 22, 1, 121, 47, 20950], [60, 236, 167, 18, 10, 436, 55], [60, 9, 7, 175, 33, 70, 17, 214, 55], [60, 308, 30, 9, 55], [60, 629, 49, 216, 6, 20951, 252, 6, 479, 77, 562, 86, 54, 234, 4, 874, 161, 399], [60, 145, 121, 20952, 6, 17, 3902], [60, 145, 492, 9, 3, 46, 7, 20953], [60, 25, 257, 2, 1, 6, 28, 2, 446, 1117, 60, 1288, 19, 545, 50, 60, 33, 609, 15, 188], [60, 25, 492, 9], [60, 16, 4, 684, 3988, 11, 10, 347, 149, 4, 171, 19, 51, 20954, 1389, 52, 67, 6, 3846, 35, 2, 1514, 125, 2, 203, 183, 1, 1737], [60, 16, 39, 9, 49, 334], [60, 16, 39, 9, 655, 2, 543, 11, 126, 20955, 811, 3, 46, 238, 1394, 10, 845], [60, 16, 39, 9, 87, 6, 907, 102, 212, 314, 1766, 36, 598, 6, 14, 498, 1978], [60, 16, 39, 9, 54, 135, 21, 3109], [60, 16, 39, 689, 664, 29, 655, 3772, 169, 4, 193, 36, 14, 1550, 20956], [60, 16, 39, 1956, 2, 344, 24, 792], [60, 16, 39, 352, 4649, 49, 19, 144], [60, 16, 78, 275, 3641, 9], [60, 16, 78, 2476, 287, 46, 37, 2476, 38, 66, 623, 5, 41, 2, 183, 1, 2497], [60, 16, 78, 33, 20957, 218, 16, 78, 226, 26, 39, 1, 14, 183], [60, 16, 5, 1, 49, 8730], [60, 16, 5, 77, 198, 14, 1039, 21, 3072, 371, 60, 16, 78, 132, 9, 32, 1608], [60, 111, 49, 1, 30, 25, 26, 5, 198, 33, 271, 750, 423, 82], [60, 111, 49, 37, 1577, 20958, 15, 37, 8873, 13, 31, 5, 44, 7, 209, 6, 1, 59, 85, 29, 5, 192, 396], [60, 388, 33, 849, 142, 4, 4999, 20959], [60, 593, 103, 33, 105, 683, 5780, 20960, 9], [60, 287, 49, 344, 283], [495, 2505, 132, 13, 6065, 91, 5, 405, 20, 2840, 34, 20961, 19, 291, 104, 1948, 3797, 3, 90, 78], [495, 547, 50, 1, 25, 680, 5, 33, 67, 256, 6, 72], [495, 333, 955, 7, 19, 144, 7, 176, 1087, 20962, 20963, 57, 2, 2502], [495, 113, 39, 4023, 272, 176, 172, 36, 9, 272, 176, 2351, 39, 229], [495, 113, 39, 24, 25, 3, 41, 240], [495, 113, 39, 24, 25, 3, 41, 240, 3, 41, 240], [495, 2878, 22, 1, 2, 20964, 74, 256, 3110, 12], [217, 51, 10, 20965, 67, 6, 2754, 3, 28, 32, 1110, 6, 934, 2, 535, 16, 354, 34, 217, 440, 101, 1155, 68, 4430, 20966], [217, 1, 491, 17, 173, 4, 2720, 31, 5, 94, 17, 18, 2283, 2199, 3, 3593, 10, 332, 4365, 1755, 228, 103, 14, 32, 129, 1305], [217, 510, 35, 26, 273, 17, 7, 3, 349, 9, 1185, 3, 47, 633, 33, 140, 7, 37, 19, 2784, 7, 15, 4199], [217, 107, 114, 39, 348, 423, 82, 17, 230, 3, 119, 4, 413, 2477], [217, 87, 6, 28, 22, 723, 1783, 181, 102, 4, 5677], [217, 333, 316, 17, 4763, 353], [217, 415, 273, 170, 688, 274, 47, 248], [217, 198, 1365, 6, 7906, 4397, 7, 81, 56, 6, 98, 3172, 2636, 3470, 12, 20967, 110, 8629, 20968], [217, 242, 22, 918, 35, 2034], [217, 113, 84, 2328, 49, 820, 16, 4, 20969, 278, 349, 20, 343, 776, 85, 49, 5, 56, 81, 311, 20, 8874, 20970], [217, 113, 17, 162, 4, 467, 3916, 162, 4, 1, 3916, 5, 19, 18, 4, 250, 264, 563, 17, 11, 4, 895], [217, 113, 4, 2095, 6, 271, 337, 116, 56], [217, 113, 22, 1, 6, 411], [217, 113, 22, 9, 6, 227, 18, 4600, 1065], [217, 273, 2207, 5792, 40, 7014, 73, 2, 1388, 149, 22, 1, 96, 1917, 80, 15, 46, 110, 7, 839], [217, 639, 79, 17, 2, 20971, 5649, 190, 20972, 215, 8875, 10, 2121, 47, 20973, 3367, 8, 47, 309, 55], [256, 356, 135, 829, 20, 1110, 5779, 100, 5780, 7878, 1], [256, 13, 2, 20974, 110, 536, 10, 4759, 1], [601, 3, 301, 3, 407, 207], [601, 3, 150, 13, 14, 109, 417, 6, 416, 88, 23, 33, 13, 304, 20, 32, 1, 769, 1933], [601, 3, 33, 67, 217, 6, 1, 6, 59, 2, 1096, 115], [601, 3, 597, 35, 18, 4, 7707, 4, 1352, 619, 1196, 2, 56, 63, 18, 20, 306, 11, 1991, 1504, 11, 2, 5461, 1504], [601, 3, 301, 3, 124, 2, 342, 1245, 269, 34, 88, 3, 375, 15, 118, 415, 20975, 1666, 257, 17, 35, 8, 2275, 10, 1728], [601, 2, 1, 87, 6, 1784, 6, 28, 162, 40, 61, 3937, 60, 45, 33, 98, 1037, 20976], [601, 275, 49, 33, 19, 144, 1669, 3, 300, 3, 33, 67, 6, 543, 78, 11, 4, 8593], [601, 574, 271, 791, 218, 15, 20977, 38, 42, 1577, 1, 26, 733, 26, 376, 11, 3139, 712, 15, 106, 6, 20978], [601, 42, 146, 762, 2, 153, 54, 205], [601, 5, 29, 131, 19, 4, 1, 34, 50, 235, 37, 93, 5, 450, 35, 19], [601, 5, 146, 572, 2, 1, 140, 148, 36, 589], [601, 5, 146, 1385, 21, 98, 1696, 541, 1, 125, 2, 93, 395, 33, 6, 3035, 630, 82, 525, 359, 18], [601, 110, 3, 146, 113, 39, 9, 6, 632, 35, 251], [386, 16, 2, 1], [386, 16, 2, 1], [386, 16, 2, 1, 3, 75, 304, 634, 1519, 12, 895], [386, 16, 2, 836], [386, 85, 12, 305, 3706, 462, 37, 179], [20979, 16, 78, 1, 87, 561, 3595, 1778, 2787], [20980, 12, 2, 104], [20981, 2628, 2053, 806, 4, 20982, 1907, 344, 35, 3407, 4387, 12, 24, 1115], [738, 103, 14, 6, 993, 20983, 8, 3, 75, 304, 140, 19, 212, 1716], [738, 73, 143, 169, 276, 384, 1, 20984, 28, 1020, 35, 40, 46, 276, 1550, 97, 1776], [1428, 10, 250, 20985, 8787, 510, 11, 5735, 1146, 721, 3, 210, 468, 10, 269], [8637, 573, 34, 23, 4, 24, 6493], [3293, 1818, 159, 824, 266, 134, 20986, 2963, 79, 21, 7527], [370, 1620, 3, 363, 6, 12, 66, 8876, 8877, 8876, 386, 31, 37, 85, 12, 7, 20987, 260, 58, 2, 1440, 1537], [370, 59, 4, 2238, 34, 3, 1038, 5, 6, 1785, 158, 18, 186, 8, 48, 6049, 20988], [370, 32, 10, 3007, 664], [370, 972, 143, 20989, 15, 70, 17, 214, 8, 1811, 6, 14, 4287, 3, 301, 3, 14, 120, 37, 78, 118, 13, 17], [370, 9, 34, 20990, 277, 48, 397, 21, 5420, 7555, 20991, 1016], [2399, 18, 4, 257, 236], [372, 13, 2, 112, 25, 6, 17, 8827, 2970, 793, 4, 269, 2640, 65, 35, 77, 3691, 985, 5853, 817, 19, 3386], [372, 13, 2, 1, 34, 766], [372, 13, 2, 274, 148, 1538, 33, 976, 54, 16, 10, 20992, 318, 14, 106, 6, 139, 633, 619, 8, 633, 1857, 35, 11, 22, 83], [372, 13, 2, 9], [2831, 72, 7, 159, 824, 12, 18, 4, 310, 27, 825, 1215, 73, 3, 409, 22, 6, 20993], [7465, 20994, 12, 13, 484, 11, 2, 1951, 1536, 27, 20, 120, 56, 1081, 69, 64, 6, 20995, 1622, 8878, 230, 230, 8541], [3563, 348], [3482, 39, 1, 20996], [569, 6, 10, 231, 5, 365, 283], [569, 16, 8820, 7, 213, 24, 47, 8821], [569, 16, 6089, 8, 20997, 3, 87, 6, 28, 10, 1341, 82, 1271, 8, 2, 401, 20998, 55, 1976, 201, 95, 27, 68, 1771], [569, 4648, 2, 320, 16, 76, 2789, 9, 29, 13, 19, 202, 189, 37, 3, 105, 363, 785, 27, 15], [1101, 267, 6, 8879, 159, 8, 5852, 51, 20999, 21000, 267, 6, 416, 7, 3662, 106, 6, 70, 4157], [1175, 10, 226, 117, 83, 88, 219, 81], [21001, 169, 7, 66, 492, 8318, 68, 13, 2839, 2111, 1, 13, 5647, 2687, 30, 2427], [1049, 169, 18, 39, 9, 25, 5, 46, 19, 45], [1282, 49, 470, 1871, 248, 43, 2009, 3822, 198, 14, 1166, 6, 569, 6, 245, 21002], [21003, 238, 9], [8178, 2350, 11, 2, 1, 231, 47, 2206, 2241, 2123, 1029, 11, 10, 6101, 3046, 17, 21, 44, 2, 1237, 16, 5736], [3611, 30, 153, 1446], [2750, 21004, 1], [2750, 12, 603, 4971, 439, 3, 623, 7, 10, 3526, 16, 9, 136, 1368, 8857, 439], [21005, 11, 4, 231, 30, 1], [5915, 56, 461, 8175], [5915, 5, 24], [6169, 14, 2, 104], [192, 929, 9, 11, 36, 21006, 8, 385], [192, 125, 7589, 2616, 3179, 749, 92, 23, 172, 32, 16, 1723, 4002, 9], [192, 27, 947, 2839, 92, 23, 1597, 54, 1], [271, 337, 88, 1, 19, 42], [271, 7101, 2059], [271, 1097], [271, 2866, 530, 141, 9, 69, 29, 58, 45, 21, 350], [21007, 35, 713, 6, 194], [795, 35, 32, 11, 47, 37, 1765, 7, 1, 363, 344, 6, 8880], [795, 35, 8, 114, 20, 21008], [795, 35, 11, 4, 489, 8765, 27, 4, 1432, 11, 10, 402, 1, 62, 23, 2, 1125, 13, 4, 3387, 91], [21009, 2, 1609, 72, 1615, 4597, 982, 14, 2, 3478, 2104, 12, 33, 344, 35, 144], [8602, 4, 2551, 59, 20, 646, 317, 626, 307, 559, 2685, 20, 172, 476, 26, 5, 266, 44, 6, 869, 747, 20, 646, 1, 177], [21010, 1720, 4, 3378, 16, 4, 21011, 2808, 781, 48, 762, 36, 1, 54, 11, 21012], [1824, 21013, 6918, 187], [1824, 6387, 41, 1012, 123, 84, 234, 1, 91, 164, 12, 284], [2356, 1137, 10, 25, 1, 14, 18, 1654], [411, 9], [411, 21014, 42, 70, 17, 3955, 1045, 1773, 83], [4673, 1291, 84, 9, 30, 128], [96, 75, 94, 57, 158, 94, 11, 76, 120, 3179], [96, 1075, 85, 1065, 748, 268, 718, 2956, 6, 4, 460, 215, 5861], [96, 29, 134, 2, 19, 133, 2, 1, 74, 50, 252], [96, 4110, 27, 39, 283], [96, 109, 1075, 2410, 3, 86, 21015, 12, 2, 181, 21016], [96, 304, 21, 1312, 6, 167, 7, 9, 3280], [96, 125, 4, 199, 1, 6, 4, 989, 16, 17], [3318, 82, 21017, 55, 34, 109, 189, 23, 134, 521, 18, 176, 7, 1, 69, 4558], [1855, 12, 505, 23, 3187, 21, 60, 570, 561, 285], [6086, 12, 2, 172, 6316], [2970, 619, 21, 473, 691, 6, 114, 2, 310, 79, 363, 108, 11, 8, 65, 11, 4, 2772, 8, 486, 2, 21018, 19, 4, 2192, 161, 1043, 30, 1], [139, 1921, 21019, 159, 524], [139, 4784, 17, 83], [139, 896, 13, 622, 33, 192, 2722, 97, 3649, 1, 3, 297, 5, 421, 240, 54, 11, 2294], [139, 14, 2, 9], [139, 134, 39, 9, 470, 2671, 138, 21020, 15, 839, 70, 50, 801, 579, 853], [139, 1500, 145, 3, 41, 97, 504, 1275, 5, 2, 1543, 145], [139, 4570, 76, 1208, 9, 780, 27, 20, 3023], [139, 7484, 4588, 56, 333], [139, 854, 10, 2803, 226, 19, 329, 5676, 42, 1, 12, 42, 185], [139, 1431, 104, 4070, 1396, 5, 2, 677, 34, 1373, 5, 266, 21021, 1673, 475, 260, 3, 21022, 26], [139, 1794, 42, 181], [139, 122, 6, 14, 142, 1391], [139, 168, 4, 324, 21023], [139, 5813, 102, 11, 4, 1306, 494, 177], [1882, 35, 2435, 149, 1409, 302, 43, 9], [1040, 1040, 61, 3135, 107, 361, 105, 5, 19, 1], [870, 3447, 30, 1], [870, 24, 78, 86, 5637, 41, 93, 24], [21024, 2, 999, 231, 104, 91, 23, 549, 16, 22, 25], [861, 35, 686, 1, 49, 1756, 4, 884, 409, 16, 3403, 1269], [1470, 123, 2485, 21, 4096, 5650, 79, 21025, 21026, 21027, 2, 21028, 204, 21029, 95, 1608], [1470, 21, 22, 1618, 959, 13, 2, 9], [1985, 18, 39, 9, 13, 26], [185, 8, 46, 41, 9], [185, 30, 5907, 939, 141, 83, 313, 15], [185, 30, 9], [185, 1], [185, 1], [185, 1, 51, 1860, 210, 134, 17, 10, 19, 3914, 1645, 37, 92, 3, 146, 119, 60, 1015, 30, 813, 1692], [185, 1, 198, 44, 271, 337], [185, 1, 655, 6, 14, 557, 13, 2, 185, 1], [185, 1, 4502, 19, 26], [185, 283], [185, 283, 19, 21030, 171, 319], [185, 187, 1, 18, 4, 1540], [185, 1554, 1, 7, 294, 13, 981, 73, 286, 8, 42, 75, 28, 224, 76, 1867, 4, 19, 35, 8139], [185, 19, 187], [185, 9, 12, 37, 963], [185, 161, 1, 109, 86, 23, 3225, 5, 21031, 1434, 27, 22, 21032], [185, 111, 81, 737, 18, 5600, 2586, 5601, 49, 4, 199, 179, 902, 8669, 5873, 23, 1003, 42, 609, 638, 110, 509, 74, 21033], [185, 660, 3450, 70, 2051, 389, 4134, 2872, 4334], [185, 120, 111, 70, 10, 448, 3789, 6, 36, 373, 164], [1341, 175, 8, 8881, 55, 1], [1411, 17, 68, 127, 106, 5, 537, 1346, 835], [1411, 141, 1, 5811, 4, 314, 21034], [21035, 218, 703, 145, 34, 10, 138, 358], [270, 2, 56, 1510, 16, 4, 294, 544, 1146], [249, 10, 138, 37, 93, 23, 13, 274, 1301, 5, 537, 1], [249, 10, 889, 269, 466], [21036, 12, 248, 78, 62, 71, 1768, 2115, 21037, 12, 6, 305, 115], [667, 16, 78, 636, 78, 14, 18, 1020, 34, 81, 133, 757, 3, 46, 58, 45, 390, 236, 23, 21038], [850, 9, 227, 173, 1444, 1039], [850, 9, 227, 173, 1444, 1039], [850, 12, 129, 37, 32, 5, 470, 927, 9, 49, 152, 44, 6, 258, 2, 395, 615], [850, 106, 1, 156, 1060], [2075, 329, 125, 143, 24, 2445, 205, 3, 46, 5387, 167, 15, 272, 96, 70, 362, 147, 40, 21039], [1461, 49, 4, 115, 6, 901, 539, 288, 416, 499, 224, 5, 12, 2065, 27, 57, 126, 3428, 1231, 412, 277, 8, 2554, 8882], [2517, 1], [889, 3643, 189, 63, 599, 14, 291, 483, 27, 43, 2184, 8, 60, 1808, 1, 103, 608, 170, 173, 21040, 55], [5527, 20, 236, 21041], [608, 16, 1294, 21042, 2090, 2221, 11, 1961, 3749], [362, 3, 41, 2, 417, 347, 2, 1973, 1435, 886, 21043, 4511, 21044, 11, 10, 1880, 8, 2, 607, 1721, 186, 253, 34, 3, 46, 41, 43, 9], [362, 301, 10, 1359, 118, 139, 21045, 549, 45, 12, 21, 4, 95], [1003, 1], [1003, 1003, 21046, 56, 2262, 21047, 1909, 8518, 2831], [21048, 16, 21049, 160, 21050, 16, 4, 21051, 527, 21052, 202, 4248, 286], [21053, 49, 5, 109, 61, 6, 70, 17, 28, 102, 22, 21054, 6, 258, 60, 148, 8883, 123, 7082, 5, 206, 83], [1008, 1], [1008, 181, 69, 5382, 3346, 579, 78, 638, 131, 21055, 1008, 35, 1449, 23, 21056, 151, 271, 6048, 35], [1008, 204, 4, 1, 13, 21057], [21058, 563, 2373], [300, 6, 274, 91, 25, 81, 127, 130, 1, 39, 115], [789, 847, 49, 5, 61, 6, 3001, 1464, 2999, 1297, 21059, 26, 159, 1908, 51, 4, 199, 106], [789, 2869, 11, 120, 2871, 136, 50, 8702, 1028, 8, 50, 21060], [789, 8, 2901, 21061, 21062, 21063, 21064], [789, 260, 95, 5, 1144, 17, 562, 21065, 1652, 21066], [789, 2901, 1328, 754, 1028, 8, 24, 21067], [789, 190, 1006, 1162, 3, 79, 50, 2443, 7532], [789, 33, 592, 7, 874, 16, 1347, 3, 1048, 215, 213, 21, 21068, 3, 394, 15, 51, 577, 2849, 123, 92, 270, 2, 8884, 303], [4747, 6, 2, 462, 34, 23, 332, 18, 2, 9], [2246, 18, 50, 3, 109, 29, 13, 22, 2013, 206, 5560, 30, 83], [1868, 2, 6467, 80, 9, 100, 17, 167, 50], [6087, 18, 80, 455, 1, 17, 8, 10, 4023, 286, 576, 66, 29, 438, 9], [6087, 80, 9], [8885, 18, 80, 455, 1, 17, 8, 10, 25, 286, 576, 66, 29, 438, 9], [8885, 18, 80, 455, 9, 286, 576, 17, 8, 10, 4023, 29, 492, 9], [6529, 18, 22, 9, 191, 171, 30, 938], [965, 81, 2668, 209, 45, 225, 7, 52, 118, 8886, 4, 1352, 27, 5883, 8, 6639, 66, 398, 450, 35, 999, 84, 817], [965, 35, 1, 43, 7942, 87, 21069, 21070], [21071, 27, 39, 9, 8861], [5428, 19, 169, 1], [21072, 5122, 8, 50, 2352, 386, 44, 4, 199, 21073, 8, 598, 6, 958, 5394, 3161, 11, 4, 775, 387, 139, 345, 97, 8302, 83], [21074, 9], [302, 17, 715, 66, 134, 15, 21075, 2, 1139, 21076, 95, 651, 107, 573, 21, 3933, 95, 21077], [302, 17, 38, 3, 72, 7, 118, 14, 204, 31, 52, 510, 108, 6, 164, 11, 225, 115, 8, 21078], [2281, 35, 27, 80, 1, 11, 2, 331, 460], [886, 70, 39, 9, 598, 127, 3666, 21079], [186, 12, 33, 13, 112, 21080, 27, 1549], [186, 21081, 58, 48, 182, 1550, 21082, 21083, 1890, 126, 9, 27, 3024, 8, 25, 37, 640, 4661, 118, 14, 783, 8887], [1672, 2408, 12, 889, 56, 38, 20, 3062], [2615, 480, 54, 48, 134, 2, 19, 3277, 35, 18, 2, 1, 125, 143, 235, 480, 102], [114, 2, 1, 6, 8546, 21, 60, 7884, 113, 50, 40, 276, 665, 15, 2578], [114, 102, 5, 19, 4434], [114, 7, 8, 1750, 15, 35, 20, 30], [114, 80, 1, 18, 2, 1283, 438, 88, 3, 1622, 50, 231], [114, 80, 9, 30, 6, 376], [114, 54, 2, 710, 21084, 8, 394, 15, 32, 18, 4, 232, 404, 4, 360, 21085, 36, 404, 2, 5781, 598, 13, 2, 8884, 6, 307], [114, 327, 23, 4, 261, 3966, 12, 19, 185], [81, 59, 17, 747, 10, 108, 3, 90, 7, 24, 385], [81, 59, 24, 863], [81, 1628, 16, 45, 34, 31, 3, 67, 151, 157, 42, 18, 4, 1251, 37, 29, 959, 17, 1], [81, 6, 21086, 215, 264, 10, 797, 93, 13, 7, 1, 21087], [533, 21088, 3, 424, 80, 1, 8, 291, 50, 1981], [81, 6743, 12, 2, 9], [81, 45, 13, 2, 9, 59, 932, 37, 13, 2, 91, 272, 4682, 5, 1497, 3, 94, 5], [2011, 27, 10, 455, 1], [21089, 49, 961, 34, 4, 3054, 7, 49, 969, 163, 63, 204, 1834, 19, 147, 3054, 652, 939, 4809, 78, 60, 24], [21090, 4, 21091, 21092, 4, 1647, 21093, 4, 180, 280, 55, 8, 2457, 161, 280], [21094, 54, 325, 9], [1356, 49, 59, 2130, 48, 5922, 68, 91, 56, 12, 246, 91, 3124], [1460, 581, 161, 145, 71, 6, 557, 2, 77], [1460, 17, 71, 6, 90, 2, 1], [2528, 8032, 65, 13, 4, 716, 1, 5, 118, 316, 337, 8, 101, 28, 2, 1015, 21095, 82], [5887, 399], [1226, 17, 5, 109, 14, 19, 1, 2893], [826, 1542, 195, 3, 465, 21096, 188, 140, 5, 44, 1340, 83], [826, 5, 124, 32, 696, 6, 58, 5, 2569, 17, 21097, 370, 1, 34, 3, 44, 2, 5771], [21098, 1386, 12, 21099, 950, 77, 46, 58, 393, 6, 21100, 30, 95], [412, 1050, 11, 22, 1], [4170, 32, 4, 25, 7, 881, 50, 999, 50, 98, 38, 40, 94, 40, 21101, 18, 22, 1, 40, 1275, 4, 670, 128], [21102, 46, 1042, 295, 34, 70, 39, 9, 65, 165], [1328, 28, 32, 50, 1556, 5490, 8, 110, 2103, 50, 21103], [113, 2, 1, 2499, 10, 231, 996, 43, 540], [113, 2, 1543, 3, 121, 19, 5, 113, 20, 1, 3, 121, 19, 5], [113, 2, 4587, 2456, 1, 1952, 142], [113, 384, 593, 1, 23, 48, 117], [113, 17, 7, 7, 24, 12, 21104], [113, 7, 90, 30, 145, 6, 242, 4, 19, 35], [113, 76, 9, 584, 32, 228, 3217], [113, 76, 9, 107, 135, 149, 15, 65, 13, 36, 911, 133, 17, 34, 4, 488, 7, 36, 46, 297, 17, 7, 198, 72, 1628, 133, 17], [113, 76, 308, 6401, 767, 36, 198, 122, 21105, 2317, 127, 1725, 1, 8, 1191, 6, 17, 73, 20, 21106], [113, 76, 703, 9, 1846, 316, 76, 834, 1, 108], [113, 39, 9, 3, 64, 76, 33, 6, 19, 240], [113, 20, 482, 5312, 21107, 21108, 15, 196, 296, 64, 20, 21109, 11, 3920], [1806, 17, 23, 974, 34, 3, 46, 4, 68, 1275, 326, 2, 1, 21, 351], [3968, 137, 27, 10, 164, 3, 318, 14, 3, 197, 1, 22, 21110, 218, 23, 48, 389, 459, 1434], [4174, 6, 1056, 155, 1355, 3, 72, 225, 27, 80, 74, 83], [21111, 41, 32, 4, 9], [7847], [262, 17, 661, 16, 137, 567, 95], [262, 17, 312, 1902, 21112], [262, 17, 27, 893, 312], [262, 97, 1, 13, 21113, 91, 249, 563, 17, 51, 143, 6022, 1333, 113, 240, 28, 84, 1130, 1452], [262, 20, 1, 60, 1788, 82, 7, 154, 5658, 2969, 8219, 2050, 230, 40, 597, 35, 37, 1358, 3390, 5, 2, 141, 882, 225], [262, 22, 1, 13, 40, 455, 2601, 19, 7, 45, 188, 40, 556, 28, 39, 6837, 9, 262], [364, 23, 208, 13, 2, 611, 30, 1, 21, 206, 3490, 107, 108, 8355, 26], [364, 1, 58, 588], [364, 1, 28, 2, 535, 8, 14, 21114], [364, 12, 2, 112, 186, 3948, 78, 18, 22, 9, 5071], [267, 5, 159], [267, 5, 159], [267, 5, 159, 243, 1903], [267, 5, 402, 54, 7, 1468, 159], [267, 21, 107, 27, 17, 215, 264, 140, 15, 179, 8, 43, 68, 499, 222, 16, 806, 15], [267, 159], [267, 159], [267, 159, 44, 2, 434, 110], [267, 21, 626, 4, 1064, 19, 54, 16, 17, 21115, 92, 3, 65, 13, 2, 285, 19, 21116], [267, 21, 7, 21117, 3, 592, 7, 2072], [267, 6, 353, 175, 225, 10, 21118, 18, 21119, 49, 3383, 18, 17, 13, 2, 1413, 264, 18, 4, 5442], [267, 6, 10, 25, 5413, 3, 532, 93, 88, 2, 9, 281, 556, 349, 21120, 4, 9, 107, 532, 2, 25], [2908, 421, 1], [2908, 570, 9], [2908, 27, 60, 609, 4, 1346, 387], [794, 10, 1, 99], [7, 8600, 629, 65, 13, 56], [7, 2206, 4, 6078, 175, 12, 356, 21121, 34, 15, 2, 1102, 209, 6, 5, 379, 1, 318, 345], [7, 5530, 21122, 14, 1811, 65, 51, 39, 950, 207, 265, 69, 66, 216, 1220, 36, 49, 48, 20, 21123], [7, 589, 1029, 38, 5, 44, 6, 176, 3416, 20, 5046, 140, 217, 176, 81, 6, 1834, 13, 420, 812], [7, 30, 41, 2, 145, 21124], [7, 30, 37, 697, 66, 75, 547, 15, 78, 1877, 9, 34, 3267, 1704, 1992, 4571, 3, 29, 594, 25, 91], [7, 30, 37, 21125, 15, 1642, 18, 2, 752, 190, 21126], [7, 2880, 1029, 38, 20, 96, 98, 183, 9], [7, 2880, 1029, 38, 2, 9, 72, 40, 48, 2, 282], [7, 2880, 1029, 38, 5, 555, 4, 676, 21, 217, 8, 36, 168, 4, 676, 244, 6, 1770, 13, 1, 5, 165, 108, 4, 19, 562], [7, 89, 1, 28, 440, 140, 16, 963, 24, 716, 4016, 149, 4, 352, 63, 28, 165, 31, 474, 59, 50, 12, 431], [7, 2868, 82, 21127, 12, 37, 681, 85, 58, 3, 259, 11, 1, 30, 3038, 288, 111, 28, 6, 259, 224, 270, 681, 213, 657], [7, 1102, 7794, 41, 8880, 6778, 8, 32, 3, 94, 97, 5154, 1], [7, 1, 3208, 920, 423, 82, 17], [7, 1, 2, 794, 794], [7, 1, 165, 14, 243, 59, 7, 21128, 8057], [7, 1, 79, 18, 8400, 21, 60, 8401, 53, 8402, 53], [7, 1, 510, 8367, 11, 1522], [7, 1, 75, 881, 17], [7, 1, 222, 400, 18, 10, 1511], [7, 1, 21129, 24], [7, 1, 21130, 10, 343, 193, 6, 752], [7, 1, 2009], [7, 1, 41, 473, 937, 520], [7, 1, 41, 21131, 253, 34, 484, 2, 5485], [7, 1, 21132, 2353, 19, 17, 3309, 19, 147, 1], [7, 1, 12, 1901, 1599], [7, 1, 12, 784, 102, 102, 102], [7, 1, 12, 625, 21133, 1185, 217, 402, 50, 2, 21134], [7, 1, 12, 21135], [7, 1, 33, 294, 102, 32, 13, 369], [7, 1, 476, 216, 4, 2552, 694], [7, 1, 18, 21136, 40, 29, 208, 117], [7, 1, 121, 50, 24, 429, 1368, 5150], [7, 1, 273, 17, 6, 829, 531, 3, 273, 50, 6, 61, 258, 630], [7, 1, 67, 10, 7210, 40, 21137, 10, 8863], [7, 1, 47, 475, 59, 595, 19, 350, 10, 237, 228, 41, 756, 123, 688, 968, 21138, 595, 198, 14, 4, 577, 16, 20, 475], [7, 1, 5, 704, 62, 57, 3, 196, 40, 29, 14, 4, 199, 1, 2, 937, 831, 790, 10, 25, 5, 150, 17], [7, 83], [7, 177, 136, 156, 132, 2, 24, 105, 132, 2, 2551], [7, 1383, 1212, 115, 3901, 57, 1681, 12, 22, 25, 1350, 700, 4, 6501, 1, 18, 1681], [7, 1170, 136, 1568], [7, 148, 21139, 476, 1, 21140, 11, 286, 219, 21141, 407, 2, 148, 3979, 148, 728, 21, 1209, 91, 55], [7, 2214, 45, 248], [7, 252, 2354, 46, 43, 21142, 2164], [7, 252, 82, 2962, 545, 4, 858, 3074, 8, 1467, 2017, 64, 52, 21143], [7, 171, 202, 1, 7, 47, 28, 4, 1092, 21, 4, 406, 216, 17, 37, 19, 214, 40, 1606, 10, 115], [7, 203, 1, 7, 156, 18, 4, 310, 33, 294, 11], [7, 580, 788, 47, 248, 7, 71, 3, 580, 788, 173, 4, 3398, 2340, 8, 1351, 18, 10, 108, 155, 817], [7, 19, 2972, 918], [7, 90, 45, 29, 196, 295, 1, 23, 150, 531], [7, 236, 363, 82, 2297, 6, 21144, 22, 19, 17, 35], [7, 9, 191, 57, 106, 15, 12, 15, 8769], [7, 9, 990, 129, 5565, 21145, 21146], [7, 9, 54, 116, 203, 7713, 121, 15, 4184], [7, 9, 21147, 517, 18, 3238, 1614], [7, 9, 47, 628], [7, 8701, 276, 28, 78, 1, 948, 35, 26, 1174, 869, 45], [7, 215, 175, 47, 33, 323, 21148, 3, 29, 109, 13, 89, 1, 3, 13, 322, 21149, 89, 1, 359, 99, 2004, 8, 99, 1725], [7, 358, 343, 317, 1112, 35, 20, 388], [7, 70, 5, 98, 589, 83, 31, 20, 54, 65, 6, 14, 1001, 5, 75, 1, 38, 20, 21150], [7, 8447, 207, 418, 21151, 86, 3, 976, 11, 64], [7, 312, 21152, 487, 547, 34, 208, 13, 4, 1651, 47, 18, 21153, 52, 210, 176, 245, 21154, 5684, 212, 21155, 736], [7, 312, 47, 2, 1080, 18, 7, 21156, 3, 118, 44, 328, 4, 199, 184], [7, 25, 37, 56], [7, 25, 7688, 56, 128, 4756, 56], [7, 25, 1192, 156, 167, 7, 9, 38, 52, 157, 8356, 21157, 11, 2, 323, 134, 305, 25, 825, 2, 2204], [7, 25, 1050, 46, 585, 112, 1944, 25, 21158, 52, 100, 3799, 3211, 1, 54, 18, 21159], [7, 25, 533, 13, 2, 9, 113, 7, 1, 25, 569, 35], [7, 145, 12, 17, 55, 21160], [7, 399, 103, 105, 137, 1231, 361], [7, 264, 2486, 4019, 12, 21, 4, 942], [7, 206, 21161, 11, 6847, 12, 2, 966, 1, 91], [7, 68, 551, 120, 1, 7, 156, 21162, 437, 4081, 51, 577, 21163, 252, 88, 345, 5859, 38, 217, 28, 505], [7, 166, 45, 21, 4, 95, 26, 28, 129, 80, 653], [7, 327, 12, 92, 5869, 123, 377, 27, 2, 79, 6, 204, 1167], [7, 24, 237, 14, 1390, 21, 4, 2368], [7, 24, 510, 2006, 1730], [7, 24, 75, 14, 7, 1031, 45, 146, 1729, 55], [7, 24, 345, 21, 547], [7, 24, 203, 3823, 1090, 15], [7, 24, 1428, 93], [7, 7664, 35, 45, 21, 4, 95, 80], [7, 1691, 16, 104, 8654, 27, 20, 387, 21164], [7, 45, 12, 21, 4, 1170, 11, 8418, 8419, 731, 320], [7, 386, 16, 2, 1, 1029, 38, 5, 458, 4, 3536, 8, 44, 43, 522], [7, 185, 1, 648, 237, 389, 35], [7, 1454, 192, 2, 490, 21165, 321], [7, 1097, 858, 150, 38, 20, 2404, 6, 134, 217, 2, 547, 3913, 81, 59, 3092, 437, 27, 166, 63, 109, 8017], [7, 47, 2, 1, 420, 3, 21166, 4, 247, 2536, 184, 3, 200], [7, 47, 2, 2531, 6081, 16, 1313, 4273, 8353, 35, 21167, 2527, 2375], [7, 47, 603, 546, 213, 1712, 3, 502, 32, 76, 1, 5027, 74, 36, 220, 21168], [7, 47, 21169, 13, 80, 734, 24, 5623], [7, 47, 10, 104, 2910, 21, 4, 1477], [7, 47, 48, 93, 106, 192, 4, 2038, 3018, 489, 738], [7, 47, 248, 23, 33, 152, 157, 10, 310, 2014, 1929], [7, 118, 14, 37, 804, 8, 8553, 197, 51, 68, 16, 212, 835, 1637, 21170, 3, 118, 2033, 10, 30, 102, 212, 1, 28, 927], [5105, 132, 2, 179, 141, 3455], [7, 97, 3579, 205, 7, 46, 10, 282], [7, 2, 799, 21171, 80, 24, 982, 532, 13, 10, 21172, 2667, 752], [7, 2, 1899, 3303, 104, 944], [7, 2, 21173, 180, 1, 11, 4, 6883, 1730, 472, 649], [7, 32, 23, 72, 5, 9, 30, 956], [7, 71, 3, 62, 4, 24, 12, 542, 21, 17, 120, 111, 2506], [7, 71, 5, 62, 69, 14, 308, 59, 28, 11, 4, 21174, 59, 578, 13, 591, 8, 2463, 8, 21175, 12, 7], [7, 71, 5, 100, 4, 257, 1478, 83], [7, 13, 72, 289, 124, 4, 3326, 371, 5799, 252, 289, 124, 98, 1074, 371, 4, 21176], [7, 247, 25, 19, 27, 4, 329, 1, 41, 17, 587, 73, 21177], [7, 10, 379, 236, 3, 29, 67, 4515, 206, 34, 50, 1689, 694], [7, 48, 2, 1438, 231, 7, 4, 3957, 16, 17, 294, 173, 2, 3327, 469, 288, 3, 47, 175, 7, 20, 2, 1633], [7, 48, 2070, 1729, 35, 10, 909, 15, 3293, 24, 10, 1758], [7, 550, 21178, 5, 63, 298, 7, 355, 480, 23, 362, 20, 1574, 4454, 12, 127, 1768, 130, 10, 1068], [7, 112, 21179, 233, 439, 22, 1, 41, 21180, 8, 96, 135, 45, 35, 4, 21181], [7, 112, 21182, 3, 273, 76, 25, 194, 71, 326, 7, 407, 18, 4, 3189, 756, 18, 4, 1, 38, 36, 28, 6, 1670], [7, 117, 23, 70, 348, 117, 92], [7, 96, 10, 24], [7, 4, 698, 16, 1, 3, 90, 19, 27], [7, 57, 3, 113, 10, 9, 38, 36, 46, 313, 4, 833, 53, 46, 357, 41, 106, 21, 4894], [7, 85, 3, 29, 1985, 39, 9, 18, 8803], [7, 85, 3, 176, 5, 135, 5, 46, 13, 76, 166, 9], [7, 85, 3, 3545, 80, 1, 42, 609, 30, 639, 1534], [7, 85, 3, 222, 156, 79, 5953, 21, 393, 10, 145, 156, 116, 110, 38, 23, 990, 596, 10, 260], [7, 80, 3162, 3, 47, 32, 35, 11, 50, 2138], [7, 20, 1, 85, 40, 208, 13, 40, 87, 2, 91], [7, 8, 66, 2266, 470, 16, 305, 4660, 213, 8, 247, 16, 305, 1526, 213, 1, 51, 922, 166, 21, 14, 171, 283, 1428, 116, 7, 776], [7, 89, 38, 20, 2781, 72, 622, 208, 13, 2, 9, 21183], [7, 426, 40, 12, 284, 55, 7, 10, 153, 205, 91, 3, 300, 21184, 357, 306, 12, 2857, 130, 588, 3154], [7, 19, 35, 134, 170, 60, 24, 53, 1025, 35, 27, 352, 18, 10, 453, 3, 198, 33, 137, 27, 2688], [7, 10, 1, 38, 3, 150, 13, 254], [7, 48, 97, 1, 31, 40, 29, 64, 134, 5, 235], [7, 60, 9, 45, 277], [7, 4, 101, 184, 2, 25, 191, 21, 15, 60, 21185, 1, 11, 135, 3445], [7, 85, 3, 46, 1354, 444, 23, 1262, 483, 39, 9, 46, 334], [4, 21186, 49, 107, 82, 7222, 6, 3442], [4, 29, 87, 4635, 74, 8704, 74, 32, 39, 180, 226, 781], [4, 16, 4, 263, 12, 120, 248], [4, 16, 4, 263, 12, 120, 248], [4, 109, 58, 454, 11, 39, 215, 535, 16, 2124], [4, 3724, 79, 2302, 4880, 4707, 747, 637, 7873], [4, 49, 137, 4, 1146, 11, 166, 324, 3, 195, 48, 228, 27, 26], [4, 1644, 21187, 21188, 21189, 12, 2, 2475, 16, 95, 16, 8798, 11, 4, 21190, 2865, 21191], [4, 21192, 136, 201, 434, 2134, 8, 1606, 76, 398, 21, 7, 56, 251], [4, 21193, 407, 248, 15, 33, 407, 73, 93, 73, 21194], [4, 4143, 2777, 47, 1815, 21195, 18, 4, 21196, 21197, 16, 8888, 21198, 101, 4477, 8888, 12, 2, 203, 21199, 838], [4, 1377, 255, 159, 123, 21200], [4, 2965, 204, 32, 4, 21201, 267, 4104, 589, 141, 7360], [4, 1055, 56], [4, 189, 41, 1110, 38, 52, 486, 354, 851, 21202, 52, 299, 3, 47, 70, 21203, 52, 47, 1699, 38, 52, 623, 15, 47, 21204], [4, 1213, 103, 70, 5, 86, 39, 1, 49, 69, 374, 428, 1591], [4, 2716, 11, 49, 32, 120, 248], [4, 1050, 21205, 496, 1222, 123, 1057, 21206, 871, 12, 2, 154, 822, 16, 4, 377, 3408, 1373, 127, 1510, 26, 2872, 8678, 6009], [4, 21207, 382, 1122, 1475, 2886, 12, 4088, 4, 21208, 1939, 3771, 136, 4, 21209, 3389, 7700, 3, 195, 61, 27, 1589, 108, 1748, 5116], [4, 4021, 265, 12, 270, 2, 24], [4, 704, 1294, 136, 1222, 98, 2007, 2559, 16, 21210, 577, 15, 48, 2, 2559, 16, 2007, 21211, 324, 21, 1343], [4, 1147, 136, 132, 2, 1], [4, 1294, 858, 1568, 8, 10, 443, 2708, 12, 599, 32, 3, 87, 11, 164, 1315], [4, 697, 2006, 21, 4, 377, 18, 20, 1495, 1304], [4, 697, 2006, 21, 4, 377, 18, 20, 1495, 1304], [4, 3836, 44, 216, 4, 1408, 8, 4, 232, 49, 21212, 136, 2923, 129], [4, 786, 56, 73, 19, 21, 48, 28, 7], [4, 1108, 21213, 1837, 16, 8181, 72, 52, 370, 52, 79, 997, 5344, 21214, 529, 1072, 7, 52, 4650], [4, 825, 21215, 824, 1401, 44, 132, 298, 3754, 21216, 11, 1382, 21, 4, 722, 2501, 8, 36, 49, 28, 110, 21217], [4, 2602, 49, 1604, 56, 55, 251], [4, 1658, 12, 392, 16, 120, 248, 4, 21218, 12, 392, 16, 120, 248, 4, 1684, 2679, 31, 392, 16, 120, 248], [4, 3355, 154, 2134, 65, 13, 5112, 21219], [4, 909, 533, 59, 1831, 24, 8, 42, 2687, 1520, 174, 2, 940, 2, 104, 22, 178, 12, 284], [4, 294, 544, 12, 56, 7931, 7, 12, 1284], [4, 7172, 280, 12, 4, 247, 144, 229, 1269], [4, 21220, 8, 8889, 3075, 8, 9, 3, 3165, 8, 2782], [4, 232, 96, 249], [4, 89, 1, 96, 3262], [4, 832, 1, 11, 4, 360, 253, 17, 18, 798, 225, 8, 192, 13, 32, 10, 8520, 3, 46, 110, 32, 7, 1252, 37, 3, 62, 40, 2070], [4, 832, 1, 12, 108, 18, 21221], [4, 681, 1219, 2340, 1196, 21222, 18, 4, 21223, 16, 21224, 21225], [4, 681, 16, 48, 87, 74, 67, 2, 91, 12, 21226, 552, 94, 71, 1, 14, 21227, 4, 19, 54, 129, 435, 36, 44, 2198, 4529, 27], [4, 7520, 44, 132, 56, 21, 13, 473, 449, 15, 598], [4, 180, 774, 5227, 2187, 39, 1928], [4, 95, 12, 4, 2392], [4, 95, 8, 4, 1578], [4, 95, 8, 4, 2946, 123, 21228, 523, 527], [4, 95, 751, 316, 299, 16, 341, 4398, 18, 22, 2428, 5500, 1207, 10, 1643, 100, 17, 578, 5, 26, 150, 350], [4, 1, 1309, 121, 40, 210, 13, 10, 2497], [4, 1, 41, 60, 1203], [4, 1, 12, 21229, 21230], [4, 1, 1239, 464, 138, 2222, 130, 2, 8255, 80], [4, 1, 69, 33, 694, 50, 387, 51, 17, 426, 40, 210, 28, 1011, 317, 477, 38, 42, 191, 21, 789, 1295, 860, 661, 16, 1321], [4, 1, 69, 565, 4448, 12, 61, 6108, 92, 52, 63, 1028], [4, 1, 208, 13, 36, 29, 14, 11, 4, 489, 27, 36, 30, 32, 54, 11, 99, 141, 30, 3691, 26, 752, 134, 240, 8890, 2627, 163, 385], [4, 1, 49, 108], [4, 1, 747, 17, 49, 37, 589], [4, 202, 11, 49, 1413, 2989], [4, 177, 69, 565, 1376, 8174], [4, 348, 3, 33, 216, 49, 2, 2998], [4, 524, 2951, 21, 4, 250, 470, 16, 4, 213, 12, 599, 144, 2495], [4, 1346, 109, 2280, 126, 21231, 381, 565, 27, 8783, 11, 21232, 21233], [4, 620, 168, 6, 44, 21234, 76, 1, 65, 3955], [4, 2193, 662, 142, 6, 4, 8596, 7, 2, 1870, 5830, 82, 2, 4913, 36, 79, 4535, 3014, 6, 28, 5, 1, 82, 123, 17], [4, 489, 29, 105, 28, 206, 6, 60, 16, 78, 9, 1168], [4, 1490, 21235, 12, 32, 1880, 1723, 4002, 21236, 25, 12, 428, 2, 3580, 18, 822, 16, 624, 8, 283], [4, 115, 10, 500, 273, 17, 40, 47, 3062, 38, 40, 359, 18, 17, 12, 4, 199, 115, 3, 3753, 207, 703, 1708, 82, 10, 4201], [4, 4659, 2, 9, 71, 40, 19, 337, 8, 84, 280], [4, 570, 95, 28, 4, 1329, 34, 4, 710, 3018, 28, 4, 873], [4, 570, 95, 114, 2, 1966, 230, 21237], [4, 6032, 193, 6, 44, 352, 27, 2, 418, 12, 6, 532, 93, 70, 50, 528, 114, 50, 6, 28, 522, 8, 88, 19, 50, 117, 11, 4, 24], [4, 1217, 3, 168, 38, 23, 1657, 125, 1, 4842], [4, 450, 6, 7, 232, 178, 47, 37, 893, 3, 75, 110, 114, 15], [4, 488, 7, 4, 1122, 2, 232, 408, 33, 568, 6, 229, 71, 669, 4, 5151, 5852, 12, 5320, 210, 58, 126, 5723], [4, 730, 16, 2925, 21238, 87, 6, 3046, 6808, 21, 7, 56, 323, 36, 1525, 11, 84, 2439], [4, 6093, 21239, 47, 2, 141, 1, 13, 25, 75, 110, 114, 142, 2, 1, 30, 1940], [4, 19, 277, 2, 190, 3060, 58], [4, 19, 2038, 2882, 502, 1566, 60, 851, 11, 2, 180, 2391, 874], [4, 172, 9], [4, 19, 2095, 1, 197], [4, 356, 184, 12, 4, 1246, 105, 41, 543, 54, 18, 50, 68, 264, 397, 3, 210, 44, 4, 5906, 6, 113, 50, 50, 306, 98, 1239, 9], [4, 179, 9, 64, 150, 2, 25, 2763, 97, 566, 17], [4, 179, 21240, 54, 2261, 16, 1308, 16, 164, 107, 21241], [4, 77, 2931, 261, 46, 295, 34, 1913, 4713, 8, 33, 216, 17, 72, 11, 10, 235, 757, 42, 614, 6, 14, 11, 5913, 124, 6, 430, 531], [4, 4202, 165, 597, 35, 8, 623, 7, 4, 93, 1403, 46, 139, 1601, 24, 38, 52, 1484, 20, 8891], [4, 1802, 21242, 49, 48, 57, 36, 21243], [4, 189, 51, 819, 1023, 49, 270, 181], [4, 1136, 103, 70, 5, 131, 157, 402, 18, 2, 145], [4, 9, 46, 1677, 43, 127, 127, 13, 21244], [4, 9, 49, 21, 326, 10, 25], [4, 9, 14, 877, 1701], [4, 774, 21245, 64, 203, 1, 13, 11, 64], [4, 8892, 1, 13, 10, 8892], [4, 4755, 16, 10, 21246, 1846, 73, 3, 121, 2086, 62, 39, 1, 218, 66, 14, 21247], [4, 1280], [4, 2457, 12, 35], [4, 462, 81, 59, 3, 44, 6, 400, 11, 22, 930, 8, 3, 44, 292, 755, 6, 633, 13, 321, 3, 330, 122, 1547, 3, 75, 19, 2168, 1], [4, 215, 8371, 51, 232, 4409, 267, 21, 70, 15, 2, 93, 68, 8846, 26], [4, 215, 106, 20, 24, 47, 7675, 1106, 6109, 749], [4, 440, 205, 2287, 2, 1142, 27, 2, 89, 1], [4, 21248, 1317, 18, 4, 1860, 543, 173, 314, 3130, 27, 4, 7693, 16, 4, 21249, 123, 21250, 21251], [4, 308, 18, 22, 135, 186, 5, 25, 452, 62, 940, 2, 24, 110, 31, 15, 491, 5, 1501, 4, 231], [4, 1722, 1, 7, 47, 533, 45, 46, 11, 1436, 521, 225, 3, 109, 67, 6, 1160, 10, 1222], [4, 141, 1, 5777, 140, 52, 48, 175, 1046], [4, 141, 1, 273, 17, 1339, 503, 47, 2, 21252, 7, 38, 40, 502, 17, 1339, 3915, 13, 4, 1339, 3915, 8854], [4, 1082, 16, 5, 9, 86, 20, 45, 29, 21253], [4, 1029, 38, 5, 1786, 442, 174, 2, 19, 21254, 16, 56, 15, 2, 64, 976, 188], [4, 247, 681, 287, 14, 1412, 4, 247, 144, 1787, 18, 126, 327, 8853, 14, 1037, 6917], [4, 247, 291, 111, 44, 4, 247, 6, 72, 1, 25, 71, 63, 5, 1800, 6, 569], [4, 629, 2, 332, 30, 418, 21255, 22, 25, 568, 108, 11, 106, 31, 52, 34, 99, 705, 163, 19, 4, 1, 129, 163, 129, 55], [4, 451, 139, 137, 8, 32, 5, 465, 12, 19, 5, 1, 151, 1218, 18, 5], [4, 1129, 62, 69, 66, 49, 34, 66, 516, 14, 112, 158, 26, 89, 283], [4, 1203, 16, 111, 8893, 75, 114, 357, 686, 3, 1475, 528, 51, 5, 319], [4, 1203, 16, 22, 153, 233, 795, 18, 10, 8315, 30, 845, 125, 76, 3193, 30, 5988], [4, 417, 234, 16, 358, 2868, 109, 41, 9, 55], [4, 101, 1030, 27, 4, 260, 734, 12, 40, 48, 861, 18, 5, 8, 179, 1, 7, 3, 103, 3776, 50, 30, 13, 98, 1644, 21256], [4, 101, 820, 16, 4, 2276, 7, 3, 13, 47, 4, 391, 820, 16, 4, 21257, 26, 4, 206, 21258, 275, 21259], [4, 101, 540, 3, 359, 12, 6, 229, 39, 1, 57, 698, 16, 138, 10, 77, 14, 21260], [4, 101, 184, 59, 153, 12, 36, 14, 253, 251, 233, 14, 97, 653, 416, 499, 12, 1041], [4, 101, 106, 3, 801, 47, 38, 4003, 3303, 7, 9, 30, 1], [4, 101, 106, 16, 213, 151, 1, 59, 48, 44, 5999, 38, 21261, 21262, 107, 962], [4, 111, 69, 44, 6730, 132, 79, 120, 56, 220, 79, 7, 21, 2, 2437, 374, 120, 248, 4, 910, 21263], [4, 21264, 47, 314, 73, 19, 13, 2231, 204, 2, 180, 30, 95, 8, 119, 15, 27, 2, 3556, 166, 184], [4, 3091, 297, 10, 387, 8, 121, 36, 1210, 355, 3, 273, 170, 3, 28, 314, 73, 5, 1, 23, 4, 91], [4, 863, 16, 3050, 21265, 5, 6, 429, 7, 285], [4, 1990, 12, 329, 1], [4, 21266, 377, 4072, 82, 21267, 70, 4, 657, 615], [4, 7361, 198, 1023, 4, 8690, 21, 21268, 31, 5, 114, 4, 215, 1347, 5, 198, 955, 18, 7, 3983, 1347, 49, 21269], [4, 938, 771, 57, 620, 41, 4, 247, 1, 27, 1052, 1022], [4, 540, 6871, 90, 1799, 12, 140, 52, 12, 2, 3206], [4, 786, 33, 2020, 6, 468, 22, 178, 251], [4, 786, 198, 396, 126, 226, 6, 4, 3827], [4, 1108, 660, 90, 22, 34, 2728, 2165], [4, 613, 265, 16, 8099, 3638, 12, 56, 8, 48, 110, 1182, 248, 8, 85, 58, 36, 32, 65, 3660, 8100], [4, 117, 21, 98, 2965, 395, 6, 61, 59, 84, 624, 12, 127, 1768, 130, 245, 21270, 16, 60, 21271, 21272, 21273], [4, 199, 1, 113, 5, 6, 100, 15, 61, 49, 4, 199, 68, 7, 118, 61, 11, 8, 1071, 15, 117, 211, 350], [4, 199, 1, 7, 1332, 21274, 62, 1314, 57, 4678, 6, 168, 6, 114, 7, 697, 1142], [4, 199, 1, 5, 418, 1856, 125, 11, 327, 21, 610, 13, 14, 4, 199, 1, 262, 20, 520, 38, 52, 46, 3214, 5, 108], [4, 45, 7, 5, 1, 1580, 59, 12, 1943], [4, 5569, 12, 1310, 303, 2, 1], [4, 1251, 12, 458, 21, 5, 114, 37, 20, 165, 1071, 15, 230, 246, 1, 58, 8, 31, 40, 12, 4298, 8, 681, 602, 40, 103, 58, 15], [4, 606, 2, 537, 9, 21275, 122, 6, 436, 15, 1168], [4, 184, 59, 197, 27, 202, 1225, 39, 1, 105, 18, 19, 106, 88, 131, 733, 59, 2, 752, 8894, 1, 21276, 92], [4, 8878, 4, 1256, 4, 21277, 4, 1], [4, 21278, 3110, 12, 18, 3668, 168, 2, 21279, 18, 3112, 7, 23, 1233, 49, 11, 50, 1728, 5, 1, 44, 43, 8895], [4, 268, 21280, 181, 7516, 26, 4991, 220, 81, 4019, 4, 1119, 178], [4, 409, 16, 1, 7, 3, 13, 86, 291, 12, 1570], [4, 2272, 1, 300, 36, 5049, 34], [4, 21281, 39, 1, 180, 321], [4, 1884, 16, 3452, 21282, 2917, 12, 7, 84, 5347, 11, 377, 2120, 49, 21283, 52, 231, 4749, 18, 3304, 21284], [4, 193, 3750, 77, 200, 875, 21285, 12, 85, 3, 58, 48, 302, 39, 9, 1171], [4, 193, 3, 19, 50, 5, 118, 86, 3, 64, 22, 1], [4, 193, 3, 94, 4116, 5, 1, 49, 365, 123, 21286, 233], [4, 193, 2, 21287, 118, 72, 7752, 21288, 12, 4, 193, 4, 72, 21289, 36, 599, 94, 2302, 73, 126, 6691], [4, 2593, 12, 85, 1, 64, 991, 682, 2811, 615], [4, 413, 5554, 136, 132, 59, 4, 21290, 768, 368], [4, 436, 154, 836, 50, 226, 12, 21291], [4, 21292, 1308, 11, 21293, 47, 10, 1, 51, 1212, 213, 206], [4, 324, 1, 29, 3768, 6, 32, 287, 34, 32, 287, 41, 2, 141, 1, 11, 240], [4, 360, 12, 20, 163, 155, 1, 11, 15], [4, 360, 103, 14, 2, 165, 507, 38, 1, 13, 50, 309, 1045], [2843, 1538, 49, 56, 5031], [126, 6563, 110, 31, 15, 21294, 4, 250, 184, 344, 61, 6, 12, 104, 494, 718, 2506, 110, 614, 21295], [126, 146, 14, 2, 2163, 3970, 1259, 3474, 2321, 292], [126, 8896, 664, 12, 21296], [76, 89, 1, 665, 605, 123, 10, 21297], [76, 348, 205], [76, 418, 21298, 157, 17, 793, 4, 739, 55, 23, 48, 2, 1751, 558, 1605, 27, 2, 171, 9, 1168], [76, 315, 252, 271, 27, 4, 832, 21299, 929, 493], [76, 9, 29, 13, 17], [76, 9, 223, 14, 79, 21300], [76, 9, 65, 37, 656, 18, 21301], [76, 206, 3910, 370, 73, 7160, 11, 4, 21302, 439, 4, 24, 28, 21303, 11, 50, 21304], [76, 322, 1, 64, 17, 76, 1, 64, 17], [76, 322, 1574, 1, 76, 3772, 5, 459, 865, 283], [76, 494, 30, 752, 21305, 41, 18], [76, 7786, 6, 1626, 1, 76, 32, 59, 4, 1278, 1], [76, 2066, 77, 14, 9, 6, 194, 54], [76, 45, 183, 282, 21306, 32, 39, 2877, 26, 42, 96, 896, 4433], [76, 8897, 12, 54, 51, 581, 21307, 331, 3, 46, 132, 224, 22, 1, 1427, 691, 26], [76, 8897, 12, 54, 123, 10, 21308, 331, 3, 46, 132, 657, 22, 1, 11, 2, 691], [76, 5130, 49, 104, 340], [76, 21309, 1647, 9, 87, 60, 8840], [76, 287, 51, 4, 904, 410, 49, 116, 21, 20, 21310, 76, 206, 9, 14, 1604], [88, 3, 167, 7, 1, 13, 2, 351, 313], [88, 3, 363, 1077, 11, 748, 6, 869, 82, 21311, 95], [88, 21312, 4, 7610, 510, 641, 76, 27, 98, 1714, 16, 68, 937, 435, 8, 2416, 21313, 36, 510, 73, 750, 73, 21314], [88, 6110, 1, 49, 3320, 8, 23, 18, 2, 5773, 8200, 3, 75, 1800, 32, 7, 45, 5, 1, 14, 21315], [88, 6110, 3, 512, 1, 11, 4, 30, 21, 58, 60, 185, 45, 13, 1250, 10, 347, 74, 912, 10, 21316], [88, 1, 276, 19, 33, 140, 169, 358, 26], [88, 3, 19, 80, 1], [88, 4, 953, 1, 131, 569, 60, 166, 172, 2318, 26, 88, 134, 2497, 75, 569, 117, 30, 364], [88, 116, 22, 185, 1, 11, 10, 521, 7, 599, 136, 6, 191, 2, 938, 155, 106, 4, 3071, 72, 2180], [88, 36, 131, 191, 5, 21317, 938, 1, 33, 113, 17, 57, 5, 87, 17, 6, 58, 8, 139, 5621, 10, 8211], [88, 22, 1, 751, 372, 13, 2, 1766, 14, 955], [88, 78, 4429, 1264, 38, 52, 436, 35, 2, 282, 55], [88, 5, 1560, 309, 31, 5, 210, 1238, 1], [116, 49, 201, 409, 16, 25, 11, 22, 3434, 112, 25, 188, 26, 1, 25], [116, 49, 320, 16, 503, 8598, 4236, 69, 192, 73, 21318], [116, 49, 3403, 116, 49, 2282, 116, 49, 4864, 8, 116, 49, 283, 5, 5045, 12, 2, 21319, 2, 171, 30, 1, 4313], [116, 49, 60, 112, 164, 9, 18, 21320, 2349], [116, 49, 60, 144, 30, 629, 18, 2676], [116, 12, 2, 56, 558, 11, 10, 3713, 7, 132, 116, 21, 13, 201, 21321, 804, 184, 15, 396, 2447, 155, 607, 115], [116, 12, 43, 270, 1585, 73, 21322, 568, 6, 4, 21323, 54, 74, 6943], [116, 12, 295, 329, 27, 3528, 6026, 33, 149, 40, 29, 65, 13, 3034, 78, 146, 2, 21324], [116, 12, 22, 190, 184, 11, 4, 8040, 3, 29, 62, 57, 6, 70, 16, 254], [116, 15, 12, 39, 1, 14, 44, 2198, 4529, 138, 8, 208, 562, 594, 7, 820, 817, 43, 21325], [116, 600, 14, 2, 181, 5560, 1868, 2, 1506], [116, 198, 14, 2, 234, 840, 173, 2152, 6, 159, 8583, 985, 21326], [116, 47, 2, 540, 85, 3, 572, 22, 1], [116, 5, 61, 208, 13, 2, 9], [116, 2, 95, 3904, 11, 10, 8868, 8, 37, 92, 38, 4, 95, 635, 54, 36, 2715, 18, 10, 1832], [116, 2, 511, 808, 97, 1, 2, 97, 228, 20, 1, 3492, 6, 1478, 125, 5, 20, 228, 33, 238, 4546], [116, 2, 875, 1743, 3066, 2, 21327, 3066, 2, 1137, 3066, 2, 866, 3066, 2, 4272, 3066, 8, 2, 4272, 1002, 1637, 3066], [116, 2, 320, 16, 180, 517, 1, 51, 21328, 1198], [116, 2, 1101, 507, 11, 286, 21, 111, 69, 2131, 18, 126, 3942, 21, 190, 480], [116, 1302, 2, 2076, 187, 69, 2, 213, 3984, 130, 17, 79, 3081, 524, 14, 4591, 59, 17, 55], [116, 252, 18, 186, 69, 44, 43, 538, 21, 126, 21329, 21330, 2772, 1142, 21331, 677, 21332, 21333, 119, 830], [116, 152, 14, 2, 320, 16, 56, 81, 225], [116, 146, 14, 13, 787, 120, 56, 1400, 259, 11, 7, 331, 8, 3, 29, 86, 245, 16, 76, 44, 2, 401], [116, 13, 473, 3068, 2, 178, 11, 21334, 45, 56, 55], [116, 13, 68, 16, 10, 500, 7, 96, 716, 2383, 247, 76, 1, 41, 4274], [116, 43, 68, 6, 1657, 27, 214, 1, 11, 10, 21335, 8898, 8898], [116, 48, 602, 115, 11, 4, 755, 6, 359, 18, 50, 31, 40, 249, 20, 138, 1777, 99, 4957, 6, 65, 21, 166, 476, 8, 24], [116, 166, 89, 1], [116, 217, 498, 224, 4, 4779, 2000, 11, 2, 21336, 21337, 27, 179, 21338, 6817], [116, 2, 77, 11, 20, 830, 5, 456, 28, 37, 239, 1], [116, 68, 252, 3, 63, 48, 397, 51, 10, 261, 140, 52, 271, 18, 4, 1554, 77, 8, 77, 82, 166, 261, 149, 553, 1181, 1167], [39, 4788, 9, 14, 784], [39, 49, 4674, 8, 8048, 56, 3311, 328, 1571, 84, 235, 39, 49, 6038, 13, 37, 6038], [39, 89, 1, 109, 46, 7, 89, 38, 5, 94, 2, 327, 16, 21339], [39, 95, 6510], [39, 1, 46, 45, 3, 911, 6, 844, 26], [39, 1, 46, 6, 14, 21340], [39, 1, 46, 21341, 2, 1176, 414, 277, 165, 8327, 130, 4, 21342], [39, 1, 156, 1070], [39, 1, 49, 114, 1115, 277], [39, 1, 14, 1105, 13, 36, 1924, 164, 8, 11, 4, 3556, 831, 3941, 23, 2711, 3002, 26, 58, 322, 148, 219], [39, 1, 132, 1976, 17, 32, 115], [39, 1, 21343], [39, 1, 398, 5923, 128, 410, 21344, 322, 77, 14, 13, 26], [39, 1, 21345], [39, 1, 544, 14, 249, 8, 19, 638, 27, 43, 21346, 131, 728, 2, 21347, 472, 4, 244, 115, 13, 133, 384, 656], [39, 1, 29, 67, 43, 520, 188, 36, 67, 2, 1078], [39, 1, 365, 68, 1204, 81, 59, 2, 9, 244, 1204, 2781, 27, 4, 9], [39, 1, 556, 19, 35, 10, 457, 7048], [39, 1, 356, 13, 1480, 21348], [39, 1, 146, 623, 7, 21349, 1590, 67, 17, 31, 52, 317, 92, 52, 200, 1368, 6039, 230], [39, 1, 21350, 8899, 21351, 8899], [39, 1, 2083], [39, 1, 12, 284], [39, 1, 12, 1060], [39, 1, 1229, 21, 43, 540], [39, 1, 64, 307, 39, 25, 2159], [39, 1, 64, 3559], [39, 1, 64, 21352], [39, 1, 91, 36, 64, 6, 2995], [39, 1, 87, 6, 28, 54, 16, 618, 8, 151, 70, 76, 8524, 647], [39, 1, 109, 14, 54, 135, 18, 2789, 7683, 194, 80, 1, 40, 222, 14, 18, 116], [39, 1, 109, 64, 3559, 54, 135], [39, 1, 109, 791, 6, 60, 613, 30, 25], [39, 1, 532, 13, 1127], [39, 1, 37, 291, 661, 16, 61, 28, 15, 36, 705, 6, 61, 191, 21, 1406], [39, 1, 37, 21353], [39, 1, 81, 45, 34, 36, 3410, 15], [39, 1, 86, 36, 62, 21354, 136, 1, 3, 195, 1396], [39, 1, 67, 4, 244, 237, 184], [39, 1, 1089, 35, 46, 43, 6067, 21355], [39, 348, 49, 859], [39, 348], [39, 1699, 30, 1, 18, 10, 572, 21356], [39, 1120, 25, 14, 433, 39, 1754, 9, 224, 21357], [39, 8900, 578, 8128, 2717, 117, 336, 177, 39, 1, 61, 171], [39, 418, 168, 57, 36, 41, 6, 28, 57, 36, 2197, 666, 16, 3661, 26, 21358, 30, 319], [39, 3932, 9, 49, 156, 18, 2, 21359], [39, 2051, 49, 19, 284, 22, 1, 121, 274, 103, 21360, 17, 140, 50, 1496, 1020, 1227, 54, 16, 50, 4318], [39, 115, 1, 14, 33, 100, 621, 167, 1744], [39, 203, 9, 86, 36, 2274, 448, 833, 35, 327, 8, 45], [39, 77, 1256, 70, 76, 65, 13, 21361, 9, 294, 142, 21362], [39, 77, 61, 6, 261, 27, 32, 698, 2730, 21363, 207, 1349, 11, 126, 21364, 61, 18], [39, 3093, 1, 1060, 602, 6, 249, 2, 260, 138], [39, 21365, 21, 326, 33, 13, 39, 145, 21, 326, 2, 9, 223, 14, 2, 9, 1804, 8, 2688], [39, 9, 30, 153, 3348, 2745, 59, 2, 153, 70, 2, 153, 131, 61, 8, 2788, 4, 1, 35, 459, 153], [39, 9, 25, 8901, 297, 470, 16, 307], [39, 9, 2, 902, 99], [39, 9, 2, 1131, 18, 68, 16, 80, 25, 8, 14, 727, 818], [39, 9, 46, 41, 295, 18, 97], [39, 9, 46, 334], [39, 9, 46, 334], [39, 9, 46, 334, 439], [39, 9, 46, 334, 91, 7, 4, 2166, 758, 3, 297, 1146, 2, 418, 27, 2, 788, 310, 1505, 17], [39, 9, 46, 334, 21366, 3755, 41, 791, 1058, 707, 211, 421, 35, 27, 180, 3081], [39, 9, 46, 334, 8, 25, 46, 519], [39, 9, 46, 21367], [39, 9, 46, 21368], [39, 9, 46, 21369], [39, 9, 46, 45, 3, 46, 840, 102, 2, 8153, 432, 13, 1514, 5, 223, 100, 17, 19, 74, 48], [39, 9, 46, 20, 15, 33, 80, 227, 1517, 42, 465, 17], [39, 9, 46, 334], [39, 9, 46, 20], [39, 9, 156, 223, 593, 224, 6, 69, 182, 134, 76, 701, 51, 4, 106], [39, 9, 49, 1943, 39, 115], [39, 9, 14, 896, 35, 8, 39, 153, 14, 896, 1715], [39, 9, 14, 4655, 251], [39, 9, 14, 912, 879, 38, 36, 28, 2], [39, 9, 14, 21370, 3, 300, 321, 2, 25, 29, 67, 78], [39, 9, 14, 308, 6, 32, 16, 263, 25, 3, 41, 1199, 21, 4, 5985, 25, 80, 1, 19, 5986, 25], [39, 9, 14, 640, 21, 701], [39, 9, 14, 122, 8902, 58, 8902], [39, 9, 75, 19, 125, 5], [39, 9, 284, 3154], [39, 9, 29, 28, 17, 11, 10, 150, 68, 5336], [39, 9, 29, 13, 2, 25, 36, 64, 10, 169, 39, 25, 29, 13, 2, 25, 36, 32, 67, 21371], [39, 9, 326, 9, 55, 61, 51, 245, 1, 394, 42, 28, 50, 1016], [39, 9, 28, 834, 163, 203, 1075, 193, 127, 130, 1725], [39, 9, 525, 2566, 738, 73, 36, 192, 6, 19, 125, 10, 21372], [39, 9, 28, 459, 402], [39, 9, 28, 1220, 146, 194, 76], [39, 9, 61, 291, 122, 6, 65, 4706, 208, 20, 2872], [39, 9, 41, 127, 481, 130, 2, 21373], [39, 9, 146, 389, 21, 10, 2494], [39, 9, 135, 3733, 5, 49, 57, 5, 100, 1077, 350, 8156], [39, 9, 12, 514, 736, 71, 209, 5, 131, 394, 40, 29, 28, 4, 401, 128], [39, 9, 636, 133, 17], [39, 9, 87, 847, 3633], [39, 9, 87, 6, 139, 2111, 866, 8, 167, 4, 1198, 21374, 663], [39, 9, 1551, 139, 238, 3001, 575, 8, 28, 374, 373, 148, 91], [39, 9, 54, 135, 14, 784, 35, 34, 66, 48, 51, 5, 1, 7, 57, 9, 58], [39, 9, 54, 135, 990, 133, 73, 1768, 73, 39, 9, 54, 135, 21375, 78, 665, 8903, 2136, 108, 26, 21376, 411, 26, 28, 169], [39, 9, 54, 135, 1281, 2627, 4624, 25, 165, 742, 35, 545, 147, 21377, 281], [39, 9, 4091, 8, 21378, 7, 85, 39, 25, 21379, 8, 21380], [39, 9, 109, 70, 17, 528, 55], [39, 9, 72, 23, 99, 1572, 3, 86, 23, 99, 209], [39, 9, 1709], [39, 9, 300, 126, 1148], [39, 9, 36, 14, 774, 907, 34, 21381, 46, 43, 501, 31, 794, 774, 75, 44, 1573, 61, 35, 88], [39, 9, 36, 64, 4, 21382], [39, 9, 67, 64, 37, 89], [39, 9, 47, 33, 109, 290, 1926, 60, 2221, 205, 18, 6706], [39, 9, 103, 14, 1459], [39, 9, 475, 133, 4, 329, 184, 11, 164], [39, 2627, 30, 9, 86, 15, 550, 6, 81, 6, 166, 574, 6642, 13, 7, 48, 356, 2174, 342, 6, 24, 907, 32, 129, 4, 507], [39, 265, 91, 112, 164, 265, 48, 110, 129, 1494, 163, 1889, 1, 400, 80, 185, 30, 142], [39, 819, 1, 640, 21, 2, 167, 419], [39, 564, 1, 29, 44, 2, 290, 21383], [39, 161, 9, 400, 1117, 143, 193, 99, 172, 8833, 13, 148, 9, 20, 2662, 882, 130, 201, 995, 82, 922, 166, 242, 4, 286, 35], [39, 161, 25, 75, 662, 180, 45, 1872, 1, 8, 180, 10, 250, 226], [39, 141, 77, 51, 5057, 220, 113, 17, 36, 13, 10, 8838, 1568, 1, 61, 337, 26, 58, 20, 2569], [39, 154, 1529, 49, 256, 21384, 5, 157, 8020, 18, 20, 24, 21, 4, 2046, 422], [39, 153, 21385, 18, 765, 5930, 5269, 2, 8522, 2276], [39, 153, 67, 1317, 134, 17, 57, 5, 41], [39, 25, 46, 45, 34, 9, 27, 843], [39, 25, 14, 896, 13, 1], [39, 25, 347, 14, 21386, 8, 36, 44, 4, 1203, 6, 157, 60, 21387, 3440, 8, 60, 5661, 11, 4, 1], [39, 25, 1953, 39, 1, 36, 41, 21388, 18, 9], [39, 25, 3093, 36, 208, 1128, 130, 39, 9, 58], [39, 25, 2270, 533, 7, 9, 45], [39, 25, 1604, 24, 3, 94, 15, 11, 36, 231], [39, 25, 516, 64, 39, 9, 88, 28, 169, 251, 57, 4, 19, 329, 27, 39, 25], [39, 25, 7974, 1558], [39, 25, 298, 36, 476, 13, 1], [39, 312, 12, 1543, 91, 8, 289, 216, 531, 37, 1016, 6, 1950], [39, 312, 13, 72, 36, 346, 4, 206, 2712], [39, 915, 579, 134, 36, 265, 179, 30, 226, 21389, 280, 49, 5, 686, 7, 1011, 4, 1844, 996, 17], [39, 3167, 2101, 348, 133, 6, 134, 17, 164, 99], [39, 111, 49, 2191], [39, 111, 51, 5967, 8506, 49, 144], [39, 590, 9, 49, 256, 499, 22, 261, 532, 13, 2, 19, 4015], [39, 388, 224, 135, 266, 13, 7, 21390, 7, 1842, 35, 36, 72], [39, 845, 49, 61, 6, 14, 2, 1, 6, 421, 11, 740], [39, 234, 1, 103, 304, 1062, 36, 62, 42, 125, 97, 462, 6, 262, 42, 2398, 21391, 1, 3943], [39, 234, 1, 404, 386, 188], [39, 366, 2786, 14, 665, 307, 13, 1, 15, 80, 1791, 80, 1388, 47, 6016, 982, 44, 132, 366, 288, 5, 47, 554], [39, 386, 16, 1, 510, 173, 84, 21392, 2187, 6, 204, 170], [39, 287, 46, 45, 34, 9, 545, 843, 260, 177, 23, 511], [39, 287, 46, 45, 34, 9, 545, 843, 26, 21393, 5, 511], [36, 49, 2448, 21394, 23, 2, 203, 1989, 31, 5, 44, 127, 130, 787, 1372, 11, 20, 310, 5, 2, 9], [36, 14, 65, 51, 782, 1974, 288, 52, 61, 102, 18, 21395, 2089, 13, 766, 83, 55], [36, 1, 3, 103, 5490, 5, 3388, 17, 6, 20, 1], [36, 79, 17, 1830, 669, 1], [36, 107, 54, 159, 21396, 36, 107, 54, 7897, 4618], [36, 107, 6, 5, 54, 16, 4, 7836, 36, 70, 166, 94, 355, 8, 875, 27, 21397, 36, 652, 156, 202, 74, 4428, 20, 48, 190, 5299], [36, 210, 468, 4, 8870, 355, 1111, 408, 49, 3189, 408, 33, 13, 232, 5709], [36, 58, 4, 24, 93], [36, 1332, 6, 623, 432, 67, 6096, 1, 1868, 35, 21398, 130, 3, 396, 4, 3747], [36, 28, 764, 13, 1, 99, 3, 86, 60, 16, 78, 25, 87, 2, 1865, 8, 1277], [36, 41, 2862, 114, 54, 4, 56], [36, 41, 60, 3392, 30, 9, 54, 135], [36, 41, 4, 786, 365, 3068], [36, 146, 176, 4, 226, 3349, 205, 36, 165, 48, 396, 15, 6, 60, 837, 30, 1094, 226], [36, 124, 2, 2717, 21399, 920, 7, 1, 13, 2, 21400], [36, 2674, 28, 21401, 38, 4, 2746, 16, 549, 2336, 3946, 126, 134, 5, 60, 21402, 177, 49, 36, 979], [36, 90, 18, 5, 140, 36, 62, 5, 89, 456, 14, 58, 256, 117, 31, 5, 41, 39, 1, 5962], [36, 44, 2, 21403, 95, 99, 55, 57, 12, 164], [36, 9, 46, 334, 36, 4380], [36, 64, 17, 51, 4, 507, 3, 316, 10, 347, 21404, 29, 62, 85, 1840, 435, 64, 1566, 601, 3, 58, 65, 13, 2, 4599, 464, 55], [36, 70, 362, 36, 44, 39, 2127, 229, 493, 35, 21, 5, 21405, 266, 338, 5, 314, 8, 21406], [36, 456, 14, 3053, 95, 3053, 95, 49, 1370, 21, 8429, 21407], [36, 109, 198, 8904, 22, 1, 27, 32, 4, 169], [36, 1395, 3, 301, 5, 1, 118, 139, 79, 288, 23, 122, 6, 28, 138, 142, 123, 20, 25], [36, 72, 3, 452, 70, 15, 92, 76, 199, 1, 12, 79, 10, 21408], [36, 72, 164, 12, 57, 5, 70, 15, 1, 34, 23, 33, 238, 70, 15, 233, 344, 35], [36, 72, 518, 29, 308, 1, 23, 48, 4, 378], [36, 72, 68, 91, 56, 12, 4, 244, 91, 21409, 162, 68, 258, 1964, 4, 244, 318, 258, 6811], [36, 72, 305, 654, 95, 12, 21410, 599, 94, 68, 51, 577, 469, 2, 115], [36, 198, 351, 32, 143, 112, 153, 163, 134, 4, 1431, 143, 106], [36, 198, 44, 105, 502, 2, 353, 2, 21411, 103, 788, 38, 52, 94, 1305], [36, 659, 21, 17, 36, 204, 21, 17, 36, 719, 21, 17, 8, 16, 1134, 1627, 14, 80, 1278, 8, 151, 1012, 7, 1, 471, 4, 481, 108, 6, 80, 30], [36, 60, 1, 30, 25], [36, 299, 3, 452, 70, 15, 24, 25, 66, 216, 15], [36, 273, 17, 6, 948, 125, 1, 34, 105, 302, 240, 36, 273, 17, 36, 10, 25, 34, 3, 105, 302, 240], [36, 424, 15, 116, 280, 5, 62, 23, 21412, 304, 2, 691, 649, 29, 28, 179, 2545], [36, 122, 6, 9, 4722, 5928, 2017, 3031, 821, 76, 4489, 8, 41, 102, 34, 3411, 5928, 4, 763, 16, 658], [36, 1174, 9, 4073, 3717, 313], [36, 1588, 21413, 154, 3209, 37, 15, 317, 65, 37, 19, 144], [36, 168, 6, 79, 10, 306, 5364, 38, 40, 47, 6234, 55, 668, 3382, 21414], [36, 220, 114, 2, 406, 8, 3, 486, 2, 95, 635, 722, 8, 3, 47, 13, 241, 95], [36, 452, 100, 17, 168, 10, 206, 406, 149, 10, 343, 47, 21415, 4, 414, 51, 4, 580, 4555, 121, 3, 452, 44, 6, 21416, 1500, 9], [374, 79, 15, 140, 4, 2136, 12, 61, 6, 70, 2, 320, 77, 949, 109, 21417], [834, 1, 18, 135, 122, 6, 580, 18, 17, 21418], [834, 1, 21419], [184, 7, 216, 17, 150, 206, 225, 4115, 1733, 12, 21420], [86, 15, 550, 6, 114, 10, 8905, 8, 421, 15, 19, 5, 1], [86, 59, 28, 10, 628, 21421], [86, 59, 4, 7869, 3025, 3025, 21422, 2402, 496, 70, 17, 528, 51, 577, 469, 2, 921], [86, 59, 122, 6, 28, 24, 21423], [86, 133, 525, 21424, 157, 18, 10, 1340, 218, 23, 28, 169, 1], [86, 133, 212, 5484, 51, 4, 2345, 2692, 205], [86, 7, 3, 279, 29, 134, 2, 19, 133, 5, 86], [86, 20, 4, 8360, 16, 21425, 55, 20, 4, 19, 2076, 1, 720, 31, 814, 41, 2, 437, 107, 6, 588, 1057, 1396, 174, 21426], [640, 30, 1, 29, 1513, 17], [640, 21427, 48, 1252], [640, 972, 143, 1, 21428, 10, 1286, 163, 45, 188, 45, 3, 1135, 22, 209, 21, 4, 2758, 3, 1741, 1144, 2, 1], [22, 21429, 287, 51, 10, 387, 21430, 1], [22, 21431, 1032, 12, 2, 1], [22, 885, 1164, 206, 18, 216, 10, 813, 65, 13, 248], [22, 7654, 4096, 3163, 46, 43, 9], [22, 21432, 1, 47, 2351, 1192, 8, 50, 91, 47, 1921, 2, 21433, 251, 365, 30, 21434, 30, 8906], [22, 5198, 2350, 6292, 6, 1098, 891, 12, 2349, 3, 90, 4, 232, 34, 4672, 1098, 21435], [22, 159, 1012, 178, 12, 322, 961], [22, 1652, 2924, 46, 43, 9, 39, 663, 456, 48, 197], [22, 427, 8907, 159, 4729], [22, 161, 21436, 1, 124, 4, 1203, 6, 79, 10, 310, 81, 284, 133, 71, 40, 28, 142, 579, 157], [22, 953, 1, 603, 33, 167, 17, 27, 50, 347, 8, 40, 21437, 129, 4, 3113, 1571, 33, 37, 40, 222, 58, 15, 2480], [22, 21438, 33, 906, 17, 81, 6, 2, 95, 8, 7, 47, 322, 2091], [22, 674, 782, 639, 19, 67, 6, 21439, 21440, 2, 91, 11, 84, 2963, 252, 5, 46, 120, 43, 690, 71, 5810], [22, 1536, 21441, 8, 21442, 1, 51, 2941, 87, 6, 108, 4, 19, 35, 54, 16, 10, 3563, 11, 493], [22, 46, 43, 1, 30, 3025, 21443, 15, 3076, 21444, 420, 895], [22, 46, 43, 663, 1, 809], [22, 2725, 45, 259, 1115, 1, 176, 4, 396], [22, 14, 549, 12, 21, 4, 942], [22, 14, 419, 45, 12, 109, 56, 1047, 38, 5, 46, 41, 357, 6, 262, 211, 5718], [22, 14, 99, 549, 6, 2508, 12, 21, 4, 95, 3, 47, 192, 6, 150, 4666, 165, 21445, 3, 150, 13, 989, 361], [22, 8908, 33, 79, 17, 2, 1], [22, 7830, 271, 11, 22, 179, 30, 2323], [22, 1], [22, 1, 33, 79, 17, 2, 7623, 835, 205, 802, 1076, 95, 128], [22, 1, 303, 5018, 5577], [22, 1, 6543], [22, 1, 1350, 12, 18, 60, 3553, 74, 256], [22, 1, 3430, 40, 472, 1803, 17], [22, 1, 603, 514, 50, 164], [22, 1, 156, 41, 45, 6, 72, 59, 57, 166, 111, 13], [22, 1, 8, 50, 21446], [22, 1, 191, 17, 85, 3, 29, 167, 50, 21447, 7, 3, 29, 81, 6, 21448, 67, 17, 6, 167, 50, 35, 37, 40, 63, 609, 74, 2182, 755, 790], [22, 1, 191, 85, 1286, 21449, 218, 765, 238, 555, 10, 6586, 35], [22, 1, 51, 4, 1069, 2539, 1761, 17, 235, 21, 5902], [22, 1, 108, 173, 10, 347, 21450, 48, 469, 34, 201, 3017], [22, 1, 133, 6, 70, 17, 1694, 1012], [22, 1, 1051, 50, 21451, 550], [22, 1, 1051, 17, 10, 522, 8, 121, 21452, 640, 83], [22, 1, 107, 337, 125, 2, 2497, 1, 61, 80, 30, 3409, 6, 197, 585, 667, 21453], [22, 1, 1945, 138, 6, 3936, 28, 4782, 188, 13, 29, 73, 5, 4782, 2, 3936, 15, 671, 127, 168], [22, 1, 487, 349, 2, 183, 1773, 2610, 31, 40, 67], [22, 1, 284], [22, 1, 328, 1807, 10, 314], [22, 1, 328, 1807, 10, 314, 8, 3, 47, 314, 102, 32, 16, 39, 692], [22, 1, 976, 344, 539, 4, 21454, 23, 314, 16, 1134, 3, 21455, 110, 31, 3, 407, 3, 1560, 96, 21456], [22, 1, 21457, 21458, 69, 308, 6, 50, 26, 3844, 22, 45, 53], [22, 1, 223, 191, 12, 66, 637, 3, 121, 576, 66, 33, 46, 389, 4, 21459, 22, 707, 447, 1, 66, 637, 28, 364, 54], [22, 1, 152, 719, 2, 1205, 2134, 8, 86, 40, 136, 60, 21460, 3, 72, 66, 429, 4, 4161, 18, 50, 1, 809], [22, 1, 41, 1462, 18, 50, 2242, 264, 21, 748, 21461, 783, 16, 522, 8, 210, 21462, 1419, 672, 4, 201, 21, 787, 51, 21463], [22, 1, 41, 1527, 204, 8, 478, 41, 2, 4331, 21464, 57, 4, 1064, 19], [22, 1, 124, 21465, 8653, 225, 21466, 21467, 50, 1582, 235, 30, 343, 355, 8, 157, 7, 1, 11, 2, 3612, 2615, 251], [22, 1, 136, 268, 401, 8, 12, 192, 261, 18, 4, 21468], [22, 1, 11, 21469, 125, 625, 231, 7529, 40, 2, 275, 4553], [22, 1, 11, 135, 157, 358, 7537, 18, 13, 2, 21470], [22, 1, 11, 581, 618, 41, 957, 2882, 7, 4718, 30, 13, 21471, 38, 3, 737, 50, 30, 15, 4718], [22, 1, 21472, 8, 21473, 21, 17], [22, 1, 12, 345], [22, 1, 12, 1845, 688, 1244, 21, 1448, 30, 23, 37, 328], [22, 1, 12, 214, 140, 50, 91, 359, 34, 40, 359, 99, 85, 5, 214], [22, 1, 12, 530], [22, 1, 12, 878, 10, 3080, 33, 123, 400, 244, 6, 876], [22, 1, 12, 109, 7763, 11, 10, 1253], [22, 1, 12, 109, 152, 400, 135, 8, 113, 17, 3, 87, 2, 915, 596, 17, 51, 4, 1998, 110, 31, 23, 1494, 1158, 43], [22, 1, 12, 37, 589], [22, 1, 12, 3176, 21474, 2733, 3746, 527], [22, 1, 12, 81, 6, 1227, 69, 4, 19, 277, 7, 1, 42, 87, 547, 27, 80, 23, 465, 21475, 11, 10, 235, 233], [22, 1, 12, 238, 192, 45, 51, 6796, 191, 263, 31, 66, 424, 2, 406, 16, 76, 425, 1, 6273], [22, 1, 12, 255, 98, 1076, 95, 2557], [22, 1, 427, 322, 40, 33, 229, 102, 50, 481, 11, 3591, 40, 3365], [22, 1, 33, 1397], [22, 1, 33, 121, 1403, 12, 21476, 43], [22, 1, 33, 262, 17, 260, 260, 5, 346, 17], [22, 1, 33, 262, 17, 54, 4, 759, 133, 67, 94, 50, 6779], [22, 1, 176, 65, 12, 40, 1668, 17, 74, 336], [22, 1, 176, 868, 125, 10, 343, 13, 40, 29, 41, 50, 6635], [22, 1, 543, 17, 54], [22, 1, 599, 33, 349, 2, 8692, 82, 50, 8523, 1440], [22, 1, 599, 33, 121, 21477, 111, 982, 197, 54, 11, 22, 1198, 140, 37, 239, 481, 6988, 2386, 4098], [22, 1, 128, 21478, 21479, 14, 784, 18, 663, 53], [22, 1, 65, 13, 21480, 21481, 1944, 280], [22, 1, 65, 13, 2, 718, 1000], [22, 1, 64, 17, 358, 106, 3, 29, 62, 85, 40, 452], [22, 1, 308, 6, 17], [22, 1, 844, 3685, 21482, 2433], [22, 1, 87, 6, 28, 491], [22, 1, 87, 6, 227, 102, 50, 1096, 451], [22, 1, 18, 3088, 41, 1474, 260, 803], [22, 1, 554, 361], [22, 1, 109, 136, 43, 4007], [22, 1, 121, 53, 678, 68, 49, 5, 53, 805, 3, 90, 50], [22, 1, 121, 4890, 10, 815, 73, 2, 21483, 7903, 21484], [22, 1, 121, 3, 65, 13, 4, 409, 6, 58, 2, 320, 16, 4595], [22, 1, 121, 1358, 58, 256, 5586, 21, 60, 396], [22, 1, 72, 40, 41, 21485, 11, 8321, 57, 4, 19, 12, 7, 908], [22, 1, 229, 17, 15, 26, 31, 78, 155, 297, 7, 702, 5773, 864, 45, 7, 6092, 1353, 939, 88, 2, 9], [22, 1, 981, 868, 13, 4, 5414], [22, 1, 37, 590], [22, 1, 114, 1, 6, 246, 822], [22, 1, 86, 3, 67, 50, 23, 11, 64, 125, 143, 21486], [22, 1, 86, 40, 431, 27, 50, 1488, 688, 1013, 28, 4, 19, 962], [22, 1, 86, 40, 2751, 27, 50, 206, 30, 21487, 28, 4, 19, 18], [22, 1, 299, 4, 341, 1645, 47, 3914, 7885, 69, 364, 157, 3914, 1645, 11, 126, 1672, 6, 2589, 27], [22, 1, 424, 50, 148, 387, 54, 13, 15, 47, 2, 1372], [22, 1, 238, 119, 3167, 23, 238, 119, 2717, 98, 45, 1, 29, 62, 295, 59, 5153], [22, 1, 175, 21488, 152, 114, 2, 21489, 21490, 790, 8729, 21491, 80, 530, 30, 108, 11, 7, 1306], [22, 1, 175, 132, 18, 446, 4, 607, 691, 3, 132, 962], [22, 1, 131, 366, 32, 16, 10, 441], [22, 1, 1349, 178, 686], [22, 1], [22, 1, 87, 6, 28, 15, 117, 20, 37, 2938, 15], [22, 1, 768], [22, 280, 12, 33, 8909, 1880, 2, 95, 59, 546, 995, 82, 5904], [22, 348, 280], [22, 347, 136, 268, 21492, 21493, 398, 1343, 68, 21, 862, 26, 68, 21, 21494, 3537], [22, 418, 65, 13, 40, 344, 35, 424, 2, 207, 3936, 6, 50, 1256], [22, 521, 179, 73, 286], [22, 1739, 98, 786, 178, 47, 2, 286, 16, 2, 178], [22, 277, 1601, 2, 2529, 699, 205, 781, 152, 44, 6, 194, 36, 476, 99, 43, 3674, 21, 609, 1046], [22, 252, 976, 218, 52, 47, 65, 51, 39, 1, 11, 4, 1832], [22, 171, 8872, 484, 11, 2120, 539, 975, 18, 84, 2409, 190, 4753, 27, 451, 21495, 2234], [22, 104, 11, 2, 2474, 47, 8910, 17, 37, 3, 167, 10, 421, 52, 311, 17, 102, 3, 1868, 3496, 52, 311, 17, 102, 361, 6, 14, 2, 141, 8908, 88], [22, 203, 1, 41, 32, 21496, 149, 40, 424, 99, 358, 6, 70, 50, 227, 37, 3, 424, 15, 37, 40, 476, 102, 6, 17], [22, 203, 1, 12, 255, 39, 183, 30, 847, 3921, 8, 50, 180, 30, 995, 49, 21497, 4, 148, 2823], [22, 203, 1, 33, 121, 21498, 106, 29, 627, 10, 1295, 21499], [22, 203, 1, 2281, 21, 60, 684, 853, 48, 276, 308, 3, 118, 14, 99], [22, 567, 95, 178, 1812, 26], [22, 5074, 510, 6, 4, 489, 125, 84, 1, 18, 2, 4149], [22, 172, 95], [22, 19, 141, 1, 1351, 18, 17, 11, 4, 347, 8, 109, 299, 3, 452, 204, 8911], [22, 858, 21500, 5205, 67, 6, 62, 71, 2, 2564, 12, 13, 2, 1053, 21501, 258, 54, 85, 135], [22, 178, 18, 60, 45, 281, 137, 7, 9, 314, 124, 17, 8, 10, 21502, 3225, 281], [22, 178, 633, 17, 102, 1581, 7, 1], [22, 77, 191, 17, 85, 3, 79, 77, 1, 85, 48, 36, 61, 54, 27, 1277, 18, 339, 8, 1580, 59, 71, 93, 36, 49, 249, 138], [22, 77, 12, 144], [22, 77, 12, 4, 21503, 2937, 1, 289, 182, 4772, 58, 48, 302, 876, 40, 12, 2, 2943, 659], [22, 77, 2824, 65, 13, 2, 1072, 605, 5761, 5, 1], [22, 189, 12, 1843, 726], [22, 189, 12, 6922, 3, 683, 154, 184, 155, 115, 42, 4, 101, 68, 96, 533, 133, 2511, 8154, 116, 61, 7, 1108, 3016], [22, 21504, 11, 4, 1483, 223, 191, 21505, 827, 793, 7, 21506, 22, 1, 121, 50, 734, 1667], [22, 5513, 2, 83], [22, 4992, 12, 2, 1], [22, 9, 347, 532, 13, 25, 100, 102, 2, 789, 1295, 859, 11, 50, 45], [22, 9, 41, 546, 710, 6, 28, 4, 286, 35, 459, 10, 231, 230, 3, 644, 7, 1349, 18, 21507], [22, 9, 41, 2, 1661, 34, 733, 59, 164, 13, 12, 40, 167, 5, 117], [22, 9, 11, 135, 7233, 554, 91, 114, 80, 30, 337], [22, 9, 21508], [22, 9, 6107, 14, 840], [22, 9, 344, 35, 4685, 18, 17, 13, 162, 200, 5, 61], [22, 9, 1041, 123, 4, 360, 251], [22, 341, 30, 202, 77, 82, 186, 568, 6, 7740, 649, 7, 21509, 3, 299, 40, 47, 60, 21510, 30, 1, 82, 1634, 423], [22, 341, 1018, 8, 1303, 1733, 99, 859, 117, 92], [22, 71, 247, 16, 78, 234, 9, 223, 65, 18, 1987, 115, 55], [22, 609, 1, 18, 4455, 121, 1205, 44, 43, 1036, 18, 126, 6899, 251], [22, 12, 1314, 85, 3, 29, 113, 22, 1, 45], [22, 12, 8912, 5482, 8, 52, 41, 214, 7, 3, 273, 170, 7, 52, 532, 13, 2, 1], [22, 12, 2, 358, 190, 21, 2, 666, 16, 1345, 21511, 48, 2, 3435, 44, 1041, 2746, 6, 7626], [22, 12, 2, 643, 2974, 27, 2, 21512, 1337, 227, 6, 3335, 21513, 6, 1056, 102, 4, 355, 1111, 11, 4, 8708], [22, 12, 165, 130, 567, 1187], [22, 12, 1314, 85, 1, 450, 35, 544, 273, 170, 6, 139, 19, 27, 17, 3, 293, 15, 1234, 83], [22, 12, 19, 35, 128, 678, 68, 49, 5, 165, 61, 6, 21514], [22, 12, 19, 144], [22, 12, 19, 248, 898, 12, 5258, 99, 37, 379, 169, 12, 4, 2636, 8483, 92], [22, 12, 434, 1818, 26, 1894, 1071, 10, 1074, 8, 1014, 15, 11, 4, 5725, 52, 2, 285], [22, 12, 71, 23, 191, 10, 1, 6, 2358, 74, 21, 50, 6, 791, 17, 21515, 367], [22, 12, 71, 5, 62, 21516, 12, 2307], [22, 12, 10, 21517, 952, 231], [22, 12, 43, 919, 6, 79, 17, 1, 5, 41, 21518, 2498], [22, 12, 109, 21, 4435, 1055, 190, 21519, 604, 1512, 22], [22, 12, 37, 209, 501], [22, 12, 21520, 159, 2193, 4, 5875, 2333, 992, 58, 254, 43, 1726], [22, 12, 85, 12, 2, 171, 30, 9], [22, 12, 85, 10, 639, 427, 1166, 6, 70, 348], [22, 12, 85, 43, 68, 13, 350, 140, 20, 2, 83, 8, 2, 2639], [22, 12, 85, 295, 28, 2433, 2541, 13, 21521, 122, 201, 1401, 2, 743, 3268, 201, 2, 775, 197, 7190, 842, 108, 18, 4], [22, 12, 85, 111, 49, 811, 36, 101, 799, 27, 2051, 129, 4, 3692, 116, 14, 2, 320, 16, 955, 54, 1, 31, 22, 47, 328, 11, 395], [22, 33, 11, 29, 302, 39, 9], [22, 265, 344, 194, 2, 1, 119, 50, 373, 3049, 5290], [22, 265, 65, 13, 2, 144, 38, 52, 122, 869, 84, 7803, 37, 3990], [22, 4376, 178, 12, 37, 144, 117, 92, 251], [22, 564, 2671, 8049, 25, 156, 81, 133, 52, 14, 4, 540, 116, 156, 190, 2050, 21522, 11, 4, 21523], [22, 161, 593, 1, 109, 122, 6, 298, 178, 18, 17], [22, 1722, 1, 21524, 11, 4, 521, 23, 98, 1457, 11, 12, 1428, 356], [22, 141, 3797, 107, 4920, 8294, 32, 4, 106, 33, 6, 58, 84, 141, 2322, 742, 21525, 8, 122, 6, 72, 15, 51, 17, 13, 23, 152, 309], [22, 581, 145], [22, 91, 21526, 146, 14, 551, 52, 62, 148, 219, 52, 29, 1181, 43, 9], [22, 3856, 348, 4888, 12, 216, 27, 21527, 21528, 3333, 4944, 2196, 3333, 2334, 8, 3333, 2125], [22, 561, 12, 1051, 6, 5, 123, 21529, 3, 109, 87, 6, 628, 22, 21530, 624, 11, 4, 5246], [22, 451, 12, 56], [22, 10, 1, 333, 231], [22, 10, 381, 113, 17, 52, 12, 328, 137, 7996, 21, 3448, 1810, 3728], [22, 154, 830, 56, 74, 336], [22, 154, 45, 23, 5934, 8620, 447, 399], [22, 153, 33, 409, 6, 21531, 49, 727, 624, 21532, 37, 23, 624, 1547, 128], [22, 312, 21533, 176, 616, 21534, 7, 1326, 17, 55], [22, 25, 146, 804, 315, 845, 21535, 23, 549, 16, 78, 100, 22, 2339, 158, 1099], [22, 25, 1579, 2241, 41, 2, 940, 2, 104, 21, 2, 386, 233, 52, 124, 6, 44, 328, 60, 2996, 45, 6999, 35, 2706], [22, 25, 132, 32, 11, 775, 27, 84, 154, 379, 1, 7754, 15, 11, 50, 231, 34, 38, 40, 3818, 15, 21536, 40, 415, 46, 110, 297, 898], [22, 25, 4705, 712, 532, 13, 89, 24], [22, 25, 244, 6, 17, 1070, 466, 8, 32, 52, 67, 6, 58, 12, 1552, 927, 1, 8, 733, 59, 71, 23, 70, 4, 712, 1448], [22, 25, 18, 4, 1036, 557, 84, 1, 129, 4, 310, 128], [22, 25, 129, 135, 113, 17, 52, 29, 19, 27, 22, 1, 26, 38, 52, 58, 26, 74, 485, 40, 308, 55], [22, 25, 121, 5, 46, 61, 539, 45, 5, 33, 87, 667, 4644, 93, 122, 9, 15, 132, 2, 288, 34, 15, 109, 667, 45, 61, 2014], [22, 25, 229, 17, 7, 611, 30, 381, 10, 77, 2380, 118, 65, 51, 7, 9, 8, 72, 25, 223], [22, 25, 4117, 21537, 8031, 58, 1579, 843, 26, 52, 96, 46, 28, 43, 24], [22, 25, 86, 52, 223, 137, 17, 512, 3010, 100, 80, 9, 1941, 17], [22, 25, 6, 10, 440, 183, 88, 2, 1], [22, 145, 12, 2, 902], [22, 145, 5966, 124, 17, 669, 215, 264], [22, 145, 165, 375, 6, 316, 84, 7313], [22, 145, 62, 1287], [22, 145, 121, 2229, 605, 17, 539, 4, 310, 65, 3115, 281], [22, 145, 598, 109, 21538, 7079, 552, 59, 7], [22, 4023, 121, 3, 14, 2057, 1], [22, 2308], [22, 399, 41, 495, 1372, 73, 1206, 55], [22, 399, 109, 122, 6, 290, 17, 18, 4, 1195, 129, 2, 4953, 5901, 1457, 8799], [22, 43, 990, 184, 12, 21, 4, 95], [22, 1294, 12, 168, 6, 1381, 21539], [22, 206, 1, 27, 4494, 1169, 498, 18, 4, 3367, 27, 17, 12, 21540, 37, 89], [22, 68, 21, 384, 1792, 1, 7, 1495, 51, 1884, 21541], [22, 68, 264, 3, 47, 840, 102, 348, 3, 157, 10, 298, 845, 18, 8, 3, 47, 96, 11, 7438, 15, 47, 3978], [22, 406, 18, 21542, 216, 3253, 5828, 1299, 7737, 190, 6105, 6, 15, 1304, 16, 1742, 1067], [22, 24, 3640, 130, 21543, 5958, 2205, 3640, 647], [22, 1234, 41, 78, 287, 81, 54, 20, 8800, 2, 25, 198, 1049, 3843, 16, 84, 4286, 18, 2, 1, 321, 28, 39, 9, 4, 19, 459, 135], [22, 1107, 742, 323, 4, 395, 244, 6, 17, 12, 477, 6, 70, 17, 131, 70, 2, 2108, 169, 8, 19, 2, 2108, 319, 3, 150, 254], [22, 21544, 406, 16, 21545, 6287, 12, 68, 16, 4, 3615, 184, 289, 297, 11, 2, 288], [22, 1093, 17, 16, 246, 2561, 496, 649, 52, 46, 21546, 6, 580, 21, 39, 2710], [22, 45, 12, 2, 178, 117, 3448, 7, 85, 3, 137, 319], [22, 45, 12, 1720, 6, 665, 10, 21547, 1458, 21548, 108, 11, 22, 1], [22, 45, 12, 144, 26], [22, 45, 117, 135, 8913], [22, 45, 21549, 248], [22, 234, 9, 455, 418, 81, 12, 8090, 28, 2, 164, 91], [22, 323, 12, 4, 21550, 296, 131, 19, 20, 2781, 21, 68, 264, 21551, 5, 86, 7, 1, 80, 2781, 34, 40, 14, 32, 18, 986], [22, 323, 600, 14, 21, 339, 1, 34, 15, 270, 2, 2156, 4829], [22, 1116, 1, 2298, 21552, 3, 454, 71, 40, 28, 10, 518], [22, 1333, 12, 37, 21553], [22, 1607, 79, 17, 6, 1, 59, 50, 8502, 3, 113, 3036, 23, 94, 98, 4662, 135, 73, 48, 21554], [22, 4741, 3180, 12, 14, 2, 1082, 1, 6, 2, 21555, 107, 18, 229, 60, 538], [22, 2176, 12, 179, 34, 766], [22, 578, 13, 3513, 24], [22, 7, 1, 25, 45, 36, 4690, 15, 3, 33, 1601, 4, 1067], [22, 106, 2, 264, 991, 682, 25, 109, 227, 173, 1613, 25, 3, 300, 3, 297, 2, 3422, 122, 303, 2941, 21556, 892, 34, 36, 637], [22, 304, 184, 12, 21, 4, 4425], [22, 47, 10, 8914, 1448, 7, 269, 21557], [22, 449, 21558, 6098, 12, 11, 4, 2960, 3, 2277, 21559, 14, 2, 104, 1603, 654, 33, 13, 21560], [22, 1414, 1222, 16, 588, 109, 87, 2, 93, 1, 21561], [22, 120, 1, 472, 73, 4, 1377, 51, 10, 3629, 241, 4, 5864, 55], [22, 120, 1, 124, 4, 172, 1203, 6, 79, 17, 2, 25, 38, 40, 4, 68, 5305, 21, 50, 767, 6, 28, 7605], [22, 120, 1, 122, 6, 644, 17, 35, 21, 2, 3382, 1317, 188, 55, 1, 15, 4522, 23, 3785, 88, 5], [22, 413, 178, 289, 132, 122, 6, 1244, 54, 85, 4, 7097, 49, 255, 1343, 1936], [22, 85, 3, 14, 18, 4, 1, 37, 209, 36, 477, 6, 17], [22, 1319, 210, 253, 17, 4607, 251], [22, 197, 45, 21, 4, 21562, 86, 15, 114, 885, 755, 6, 58, 21563], [22, 360, 87, 2, 1478, 2, 1, 6644], [1305, 1639], [1305, 1639], [212, 8606, 17, 59, 630, 53, 541, 30, 25, 188, 272, 284, 1, 7, 32, 5, 87, 6, 1507], [212, 104, 7, 176, 448, 315, 30, 496, 16, 76, 2126, 27, 126, 1661, 18, 3928], [212, 189, 49, 4, 857, 16, 120, 56], [212, 10, 2545, 833, 92, 236], [2310, 2618, 48, 382, 21564, 21565], [299, 3, 273, 5, 48, 6, 302, 39, 9], [299, 16, 50, 220, 93, 82, 3281, 8, 4, 884, 38, 40, 458, 50, 21566, 16, 4, 761, 12, 36, 65, 789, 34, 39, 9, 2844, 2549], [1058, 141, 95], [313, 2, 21567, 18, 20, 789, 1913, 8, 326, 316, 5, 2336, 8, 1092, 6, 10, 967, 83, 5, 994, 110, 1048, 5, 1451, 1054, 1926, 135], [313, 60, 1685, 18, 147, 1], [313, 7, 1736, 1, 5, 46, 4, 112, 2514], [313, 739, 353, 51, 347, 7, 45, 12, 356, 73, 19], [21568, 5, 117, 11, 4, 977, 1], [1903, 109, 132, 56, 22, 658], [21569, 120, 3295, 1130, 137, 22, 696, 11, 21570, 51, 4, 21571, 21572, 27, 159, 21573, 4, 244, 21574], [8915, 21575, 5473, 5281, 1, 40, 12, 20, 8915, 21576, 7448, 52, 37, 589], [4684, 21577, 1109, 21578, 35, 80, 9], [1683, 9], [3339, 49, 172, 1439, 847, 21579, 2, 138, 21580, 20, 33, 73, 56, 73, 7, 370, 30, 6345], [634, 21581, 2138, 147, 9], [7912, 10, 8224, 108, 935, 10, 977, 114, 2, 2787, 11, 10, 1009, 28, 6, 62, 17], [106, 201, 204, 201, 95, 27, 378, 4215, 197, 54, 288, 3, 7224, 10, 522, 21582, 1092, 4904, 842, 137, 21, 22, 171, 521], [106, 21, 618, 1258, 1], [106, 21, 60, 8817, 1], [106, 907, 70, 17, 623, 71, 209, 102, 2, 104, 3, 47, 55], [106, 6, 61, 70, 4, 1198, 10, 1], [106, 6, 192, 1304, 6, 6738, 1594], [106, 6, 1985, 18, 39, 9], [2649, 54, 135, 65, 13, 98, 1376, 355, 1359, 4791, 82, 2, 961, 177, 941, 1728], [515, 16, 9, 91], [515, 16, 39, 4293, 8628, 97, 310, 56, 6962, 66, 29, 67, 240], [515, 16, 39, 9, 1238, 10, 21583], [515, 16, 39, 25, 227, 275, 173, 861, 35, 1], [515, 635, 38, 3, 3711, 4, 21584, 10, 5681, 341, 8, 39, 9, 1026], [815, 579, 24], [909, 1807, 35, 9, 18, 3464, 1270, 52, 46, 21585, 78, 9], [6, 2, 689, 1, 1192, 768, 12, 21586], [6, 14, 1891, 3, 29, 86, 116, 245, 1180, 21587, 338, 21, 21588, 34, 15, 501, 6, 382, 4, 8243], [6, 239, 171, 9, 11, 6328], [6, 239, 25, 8, 48, 602, 9, 8, 247, 16, 5, 25, 208, 13, 9], [6, 4, 1526, 521, 116, 103, 14, 354, 21589, 904, 11, 4, 913, 22, 561], [225, 3, 566, 10, 900, 72, 21590, 368, 13, 15, 47, 37, 356, 426, 40, 136, 98, 668, 3369], [225, 136, 132, 2, 1, 3, 167, 531, 11, 4, 231, 27, 2, 7391, 3, 514, 13, 473, 1381, 16, 591, 1414, 8, 23, 21591, 267, 5], [225, 12, 21592, 3, 87, 6, 404, 37, 10, 1586, 63, 5110], [225, 12, 501, 34, 3471, 103, 14, 8916, 2545], [225, 47, 33, 2198, 18, 2198, 18, 2198, 16, 60, 3338, 125, 10, 145], [225, 2735, 2175, 647, 643, 4233, 21593, 36, 118, 150, 93, 18, 21594, 8, 8826, 64, 4, 2994, 3266, 18, 4, 166, 513], [225, 2735, 2175, 21595, 508, 87, 2, 656, 735, 21596, 3, 394, 22, 4951, 1465, 532, 21597], [225, 2735, 2175, 647, 2, 823, 189, 27, 180, 21598, 3, 8917, 6, 735, 84, 508, 163, 5331, 508, 18, 10, 968, 513], [273, 143, 153, 2544, 35, 6, 84, 231, 21599, 52, 41, 784, 18, 3, 67, 21600, 52, 1559, 60, 409, 16, 193, 133, 15], [273, 50, 1671, 15, 1638, 2718, 54, 22, 1, 8, 23, 2900, 11, 1708, 21601, 47, 13, 2673, 38, 66, 41, 21602, 13, 21603, 45, 29, 1299, 562], [273, 10, 1, 3, 29, 131, 119, 23, 169, 807], [273, 10, 586, 6, 61, 303, 851, 21, 4, 1851, 21604, 25, 1048, 4613], [273, 7, 9, 40, 1101, 13, 4, 21605, 51, 21606], [273, 7, 9, 6, 249, 15, 35, 40, 41, 767, 13, 4133, 1438], [273, 97, 707, 892, 159, 407, 21607, 21608, 12, 244], [3674, 57, 11, 4782, 8816, 21609, 213, 377, 44, 132, 2, 1964, 11, 305, 21610], [782, 1974, 12, 4, 796, 24, 11, 4, 1593, 123, 750], [4535, 56], [740, 7126, 2338, 348, 26, 1550, 2, 535, 458, 1728], [1200, 1077, 50, 24, 74, 29, 2361, 119, 50], [390, 3, 146, 114, 2, 961, 30, 406, 125, 2, 89, 1, 288, 23, 551, 37, 3, 63, 396, 10, 7189, 23, 515, 16, 94, 22, 68, 330], [390, 192, 4, 1540, 4, 889, 1743, 21, 4, 135, 66, 61, 348, 135, 66, 61, 1659, 1659], [1146, 10, 508, 1405, 12, 6, 14, 21611, 21612, 264, 102, 8, 43, 521, 11, 4, 2975, 485, 3, 655, 15], [1458, 8123, 1805, 2514, 1], [1458, 4388, 12, 70, 5611, 2890, 84, 1, 27, 4, 68, 18, 68, 74, 33, 1823, 170, 102, 4, 21613, 98, 421, 60, 148, 2303], [99, 89, 2262, 21614, 427, 152, 44, 7, 21615, 3787, 51, 21616], [99, 1026, 21, 4, 1599, 99, 2913, 21, 4, 21617, 124, 6, 4677, 10, 206, 1, 525, 1339, 125, 4, 1616], [99, 141, 99, 713, 1, 30, 25], [99, 239, 89, 1, 215, 264], [99, 239, 1, 41, 21618, 8, 3, 90, 2, 236, 6536, 414, 21619, 414], [99, 239, 418, 122, 14, 21620, 1, 14, 630], [99, 239, 322, 1, 41, 4, 3293, 977, 21621, 355, 21622], [99, 209, 1631, 37, 2278], [99, 209, 45, 61, 18, 6, 799, 27, 246, 1, 4019, 749], [99, 475, 133, 1, 26, 1698, 36, 61, 346, 11, 4848], [424, 21623, 16, 1361, 21624, 21625], [424, 3373, 6, 26, 82, 21626, 21627, 489, 215, 3270, 21628, 21629, 3726, 130, 4, 5902, 21630, 124, 21631, 1037, 6, 313, 51, 4, 319], [424, 2, 291, 1, 25], [424, 80, 1, 8, 502, 50, 108, 10, 1758], [503, 473, 21632, 24], [503, 21633, 9, 28, 4, 247, 48, 4, 5330], [966, 1780, 147, 9, 898, 2665, 18, 7, 1704, 3178], [3676, 9, 188, 3676, 9], [7142, 3366, 347, 2909, 8, 4, 1160, 47, 1112, 123, 21634, 11, 4, 21635, 21636, 27, 2, 348, 8, 1087, 94, 15, 32, 21637], [2924, 11, 4, 21638, 21639], [21640, 56, 8879, 106], [3502, 462, 12, 2, 1, 5293, 10, 402, 216, 17, 1373, 50, 272, 1470, 21, 2, 959, 740, 8, 552, 3, 29, 13, 50, 40, 122, 6, 421, 17], [3858, 21, 4, 981, 52, 54, 492, 9, 378, 123, 378, 54, 135, 492, 259], [941, 692, 14, 28, 32, 698, 16, 1, 128], [941, 1400, 3, 14, 8918, 13, 2, 1, 430, 17, 35, 11, 2924, 318, 14, 8918, 27, 80, 1, 160], [56, 202, 111, 101, 137, 5963, 26, 1443, 907, 51, 126, 21641, 60, 6752, 8, 21642, 490, 87, 6, 8904], [2278, 94, 71, 3, 3834, 4, 21643, 11, 2278, 369, 12, 22, 354, 323, 123, 523, 3885, 364], [7050, 80, 9, 13, 40, 80, 21644, 13, 7, 1039], [1839, 201, 2008, 1044, 4269, 592, 11, 56, 11, 21645], [2684, 3472, 63, 751, 34, 75, 428, 117, 2, 93, 3037, 2684, 3472, 12, 101, 3789, 140, 16, 640, 202, 1], [2684, 3472, 363, 11, 18, 7, 2919, 30, 952, 1257, 6, 1704], [840, 466, 21646, 1], [302, 2, 1, 3, 75, 436, 2, 1, 3, 75], [302, 17, 38, 3, 72, 1735, 3776, 505, 13, 2, 19, 1], [302, 17, 38, 3, 72, 5, 982, 302, 50, 31, 40, 175, 21647, 482, 6, 321, 112, 21648, 101, 9, 63, 405, 25, 4760, 4897], [302, 43, 25, 1293, 43, 1], [302, 43, 781, 1293, 43, 83], [302, 553, 1, 3, 29], [302, 553, 1, 3, 29, 436, 2, 1, 1, 3, 266], [910, 101, 2, 104, 118, 227, 142, 1031, 24], [910, 14, 273, 6174, 32, 10, 24], [910, 12, 672, 190, 1979, 73, 2, 21649], [910, 12, 20, 59, 73, 3341, 73, 2, 7261, 83], [21650, 34, 1, 42, 595, 205, 289, 132, 206, 32, 10, 206, 30, 1068, 8, 7, 4394], [21651, 488, 398, 88, 638, 12, 24, 579, 151, 1318, 240, 398, 579, 5804, 21652, 123, 10, 25, 100], [122, 21653, 154, 591, 2313, 21654, 21655, 353, 2163, 27, 602, 21656, 73, 6, 70, 320, 436, 65, 21657, 101, 21658, 2, 874], [122, 6, 114, 21659, 692, 1, 23, 21660, 35], [238, 14, 21661, 2837, 1232, 439, 92, 3, 75, 302, 245, 1, 125, 24, 7, 578, 13, 2837, 1232], [238, 4298, 31, 40, 2, 89, 1, 34, 88, 186, 492, 50], [238, 28, 6, 337, 13, 1095, 6, 1095, 6, 1095, 3237, 65, 13, 1260, 16, 4, 2787, 673], [238, 492, 2, 9, 7, 29, 131, 14, 492, 1171, 1171, 1171, 48, 17], [3939, 12, 93, 4, 763, 56, 63, 16, 2238, 247, 1784, 522, 136, 6, 14, 245, 1734, 11, 2, 63, 3939, 1581], [2316, 222, 19, 245, 1, 11, 4, 360, 11, 4268, 8, 25, 18, 135, 345, 59, 2, 327, 52, 424, 21, 1], [21662, 2, 9, 21663], [227, 2, 19, 399, 6, 2, 21664], [227, 2, 9, 173, 2, 331, 436, 5, 394, 48], [227, 15, 35, 27, 581, 142, 1], [227, 18, 4, 1579, 16, 207, 8059], [227, 4, 1119, 19, 35, 9], [5762, 18, 32, 16, 5, 9], [4784, 372, 13, 3004], [2587, 9], [5071, 9], [1547, 2285, 660, 1382, 5874, 979, 72, 1603, 12, 3338, 21, 6103, 8919, 730, 2942], [1547, 2285, 660, 1382, 5874, 979, 72, 1603, 12, 3338, 21, 6103, 8919, 730, 2942], [1347, 49, 37, 21665, 678, 12, 5759, 140, 36, 49, 1207], [186, 178, 12, 18, 446, 390, 1906, 189, 31, 5, 745, 906, 18, 20, 392, 1633], [186, 136, 1460, 17, 7, 116, 49, 37, 239, 1, 216, 25, 11, 4, 360, 29, 14, 902], [186, 12, 21, 2191], [186, 12, 13, 4, 228, 3, 601, 627, 6, 1550, 8, 88, 52, 79, 8, 208, 13, 2, 2822, 21666, 27, 2, 234, 16, 83], [186, 12, 56], [186, 100, 5, 62, 69, 155, 9, 12, 11, 155, 620, 8, 823], [186, 25, 156, 67, 5, 6, 44, 7540, 352, 27, 39, 295, 30, 283, 336], [186, 327, 21667, 9, 533], [186, 194, 283], [186, 20, 14, 2, 1], [186, 141, 759, 95, 226, 12, 2206, 211, 4588, 21668, 2206, 95, 741, 21669, 12, 21670], [268, 1958, 391, 131, 605, 32, 264, 3, 33, 1646, 6, 274, 7, 22, 45, 61, 117], [268, 115, 223, 40, 132, 223, 37, 358, 5, 75, 28, 50, 18, 4, 310, 218, 7, 1, 328, 132, 125, 8121], [268, 391, 8632, 129, 2, 1, 55, 3943], [268, 1797, 9, 1409, 13, 4, 339], [268, 9, 53, 78, 62, 57, 66, 49, 53], [268, 1808, 189, 137, 27, 2, 643, 8228, 1263, 5701, 24, 230, 36, 21671], [268, 1808, 189, 114, 227, 257, 4, 45, 54, 16, 2, 926, 1328, 21672], [268, 355, 1006, 5975, 163, 143, 108, 930], [268, 213, 870, 27, 22, 1391], [1655, 8, 898, 268, 480, 682, 1, 34, 31, 124, 6, 1668, 11, 2, 290, 3, 118, 61, 27, 4, 189, 82, 21673, 129, 4, 68, 82, 8836], [1655, 12, 2, 9, 52, 6111, 11, 10, 6092, 21674, 66, 133, 6, 290, 321], [2976, 10, 83, 370, 34, 3, 373, 350], [21675, 201, 21676, 325, 866, 163, 2661, 410, 319], [409, 16, 153, 1632, 622, 169, 34, 96, 191, 5, 6, 61, 163, 18, 2, 866], [1413, 1, 985, 2, 421, 35, 175, 1737], [1413, 90, 21677, 1288, 151, 8, 183, 391, 56, 1072, 535, 5033, 6342, 8, 21678, 21679], [21680, 1689, 96, 28, 1135, 21, 39, 770, 244, 503, 1263, 2410, 298, 22, 1, 37, 5495], [4003, 56], [42, 161, 185, 30, 1, 3, 46, 19, 125, 21681], [42, 1, 96, 4247, 2514], [42, 75, 271, 4, 199, 26, 772, 6870, 42, 75, 1786, 772, 2, 93, 91, 31, 52, 79, 1399, 25, 21682, 196, 4, 4787, 2, 43, 93, 395], [42, 490, 75, 304, 6, 255, 76, 354, 2809], [42, 490, 194, 64, 8, 1443, 907, 46, 5], [42, 1901, 635, 88, 1, 38, 15, 136, 43, 3484, 8, 15, 6154, 875, 27, 392, 16, 2350, 32, 129], [42, 182, 297, 2, 1, 81, 45, 59, 246, 1, 88, 42, 94, 76, 662, 612], [42, 2143, 1, 3251], [42, 41, 2, 1883, 618, 80, 1, 30, 165, 48, 1713, 50, 129, 6, 80, 967, 42, 165, 102, 376, 18, 2, 21683, 10, 177], [42, 41, 25, 98, 3, 41, 1], [42, 9, 21684, 11, 21685, 225, 46, 78], [42, 62, 7, 24, 93, 38, 15, 372, 13, 42, 1223, 4594, 38, 42, 167, 15, 55], [42, 62, 22, 1, 332], [42, 65, 13, 2, 391, 11, 174, 327, 55], [42, 25, 1138, 13, 17, 3, 394, 3, 63, 1481, 80, 1, 205], [42, 16, 2, 9, 545, 4, 517, 3659, 54], [42, 18, 4, 167, 1304, 6, 1, 204, 80, 653], [42, 21686, 42, 21687, 73, 2, 2089, 9], [42, 94, 2, 889, 89, 1, 11, 4, 489, 27, 2, 25, 7, 42, 33, 75, 594, 71, 52, 41, 50, 5918, 1180, 52, 563, 50, 51], [42, 686, 280, 55, 8137, 570, 95, 1101], [42, 96, 19, 27, 20, 206, 1, 974, 13, 45], [42, 362, 794, 1, 46, 21688, 129, 544, 55, 4, 593, 12, 54, 135, 26], [42, 86, 76, 312, 42, 27, 12, 27, 42], [42, 131, 633, 2, 9, 102, 38, 42, 11, 4, 489, 26, 40, 11, 580, 42, 238, 856, 21, 42, 58, 57, 23, 58, 117, 92, 175], [42, 67, 2, 180, 21689, 21690, 6, 1089, 97, 3440, 2042, 3, 772, 2, 418, 51, 143, 4168, 347, 1089, 6, 2256, 10, 3440, 16, 32, 3942, 3553], [42, 67, 6, 61, 11, 4, 2388, 34, 80, 1, 30, 487, 806, 357, 512, 51, 42, 37, 242, 80, 663, 476, 8, 212, 69, 200], [42, 454, 85, 23, 48, 729, 23, 454, 162, 10, 169, 51, 25, 208, 13, 1, 39, 115], [42, 266, 94, 17, 3062, 882, 3, 41, 1605, 1386, 4, 237, 1, 11, 164], [1588, 1058, 21691, 211, 4950, 315, 189, 440, 11, 2991, 4383, 211, 14, 181, 2546, 11, 7764], [263, 2735, 2185, 49, 635, 129, 2252, 2623, 11, 2280, 21, 377, 1050, 21692, 27, 3865, 5260, 527], [1035, 3, 75, 397, 2, 1, 7, 366, 202, 26, 21693, 36, 70, 17, 4475], [1035, 3, 172, 90, 38, 22, 1, 29, 729, 10, 79, 8479], [1035, 3, 109, 75, 304, 6, 28, 1135, 740, 8, 1049, 15, 18, 10, 9], [1035, 23, 270, 2, 141, 1], [1035, 89, 1, 406, 107, 738], [1035, 52, 588, 1, 52, 588, 26, 588, 5746, 7, 10, 260, 10, 720, 33, 62, 26, 14, 8510, 7, 17], [1035, 13, 3, 90, 38, 10, 734, 28, 6, 81, 32, 4512, 13, 1, 5750], [1035, 7, 284, 1, 11, 4, 21694, 251], [183, 30, 9, 131, 14, 17, 37, 89, 1, 223, 18], [183, 1, 156, 1174, 114, 327, 82, 4, 199, 4678, 380, 15, 36, 237, 234], [183, 1, 62, 6, 28, 54, 4, 967, 230, 4, 2192, 107, 35], [183, 1, 477, 78, 63, 48, 14, 1412, 2, 1116, 2497, 78, 29, 44, 295, 197, 21, 5, 34, 20, 395, 37, 29, 19, 15, 562], [183, 1, 448, 4, 247, 144, 45, 18, 685, 7944], [183, 1, 271, 1341], [183, 19, 158, 2727, 299, 15, 47, 2, 3342, 51, 21695], [183, 9, 443, 493, 584, 750, 82, 21696, 3, 14, 13, 576, 9, 5, 3857, 130, 5, 86], [183, 9, 5, 63, 48, 44, 764, 204, 4, 590, 5, 87, 6, 14, 417, 149, 20, 65, 362, 46, 28, 5, 2488], [1158, 4128, 79, 17, 2, 1043, 30, 1, 8, 3, 121, 3, 86, 5, 1456, 6, 72, 900, 30, 1, 34, 151, 100, 15, 61, 1335], [1158, 241, 829, 80, 1, 31, 5, 29, 67, 50, 11, 43, 385, 15, 7, 1310], [21697, 71, 358, 58, 3, 44, 634, 107, 54, 27, 4, 5089, 21698, 16, 4, 23, 37, 4374, 268, 213, 8, 22, 1, 96, 568], [4206, 1], [21699, 39, 9, 87, 6398, 165, 478, 2, 21700], [21701, 4, 243, 1219, 1302, 424, 2, 2678, 18, 10, 186, 8, 216, 15, 21702], [3566, 21703, 21704, 819, 21705, 3566, 8920, 3581, 21706, 2632, 1968, 1635, 1968, 8920, 6083, 3010, 23, 370, 1968, 1635, 6083, 3010, 21707], [5356, 21, 32, 56, 53, 21708, 678, 68, 4, 237, 53], [674, 782, 2490], [674, 782, 30, 21709], [4013, 25, 28, 4, 247, 1], [3213, 3, 64, 50, 4, 247, 205, 7, 174, 9, 99], [2376, 1, 105, 243, 71, 42, 48, 243, 57, 42, 196, 42, 46, 243], [2376, 45, 55, 12, 471, 21, 17, 11, 2, 3373, 4, 154, 193, 16, 238, 389, 21, 24, 218, 55, 3358, 3854], [21710, 7735, 16, 4, 1254, 1599, 21711, 8921, 16, 21712, 522, 3433, 11, 4, 56, 807, 2749], [4977, 33, 121, 757, 167, 4, 1149, 8, 36, 24, 192, 21713, 128], [2186, 60, 16, 78, 723, 30, 1, 55], [2770, 77, 227, 93, 189, 173, 4324, 233, 2770, 189, 227, 93, 287, 173, 180, 106, 2365], [444, 244, 106, 388, 151, 94, 5, 361, 410, 388, 27, 8867], [444, 5, 9, 192, 428, 19, 27, 17, 88, 151, 134, 8187, 34, 444, 88, 5, 9, 56], [35, 8, 100, 4, 1136, 429, 1], [35, 570, 18, 147, 93, 961, 125, 10, 153], [35, 570, 88, 2, 1, 484, 6, 21714, 526, 63, 3, 420, 330], [35, 11, 22, 1, 13, 3367], [35, 13, 98, 1935, 238, 430, 4, 570, 95, 7, 430, 4, 5682], [35, 99, 570, 4, 148, 95, 49, 96, 5511, 1936], [6108, 9, 64, 142, 1658, 25, 8, 142, 1658, 275, 64, 6108, 25], [174, 203, 188, 48, 21715, 15, 2, 511, 1], [174, 43, 82, 135, 42, 208, 372, 5041, 3427, 17, 74, 151, 14, 98, 21716, 187, 579, 421, 174, 3419, 310, 4671], [168, 6, 941, 76, 95, 92, 23, 635, 13, 2, 21717], [168, 4, 831, 5604, 26, 21718, 51, 4, 21719, 34, 92, 23, 303, 7, 1, 54, 149, 45, 3, 67, 15, 32, 749], [168, 6, 44, 2, 504, 92, 32, 3, 41, 12, 1541], [8556, 852, 4, 3170, 96, 67, 20, 8778, 403, 7649, 21720, 7020, 421, 6896, 87, 6, 14, 7385, 897, 71, 15, 150, 6, 14, 2109, 6112, 177], [2240, 2304, 2500, 1], [21721, 12, 270, 2, 1], [1884, 20, 21722, 20, 21723, 303, 21724, 19, 248], [8922, 7, 21725, 962], [21726, 12, 270, 2, 172, 711], [2977, 11, 445, 115, 283], [21727, 684, 591, 70, 15, 6357, 9], [5223, 2051, 2312, 12, 56, 73, 1066, 289, 132, 11, 4, 1333, 745, 132, 3639, 74, 2766], [4192, 2758, 8, 8917, 3748, 33, 266, 311, 254, 87, 6, 109, 229, 84, 30, 2360, 141, 1], [2712, 1199, 1876, 27, 4, 3664, 377, 136, 4, 6003, 3, 3858, 21728, 42, 73, 15, 372, 1345], [496, 159, 1186, 2483, 412, 2223, 1372, 2803, 3397, 21, 563], [496, 159, 1186, 70, 679, 842, 21, 946], [496, 159, 1186, 375, 782, 21729], [496, 18, 4, 1665, 159, 1186], [496, 933, 2414, 3, 75, 21730], [1535, 82, 4, 179, 46, 89, 7997], [1454, 12, 1207, 27, 24, 55, 251], [8561, 1052, 8, 2454, 2957, 1013, 964, 21731, 190, 1052, 6232, 1366, 21732, 123, 21733, 527], [8837, 21734, 75, 79, 120, 56, 287, 120, 56, 13, 22, 985, 21735], [21736, 1527, 1367, 21, 5590, 395, 11, 21737, 48, 2, 320, 16, 1273, 2164, 86, 59, 494, 21738, 265, 225], [596, 1], [294, 102, 2102], [194, 160, 66, 2002, 4, 2001, 3471, 377, 1, 1300, 8923, 8924, 739, 51, 2953, 5944, 985, 5567], [8925, 1147, 377, 1, 1300, 2188, 160, 8926, 2259, 2953, 985, 4755, 264, 106, 5567], [8925, 1147, 377, 1, 1300, 2188, 160, 8926, 2259, 2953, 985, 4755, 264, 106, 21739], [21740, 4060, 1525, 8254, 377, 136, 1827, 6, 2769, 11, 2810], [194, 1110, 1331, 377, 28, 126, 4687, 352, 2172, 18, 6113, 115], [194, 1110, 1331, 377, 28, 126, 4687, 352, 2172, 18, 6113, 115], [194, 1110, 1331, 377, 28, 126, 4687, 352, 2172, 18, 6113, 115], [21741, 37, 57, 45, 12, 1305, 1693, 9, 615, 57, 12, 61, 962], [66, 2002, 4, 2001, 3471, 377, 1, 1300, 8923, 8924, 739, 51, 2953, 5944, 21742], [6641, 21743, 21744, 21745, 651, 1144, 6960, 508, 3139, 8, 8326, 21746, 5978], [3375, 642, 266, 226, 3391, 2566, 444, 5, 3690, 44, 330, 21747, 20, 5679, 4302, 160, 341, 1211], [21748, 137, 244, 860, 21749, 4, 21750, 21751, 11, 21752, 27, 159, 7615, 26, 21753, 2509, 16, 674, 5270, 1683, 21754], [369, 571, 58, 59, 10, 645, 159, 21755], [369, 12, 22, 418, 751, 4, 2588, 4195, 3070, 51, 4, 1055, 178, 255, 40, 13, 2, 388, 21756, 21757], [21758, 12, 8907, 5, 72, 15, 5, 198, 14, 21759, 11, 4, 977, 74, 508, 21760], [4305, 1, 3, 146, 28, 364, 459, 22, 975, 3445], [21761, 2365], [304, 57, 5, 2, 104, 31, 5, 255, 2, 930, 257], [304, 2, 1204, 74, 50, 24, 7, 1350, 7926, 21, 435, 415, 532, 13, 6114, 2167, 8, 1574, 21762], [304, 2, 1204, 5, 25, 1, 55, 3, 29, 134, 2, 148, 31, 15, 2688], [304, 2, 6031, 21763, 149, 2, 190, 11, 2, 778, 849, 21764, 1313], [304, 21765, 15, 1310, 105, 339], [304, 200, 114, 10, 348], [304, 7, 4549, 971, 927, 1, 8927, 177], [2761, 57, 11, 4, 5749, 187, 3016], [2761, 57, 78, 182, 157, 174, 714, 11, 4, 161, 1556, 11, 4, 108, 16, 4, 24, 33, 17, 3767], [304, 21, 2122, 3, 67, 2122, 217, 1553, 15, 35], [304, 18, 39, 1], [304, 18, 22, 2264, 21766], [3464, 1, 89, 1446], [597, 35, 732, 8858, 579, 139, 1166, 39, 24, 2671, 4468, 69, 105, 912, 2, 743, 11, 36], [597, 35, 1], [597, 35, 5, 21767, 391], [294, 11, 4, 460, 2137, 35, 80, 9], [294, 54, 7, 1, 13, 33, 1012, 7, 959], [294, 35, 6, 20, 331, 762, 18, 4, 676, 8, 665, 20, 30, 1724, 405, 15, 102, 405, 15, 102, 1, 3, 41, 2, 486, 102], [294, 11, 125, 2, 154, 1, 18, 17, 41, 25, 214, 34, 3, 62, 15], [294, 173, 2, 460, 8, 36, 47, 868, 8230, 160, 1211, 1453, 5987, 3, 294, 459, 7, 1, 3469, 8, 4420, 11, 126, 2412], [3997, 151, 405, 543, 22, 1], [3997, 277, 22, 171, 1, 651, 59, 4, 19, 3922, 6, 597, 35, 22, 570, 8, 137, 19, 5, 282], [131, 258, 54, 4, 910, 59, 495, 33, 113, 240, 5768, 8, 194, 4, 112, 1, 25, 74, 9, 107, 54, 240], [67, 60, 873, 27, 7, 1545, 1], [67, 6, 345, 149, 16, 4, 77, 51, 819, 1023, 188, 571, 1], [67, 6, 61, 28, 22, 348, 23, 861, 5245], [67, 6, 881, 794, 21768, 6, 881, 4, 21769], [67, 6, 119, 50, 24, 82, 4, 108, 34, 40, 21770], [3551, 46, 404, 45, 31, 6114, 176, 868, 13, 2, 1], [47, 556, 935, 10, 1256, 35, 11, 4, 1495, 34, 21771, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26], [47, 11, 5634, 1198, 225, 177, 31, 36, 124, 4, 21772, 5634, 15, 7, 9, 15, 1560, 132, 185], [1089, 35, 9], [21773, 2162, 159, 824, 8582, 2065, 27, 408, 808, 645, 6, 139, 1513, 38, 21774, 938, 381], [1089, 10, 490, 343], [1287, 125, 32, 39, 810, 153], [194, 71, 3, 139, 81, 233, 4, 1, 96, 175], [194, 272, 167, 7, 9, 790, 18, 22, 850, 556, 14, 4, 21775, 21776, 460, 16, 862], [194, 10, 186, 1], [194, 54], [194, 54, 158, 8852, 5, 115, 12, 3305], [194, 4, 202, 8, 8928, 345], [194, 80, 9], [194, 60, 1170, 119, 2, 1799], [194, 5032, 28, 1380, 123, 4, 3355, 21777, 65, 13, 666, 16, 5700], [194, 5606, 2282, 22, 21778, 1, 440, 1243, 260, 54, 11, 4, 2192, 37, 36, 63, 2338, 6, 4399, 8265], [194, 6056, 6057, 136, 1460, 17, 7, 39, 1, 131, 9, 444, 374, 515], [194, 8929, 613, 18, 21779, 52, 67, 6, 543, 15, 27, 4, 179, 21780, 229, 2785, 71, 209, 169, 46, 2, 21781], [194, 4, 158, 629, 21782, 122, 6, 683, 127, 59, 4, 4423, 93, 21783], [6055, 872, 11, 143, 63, 3859, 399], [591, 6112, 1, 7, 1364, 21784], [827, 35, 27, 574, 79, 17, 8363, 1, 92], [1835, 74, 28, 3209, 18, 97, 1, 5], [193, 99, 239, 24, 69, 33, 973, 142, 8, 58, 295, 11, 10, 5710, 398, 599, 8, 21785], [1441, 21786, 154, 2253, 30, 153, 55], [1441, 363, 673, 45, 18, 1118, 21787], [66, 46, 276, 81, 133, 80, 5930, 218, 765, 46, 45, 13, 10, 153], [66, 46, 109, 125, 7, 533, 1, 66, 133, 7, 1781], [66, 49, 108, 1], [66, 49, 4, 101, 408, 1095, 69, 123, 8, 2850, 134, 2, 2678, 7, 21788, 3413, 84, 189, 897, 357, 1, 59, 22, 21, 1974, 8, 21789], [66, 132, 433, 384, 153, 1164, 892, 1446], [66, 398, 44, 625, 9, 34, 3, 300, 32, 3, 67, 12, 5], [66, 133, 6, 14, 4, 244, 5502, 4518, 2, 1522, 535, 16, 181, 121, 66, 273, 76, 31, 36, 210, 13, 126, 522, 6, 28, 897, 105, 582], [66, 75, 79, 495, 963, 66, 41, 21790, 21791, 8795, 37, 248], [66, 75, 302, 39, 9, 1154], [66, 2913, 447, 1, 66, 21792], [66, 2470, 1], [66, 29, 2010, 1], [66, 29, 64, 76, 9], [66, 29, 64, 39, 9], [66, 29, 64, 39, 9, 3, 101, 67, 68, 264, 21793], [66, 29, 137, 1, 116, 43, 114, 108], [66, 29, 429, 54, 1, 66, 1099], [66, 29, 67, 80, 1, 1151, 66, 33, 131, 44, 501, 27, 876], [66, 41, 8423, 214, 866, 8, 1, 249, 138], [66, 41, 2990, 21794, 8, 32, 10, 9, 21795, 21796, 21797, 89, 21798, 3, 29, 1049, 3201], [66, 90, 5, 99, 161, 153, 55, 3, 90, 4, 3355, 797], [66, 11, 22, 1], [66, 33, 778, 8889, 657, 1184, 66, 46, 778, 9, 657, 135, 26], [66, 62, 57, 22, 9, 152, 58, 21, 50, 1451, 92, 2816, 3, 893, 18, 15], [66, 62, 5, 203, 9, 49, 48, 180, 1006, 20, 383, 203, 483], [66, 259, 1427, 979, 162, 66, 3267, 39, 319], [66, 87, 2, 4788, 1459, 9, 1447, 21799], [66, 87, 9], [66, 87, 6, 192, 44, 2, 2554, 412, 16, 4788, 9, 55], [66, 129, 135, 1784, 27, 1197, 8, 197, 8, 684, 3930, 1127, 70, 169, 21, 14, 56, 649, 57, 136, 22, 360, 107, 1836], [66, 920, 785, 4, 1, 5, 3888, 11, 64, 27], [66, 37, 839, 11, 22, 1, 66, 318, 2150], [66, 56], [66, 168, 6, 1465, 35, 18, 76, 534, 108, 11, 1932, 7738, 8, 21800, 7365, 8, 2878, 36, 30, 11, 4, 2340, 161, 1], [66, 5310, 95, 49, 96, 175], [219, 430, 76, 9, 790, 271, 18, 97, 1862], [220, 316, 4, 21801, 381, 159, 4729], [220, 2, 93, 1141, 218, 66, 398, 21802, 441], [220, 61, 6, 70, 4, 261, 65, 37, 388, 2199], [21803, 1, 21804, 3833], [6429, 6, 144], [441, 348, 3453], [441, 8913, 800, 7], [21805, 21806, 12, 7, 164, 19, 567, 95], [696, 12, 1184, 57, 98, 1455, 449, 22, 136, 5795, 100, 168, 22, 5640, 696, 6, 1120, 305, 1875, 10, 3007, 494, 3696], [804, 30, 1], [804, 4092, 207, 21807, 12, 21808], [1073, 6, 305, 1351, 16, 21809, 536, 54, 4, 1893, 529, 1430, 400, 18, 795, 2415, 21810, 8060, 8761], [1073, 6, 4, 730, 3703, 21811], [21812, 27, 20, 758, 102, 12, 4, 388, 2261, 16, 2011, 55], [219, 3, 301, 3, 222, 512, 4, 45, 125, 42, 1, 34, 803, 146, 28, 325, 169, 21813], [219, 23, 108, 18, 4, 21814, 21, 2, 89, 1], [219, 1615, 3, 380, 31, 5, 131, 176, 20, 331, 82, 1276, 21815, 95, 12, 4, 324, 221], [219, 3992, 28, 2, 190, 3163, 37, 3, 62, 162, 151, 14, 2767, 23, 337], [219, 148, 21816, 439, 15, 47, 4, 391, 11, 7, 406, 40, 168, 6, 14, 2, 77, 469, 35, 18, 2, 21817], [219, 3549, 3, 297, 5, 1, 762, 5828, 1318, 102, 20, 754, 18, 20, 21818, 27, 4532], [219, 328, 57, 2, 2993], [219, 21819, 21820, 2987, 401, 21821, 5950, 184, 759, 5711, 182, 328, 40, 96, 98, 183, 158, 260], [219, 93, 561, 570, 7583, 965, 8180, 6332, 1204, 444, 2843, 2670, 897, 88, 1418, 1306, 1849, 68, 8, 376], [219, 380, 3, 62, 2, 666, 16, 9, 2932, 223, 316, 97, 201, 3801, 390, 205], [219, 3, 150, 13, 2, 812], [219, 427, 7, 2, 1, 201, 21822, 49, 61, 6, 4], [219, 92, 7, 23, 339, 223, 392, 144, 100, 28, 1626], [219, 267, 93, 3, 41, 166, 21823, 7, 652, 1820, 13, 21, 6000], [219, 36, 58, 92, 281, 3, 33, 86, 39, 1, 49, 3890, 13, 23, 4667, 55], [219, 20, 2, 141, 187], [219, 21824, 12, 134, 17, 482, 33, 41, 337, 82, 197, 8, 272, 313, 4, 24, 51, 170], [21825, 52, 152, 114, 143, 1, 74, 576], [4152, 571, 9, 361, 964, 40, 2, 9, 31, 40, 13, 21826], [4152, 17, 260, 3, 867, 482, 57, 21, 1283, 17, 7, 1, 5, 132, 262], [1497, 622, 94, 1158, 89, 1, 163, 131, 2661, 72, 5304], [363, 6, 98, 458, 331, 225, 26, 4, 507, 47, 248, 2584], [363, 97, 1, 331, 92, 40, 48, 2, 2699, 1046], [7450, 5, 466, 4119, 1, 433, 15, 6, 20, 172, 6716, 31, 5, 67, 6, 404], [7739, 377, 4487, 168, 16, 2318, 2771, 1355, 27, 2983, 324, 6, 372, 2968, 160], [3821, 153], [631, 1], [57, 770, 1226, 111, 31, 5, 1, 59, 256, 602, 604, 28, 57, 5, 2197], [57, 3, 90, 59, 5766, 8670, 12, 4, 111, 69, 1, 59, 4, 493, 562], [57, 3, 65, 13, 236, 3, 65, 13, 367, 8, 5, 65, 13, 43], [57, 2, 537, 77, 281], [57, 2, 812], [57, 2, 171, 1], [57, 2, 181], [57, 2, 19, 104], [57, 2, 19, 144], [57, 2, 9, 55], [57, 2, 24, 37, 5, 63, 21827, 59, 17, 88, 753, 34, 75, 110, 1257, 8, 122, 6, 594, 10, 446, 221, 8, 23, 4, 4752], [57, 2, 21828, 141, 838, 3, 118, 14, 2091, 21, 170, 34, 3, 75, 397, 4, 3042], [57, 2, 56, 8478, 5850, 103, 751, 4, 1129, 3803, 51, 4, 4893, 658, 458, 2199], [57, 2, 2264, 65, 13, 38, 52, 28, 906, 1501, 4, 6005], [57, 2, 1039, 118, 594, 2, 9, 222, 105, 21829], [57, 98, 1455, 818, 115, 15, 47, 225, 21, 8, 106, 21, 618, 93, 3486], [57, 3443, 16, 56, 317, 532, 73, 89, 2337, 2078, 74, 21830], [57, 14, 4, 21831, 748, 378, 120, 2524, 201, 207, 292, 21832, 4194, 445, 2983, 473, 1422, 3, 29, 1507, 3, 14, 21833], [57, 58, 5, 58, 38, 5, 4, 25, 7, 1254, 2209, 2, 1, 147, 28, 1459], [57, 499, 107, 18, 18, 1147, 23, 48, 556, 194, 7, 56, 289, 2275, 21834, 1209, 21835], [57, 182, 582, 6, 4, 1328, 6017, 16, 10, 115, 8, 85, 456, 36, 382, 17, 27, 22, 1328, 6017, 61], [57, 31, 3, 81, 179, 55, 278, 14, 37, 589, 16, 10, 653], [57, 31, 3, 47, 18, 10, 30, 7, 196, 40, 28, 470, 16, 10, 1278, 91, 7, 1, 63, 605, 10, 30], [57, 12, 186, 110, 21, 128, 22, 9, 963, 483], [57, 12, 22, 4, 49, 58, 225, 168, 212, 6865, 184, 8, 70, 15, 32, 4, 193, 224, 4, 1095, 6030], [57, 12, 35, 10, 7855, 153], [57, 1176, 9, 216, 22], [57, 698, 16, 1, 30, 313, 47, 7, 5907, 1066], [57, 698, 16, 395, 195, 3, 4, 68, 7, 255, 2, 1493, 8, 277, 692, 8, 13, 6, 19, 27, 1], [57, 698, 16, 21836, 12, 6394, 1171, 119, 22, 24, 288, 23, 18, 10, 4753, 26, 79, 15, 4251, 2215], [57, 214, 187, 1601, 3832, 7, 252, 87, 2, 314, 21837], [57, 216, 22, 145, 72, 7, 54, 84, 476], [57, 70, 5, 468, 20, 5615, 171, 30, 1, 69, 81, 45, 34, 266, 294, 2, 3673, 11, 5, 373, 845], [57, 3230, 16, 202, 617, 114, 126, 265, 498, 11, 4, 179, 6, 446, 54, 21838, 4499, 8, 3323, 26, 3056, 21839, 8, 72], [57, 92, 1, 289, 41, 20, 504], [57, 574, 772, 2294, 21840, 12, 2, 312, 82, 154, 2253], [57, 3450, 692, 959, 1292, 7, 172, 56], [57, 654, 41, 4, 237, 24], [57, 7, 1, 238, 72], [57, 4, 19, 205, 109, 4, 1119, 19, 12, 136, 223, 48, 6, 62, 7339], [57, 4, 19, 698, 16, 388, 2786, 47, 7], [57, 4, 286, 49, 66, 58, 27, 24, 1585, 7, 2622, 29, 1281, 4176, 1978, 18, 1095, 36, 49, 21841, 1132, 2678, 26, 111, 2754], [57, 4, 21842], [57, 39, 1, 67, 82, 2, 153, 233], [57, 39, 1, 67, 82, 2, 25, 13, 18, 60, 4872, 45], [57, 36, 1460, 263, 91, 76, 89, 1, 101, 67, 4, 7865, 4, 21843, 66, 21844, 92, 4, 9, 131, 2698, 5904], [57, 106, 21845, 192, 7746, 37, 3, 2036, 872, 21, 4, 183, 319], [57, 42, 29, 58, 246, 9, 103], [57, 35, 365, 30, 9, 23, 48, 223, 3006, 5, 1185, 2451, 10, 25, 402, 108], [57, 35, 816, 3, 196, 21846], [57, 47, 7, 5360, 6, 28, 45, 108, 11, 1841, 38, 15, 192, 28, 858], [57, 118, 78, 21847, 118, 208, 13, 68, 16, 76, 579, 208, 13, 66, 541, 21, 4, 199, 1, 128], [57, 5, 58, 1, 249, 15, 29, 1942, 15], [57, 5, 152, 58, 31, 40, 359, 345, 290, 21, 50, 43, 543, 7, 1, 54, 8, 61, 344, 6, 8495], [57, 5, 62, 59, 28, 169, 702, 1250, 233, 662, 27, 4, 606, 153, 5712, 125, 4, 2730], [57, 5, 72, 9], [57, 2, 1235, 461, 2, 1065, 21848, 1045, 30, 1], [57, 2, 56, 460], [57, 109, 356, 133, 22, 327, 12, 23, 362, 36, 442, 76, 9, 12, 89], [57, 144, 12, 7, 3, 428, 64, 10, 401, 8, 44, 2, 109, 804, 3542, 21, 254], [57, 37, 93, 59, 2358, 32, 3, 94, 12, 246, 104, 30, 314, 261, 6816], [57, 7, 1631, 79, 18, 20, 2487, 3, 79, 15, 1, 1251, 128], [57, 22, 45, 31, 20, 448, 2, 21849, 15, 48, 2, 1878, 29, 5533, 2915, 21850, 30, 1], [57, 22, 1, 65, 13, 78, 1299, 17, 18, 20, 185, 21851, 26], [57, 22, 1, 144, 134, 17, 108, 10, 1913, 831, 155, 106, 3, 563, 495, 3, 1233, 151, 105, 563, 76, 361], [57, 35, 104, 394, 78, 299, 1502, 297, 4, 215, 16, 17], [57, 35, 27, 32, 39, 1, 11, 618, 21852, 294, 4, 606, 13, 7, 45, 12, 2383], [57, 1128, 130, 4, 3874, 144, 122, 6, 70, 15, 2, 849, 21853, 1057, 8750, 136, 149, 127, 732, 989, 130, 8622], [57, 1128, 130, 5967, 3384, 12, 4, 3033, 5, 28, 288, 1759, 7, 4, 979, 775, 12, 726], [766, 23, 61, 6, 2341, 21854, 75, 14, 2, 141, 1, 117, 92], [766, 582, 3, 266, 100, 2331, 671, 2, 180, 1839, 1404, 3, 21855, 129, 10, 172, 544, 481, 1, 23, 1223, 3, 75, 14, 529], [57, 329, 545, 22, 1386, 21856, 812], [57, 329, 27, 22, 1], [38, 41, 20, 500, 1, 26, 4, 68, 5, 238, 420, 18, 545, 15, 106, 6, 79, 26, 134, 15, 2, 35], [38, 159, 122, 6, 294, 173, 10, 712, 8, 15, 75, 375, 31, 3, 1020, 4, 676, 74, 48], [38, 1830, 3188, 121, 296, 46, 328, 227, 35, 368], [38, 3, 14, 4651, 78, 2685, 108, 8, 21857, 6, 4550, 8, 45, 3, 14, 6609, 847, 3, 12, 207], [38, 3, 14, 7, 24, 3, 14, 79, 5, 10, 83], [38, 3, 79, 1, 5, 6668], [38, 3, 309, 313, 2, 535, 89, 1, 11, 10, 3974], [38, 3, 94, 2, 595, 1, 3, 29, 28, 1110], [38, 3, 795, 102, 11, 143, 489, 25, 134, 17, 21858, 8, 1420, 9, 2246, 765, 387, 1676, 68, 184, 117, 36, 131, 19], [38, 3, 131, 879, 98, 40, 131, 879, 51, 4, 199, 106, 23, 2533, 91, 22, 1, 21859, 21860], [38, 3, 47, 1913, 26, 17, 10, 774, 168, 6, 61, 6, 4, 1483, 6, 349, 319, 278, 14, 51, 337, 790, 7, 264, 5994], [38, 3, 47, 11, 2248, 940, 15, 47, 2, 161, 1, 51, 10, 261, 11, 2317, 8, 40, 47, 554, 13, 369, 3, 1240, 154, 57, 24, 65, 13, 7, 379], [38, 3, 47, 11, 2940, 66, 124, 2, 856, 412, 8, 88, 66, 124, 4, 21861, 76, 9, 47, 179, 73, 45, 34, 36, 1874, 4, 8655, 2221, 1617], [38, 23, 2, 575, 23, 5964, 186, 218, 15, 6, 239, 1, 7, 49, 21862, 3, 146, 4, 5836, 16, 2, 1682, 213, 206, 337, 771], [38, 2407, 47, 214, 243, 8, 1420, 4020, 231, 21863, 21864, 51, 4, 450, 16, 378, 3, 47, 13, 221, 76, 1, 133, 6, 404, 15, 32], [38, 161, 1441, 121, 1542, 134, 2, 1, 20, 548, 38, 2213, 516, 44, 2, 5812], [38, 4779, 6064, 440, 4, 232, 36, 220, 506, 84, 1586, 21, 21865, 38, 5966, 8320, 363, 6, 865, 36, 1597, 84, 21, 21866], [38, 6086, 427, 58, 84, 104, 1479, 569, 52, 428, 356], [38, 2, 1, 3, 29, 13, 528, 51, 10, 675], [38, 2, 1, 32, 11, 97, 91, 231, 11, 775], [38, 2, 418, 235, 12, 669, 3, 33, 637, 10, 387, 8, 2337, 17, 134, 2, 89, 1, 13, 4040, 21867, 108, 565, 37, 3, 63, 28, 10, 879, 102], [38, 2, 203, 1, 67, 5, 8, 2, 703, 1, 75, 867, 777, 21, 5, 39, 9, 46, 807], [38, 2, 77, 191, 17, 31, 3, 119, 2741, 51, 250, 3, 29, 110, 149, 7, 33, 2, 185, 938, 11, 3946], [38, 2, 77, 122, 6, 687, 27, 17, 4483, 3, 47, 551, 2079, 48, 21868, 463, 242, 4, 19, 35, 368, 23, 2, 530, 187, 4483, 551], [38, 2, 9, 61, 108, 6, 50, 1752], [38, 2, 9, 238, 28, 51, 5, 288, 97, 77, 12, 65], [38, 2, 145, 86, 52, 276, 107, 21869, 17, 8, 10, 5086, 151, 19, 5, 8, 50, 35], [38, 2, 24, 25, 1568, 5, 8, 317, 762, 5, 897], [38, 2, 112, 145, 67, 5], [38, 2, 889, 89, 1, 294, 722, 42, 8, 42, 75, 547, 34, 1442], [38, 32, 499, 1332, 1626, 1240, 628], [38, 482, 2210, 9, 149, 52, 101, 67, 5], [38, 482, 72, 40, 784, 6, 4, 489, 27, 50, 77, 3, 14, 619, 7, 1, 51, 3978, 1671], [38, 1, 3, 197, 27, 49, 18, 116, 1230, 188], [38, 1, 11, 4, 8344, 192, 208, 35], [38, 1, 62, 36, 150, 185, 36, 176, 116, 1355, 7115], [38, 1, 72, 296, 67, 6, 21870, 15, 112, 12, 76, 569, 11, 1803, 72, 36, 67, 4, 717], [38, 1, 5, 29, 13, 81, 6, 5, 51, 1869], [38, 200, 1518, 227, 179], [38, 200, 2343, 28, 37, 1221, 5, 386, 16, 283], [38, 200, 15, 671, 431, 6, 6097, 185, 22, 660, 1726, 12, 3207, 18, 488, 51, 4184], [38, 182, 5, 381, 9, 109, 89, 5, 450, 35, 545, 2, 504, 188], [38, 500, 77, 228, 28, 4274, 7, 274, 72, 403, 4038, 20, 1073, 425, 180, 1384, 1], [38, 77, 72, 13, 2984, 23, 37, 183, 13, 1, 5, 46, 1127, 21, 2558, 20, 13, 839, 3678, 2563, 19], [38, 189, 49, 127, 8550, 130, 247, 77, 13, 91, 35, 24], [38, 189, 313, 185, 1, 1023, 15, 13, 21871, 632, 60, 466, 2034, 3, 44, 1104, 466, 130, 350], [38, 50, 24, 317, 578, 13, 2626], [38, 50, 24, 1116, 38, 80, 77, 72, 40, 152, 100, 5, 167, 390], [38, 9, 14, 854, 36, 1719, 4514, 74, 87, 60, 138], [38, 9, 86, 3, 41, 2952, 25, 2290, 1117, 10, 21872], [38, 3, 1, 19, 10, 8930, 277], [38, 3, 309, 1, 19, 10, 8930, 21873, 116, 2528], [38, 3, 309, 313, 2, 535, 89, 1, 11, 10, 3974], [38, 3, 309, 313, 2, 535, 89, 1, 11, 10, 21874], [38, 3, 94, 2, 889, 89, 1, 8, 40, 582, 6, 14, 82, 10, 620, 3, 33, 150, 4, 87, 6, 512, 10, 7380], [38, 15, 107, 6, 5501, 25, 103, 28, 537], [38, 15, 1234, 15, 93, 1993, 6, 4, 1483, 21875, 32, 4, 490, 14, 51, 337], [38, 15, 192, 1234, 1, 156, 1863, 28, 19, 1, 114, 2, 1966], [38, 15, 192, 3769, 1, 14, 13, 3, 1863, 2126, 576, 1, 5, 33, 1863, 919, 6, 249, 2, 138, 5, 8, 1963, 400, 364, 142, 11, 2, 1825], [38, 15, 341, 3, 255, 766, 55, 45, 31, 222, 107, 54, 22, 1, 11, 4742, 3, 118], [38, 2407, 82, 654, 3240, 176, 79, 80, 1, 34, 78, 41, 3064], [38, 164, 41, 97, 142, 5, 33, 146, 28, 108, 35, 8, 1078, 491, 7, 9], [38, 663, 113, 5, 69, 5, 81, 6, 8, 15, 46, 21876, 43, 1], [38, 10, 228, 49, 21877, 10, 166, 228, 8, 552, 69, 6, 2313, 23, 33, 13, 304, 1472, 49, 20, 573, 21878, 143, 4330], [38, 10, 117, 402, 28, 54, 25, 276, 375, 85, 66, 4579, 334, 24], [38, 10, 826, 72, 339, 4513, 3, 86, 16, 339, 1], [38, 3948, 468, 11, 2, 290, 36, 443, 493, 12, 21879, 101, 53], [38, 25, 2451, 126, 1523, 8, 15, 56], [38, 25, 72, 36, 13, 1959, 36, 29, 196, 5, 203, 1, 7, 532, 13, 8256], [38, 25, 131, 359, 36, 192, 98, 2469, 27, 126, 4983, 757, 3, 273, 5, 3, 90, 3079, 18, 10, 21880, 19, 22, 23, 3217], [38, 111, 21881, 10, 262, 36, 28, 1211, 54, 11, 10, 235, 32, 409, 16, 1, 98, 5399], [38, 111, 3354, 126, 226, 18, 116, 179, 21882], [38, 111, 109, 86, 23, 668, 3, 28, 1001, 110, 464, 3, 70, 501, 16, 10, 1479, 653], [38, 111, 8910, 88, 433, 5, 35, 8, 65, 55, 3, 33, 1835, 13, 84, 1, 221, 3, 94, 5, 58, 3, 279, 19, 43, 433, 17, 35], [38, 590, 1, 258, 54, 4, 489, 46, 8239, 6, 28, 11], [38, 94, 42, 98, 21883, 728, 2, 21884, 2097, 503, 27, 2, 5607, 18, 11, 4, 731, 3436, 134, 2, 1143, 16, 606, 25, 2, 179, 4021, 521], [38, 40, 125, 17, 41, 80, 1, 458], [38, 40, 2, 344, 35, 9, 34, 317, 249, 1270], [38, 495, 191, 3697, 143, 9, 4765, 1814, 729, 12, 21885, 42, 41, 4067], [38, 7, 391, 603, 510, 21, 17, 38, 3, 210, 471, 21, 50, 7574], [38, 4, 832, 1, 11, 261, 294, 123], [38, 4, 1, 137, 27, 20, 1393, 98, 266, 100, 5, 8931, 7, 4, 1029, 162, 3, 131, 543, 50, 344, 11, 4, 4524], [38, 4, 115, 568, 89, 33, 113, 630, 4095, 4, 24, 4765], [38, 4, 2782, 479, 42, 35, 211, 42, 2563, 11, 4, 24], [38, 4, 24, 1116], [38, 4, 826, 1457, 122, 208, 13, 40, 4, 21886, 1, 333], [38, 36, 1, 59, 21887, 21888, 113, 76, 6, 139, 1238, 140, 5580, 1299, 21889, 21890, 6, 4, 21891], [38, 184, 29, 61, 10, 193, 23, 2, 966, 83], [38, 22, 959, 12, 129, 225, 23, 70, 2, 2477, 16, 2122, 23, 61, 6, 973, 11, 618, 32, 115, 26, 119, 76, 444, 10, 548, 12, 21892], [38, 42, 167, 15, 82, 4, 108, 42, 146, 79, 50, 1063, 36, 64, 7, 34, 29, 42, 1038, 79, 240, 7584], [38, 42, 94, 7, 1, 11, 473, 707, 3498, 447, 23, 44, 2, 177, 53, 1, 42, 47, 987, 18, 4644, 18, 6526], [38, 47, 2, 9, 182, 614, 6, 14, 3462, 3, 196, 15, 452, 70, 240, 2, 9, 3298, 14, 246, 2255], [38, 103, 852, 139, 113, 6084, 71, 6, 58, 84, 401, 5, 487, 110, 176, 2, 401, 11, 8621], [38, 287, 49, 37, 818, 7, 36, 29, 13, 6, 867, 26, 656, 1, 139, 14, 21893, 15, 48, 342], [38, 5, 46, 124, 24, 11, 2, 341, 6031], [38, 5, 430, 80, 1, 471, 677, 6, 246, 2400], [38, 5, 207, 155, 115, 12, 1461], [38, 5, 134, 495, 7, 1063, 65], [38, 5, 146, 6285, 30, 768, 32, 5, 44, 6, 58, 12, 65, 51, 1, 8, 801, 615, 913, 97, 11, 143, 24], [38, 5, 44, 474, 36, 67, 26, 20, 58, 474, 36, 75, 1, 49, 61, 6, 81, 385, 29, 100, 76, 139, 20, 1994], [38, 5, 465, 97, 774, 27, 43, 9, 308], [38, 5, 62, 21, 2, 488, 5, 41, 2, 414, 69, 64, 5, 166, 1, 29, 110, 3813], [38, 5, 623, 71, 8932, 12, 2, 83, 98, 198, 16, 100, 4, 5219, 271, 21894], [38, 5, 94, 59, 6, 290, 2, 1, 749], [38, 5, 94, 2, 203, 1, 255, 645, 8, 2, 2723, 758], [38, 5, 94, 265, 14, 89, 26, 126, 915, 33, 397, 116, 26, 5, 65, 410, 240, 13, 1, 5, 46, 276, 58, 1406], [38, 5, 113, 2, 991, 682, 1, 6, 471, 5, 60, 643, 45], [38, 5, 273, 97, 774, 40, 47, 2, 9, 34, 52, 96, 436, 15, 1787, 22, 26], [38, 20, 1862, 27, 2, 1, 8, 40, 762, 5, 129, 27, 4, 517], [38, 20, 25, 433, 5, 2, 9], [38, 20, 234, 1, 266, 338], [2767, 3, 510, 6, 261, 1241, 3, 424, 625, 3966, 421, 33, 37, 4, 9, 222, 536, 17, 54], [2767, 3, 94, 2, 327, 1787, 21895, 4821, 3, 2489, 102, 21, 1727, 691], [2767, 5, 87, 20, 9, 1367, 18, 685, 871, 74, 2978, 11, 4, 360, 333, 1372, 8, 286, 290, 21, 7, 282], [162, 12, 21896, 7, 158, 1632, 17, 546, 1889], [162, 2, 6707, 1, 38, 3, 87, 68, 3, 44, 43, 1778, 98, 2, 413, 874, 16, 2837, 5209, 8664, 91], [162, 32, 4, 1700, 3470, 1, 51], [162, 49, 32, 212, 1779, 1, 38, 5486, 440, 71, 107, 8871, 46, 525, 45], [162, 12, 188, 3, 346, 7, 83], [162, 10, 1, 51, 2683], [162, 364, 22, 1, 11, 4, 1106, 82, 22, 9, 3275], [162, 4, 89, 1, 51, 8, 123, 1983, 952, 3, 196, 21897], [162, 4, 89, 1, 932, 162, 97, 869, 8818, 2114], [162, 4, 1847, 8, 540, 287, 51, 48, 39, 653, 5581, 3, 655, 4, 360, 461, 197, 21, 15, 218, 3, 41, 2, 24, 283], [162, 4, 77, 51, 72, 243, 457, 6, 17, 3, 87, 1, 18, 1, 13, 3, 41, 2396, 18, 2396], [162, 4, 9, 51, 66, 65, 21, 4, 9, 5038], [162, 4, 9, 6058], [162, 22, 21898, 1, 51, 55], [162, 22, 9, 21899, 51], [162, 118, 17, 164, 14, 461, 274, 8, 21900, 278, 415, 14, 259, 11, 2, 56, 63, 281], [162, 97, 815, 161, 1], [162, 32, 10, 21901, 200, 36, 21902], [162, 10, 169, 1], [162, 4, 820, 162, 203, 5508, 568, 5937, 1466, 21903, 21904], [162, 4, 327, 16, 50, 397, 361, 22, 1, 65, 13, 21905, 26], [162, 22, 1, 915, 1000, 61, 337, 5, 5881], [678, 21906, 781, 63, 66, 157, 11, 27, 4, 508, 4336, 16, 421, 21907, 3447], [678, 196, 5, 9, 99, 185, 432, 67, 15, 224, 17], [678, 68, 233, 7639, 74, 21908, 74, 398, 2079, 470, 4082], [678, 68, 16, 5, 9, 88, 2077, 7, 21909, 21910], [792, 853], [792], [792, 54, 60, 1374, 11, 580, 16, 60, 1059, 51, 4, 448, 5531], [120, 1, 14, 1886, 143, 207, 435], [120, 1195, 2153, 49, 32, 120, 248], [120, 265, 202, 265, 190, 265, 286, 110, 2016, 265, 31, 5, 1281, 5155, 13, 1908, 5, 103, 61, 6046], [120, 111, 156, 502, 190, 30, 1022], [120, 56, 2546], [120, 56, 44, 1041, 129, 155, 4702, 1947, 11, 4, 2012], [120, 56, 5549, 29, 914, 73, 112, 120, 1225, 6, 914, 73, 2, 120, 395, 5, 44, 6, 914, 2, 4768, 5549, 652, 1225], [69, 143, 19, 12, 80, 552, 399], [69, 317, 67, 2, 89, 1], [69, 182, 200, 4, 257, 18, 7, 1441, 123, 1830, 7, 1, 2, 5172], [69, 5712, 125, 21, 112, 21, 112, 233, 147, 153, 14, 498], [69, 12, 1050, 8933, 2, 21911, 91, 2, 3020, 1050, 8933, 47, 4, 250, 970, 16, 4, 2942, 654, 21912], [69, 12, 7, 1106, 1100, 189, 4128, 5617, 519, 193, 52, 12, 2, 129, 1393, 83], [69, 87, 98, 3158, 38, 5, 44, 4, 360, 247, 589, 95, 619, 20, 1371], [69, 375, 38, 66, 220, 11, 848, 21913, 261, 8, 118, 313, 1010, 11, 4, 56, 82, 305, 930, 8, 1087, 21914, 1667], [69, 565, 1050, 541, 30, 9], [69, 114, 3660, 82, 4, 237, 21915, 1710, 172, 2288, 3899, 2191], [69, 364, 70, 98, 1024, 16, 246, 836, 13, 5, 131, 14, 4998, 1, 147, 5049, 1614, 203, 30, 9], [69, 4, 19, 12, 22, 1, 27, 22, 2113, 30, 1353, 1359, 18, 10, 1464, 20, 515, 30, 21916, 3, 118, 105, 1177, 42, 21, 2, 460], [69, 4, 19, 216, 22, 187, 4, 7164, 18, 435], [69, 4, 19, 157, 2, 572, 16, 873, 11, 36, 712, 461, 2, 21917, 179, 30, 25, 8117, 13, 7, 33, 4, 184, 6, 58, 2625], [69, 4, 19, 96, 137, 567, 95, 567, 95, 150, 13, 26], [69, 4, 286, 12, 152, 303, 20, 45, 38, 20, 537, 1277, 8, 56, 49, 1113, 11, 4, 2015, 16, 4, 406], [69, 4, 286, 1460, 5, 71, 6, 19, 1, 7916, 15, 35], [69, 273, 22, 6102, 9, 6, 192, 1692], [69, 131, 137, 4261, 143, 2615, 18, 143, 207, 91, 971], [69, 194, 3618, 1782, 141, 265, 8, 120, 56], [69, 1560, 1370, 7, 21918, 107, 108, 6, 4, 179, 964, 18, 7, 822, 8, 7, 21919, 13, 2, 202, 21920], [8656, 44, 299, 10, 388, 2401, 118, 708, 4, 1792, 1178], [69, 2, 3222, 5, 2, 3222, 69, 2, 3222, 5, 2, 3222, 367, 5, 1, 21921, 21922, 1403, 492, 39, 7090, 9], [69, 260, 12, 147, 69, 143, 91, 147, 200, 147, 201, 42, 2345, 1, 237, 14, 168, 1960], [69, 41, 4, 832, 24, 18, 4, 1260], [69, 542, 21, 158, 2238], [1703, 510, 35, 27, 7, 53, 3, 29, 44, 43, 500, 53, 854, 4158, 132, 2, 9], [1703, 124, 1753, 21923, 21, 21924, 624, 997, 205, 529, 5749, 187], [1703, 756, 11, 18, 2, 21925, 12, 2, 83], [1703, 216, 39, 348, 8, 851, 1642, 11, 2056], [1703, 382, 4, 950, 2532, 84, 21926, 52, 69, 12, 721, 51, 21927, 103, 48, 61, 8934], [413, 106, 20, 1, 18, 4, 310, 1897, 11, 17, 8, 10, 1, 1340, 5222], [21928, 2, 154, 1252, 11, 3038, 620, 95, 16, 21929, 563, 22, 6133, 1303, 21, 84, 2773, 11, 2139, 21930], [21931, 43, 497, 1828, 135, 269, 269, 26], [1866, 1048, 21932, 4663, 858, 2137, 140, 15, 587, 73, 466, 32, 16, 2, 2547], [21933, 21934, 61, 366, 2, 866, 8, 113, 2, 25, 6, 107, 5706, 5, 49, 1040], [69, 24, 12, 15, 40, 121, 8929], [85, 201, 252, 118, 131, 19, 4, 199, 1, 51, 4, 199, 106, 12, 750, 2239, 307], [85, 4488, 90, 942], [85, 1653, 1418, 93, 34, 4, 1255, 56], [85, 32, 4, 1, 365, 315, 92], [85, 195, 3, 14, 270, 2, 1, 225], [85, 49, 37, 1489, 11, 492, 111, 69, 49, 1387, 277, 2810, 44, 2334], [85, 49, 677, 79, 677, 3, 118, 516, 14, 13, 53, 403, 77, 471, 17, 4, 1169, 8, 30, 9, 53], [85, 49, 111, 72, 29, 100, 189, 557, 5, 13, 2, 190, 3205, 7, 10, 21935], [85, 49, 60, 111, 270, 104, 13, 220, 5, 1348, 7, 193, 74, 49, 5, 33, 7, 180, 16, 2, 2801, 21936], [85, 49, 116, 37, 239, 9], [85, 49, 5, 4, 101, 834, 2220, 11, 4, 178, 85, 3, 146, 137, 2, 703, 1], [85, 2020, 21, 677, 38, 5, 222, 19, 7, 1, 8, 70, 2, 5302, 1442, 630, 8, 5, 28, 60, 517, 404, 2379], [85, 1, 208, 13, 3, 75, 509, 74, 13, 324, 29, 44, 2, 5922], [85, 1, 28, 37, 1617, 98, 214, 38, 42, 191, 31, 36, 249, 138, 13, 367, 74, 43, 8623, 7721], [85, 1, 705, 6, 44, 2, 25, 260, 88, 14, 21937, 38, 40, 114, 279, 16, 15, 123, 1227], [85, 202, 77, 146, 14, 593, 46, 357, 316, 35, 4, 203, 120, 9, 5, 19, 108, 11, 848, 2119], [85, 75, 3, 44, 207, 387, 13, 10, 21938], [85, 75, 116, 14, 859, 419, 1, 3190, 18, 4301], [85, 75, 5, 14, 2792, 13, 20, 306, 8, 48, 9], [85, 200, 5, 1525, 10, 677, 5, 4503], [85, 58, 3, 44, 4, 884, 3579, 11, 4, 360, 251, 22, 1, 4, 1377], [85, 58, 3, 137, 39, 939, 5337, 178, 218, 23, 48, 2, 24, 8, 3, 13, 14, 626, 21939], [85, 58, 1, 107, 6, 261, 255, 1740, 3261, 6, 261, 70, 43, 1237], [85, 58, 1, 157, 19, 2, 1618, 11, 36, 21940, 4170, 42, 96, 2171, 2, 21941], [85, 58, 1702, 146, 14, 214, 179, 2330, 251, 349, 35, 20, 1286], [85, 58, 111, 316, 126, 1334, 6, 4, 6718, 22, 953, 1, 87, 50, 978, 18, 2, 4149, 21, 1798], [85, 58, 111, 168, 4, 2568, 1217, 11, 1191, 6, 2, 138, 31, 20, 138, 12, 2016, 27, 2, 875, 503, 94, 2, 1998, 2549], [85, 58, 37, 239, 2009, 2264, 3934, 1282, 1828, 259, 11, 553, 16, 76, 44, 245, 117, 51, 32, 6, 14, 1184], [85, 58, 60, 77, 150, 4, 87, 6, 14, 1, 21, 43, 540, 51, 32], [85, 58, 60, 3663, 25, 8, 9, 90, 18, 2, 243, 575, 33, 100, 76, 14, 243, 612, 19], [85, 58, 4, 13, 22, 1582, 1034, 733, 59, 71, 358, 2, 1005, 12, 198, 66, 33, 1552, 5, 2541, 3591], [85, 58, 1550, 412, 1545, 59, 117, 1194, 73, 31, 15, 12, 1363, 21, 126, 21942], [85, 58, 78, 1, 208, 37, 1133], [85, 277, 13, 8133, 2594, 40, 65, 13, 2, 718], [85, 277, 4455, 44, 2, 21943, 229, 7, 12, 1843, 1242, 26, 117, 1919, 81, 446, 852, 4, 1129, 12, 27, 6084, 48, 42, 660], [85, 277, 22, 1, 18, 4, 3352, 44, 2, 1055, 1130, 1457, 18, 7, 65, 13, 3703, 1953, 15, 21, 732, 21944], [85, 277, 22, 104, 11, 580, 16, 17, 44, 6, 28, 268, 8762, 21945, 117, 92, 28, 4, 19, 18], [85, 29, 5, 262, 20, 373, 306, 171, 83], [85, 326, 37, 1617, 6, 94, 39, 1303, 111, 927, 78, 9, 33, 3720, 36, 33, 41, 169], [85, 326, 81, 59, 1350, 677, 13, 40, 889, 587, 927, 33, 218, 40, 1303, 932, 7, 9, 1484, 13, 2, 2115, 2343, 6025], [85, 134, 2, 1, 98, 1435, 38, 40, 516, 44, 1079], [85, 134, 2, 1, 174, 548, 38, 2213, 516, 44, 2, 5047, 85, 134, 2, 1, 98, 1435, 38, 2213, 516, 44, 21946, 39, 9, 46, 334], [85, 52, 122, 72, 21947, 1796, 8770, 1, 128], [85, 625, 1, 208, 13, 36, 41, 474, 36, 44, 18, 36, 373, 13, 43, 1, 5, 124, 60, 2300, 16, 21948], [85, 12, 270, 2, 1, 3, 196, 69, 28, 6994, 8896, 84, 1544, 198, 14, 21949], [85, 12, 2719, 37, 148, 179], [85, 12, 32, 39, 2526, 8, 154, 68, 70, 37, 209, 56], [85, 12, 15, 156, 4, 203, 1, 81, 45], [85, 12, 15, 2026, 3, 61, 6, 353, 3443, 4, 77, 27, 434, 1169, 7, 930, 5, 69, 12, 20, 8935, 1171, 15, 4, 418, 27, 201, 1022], [85, 12, 10, 639, 2361, 17, 59, 4, 56, 15, 10, 115, 102, 338, 17, 771, 8, 139, 3390], [85, 12, 10, 310, 14, 2, 19, 1], [85, 12, 7, 247, 16, 4, 4724, 3, 168, 6, 1181, 13, 6, 1341, 17], [85, 12, 22, 1, 313, 2904, 128], [85, 427, 6033, 11, 4, 178, 57, 2, 24, 43, 4942, 48, 21950, 162, 4, 54, 345, 241, 52, 109, 505, 43, 4982, 4597, 21951], [85, 153, 14, 90, 205, 55, 233, 100, 17, 259, 774], [85, 43, 21952, 16, 529, 7119], [85, 364, 49, 77, 96, 2699, 66, 101, 41, 201, 707, 6, 259, 1, 5, 165, 313, 7, 30, 108], [85, 4, 19, 195, 3, 28, 6023, 59, 268, 187, 28, 791, 18, 1126, 3, 5444, 21953, 2, 19], [85, 4, 19, 49, 4, 313, 2640, 2905, 390, 1084, 2355], [85, 4, 19, 12, 22, 1, 79, 17, 21], [85, 4, 247, 590, 1, 14, 533, 45, 78, 41, 295, 165, 6, 58, 34, 81, 45, 479, 35, 4, 5782, 8, 907, 18, 2, 1270], [85, 4, 1039, 409, 77, 419, 8, 4, 9, 14, 1354, 464], [85, 39, 1, 14, 525, 610, 33, 6, 448, 406, 16, 166, 1, 3, 29, 28, 15], [85, 39, 9, 156, 238, 14, 1, 29, 36, 62, 7, 9, 75, 14, 1820, 149, 36, 9], [85, 39, 640, 1, 122, 6, 167, 17, 35, 1099, 54, 16, 10, 2737, 1558], [85, 47, 5334, 2864, 1462, 58, 21954, 44, 2, 125, 7, 486, 21955, 1183, 21956, 49, 36, 1491, 16, 4, 3368, 24], [85, 266, 66, 298, 4, 466, 305, 1248, 21957, 12, 144], [85, 118, 3, 14, 214, 51, 2, 1, 69, 487, 433, 4, 8710, 940, 151, 304], [85, 118, 3, 19, 2, 1, 7, 75, 19, 383, 13, 42, 9, 29, 67, 67, 2, 25, 125, 2, 4172, 21958], [85, 118, 5, 438, 98, 183, 77, 69, 12, 560, 2, 1139, 1], [85, 118, 5, 86, 2269, 12, 56, 364], [85, 78, 1, 14, 1412, 3070, 2873, 18, 78, 2630, 30], [85, 367, 2508, 205, 49, 5, 144], [85, 5, 475, 133, 2, 1, 441, 21959, 178, 2777, 21960, 34, 43, 401], [85, 5, 172, 125, 2, 145, 31, 5, 46, 172, 125, 2, 112, 145], [85, 5, 146, 14, 270, 2, 9, 251, 3, 46, 2216, 492, 2, 9], [85, 5, 100, 39, 9, 1516, 57, 66, 124, 1880, 5, 8507, 14, 5419, 5419], [85, 5, 100, 39, 9, 1516, 57, 66, 124, 117, 1880], [85, 5, 982, 119, 24, 650, 5, 64, 50], [85, 5, 3247, 133, 2, 1, 26], [85, 5, 81, 6, 9, 59, 280, 4714], [85, 5, 86, 32, 39, 25, 450, 35, 27, 32, 39, 265, 19, 183, 1], [85, 5, 475, 133, 7, 166, 9, 218, 7, 166, 9, 46, 475, 133, 246, 9], [4885, 354], [1039, 124, 4, 9, 108, 88], [103, 3424, 21961, 14, 384, 5167, 2104, 6, 114, 129, 642, 401, 73, 263, 5457, 381, 527], [103, 14, 1489, 6, 194, 71, 21962, 6100, 11, 22, 3270, 21963, 347, 339, 4, 1802, 1072, 21, 21964, 790, 22, 2861], [103, 1182, 4, 9, 251], [103, 5, 506, 7, 24, 21, 17], [103, 175, 801, 65, 51, 17, 23, 2, 21965, 30, 1, 13, 473, 16, 4, 1212, 115, 11, 2, 2501], [2090, 2, 9, 52, 121, 7, 45, 201, 213, 892], [3459, 1217, 23, 59, 6, 19, 50, 117, 11, 4, 24], [21966, 21967, 12, 21, 112, 638, 21968, 12, 21, 24], [1444, 106, 294, 12, 43, 9, 1335], [1444, 1032, 276, 44, 2, 145, 11, 84, 150, 26], [8069, 233, 133, 6, 227, 4, 1862, 108, 18, 233, 29, 2266, 602, 169, 125, 42, 153], [301, 118, 139, 14, 1810, 8, 14, 2, 141, 21969, 107, 6, 4761, 1, 21970, 346, 5], [301, 3, 2063, 121, 127, 6, 1146, 93, 94, 5, 1298], [301, 3, 41, 9, 13, 1297, 5608], [301, 3, 118, 100, 5, 2595, 11, 10, 1434, 188, 274, 1236, 5, 545, 1238, 11, 20, 21971, 1810, 30, 1, 28, 35, 26, 192, 1862], [301, 3, 124, 2, 89, 1, 390, 162, 36, 51], [301, 3298, 1226, 21972, 32, 8793, 58, 7, 5786, 387, 385, 3, 86, 15, 8397], [27, 2, 24, 3757], [27, 95, 151, 958, 22, 1045, 1535], [27, 10, 237, 1], [27, 10, 3635, 11, 2672, 8201, 4223, 1, 1796, 10, 65, 4361], [27, 43, 8936, 2087, 234, 9, 32, 7, 21973, 996, 17, 163, 101, 17], [27, 4, 95, 3, 958, 22, 1045, 21974], [27, 4, 1, 26, 3630], [27, 80, 4784, 30, 1], [461, 21975, 4, 95, 21976, 4, 2192, 1276, 4, 2994, 632, 4, 360, 21977, 4, 2179, 4466, 4, 2190, 8209, 34, 3, 309, 461, 21978], [461, 4, 9, 15, 47, 152, 14, 332, 21, 263, 6, 479, 54, 93, 287, 37, 9, 5, 58, 2, 93, 401, 21979, 18, 9], [1336, 6544, 47, 4, 247, 21980, 992, 11, 10, 21981, 66, 598, 6, 627, 32, 4, 1839, 22, 399, 192], [1336, 514, 84, 1, 6, 22, 25, 46, 43, 441, 11, 4, 360, 870, 602, 6, 547, 170, 28, 129, 7], [1336, 87, 6, 61, 108, 6, 4, 21982, 368, 21983, 1336], [1336, 299, 52, 222, 227, 84, 9, 173, 2, 331, 436], [3756, 227, 173, 2, 9, 211, 2, 421, 35], [1025, 35, 587, 3958, 1, 163, 1855, 18, 1165, 1446], [1025, 35, 325, 561, 1434, 1207, 27, 21984, 2657, 318, 1099, 785, 957, 709, 390, 163, 1236, 4, 9, 1546], [1025, 35, 150, 13, 2, 83, 152, 139, 208, 13, 2, 1, 129, 60, 669, 45, 8, 1841, 18, 531, 615, 15, 17, 106, 321], [1025, 35, 4, 244, 561, 13, 1542, 11, 2843, 19, 200, 3, 3083, 10, 873, 6, 39, 2937, 894], [414, 912, 50, 30, 6, 333, 5, 8, 5, 557, 50, 13, 45, 218, 5, 2, 8070, 30, 161, 2756, 221, 19, 32, 5, 9, 30, 956], [414, 44, 1442, 437, 33, 73, 209, 73, 21985, 32, 22, 21986, 8074, 59, 21987, 33, 134, 76, 144, 231, 74, 609, 5965], [287, 75, 58, 256, 79, 259, 21988, 7, 14, 2, 282], [287, 271, 1580, 59, 126, 91, 1757, 8, 454, 85, 20, 228, 19, 21989, 21990, 1482, 282], [287, 168, 25, 32, 4, 106, 21, 21991, 1405, 8, 2759, 31, 2, 1, 131, 303, 17, 60, 4773, 3, 46, 227, 45, 2014], [287, 67, 2, 237, 91, 2368, 409, 16, 25, 2842, 5, 44, 214, 593, 327, 18, 97, 2046, 81, 59, 1539, 222, 14, 6077, 1, 309], [287, 69, 49, 3746, 49, 4, 183, 1, 69, 75, 258, 2, 91, 21, 943], [266, 430, 17, 1465, 1877, 7, 972, 4, 942], [266, 795, 586, 17, 282, 55], [21992, 983, 126, 21993, 1957, 3164, 16, 4, 658, 8, 6093, 51, 2247], [324, 8, 24, 8, 1795, 462, 176, 828, 2688], [324, 6, 1410, 1173, 31, 3, 791, 5, 46, 223, 14, 43, 2285, 83, 101, 193, 459, 22, 12, 11, 2, 874, 74, 11, 21994], [324, 6, 10, 95], [324, 35, 277, 2982, 93, 21995, 2, 1120, 1], [8517, 34, 57, 523, 706, 2, 186, 1562, 12, 60, 1, 385, 91, 35, 26, 3963, 50, 706, 321], [324, 21, 10, 419, 638, 54, 135, 99, 239, 89, 1, 165, 130, 4, 215, 37, 105, 1513, 2, 418, 91, 36, 1075, 8, 7, 3351], [197, 25, 19, 197, 15, 928, 1, 19, 928, 32, 59, 1445, 740, 103, 14, 3232], [197, 14, 44, 2, 1, 21996, 8, 385], [197, 12, 270, 2, 1, 117, 92], [197, 54, 9], [197, 117, 92, 12, 1], [197, 1445, 12, 21, 4, 95], [360, 1317, 2268, 12, 18, 2676, 4337, 1, 4337], [360, 796, 104, 55], [884, 45, 21997, 21998, 330, 56, 8, 6, 1223, 7, 56, 45, 125, 4, 6085, 21999, 7, 12, 3079, 12, 2023, 56], [118, 5, 14, 1489, 11, 60, 2568, 987, 18, 17], [118, 5, 467, 27, 2, 399, 58, 5, 366, 441], [118, 5, 516, 14, 2, 269, 74, 2, 3342, 1776, 374, 398, 1031, 34, 31, 3, 124, 6, 1668, 2, 2319, 22000], [1560, 13, 60, 127, 8781, 34, 3, 63, 806, 531, 641, 2, 1190, 16, 4386], [583, 7, 2, 185, 1], [583, 3, 300, 23, 152, 187, 929, 5], [583, 2143, 7993, 249, 809, 8, 84, 1309, 121, 22, 145, 63, 137, 21, 22001, 5728], [583, 10, 22002, 29, 13, 161, 22003, 22, 145, 1070], [583, 10, 586, 33, 3065, 17, 57, 2, 181], [583, 786, 29, 67, 22], [583, 159, 870, 12, 656, 1728, 318, 14, 22004, 16, 546, 1525, 230, 52, 12, 2433], [583, 4, 8928, 51, 4, 1289, 460, 1129, 1742, 307, 3, 210, 110, 168, 245, 89, 324, 485, 10, 529, 592, 1544, 1083, 200, 2021], [2375, 43, 190, 478, 903, 22005, 8, 8912, 22006, 485, 43, 190, 107], [22007, 37, 22, 12, 85, 180, 815, 220, 4044, 225, 42, 1, 139, 4, 908, 188], [22008, 22, 1, 12, 37, 590, 1084, 2678], [2171, 4, 1064, 884, 1010, 16, 10, 164, 215, 449, 8, 96, 41, 2, 22009, 146, 64, 114, 1554, 2965], [369, 3, 65, 13, 308, 59, 62, 2, 1, 21, 31, 3, 29, 62, 4, 9, 3, 29, 62, 4, 282, 364, 15, 1310], [369, 195, 3, 194, 8736, 3, 1100, 194, 39, 183, 30, 179, 9, 157, 116, 730, 226, 6, 1898], [369, 1], [369, 21, 112, 92, 32, 39, 185, 1, 49, 311, 129, 60, 265, 366, 1616, 3, 63, 3014, 129, 470, 16, 76, 366, 1616, 943], [369, 22010, 17, 4, 9, 8739], [22011, 292, 115, 26, 292, 264, 31, 3, 61, 246, 22012, 32, 3, 62, 12, 23, 61, 673, 22013], [3286, 24, 1707], [4183, 2, 1], [5231, 2, 9, 52, 105, 541, 3829], [693, 825, 270, 2, 669, 9, 163, 22, 658, 48, 2, 93, 65, 1154], [693, 3581, 22014, 3418, 404, 6015, 7, 10, 412, 1], [693, 42, 2, 1, 277], [78, 72, 5, 452, 119, 50, 24, 127, 21, 17], [78, 663, 165, 442, 11, 648, 188, 7, 1, 241, 37, 112], [78, 32, 60, 9], [78, 14, 431, 54, 116, 11, 7, 587, 778, 76, 9], [78, 14, 134, 4, 22015, 1, 37, 209, 1617, 139, 254], [78, 14, 100, 97, 234, 1, 11, 4, 331, 78, 1070], [78, 1, 365], [78, 1, 14, 107, 35, 27, 60, 171, 2355, 57, 4, 19, 12, 22016], [78, 1, 165, 139, 4, 214, 2059], [78, 1, 87, 6, 22017], [78, 1, 131, 14, 37, 511, 8, 78, 109, 37, 339], [78, 1, 67, 2, 93, 252, 34, 75, 14, 112, 51, 32, 88, 67, 6, 924, 76, 21, 126, 2522, 6, 20, 3282, 632, 4, 19, 562], [78, 63, 44, 5267, 22018, 65, 13, 2, 718, 6, 17], [78, 63, 44, 39, 37, 79, 1983, 8183, 23, 65, 21, 2, 3097, 13, 7369, 22019, 4525], [78, 63, 72, 4075, 70, 15, 193, 22020, 130, 22021, 5, 67, 34, 773, 23, 152, 44, 501, 1, 37, 249, 2, 22022], [78, 171, 1, 54, 135, 19, 35], [78, 1182, 123, 39, 1, 3204, 25, 167, 287, 251, 69, 878, 5], [78, 617, 339, 97, 915, 398, 529, 23, 3647, 39, 9, 54, 135, 3055, 1548], [78, 9, 442, 393, 464], [78, 9, 291, 14, 719, 82, 4, 1483, 34, 14, 1764], [78, 9, 29, 87, 2, 1987, 78, 87, 847], [78, 9, 64, 744], [78, 9, 530, 100, 245, 481, 167, 98, 119, 78, 54, 251], [78, 9, 109, 28, 214, 149, 2, 25, 29, 67, 4022], [78, 9, 37, 1035], [78, 62, 57, 23, 267, 22023, 97, 1, 695, 10, 746, 356], [78, 1045, 30, 1, 362, 58, 134, 54, 2, 320, 16, 575, 22024], [78, 435, 87, 6, 194, 39, 22025, 22026, 1, 14, 44, 8890, 2627, 26, 18, 2, 1212, 115, 22027, 8937, 62, 4, 511], [78, 4875, 6447, 237, 64, 10, 3311, 460, 11, 22028, 22, 45, 12, 330, 2, 83], [78, 25, 46, 81, 133, 22029, 48, 2, 1162, 48, 2, 48, 2, 1162, 9], [78, 24, 30, 1956, 87, 6, 70, 60, 420, 233, 28, 35, 116], [78, 109, 4757, 174, 259, 1349, 11, 26, 54, 16, 2924, 2742, 785, 268, 2628, 21, 60, 24], [78, 486, 71, 214, 7, 141, 1485, 177, 47, 52, 452, 110, 100, 84, 586, 881, 170, 321, 128], [78, 376, 18, 933, 2414, 379, 22030], [78, 249, 18, 567, 95], [78, 86, 118, 79, 10, 1246, 2, 158], [78, 122, 6, 168, 4, 1403, 6, 506, 24, 18, 22, 22031, 3, 330, 62], [78, 175, 4, 199, 45, 2026, 3, 28, 108, 18, 22, 1], [78, 597, 364, 562, 78, 49, 24, 15, 850, 106, 227, 364, 35], [78, 804, 18, 1184, 365, 9, 21, 701], [367, 43, 103, 5, 303, 4, 154, 8345, 1232, 2304, 16, 354], [22032, 156, 28, 906, 35, 27, 22033, 1655, 428, 124, 2, 1388, 27, 1155, 25, 28, 613, 2, 303, 1], [5, 8, 76, 1, 7, 5, 510, 125], [97, 1, 46, 89, 25, 42, 46, 41, 43, 578], [97, 1, 339, 31, 40, 1070, 102, 20, 685, 1848, 22034], [97, 1, 2797], [97, 1, 41, 10, 537, 3402, 11, 50, 967, 8881, 15], [97, 1, 24, 93, 3, 46, 566, 15, 749, 3, 132, 11, 116], [97, 1, 7958, 498, 27, 17], [97, 1, 171, 73, 19, 21, 4, 22035], [97, 636, 25, 41, 268, 22036, 38, 4, 161, 1, 192, 22037, 1358, 94, 39, 175, 74, 217, 103, 1431], [97, 215, 153, 487, 257, 15, 233, 3, 167, 15, 13, 2, 351, 313], [97, 215, 153, 487, 257, 15, 188, 3, 167, 15, 13, 2, 351, 313], [97, 1722, 185, 30, 1, 3, 46, 4247, 22038], [97, 87, 2, 112, 25, 1619, 37, 107, 26, 313, 7, 24, 8891, 2851], [78, 114, 22039, 116, 46, 105, 4285, 162, 207, 617, 259], [8938, 1], [6970, 1, 8938], [22040, 1, 11, 127, 1768, 22041], [22042, 39, 1, 611, 53, 5, 29, 13, 17, 85, 4980, 10, 228, 22043, 7, 339, 71, 77, 22044], [22045, 38, 2, 9, 12, 81, 59, 71, 36, 109, 29, 14, 4620, 13, 77, 31, 5, 146, 1365, 1770, 4981, 2, 282], [22046, 1, 22047], [2346, 383, 181, 1464, 7114, 4, 45, 54, 16, 10, 761], [78, 145, 41, 17, 19, 35, 1265, 272, 1221, 30, 1416, 751, 2, 64, 323, 6, 5, 30, 145, 26], [78, 1, 14, 13, 78, 30, 672, 425], [78, 1, 101, 1387, 38, 78, 343, 19, 35, 1335, 139, 7, 379], [78, 1, 198, 14, 504, 21, 923, 371, 78, 132, 22048, 32, 213], [78, 202, 30, 9, 46, 1398, 1644], [78, 63, 139, 7052, 7, 8939, 45, 99, 218, 23, 96, 276, 119, 1271, 982, 44, 748, 4, 813, 171, 83], [78, 487, 304, 634, 923, 6, 472, 35, 13, 9], [78, 29, 67, 2, 25, 650, 166, 1, 67, 8911, 34, 38, 5, 28, 170, 5, 28, 214, 218, 212, 199, 1, 96, 67, 1167], [78, 9, 41, 295, 165, 6, 58, 130, 6, 2468, 8, 137, 22049], [78, 9, 96, 137, 224, 27, 4, 329, 45, 3, 8278, 1936], [78, 62, 2931, 22050, 12, 59, 6, 935, 84, 3078, 129, 2578, 55], [78, 100, 39, 9, 19, 5, 27, 4, 1882, 211, 5, 121, 43], [78, 259, 21, 1, 8, 22051, 66, 259, 21, 441, 8, 169], [78, 54, 135, 172, 166, 287, 435, 4757, 97, 164, 26, 2964, 34, 23, 54, 135, 419, 26, 4418, 27, 43, 1, 5, 146, 475, 2195], [78, 94, 22052, 265, 180, 30, 202, 1], [78, 22053, 39, 1928, 289, 105, 132, 7, 4335], [22054, 146, 389, 17, 21, 138, 23, 22055, 1, 183], [232, 22056, 70, 17, 32, 22057], [232, 8711, 318, 14, 4, 237, 8334, 11, 4, 8281, 34, 4, 8831, 1540, 68, 49, 4, 884, 2816, 65, 13, 98, 3387, 941, 11, 2, 5968, 4822], [232, 28, 204], [232, 434, 852, 8603, 6053, 168, 6, 257, 436, 5910, 22058, 135, 40, 12, 11, 22059, 2347, 2285], [232, 658, 129, 1000, 37, 1530], [232, 198, 44, 105, 502, 423, 22060, 189, 63, 1165, 54, 7265], [232, 982, 8492, 18, 4, 358, 466, 11, 4, 1408], [1316, 955, 22061, 514, 445, 5741, 375], [1316, 266, 70, 4, 1408, 34, 66, 46, 11, 4, 1057, 22062, 7, 4, 355, 1111, 8734], [97, 1, 97], [97, 1], [2664, 1, 2875], [2664, 1, 23, 524], [2664, 348, 26, 684, 853], [2939, 23, 2, 388, 864, 16, 45], [22063, 23, 152, 14, 1429, 102, 6, 39, 1, 32, 115, 225], [8940, 1, 8940], [447, 3, 94, 97, 9], [447, 23, 3758, 341, 73, 2, 8304, 83], [447, 2553, 20, 2, 22064, 757, 3, 259, 11, 2, 172, 56, 8829], [447, 1417, 388, 120, 2967, 185, 158, 8276, 54, 126, 347, 61, 142, 4, 1540, 122, 6, 167, 18, 17, 19, 4878], [447, 1, 71, 147, 45, 150], [447, 1492, 2, 320, 16, 2808, 56, 81, 61, 18], [447, 6879, 7, 120, 22065, 396, 10, 413, 453, 7, 9, 417], [447, 5, 89, 34, 9, 37, 57], [447, 5, 89, 34, 9, 37, 57], [447, 1480, 124, 2, 22066, 6091, 11, 5159], [447, 10, 1, 12, 2349, 37, 57], [22067, 1, 3, 14, 27, 381, 13, 7815, 447, 66, 271, 656, 34, 66, 28, 537, 13, 2139], [221, 890, 524, 857, 4, 2166, 3328, 5551, 207, 25, 16, 32, 106, 21, 7, 43, 908, 323, 340, 7, 1314, 71, 3, 14, 1596], [221, 3, 63, 33, 113, 123, 4, 1032, 7, 3, 266, 14, 525, 245, 24, 225], [221, 3, 44, 22068, 34, 3, 96, 349, 2394, 1, 130, 5, 8941], [221, 3, 122, 8, 5, 1426, 32, 1380, 8, 385, 55, 1258, 83], [221, 22069, 87, 6, 28, 19, 35, 27, 22, 172, 591, 2146, 22070, 41, 5653, 8718, 142, 4, 1, 98, 45], [221, 1], [221, 283, 5, 62, 52, 47, 341, 45, 108, 11, 4, 115], [221, 9], [221, 282], [221, 282], [221, 23, 2478, 117, 39, 1, 544, 329], [221, 15, 47, 2, 434, 68, 428, 23, 19, 1943, 1], [221, 550, 100, 33, 157, 2, 739, 353, 11, 2, 5268, 2215, 8, 94, 57, 582], [221, 117, 221, 117, 22, 189, 2, 711], [221, 7, 162, 20, 614, 6, 157, 4, 56, 22071], [221, 4, 1593, 56, 73, 19, 21, 22, 6037, 45], [221, 36, 2019, 2604, 983, 135, 51, 4, 4409, 1337, 4, 355, 1111, 22072], [221, 5, 89, 34, 9, 37, 57], [221, 5, 1], [221, 20, 1256, 18, 446, 34, 12, 97, 24, 656], [221, 3, 124, 2, 1, 34, 40, 46, 89, 73, 5, 37, 167, 17, 35, 38, 5, 433, 539], [221, 23, 37, 589, 444, 5, 87, 22073, 3, 29, 137, 7, 45, 19, 27, 10, 548, 8, 151, 70, 5, 301], [221, 52, 911, 6, 72, 22074, 216, 2, 2638, 21, 79, 83], [22075, 36, 566, 23, 19, 879, 13, 4, 1008, 16, 2, 181], [6517, 177, 10, 1290, 153, 273, 17, 147, 22076], [2805, 105, 297, 2, 203, 25, 18, 2, 1361, 1, 571, 505, 1406], [2805, 43, 112, 153, 31, 2805, 41, 43, 1202, 2555, 163, 20, 1213, 2142], [7381, 47, 172, 56], [190, 1925, 51, 1069, 2539, 56, 63, 49, 4, 884], [1962, 1171, 8, 105, 22077, 2811, 42, 182, 124, 60, 24, 37, 93, 5, 471, 2, 2236, 57, 49, 8609, 262], [1962, 2831, 3033, 254, 7, 2207, 2341, 215, 264, 47, 56], [367, 26, 43, 12, 15, 422, 6, 257, 2, 1, 35, 129, 60, 175, 74, 336], [367, 3, 64, 352, 3, 273, 80, 1, 14, 4, 4133], [367, 1, 5, 96, 11, 64, 11, 4706, 40, 308], [367, 3415, 439, 274, 424, 1037, 106, 18, 2419, 463, 44, 767, 13, 7431, 22078, 7154, 23, 202], [367, 22079, 19, 5, 1, 23, 1397, 5, 525, 259, 740], [367, 183, 1, 27, 4, 1096, 5656, 1958, 22080, 343, 5, 200, 114, 311], [367, 367, 367, 7, 32, 5, 223, 465, 105, 704, 2, 9, 478, 7, 2, 113, 17, 43], [367, 22081, 8, 22082, 49, 10, 153, 41, 15, 1665, 132, 304, 707, 21, 22, 658, 8428], [367, 23, 2, 1031, 120, 91, 27, 388, 8058, 69, 1064, 64, 22083, 22084, 19, 5, 5468], [2140, 8, 443, 1305, 333, 113, 17, 5, 210, 303, 7, 56], [22085, 5, 62, 22, 91, 42, 41, 60, 1440, 181, 177, 23, 1506, 785], [1157, 47, 98, 32, 224, 93, 921, 434, 921, 486, 2, 320, 16, 111, 3, 745, 297, 11, 2, 288, 8, 41, 314, 73, 4411, 24], [1157, 3, 486, 2, 355, 343, 58, 27, 6054, 16, 1685, 8, 190, 11, 254, 3557, 35, 13, 8877, 1932, 22086, 22087], [478, 5, 266, 1318, 57, 2, 285, 53, 22088, 57, 2, 5173, 53], [80, 3, 346, 350, 97, 838], [80, 42, 100, 7, 2710, 2931, 28, 423, 27, 8680, 19, 42], [80, 23, 48, 2, 1, 34, 29, 114, 10, 748, 117, 8, 3, 103, 19, 671, 1155], [80, 1, 3, 124, 501, 27, 7], [80, 1, 541, 13, 40, 1863, 19, 22089], [80, 1, 2, 1125, 19, 136, 6, 376, 8, 147, 47, 4, 215, 106, 3, 47, 1705, 962, 26, 8486, 3, 1025, 136, 35, 579, 19, 136, 361, 37, 40, 46, 376, 358], [80, 1, 32, 129, 17, 3, 46, 70, 43, 1694], [80, 1, 30, 87, 6, 900, 4, 19, 562], [80, 1, 2797, 33, 100, 50], [80, 1, 2797, 33, 6115], [80, 1, 2797, 33, 100, 50], [80, 1, 22090, 33, 6115], [80, 1, 7816, 40, 2523, 22091], [80, 1, 61, 1060, 127, 1634, 18, 50, 24, 88, 10, 347, 58], [80, 1, 62, 827, 23, 533, 133], [80, 1, 13, 6, 28, 342, 8, 61, 4, 629, 1151, 10, 1, 13, 6, 28, 595, 8, 61, 6, 4, 743, 3414], [80, 1, 18, 10, 138, 40, 107, 6, 10, 967, 40, 28, 433, 224, 43, 64], [80, 1, 40, 4655, 40, 41, 7, 22092, 24], [80, 1, 131, 19, 4, 1916], [80, 1, 131, 19, 4, 1916], [80, 63, 5, 189, 139, 14, 141, 1, 33, 62, 474, 582, 21, 2, 540, 16, 20, 1456, 6, 14, 5, 103, 14], [80, 803, 12, 2, 1, 5, 383, 2, 386, 16, 7, 22093], [80, 19, 22094, 21, 7, 2786, 3959, 1, 1179, 6, 298, 129, 189, 496, 3965, 278, 311, 2, 1, 129, 760], [80, 19, 4, 2378, 36, 49, 96, 1], [80, 9, 12, 13, 2, 4684, 37, 40, 2280, 21, 2, 1009], [80, 3036, 203, 8, 41, 2, 3074, 43, 87, 6, 22095, 1, 53, 7], [80, 31, 5, 28, 13, 129, 1727, 16, 567, 95, 5, 87, 6, 58, 60, 653, 8738, 140, 5, 415, 44, 43, 164], [80, 455, 1, 7, 10, 234, 9], [80, 373, 3036, 854, 5, 2, 1699, 1], [80, 24, 46, 45, 650, 5, 124, 60, 11, 15], [80, 24, 46, 45, 650, 5, 124, 60, 2407, 82, 654, 3240, 11, 15], [80, 24, 132, 539, 15, 21, 4, 1079, 22096, 22097, 26], [80, 24, 4016], [80, 7, 25, 51, 47, 308, 124, 78, 1, 79, 170, 97, 3059, 8, 32, 71, 58, 42, 22098, 108, 6, 5, 3085], [80, 7, 826, 11, 2719, 407, 22099, 27, 7, 1, 128], [80, 22, 145, 430, 155, 175, 2042, 241, 10, 93], [3154, 188, 22, 1, 11, 7708, 122, 6, 298, 54, 4, 1333, 27, 2, 22100, 16, 754, 8, 41, 906], [3294, 136, 132, 224, 21, 1247, 8, 39, 1, 33, 92, 1244, 15, 54], [22101, 348, 124, 17, 8830, 35, 314, 215, 264], [4120, 18, 22102, 1539, 12, 4, 796, 120, 56, 2628, 11, 4, 6144], [5, 715, 66, 94, 22103, 1123, 15, 54, 6, 4, 5704, 715], [5, 87, 98, 1074, 6, 168, 126, 185, 194, 1232, 12, 33, 1071, 111, 2303, 8, 1448, 4, 169, 54, 16, 3690, 22104], [5, 2, 339, 30, 1], [5, 2, 1], [5, 2, 2610, 149, 80, 91, 2, 285], [5, 2, 104, 31, 5, 316, 2, 1925, 6, 197, 8, 176, 15, 51, 97, 4555, 2739, 4, 1294, 12, 5142], [5, 2, 9, 8, 6391, 62], [5, 2, 9, 21, 48, 44, 799, 18, 860, 813], [5, 2, 9, 31, 42, 119, 1468, 1901], [5, 2, 9, 31, 5, 345, 140, 80, 30, 8332, 15, 47, 32, 872, 288, 5, 47, 498, 7, 138, 83], [5, 2, 9, 31, 5, 182, 22105, 211, 5718], [5, 2, 9, 31, 5, 13, 525, 551], [5, 2, 9, 31, 5, 114, 2, 3842, 6, 4, 489], [5, 2, 282], [5, 2, 564, 30, 25, 96, 2209, 39, 9, 10, 1, 41, 2, 1, 27, 1905], [5, 2, 24, 797], [5, 2, 24, 9, 444, 5, 134, 17, 24, 9], [5, 2, 112, 164, 104, 31, 5, 182, 290, 246, 91, 140, 52, 19, 20, 2449, 5, 33, 146, 114, 7, 1432, 13, 2, 91, 8, 420, 18], [5, 2, 1521, 2063, 2062, 30, 145, 272, 301, 2, 145, 118, 2422, 689, 30, 145], [5, 2, 185, 9], [5, 2, 360, 521, 9], [5, 46, 41, 43, 401, 43, 7620, 43, 169, 1, 51, 20, 915, 38, 36, 29, 134, 5, 169, 21, 441, 478, 66, 87, 6, 208, 13, 2008], [5, 46, 10, 1, 37, 161, 1, 85, 5, 2450], [5, 46, 10, 1, 37, 161, 1, 85, 5, 2450], [5, 46, 10, 455, 1, 37, 85, 4, 810, 58, 5, 279], [5, 46, 777, 34, 2, 864, 16, 873, 27, 54, 4, 1825, 11, 166, 324, 5, 46, 105, 223, 14, 2, 2583, 1], [5, 46, 1916, 161, 1], [5, 46, 1174, 948, 28, 97, 845, 9], [5, 32, 49, 144, 31, 5, 109, 2598, 47, 122, 6, 1877, 32, 212, 992, 29, 86, 33, 218, 226, 220, 121, 52, 47, 107, 51, 76], [5, 156, 303, 17, 207, 4763, 38, 10, 4654, 12, 702, 8, 5, 49, 2, 4210, 2660, 6, 17, 8], [5, 156, 258, 256, 6, 1, 2195], [5, 156, 94, 60, 45, 18, 206, 1648, 5535, 18, 4, 713, 264, 3, 328, 297, 13, 445, 718, 8, 2, 6102], [5, 8, 7, 4947, 45, 63, 28, 364, 102, 22, 8064, 114, 39, 2577, 9, 27, 5, 776], [5, 8, 2785, 1, 30, 22106, 28, 737, 705], [5, 49, 2, 177, 5, 29, 72, 22107, 181, 809, 7, 7, 1, 45, 3623, 7377], [5, 49, 2, 83], [5, 49, 2, 83], [5, 49, 2, 22108], [5, 49, 2239, 144], [5, 49, 37, 365, 26, 23, 61, 6, 157, 5, 18, 1626, 83], [5, 22109, 133, 2, 1, 8, 40, 2, 274, 148, 22110], [5, 191, 17, 59, 862, 571, 70, 147, 1, 10, 1], [5, 51, 4, 489, 155, 449, 1, 28, 2, 164], [5, 132, 4, 234, 9], [5, 165, 1646, 6, 274, 3, 29, 13, 80, 1, 149, 66, 318, 430, 387, 8, 40, 318, 28, 167], [5, 165, 194, 20, 9, 40, 172, 326], [5, 165, 197, 1], [5, 1, 1556, 5, 105, 262, 17, 4903, 63, 5, 380, 69, 22, 4650, 281, 3, 105, 262, 621, 108, 10, 89], [5, 1, 13, 6, 262, 1217], [5, 1, 32, 41, 7, 68, 228, 69, 255, 4, 199, 1023, 6, 155, 166, 2508, 8, 15, 29, 110, 14, 7, 656], [5, 1, 49, 284], [5, 1, 75, 1342, 6, 307, 37, 2498], [5, 1, 41, 17, 32, 4, 193, 19, 35, 1153, 71, 239, 2626, 78, 119, 20, 24, 96, 276, 578, 4, 199, 37, 134, 7, 45, 35, 333], [5, 1, 70, 17, 549], [5, 1, 7, 1182, 32, 4, 701, 5, 28, 82, 39, 25, 49, 4, 884, 698, 16, 9, 116, 12], [5, 1, 255, 645, 744, 49, 3955, 3, 62, 78, 2503, 4, 199, 2035, 292, 115, 11, 2, 3363, 5, 75, 902, 17], [5, 1150, 1, 87, 2, 5771], [5, 2590, 10, 1009, 33, 71, 22111, 8, 71, 209, 3427, 98, 4281, 1, 5, 1563, 31, 42, 122, 6, 229, 102, 151, 788, 579, 247, 13, 61, 879], [5, 63, 191, 31, 3, 19, 2, 1, 34, 75, 191, 71, 10, 1544, 115, 47, 188, 39, 9, 14, 459, 493], [5, 63, 14, 2, 9, 11, 64], [5, 63, 303, 2, 1, 22112, 11, 4, 360, 3, 394, 40, 96, 258, 256, 6, 733, 59], [5, 63, 303, 22113, 2225, 205], [5, 63, 303, 10, 19, 164, 8, 814, 105, 110, 2085, 2, 1513, 139, 345, 1], [5, 63, 79, 17, 2, 1, 422, 34, 2, 4, 22114, 28, 54, 16, 1184, 3584], [5, 63, 772, 17, 6, 14, 2, 966, 1, 2018, 5, 92, 478, 1404], [5, 63, 101, 72, 4, 324, 664, 31, 15, 3951, 6, 4, 324, 8882, 88, 220, 966, 431, 3095], [5, 63, 72, 23, 33, 2, 902, 7, 397, 21, 2766, 219, 6, 7, 3, 72, 20, 2, 187], [5, 75, 14, 214, 38, 111, 79, 5, 2, 9, 31, 5, 54, 135, 208, 13, 68], [5, 75, 924, 17, 21, 4, 1, 3, 22115, 78, 72, 272, 1034, 38, 3, 81, 59, 1928, 34, 7, 716, 57, 3, 14, 22116], [5, 75, 79, 2, 1, 2, 1, 31, 20, 2, 1], [5, 75, 1632, 17, 45, 3, 29, 302, 153], [5, 75, 1632, 17, 45, 432, 302, 153], [5, 75, 137, 17, 21, 2, 902, 10, 145], [5, 75, 157, 393, 722, 2, 154, 1648, 83, 74, 2, 2397, 83, 74, 2, 2962, 83], [5, 75, 157, 4, 24, 18, 2, 8764], [5, 75, 1175, 3397, 461, 843, 37, 843, 74, 557, 1], [5, 75, 557, 39, 9, 13, 462], [5, 75, 302, 43, 418, 7, 41, 2, 1245, 534, 340, 212, 1, 14, 214, 3308], [5, 75, 113, 39, 1, 8022, 36, 1642, 6, 4, 620], [5, 222, 14, 1535, 4, 1152, 539, 6060, 1178, 22117, 127, 21, 4697], [5, 222, 19, 10, 1, 1416, 19, 80, 1], [5, 143, 22118, 5, 655, 2, 3437, 1], [5, 58, 256, 511, 5, 227, 54, 2, 9], [5, 29, 44, 6, 72, 254, 5, 229, 22119, 1, 357, 121, 3, 200, 92, 242, 4, 19, 35, 7, 203, 216, 5, 144], [5, 29, 62, 17, 34, 23, 20, 22120, 22121, 646, 2005, 1486, 1653, 72, 286, 3051, 54, 73, 2, 22122], [5, 328, 27, 7, 1353, 1, 74, 188], [5, 467, 480, 828, 22123, 57, 2, 24], [5, 171, 1, 5, 86, 3, 197, 21, 351], [5, 22124, 1, 3, 29, 13, 5, 71, 332, 12, 15, 6, 594], [5, 182, 651, 59, 19, 2, 418, 19, 50, 11, 112, 164, 88, 4, 24, 47, 165, 11, 4, 651], [5, 182, 124, 2, 864, 16, 24, 91, 7, 14, 18, 20, 453, 13, 169], [5, 182, 44, 352, 27, 2, 22125, 3, 157, 7, 24, 11, 2, 22126], [5, 182, 3436, 1025, 35, 8, 97, 1, 397, 129, 5, 33, 22127], [5, 182, 94, 1, 1088, 18, 2, 1454, 13, 2229, 10, 274, 7, 986, 4086, 148, 219, 40, 118, 1161, 58, 60, 45, 13, 7, 22128], [5, 182, 297, 2, 595, 22129, 7796, 11, 2898, 3378, 65, 76, 35, 615], [5, 181, 1617, 7, 45, 35, 37, 209, 8, 3, 477, 6, 2021, 474, 12, 1439], [5, 203, 9, 87, 6, 22130, 8, 2093], [5, 253, 2, 413, 666, 16, 1, 7, 65, 165, 130, 20, 77, 29, 58, 777, 34, 70, 5, 131, 359, 127], [5, 19, 35, 3, 122, 6, 14, 8865, 3, 19, 35, 5, 61, 673, 45, 8, 271, 5962, 369, 281], [5, 19, 181, 22, 12, 1314, 57, 3, 195, 81, 59, 287, 49, 1072, 26], [5, 77, 14, 1682, 81, 59, 296, 90, 376, 5788, 233, 219, 1, 5, 165, 303, 2, 148, 2799, 5693], [5, 77, 41, 43, 401, 43, 1197, 644, 35, 6, 44, 2, 165, 1152, 88, 28, 214, 38, 2, 25, 338, 5, 149, 32, 5, 41, 12, 24], [5, 77, 1551, 139, 27, 4, 22131, 148, 1196, 41, 2070, 2, 449, 74, 268, 892, 8, 4, 1, 176, 22132, 50, 193, 108], [5, 134, 17, 235, 390, 74, 336, 151, 512, 20, 19, 24, 9], [5, 41, 7363, 253, 163, 4, 199, 618, 2646, 82, 215, 707, 233, 39, 1, 14, 22133, 647, 513, 768], [5, 41, 391, 3, 41, 4, 4226], [5, 41, 9, 109, 54, 116, 815, 3089], [5, 41, 17, 104], [5, 41, 10, 226, 11, 20, 476, 34, 3, 41, 20, 1, 18, 10, 138], [5, 41, 25, 8, 3, 41, 1], [5, 41, 25, 8, 3, 41, 283, 22134, 46, 105, 6029], [5, 41, 7, 24, 25, 3024, 46, 43, 2992, 97], [5, 41, 6, 14, 2, 89, 1, 21, 17, 840], [5, 41, 1060, 1, 1806, 5, 22135], [5, 146, 572, 171, 9], [5, 189, 49, 32, 1716], [5, 90, 1231, 20, 2, 104], [5, 44, 10, 324, 66, 103, 257, 212, 19, 104, 3358], [5, 44, 43, 228, 426, 357, 67, 6, 14, 2899, 123, 2556], [5, 9, 46, 19, 27, 17], [5, 9, 46, 41, 43, 112, 228, 149, 4, 45, 3, 14, 94, 22136, 10, 228, 585, 22137, 17, 688, 22138, 793, 2779, 31, 23, 182, 1878], [5, 9, 49, 11, 21, 2, 22139, 1003], [5, 9, 733, 99, 1572], [5, 9, 134, 17, 127, 8, 127, 540, 744, 6, 271, 10, 30, 419, 21, 246, 201, 213], [5, 9, 64, 854, 463, 86, 5, 342, 22140, 3535, 5, 4497], [5, 9, 2298, 107, 21, 17], [5, 33, 2, 186, 9], [5, 33, 906, 22, 1, 5363, 288, 5, 51, 197, 40, 27, 60, 252, 1532, 6, 28, 102, 19, 22141, 50, 977, 311, 22, 1, 235, 102], [5, 33, 50, 228, 23, 4, 145, 40, 131, 19, 125], [5, 33, 2141, 5, 183, 8, 120, 36, 32, 60, 9], [5, 33, 475, 133, 4, 1, 3, 41, 68, 77, 8, 40, 10, 77, 43, 68, 499, 63, 167, 15], [5, 62, 23, 48, 180, 18, 4, 1593, 34, 23, 37, 549, 16, 465, 32, 16, 22, 3296, 8, 8667, 385, 55, 410, 3189, 408, 8, 286, 61, 22142], [5, 62, 2, 1, 12, 284, 38, 40, 872, 8, 40, 1917], [5, 62, 2, 1, 214, 38, 40, 313, 50, 467, 92, 40, 41, 6, 258, 246, 25, 6, 303, 50, 246, 68], [5, 62, 1, 14, 214, 38, 36, 14, 13, 584, 10, 373], [5, 62, 71, 332, 15, 12, 6, 258, 2, 93, 414, 34, 80, 9, 30, 14, 2376, 8, 359, 18, 20, 93, 414, 218, 57, 104, 385], [5, 62, 71, 239, 341, 1, 3, 373], [5, 62, 71, 39, 9, 14], [5, 62, 71, 39, 161, 1, 22143, 36, 476, 35, 11, 4, 606], [5, 62, 71, 56, 16, 2, 1262, 30, 414, 5, 146, 14, 21, 2, 25, 6, 14, 19, 224, 1584, 213, 206, 546, 213, 206, 22144, 248], [5, 62, 3, 271, 18, 19, 2, 1, 45, 34, 27, 2, 606, 25, 7, 57, 5, 152, 28, 26], [5, 62, 23, 48, 110, 152, 2182, 6, 7, 34, 3, 62, 4, 112, 5, 1], [5, 62, 111, 179, 38, 36, 338, 4, 2633, 45, 18, 126, 886], [5, 62, 1107, 638, 8, 1, 301, 4, 884, 18, 22145, 33, 65, 51, 126, 2518], [5, 62, 4, 235, 93, 38, 15, 150, 13, 40, 136, 2, 24, 2178, 142, 50, 977], [5, 62, 39, 9, 12, 43, 93, 38, 32, 4, 3851, 139, 70, 64, 323], [5, 62, 39, 9, 3438, 3439], [5, 62, 39, 9, 3438, 3439], [5, 62, 57, 19, 7, 1, 8, 5, 210, 3818, 77, 15, 17, 8, 5], [5, 62, 57, 19, 5, 99, 1, 20, 270, 2, 141, 9, 22146], [5, 62, 57, 23, 173, 25, 233, 169, 26, 3320, 1], [5, 62, 57, 32, 5, 49, 58, 12, 14, 2, 22147, 6, 307, 2, 172, 589, 8, 3, 90, 1, 13, 5], [5, 62, 85, 66, 79, 164, 2, 1, 218, 40, 29, 168, 43, 5790, 74, 777, 38, 40, 741, 50, 180, 1384, 968, 35, 20, 30, 8, 19, 5, 8802], [5, 62, 5, 2, 1, 30, 37, 3, 29, 87, 6, 72, 254], [5, 62, 5, 49, 11, 4, 179, 38, 5, 94, 606, 226, 1920, 22148, 1065, 3833, 26, 22149], [5, 62, 5, 716, 598, 13, 2, 530, 83], [5, 62, 5, 791, 2, 9, 30, 1, 38, 40, 100, 4, 25, 107, 129, 8, 100, 4, 25, 114, 97, 1202, 22150], [5, 62, 147, 469, 5, 120, 1, 136, 143, 202, 968, 18, 80, 22151, 120, 1034, 5, 67, 15, 361, 8, 361, 8, 361], [5, 13, 76, 1, 956], [5, 13, 212, 1061, 36, 578, 13, 4, 508, 16, 10, 845, 7, 2, 8895], [5, 13, 162, 4, 286, 12, 80, 1, 2842, 80, 1, 13, 162, 4, 286, 12, 80, 4727], [5, 161, 185, 30, 1, 3, 46, 19, 27, 5], [5, 141, 171, 30, 1, 3, 29, 19, 27, 5], [5, 141, 185, 30, 1, 3, 46, 172, 8942], [5, 141, 185, 30, 1, 3, 46, 172, 27, 5], [5, 141, 5903], [5, 468, 8129, 8, 7, 57, 42, 122, 6, 58, 185, 2846], [5, 214, 218, 3, 47, 11, 4, 1536, 27, 80, 1, 27, 398, 402, 18, 50, 1169], [5, 214, 218, 40, 19, 18, 97, 3996, 40, 404, 218, 5, 100, 7, 45, 19, 27, 350, 5, 75, 829, 39, 9, 85, 1040], [5, 196, 39, 9, 4876, 105, 152, 14, 243, 321], [5, 456, 14, 820, 16, 4, 534, 2865, 26, 218, 20, 2, 19, 24], [5, 456, 14, 144, 1083, 27, 2, 1887, 941, 26], [5, 87, 2, 8190, 21, 20, 1766, 231, 83], [5, 87, 2, 153, 13, 17, 6, 316, 7, 1125, 459, 5], [5, 105, 566, 296, 86, 3, 44, 441, 22152, 149, 15, 29, 1838, 9], [5, 105, 1713, 17, 2978, 478, 5, 1, 59, 15, 38, 3, 58, 15, 6, 5, 988], [5, 25, 119, 39, 9, 24, 34, 36, 46, 783, 15], [5, 25, 4509, 1, 5, 745, 110, 19, 478, 18, 2, 22153, 2650, 50, 102, 20, 167, 1304, 2436, 5, 46, 105, 2111, 760], [5, 25, 81, 6, 39, 275, 122, 6, 28, 60, 24, 34, 29, 623, 20, 101, 4829, 126, 2121, 8, 28, 22154], [5, 25, 7, 118, 516, 20, 77, 255, 1708, 8, 2809, 661, 16, 2, 926, 472, 8, 3261, 49, 22155], [5, 638, 12, 1, 165, 478, 4216, 143, 888, 167, 97, 30, 579, 788, 5, 13, 2, 22156, 5371], [5, 399, 7860, 24], [5, 48, 137, 17, 1, 3, 62, 1287], [5, 206, 22157, 30, 153, 70, 10, 4398, 7980, 102, 10, 1006, 270, 1, 5, 49], [5, 101, 2352, 111, 5, 62, 5, 2960, 85, 5, 46, 58, 22, 11, 4, 1408, 1], [5, 54, 116, 429, 76, 1515, 19, 76, 1116, 1541, 176, 15, 112, 5, 46, 109, 133, 20, 1689, 22158, 20, 22159], [5, 950, 931, 218, 203, 1, 4, 101, 184, 7, 3, 13], [5, 24, 31, 5, 308, 21, 24], [5, 24, 25, 3, 94, 97, 8555], [5, 590, 30, 1, 152, 44, 357, 6, 924, 34, 630, 38, 5, 28, 98, 3654], [5, 109, 75, 14, 99, 417, 6, 1, 7, 4, 6032, 193, 6, 28, 359, 18], [5, 117, 3849, 383, 1702, 174, 22160, 22161, 51, 22162, 2, 1], [5, 121, 3, 262, 42, 8, 273, 42, 3, 346, 5, 221, 3, 200, 1, 13, 445, 449, 1712, 632, 35], [5, 121, 7, 80, 1, 34, 7, 1, 65, 3458], [5, 121, 5, 14, 366, 870, 34, 20, 329, 5, 132, 366, 56, 8, 15, 46, 11, 10, 8943, 31, 15, 46, 7, 4368], [5, 121, 5, 14, 366, 870, 34, 20, 329, 5, 132, 366, 56, 15, 48, 11, 10, 8943, 31, 15, 46, 7, 22163], [5, 72, 23, 2, 1, 3, 72, 23, 2, 414, 27, 2, 870, 395, 7, 317, 137, 219, 27, 166], [5, 72, 15, 13, 374, 2, 154, 2105, 374, 1334, 5, 171, 1, 1223, 22164, 67, 68, 26], [5, 72, 43, 6, 590, 24, 34, 22165, 75, 1130, 103, 70, 50, 856], [5, 72, 43, 6, 590, 24, 2263, 1137, 5893], [5, 72, 7, 1, 89, 34, 40, 46, 45, 6, 17], [5, 72, 5, 1677, 8, 8944, 3, 72, 1, 5, 2, 3362], [5, 72, 5, 146, 154, 1], [5, 626, 3, 46, 626, 6, 257, 4, 24, 35], [5, 2757, 280, 38, 794, 24, 47, 56, 34, 40, 96, 4025, 22166, 10, 164, 46, 45], [5, 94, 17, 4105, 22, 1], [5, 94, 17, 1994, 18, 80, 1, 30], [5, 94, 39, 268, 24, 3030, 22167, 579, 3030, 1081, 114, 8914, 18, 4, 2046, 34, 46, 59, 7], [5, 94, 5, 5, 2, 1, 8822, 81, 45, 25, 604, 28, 97, 1222], [5, 1948, 836, 3, 394, 5, 64, 22168, 3, 362, 2019], [5, 198, 44, 6, 14, 129, 688, 1735, 8, 8819, 4180, 6, 303, 2, 6368, 66, 62, 247, 16, 5, 28, 240, 149, 20, 5280, 823, 1549], [5, 198, 415, 61, 656, 20, 530, 24, 8, 48, 475, 59, 369, 23, 8247], [5, 60, 409, 16, 1101, 104, 31, 5, 316, 1018, 5803, 6, 2, 366, 22169], [5, 654, 15, 1479], [5, 96, 75, 227, 2, 9, 173, 2, 331, 436], [5, 96, 172, 27, 2, 370, 30, 25, 7, 70, 5, 2, 370, 30, 1], [5, 96, 7, 25, 340, 29, 22170, 36, 33, 1500, 149, 36, 41, 43, 1, 25, 1796, 18, 1566, 2550, 8689], [5, 794, 9], [5, 4, 1, 25, 409, 5, 46, 105, 124, 2, 3866], [5, 86, 770, 136, 2966, 22171, 11, 166, 823, 28, 3973, 11, 4, 606, 21, 22172, 732, 9, 452, 70, 254], [5, 86, 278, 683, 123, 92, 7, 469, 355, 1736, 908, 2052, 6, 5529, 34, 4208, 3, 44, 6, 44, 104, 30, 1148, 11, 1225], [5, 86, 40, 1677, 145, 34, 40, 109, 590], [5, 86, 20, 24, 12, 631, 10, 5205, 2150, 268, 115, 1712], [5, 299, 3, 47, 868, 38, 3, 311, 7, 1, 102], [5, 99, 206, 6, 14, 18, 186, 345, 13, 2, 836], [5, 56, 205, 22173, 1641, 1605, 92], [5, 122, 17, 282, 3, 63, 22174], [5, 753, 17, 5, 171, 187, 22175, 29, 924, 350], [5, 131, 258, 9, 18, 135, 33, 253, 4, 418, 69, 1257, 27, 548, 387, 793, 352, 4649], [5, 131, 341, 481, 5, 131, 5044, 5, 131, 22176, 5, 165, 1505, 2, 1689, 1], [5, 131, 62, 60, 284, 45, 461, 4, 4696, 5, 222, 258, 2, 2762, 1], [5, 131, 194, 4, 178, 40, 131, 194, 34, 80, 1, 30, 210, 303, 50, 246, 886, 37, 5, 146, 114, 143, 1432], [5, 67, 2, 1220, 2342, 171, 1, 5, 63, 8931], [5, 67, 17, 18, 4, 2022, 137, 496, 178, 162, 5, 63, 94, 17, 74, 54, 27, 10, 228, 27, 166, 24, 11, 1912, 482], [5, 67, 22177, 3, 41, 4700, 1], [5, 47, 105, 27, 17, 31, 5, 100, 57, 246, 1, 72, 396, 20, 1781, 2018, 17], [5, 47, 295, 34, 2, 537, 835, 19, 5, 1], [5, 103, 105, 28, 2, 31, 5, 29, 62, 71, 6, 867, 21, 97, 91, 1446, 1996, 48, 82, 2, 25, 13, 307, 4633, 30, 1], [5, 197, 225, 104], [5, 2386, 175, 610, 175, 262, 60, 9, 2106, 616, 1922, 39, 379, 177, 46, 146, 2732, 57, 1862, 12], [5, 5, 75, 28, 43, 169, 1482, 9], [20, 2, 1, 46, 297, 78, 468, 7, 89, 371, 51, 197, 935, 10, 3078, 22178, 267, 782, 1974], [20, 2, 141, 1, 10, 412, 41, 7839, 54, 11, 4, 889, 1743], [604, 105, 430, 17, 11, 775, 27, 2, 418, 7, 41, 98, 1074, 7936, 23, 101, 297, 11, 775, 27, 1677, 1], [20, 2, 89, 1, 8, 3, 67, 350], [20, 2, 1, 26, 3, 90, 5], [20, 2, 1, 4243, 2, 344, 83], [20, 2, 171, 83, 2375], [20, 2, 104, 31, 5, 168, 4, 1112, 20, 231, 1217], [20, 2, 9, 30, 104, 1, 187, 25], [20, 2, 24, 242, 35], [20, 2, 185, 19, 1], [20, 2, 185, 9], [20, 32, 104, 22179], [20, 32, 33, 1170, 18, 4, 863, 5212], [20, 98, 183, 203, 187, 3174, 5, 87, 6, 5946], [20, 98, 183, 19, 1, 28, 102, 20, 314, 1766], [20, 202, 20, 226, 65, 22180, 5, 791, 2, 7828], [20, 4288, 83, 22181, 3, 131, 137, 27, 5, 22182], [20, 1555, 1], [20, 33, 246, 3815], [20, 33, 56, 13, 370], [20, 13, 2, 811, 3839, 27, 2, 5556, 115, 18, 20, 22183, 127, 21, 5429], [20, 43, 193, 1196, 59, 7, 164, 1, 128], [20, 48, 2, 727, 93, 477, 2287, 2, 1142, 27, 2, 89, 1, 26], [20, 24, 30, 644, 29, 196, 45, 6, 307], [20, 397, 18, 2, 2529, 699, 162, 15, 32, 99, 1016, 5072, 127, 21, 4697], [20, 861, 18, 179, 848, 261, 2124, 795, 305, 22184, 369, 71, 585, 3, 861, 11, 4, 848, 261, 178, 22185, 22186], [20, 270, 2, 365, 83, 3, 2053, 397, 350, 31, 5, 509, 22, 8, 454, 31, 15, 59, 5, 15, 415, 1437], [20, 270, 2, 24], [20, 183, 769, 282, 400, 364, 142, 1504], [20, 8725, 8674, 1283, 438, 27, 80, 91, 83, 26], [379, 22187, 26, 2314, 1830, 132, 204, 15, 11, 4, 22188, 11, 18, 7, 112, 22189, 2115, 2343, 56, 11, 4, 22190], [379, 1021, 79, 2, 1, 84, 1883, 18, 2, 4818, 3, 29, 110, 62, 57, 52, 196, 123, 7, 34, 23, 857, 133, 6, 192, 79, 1, 7], [379, 1, 81, 59, 126, 154, 91, 6422, 22191, 31, 621, 12, 109, 22192, 11, 7, 45, 55], [379, 22193, 147, 399], [379, 185, 30, 9, 39, 115], [20, 2, 93, 22194, 159, 524], [20, 208, 13, 2, 1794, 141, 104, 44, 501], [20, 1, 156, 121, 40, 131, 19, 2, 112, 25], [20, 1, 1668, 33, 6115], [20, 1, 3425, 7, 5, 10, 1, 5758, 7, 17], [20, 1, 41, 50, 5636, 18, 10, 5991], [20, 1, 12, 2, 365, 2382, 16, 1295], [20, 1, 101, 131, 19, 38, 5, 58, 256, 7, 136, 295, 6, 58, 27, 22195, 137, 496, 178, 74, 194, 4, 1537], [20, 1, 137, 178, 3, 600, 14, 4, 22196], [20, 1, 67, 6, 19, 4, 1916], [20, 1, 67, 6, 61, 6, 141, 22197, 27, 17, 1146, 273, 50, 988, 19, 2, 5881], [20, 1473, 49, 365, 20, 2, 141, 1, 20, 48, 342, 8, 3, 67, 6, 929, 350], [20, 500, 436, 578, 13, 789, 2101], [20, 1256, 18, 3238, 34, 97, 24, 18, 1729], [20, 77, 24, 13, 2, 294, 11, 4604, 4, 2992, 21, 155, 549, 25], [20, 77, 24, 532, 13, 2844, 853, 8, 22198], [20, 4254, 12, 248], [20, 3159, 728, 2, 19, 1091, 3750, 8, 856, 13, 2, 104, 82, 3226], [20, 226, 253, 4, 324, 187, 11, 4, 5252, 1428, 57, 7, 113, 5], [20, 154, 1, 10, 206, 9], [20, 2169, 893, 8364, 934, 10, 310, 5, 19, 2319, 100, 17, 94, 20, 30, 51, 22199, 5273, 5, 131, 81, 45, 151, 22200, 20, 1511], [20, 24, 625, 22201, 424, 17, 98, 755, 6, 1099, 11, 7, 22202, 1083, 8, 151, 2558, 5], [20, 24, 1556, 456, 14, 969, 53, 4, 22203, 3011, 364, 12, 22204, 22205, 22206], [20, 726], [20, 8903, 1842, 49, 22207, 123, 2, 19, 25, 7, 19, 5, 8, 2, 607, 166, 283, 311, 240, 73, 5, 983, 20, 8937], [20, 2, 19, 183, 1, 3, 131, 2836, 5, 6, 989, 8, 88, 137, 224, 27, 20, 1009, 22208, 22209], [5, 2, 1052, 1149, 39, 9, 1106, 22210], [5, 2, 1, 30, 25, 945, 3, 842, 4, 2050, 8760, 634, 224, 4135, 115, 696, 227, 3123], [622, 2, 1, 216, 25], [2785, 1, 22211, 855, 22212, 51, 422, 47, 4, 237, 663, 928, 478, 513], [1290, 158, 420, 7, 961], [2573, 1711, 1902, 56, 742], [2573, 88, 40, 41, 1457, 8, 309, 4371, 47, 2, 1], [2573, 3, 1239, 58, 48, 13, 350, 5, 49, 2, 4106, 3279, 1, 69, 87, 6, 44, 15, 20, 3810], [22213, 22214, 28, 19, 123, 268, 189, 444, 40, 28, 50, 22215], [22216, 7741, 113, 80, 1, 6, 338, 17, 364, 771], [6371, 96, 938, 10, 64, 21, 354, 55], [22217, 1, 55], [22218, 2125, 47, 33, 8130, 18, 84, 618, 8, 22219, 33, 912, 173, 84, 712, 8, 47, 13, 463, 525, 2, 323, 368], [2864, 66, 1506, 21, 80, 164, 83], [22220, 28, 1], [22221, 8264, 2748, 22222, 16, 2, 1, 672, 10, 2391, 163, 22223], [8945, 365, 1, 8945], [2, 1, 63, 44, 268, 202, 387, 3049, 767, 4099, 5767, 2752, 8, 2, 2085, 1291, 8, 96, 14, 13, 3134, 3, 64, 4100, 128], [2, 1, 11, 10, 1436, 521, 117, 92, 12, 428, 119, 33, 344, 35, 7846], [22224, 10, 1213, 136, 309, 21, 4, 413, 696, 23, 273, 33, 11, 106, 6, 1226, 17, 4, 573, 2802, 16, 8721, 19, 838], [59, 6, 22225, 28, 2, 351, 4681, 2645, 8408, 7, 72, 6415, 2402], [896, 1210, 2972, 21, 2, 1, 11, 2, 22226, 4, 22227, 2557], [1299, 17, 18, 1690, 1, 410, 22228], [1812, 6, 24, 1872], [211, 4, 3355, 514, 4, 7099, 3, 2163, 35, 4, 202, 8, 190, 22229, 18, 10, 306, 4630, 3, 86, 4, 2088, 1447, 12, 96, 458], [585, 25, 147, 279, 59, 1242, 8, 28, 4081, 11, 9, 45, 519, 315, 291, 74, 46, 28, 602, 24], [5134, 19, 494, 204, 4526], [3203, 24, 12, 1065], [22230, 6306, 22231, 71, 42, 13, 17, 92, 1123, 54, 201, 10, 280, 2653, 5342, 1907, 4802, 22232, 902, 445, 325, 378], [46, 22233, 26, 22234, 69, 803, 2, 19, 153], [46, 10, 9, 3, 33, 299, 15, 6109], [46, 43, 1, 41, 45, 18, 17], [46, 2357, 2177, 311, 7, 1, 102], [46, 4, 1, 1963, 96, 125, 315, 30, 4004], [46, 302, 43, 1, 74, 43, 2400, 9, 74, 43, 3417], [46, 4515, 144, 133, 1192, 34, 22, 1052, 8197], [46, 45, 322, 34, 10, 1, 8, 10, 779, 233, 621, 63, 28, 4, 2087], [46, 45, 461, 10, 1844, 1, 3, 259, 7, 558, 164], [1274, 29, 609, 17, 1], [32, 3, 2883, 67, 47, 60, 5450, 172, 4599], [32, 3, 67, 47, 2, 2860, 937, 831, 8, 2, 89, 1], [32, 10, 3075, 49, 1], [32, 16, 263, 18, 186, 58, 7, 330, 55, 3, 22235, 68, 16, 5, 6, 795, 35, 8, 3775, 6, 477, 6, 17, 83], [32, 4, 1, 64, 17], [32, 4, 169, 163, 4, 24, 3, 67, 3, 87, 7, 116], [32, 76, 22236, 9, 253, 2, 22237, 22238, 88, 167, 4, 22239, 571, 101, 253, 1727, 111, 22240], [32, 39, 5637, 323, 49, 206, 6, 17, 1, 36, 82, 13, 201, 449, 892, 3346], [32, 39, 89, 1, 91, 36, 67, 4, 22241], [32, 39, 681, 1, 8570, 681, 184], [32, 39, 9, 37, 4716], [32, 39, 9, 1513, 8, 778, 25, 18, 22, 229], [32, 78, 60, 9, 1249], [22242, 846, 281, 1, 30, 8299, 167, 7, 9, 27, 7, 1787], [603, 3009, 10, 2611, 2832, 215, 8875, 9, 109, 510, 1467, 18, 305, 676, 3978], [5249, 215, 264, 10, 462, 273, 17, 4, 1250, 6, 243, 47, 154, 24], [156, 10, 9, 703, 69, 49, 468, 169, 3353, 6, 22243, 1005], [156, 550, 6, 316, 20, 236, 6, 4, 8065, 464, 36, 1326, 431, 483], [195, 3, 4, 22244, 68, 94, 1670, 2190, 54, 137, 1, 30, 3445], [8, 3, 146, 72, 3, 29, 13, 22, 6182, 22245, 2480, 2504, 3330, 1], [8, 246, 68, 268, 9, 53, 78, 62, 57, 66, 49, 53, 26], [8, 31, 7, 80, 1, 88, 5, 600, 44, 6, 290, 22246], [8, 23, 144, 99, 3, 176, 729, 4, 331, 310, 38, 3, 62, 15, 46, 21, 17, 1432], [8, 10, 1, 37, 89, 7, 23, 105, 182, 359], [8, 92, 155, 106, 17, 8, 10, 228, 81, 43, 690, 4, 5825, 50, 628, 7273, 2012, 15, 73, 31, 68, 628, 47, 3388, 3946, 6, 4, 8043], [8, 39, 9, 5622, 22247, 3985, 34, 66, 132, 724, 760], [8, 22, 12, 85, 23, 419, 3, 29, 19, 27, 1, 74, 116, 764, 7581], [8, 122, 6, 22248, 22, 207, 12, 152, 14, 2, 172, 1, 13, 3, 1089, 10, 343, 469, 8, 15, 330, 192, 61, 1958, 361, 552, 552], [978, 353, 49, 4, 172, 859, 80], [246, 358, 264, 27, 4557, 87, 165, 4715, 130, 22249, 74, 4589, 5, 1175, 15], [1311, 18, 4, 412, 136, 4403, 6, 19, 10, 1], [1311, 375, 7, 629, 22250, 3, 210, 1649, 71, 22251, 4, 95, 47, 444, 92], [1311, 67, 245, 2196, 5308, 22252, 3, 44, 59, 1243, 429, 35, 11, 22253, 837, 22254, 17, 8, 22255, 3041, 268, 3491], [1311, 67, 6, 114, 17, 6, 1635], [769, 105, 302, 2, 1, 26, 29, 1431, 650, 5, 65, 21, 60, 3204, 8, 378, 4677], [1302, 23, 2169, 56, 1417, 8941], [49, 5, 686, 117, 92, 2490, 8, 957, 1911, 19, 459, 10, 231, 27, 7, 56], [191, 21, 10, 518, 52, 2, 564, 23, 13, 1114, 8855, 27, 10, 1, 227, 142, 21, 57], [8191, 718], [1210, 45, 7720, 11, 22, 1], [8927, 1285, 1609, 291, 84, 24], [773, 1, 122, 22], [773, 8785, 63, 3, 2324, 1243, 831, 15, 46, 13, 622, 46, 41, 268, 401, 219, 63, 3, 2324, 60, 24, 3, 46, 13, 622, 223, 134, 35, 43, 235], [2739, 40, 13, 202, 435, 8, 742, 451, 932, 55, 11, 979, 40, 67, 6, 14, 207], [89, 1], [89, 1, 1846, 18, 10, 22256, 3786, 3831, 160, 7, 25, 7182], [89, 1, 82, 22257, 222, 14, 2, 22258, 2, 22259], [89, 1, 27, 17, 122, 6, 665, 17, 13, 2, 7134], [89, 1, 12, 4, 101, 184, 3, 13], [482, 1159, 84, 178], [4979, 648, 12, 2, 1], [466, 13, 23, 7908, 1], [1095, 274, 19, 32, 10, 1], [4076, 2563, 2321, 3797], [2640, 49, 431, 73, 286, 140, 374, 339, 470, 2649, 1940, 470, 3926, 1187], [1493, 1266, 112, 738], [132, 2, 358, 5545, 2764, 15, 914, 1170, 647], [230, 8, 211, 3, 192, 137, 567, 95, 188, 230, 211], [14, 35, 51, 4873, 218, 20, 534, 4032, 51, 2, 22260, 95, 12, 4, 2023], [180, 1, 14, 854, 85, 80, 387, 32, 18, 10, 1855, 1, 85, 80, 1855, 32, 11, 10, 387], [1, 3, 14, 1921, 1069, 3, 222, 192, 2, 5583], [1, 3, 41, 4, 990, 1827], [1, 3, 318, 340], [1, 3, 87, 7, 481, 314, 58, 48, 19, 125, 10, 235, 22261], [1, 3, 297, 76, 843, 230, 1449], [1, 23, 119, 5, 49, 37, 572, 139, 120, 111, 862, 53], [1, 23, 3651, 260, 23, 17], [1, 23, 22262, 37, 69, 42], [1, 30, 4940, 74, 2279, 29, 167, 17, 108, 35], [1, 30, 25], [1, 1741, 28, 15, 22263, 22264, 22265, 9, 14, 22266], [1, 75, 555, 1227, 142, 88, 40, 2373, 6, 22267], [1, 138, 99, 859], [1, 29, 298, 6, 4, 2233, 52, 544, 99], [1, 28, 102, 10, 186, 9], [1, 28, 54, 4022, 1, 28, 54, 4022, 1, 28, 54, 4022, 8322, 11, 10, 22268, 369], [1, 784, 22269, 22270], [1, 276, 1846, 38, 1971, 742, 765, 415, 626, 48, 99], [1, 3, 103, 311, 5], [1, 1153, 31, 5, 13, 17, 34, 5, 103, 538, 17], [1, 23, 544, 76, 22271, 276, 157, 7422, 11, 2, 1825, 26, 114, 327, 533, 133, 2086, 11, 22272], [1, 23, 12, 48, 133, 6, 28, 43, 148, 2094, 22273, 279, 31, 15, 12, 22274], [1, 204, 4354, 61, 18, 6, 4, 3966, 8, 119, 4, 1515, 1, 32, 16, 240], [1, 259, 2, 7988], [1, 216, 252, 896, 1, 216], [1, 25, 1632, 17, 169], [1, 2054], [1, 415, 22275, 4, 841, 25, 7, 121, 93, 4562, 108, 6, 50], [1, 109, 396, 50, 410, 226, 281, 15, 12, 48, 7, 4668, 3597, 408, 44, 99, 209, 106, 18, 126, 402, 304, 11, 7, 3329, 1294], [1, 121, 237, 193, 6, 28, 129, 2, 91, 12, 6, 28, 793, 246, 68, 251, 147, 585, 9, 21, 42], [1, 7, 80, 25, 22276, 5, 46, 84, 1], [1, 42, 380, 15], [1, 42, 636, 10, 178, 926], [1, 66, 49, 4, 2166, 22277], [1, 57, 4, 893, 80, 874, 1555], [1, 27, 32, 25, 4359, 40, 519, 315, 74, 2, 9], [1, 5, 14, 8077, 55], [1, 5, 165, 48, 4728, 307, 5259, 8, 3533, 8, 22278, 44, 10, 154, 419, 12, 107, 1147], [1, 5, 146, 3057, 35, 68, 921], [1, 5, 22279], [1, 5, 724, 3, 47, 18, 20, 22280, 22281], [1, 20, 120, 411, 27, 20, 1096, 1840], [1], [1, 46, 45, 8, 36, 46, 72, 777], [1, 46, 45, 34, 9, 98, 843], [1, 330, 3089, 18, 8946, 22, 45, 600, 383, 14, 165, 130, 610], [1, 8, 1411, 3346], [1, 8, 126, 676, 2131, 6090, 3441], [1, 51, 825, 11, 2854, 1686, 503, 205], [1, 14, 22282], [1, 14, 470, 927, 11, 126, 830, 81, 59, 3, 29, 471, 677], [1, 14, 90], [1, 14, 13, 53, 23, 2, 22283, 34, 1265, 8490, 12, 3565, 43, 1, 201, 511, 507], [1, 14, 13, 23, 1223, 125, 3920, 1745, 579, 1644, 732, 3, 14, 13, 1, 33, 218, 5, 672, 174], [1, 14, 22284], [1, 132, 593, 37, 358, 38, 36, 28, 1459, 6, 256, 2576, 36, 28, 22285], [1, 107, 26, 61, 97, 62, 7], [1, 1490, 483, 5, 708, 6, 14, 243, 34, 345, 744, 2442, 5236, 162, 36, 58, 7, 7041], [1, 29, 2493, 57, 6, 100, 498, 2045, 45, 46, 197, 844], [1, 171], [1], [1, 64, 2399, 37, 3, 380, 151, 255, 22286, 2399], [1, 64, 3597], [1, 64, 93, 561, 448], [1, 333, 11, 22287, 22288, 130, 947, 111, 220, 22289, 8, 599, 201, 16, 212, 220, 1193, 73, 2991], [1, 271, 11, 36, 150], [1, 8599, 9, 81, 110, 127], [1, 7, 29, 119, 1734, 49, 13, 6, 4563, 1288, 151], [1, 238, 14, 142, 34, 3, 46, 21, 7, 575, 164, 117, 615], [1, 69, 105, 724, 17, 92, 79, 17, 8947], [283], [22290, 22291, 22292, 1340, 11, 22293, 2350, 18, 4062], [1602, 163, 9, 439], [1364, 1, 70, 7, 481, 788, 5, 62, 3, 29, 62, 4021, 1], [2373, 5382, 1750, 11, 2, 56, 3806, 27, 268, 1731, 11, 4, 108, 16, 4, 1643, 296, 3593, 905, 22294, 121, 4, 360, 884, 22295], [133, 6, 257, 22, 1548, 13, 2, 24, 25], [133, 6, 28, 60, 186, 1, 10, 186, 3285, 878, 797], [22296, 269, 147, 1746, 269], [6926, 2931, 54, 16, 2, 22297, 178, 27, 642, 6, 1866, 725, 9, 809], [3290, 15, 2, 22298, 975, 11, 2696, 31, 42, 131, 44, 1, 18, 2609, 420, 116], [321, 2088, 2, 1, 30, 25, 321, 18, 17, 2549], [666, 16, 24], [34, 3, 210, 28, 2, 1053, 35, 267, 274, 55, 171, 120, 1], [34, 278, 516, 14, 2, 351, 91, 11, 10, 4621, 130, 259, 73, 2, 5458, 74, 2, 2172, 34, 2037, 212, 45, 3762, 1, 118, 14, 351, 1524, 8, 613], [34, 51, 4, 199, 106, 40, 90, 17, 37, 3, 29, 131, 302, 50, 1, 30], [34, 3, 58, 62, 68, 184, 464, 1, 36, 107, 36, 61, 1445, 539, 1461, 1147, 1147, 539, 1461, 22299], [34, 1619, 5, 48, 2, 1, 5, 4, 68, 3, 28, 169, 2938], [971, 901, 22300, 74, 336], [4317, 1], [79, 17, 1], [63, 1, 51, 577, 304, 634, 15, 126, 1451, 707, 6, 157, 7, 45, 35, 22301, 78, 8220], [63, 10, 534, 48, 204, 95, 8, 70, 2, 1139, 17, 16, 1508], [75, 1389, 31, 3, 198, 255, 10, 190, 1234, 2137, 21, 4, 1405, 16, 14, 32, 202, 26, 190, 22302], [75, 28, 129, 71, 239, 9, 3, 1764, 18, 215, 264, 8948], [75, 19, 224, 125, 379, 25, 149, 36, 14, 208, 13, 9], [75, 90, 4203, 1, 28, 1135, 21, 57, 40, 41], [75, 397, 38, 2, 153, 2270, 81, 59, 5, 6, 2, 1], [75, 302, 25, 38, 15, 107, 6, 1], [347, 3080, 12, 2, 83], [149, 32, 10, 164, 3, 47, 273, 8, 1460, 3, 195, 48, 45, 123, 5, 963, 19, 1055, 2382, 16, 308, 381, 45, 92, 5, 242, 35, 83], [396, 4, 24, 173, 2, 739, 22303], [4256, 8, 3349, 49, 398, 56], [4591, 55, 3, 67, 212, 32, 202, 8, 190, 5639, 6110, 22304, 3, 212], [813, 4594, 56], [497, 1], [497, 22305, 23, 28, 353, 1315], [955, 7, 1], [890, 524, 121, 39, 9, 407, 334, 251], [3932, 9, 2059], [656, 32, 4, 95, 3904, 54, 16, 4, 22306, 8, 542, 21, 127, 1234, 4, 260, 95, 49, 54, 615, 538, 4, 22307, 1578, 647], [207, 22308, 70, 17, 6561], [851, 8, 353, 652, 110, 18, 4, 199, 822], [490, 22309, 1637, 35, 22310, 22311, 1474, 2716, 22312, 6, 1207, 166, 22313], [490], [2063, 132, 56, 81, 7, 25, 218, 25, 41, 22314, 11, 2554], [5077, 32, 10, 9, 25, 7, 32, 3, 62, 25], [823, 177, 1307, 8662, 120, 3401, 3980, 1736], [1081, 85, 12, 116, 2, 95, 18, 20, 1464, 17, 15, 186, 1081, 3, 3873, 5, 17, 7, 1126], [284, 1, 3, 13, 4, 193, 5, 498, 22, 138], [3441, 1, 122, 28, 1715, 27, 17, 88, 920, 1077, 6, 28, 50, 2401, 736], [8932, 204, 4, 534, 1, 1679, 309, 54, 135, 33, 6, 94, 10, 235, 178], [311, 7, 1, 102], [311, 35, 22315, 63, 3326, 1324, 2, 969, 63, 16, 8665, 63, 16, 1901, 22316, 2, 22317, 22318, 3132, 1002, 1562, 355, 2771], [586, 427, 20, 226, 104, 2, 141, 127, 6341], [148, 26, 22319, 21, 4, 462, 26, 138, 21, 4, 894, 55], [148, 3, 44, 295, 6, 22320, 6, 733, 74, 1, 59, 513, 55], [148, 1, 128], [148, 55, 22321, 1173, 569, 18, 4, 8856, 4744, 1980, 7, 382, 50, 1603], [148, 36, 152, 338, 22322, 135, 358, 22323, 56], [22324, 38, 42, 753, 585, 1, 211, 19, 125, 765, 25, 147, 70, 78, 150, 60, 698, 16, 193], [22325, 144, 55], [147, 196, 42, 183, 9, 31, 101, 28, 19, 22326, 1907, 341, 25], [147, 85, 42, 75, 433, 35, 18, 1, 218, 765, 585, 70, 15, 598, 13, 42, 1513, 22327, 42, 2493, 147, 91, 2505, 19, 42], [22328, 197, 13, 2, 5556, 11, 22329, 22330, 22331, 27, 392, 959, 22332, 4, 7662, 2261, 118, 2510, 216, 11, 116], [8611, 67, 4, 1645, 634, 45, 41, 112, 88, 25, 131, 108, 35, 2442, 5236, 88, 251, 24], [799, 27, 5, 1, 38, 3, 150, 13, 15], [799, 27, 20, 1, 30, 12, 37, 589], [4659, 345, 140, 40, 87, 6, 2168, 1892, 176, 72, 158], [1656, 1995, 22333, 242, 4, 19, 35, 5, 284, 83], [1656, 1794, 4694, 836], [384, 25, 2036, 44, 76, 120, 3179, 3, 64, 10, 681, 202, 22334], [855, 9, 3438, 3439], [765, 506, 2267, 467, 11, 325, 1, 99], [200, 22, 1, 109, 3262, 17, 82, 10, 22335, 6, 547, 479, 54, 50, 7872, 205], [2093, 2543, 56], [2595, 2, 1556, 12, 727, 3960, 15, 3879, 54, 7, 2, 83], [2634, 100, 95, 497, 11, 2258, 21, 954, 22336, 422], [325, 3366, 9, 11, 143, 848, 16, 22337], [3449, 111, 69, 1, 59, 166, 111, 14, 11, 575, 3449, 111, 69, 1, 59, 111, 14, 419], [58, 1, 96, 64, 2399, 22338], [58, 39, 1, 7, 175, 59, 114, 6407, 744, 86, 126, 332, 74, 336], [58, 36, 110, 70, 472, 245, 127, 7, 44, 1882, 26, 1112, 20, 30, 60, 16, 263, 44, 43, 1169, 26, 2, 180, 809, 3, 103, 1385, 21, 2, 56, 558], [58, 5, 86, 32, 4, 1173, 181, 49, 51, 1653], [22339, 191, 2, 1055, 875, 5176, 294, 11, 1281, 2, 8921, 16, 2122, 5, 600, 44, 2, 348, 5522], [29, 14, 18, 7, 236, 45], [29, 14, 1003, 38, 23, 2, 1, 6, 5, 140, 20, 156, 2, 138, 2018, 17], [29, 1, 59, 10, 764, 140, 20, 4, 540, 3, 44, 68], [29, 110, 1182, 39, 9, 41, 495, 99, 22340], [29, 253, 17, 8, 753, 17, 5, 49, 144], [29, 28, 15, 1717, 15, 10, 385, 1625, 142, 283], [29, 134, 585, 19, 59, 585, 1, 74, 585, 25], [29, 65, 51, 17, 13, 289, 41, 2, 1972, 11, 10, 402, 5, 19, 2319], [29, 122, 6, 14, 417, 6, 17, 211, 5, 220, 14, 2, 1], [328, 474, 34, 302, 39, 9], [328, 27, 32, 4, 4400, 5899, 2450, 27, 20, 1, 22341], [22342, 386, 16, 2, 1, 639, 1534], [29, 3317, 39, 319], [29, 79, 17, 2, 399, 650, 42, 79, 17, 10, 399], [29, 70, 2634, 387, 1372, 27, 22343, 534, 295, 55, 23, 61, 54, 1684, 6, 1195, 22344], [29, 302, 2, 9, 105, 302, 2, 9], [961, 11, 4, 558, 322, 1, 18, 4, 234], [961, 11, 4, 558, 322, 1, 18, 4, 234, 3, 506, 961, 11, 4, 22345, 5, 238, 28, 314], [898, 87, 6, 70, 35, 84, 3306, 14, 2, 992, 74, 2, 1, 281], [22346, 875, 2, 1, 30, 25, 321], [405, 15, 2, 115, 570, 19, 25, 87, 6, 465, 15, 92, 47, 37, 332, 34, 7, 56, 1945, 6], [171, 183, 185, 908, 30, 1], [1935, 49, 19, 187], [1711, 1902, 578, 13, 57, 95, 8874, 65, 13], [22347, 56], [22348, 33, 3256, 17, 7, 10, 8779, 12, 98, 7200, 3678, 2369, 27, 2, 56, 558, 16, 8939, 22349, 22350, 18, 4609, 5301, 3685, 7342, 22351], [3116, 91, 65, 13, 2, 1718, 38, 52, 81, 6, 4, 189, 18, 4, 2089, 27, 84, 402, 35, 26, 13, 144, 483], [22352, 2, 1], [6069, 11, 325, 1, 28, 1011, 22353, 6069, 11, 325, 1, 28, 5666], [4005, 3653, 11, 178, 49, 1814, 56], [1047, 371, 825, 8, 22354, 49, 1467, 922, 166, 11, 4, 22355, 34, 4, 1, 309, 330], [110, 905, 65, 1772, 38, 207, 11], [110, 205, 3, 204, 2, 24, 25, 3, 293, 52, 61, 6, 2056, 22356, 1021], [110, 464, 10, 260, 12, 98, 4517, 4577, 1838, 1], [155, 462, 46, 43, 9, 34, 155, 462, 362, 46, 43, 1235], [155, 106, 3, 191, 21, 256, 4, 8935, 881, 10, 1981, 634, 23, 328, 22357, 7, 196, 40, 238, 134, 2, 25, 60, 24, 29, 254], [155, 106, 3, 72, 3, 29, 13, 217, 8731, 992, 2415, 416, 1, 126, 19, 235, 102, 73, 31, 15, 396, 10, 7110, 22358, 988], [155, 106, 3, 122, 6, 559, 366, 60, 171, 1, 156, 146, 14, 19, 589, 8, 122, 10, 3971, 425], [155, 106, 22, 1, 70, 2, 2161, 59, 189, 40, 262, 17, 13, 22359, 5872], [326, 172, 326, 1, 326, 125, 4, 45, 7, 164], [326, 525, 549, 3, 150, 13, 8601, 91, 11, 325, 1], [326, 271, 1087, 15, 22360, 658, 22361, 1, 15, 10, 25, 29, 131, 220, 2, 4133, 24, 6, 93, 658, 364], [326, 81, 133, 9, 290, 23, 22362, 18, 60, 169], [326, 443, 4069, 6, 122, 8, 450, 98, 2469, 463, 58, 5, 8, 3, 58, 986, 128, 104], [416, 1193, 21, 14, 2, 1139, 104], [416, 86, 16, 5, 73, 2, 9, 37, 552, 85, 20, 122, 6, 81], [4628, 3, 90, 71, 1, 472, 601], [1561, 42, 3668, 426, 10, 3689, 12, 202, 26, 120, 34, 116, 37, 239, 434, 207, 184, 3, 222, 8949, 3197], [104], [104, 106, 52, 2120, 4, 572, 21, 292, 755], [104], [181, 274, 148], [203, 1, 203, 1, 8866], [203, 391, 70, 17, 67, 6, 4482], [203, 120, 1, 98, 2, 703, 2980, 202, 22363, 23, 11, 22364, 996, 22365], [443, 2, 1, 327, 12, 1657, 2330], [150, 13, 23, 51, 337, 38, 23, 11, 325, 1], [1596, 32, 1097, 8, 858, 22366], [250, 184, 6, 58, 985, 4, 4390, 8841, 506, 10, 9], [250, 184, 6, 58, 38, 3, 597, 35, 506, 10, 9], [250, 184, 6, 58, 38, 5, 563, 2, 1303, 883, 506, 10, 9], [567, 95, 70, 17, 67, 6, 1131, 10, 172, 1464], [21, 4, 1937, 77, 97, 226, 3, 266, 22367, 18, 610, 344, 22368, 1, 5, 1357, 1878, 423, 82, 22369], [1797, 89, 1, 163, 40, 121, 50, 226, 22370, 941, 331, 65, 13, 15, 41, 167, 123, 3560, 22371], [1797, 1074, 571, 79, 2, 4391, 9], [1374, 2616, 146, 134, 7, 1754, 1, 201, 3673, 218, 16, 2, 2285, 151, 105, 791, 553, 42, 1], [82, 1514, 51, 4325, 39, 9, 14, 616, 99, 2495], [19, 585, 1, 32, 3, 86, 59, 12, 6028], [19, 22372, 1], [19, 50, 2592, 11, 4, 24], [19, 1410, 1173, 217, 1144, 7, 1], [19, 22, 203, 953, 83], [19, 186, 3, 46, 28, 18, 22, 1, 43, 127], [19, 42, 1, 19, 42, 1], [19, 20, 98, 1], [172, 5903], [19, 3050, 3, 90, 22373, 8, 22374, 5, 599, 28, 1135, 6, 1226, 144, 6, 139, 479, 126, 3935, 28, 4, 19, 459, 10, 231], [19, 341, 7276, 69, 317, 64, 2, 2137, 2756, 735, 212, 508, 22375], [19, 494], [1156, 5, 42, 185, 816, 1156, 22376, 22377, 22378, 8, 2726, 7, 1266, 102, 174, 767], [858, 1568, 49, 4, 428, 164], [315, 30, 181], [22379, 22380, 22381, 22382, 550, 34, 1557, 22, 8893], [28, 18, 10, 822, 1, 23, 279, 69, 3, 543, 15, 125], [28, 129, 15, 24], [28, 155, 2969, 54, 22, 1], [77, 208, 13, 23, 1442, 51, 50, 1, 3, 33, 75, 528, 51, 20, 675, 46, 783, 1442, 51, 769], [77, 103, 9, 33, 73, 4, 2192, 103, 1994], [134, 50, 961, 138, 92, 40, 2, 172, 1812, 9, 42, 2, 902, 31, 42, 299, 2, 25, 1161, 124, 15, 80], [134, 76, 1, 93, 235, 3, 63, 7345, 5, 36, 103, 14, 108, 4858, 26, 513], [22383, 10, 1109, 8, 10, 280, 8, 10, 9], [721, 6, 62, 5, 220, 33, 2, 9, 65, 21, 32, 4, 701], [22384, 41, 164, 1861, 6, 22385, 8, 36, 49, 492, 170, 29, 780, 27, 4, 95], [61, 28, 440, 11, 2, 341, 347, 8, 309, 1], [274, 3, 75, 19, 397, 22386, 69, 1, 59, 111, 48, 22387, 28, 2, 112, 19, 401], [152, 28, 2, 1356, 16, 2, 22388, 18, 10, 138, 149, 3, 1012, 7, 24], [152, 44, 76, 24, 1223, 35, 60, 22389, 1185, 1226, 76, 6, 1856, 13, 307, 3, 195, 2, 2188, 22390, 8, 3, 103, 100, 5, 14, 99, 647], [93, 138, 1356, 1, 13, 8950, 81, 6, 384, 245, 698, 16, 193, 4, 1, 13, 8950], [1929, 5, 861, 35, 816, 21, 48, 528, 51, 10, 175], [41, 2, 1, 37, 89, 5, 75, 1800, 6, 19], [41, 2, 989, 301, 641, 13, 22391, 187, 23, 33, 43, 2, 243, 91], [41, 585, 926, 22392, 19, 174, 1, 33, 704, 50], [41, 3186, 1], [41, 13, 445, 9, 11, 10, 702, 2657], [41, 10, 1, 11, 50, 792, 107, 6, 479, 17, 35], [41, 39, 89, 1, 304, 18, 17], [41, 6, 4, 489, 570, 33, 6, 28, 11, 351, 8, 304, 21, 9, 6, 229, 35], [41, 20, 9, 18, 4, 3861], [146, 1079, 21, 4, 1, 459, 493], [146, 1891, 97, 977, 16, 32, 7, 24, 22393, 10, 768, 12, 4, 8703, 11, 4, 561], [146, 1093, 531, 6, 157, 143, 310, 142, 601, 218, 3, 28, 22394, 38, 3, 94, 32, 39, 89, 1, 163, 913, 28, 214, 218, 3, 75, 563, 240], [146, 1011, 21, 4, 5985, 25, 80, 1, 172, 5986, 916], [2155, 353, 27, 6074, 4, 141, 6074, 8, 141, 1018, 904, 8, 66, 63, 70, 22395, 720], [22396, 344, 111, 49, 13, 63, 66, 32, 33, 14, 417, 6, 922, 166, 8, 494, 111, 4422], [875, 1324, 850, 190, 5605, 22397, 6078, 3, 103, 644, 60, 127, 54, 123, 4, 1540, 225, 15, 7985], [2430, 35, 11, 22, 45, 861, 125, 143, 45, 42, 99, 24, 6, 19, 125, 325, 45, 34, 23, 11, 64, 125, 325, 45], [380, 3, 103, 780, 27, 15, 790, 48, 362, 57, 499, 6, 58, 485, 56, 15, 55, 48, 478, 485, 211, 3, 38, 4, 3922], [380, 3690, 317, 67, 6, 61, 18, 2, 438, 27, 17], [189, 733, 6, 17, 49, 22398, 10, 1680, 8, 65, 51, 5, 733, 13, 141, 285, 8951, 8951], [189, 7, 359, 18, 126, 504, 49, 248, 4, 77, 7, 62, 52, 136, 2, 504, 49, 560, 248], [136, 19, 3004, 61, 345, 59, 3646, 60, 127], [736, 148, 22399, 9], [736, 171, 1], [736, 93, 1640, 27, 7, 68, 1], [736, 10, 77, 33, 429, 18, 2, 1, 13, 2, 1361, 281], [736, 22, 252, 18, 10, 1747, 72, 1, 11, 155, 22400, 23, 3277, 51, 60, 16, 76, 55], [243, 457, 10, 399], [243, 457, 6, 64, 97, 1, 66, 220, 342, 108, 11, 22401, 8, 66, 96, 49], [243, 457, 6, 10, 455, 1, 10, 498, 74, 309, 10, 504, 64, 5, 37, 209], [243, 457, 6, 4, 2123, 1, 3, 62], [243, 280, 243, 236, 7084, 2401, 1250, 6, 1603, 42, 16, 1327, 1470, 86, 7661, 335], [243, 923, 1], [6066, 22, 24, 661, 346, 22402, 6161, 3092, 1607, 215, 297, 3471, 600, 6066, 1399], [136, 621, 1649, 7, 2525, 44, 3058, 99, 60, 16, 212, 144, 44, 1780, 1351, 18, 1681, 196, 36, 29, 62, 71, 6, 484], [90, 38, 9, 1787, 45, 1472, 12, 22403, 55, 45, 12, 625, 3782], [90, 38, 5, 446, 54, 910, 6, 111, 8, 36, 788, 4, 3906, 13, 20, 11, 4, 329, 1, 57], [44, 2, 1626, 22404, 110, 124, 17, 18, 4, 269, 904, 238, 204, 531, 55], [44, 68, 16, 212, 115, 162, 2, 1078, 67, 6, 753, 155, 1, 11, 2, 954, 1634, 6658, 18, 798, 7, 266, 100, 17, 257], [52, 124, 2, 323, 79, 8834, 42, 82, 4, 4806, 27, 4, 7205, 493, 2834, 36, 61, 2, 180, 1384, 1440, 16, 322, 8433], [52, 48, 315, 43, 52, 33, 19, 27, 912, 339, 1, 55], [52, 121, 15, 2, 202, 1], [52, 47, 428, 345, 1], [52, 70, 501, 16, 17, 149, 23, 475, 59, 4, 95, 8, 52, 72, 52, 48, 1003, 140, 3, 29, 13, 3001, 3327, 55, 1035, 2600], [566, 97, 41, 2, 91, 9, 293, 52, 594, 205], [286, 118, 2033, 129, 230, 3, 182, 100, 245, 1, 543, 17, 11, 4, 172, 231], [286, 221, 23, 14, 2, 24, 534, 3195, 29, 627, 2, 643, 68], [2794, 1833, 18, 32, 7, 684, 1, 23, 4384, 35], [50, 6096, 121, 3, 47, 5622, 4695, 8, 22405, 3, 1071, 50, 3078, 8, 121, 4144, 81, 6, 212, 203, 1176, 1, 8475], [50, 30, 2683, 280, 3, 63, 400, 18, 50, 45, 1432, 40, 294, 123, 13, 3, 407, 223, 1071, 15, 1, 680], [50, 172, 3447, 22406, 40, 12, 119, 22, 1, 413, 19, 22, 45], [50, 24, 13, 17, 50, 548, 13, 19, 254], [403, 23, 48, 1580, 34, 23, 13, 4, 237, 51, 22407, 5, 62, 3, 41, 7, 1278, 3834, 236], [403, 154, 253, 22408, 1073, 432, 14, 81, 133, 2745, 205, 33, 144, 30, 299, 7, 429, 35, 11, 10, 235], [403, 22409, 23, 613, 1], [84, 3, 195, 1776, 171, 2174, 2, 83, 23, 322, 1220, 8, 195, 68, 16, 4, 247, 3052, 417, 111, 289, 182, 4772], [837, 22410, 1006], [167, 7, 1, 27, 2, 2127, 8894, 1, 64, 2127, 22411], [167, 4, 1692, 489, 8, 94, 60, 1, 3, 363, 6, 261, 22412], [9, 30, 25], [9, 596, 4, 4725, 22413, 22414], [9, 46, 45, 38, 15, 107, 6, 585, 334, 414], [9, 49, 156, 157, 20, 653, 11, 2, 25, 3019, 78, 48, 61, 6, 14, 3960, 634, 5, 28, 20, 30, 257, 123, 2, 916], [9, 110, 185], [9, 28, 257, 8686, 163, 31, 245, 25, 2493, 17, 765, 585, 113, 42, 3, 271, 125, 585, 3402, 163, 156, 542, 6, 4731], [9, 28, 214, 38, 36, 86, 5, 627, 76], [9, 11, 10, 22415], [9, 13, 38, 5, 2293, 36, 72, 15, 5835], [9, 87, 6, 271, 11, 9, 507, 1446], [9, 479, 17, 13, 22416], [9, 1265, 862, 227, 76, 173, 1348, 361, 22417], [555, 18, 1, 23, 59, 6, 1646, 88, 211, 7, 571, 1071, 4, 3534], [1991, 31, 5, 109, 67, 6, 421, 10, 548, 70, 2, 629, 59, 2, 3643, 144, 91, 69, 12, 93, 51, 2370, 8, 136, 2, 196, 3940], [1084, 19, 78, 49, 141, 283, 15, 13, 1243, 11, 1914, 4093, 411], [1084, 45, 3, 195, 33, 28, 3837, 18, 123, 2, 1224, 22, 12, 8869], [1061, 3, 33, 58, 15, 21, 4, 1, 2990], [293, 22418, 28, 565, 11, 84, 104, 235], [293, 22, 1, 12, 2513, 21, 4, 22419, 16, 57, 40, 200], [341, 25, 12, 33, 73, 180, 73, 3, 29, 13, 6109, 1364, 1, 417, 99, 52, 266, 205], [71, 585, 2846, 1912, 8449, 22420, 51], [71, 239, 714, 277, 2, 1, 146, 421, 37, 639, 1534, 103, 139, 114, 10, 274, 148, 3515], [71, 239, 16, 42, 9, 89, 30, 141, 265, 29, 126, 3092, 8, 311, 35, 11, 261, 155, 449], [71, 209, 5, 131, 394, 7, 2, 22421, 3296, 22422, 660, 47, 747, 4, 3814, 5858, 8608], [71, 4, 19, 58, 32, 39, 19, 104, 30, 22423, 110, 258, 4040, 191, 1024], [71, 5, 1937, 34, 2, 9, 364], [71, 5, 22424, 1839, 38, 20, 5783, 59, 255, 4, 199, 45, 416, 499, 12, 2722, 8, 5783, 59, 22, 1523, 12, 56, 80], [4, 750, 440, 65, 4, 237, 31, 5, 191, 17, 1, 122, 99, 4500, 33, 14, 630, 1047, 31, 20, 834], [22425, 1], [31, 212, 5324, 51, 7585, 79, 17, 98, 22426, 3, 118, 72, 22427, 19, 2419, 433, 4, 2500, 368], [22428, 2487, 223, 14, 587, 130, 2, 1], [22429, 1085, 3605, 668, 1059, 137, 27, 50, 24, 22430], [22431, 2814, 8, 5584, 355, 343, 1328, 137, 27, 50, 8952], [22432, 22433, 6365, 1878, 102, 50, 2871, 8, 1007, 50, 631, 24, 22434], [2350, 883, 22435, 8, 137, 1059, 2350, 883, 1624, 50, 24, 22436], [22437, 6777, 8227, 77, 244, 676, 5454, 50, 24, 27, 2, 22438], [8953, 2649, 1328, 8953, 19, 50, 5542, 24, 27, 22439], [8954, 7116, 682, 6116, 8954, 714, 50, 8952], [22440, 2097, 341, 1958, 1328, 19, 50, 5542, 24, 27, 22441], [4748, 4471, 6116, 22442, 229, 102, 50, 1106, 24, 288, 40, 22443], [4748, 4471, 7945, 341, 6116, 4748, 4471, 1750, 50, 3170, 839, 173, 50, 7821], [92, 197, 18, 2751, 22444, 37, 3, 195, 22445, 3, 44, 2, 949, 310, 7, 3, 79, 1753, 949, 7, 101, 22446, 8, 22447], [2927, 28, 4, 19, 102, 16, 1454, 5, 181], [4909, 88, 2, 236], [505, 30, 71, 585, 413, 25, 90, 18, 2, 1, 364], [3, 46, 475, 59, 2, 25, 1823, 10, 83], [3, 195, 68, 16, 212, 111, 69, 87, 22448, 37, 148, 1725, 7, 23, 48, 4, 2272, 1, 11, 4, 3434], [3, 132, 19, 7, 9, 40, 2, 357], [3, 394, 80, 1, 122, 163, 1099, 469, 3, 100, 10, 343, 142], [3, 63, 14, 2, 4747, 1061, 34, 14, 2, 1, 12, 10, 22449], [3, 29, 45, 81, 3, 1499, 81, 1019, 638, 383, 1, 81, 1019, 638, 383, 5502, 1509, 576, 3, 46, 41, 43, 22450], [3, 29, 86, 287, 198, 255, 4398, 3008, 207, 22451, 55], [3, 258, 15, 356, 38, 181, 1053, 2919, 21, 8452, 18, 2, 22452, 22453, 55, 7, 2, 19, 3540, 6694], [3, 28, 57, 7, 77, 446, 598, 6, 14, 34, 207, 111, 309, 985, 4, 8955, 8, 22454, 22455, 7, 2, 406, 16, 4, 8955, 22456], [3, 41, 292, 11, 2, 899, 3989, 1], [3, 41, 60, 144, 30, 228, 34, 3, 64, 240, 205, 36, 70, 10, 164, 22457], [3, 41, 2416, 1, 13, 23, 2399, 2072, 10, 22458, 22459, 13, 60, 8886, 8, 3057], [3, 146, 412, 16, 9, 13, 2378, 22460], [3, 90, 585, 537, 331, 2446, 259, 1], [3, 90, 319], [3, 90, 10, 2081, 37, 209, 40, 70, 17, 131, 313, 8883, 51, 50, 185, 1, 30], [3, 90, 4, 413, 659, 9, 22461, 81, 55, 2096, 57, 23, 362, 111, 395, 3655, 8, 713, 264, 65, 13], [3, 44, 6, 14, 4, 2819, 1944, 1], [3, 8901, 3006, 2, 1, 1427, 8636, 22462, 2761], [3, 235, 34, 2, 1, 11, 4, 3941, 128, 40, 122, 6, 137, 15, 1724, 1, 3, 62, 20, 235, 505], [3, 33, 976, 11, 64, 27, 2, 1, 27, 2, 185, 22463], [3, 33, 623, 17, 8, 44, 132, 81, 45, 6, 922, 166, 22464, 21, 4, 722, 3576, 7388, 139, 262, 17, 83], [3, 13, 1397, 27, 80, 1, 3, 13, 172, 50], [3, 477, 6, 3662, 445, 59, 1058, 106, 1314, 245, 127, 130, 7, 276, 70, 5, 2, 24, 5635], [3, 64, 89, 1, 7, 10, 19, 437], [3, 64, 71, 38, 15, 47, 1211, 416, 64, 204, 819, 204, 34, 3, 47, 13, 1600, 15, 19, 2967, 8, 92, 416, 69, 64, 15, 90, 15], [3, 216, 789, 26, 4131, 6082, 3796, 27, 22465, 8, 22466, 236, 501, 3796, 27, 5283, 22467, 10, 108, 12, 22468], [3, 318, 87, 6, 28, 60, 9], [3, 87, 68, 16, 39, 224, 4, 360, 186, 1, 149, 39, 1595, 1126, 9, 46, 8835, 15, 55], [3, 87, 60, 22469, 1891, 11, 22, 1], [3, 87, 6, 61, 6, 4, 953, 22470, 3257, 8, 1071, 60, 365, 1192, 3921, 37, 3, 63, 1985, 18, 5, 9], [3, 105, 724, 2, 639, 37, 2536, 8, 270, 2, 1, 31, 15, 220, 10, 639, 40, 118, 44, 132, 429, 18, 1449], [3, 429, 22471, 330, 26, 3, 41, 1, 21, 8284, 180, 954, 22472], [3, 920, 54, 22, 9, 33, 262, 17, 191, 6, 2324, 2, 694, 16, 22473, 444, 740], [3, 109, 90, 38, 807, 1, 157, 138, 808, 2243, 3, 300, 78, 198, 28, 257, 4, 19, 562, 151, 229, 5, 2243], [3, 109, 67, 98, 7416, 92, 8, 31, 5, 121, 3, 118, 72, 22, 2, 449, 892, 3, 118, 79, 5, 2, 889, 144], [3, 8949, 76, 6, 382, 50, 274, 1236], [3, 492, 2, 95, 5433], [3, 297, 2, 25, 472, 6, 1268, 907, 54, 143, 1195, 163, 2, 1, 125, 2, 22474, 28, 102, 51, 84, 139, 776, 72, 22475, 5188, 42, 143, 5528], [3, 96, 29, 594, 85, 1, 51, 10, 314, 22476, 118, 157, 18, 2784, 3446, 155, 19, 115], [3, 86, 3, 87, 6, 194, 3077, 16, 4, 1260, 16, 4, 673, 2704], [3, 86, 31, 10, 504, 220, 6, 28, 1020, 35, 2213, 14, 4, 250, 68, 22477], [3, 86, 23, 1812, 6, 927, 406, 98, 2662, 533, 133, 1, 66, 603, 124], [3, 299, 1439, 435, 220, 614, 6, 316, 56, 6, 4, 1476, 34, 36, 452, 114, 17, 136, 136, 5378, 653, 22478, 22479], [3, 131, 61, 6, 4, 179, 489, 1146], [3, 67, 2, 391, 4727], [3, 47, 5455, 422, 22480, 28, 18, 10, 822, 1], [3, 47, 934, 1704, 1992, 323, 2644, 444, 40, 121, 19, 703, 283, 55, 336, 1, 19, 5], [3, 47, 223, 21, 201, 115, 29, 50, 1, 30, 346, 17], [3, 47, 1722, 913, 2, 1, 215, 264], [3, 47, 105, 196, 6, 5, 211, 66, 291, 35, 5, 176, 70, 17, 598, 13, 98, 809, 3, 105, 363, 102, 6, 460, 8, 19, 1], [3, 47, 349, 21, 4, 11, 7, 68], [3, 47, 270, 2, 826, 1245, 11, 2949, 2119, 13, 3, 1051, 76, 851, 8, 348, 8, 502, 76, 7827, 23, 1811], [3, 301, 3, 47, 2425, 37, 3, 452, 44, 6, 799, 27, 1, 177, 34, 2448, 426, 77, 49, 22481, 341], [3, 454, 85, 77, 63, 79, 22482, 1, 36, 431, 27, 15, 34, 38, 2, 25, 79, 384, 68, 5186, 32, 54, 36, 481], [3, 266, 28, 2070, 1046, 205, 426, 23, 43, 1363, 122, 6, 741, 22483, 22484, 173, 186, 9], [3, 452, 21, 22485, 22486, 39, 9, 54, 16, 829], [278, 61, 6, 4670, 163, 2377, 212, 1060, 7742, 4969, 6, 383, 2043, 883, 7278, 3209, 2, 1, 102, 2, 1308, 163, 28, 18], [278, 516, 400, 771, 130, 19, 545, 4252, 283], [23, 560, 65, 6, 2010, 392, 106, 1], [23, 370, 34, 31, 5, 29, 119, 22487, 508, 123, 4, 488, 7, 15, 82, 4, 2372, 5, 49, 944, 98, 22488, 285], [23, 370, 3, 79, 5, 2, 8956, 1, 15, 48, 20, 1791, 20, 37, 8956], [1409, 1161, 778, 9, 36, 420, 6, 981, 3, 100, 240, 778, 17], [22489, 37, 56], [2575, 885, 2659, 12, 56, 10, 310, 14, 3834, 4, 8672, 184], [278, 65, 112, 144, 1174, 84, 473, 531, 37, 151, 33, 58, 15, 11, 10, 235], [1004, 133, 43, 339, 1], [552, 57, 1260, 22, 1, 197, 18, 34, 18, 1260, 1681, 253, 10, 22490, 5079, 277, 48, 196, 23, 3744, 22491], [552, 78, 574, 7, 22492, 6, 22493, 22494, 13, 78, 2135, 59, 2673, 22495, 15, 47, 60, 250, 521, 236, 51, 965, 7, 3, 724, 395], [31, 2, 1, 29, 13, 17, 1406, 329, 125, 143, 1], [31, 2, 1, 118, 22496], [31, 2, 77, 2, 9, 34, 40, 46, 719, 621, 91, 88, 411], [31, 585, 25, 990, 125, 42, 765, 276, 122, 6, 19, 174, 1, 33, 6, 204, 42, 22497], [31, 621, 2202, 2, 473, 178, 4653, 781, 5, 49, 2, 187, 982, 14, 58, 473, 178, 2202, 1047, 51, 4, 192, 16, 5294], [31, 1, 131, 25, 28, 102, 4, 2022, 8, 61, 595, 68], [31, 765, 61, 6, 22498, 612, 40, 276, 119, 7, 24, 5446, 36, 107, 4903], [31, 3, 220, 6, 309, 8, 14, 7792, 73, 98, 978, 278, 14, 2, 22499, 269], [31, 684, 3930, 1127, 28, 32, 39, 65, 69, 109, 56, 17, 74, 170], [31, 15, 3420, 29, 5088, 122, 307, 25, 7, 81, 4, 247, 56, 11, 1131, 280, 14, 4, 8957, 39, 49, 488], [31, 289, 182, 132, 2, 104, 6, 5, 100, 17, 62, 8, 151, 396, 513], [31, 217, 86, 5, 44, 9, 36, 33, 72, 7, 149, 519, 36, 131, 14, 68, 74, 14, 4, 101, 68], [31, 42, 2945, 35, 3, 41, 4, 22500, 445, 42, 1], [31, 42, 29, 303, 4, 874, 16, 207, 4763, 5, 523, 2, 529, 1249], [31, 42, 119, 860, 1711, 8, 338, 4, 22501, 1119, 190, 174, 2, 2158, 8, 560, 530], [31, 42, 28, 214, 74, 11, 174, 150, 133, 4040, 1259, 1316, 175, 88, 186, 46, 21, 42, 3, 14, 694, 51, 22, 45, 205], [31, 42, 276, 14, 125, 174, 482, 110, 31, 52, 74, 40, 359, 33, 242, 4, 19, 35, 8, 114, 4, 138, 74, 2741, 211, 32, 46, 295, 165, 88, 64], [31, 22502, 64, 22503, 13, 2332, 23, 37, 1438, 6, 44, 135, 11, 7633, 164], [31, 174, 77, 194, 1396, 11, 580, 16, 42, 40, 122, 6, 1594, 42], [31, 80, 77, 317, 3761, 265, 7, 1, 339], [31, 5, 63, 19, 10, 1, 149, 25, 23, 4, 45, 151, 2002, 97], [31, 5, 998, 175, 129, 68, 755, 211, 5, 175, 76, 5, 49, 2, 22504, 24], [31, 5, 44, 7, 161, 24, 1855, 7216, 22505, 29, 255, 43, 926, 5394, 45, 12, 8873], [31, 20, 173, 5738, 22506, 2492, 5, 198, 44, 6, 255, 76, 224, 11, 112, 164, 37, 4, 763, 16, 263, 62, 57, 2, 187, 5, 1563], [31, 20, 101, 193, 16, 122, 6, 70, 17, 150, 89, 12, 123, 79, 17, 2, 203, 1, 835, 2415, 88, 5, 198, 6550, 20, 1068], [31, 20, 122, 54, 21, 22507, 2702, 29, 79, 621, 499, 2, 24], [31, 20, 48, 1801, 21, 3418, 20, 2, 141, 1], [2207, 131, 14, 202, 37, 1758, 174, 2, 120, 7670, 9], [1676, 3, 65, 93, 8, 32, 34, 1301, 1, 139, 70, 15, 22508, 20, 1442, 51, 17, 5872], [151, 79, 5, 1, 21, 752, 73, 2, 215, 3923, 8, 10, 250, 3923], [23, 2, 961, 30, 25, 8, 39, 1, 625, 3062], [23, 2, 203, 1], [23, 2, 9, 21, 627, 10, 8958], [23, 3052, 28, 214, 51, 22, 1334, 496, 178, 59, 2038, 3018, 8, 991, 8, 180, 1250], [23, 152, 555, 22, 1, 6, 84, 324], [23, 194, 20, 244, 8, 22, 1, 33, 122, 298, 619, 8, 41, 50, 833, 2583], [23, 255, 2, 2557, 8, 15, 2071, 5898, 2718, 11, 10, 331], [23, 22509, 56], [272, 2944, 1019, 25, 522, 37, 272, 383, 119, 147, 31, 147, 24, 89, 180, 22510, 276, 257, 147], [272, 900, 30, 1, 1, 1], [272, 8558, 409, 399], [272, 762, 143, 24, 54, 13, 290, 264], [2337, 31, 120, 111, 121, 1163, 22511, 661, 16, 1163, 1590, 55], [571, 167, 4, 2306, 197, 11, 4, 24, 40, 223, 107, 108, 2026], [571, 1888, 2328, 235, 125, 2, 203, 231, 1, 58, 165], [11, 19, 3418, 1], [11, 748, 99, 67, 2, 112, 25, 5, 146, 14, 2, 112, 1], [11, 112, 164, 8, 2492, 3, 253, 760, 370, 617, 34, 33, 149, 3, 65, 13, 2, 1909, 5036, 29, 196, 3, 195, 1155, 1348, 8, 878, 135], [22512, 5, 6472, 158, 204, 630], [432, 279, 31, 23, 11, 4, 329, 1, 29, 665, 174, 5329, 51, 17], [432, 279, 69, 10, 25, 438, 340, 31, 4, 1, 70, 5, 243, 8, 5, 431, 27, 50, 88, 58, 5], [432, 44, 9, 37, 109, 5, 44, 43, 540, 6, 475, 59, 17, 8387, 31, 393, 151, 359, 18, 5, 27, 10, 440, 402, 22513], [432, 13, 4323, 34, 52, 363, 11, 55], [432, 506, 4226, 43, 1091, 432, 467, 2110, 43, 1091, 1, 432, 110, 366, 1308, 43, 1091], [432, 569, 18, 71, 3058, 25, 8, 640, 9, 14, 18, 22514, 34, 22515, 65, 51, 135], [432, 302, 39, 1, 8, 432, 302, 39, 25], [12, 416, 152, 14, 2, 983, 1779, 141, 260, 1, 59, 22, 45, 92, 128], [12, 15, 179, 6, 3852, 80, 4099, 51, 197], [12, 169, 129, 1], [12, 40, 955, 15, 3, 67, 2, 1245, 269, 26], [12, 4, 1, 11, 4, 154, 3773, 341], [15, 12, 10, 274, 2096, 117, 6, 44, 120, 1], [15, 196, 7, 23, 253, 748, 8, 14, 22516, 3046, 17, 97, 391], [15, 318, 1234, 225, 22517, 3, 29, 67, 6, 65, 13, 2, 24, 1281, 98, 8958, 224, 34, 3, 560, 29, 67, 6, 4757, 10, 8000, 28, 8354], [15, 862, 1, 87, 6, 14, 542, 21, 4, 717, 22518, 29, 137, 36, 178, 100, 7, 314, 261, 3362, 45, 215, 2, 921], [15, 928, 1], [15, 2, 2057, 154, 115, 8, 4, 95, 36, 7844], [15, 1455, 57, 689, 1, 255, 3, 36, 481, 8, 11, 36, 235], [15, 1772, 38, 111, 814, 1370, 21, 213, 81, 56, 59, 5, 747, 20, 108, 8, 88, 191, 5, 21, 3002, 3026, 1786, 8916], [15, 132, 1654, 1204, 1, 3, 502, 5, 2, 201, 1204, 4662, 2642], [15, 474, 6, 311, 7, 1, 102], [15, 2405, 6, 4, 446, 162, 3, 599, 29, 279, 8, 23, 152, 192, 929, 1, 31, 36, 29, 420, 11, 4, 4584], [15, 37, 804, 3395, 15, 13, 1343], [15, 132, 473, 213, 8, 22, 1, 96, 86, 23, 129, 71, 40, 200, 17, 2260, 3, 29, 86, 2028, 22519], [15, 519, 2, 743, 2, 1799, 74, 6094, 4585, 65, 109, 858, 117, 92, 8, 3, 29, 302, 245, 1205, 4326, 11, 1091], [289, 363, 539, 1243, 181, 11, 473, 115, 48, 727, 243], [3500, 2533, 5, 49, 2, 19, 83, 526, 3, 64, 5, 1168, 148, 7, 4, 237, 45, 5, 349], [3278, 42, 65, 13, 2, 269, 11, 325], [3278, 33, 13, 411, 1], [7674, 4258, 628, 1878], [847, 3050, 20, 2, 19, 144, 31, 5, 442, 11, 22520, 22521, 3242, 20, 164], [1280, 8959, 22522, 216, 501, 16, 26, 92, 4, 5265, 1895, 445, 1332, 776], [1280, 8959, 21, 22523], [22524, 370, 6, 465, 22, 23, 61, 6, 2765, 21, 4, 250, 817, 15, 165, 48, 14, 248], [22525, 54, 445, 206, 9, 2, 6674, 8, 2, 391, 2473, 44, 3511, 22526], [33, 2, 5876, 179, 730, 987, 7447], [33, 592, 54, 136, 98, 970, 49, 10, 412, 22527, 390], [33, 41, 328, 2295, 27, 10, 391], [33, 13, 77, 75, 14, 2, 3034, 189, 75, 167, 2, 77, 3583, 15, 2, 957, 1911, 7, 103, 1115, 22528], [33, 13, 3, 216, 5, 9, 107, 21, 17, 3, 63, 70, 78, 61, 423], [33, 216, 22529, 10, 1], [33, 1649, 60, 56, 18, 10, 6023, 1447, 3, 124, 6, 656, 35], [33, 486, 4, 324, 22530, 22531, 2622, 22532, 8, 22533, 5768, 22534], [543, 22, 1, 6, 4, 4159, 2549], [1854, 29, 2270, 22535, 125, 765, 1], [5002, 5003, 56], [62, 5, 29, 13, 17, 22536, 80, 1, 247, 13, 22537], [3250, 274, 1], [5883, 23, 807, 559, 81, 8, 100, 61, 9], [3354, 17, 2, 9], [215, 299, 230, 618, 11, 5594, 66, 124, 2, 5572, 8842, 11, 2636, 940, 8, 3, 946, 21, 8843, 485, 3, 1342, 6, 84, 109, 180, 1340, 7215], [215, 324, 6, 2, 1, 25, 85, 5, 308], [713, 2885, 1], [528, 18, 4, 1077, 86, 1678, 57, 80, 1, 30, 28, 19, 22538], [338, 43, 293, 21, 39, 319], [100, 4, 9, 30, 22539, 28, 5722, 8960, 8, 305, 841, 5535, 479], [164, 12, 97, 3071, 165, 62, 7, 1, 12, 223, 959, 97], [164, 6, 434, 6, 14, 214, 32, 4413, 1, 23, 1236, 420, 174, 1864, 147, 193], [13, 2919, 51, 22, 589, 141, 22540, 213, 206, 191, 21, 2, 498, 281, 19, 50, 4915, 1, 3115], [13, 2, 1, 327, 12, 1657, 2330], [13, 2, 1, 125, 43, 30, 42, 46, 45], [13, 2, 981, 989, 71, 277, 15, 150, 6, 44, 2, 45, 2163, 16, 677, 6, 22541, 6, 34, 48, 68, 1, 6, 19], [13, 31, 5, 49, 61, 6, 14, 2, 2512, 161, 1, 58, 48, 81, 6, 307], [2226, 978, 353, 49, 2824, 4, 237, 1795], [161, 1], [161, 1, 7, 142, 6, 70, 20, 5608, 46, 41, 6, 113, 50], [161, 1594, 8, 1290, 2110, 8, 22542, 32, 264], [161, 185, 30, 1], [141, 185, 30, 1, 3, 46, 172, 125, 22543], [128, 3, 22544, 44, 1752, 27, 22545, 343, 70, 15, 65, 37, 537, 23], [128, 23, 6520, 10, 24, 5931, 1368, 26, 4504], [128, 805, 23, 48, 2, 9, 23, 2, 111, 395], [128, 2874, 6385, 8845, 22546, 56], [128, 584, 1727, 213, 206, 23, 238, 44, 60, 22547, 903, 584, 2, 917], [128, 25, 920, 2, 22548, 3869, 18, 76, 319], [128, 141, 277, 22, 1, 22549], [128, 981, 154, 115, 21, 5259, 408, 932, 22550, 27, 4721, 281, 7, 372, 726, 37, 40, 600, 22551, 48, 168, 2, 372, 22552], [1140, 77, 29, 100, 2, 189, 557, 5, 13, 2, 190, 3473, 5, 49, 2, 1106, 3473], [1140, 474, 18, 394, 12, 248, 22553, 120, 1480, 47, 18, 394, 52, 75, 14, 56], [1140, 55, 422, 3494, 57, 1, 223, 113, 17, 43, 4929], [2516, 38, 5, 400, 11, 2, 179, 77, 930, 51, 1255], [2516, 1769, 22554, 18, 97, 2873, 1, 809, 694, 5548, 19, 4, 654, 16, 1094], [2560, 252, 121, 1, 82, 2060, 19, 6, 22555, 2387, 167], [2560, 119, 7, 1487, 104], [425, 57, 31, 20, 108, 12, 1015, 38, 5, 28, 54, 4, 1306, 20, 2, 9], [1614, 2767, 5, 114, 1142, 51, 197, 15, 156, 68, 1500, 30, 1, 11, 4, 1088, 2041, 463, 46, 22556], [1614, 3, 75, 80, 26, 22, 1, 136, 1239, 1501, 4, 493], [1667, 1336, 12, 2, 697, 3876, 16, 71, 3285, 63, 28, 5, 283, 52, 65, 13, 20, 1413, 22557, 1859, 2013], [1020, 7, 1, 99, 176, 4, 1136, 54, 242, 4, 580, 676], [55, 410, 32, 4, 9, 289, 132, 539, 101, 6, 623, 7, 3, 29, 172, 87, 245, 16, 980], [55, 410, 7, 175, 5242], [55, 20, 2, 185, 30, 1, 53, 375, 1486, 524, 22, 12, 170, 615, 150, 206, 478], [55, 38, 5, 410, 482, 178, 26, 98, 5219, 9, 801, 84, 226, 1229, 22558], [55, 1, 46, 2355], [55, 3, 13, 7, 1623, 7, 22559, 1452, 1623, 47, 37, 56, 22560], [55, 31, 5, 90, 17, 3, 109, 29, 134, 2, 45, 140, 289, 519, 328, 295, 6, 5, 426, 20, 33, 2, 1], [55, 422, 187], [55, 185, 30, 1, 3, 29, 19, 545, 5], [55, 36, 2566, 4, 180, 190, 813, 27, 6492], [55, 4970, 9], [22561, 22562, 113, 80, 1, 6, 1942, 143, 4699], [65, 51, 7, 1, 117, 116, 117, 116], [65, 51, 22, 1, 995, 71, 12, 40, 314, 1698, 1114], [65, 51, 22, 1, 294, 99, 637, 6, 10, 1152, 2401], [65, 13, 2, 837, 8, 48, 1141, 12, 57, 3, 58, 237, 1929, 1818], [65, 13, 10, 4976, 16, 4, 264, 103, 14, 28, 8535, 8, 44, 2, 705, 181, 619, 197], [514, 2, 535, 2492, 1141, 11, 22563, 1, 167, 17, 27, 50, 1832, 586, 672, 10, 8218, 33, 68, 16, 212, 115], [64, 275, 34, 90, 1], [64, 71, 115, 22564, 156, 107, 27, 1934, 5802, 8, 3125, 22565, 15, 70, 17, 150, 750, 127, 1768, 88, 3, 428, 2975], [4965, 3, 33, 200, 23, 22566, 426, 40, 132, 175, 13, 2, 9], [4965, 5762, 161, 1], [22567, 22568, 22569, 22570, 8, 3, 44, 2405, 37, 637, 278, 204, 2, 1, 21, 76, 1249], [70, 174, 1, 67, 60, 127], [70, 789, 64, 6, 10, 402, 149, 3, 75, 303, 2, 9, 390], [70, 4, 8957, 1072, 11, 2, 2708, 34, 374, 152, 14, 1639, 23, 48, 238, 1268, 5439, 22571, 1, 30, 23, 122, 6, 70, 6797], [1483, 27, 10, 3007, 5169, 6, 58, 60, 1503, 1495], [91, 3, 146, 662, 54, 27, 3476, 4600, 1274, 8395, 9], [91, 204, 639, 16, 201, 211, 40, 6001, 40, 7797, 1531, 211, 44, 22572, 1, 655, 15], [4544, 12, 59, 6, 28, 214], [22573, 5, 41, 7, 859, 2671, 24, 55], [3711, 1295, 3470, 1324, 190, 1173, 8, 813], [485, 1, 103, 139, 81, 59, 22, 252, 22574, 68, 115], [17, 8, 1892, 44, 156, 132, 1300, 39, 9], [17, 64, 2, 9, 12, 585, 43, 43], [17, 22575, 59, 4694, 120, 8266, 4694, 120, 77, 20, 2, 1, 17, 422, 42, 599, 33, 1392, 10, 446], [22576, 69, 67, 6, 14, 2, 6823, 1143, 27, 2, 666, 16, 1248, 154, 1648, 620, 494, 617, 1566], [318, 44, 6, 137, 4, 22577, 390, 21, 10, 202, 9, 5, 62, 3, 96, 279, 59, 2346], [318, 294, 6, 5574, 4568, 3, 67, 2, 354, 1637, 7975], [1963, 56, 55], [5498, 5, 96, 2, 9], [169, 230, 1, 426, 1, 253, 1946], [169, 9, 8, 754], [169, 441, 163, 2365, 662, 125, 1431, 45, 15, 407, 10, 2768], [639, 22578, 4, 1377, 12, 585, 308, 1, 23, 4, 910], [10, 833, 10, 108, 735, 10, 24, 8, 10, 1144], [10, 1, 12, 11, 975], [10, 1, 65, 13, 2, 202, 3938, 163, 25, 571, 8068, 2945, 1238, 4271, 13, 5954, 5955, 8, 22579], [10, 1, 271, 10, 1, 37, 29, 65, 40, 176, 7, 24, 3545], [10, 1, 28, 110, 4710], [10, 646, 5324, 228, 86, 15, 550, 6, 8922, 305, 8905, 140, 52, 2, 529, 1863, 14, 4431], [10, 418, 4710, 130, 20, 339, 1], [10, 586, 2, 172, 138, 1, 3, 216, 20, 30, 22580, 20, 48, 1166, 6, 107, 337, 214], [10, 692, 49, 875, 10, 1, 120], [10, 387, 2314, 41, 1810, 509, 8, 65, 51, 42, 1, 7701, 8, 308, 32, 115], [10, 2325, 22581, 88, 88, 4, 1, 1579, 2241, 47, 4693], [10, 504, 3, 265, 5, 48, 119, 2500, 461, 1598, 15, 173, 4, 5588, 16, 22582, 2101, 289, 2434, 897, 23, 13, 1378, 49, 5, 2, 4321], [10, 994, 41, 2, 22583, 207, 472, 15, 37, 322, 40, 165, 100, 17, 2324, 15], [10, 141, 746, 2737, 226, 12, 593, 30, 593, 85, 32, 10, 746, 44, 6, 14, 1125, 9], [10, 455, 1], [10, 306, 122, 6, 28, 17, 6, 303, 918, 2137, 426, 36, 220, 18, 1881, 13, 23, 48, 11, 2, 22584, 1130, 333, 2498], [10, 639, 878, 2, 4503, 55], [10, 25, 12, 2, 89, 30, 1, 1896, 1896], [10, 399, 369], [10, 24, 429, 1368, 8, 20, 29], [10, 117, 1340, 12, 2479, 2222, 130, 2, 2699, 24], [10, 234, 1, 12, 10, 455, 1, 218, 10, 455, 1, 46, 1596, 17, 22585], [10, 1747, 65, 640, 426, 32, 5, 339, 9, 176, 81, 133, 4, 199, 25, 7, 29, 690, 3441], [10, 175, 46, 45, 34, 5, 1, 46, 519], [163, 3, 75, 110, 934, 4, 7140, 331, 2621, 678, 12, 378, 16, 10, 1988, 22586, 3, 62, 331, 2621, 1760, 1, 30, 107, 18, 244], [163, 31, 5, 253, 17, 99, 14, 1208, 20, 152, 309, 2, 2265, 1964, 1045, 30, 989, 1], [530, 9], [87, 6, 28, 4, 8961, 825, 11, 135, 6, 229, 39, 24, 30, 1205, 1294, 69, 12, 5896], [664, 156, 616, 1922, 18, 1566], [1776, 44, 3, 5442, 3, 22587, 6062, 105, 124, 2, 158, 22588], [1161, 132, 2, 1, 25, 5, 29, 67, 76, 437, 280], [105, 396, 151, 105, 436, 585, 1, 22589], [105, 124, 3, 124, 2, 437, 27, 2, 77, 11, 10, 213, 16, 14, 11, 261, 34, 22, 8283, 65, 816, 165, 559, 134, 17, 65], [105, 44, 3, 297, 2, 6833, 901, 2, 591, 1149, 37, 1026, 55], [105, 308, 105, 345, 105, 309, 66, 223, 309, 64, 10, 228, 64, 10, 9, 190, 659, 79, 76, 1052], [105, 308, 105, 345, 105, 309, 66, 223, 309, 64, 10, 228, 64, 10, 9, 190, 659, 79, 76, 1052], [105, 468, 1, 778, 169], [105, 302, 2, 9], [105, 118, 3, 157, 2500, 3852, 18, 10, 231, 8, 100, 2, 8864, 119, 10, 231, 6, 492, 2, 83, 1171, 1171, 1171], [25, 1915, 2, 1, 8, 1, 5, 132, 2478, 11, 8962, 27, 17], [25, 1769, 128, 3, 359, 18, 10, 77, 27, 1321, 1, 37, 22, 2, 43, 22590, 53, 2582], [25, 42, 2, 187, 162, 80, 8716, 3374], [145, 1867, 35], [25, 26, 1, 438, 183, 25, 26, 9, 7559, 36, 63, 302, 240, 88, 36, 359, 545, 4, 3724, 9, 26, 25, 188], [25, 46, 868, 2, 2046, 16, 2145, 91, 1576, 87, 6, 113, 39, 1, 30, 25, 91, 35], [25, 49, 383, 13, 7602, 81, 133, 2, 9, 88, 117, 108, 11, 50, 231, 1138, 107, 6, 17, 81, 133, 6251, 9, 31, 5, 22591, 340, 117, 108, 22592], [25, 2946, 31, 36, 86, 10, 1, 46, 1679, 113, 17, 256, 136], [25, 28, 2, 1241, 311, 8198, 6, 1141, 4, 845, 8, 22593, 29, 110, 72, 4305, 6, 4, 322, 1, 244, 6, 240, 11, 143, 1195], [25, 259, 13, 9, 147, 85, 765, 309, 133, 295], [25, 87, 6, 683, 6, 498, 21, 116, 774, 48, 21, 4, 1790, 9, 22594], [25, 48, 795, 35, 36, 96, 238, 28, 108, 11, 4, 115, 716, 24, 55], [25, 271, 27, 1077, 129, 60, 9, 45], [25, 81, 133, 9, 34, 4, 199, 9, 14, 11, 126, 618, 51, 264, 3441], [25, 545, 1, 1288, 12, 2, 43, 61, 26], [25, 304, 11, 493, 21, 1488, 1525, 4509, 36, 164, 18, 4, 493, 383, 6, 1268, 60, 1], [43, 425, 212, 56, 205, 1468, 1901, 2809, 22595, 53, 39, 332, 53], [43, 1, 3, 200, 48, 67, 6, 255, 1631], [43, 1764, 22596, 9], [43, 9, 45, 74, 22597, 45, 34, 8203, 3, 300, 3, 46, 2493, 8796, 43, 71, 6, 22598], [43, 23, 48, 3619, 1, 23, 22599, 82, 7, 22600, 3927], [43, 308, 205, 23, 669, 21, 2, 322, 83, 44, 17, 58, 32, 409, 16, 45, 7, 46, 109, 307], [43, 87, 6, 14, 2, 83], [43, 1010, 9, 34, 5, 63, 44, 60, 127, 16, 17], [43, 1515, 383, 441, 204, 147, 24, 32, 264, 148, 117, 5229, 42, 117], [43, 22601, 383, 441, 204, 147, 24, 32, 264, 148, 117, 229, 42, 117], [43, 20, 2, 19, 144, 7, 152, 28, 19, 438, 999, 51, 2, 4042, 1146, 44, 501, 27, 212, 22602, 2530], [357, 133, 126, 1781, 5, 32, 24], [357, 13, 3049, 628], [357, 594, 17, 1782, 10, 115, 378, 1, 333, 107, 108, 426, 23, 515, 16, 39, 275, 86, 36, 62, 307], [357, 67, 2, 25, 6, 114, 76, 54, 18, 98, 3320, 22603, 33, 29, 772, 24, 149, 5, 424, 4, 77, 3101, 13, 364], [553, 135, 8786, 55, 53, 116, 136, 41, 6, 14, 60, 319, 591, 2817, 12, 99, 180, 21, 116, 48, 6, 14, 22604], [553, 16, 76, 292, 1, 65, 13, 765, 2036, 2590, 2, 1711, 34, 197, 51, 1852, 22605], [1171, 33, 748, 22606, 195, 3, 56], [48, 110, 370, 128, 632, 35, 48, 44, 45, 8, 96, 44, 6, 197, 21, 45, 3, 655, 8, 94, 1, 28, 766, 633, 17, 102], [48, 501, 38, 5, 44, 8547, 1307, 8, 3186, 22607, 82, 420, 3141, 5, 122, 15], [48, 11, 4, 624, 16, 22608, 6, 43, 1, 321, 2549], [48, 7, 15, 1169, 21, 22609, 34, 66, 29, 72, 45, 6, 305, 177, 33, 13, 5, 29, 536, 7, 22610, 1, 5, 79, 2, 237, 3675], [1895, 6, 653, 2590, 591, 341, 269, 1209], [92, 3, 44, 6, 656, 35, 2, 544, 95, 8, 864, 16, 1178], [92, 106, 6, 258, 4, 269, 1067, 3906], [3236, 15, 32, 93, 295, 12, 329, 27, 1, 7139], [709, 8934, 22, 136, 132, 4, 1535, 21, 239, 1721, 16, 213, 11, 22611, 8, 22612, 7919], [709, 447, 13, 4, 5093], [16, 1134, 204, 15, 17, 8, 10, 2537, 728, 7, 1, 332, 8944, 22613], [22614, 38, 217, 191, 57, 499, 6, 119, 4520, 129, 135, 568, 22615, 180, 1003, 3192], [241, 148, 325, 1, 592, 54, 50, 260, 544, 8, 92, 40, 152, 7031, 4, 1012, 128, 71, 501], [241, 2411, 52, 2, 181, 3379], [22616, 56, 5, 4234, 22, 56, 152, 176, 484, 785, 22617, 40, 248, 33, 146, 609, 876], [550, 1, 477, 35, 22, 12, 1768, 22618, 1256, 198, 48, 14, 2, 22619, 22620], [550, 34, 71, 239, 111, 109, 279, 31, 5, 63, 94, 2, 77, 628, 539, 50, 758], [5185, 399], [206, 2811, 591, 4384, 11, 7, 4008, 2247, 52, 41, 15, 22621, 8, 67, 17, 6, 547, 28, 84, 2870, 61, 361, 7, 507, 1594, 17, 22622], [2480, 20, 995, 1, 3410, 256, 537, 11, 10, 1340], [526, 203, 83, 57, 50, 410], [526, 2813, 3552, 12, 92, 1093, 17, 16, 1386, 3377, 22623, 1, 5703, 11, 54, 16, 2488, 8, 396, 4, 472, 22624, 43, 991, 7989, 74, 2557], [526, 7, 1, 3457, 4486, 1035, 8832, 22625], [526, 22, 629, 12, 2544, 35, 144, 161, 22626, 428, 2819, 913, 2219, 3658, 163, 22627, 12, 2, 3549, 5530], [18, 10, 193, 6, 19, 20, 1], [18, 60, 1194, 158, 45], [18, 4, 250, 115, 16, 261, 10, 5880, 124, 43, 1010, 8, 43, 22628, 32, 15, 124, 220, 445, 22629, 904, 2, 348, 8, 2, 558, 16, 7457], [18, 4, 702, 1287, 27, 5, 9], [68, 180, 7551, 3713, 392, 16, 1, 11, 22630, 2148, 99, 1686, 503], [68, 115, 23, 13, 2139, 1907, 12, 37, 341, 4, 244, 115, 12, 69, 364, 12, 22, 104], [68, 839, 11, 10, 22631, 2782, 89, 1, 27, 17, 919, 17, 162, 10, 3230, 61], [68, 635, 30, 1], [68, 93, 77, 12, 783, 2472, 1], [68, 91, 56, 12, 246, 91, 4667], [68, 16, 10, 534, 204, 2, 260, 95, 8, 2, 5628], [68, 16, 4, 2081, 122, 17, 81, 59, 271, 634, 3978, 8, 46, 357, 22632, 3, 294, 22633, 54, 7, 1], [68, 106, 21, 4, 22634, 1, 1524], [68, 106, 21, 4, 112, 25, 268, 106, 21, 4, 89, 1, 26], [68, 20, 22635, 268, 5, 2, 148, 282, 1058, 5, 46, 59, 6, 58, 2, 2432, 456, 66, 61, 962], [101, 2425, 28, 126, 628, 1663, 2320], [101, 13, 1, 920, 21, 3600, 34, 13, 787, 298, 21, 2358], [101, 10, 261, 452, 134, 265, 126, 22636], [2442, 77, 342, 231, 34, 190, 22637, 55], [3828, 22638, 11, 911, 22639, 2, 22640, 16, 4, 3350, 7582, 3268, 1742, 22641], [74, 544, 324, 31, 97, 306, 79, 4, 670, 211, 40, 46, 566, 82, 5, 21, 1763, 115, 5, 415, 24], [74, 10, 1833, 1207, 64, 2, 1, 7, 62, 6, 176, 17, 68, 694], [22642, 40, 41, 143, 3054, 24], [8682, 10, 1855, 505, 13, 2, 1], [2519, 56], [1010, 1926, 24], [389, 108, 2, 1, 46, 15], [1915, 2, 1, 8, 1, 814, 132, 2478, 11, 8962, 27, 17], [111, 14, 512, 126, 743, 224, 135, 713, 73, 19, 41, 17, 86, 36, 238, 512, 10, 202, 30, 445, 5865, 3523, 451], [1078, 35, 9, 142], [3326, 22643, 651, 227, 173, 22644, 2127], [333, 113, 22, 1, 23, 6556, 50, 1676, 68, 16, 5, 22645, 18, 135, 19, 27, 212, 564, 45, 23, 572, 74, 3, 118, 55], [3358, 139, 4001, 203, 9], [1434, 625, 2845, 34, 39, 1, 2298, 22646], [3612, 2615, 355, 1574, 96, 11, 261, 1], [429, 17, 2, 1515, 26, 313, 7, 24, 2, 3555], [1646, 21, 2, 1], [554, 51, 4, 199, 106, 8, 1, 86, 7, 342], [322, 77, 125, 95, 22647, 2, 936, 251], [8310, 12, 2, 1], [700, 667, 9, 238, 28, 11, 4, 3560, 351, 69, 1415, 7, 25, 6, 186, 205], [349, 54, 10, 1689, 694, 18, 78, 1, 13, 2581], [349, 35, 119, 18, 7, 24, 8, 1598], [929, 2, 1, 18, 50, 767, 736], [1604, 56], [842, 2, 1, 54, 2, 347, 13, 23, 1192, 1151, 1], [24], [24, 46, 45, 34, 2, 3925, 5, 519, 152, 28, 4203, 4020, 74, 5, 146, 389], [24, 30, 1], [24, 30, 111, 27, 743, 8, 22648, 1449, 3, 1512, 4, 111, 96, 103, 6, 313, 402, 4858], [24, 177, 223, 309, 2, 1], [24, 149, 8613], [24, 12, 2, 675, 5, 63, 519, 28, 15, 74, 48, 28, 254], [24, 18, 10, 453, 160, 1625, 583], [24, 22649, 18, 10, 22650, 37, 4, 670, 94, 22651], [24, 157, 84, 30, 6, 376], [24, 37, 93, 41, 17, 298, 539, 4, 689], [24, 37, 93, 3, 2520, 492, 7, 45, 21, 22652], [22653, 32, 2, 25, 87], [559, 229, 17, 69, 10, 573, 228, 220, 8, 15, 229, 17, 32, 4, 68, 69, 220, 4, 268, 231, 1, 513], [1083, 22, 27, 20, 237, 529, 1088, 3, 87, 76, 21, 22, 120, 1, 1506, 51, 10, 202, 234, 7843], [8963, 1, 8963], [2423, 556, 737, 5722, 8960, 1, 30], [1107, 298, 381, 11, 4, 179], [1410, 3771, 13, 6104, 7, 60, 2082, 1400, 187, 30, 22654, 1027, 15, 12], [112, 25, 45, 40, 131, 14, 2, 5581, 379, 613, 25, 1], [109, 1], [109, 54, 135, 205, 83], [109, 515, 16, 44, 2, 4210, 1, 231], [355, 1006, 34, 50, 22655, 22656], [355, 1734, 56], [388, 11, 4, 120, 331, 8948, 22657, 7770], [375, 61, 54, 6, 428, 1125, 2, 1, 221, 7, 1822, 12, 895], [375, 38, 4, 252, 69, 137, 379, 4715, 253, 10, 2088, 22658, 22, 47, 38, 3, 428, 168, 10, 2088, 21, 127, 130, 443], [538, 4, 942, 1258, 11, 22659], [1633], [800, 585, 1, 175, 12, 1657, 2330], [945, 31, 42, 375, 38, 1824, 82, 759, 2732, 440, 263, 27, 7, 166, 1, 30, 25, 852], [1585, 518, 378, 105, 19, 125, 585, 1150, 8936, 765, 276, 1999, 42, 2544, 7825, 5131, 42, 468, 431, 446, 9], [298, 4, 178, 21, 473, 213, 380, 7, 85, 10, 995, 505, 454, 38, 36, 1942, 17, 58, 39, 1, 1022, 505], [1017, 1364, 1, 3, 124, 6, 481, 325], [199, 9, 7, 121, 3, 487, 28, 15, 238, 543, 15], [3227, 187, 367], [94, 3, 1702, 15, 26, 24, 12, 863], [6098, 679, 200, 254, 105, 361, 194, 3408, 11, 4, 561, 18, 1404, 18, 21, 17], [506, 931, 447, 1, 45, 686], [944, 39, 978, 353, 44, 2, 8092, 2463, 4107, 22660, 15, 109, 19, 35, 15, 198, 48, 14, 22, 193, 34, 15, 1437], [944, 69, 279, 57, 207, 495, 12, 7, 70, 5, 2, 1139, 104, 11, 10, 6101], [643, 30, 1, 119, 2, 860], [40, 906, 1058, 879, 34, 40, 105, 430, 150, 8, 1, 125, 147, 22661, 66, 63, 914, 937], [40, 100, 17, 137, 27, 50, 24, 88, 40, 735, 15, 102, 10, 22662], [40, 18, 10, 453, 75, 28, 22, 1, 102, 10, 3306], [40, 6111, 519, 379, 1021, 315, 74, 22, 1, 6111, 26], [40, 785, 17, 147, 24, 34, 3, 105, 906, 2021, 42, 191, 17, 85, 22663, 15, 41, 6, 209, 22664], [40, 47, 113, 17, 59, 22, 265, 69, 508, 16, 84, 845, 49, 616, 1724, 3, 195, 61, 6, 28, 170, 60, 4657, 293, 84, 915, 29, 28, 214], [40, 2, 9, 40, 2, 659, 40, 2, 22665], [4958, 1170, 14, 4, 482], [4333, 3, 299, 15, 47, 1899, 6, 257, 80, 282], [45, 1, 25, 45], [45, 3, 131, 62, 31, 10, 1, 223, 1367, 17], [45, 633, 19, 187, 4366, 1400, 1169], [45, 18, 39, 3679, 9], [1123, 54, 6, 22666, 218, 3, 636, 31, 3, 47, 56, 52, 118, 44, 1874, 15, 2, 22667, 3, 300, 52, 124, 155, 3, 216, 383, 218, 163, 428, 1571, 384, 99], [1123, 54, 6, 4, 1, 69, 13, 2343, 3, 14, 3413, 7, 45], [3681, 127, 64, 6, 1, 19, 18, 4, 234], [242, 35, 1], [2815, 181, 18, 60, 112, 45, 275, 64, 2, 112, 25, 13, 17], [549, 8, 194, 4, 232, 178], [703, 379, 25, 163, 23, 5493, 130, 10, 1], [491, 2, 9], [491, 39, 9, 18, 4, 30, 13, 66, 1809, 240], [1300, 17, 3614, 1325, 1, 151, 311, 5], [981, 1257, 70, 17, 150, 13, 2, 144, 8, 3, 33, 67, 6, 157, 10, 1735, 539, 2, 22668, 22669], [659, 835, 9], [2639, 22670, 1376, 22671, 5253, 6339, 22672], [532, 22673, 35, 11, 325, 1], [251, 2327, 670, 338, 1206, 1998, 22674, 1476, 4392, 8, 4781, 11, 775, 56, 63], [251, 7, 45, 56, 742, 6832, 52, 152, 2566, 22675, 27, 2198, 13, 22], [251, 1655, 1521, 724, 5054, 7541, 47, 2, 9, 38, 84, 386, 6433, 294, 54, 50, 285], [1979, 115, 1, 1788, 525, 328, 163, 1852, 28, 366], [37, 587, 581, 312], [37, 15, 227, 54, 293, 2288, 12, 68, 284, 1], [37, 559, 2482, 18, 10, 138, 8, 907, 20, 203, 30, 22676, 218, 3, 46, 238, 19, 27, 20, 7145, 30, 1, 41, 50, 373, 22677], [37, 6, 2210, 76, 25, 29, 1580, 29, 22678, 29, 2370, 21, 9, 29, 6585, 37, 702, 7, 71, 42, 450, 22679, 11, 1675, 13, 42, 729, 329], [37, 8828], [37, 8695, 72, 9, 5, 62, 23, 4, 9], [37, 693, 66, 748, 1255, 51, 197, 6, 14, 2470, 163, 15, 13, 546, 574, 784, 163, 163, 23, 4, 101, 68, 125, 2, 1092, 163, 22, 236, 152, 22680], [2028, 22681, 66, 259, 11, 2, 360, 162, 1430, 63, 61, 6, 865, 21, 2, 324, 166, 617, 255, 117, 18, 126, 1100, 26, 22682, 31, 3, 2503, 7, 22683], [60, 79, 17, 4, 323, 95, 16, 10, 979], [60, 187, 61, 28, 17, 2007, 4796, 8, 1010, 4680, 14, 5418, 294, 6, 22684], [60, 189, 121, 3, 47, 255, 645, 8, 528, 8, 79, 17, 2, 1298, 374, 22685, 5886], [60, 265, 11, 98, 1076, 95, 1980, 1571, 173, 17, 8, 3, 976, 129, 70, 256, 499, 616, 129, 173, 256, 499, 678, 5261, 22686], [60, 2703, 1, 22687, 17, 229, 17, 174, 183, 231], [60, 613, 24, 27, 60, 908, 613, 2029, 22688, 21, 98, 5595, 22689], [495, 157, 2, 5095, 18, 10, 381, 2487, 1], [495, 114, 39, 354, 423, 82, 17, 230, 3, 119, 4, 413, 1440], [217, 33, 79, 217, 2, 757, 30, 1590, 18, 202, 2175], [217, 1113, 2, 4627, 30, 22690], [601, 23, 33, 13, 583, 22, 1, 124, 4, 22691, 6, 81, 45, 749, 65, 51, 5, 8, 20, 164, 88, 65, 51, 17, 8, 588], [386, 16, 2, 83, 3, 293, 3, 29, 28, 4, 22692, 22693, 230, 3, 63, 498, 10, 22694, 51, 22695], [738, 73, 42, 28, 60, 3795, 8, 78, 454, 85, 3, 61, 37, 332, 18, 39, 9, 1, 46, 45, 22696], [370, 17, 8, 14, 19, 1, 8, 66, 625, 3334], [370, 329, 1], [1794, 19, 1, 69, 28, 766, 36, 67, 87, 6, 795, 102, 8, 22697, 126, 259], [1999, 143, 22698, 125, 8763, 2334, 293, 147, 172, 3054, 338, 74, 22699, 3, 293, 147, 1, 309, 981, 117, 92], [2750, 421, 1], [7002, 1568, 56], [22700, 6114, 65, 13, 2, 141, 1, 525, 806, 13, 2, 4338, 2945, 1614], [411, 388, 120, 56, 235, 30], [96, 41, 2, 9, 5598], [96, 56], [4627, 9], [2863, 4656, 25, 9, 12, 10, 2371], [2178, 50, 13, 98, 354], [185, 30, 9], [185, 1], [185, 1, 914, 6, 1188, 8, 28, 102, 10, 310], [185, 187], [185, 19, 4248, 95], [185, 1394, 24, 1], [185, 826, 81, 6, 13, 52, 144], [270, 2, 2952, 21, 60, 354], [2517, 1], [7316, 6, 4, 816], [789, 847, 23, 2, 22701, 65, 51, 22, 1, 25, 205, 26], [81, 16, 4, 561, 12, 9, 8, 992, 148, 78, 81, 59, 4, 199, 45, 744], [81, 284, 129, 4, 1213, 12, 4, 199, 184, 73, 58, 15, 11, 4768, 29, 122, 6, 14, 1492, 1492, 27, 17, 790, 18, 104, 19, 350], [1516, 29, 79, 17, 22702, 5, 19, 144], [1022, 63, 70, 74, 421, 2, 4768, 5, 222, 14, 2, 546, 8, 44, 190, 1022, 8, 3469, 405, 6, 2, 1272], [113, 17, 85, 1723, 4002, 133, 6, 1713, 1336, 6, 7934, 54, 98, 167, 170, 125, 4, 3, 19, 20, 1, 1877, 281], [113, 4, 90, 145, 411], [267, 274, 1793, 210, 107, 108, 58, 60, 1096, 22703, 7144, 22704], [267, 21, 4, 253, 3, 600, 14, 2, 408, 34, 5, 189, 49, 68, 16, 4, 237, 3129, 11, 4], [7, 1, 6381, 483], [7, 1, 65, 22705], [7, 1, 71, 63, 40, 557, 2681, 13, 7], [7, 714, 6, 4, 231, 1856, 1, 58, 92, 2, 115, 13, 418, 43, 3, 131, 94, 212, 767], [7, 236, 121, 22706, 38, 3, 41, 6, 4, 4558], [7, 9, 46, 116, 1046], [7, 9, 7, 5, 11, 64, 27, 7, 7, 9, 3, 780, 224, 27], [7, 12, 57, 3, 58, 4, 3624, 5, 49, 4, 2245, 20, 3467, 37, 33, 14, 2, 812], [7, 161, 1, 1525, 4, 8780, 1306, 846, 808, 956], [7, 24, 37, 631, 23, 79, 15, 1234], [7, 47, 17, 122, 6, 14, 22707, 59, 4, 22708, 57, 698, 16, 19, 24, 49, 5, 6, 1, 59, 2, 22709, 175, 641, 668], [7, 118, 14, 4, 1985, 11, 678, 1501, 60, 591, 472, 73, 2, 544, 91, 288, 84, 660, 8961, 228, 194, 1167], [7, 503, 102, 429, 102, 23, 27, 10, 381, 13, 6226, 4397, 1, 465, 17, 36, 14, 13, 2442, 52, 8909], [4, 16, 10, 22710, 194, 12, 37, 89, 3, 75, 110, 22711, 175, 15], [4, 8964, 2661, 1259, 159, 2193, 22712, 12, 22713, 45, 152, 14, 587, 1027, 8964, 2661, 152, 197, 34, 15, 84, 215, 22714], [4, 482, 525, 50, 628, 1663], [4, 180, 767, 47, 11, 4, 1401, 1], [4, 95, 27, 4, 4406, 16, 651], [4, 95, 54, 390], [4, 1, 22715, 1801, 21, 4, 7403, 51, 22716, 22717, 277, 48, 598, 6, 1884, 50, 164], [4, 1, 2990, 12, 89, 21, 20, 3919], [4, 4638, 236, 21, 43, 540, 18, 886, 402, 142, 49, 22718, 1386, 22719, 179, 193, 40, 1175, 22720, 8, 22721, 342, 30, 77], [4, 1377, 132, 471, 84, 3180, 6, 28, 51, 17, 22722, 24, 19, 177, 122, 22723, 75, 22724, 313, 17, 102, 10, 8366, 22725], [4, 488, 7, 4011, 177, 18, 201, 5353, 2127, 229, 125, 201, 5353, 1820], [4, 4335, 68, 2019, 37, 111, 61, 6, 1197, 27, 2768, 16, 14, 2, 9, 4356], [4, 1422, 276, 14, 3345, 51, 2, 25, 18, 4895, 115, 38, 36, 94, 71, 183, 22, 1, 47], [4, 3313, 51, 197, 12, 2085, 37, 10, 179, 30, 157, 2, 7896, 3793, 11, 4, 6851, 6, 1097, 15, 2360], [4, 306, 208, 13, 2, 1, 277, 13, 422, 174, 468, 174, 2530, 34, 29, 14, 2, 187, 6, 174, 1246], [4, 25, 18, 186, 13, 3, 119, 24, 8, 8965, 8965, 12, 4, 25, 27, 8794, 8, 45], [4, 101, 507, 3, 182, 191, 76, 6, 484, 17, 12, 6, 4, 3555, 21, 229, 8, 36, 19, 1, 59, 7], [4, 458, 6, 22726, 2660, 17, 6, 597, 35, 8, 14, 4, 832, 1, 3, 62, 3, 63, 14, 155, 115, 267, 5], [4, 2423, 109, 29, 131, 14, 56, 3699, 8576, 109, 133, 15], [4, 22727, 23, 156, 1453, 6, 81, 6, 12, 270, 2, 529, 838, 3, 79, 50, 21, 98, 4442, 8, 40, 121, 1358, 79, 307, 1369, 4273, 2766], [4, 5459, 7964, 51, 4, 448, 1294, 47, 4778, 85, 3, 47, 28, 7833, 82, 4560, 1, 23, 33, 7178, 2105], [4, 22728, 276, 22729, 1781, 11, 22, 1, 42, 8441, 6, 143, 1790], [4, 184, 3, 58, 21, 22, 1, 251], [4, 1036, 2539, 2139, 51, 12, 56, 289, 132, 6, 4, 199, 22730, 99, 36, 4712, 10, 413, 840, 6, 7092, 426, 1036, 2465], [4, 56, 2701, 136, 2, 186, 8, 22731, 387], [4, 409, 16, 1952, 6, 157, 22732, 6, 376, 919, 17, 7, 1, 132, 18, 10, 453, 32, 449], [76, 1, 49, 93, 128], [76, 22733, 14, 3374, 21, 8165, 205], [88, 78, 175, 59, 48, 302, 9, 13, 7, 45, 46, 2269, 1237, 330], [116, 46, 68, 22734, 1, 11, 4, 360, 1046, 251], [116, 47, 2, 95, 18, 4, 108, 8482, 1923, 27, 611, 3, 4704, 18, 4, 22735, 16, 164, 157, 170, 11, 2, 558, 8, 1014, 170, 11, 4, 248], [116, 1682, 111, 11, 10, 331, 8, 374, 32, 1087, 3358, 274, 134, 17, 4, 8851, 48, 6, 257, 2, 83], [116, 156, 7, 171, 186, 9, 38, 15, 107, 6, 4474, 296, 293, 2985, 257, 22736, 74, 296, 293, 154, 2253, 257, 4, 22737], [39, 1, 208, 1595, 8, 86, 22738], [39, 1, 14, 936, 106, 18, 60, 2376, 25], [39, 1, 3879, 18, 17, 3879, 18, 17], [39, 1, 12, 298, 54, 16, 843, 22739, 1240, 430, 10, 4018], [39, 1, 87, 6, 14, 79, 54, 23, 370], [39, 1, 751, 22, 323, 205, 2129], [39, 9], [39, 9, 46, 334, 163, 39, 25, 46, 519, 19, 585, 1, 28, 585, 95], [39, 9, 14, 308, 6, 263, 25], [39, 9, 133, 6, 5585, 18, 8946], [39, 9, 134, 15, 35, 92, 1898, 3, 222, 94, 36, 4251, 22740, 11, 4, 19, 5725], [39, 236, 109, 14, 1500, 18, 4552, 595, 30], [39, 1105, 276, 122, 26, 9, 2985, 31, 52, 29, 229, 54, 22, 215, 657], [39, 25, 54, 135, 2450, 113, 240, 249, 2075, 39, 1, 94, 10, 4043, 113, 240, 19, 2075], [39, 24, 30, 25, 46, 133, 7, 164], [36, 924, 15, 18, 4, 22741, 34, 708, 4, 910, 107, 54, 38, 36, 22742, 2024, 4, 9, 14, 2, 9, 5, 3224, 30, 5625], [36, 146, 506, 36, 183, 183, 1, 14, 4, 247, 861, 35, 188, 13, 8906, 57], [36, 216, 17, 157, 18, 1641, 752, 92, 3, 65, 13, 2, 1075, 391, 6075, 3551], [36, 415, 90, 17, 110, 127, 140, 48, 101, 58, 3, 65, 120, 22743, 23, 4170, 2, 22744, 34, 3, 44, 120, 343, 92, 23, 957, 353], [36, 72, 5, 61, 99, 332, 33, 763, 97, 387, 26, 23, 33, 13, 85, 1, 3, 46, 105, 297, 2724, 4084, 376], [36, 565, 246, 269, 6130], [374, 48, 137, 159, 870, 1221, 29, 298, 35, 4, 1228, 7498, 374, 137, 22, 3042], [374, 197, 18, 2, 1005, 6, 3035, 144, 82, 5207, 69, 724, 144, 222, 946, 184, 49, 192, 6, 70, 1237, 615], [86, 3, 198, 396, 22745, 22746, 6, 8061, 7, 568, 22747], [2540, 460, 7007, 18, 2575, 885, 56], [640, 30, 1, 45, 147, 432, 1671], [22, 1], [22, 1, 22748, 22749, 45, 46, 110, 405, 478], [22, 1, 12, 804, 40, 62, 99, 209], [22, 1, 12, 404, 27, 2796], [22, 1, 33, 121, 278, 249, 20, 138, 31, 15, 47, 1899, 6, 10, 534], [22, 1, 87, 6, 597, 35, 4632, 55], [22, 1, 121, 22750, 1049, 4, 264, 27, 17, 21, 2, 22751, 8745, 57, 5, 41, 17, 19, 35, 55], [22, 1, 372, 13, 40, 525, 999, 123, 22752, 1558, 22753, 637, 4, 1371, 835, 534], [22, 1, 86, 52, 279, 59, 50, 3260], [22, 836, 55], [22, 222, 14, 10, 215, 1238, 272, 114, 10, 106, 149, 272, 61, 54, 4, 199, 193, 3, 510, 11, 117, 123, 4, 24, 27, 777, 18, 10, 453], [22, 203, 1, 47, 2892, 13, 2086, 44, 99, 239, 203, 8, 1810, 4182, 44, 5, 297, 2, 2772, 369], [22, 189, 12, 11, 135, 751, 664, 3381, 163, 45], [22, 189, 12, 4, 796, 104, 2480], [22, 343, 801, 1], [22, 236, 18, 8162, 5832], [22, 12, 85, 3, 64, 942], [22, 462, 12, 415, 13, 1378, 4, 19, 277, 22, 1, 477, 3608], [22, 629, 12, 428, 93, 218, 15, 37, 144], [22, 25, 19, 2, 1, 51, 22754, 288, 17, 22755, 8, 340, 132, 304, 11, 4, 347, 21, 787, 691, 92], [22, 68, 1, 29, 150, 4, 199, 43, 127, 98, 2794, 29, 109, 204, 4, 1964, 43, 127], [22, 460, 784, 14, 102, 4, 22756, 1, 101], [22, 45, 37, 56, 55], [22, 229, 56, 1235, 4863, 22757], [22, 4, 68, 9, 29, 14, 3590, 97, 25, 36, 67, 97, 243, 1265, 52, 223, 58, 445, 76, 57, 52, 277, 21, 42, 1482, 9], [22, 183, 1, 87, 6, 28, 2, 154, 226, 205, 5, 29, 65, 13, 17, 5, 29, 44, 73, 209, 253, 73, 17, 22758, 1854, 1], [22, 85, 3, 87, 1], [212, 1107, 265, 69, 400, 51, 4, 22759, 32, 115, 27, 126, 1096, 347], [593, 9], [22760, 100, 174, 1, 22761, 35, 11, 6175], [5388, 1, 65, 33, 13, 8966, 8967, 40, 28, 142, 33, 13, 8966, 8967], [5988, 344, 56, 464], [106, 6, 192, 98, 1714, 16, 9], [6, 17, 25, 359, 18, 36, 89, 1, 426, 36, 86, 36, 63, 28, 127, 89, 1, 7, 68, 77, 103, 134, 240, 2, 180, 30, 2121], [225, 3, 192, 421, 11, 2, 154, 2035, 16, 3234, 44, 6965, 18, 10, 508], [225, 10, 228, 1460, 17, 37, 689, 4109, 40, 121, 19, 25, 25, 1, 19, 177, 25, 321], [782, 6089, 415, 19, 32, 39, 9], [99, 89, 174, 2, 24], [99, 239, 1, 48, 602, 22762], [99, 239, 1262, 91, 54, 135, 5067, 59, 4, 22763, 41, 8743, 19, 10, 312], [503, 5815, 248], [503, 3790, 9, 28, 4, 247, 48, 4, 5330], [56, 2004, 4, 4760, 3729, 420, 163, 2259, 13, 22764, 493, 125, 2, 1441, 493, 7, 363, 129, 25, 235], [56, 63, 4, 22765, 22766, 386, 4448, 22767, 742, 194, 26, 946, 135], [56, 483], [56, 398, 193, 55, 1, 204, 22768, 13, 1005, 5995, 27, 1631, 18], [56], [56, 264, 1146, 3, 63, 330, 465, 4, 372, 16, 770, 22769, 22770, 22771, 54, 18, 4, 606, 1763, 2701, 68, 16, 76, 22772], [56, 229], [843, 102, 97, 1010, 46, 827, 42, 4771, 146, 683, 4, 22773, 70, 147, 9, 303, 42], [2849, 4758, 348, 22774, 684, 853], [2849, 1357, 30, 9], [302, 17, 33, 644, 4, 3977, 6, 22775, 15, 33, 73, 93, 22776, 22777, 130, 644, 4, 8754, 6, 22778, 92, 635, 18, 3171, 95], [238, 28, 4389, 6, 79, 102, 197, 34, 52, 14, 2, 1, 55], [227, 54, 84, 22779, 79, 170, 2, 285, 52, 215, 2, 449, 8, 2, 921, 5, 63, 79, 17, 393, 33, 29, 22780, 34, 3, 195, 48, 1727, 2027], [409, 2, 1, 70, 42, 114, 50, 18, 546, 438, 88, 40, 134, 42, 143, 22781, 8, 4, 45, 7306, 2629], [42, 2, 9], [42, 2, 185, 9], [42, 63, 113, 80, 1, 66, 60, 1290, 613, 774], [42, 236, 42, 341, 3, 109, 13, 4, 193, 42, 176, 3405, 2325, 905], [42, 62, 3, 510, 6, 1985, 37, 405, 7, 24, 1], [42, 62, 42, 194, 99, 209, 315, 1202, 38, 42, 1191, 6, 177, 971, 73, 6104, 3115, 74, 6076, 887, 426, 17, 11, 10, 235, 1978], [42, 811, 52, 5472, 17, 108, 1], [42, 1415, 677, 38, 1427, 575, 74, 336, 53, 50, 24, 5767, 74, 336, 53, 2129, 53], [42, 198, 14, 135, 125, 17, 1], [42, 185, 1], [42, 7, 25, 3, 44, 43, 1179, 71, 1107, 3631, 14, 62, 10, 226, 51, 197, 1936], [42, 67, 2, 851, 740, 1], [22782], [1035, 4, 1, 226, 47, 3926], [183, 9], [793, 10, 22783, 4464, 20, 1022, 872, 2370, 81, 56, 793, 20, 1238], [174, 56], [4192, 95, 5973], [7870, 99, 239, 25, 3235, 125, 472, 35, 13, 183, 1, 21, 798, 13, 98, 22784], [963, 1, 70, 17, 1189, 76], [294, 544, 152, 14, 37, 56, 22, 658], [294, 142, 4, 1961, 8, 22, 77, 27, 2, 189, 722, 17, 8, 4, 77, 72, 23, 133, 6, 227, 391, 21, 50, 3441, 1621], [3997, 3, 19, 90, 22, 172, 953, 1, 37, 1572], [131, 70, 2, 900, 243, 1, 81, 3365], [67, 6, 430, 10, 701, 145, 313, 35, 2, 2969, 821], [47, 33, 3256, 7, 22785, 46, 544, 2402, 55, 550, 362], [194, 54, 21, 39, 2446, 9, 8, 4774, 25], [66, 32, 363, 539, 37, 209, 45, 612, 26, 3, 346, 76, 1], [66, 384, 942], [66, 29, 389, 1928, 66, 29, 492, 9], [66, 11, 135, 227, 35, 227, 35, 162, 4, 1], [66, 259, 11, 2, 360, 162, 898, 63, 719, 20, 9, 8, 70, 501, 16, 5, 45, 284], [66, 87, 6, 3707, 60, 9, 11, 4, 108, 16, 2363, 347], [22786, 28, 235, 82, 9, 125, 22787], [255, 7260, 390, 445, 143, 1479, 22788, 4389, 115], [2593, 70, 323, 21, 4, 9], [219, 46, 7, 2, 1], [219, 3, 67, 6, 14, 3499, 1564, 391, 1647], [220, 1679, 1448, 305, 2109, 5465, 22789, 647], [57, 2, 291, 145, 223, 113, 876], [57, 2, 949, 1898], [57, 2, 9], [57, 2, 141, 1, 55], [57, 2, 144, 55], [57, 52, 47, 1113, 654, 6, 4, 2793, 22790, 12, 6, 14, 22791, 77, 471, 54, 147, 24, 6, 10, 6036], [57, 6, 58, 38, 20, 1340, 505, 13, 2, 1], [57, 329, 27, 1, 19, 25], [38, 240, 121, 584, 18, 10, 344, 8509, 37, 85, 118, 3, 303, 5, 2, 315, 30, 2799, 1538, 1, 20, 330, 22792], [38, 2, 1, 72, 5, 75, 856], [38, 585, 613, 25, 67, 174, 1, 15, 295, 42, 63, 4771, 34, 293, 40, 86, 59, 42, 18, 384, 1495, 22793], [38, 22794, 404, 23, 81, 37, 209, 56], [38, 1, 14, 238, 1089, 126, 45, 18, 4, 702, 55, 356, 483], [38, 1, 396, 8, 192, 208, 13, 4, 25, 36, 27, 22795], [38, 1, 42, 90, 266, 139, 1442, 51, 42, 11, 4, 3713], [38, 23, 116, 27, 2, 179, 30, 3369, 14, 933, 73, 286, 13], [38, 3475, 121, 22796, 7, 1, 151, 303, 2, 154, 2918, 22797], [38, 4, 252, 512, 84, 22798, 11, 4, 1, 387, 11, 2259, 16, 4, 22799], [38, 97, 226, 2759, 1414, 97, 500, 1, 75, 100, 61], [38, 97, 226, 2759, 1414, 97, 500, 9, 75, 100, 61], [38, 80, 323, 107, 18, 8, 5, 167, 4, 866, 332, 483, 149, 7, 9, 61, 147, 332], [38, 5, 250, 294, 11, 4, 676, 51, 7, 460, 5, 486, 2, 180, 517, 9, 226], [38, 20, 185, 5, 29, 62, 254, 164, 12, 37, 2495, 44, 5, 182, 297, 2, 2214, 144, 3, 8575, 760], [162, 143, 590, 9, 51], [162, 10, 2149, 9, 51], [162, 523, 4, 501, 1883, 51, 23, 122, 6, 735, 8900, 3553, 8, 22800, 102, 20, 628], [22801, 1, 5, 308], [678, 68, 16, 39, 226, 12, 127, 1248, 2954, 1466, 22802, 2264, 5449, 22803, 1479, 74, 22804], [678, 186, 1, 427, 506, 22805], [69, 22806, 13, 2, 348, 445, 22807, 87, 22808], [69, 24, 165, 88, 2, 284, 1], [85, 49, 111, 208, 13, 36, 210, 62, 9, 3771, 47, 61, 6, 4, 3599, 688, 707, 892], [85, 49, 39, 1554, 37, 179, 128], [85, 1, 146, 14, 1], [85, 75, 77, 33, 1124, 7, 36, 67, 4, 138, 73, 209, 73, 263, 189, 67, 4, 24, 1044, 905, 3878], [85, 200, 4, 5195, 821, 22809, 52, 2, 22810, 1], [85, 58, 9, 86, 15, 2, 93, 1179, 6, 1211, 54, 126, 537, 3894, 51, 2, 775, 507, 1, 23, 238, 934, 10, 4849], [85, 58, 141, 5280, 120, 177, 137, 179, 742, 451, 288, 36, 294, 3141], [85, 110, 28, 554, 123, 217, 7, 427, 98, 105, 103, 14, 1023, 6, 14, 2, 586, 251, 185, 185, 9], [85, 12, 22, 640, 120, 339, 30, 1, 96, 81, 6, 17, 2499], [85, 308, 205, 66, 276, 258, 5, 1], [85, 25, 157, 548, 387, 793, 326, 406, 88, 15, 14, 76, 4641, 819, 819, 319], [85, 198, 116, 14, 98, 1247, 2148, 18, 629, 15, 46, 126, 1791, 31, 2, 22811, 206, 12, 8116, 82, 98, 523, 877, 2348, 666, 16, 24], [85, 364, 12, 22, 1, 11, 10, 521, 255, 32, 22812, 45, 15, 1231, 658], [85, 4, 19, 200, 186, 420, 4, 154, 175, 874, 6, 2037, 4, 1090, 55, 15, 65, 19, 144], [85, 36, 137, 56, 18, 2798, 117, 615], [85, 5, 208, 13, 2, 141, 22813, 1, 92, 7, 85, 5, 29, 44, 228, 9], [85, 5, 86, 802, 25, 125, 43, 169, 29, 110, 279, 59, 1008, 2351, 3921, 125, 22814, 1882, 36, 46, 5879, 21, 1], [85, 22, 1, 255, 2, 8233, 22815, 8, 1783, 2135], [103, 42, 64, 147, 25, 110, 31, 52, 468, 15, 22816, 74, 103, 42, 1598, 13, 4, 3093, 9, 1785, 21, 246], [103, 42, 506, 147, 24, 21, 17], [301, 3, 124, 2, 348, 74, 2, 7647, 6, 762, 17, 54, 1315], [301, 3, 222, 314, 2043, 1703, 226, 2, 2475, 16, 95, 22817, 8844], [27, 5840, 22818, 468, 215, 264, 2, 404, 6, 22819, 390, 198, 44, 76, 108, 11, 4, 503, 473], [287, 90, 9, 6829, 36, 172, 35, 4, 7777], [454, 31, 36, 276, 44, 240, 21, 4, 702, 18, 158, 22820], [22821, 12, 4, 237, 4643, 2217, 1269, 3, 33, 41, 2, 822, 2783, 1688, 22822, 21, 2, 822, 445, 2589, 1890, 56, 4643], [884, 184, 2, 1, 63, 58, 1, 455, 540, 21, 14, 11, 246, 25, 231, 12, 6, 28, 36, 25, 1176, 26, 963, 26], [452, 14, 270, 2, 1, 31, 111, 210, 633, 17, 102, 1978], [583, 23, 2, 1, 417, 6, 19, 1507], [583, 23, 152, 366, 531, 144, 38, 3, 28, 337], [583, 60, 1, 33, 655, 6, 28, 22823, 11, 4, 4524], [22824, 2, 95, 33, 45, 18, 17], [3537, 12, 7, 137, 22825, 8467, 3, 196, 944, 22, 629, 223, 14, 56], [4183, 1594, 17, 110, 127, 12, 15, 276, 14, 991, 38, 25, 484, 459, 22826, 23, 549, 330], [22827, 203, 1, 27, 1975, 1366, 645, 14, 65, 13, 347, 22828], [693, 134, 2, 1, 98, 1435, 38, 40, 516, 44, 1079], [78, 23, 37, 214, 3, 936, 76, 5972, 18, 7, 2443, 22829, 7, 236, 47, 1015, 73, 286], [78, 9, 2438, 3869], [78, 306, 47, 9, 27, 43, 2366, 37, 3, 46, 1003], [78, 375, 7, 1888, 30, 391, 226, 1615, 1614], [97, 1, 46, 89, 25, 5, 46, 41, 43, 578], [97, 77, 24, 12, 56, 73, 1066], [78, 158, 44, 2, 93, 2908], [2346, 60, 104, 2573, 25, 5, 163, 5, 172, 2463, 22830], [78, 284, 9, 87, 847, 55], [78, 24, 3, 22831], [2939, 3, 13, 38, 3278, 136, 207, 22832], [22833, 22834, 342, 830, 205, 3, 124, 43, 1179, 40, 47, 376], [447, 37, 59, 725, 154, 5509, 32, 10, 228, 636, 374, 101, 1166, 68, 342, 3422, 228, 163, 7, 17, 55], [221, 23, 2, 1, 34, 380, 57, 20, 96, 2, 2639], [221, 23, 969, 913, 2, 9], [221, 3, 41, 931, 3, 47, 1051, 35, 123, 207, 2282], [221, 39, 6928, 104, 63, 61, 19, 943], [367, 93, 1471, 22835, 22836], [478, 22, 25, 96, 5879, 35, 18, 84, 206, 4620], [80, 1, 1, 223, 100, 17, 19, 390, 22837, 1903, 51, 4, 8947, 5400], [80, 1, 65, 13, 2, 22838], [80, 1, 67, 7, 4750, 717, 40, 541, 1773], [80, 1, 6112, 11, 4, 570, 561], [80, 9, 103, 28, 1300, 26], [80, 9, 103, 28, 1300], [5, 2, 9, 25, 1896], [5, 2, 24, 30, 25, 8, 3, 62, 15, 916], [5, 46, 2, 112, 25, 461, 1487, 2, 6, 778, 8, 2, 190, 1006, 1, 545, 60, 1109, 6, 1622], [5, 46, 146, 14, 2, 391, 6, 13, 9], [5, 49, 2, 9, 9, 26, 2, 282], [5, 1, 64, 78, 60, 1490, 25], [5, 63, 3832, 3241, 1, 55, 3, 33, 67, 60, 148, 771, 817, 22839, 55], [5, 63, 105, 28, 2, 1143, 16, 9, 612, 5269, 240, 3923, 6, 14, 3179], [5, 63, 113, 38, 138, 1815, 132, 11, 2, 24, 578, 530, 483, 2584, 1, 165, 105, 137, 7, 45], [5, 75, 2359, 2, 9, 128], [5, 3087, 17, 388, 284], [5, 365, 145, 4370], [5, 41, 25, 8, 3, 41, 283], [5, 146, 14, 2, 154, 1871, 16, 144, 31, 5, 58, 760], [5, 146, 594, 7, 39, 1, 49, 1133], [5, 9, 3550], [5, 33, 67, 60, 701, 9], [5, 62, 57, 36, 72, 4, 570, 95, 28, 4, 5682, 5102, 5120, 1329, 11, 20, 561, 22840], [5, 62, 57, 20, 58, 38, 5, 443, 2, 175, 238, 359, 30, 1, 281], [5, 161, 171, 30, 1, 3, 46, 172, 125, 22841, 3, 41, 2, 937, 8887, 184, 278, 516, 172, 4497, 130, 6, 14, 172, 8942], [5, 65, 13, 5519, 22842, 29, 79, 135, 6747], [5, 65, 13, 20, 1296, 139, 81, 59, 19, 1], [5, 318, 73, 219, 223, 24, 429, 18, 2, 1706], [5, 158, 359, 18, 97, 1661, 22843], [5, 109, 279, 133, 325, 83, 10, 138, 32, 11, 80, 150], [5, 475, 133, 166, 1, 5, 87, 17, 21], [20, 32, 158], [20, 270, 2, 144, 3, 293, 5, 28, 409, 201, 4527, 8, 309, 82, 2, 2196, 22844, 5, 19, 104], [5, 2, 22845, 308, 117, 84, 909, 12, 56, 26, 92, 588, 3534, 6588, 8, 22846], [814, 223, 8, 291, 4, 329, 548, 260, 8, 3087, 17, 388, 284], [379, 1889, 131, 22847, 147, 399, 13, 3, 46, 172, 325, 35, 361], [4556, 41, 1060, 1, 1806, 5, 308], [22848, 335, 22849, 22850, 22851, 160, 681, 207, 4506, 16, 1106, 1685, 190, 26, 4428, 2, 22852]]\n","[[   73     2   414 ...     0     0     0]\n"," [  177   147  8968 ...     0     0     0]\n"," [  797     5   182 ...     0     0     0]\n"," ...\n"," [  379  1889   131 ...     0     0     0]\n"," [ 4556    41  1060 ...     0     0     0]\n"," [22848   335 22849 ...     0     0     0]]\n"]},{"output_type":"execute_result","data":{"text/plain":["24783"]},"metadata":{},"execution_count":45}],"source":["# integer encode the documents\n","#encoded_docs = t.texts_to_sequences(stripped_hashtags_preprocessed_tweets)\n","encoded_docs = t.texts_to_sequences(stemmed_stripped_hashtags_preprocessed_tweets)\n","print(encoded_docs)\n","# pad documents to a max length of 100 words\n","max_length = 100\n","padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n","print(padded_docs)\n","len(padded_docs)"]},{"cell_type":"markdown","metadata":{"id":"rtWhKS6_09Zq"},"source":["# **Running the model**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"59lyj2Cf09Zr"},"outputs":[],"source":["y = df['class']"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"KWAyNbBc09Zr"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.utils import class_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCzgN82m8T7e"},"outputs":[],"source":["inputs = padded_docs\n","targets = y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1678003236268,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"7O7R20va8kT6","outputId":"038366d0-48aa-4b69-c9e2-074343a8553b"},"outputs":[{"output_type":"stream","name":"stdout","text":["24783\n","24783\n"]}],"source":["print(len(inputs))\n","print(len(targets))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1678003236269,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"Aj_327D6807e","outputId":"6317cedf-0750-4984-ba68-0e7eaacce018"},"outputs":[{"output_type":"stream","name":"stdout","text":["(24783, 100)\n","(24783,)\n"]}],"source":["print(inputs.shape)\n","print(targets.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1678003236269,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"W6oqjvgE9Tw8","outputId":"34f39b2c-5c69-4218-9512-6ae9e9ca4b4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[   73     2   414 ...     0     0     0]\n"," [  177   147  8968 ...     0     0     0]\n"," [  797     5   182 ...     0     0     0]\n"," ...\n"," [  379  1889   131 ...     0     0     0]\n"," [ 4556    41  1060 ...     0     0     0]\n"," [22848   335 22849 ...     0     0     0]]\n"]}],"source":["print(inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1678003236269,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"CTvgNavL9itJ","outputId":"c7b3006a-2a02-4ffe-af70-d3d7baf3a852"},"outputs":[{"output_type":"stream","name":"stdout","text":["0        2\n","1        1\n","2        1\n","3        1\n","4        1\n","        ..\n","24778    1\n","24779    2\n","24780    1\n","24781    1\n","24782    2\n","Name: class, Length: 24783, dtype: int64\n"]}],"source":["print(targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1678003236270,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"},"user_tz":-120},"id":"OyXlnU089yXZ","outputId":"990a81d6-2f4f-44a3-95c4-06a4aea4efd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," ...\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n","(24783, 3)\n"]}],"source":["targets = tf.keras.utils.to_categorical(targets, num_classes = 3)\n","print(targets)\n","print(targets.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eVJQPsh7pJ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678003236270,"user_tz":-120,"elapsed":19,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"}},"outputId":"4562a04a-1060-4fed-b83d-f63d36d5a577"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-54-bb9078332801>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  X_train_shares = np.array(np.array_split(inputs, clients_number))\n","<ipython-input-54-bb9078332801>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  Y_train_shares = np.array(np.array_split(targets, clients_number))\n"]}],"source":["# Divide X_train & Y_train into subset of arrays each have (21000/no.of_clients) element\n","X_train_shares = np.array(np.array_split(inputs, clients_number))\n","Y_train_shares = np.array(np.array_split(targets, clients_number))\n","#Y_test = y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5WxBZuNJ4GPQ"},"outputs":[],"source":["X_t, X_test, y_t, Y_test = train_test_split(inputs, targets, random_state=42, test_size=0.1)"]},{"cell_type":"markdown","metadata":{"id":"HqnrQG7cHhSF"},"source":["# **Start Running the Federated Learning Process**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mevu1Aw8zccu","outputId":"db91cdc5-72a9-4576-e770-f04cfe964ed3","executionInfo":{"status":"ok","timestamp":1678011387443,"user_tz":-120,"elapsed":1411337,"user":{"displayName":"tharwat elsayed","userId":"18312503812804922309"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["> 10 ROUNDS 7 CLIENTS STARTED..........\n","\n","##############################################################################################################\n","\n","> round 1 start, random seed= 1\n","\n","> client 1 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 18s 32ms/step - loss: 0.6328 - accuracy: 0.8388 - tp: 2218.0000 - fp: 573.0000 - tn: 5799.0000 - fn: 968.0000 - precision: 0.7947 - recall: 0.6962 - auc: 0.8949 - prc: 0.8277\n","Epoch 2/10\n","32/32 [==============================] - 1s 22ms/step - loss: 0.3947 - accuracy: 0.9021 - tp: 2599.0000 - fp: 349.0000 - tn: 6023.0000 - fn: 587.0000 - precision: 0.8816 - recall: 0.8158 - auc: 0.9590 - prc: 0.9279\n","Epoch 3/10\n","32/32 [==============================] - 1s 22ms/step - loss: 0.2233 - accuracy: 0.9518 - tp: 2890.0000 - fp: 165.0000 - tn: 6207.0000 - fn: 296.0000 - precision: 0.9460 - recall: 0.9071 - auc: 0.9862 - prc: 0.9749\n","Epoch 4/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.1063 - accuracy: 0.9767 - tp: 3050.0000 - fp: 87.0000 - tn: 6285.0000 - fn: 136.0000 - precision: 0.9723 - recall: 0.9573 - auc: 0.9969 - prc: 0.9941\n","Epoch 5/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0684 - accuracy: 0.9831 - tp: 3080.0000 - fp: 56.0000 - tn: 6316.0000 - fn: 106.0000 - precision: 0.9821 - recall: 0.9667 - auc: 0.9986 - prc: 0.9974\n","Epoch 6/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0379 - accuracy: 0.9912 - tp: 3119.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 67.0000 - precision: 0.9946 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994\n","Epoch 7/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0323 - accuracy: 0.9918 - tp: 3137.0000 - fp: 29.0000 - tn: 6343.0000 - fn: 49.0000 - precision: 0.9908 - recall: 0.9846 - auc: 0.9998 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0562 - accuracy: 0.9866 - tp: 3113.0000 - fp: 55.0000 - tn: 6317.0000 - fn: 73.0000 - precision: 0.9826 - recall: 0.9771 - auc: 0.9987 - prc: 0.9974\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0691 - accuracy: 0.9848 - tp: 3096.0000 - fp: 55.0000 - tn: 6317.0000 - fn: 90.0000 - precision: 0.9825 - recall: 0.9718 - auc: 0.9982 - prc: 0.9965\n","Epoch 10/10\n","32/32 [==============================] - 1s 38ms/step - loss: 0.0379 - accuracy: 0.9915 - tp: 3132.0000 - fp: 27.0000 - tn: 6345.0000 - fn: 54.0000 - precision: 0.9915 - recall: 0.9831 - auc: 0.9997 - prc: 0.9993\n","Score for fold 1: loss of 0.6919164657592773; accuracy of 83.47417712211609%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.1149 - accuracy: 0.9795 - tp: 3075.0000 - fp: 84.0000 - tn: 6290.0000 - fn: 112.0000 - precision: 0.9734 - recall: 0.9649 - auc: 0.9944 - prc: 0.9911\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0360 - accuracy: 0.9935 - tp: 3147.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 40.0000 - precision: 0.9931 - recall: 0.9874 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0152 - accuracy: 0.9968 - tp: 3167.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 20.0000 - precision: 0.9965 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0128 - accuracy: 0.9975 - tp: 3170.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 17.0000 - precision: 0.9978 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0174 - accuracy: 0.9955 - tp: 3162.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 25.0000 - precision: 0.9943 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0140 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 22ms/step - loss: 0.0096 - accuracy: 0.9978 - tp: 3171.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 16.0000 - precision: 0.9984 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0063 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0055 - accuracy: 0.9983 - tp: 3176.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9984 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0051 - accuracy: 0.9984 - tp: 3178.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 9.0000 - precision: 0.9981 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.0903715267777443; accuracy of 97.64595031738281%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0155 - accuracy: 0.9959 - tp: 3164.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 23.0000 - precision: 0.9950 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0267 - accuracy: 0.9933 - tp: 3147.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 40.0000 - precision: 0.9924 - recall: 0.9874 - auc: 0.9998 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0349 - accuracy: 0.9916 - tp: 3139.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 48.0000 - precision: 0.9899 - recall: 0.9849 - auc: 0.9994 - prc: 0.9989\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0113 - accuracy: 0.9976 - tp: 3171.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 16.0000 - precision: 0.9978 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9978 - tp: 3175.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 12.0000 - precision: 0.9972 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0069 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0063 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0060 - accuracy: 0.9984 - tp: 3174.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 13.0000 - precision: 0.9994 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0064 - accuracy: 0.9979 - tp: 3173.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 14.0000 - precision: 0.9981 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 22ms/step - loss: 0.0059 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.009189650416374207; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0055 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0046 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0046 - accuracy: 0.9988 - tp: 3180.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 7.0000 - precision: 0.9987 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3179.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 8.0000 - precision: 0.9987 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0052 - accuracy: 0.9986 - tp: 3178.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 9.0000 - precision: 0.9987 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0041 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.013229086063802242; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0056 - accuracy: 0.9980 - tp: 3173.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 14.0000 - precision: 0.9984 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0050 - accuracy: 0.9984 - tp: 3174.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 13.0000 - precision: 0.9994 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0049 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0048 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0052 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0048 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.00031436755671165884; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.011146992444992065; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0057 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0052 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0046 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0047 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 6.54270697850734e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0033 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0034 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0032 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.012828911654651165; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0041 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0042 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.0016178077785298228; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0045 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0044 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 1.2828561921196524e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.6919164657592773 - Accuracy: 83.47417712211609%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0903715267777443 - Accuracy: 97.64595031738281%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.009189650416374207 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.013229086063802242 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.00031436755671165884 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.011146992444992065 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 6.54270697850734e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.012828911654651165 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.0016178077785298228 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 1.2828561921196524e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 97.9801857471466 (+- 4.881689595112501)\n","> Loss: 0.08306930640837891\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 4ms/step\n","78/78 [==============================] - 0s 4ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3528.0000 - fp: 1.0000 - tn: 7081.0000 - fn: 13.0000 - precision: 0.9997 - recall: 0.9963 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 1.1331 - accuracy: 0.9045 - tp: 2120.0000 - fp: 351.0000 - tn: 4607.0000 - fn: 359.0000 - precision: 0.8580 - recall: 0.8552 - auc: 0.9175 - prc: 0.8506\n","\n",">round 1  client 1 evaluation training metrics:\n","[0.0038384641520678997, 0.9986820816993713, 3528.0, 1.0, 7081.0, 13.0, 0.9997166395187378, 0.9963287115097046, 0.9999945163726807, 0.9999890923500061]\n","\n",">round 1  client 1 evaluation metrics:\n","[1.1331393718719482, 0.9045314192771912, 2120.0, 351.0, 4607.0, 359.0, 0.8579522371292114, 0.8551835417747498, 0.9175184369087219, 0.8505518436431885]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 27ms/step - loss: 0.7354 - accuracy: 0.8452 - tp: 4039.0000 - fp: 1005.0000 - tn: 10325.0000 - fn: 1626.0000 - precision: 0.8008 - recall: 0.7130 - auc: 0.8892 - prc: 0.8072\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.5224 - accuracy: 0.8598 - tp: 2279.0000 - fp: 433.0000 - tn: 5939.0000 - fn: 907.0000 - precision: 0.8403 - recall: 0.7153 - auc: 0.9280 - prc: 0.8788\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.3453 - accuracy: 0.9119 - tp: 2636.0000 - fp: 292.0000 - tn: 6080.0000 - fn: 550.0000 - precision: 0.9003 - recall: 0.8274 - auc: 0.9679 - prc: 0.9421\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.2065 - accuracy: 0.9497 - tp: 2877.0000 - fp: 172.0000 - tn: 6200.0000 - fn: 309.0000 - precision: 0.9436 - recall: 0.9030 - auc: 0.9884 - prc: 0.9786\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1269 - accuracy: 0.9704 - tp: 3024.0000 - fp: 121.0000 - tn: 6251.0000 - fn: 162.0000 - precision: 0.9615 - recall: 0.9492 - auc: 0.9963 - prc: 0.9930\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0921 - accuracy: 0.9777 - tp: 3069.0000 - fp: 96.0000 - tn: 6276.0000 - fn: 117.0000 - precision: 0.9697 - recall: 0.9633 - auc: 0.9976 - prc: 0.9954\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1259 - accuracy: 0.9663 - tp: 3003.0000 - fp: 139.0000 - tn: 6233.0000 - fn: 183.0000 - precision: 0.9558 - recall: 0.9426 - auc: 0.9954 - prc: 0.9918\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0774 - accuracy: 0.9814 - tp: 3086.0000 - fp: 78.0000 - tn: 6294.0000 - fn: 100.0000 - precision: 0.9753 - recall: 0.9686 - auc: 0.9985 - prc: 0.9972\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0502 - accuracy: 0.9889 - tp: 3125.0000 - fp: 45.0000 - tn: 6327.0000 - fn: 61.0000 - precision: 0.9858 - recall: 0.9809 - auc: 0.9995 - prc: 0.9991\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0295 - accuracy: 0.9925 - tp: 3146.0000 - fp: 32.0000 - tn: 6340.0000 - fn: 40.0000 - precision: 0.9899 - recall: 0.9874 - auc: 0.9998 - prc: 0.9996\n","Score for fold 1: loss of 1.3588144779205322; accuracy of 58.028167486190796%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.1536 - accuracy: 0.9677 - tp: 3021.0000 - fp: 143.0000 - tn: 6231.0000 - fn: 166.0000 - precision: 0.9548 - recall: 0.9479 - auc: 0.9913 - prc: 0.9839\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0617 - accuracy: 0.9862 - tp: 3112.0000 - fp: 57.0000 - tn: 6317.0000 - fn: 75.0000 - precision: 0.9820 - recall: 0.9765 - auc: 0.9981 - prc: 0.9961\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0321 - accuracy: 0.9923 - tp: 3147.0000 - fp: 34.0000 - tn: 6340.0000 - fn: 40.0000 - precision: 0.9893 - recall: 0.9874 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0316 - accuracy: 0.9917 - tp: 3146.0000 - fp: 38.0000 - tn: 6336.0000 - fn: 41.0000 - precision: 0.9881 - recall: 0.9871 - auc: 0.9997 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0240 - accuracy: 0.9939 - tp: 3158.0000 - fp: 29.0000 - tn: 6345.0000 - fn: 29.0000 - precision: 0.9909 - recall: 0.9909 - auc: 0.9999 - prc: 0.9997\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0208 - accuracy: 0.9936 - tp: 3156.0000 - fp: 30.0000 - tn: 6344.0000 - fn: 31.0000 - precision: 0.9906 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0186 - accuracy: 0.9948 - tp: 3161.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 26.0000 - precision: 0.9925 - recall: 0.9918 - auc: 0.9999 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0176 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 0.9999 - prc: 0.9998\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0168 - accuracy: 0.9944 - tp: 3160.0000 - fp: 27.0000 - tn: 6347.0000 - fn: 27.0000 - precision: 0.9915 - recall: 0.9915 - auc: 0.9999 - prc: 0.9998\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0172 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9999 - prc: 0.9998\n","Score for fold 2: loss of 0.048538826406002045; accuracy of 97.92843461036682%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0152 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0175 - accuracy: 0.9945 - tp: 3160.0000 - fp: 26.0000 - tn: 6348.0000 - fn: 27.0000 - precision: 0.9918 - recall: 0.9915 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0303 - accuracy: 0.9926 - tp: 3151.0000 - fp: 35.0000 - tn: 6339.0000 - fn: 36.0000 - precision: 0.9890 - recall: 0.9887 - auc: 0.9995 - prc: 0.9990\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0328 - accuracy: 0.9904 - tp: 3141.0000 - fp: 46.0000 - tn: 6328.0000 - fn: 46.0000 - precision: 0.9856 - recall: 0.9856 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0256 - accuracy: 0.9932 - tp: 3154.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 33.0000 - precision: 0.9900 - recall: 0.9896 - auc: 0.9998 - prc: 0.9997\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0237 - accuracy: 0.9932 - tp: 3153.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 34.0000 - precision: 0.9903 - recall: 0.9893 - auc: 0.9998 - prc: 0.9997\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0209 - accuracy: 0.9937 - tp: 3157.0000 - fp: 30.0000 - tn: 6344.0000 - fn: 30.0000 - precision: 0.9906 - recall: 0.9906 - auc: 0.9999 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0304 - accuracy: 0.9910 - tp: 3144.0000 - fp: 43.0000 - tn: 6331.0000 - fn: 43.0000 - precision: 0.9865 - recall: 0.9865 - auc: 0.9997 - prc: 0.9995\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0211 - accuracy: 0.9934 - tp: 3155.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 32.0000 - precision: 0.9903 - recall: 0.9900 - auc: 0.9999 - prc: 0.9998\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0148 - accuracy: 0.9953 - tp: 3162.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 25.0000 - precision: 0.9937 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Score for fold 3: loss of 0.07022632658481598; accuracy of 97.74011373519897%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0725 - accuracy: 0.9830 - tp: 3099.0000 - fp: 75.0000 - tn: 6299.0000 - fn: 88.0000 - precision: 0.9764 - recall: 0.9724 - auc: 0.9980 - prc: 0.9962\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0525 - accuracy: 0.9868 - tp: 3122.0000 - fp: 61.0000 - tn: 6313.0000 - fn: 65.0000 - precision: 0.9808 - recall: 0.9796 - auc: 0.9988 - prc: 0.9976\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0336 - accuracy: 0.9917 - tp: 3147.0000 - fp: 39.0000 - tn: 6335.0000 - fn: 40.0000 - precision: 0.9878 - recall: 0.9874 - auc: 0.9995 - prc: 0.9993\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0217 - accuracy: 0.9938 - tp: 3156.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 31.0000 - precision: 0.9912 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0322 - accuracy: 0.9905 - tp: 3140.0000 - fp: 44.0000 - tn: 6330.0000 - fn: 47.0000 - precision: 0.9862 - recall: 0.9853 - auc: 0.9996 - prc: 0.9993\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0171 - accuracy: 0.9944 - tp: 3159.0000 - fp: 26.0000 - tn: 6348.0000 - fn: 28.0000 - precision: 0.9918 - recall: 0.9912 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0127 - accuracy: 0.9958 - tp: 3164.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 23.0000 - precision: 0.9947 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0106 - accuracy: 0.9960 - tp: 3165.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 22.0000 - precision: 0.9950 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0182 - accuracy: 0.9942 - tp: 3158.0000 - fp: 26.0000 - tn: 6348.0000 - fn: 29.0000 - precision: 0.9918 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9960 - tp: 3165.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 22.0000 - precision: 0.9950 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.09515385329723358; accuracy of 98.11676144599915%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0196 - accuracy: 0.9933 - tp: 3153.0000 - fp: 30.0000 - tn: 6344.0000 - fn: 34.0000 - precision: 0.9906 - recall: 0.9893 - auc: 0.9996 - prc: 0.9993\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0173 - accuracy: 0.9934 - tp: 3150.0000 - fp: 26.0000 - tn: 6348.0000 - fn: 37.0000 - precision: 0.9918 - recall: 0.9884 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0124 - accuracy: 0.9956 - tp: 3164.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 23.0000 - precision: 0.9940 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0135 - accuracy: 0.9954 - tp: 3163.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 24.0000 - precision: 0.9937 - recall: 0.9925 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0162 - accuracy: 0.9953 - tp: 3160.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 27.0000 - precision: 0.9943 - recall: 0.9915 - auc: 0.9995 - prc: 0.9993\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0144 - accuracy: 0.9942 - tp: 3157.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 30.0000 - precision: 0.9921 - recall: 0.9906 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0111 - accuracy: 0.9961 - tp: 3166.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 21.0000 - precision: 0.9950 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0102 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0103 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0098 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 5: loss of 0.008527347818017006; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0095 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0087 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0084 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0081 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0081 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0079 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0076 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0084 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.01932106912136078; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0088 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0110 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0097 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9970 - tp: 3172.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0076 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0077 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0077 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.023601816967129707; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0083 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9957 - tp: 3166.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9949 - tp: 3162.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 25.0000 - precision: 0.9925 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0080 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.01788579672574997; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9958 - tp: 3165.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 22.0000 - precision: 0.9943 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0125 - accuracy: 0.9952 - tp: 3163.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 24.0000 - precision: 0.9931 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0699 - accuracy: 0.9837 - tp: 3108.0000 - fp: 77.0000 - tn: 6297.0000 - fn: 79.0000 - precision: 0.9758 - recall: 0.9752 - auc: 0.9978 - prc: 0.9959\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0626 - accuracy: 0.9831 - tp: 3102.0000 - fp: 77.0000 - tn: 6297.0000 - fn: 85.0000 - precision: 0.9758 - recall: 0.9733 - auc: 0.9989 - prc: 0.9979\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0337 - accuracy: 0.9904 - tp: 3131.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 56.0000 - precision: 0.9886 - recall: 0.9824 - auc: 0.9997 - prc: 0.9994\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0174 - accuracy: 0.9946 - tp: 3156.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 31.0000 - precision: 0.9934 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0136 - accuracy: 0.9952 - tp: 3161.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 26.0000 - precision: 0.9937 - recall: 0.9918 - auc: 0.9999 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0170 - accuracy: 0.9940 - tp: 3157.0000 - fp: 27.0000 - tn: 6347.0000 - fn: 30.0000 - precision: 0.9915 - recall: 0.9906 - auc: 0.9997 - prc: 0.9994\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0155 - accuracy: 0.9950 - tp: 3162.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 25.0000 - precision: 0.9928 - recall: 0.9922 - auc: 0.9997 - prc: 0.9994\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0106 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Score for fold 9: loss of 0.018652742728590965; accuracy of 99.52918887138367%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0127 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0132 - accuracy: 0.9957 - tp: 3165.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 22.0000 - precision: 0.9940 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9968 - tp: 3170.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 17.0000 - precision: 0.9956 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 10: loss of 0.015090848319232464; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 1.3588144779205322 - Accuracy: 58.028167486190796%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.048538826406002045 - Accuracy: 97.92843461036682%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.07022632658481598 - Accuracy: 97.74011373519897%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.09515385329723358 - Accuracy: 98.11676144599915%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.008527347818017006 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.01932106912136078 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.023601816967129707 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.01788579672574997 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.018652742728590965 - Accuracy: 99.52918887138367%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.015090848319232464 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 94.87061262130737 (+- 12.302311148253596)\n","> Loss: 0.16758131058886647\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 4ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0084 - accuracy: 0.9964 - tp: 3522.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 19.0000 - precision: 0.9946 - recall: 0.9946 - auc: 1.0000 - prc: 0.9999\n","78/78 [==============================] - 1s 8ms/step - loss: 0.9091 - accuracy: 0.9184 - tp: 2175.0000 - fp: 303.0000 - tn: 4655.0000 - fn: 304.0000 - precision: 0.8777 - recall: 0.8774 - auc: 0.9369 - prc: 0.8836\n","\n",">round 1  client 2 evaluation training metrics:\n","[0.008446955122053623, 0.9964228272438049, 3522.0, 19.0, 7063.0, 19.0, 0.9946342706680298, 0.9946342706680298, 0.999970555305481, 0.9999414086341858]\n","\n",">round 1  client 2 evaluation metrics:\n","[0.9090688824653625, 0.9183810949325562, 2175.0, 303.0, 4655.0, 304.0, 0.8777239918708801, 0.8773698806762695, 0.9369145035743713, 0.8835725784301758]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 30ms/step - loss: 0.6599 - accuracy: 0.8650 - tp: 4225.0000 - fp: 855.0000 - tn: 10475.0000 - fn: 1440.0000 - precision: 0.8317 - recall: 0.7458 - auc: 0.9123 - prc: 0.8454\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.4271 - accuracy: 0.8974 - tp: 2600.0000 - fp: 395.0000 - tn: 5977.0000 - fn: 586.0000 - precision: 0.8681 - recall: 0.8161 - auc: 0.9506 - prc: 0.9126\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2956 - accuracy: 0.9363 - tp: 2803.0000 - fp: 226.0000 - tn: 6146.0000 - fn: 383.0000 - precision: 0.9254 - recall: 0.8798 - auc: 0.9759 - prc: 0.9542\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1694 - accuracy: 0.9634 - tp: 2977.0000 - fp: 141.0000 - tn: 6231.0000 - fn: 209.0000 - precision: 0.9548 - recall: 0.9344 - auc: 0.9906 - prc: 0.9823\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0857 - accuracy: 0.9839 - tp: 3089.0000 - fp: 57.0000 - tn: 6315.0000 - fn: 97.0000 - precision: 0.9819 - recall: 0.9696 - auc: 0.9971 - prc: 0.9945\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0635 - accuracy: 0.9862 - tp: 3110.0000 - fp: 56.0000 - tn: 6316.0000 - fn: 76.0000 - precision: 0.9823 - recall: 0.9761 - auc: 0.9981 - prc: 0.9964\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0399 - accuracy: 0.9920 - tp: 3135.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 51.0000 - precision: 0.9921 - recall: 0.9840 - auc: 0.9994 - prc: 0.9990\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9866 - tp: 3113.0000 - fp: 55.0000 - tn: 6317.0000 - fn: 73.0000 - precision: 0.9826 - recall: 0.9771 - auc: 0.9990 - prc: 0.9980\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0468 - accuracy: 0.9896 - tp: 3125.0000 - fp: 38.0000 - tn: 6334.0000 - fn: 61.0000 - precision: 0.9880 - recall: 0.9809 - auc: 0.9992 - prc: 0.9984\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0209 - accuracy: 0.9957 - tp: 3162.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 24.0000 - precision: 0.9947 - recall: 0.9925 - auc: 0.9996 - prc: 0.9993\n","Score for fold 1: loss of 1.2406573295593262; accuracy of 56.43192529678345%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.1094 - accuracy: 0.9792 - tp: 3075.0000 - fp: 87.0000 - tn: 6287.0000 - fn: 112.0000 - precision: 0.9725 - recall: 0.9649 - auc: 0.9940 - prc: 0.9890\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0449 - accuracy: 0.9909 - tp: 3138.0000 - fp: 38.0000 - tn: 6336.0000 - fn: 49.0000 - precision: 0.9880 - recall: 0.9846 - auc: 0.9988 - prc: 0.9977\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0218 - accuracy: 0.9954 - tp: 3161.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 26.0000 - precision: 0.9943 - recall: 0.9918 - auc: 0.9994 - prc: 0.9988\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0145 - accuracy: 0.9970 - tp: 3170.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 17.0000 - precision: 0.9962 - recall: 0.9947 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9978 - tp: 3175.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 12.0000 - precision: 0.9972 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0066 - accuracy: 0.9987 - tp: 3180.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 7.0000 - precision: 0.9984 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0153 - accuracy: 0.9975 - tp: 3174.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 13.0000 - precision: 0.9965 - recall: 0.9959 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0147 - accuracy: 0.9964 - tp: 3167.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 20.0000 - precision: 0.9956 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0142 - accuracy: 0.9970 - tp: 3170.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 17.0000 - precision: 0.9962 - recall: 0.9947 - auc: 0.9999 - prc: 0.9999\n","Score for fold 2: loss of 0.08111602067947388; accuracy of 98.68173003196716%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0127 - accuracy: 0.9976 - tp: 3175.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 12.0000 - precision: 0.9965 - recall: 0.9962 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0138 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0577 - accuracy: 0.9833 - tp: 3106.0000 - fp: 79.0000 - tn: 6295.0000 - fn: 81.0000 - precision: 0.9752 - recall: 0.9746 - auc: 0.9989 - prc: 0.9981\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0663 - accuracy: 0.9844 - tp: 3110.0000 - fp: 72.0000 - tn: 6302.0000 - fn: 77.0000 - precision: 0.9774 - recall: 0.9758 - auc: 0.9986 - prc: 0.9975\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0375 - accuracy: 0.9929 - tp: 3151.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 36.0000 - precision: 0.9899 - recall: 0.9887 - auc: 0.9997 - prc: 0.9993\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0082 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0049 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0043 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.055640120059251785; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0111 - accuracy: 0.9978 - tp: 3176.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0074 - accuracy: 0.9984 - tp: 3179.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0073 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9998 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0245 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 0.9988 - prc: 0.9979\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0357 - accuracy: 0.9916 - tp: 3147.0000 - fp: 40.0000 - tn: 6334.0000 - fn: 40.0000 - precision: 0.9874 - recall: 0.9874 - auc: 0.9996 - prc: 0.9993\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0057 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.01902531459927559; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0064 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.0019430831307545304; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.00012872126535512507; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.00011714285938069224; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0022 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.02334132231771946; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0047 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0074 - accuracy: 0.9974 - tp: 3174.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0607 - accuracy: 0.9873 - tp: 3126.0000 - fp: 60.0000 - tn: 6314.0000 - fn: 61.0000 - precision: 0.9812 - recall: 0.9809 - auc: 0.9979 - prc: 0.9966\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0423 - accuracy: 0.9898 - tp: 3137.0000 - fp: 48.0000 - tn: 6326.0000 - fn: 50.0000 - precision: 0.9849 - recall: 0.9843 - auc: 0.9991 - prc: 0.9984\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0196 - accuracy: 0.9950 - tp: 3161.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 26.0000 - precision: 0.9931 - recall: 0.9918 - auc: 0.9999 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0107 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0167 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 0.9999 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9982 - tp: 3178.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.04845445230603218; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0106 - accuracy: 0.9974 - tp: 3174.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.0009761822875589132; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 1.2406573295593262 - Accuracy: 56.43192529678345%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.08111602067947388 - Accuracy: 98.68173003196716%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.055640120059251785 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01902531459927559 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0019430831307545304 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.00012872126535512507 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.00011714285938069224 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.02334132231771946 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.04845445230603218 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.0009761822875589132 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 95.22887885570526 (+- 12.940298930106335)\n","> Loss: 0.14713996890641284\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 7ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0025 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.9682 - accuracy: 0.8997 - tp: 2106.0000 - fp: 373.0000 - tn: 4585.0000 - fn: 373.0000 - precision: 0.8495 - recall: 0.8495 - auc: 0.9204 - prc: 0.8573\n","\n",">round 1  client 3 evaluation training metrics:\n","[0.0025492266286164522, 0.9990586638450623, 3536.0, 5.0, 7077.0, 5.0, 0.998587965965271, 0.998587965965271, 0.9999978542327881, 0.9999957084655762]\n","\n",">round 1  client 3 evaluation metrics:\n","[0.968209445476532, 0.8996907472610474, 2106.0, 373.0, 4585.0, 373.0, 0.849536120891571, 0.849536120891571, 0.9204171895980835, 0.8573257327079773]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.5872 - accuracy: 0.8722 - tp: 4381.0000 - fp: 888.0000 - tn: 10442.0000 - fn: 1284.0000 - precision: 0.8315 - recall: 0.7733 - auc: 0.9087 - prc: 0.8368\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.3457 - accuracy: 0.9183 - tp: 2709.0000 - fp: 304.0000 - tn: 6068.0000 - fn: 477.0000 - precision: 0.8991 - recall: 0.8503 - auc: 0.9684 - prc: 0.9449\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1939 - accuracy: 0.9614 - tp: 2959.0000 - fp: 142.0000 - tn: 6230.0000 - fn: 227.0000 - precision: 0.9542 - recall: 0.9288 - auc: 0.9881 - prc: 0.9778\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0945 - accuracy: 0.9815 - tp: 3084.0000 - fp: 75.0000 - tn: 6297.0000 - fn: 102.0000 - precision: 0.9763 - recall: 0.9680 - auc: 0.9969 - prc: 0.9941\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0684 - accuracy: 0.9871 - tp: 3113.0000 - fp: 50.0000 - tn: 6322.0000 - fn: 73.0000 - precision: 0.9842 - recall: 0.9771 - auc: 0.9982 - prc: 0.9968\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0157 - accuracy: 0.9972 - tp: 3169.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 17.0000 - precision: 0.9969 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0112 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 0.9998 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0093 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 1.110700249671936; accuracy of 66.19585752487183%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1216 - accuracy: 0.9765 - tp: 3070.0000 - fp: 109.0000 - tn: 6263.0000 - fn: 116.0000 - precision: 0.9657 - recall: 0.9636 - auc: 0.9939 - prc: 0.9895\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0290 - accuracy: 0.9946 - tp: 3159.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 27.0000 - precision: 0.9921 - recall: 0.9915 - auc: 0.9994 - prc: 0.9992\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0283 - accuracy: 0.9932 - tp: 3151.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 35.0000 - precision: 0.9906 - recall: 0.9890 - auc: 0.9998 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0142 - accuracy: 0.9977 - tp: 3174.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9969 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0054 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.10449269413948059; accuracy of 96.79849147796631%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0144 - accuracy: 0.9972 - tp: 3171.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 15.0000 - precision: 0.9962 - recall: 0.9953 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0369 - accuracy: 0.9931 - tp: 3152.0000 - fp: 32.0000 - tn: 6340.0000 - fn: 34.0000 - precision: 0.9899 - recall: 0.9893 - auc: 0.9986 - prc: 0.9973\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0119 - accuracy: 0.9978 - tp: 3175.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0075 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.01496545597910881; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0091 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0015986058861017227; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.000210270140087232; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.3463e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.9439e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9669e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.6094e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7250e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9323e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.7828e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.3245e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5788e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3809e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Score for fold 6: loss of 0.01226700097322464; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.9292e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.7010e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2413e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.2632e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0673e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1150e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1871e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4942e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.4794e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.01552971638739109; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0023 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 9.435129322810099e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.9358e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9839e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3346e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0873e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6952e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7402e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7877e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6685e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4480e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.5354e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.012255297042429447; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 6.32364462944679e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 1.110700249671936 - Accuracy: 66.19585752487183%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.10449269413948059 - Accuracy: 96.79849147796631%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.01496545597910881 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0015986058861017227 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.000210270140087232 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.01226700097322464 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.01552971638739109 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 9.435129322810099e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.012255297042429447 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 6.32364462944679e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 96.22410416603088 (+- 10.052550322150308)\n","> Loss: 0.1272176877959282\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 12ms/step - loss: 8.8106e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 1.1003 - accuracy: 0.8971 - tp: 2096.0000 - fp: 382.0000 - tn: 4576.0000 - fn: 383.0000 - precision: 0.8458 - recall: 0.8455 - auc: 0.9204 - prc: 0.8614\n","\n",">round 1  client 4 evaluation training metrics:\n","[0.0008810646249912679, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999996423721313, 0.9999994039535522]\n","\n",">round 1  client 4 evaluation metrics:\n","[1.1002639532089233, 0.8971359133720398, 2096.0, 382.0, 4576.0, 383.0, 0.8458434343338013, 0.8455021977424622, 0.9204274415969849, 0.8614325523376465]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 28ms/step - loss: 0.6265 - accuracy: 0.8623 - tp: 4248.0000 - fp: 923.0000 - tn: 10407.0000 - fn: 1417.0000 - precision: 0.8215 - recall: 0.7499 - auc: 0.9014 - prc: 0.8282\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.3650 - accuracy: 0.9111 - tp: 2656.0000 - fp: 320.0000 - tn: 6052.0000 - fn: 530.0000 - precision: 0.8925 - recall: 0.8336 - auc: 0.9647 - prc: 0.9376\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2378 - accuracy: 0.9511 - tp: 2898.0000 - fp: 179.0000 - tn: 6193.0000 - fn: 288.0000 - precision: 0.9418 - recall: 0.9096 - auc: 0.9830 - prc: 0.9683\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1226 - accuracy: 0.9735 - tp: 3025.0000 - fp: 92.0000 - tn: 6280.0000 - fn: 161.0000 - precision: 0.9705 - recall: 0.9495 - auc: 0.9950 - prc: 0.9907\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0680 - accuracy: 0.9874 - tp: 3122.0000 - fp: 56.0000 - tn: 6316.0000 - fn: 64.0000 - precision: 0.9824 - recall: 0.9799 - auc: 0.9984 - prc: 0.9971\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0410 - accuracy: 0.9923 - tp: 3148.0000 - fp: 36.0000 - tn: 6336.0000 - fn: 38.0000 - precision: 0.9887 - recall: 0.9881 - auc: 0.9994 - prc: 0.9990\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0684 - accuracy: 0.9846 - tp: 3108.0000 - fp: 69.0000 - tn: 6303.0000 - fn: 78.0000 - precision: 0.9783 - recall: 0.9755 - auc: 0.9983 - prc: 0.9968\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0291 - accuracy: 0.9939 - tp: 3156.0000 - fp: 28.0000 - tn: 6344.0000 - fn: 30.0000 - precision: 0.9912 - recall: 0.9906 - auc: 0.9998 - prc: 0.9996\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0119 - accuracy: 0.9975 - tp: 3172.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 14.0000 - precision: 0.9969 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0163 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 0.9999 - prc: 0.9999\n","Score for fold 1: loss of 0.9075053334236145; accuracy of 77.96609997749329%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0844 - accuracy: 0.9870 - tp: 3121.0000 - fp: 59.0000 - tn: 6313.0000 - fn: 65.0000 - precision: 0.9814 - recall: 0.9796 - auc: 0.9955 - prc: 0.9916\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0309 - accuracy: 0.9957 - tp: 3165.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 0.9992 - prc: 0.9986\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0204 - accuracy: 0.9958 - tp: 3164.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 22.0000 - precision: 0.9943 - recall: 0.9931 - auc: 0.9997 - prc: 0.9993\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0189 - accuracy: 0.9963 - tp: 3168.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.07209454476833344; accuracy of 98.49340915679932%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0069 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0062 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9998 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9984 - tp: 3178.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0162 - accuracy: 0.9954 - tp: 3164.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0150 - accuracy: 0.9971 - tp: 3172.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0279 - accuracy: 0.9942 - tp: 3158.0000 - fp: 27.0000 - tn: 6345.0000 - fn: 28.0000 - precision: 0.9915 - recall: 0.9912 - auc: 0.9993 - prc: 0.9987\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0340 - accuracy: 0.9949 - tp: 3161.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 25.0000 - precision: 0.9925 - recall: 0.9922 - auc: 0.9988 - prc: 0.9977\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0092 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 0.9997 - prc: 0.9995\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.02303483337163925; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0051 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0129 - accuracy: 0.9965 - tp: 3169.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0139 - accuracy: 0.9970 - tp: 3170.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9959 - recall: 0.9950 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0143 - accuracy: 0.9972 - tp: 3172.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 14.0000 - precision: 0.9959 - recall: 0.9956 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 0.9997 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.4911e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.8648e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.00894915871322155; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0020 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9019e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9671e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6802e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9925e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.5360e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6711e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6086e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.5571e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.00022865422943141311; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.1220e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4611e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5245e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9891e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1351e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8103e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2854e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.7263e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5012e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.3513e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.00010405369539512321; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 2.9657e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.6708e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.3993e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.2590e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1487e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.0340e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5911e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.9567e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9572e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.4488e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.010692737996578217; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 2.6706e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1923e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.7885e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4251e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.1498e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6556e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2121e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9150e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7404e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.013375967741012573; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0113 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0651 - accuracy: 0.9838 - tp: 3107.0000 - fp: 76.0000 - tn: 6296.0000 - fn: 79.0000 - precision: 0.9761 - recall: 0.9752 - auc: 0.9983 - prc: 0.9966\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0144 - accuracy: 0.9971 - tp: 3172.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9995 - prc: 0.9990\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0554 - accuracy: 0.9870 - tp: 3121.0000 - fp: 59.0000 - tn: 6313.0000 - fn: 65.0000 - precision: 0.9814 - recall: 0.9796 - auc: 0.9989 - prc: 0.9978\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0144 - accuracy: 0.9974 - tp: 3173.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 0.9995 - prc: 0.9990\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9998 - prc: 0.9995\n","Score for fold 9: loss of 0.095462366938591; accuracy of 97.74011373519897%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0127 - accuracy: 0.9969 - tp: 3171.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0322 - accuracy: 0.9930 - tp: 3152.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 34.0000 - precision: 0.9896 - recall: 0.9893 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0048 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.4660e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.4906e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.1860e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.3370e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2838e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.0037357232067734003; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.9075053334236145 - Accuracy: 77.96609997749329%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.07209454476833344 - Accuracy: 98.49340915679932%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.02303483337163925 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00894915871322155 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.00022865422943141311 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.00010405369539512321 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.010692737996578217 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.013375967741012573 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.095462366938591 - Accuracy: 97.74011373519897%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.0037357232067734003 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 97.28813409805298 (+- 6.479109117967055)\n","> Loss: 0.11351833740845904\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 12ms/step - loss: 9.1906e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.9930 - accuracy: 0.8962 - tp: 2089.0000 - fp: 382.0000 - tn: 4576.0000 - fn: 390.0000 - precision: 0.8454 - recall: 0.8427 - auc: 0.9271 - prc: 0.8711\n","\n",">round 1  client 5 evaluation training metrics:\n","[0.0009190552518703043, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997615814209, 0.999999463558197]\n","\n",">round 1  client 5 evaluation metrics:\n","[0.993031919002533, 0.8961946964263916, 2089.0, 382.0, 4576.0, 390.0, 0.845406711101532, 0.8426784873008728, 0.9271388053894043, 0.8711004257202148]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 31ms/step - loss: 0.5991 - accuracy: 0.8673 - tp: 4295.0000 - fp: 886.0000 - tn: 10444.0000 - fn: 1370.0000 - precision: 0.8290 - recall: 0.7582 - auc: 0.9102 - prc: 0.8418\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.3589 - accuracy: 0.9150 - tp: 2700.0000 - fp: 326.0000 - tn: 6046.0000 - fn: 486.0000 - precision: 0.8923 - recall: 0.8475 - auc: 0.9652 - prc: 0.9373\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2197 - accuracy: 0.9540 - tp: 2918.0000 - fp: 172.0000 - tn: 6200.0000 - fn: 268.0000 - precision: 0.9443 - recall: 0.9159 - auc: 0.9851 - prc: 0.9715\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1340 - accuracy: 0.9702 - tp: 3017.0000 - fp: 116.0000 - tn: 6256.0000 - fn: 169.0000 - precision: 0.9630 - recall: 0.9470 - auc: 0.9940 - prc: 0.9884\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0777 - accuracy: 0.9842 - tp: 3089.0000 - fp: 54.0000 - tn: 6318.0000 - fn: 97.0000 - precision: 0.9828 - recall: 0.9696 - auc: 0.9980 - prc: 0.9960\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0292 - accuracy: 0.9947 - tp: 3155.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 31.0000 - precision: 0.9937 - recall: 0.9903 - auc: 0.9998 - prc: 0.9996\n","Epoch 7/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0213 - accuracy: 0.9953 - tp: 3161.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 25.0000 - precision: 0.9937 - recall: 0.9922 - auc: 0.9999 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0156 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0126 - accuracy: 0.9977 - tp: 3174.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9969 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0107 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 0.867932140827179; accuracy of 79.37853336334229%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1528 - accuracy: 0.9682 - tp: 3023.0000 - fp: 141.0000 - tn: 6231.0000 - fn: 163.0000 - precision: 0.9554 - recall: 0.9488 - auc: 0.9916 - prc: 0.9842\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0535 - accuracy: 0.9908 - tp: 3138.0000 - fp: 40.0000 - tn: 6332.0000 - fn: 48.0000 - precision: 0.9874 - recall: 0.9849 - auc: 0.9993 - prc: 0.9986\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0183 - accuracy: 0.9963 - tp: 3168.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9978 - tp: 3174.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 12.0000 - precision: 0.9972 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9979 - tp: 3172.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 14.0000 - precision: 0.9981 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0058 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.1746029108762741; accuracy of 95.57439088821411%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0086 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.00034590784343890846; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8915e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5049e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.3002e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.0547e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.00022091691789682955; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3684e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.9098e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3223e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.8806e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.8016e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1502e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0401e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.6490e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.7868e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.00015109410742297769; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.5195e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.4224e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.1919e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.2913e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2858e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.5643e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1980e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6820e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.3985e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.3495e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Score for fold 6: loss of 6.744080019416288e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2138e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7031e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6124e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0140e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.3417e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1284e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.4617e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.4255e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.0785e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1125e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 7.012076821411029e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3433e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.0795e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0224e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6127e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7902e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6567e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2252e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.8303e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8602e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2721e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 3.09228926198557e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.8935e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6747e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3610e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6655e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.8476e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5413e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4317e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8363e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3924e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6932e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 7.435682346113026e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.7966e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.6370e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.4581e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.3402e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.2400e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.1562e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 2.0620e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.9954e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.9412e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 1.8717e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.003966130316257477; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.867932140827179 - Accuracy: 79.37853336334229%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.1746029108762741 - Accuracy: 95.57439088821411%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.00034590784343890846 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00022091691789682955 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.00015109410742297769 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 6.744080019416288e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 7.012076821411029e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.09228926198557e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 7.435682346113026e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.003966130316257477 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 97.47645974159241 (+- 6.174008543046327)\n","> Loss: 0.10474619421729585\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 4.1283e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 1.1384 - accuracy: 0.8967 - tp: 2095.0000 - fp: 384.0000 - tn: 4574.0000 - fn: 384.0000 - precision: 0.8451 - recall: 0.8451 - auc: 0.9187 - prc: 0.8544\n","\n",">round 1  client 6 evaluation training metrics:\n","[0.0004128250293433666, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 1  client 6 evaluation metrics:\n","[1.1384053230285645, 0.8967325687408447, 2095.0, 384.0, 4574.0, 384.0, 0.8450988531112671, 0.8450988531112671, 0.9186868071556091, 0.8544007539749146]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.5766 - accuracy: 0.8730 - tp: 4423.0000 - fp: 916.0000 - tn: 10414.0000 - fn: 1242.0000 - precision: 0.8284 - recall: 0.7808 - auc: 0.9058 - prc: 0.8321\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.3560 - accuracy: 0.9122 - tp: 2672.0000 - fp: 325.0000 - tn: 6047.0000 - fn: 514.0000 - precision: 0.8916 - recall: 0.8387 - auc: 0.9660 - prc: 0.9388\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2418 - accuracy: 0.9432 - tp: 2847.0000 - fp: 204.0000 - tn: 6168.0000 - fn: 339.0000 - precision: 0.9331 - recall: 0.8936 - auc: 0.9833 - prc: 0.9684\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1257 - accuracy: 0.9749 - tp: 3041.0000 - fp: 95.0000 - tn: 6277.0000 - fn: 145.0000 - precision: 0.9697 - recall: 0.9545 - auc: 0.9940 - prc: 0.9870\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0621 - accuracy: 0.9884 - tp: 3129.0000 - fp: 54.0000 - tn: 6318.0000 - fn: 57.0000 - precision: 0.9830 - recall: 0.9821 - auc: 0.9985 - prc: 0.9973\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0415 - accuracy: 0.9922 - tp: 3145.0000 - fp: 34.0000 - tn: 6338.0000 - fn: 41.0000 - precision: 0.9893 - recall: 0.9871 - auc: 0.9991 - prc: 0.9982\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0285 - accuracy: 0.9954 - tp: 3161.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 25.0000 - precision: 0.9940 - recall: 0.9922 - auc: 0.9995 - prc: 0.9993\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0580 - accuracy: 0.9878 - tp: 3119.0000 - fp: 50.0000 - tn: 6322.0000 - fn: 67.0000 - precision: 0.9842 - recall: 0.9790 - auc: 0.9986 - prc: 0.9974\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0415 - accuracy: 0.9914 - tp: 3141.0000 - fp: 37.0000 - tn: 6335.0000 - fn: 45.0000 - precision: 0.9884 - recall: 0.9859 - auc: 0.9995 - prc: 0.9991\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0152 - accuracy: 0.9978 - tp: 3173.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 13.0000 - precision: 0.9975 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 1.7942965030670166; accuracy of 53.295665979385376%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0931 - accuracy: 0.9848 - tp: 3111.0000 - fp: 70.0000 - tn: 6302.0000 - fn: 75.0000 - precision: 0.9780 - recall: 0.9765 - auc: 0.9953 - prc: 0.9921\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0432 - accuracy: 0.9929 - tp: 3152.0000 - fp: 34.0000 - tn: 6338.0000 - fn: 34.0000 - precision: 0.9893 - recall: 0.9893 - auc: 0.9985 - prc: 0.9970\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0223 - accuracy: 0.9951 - tp: 3162.0000 - fp: 23.0000 - tn: 6349.0000 - fn: 24.0000 - precision: 0.9928 - recall: 0.9925 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0141 - accuracy: 0.9976 - tp: 3174.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 12.0000 - precision: 0.9965 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0096 - accuracy: 0.9982 - tp: 3177.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0069 - accuracy: 0.9984 - tp: 3178.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0068 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0069 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.13268333673477173; accuracy of 96.42184376716614%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0150 - accuracy: 0.9969 - tp: 3170.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9956 - recall: 0.9950 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0292 - accuracy: 0.9934 - tp: 3154.0000 - fp: 31.0000 - tn: 6341.0000 - fn: 32.0000 - precision: 0.9903 - recall: 0.9900 - auc: 0.9998 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0388 - accuracy: 0.9915 - tp: 3144.0000 - fp: 39.0000 - tn: 6333.0000 - fn: 42.0000 - precision: 0.9877 - recall: 0.9868 - auc: 0.9996 - prc: 0.9992\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0310 - accuracy: 0.9933 - tp: 3152.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 34.0000 - precision: 0.9906 - recall: 0.9893 - auc: 0.9996 - prc: 0.9991\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9988 - tp: 3178.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 8.0000 - precision: 0.9991 - recall: 0.9975 - auc: 0.9997 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0064 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0072 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0054 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.020682737231254578; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0159 - accuracy: 0.9973 - tp: 3172.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9962 - recall: 0.9956 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0057 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0023 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.01756688393652439; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.8679e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.2370e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.9773e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.8601e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.8347e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.9342e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.8731e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.004541546106338501; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.002023590262979269; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 4.3533946154639125e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8049e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7226e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2908e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1038e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5950e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1110e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7819e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.7498e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7802e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8610e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.011989706195890903; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.0024080316070467234; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 2.1650570488418452e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 1.7942965030670166 - Accuracy: 53.295665979385376%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.13268333673477173 - Accuracy: 96.42184376716614%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.020682737231254578 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01756688393652439 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.004541546106338501 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.002023590262979269 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 4.3533946154639125e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.011989706195890903 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.0024080316070467234 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 2.1650570488418452e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 94.87758755683899 (+- 13.899223938559652)\n","> Loss: 0.1986257519658466\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 9.6471e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 1.1072 - accuracy: 0.8946 - tp: 2085.0000 - fp: 390.0000 - tn: 4568.0000 - fn: 394.0000 - precision: 0.8424 - recall: 0.8411 - auc: 0.9212 - prc: 0.8581\n","\n",">round 1  client 7 evaluation training metrics:\n","[0.00096471281722188, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997019767761, 0.9999992251396179]\n","\n",">round 1  client 7 evaluation metrics:\n","[1.1071845293045044, 0.894581139087677, 2085.0, 390.0, 4568.0, 394.0, 0.842424213886261, 0.8410649299621582, 0.9211912751197815, 0.8581296801567078]\n","\n","=============================================================\n","\n","> round 1 average training auc= 0.2491720360400486\n","> round 1 average training loss= 0.134556936755884\n","> round 1 average epoch count= 10.0\n"," 1/78 [..............................] - ETA: 2s"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["78/78 [==============================] - 0s 6ms/step\n","> round 1 test auc= 0.5\n","111/111 [==============================] - 1s 10ms/step - loss: 1.3087 - accuracy: 0.6667 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 7082.0000 - fn: 3541.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1943 - prc: 0.2131\n","\n","> round 1 final model training loss_metric= [1.3086893558502197]\n","> round 1 final model training TP_metric= [0.0]\n","> round 1 final model training FP_metric= [0.0]\n","> round 1 final model training TN_metric= [7082.0]\n","> round 1 final model training FN_metric= [3541.0]\n","> round 1 final model training accuracy_metric= [66.66666865348816]\n","> round 1 final model training precision_metric= [0.0]\n","> round 1 final model training recall_metric = [0.0]\n","> round 1 final model training auc_metric= [0.1942644715309143]\n","> round 1 final model training prc_metric= [0.21307504177093506]\n","\n","78/78 [==============================] - 1s 10ms/step - loss: 1.3359 - accuracy: 0.6667 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4958.0000 - fn: 2479.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1484 - prc: 0.2041\n","> round 1 final model loss_metric= [1.3359136581420898]\n","> round 1 final model TP_metric= [0.0]\n","> round 1 final model FP_metric= [0.0]\n","> round 1 final model TN_metric= [4958.0]\n","> round 1 final model FN_metric= [2479.0]\n","> round 1 final model accuracy_metric= [66.66666865348816]\n","> round 1 final model precision_metric= [0.0]\n","> round 1 final model recall_metric = [0.0]\n","> round 1 final model auc_metric= [0.14842158555984497]\n","> round 1 final model prc_metric= [0.20406179130077362]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 2 start, random seed= 2\n","\n","> client 1 started learning...........\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 27ms/step - loss: 0.6611 - accuracy: 0.7546 - tp: 2026.0000 - fp: 532.0000 - tn: 10798.0000 - fn: 3639.0000 - precision: 0.7920 - recall: 0.3576 - auc: 0.6674 - prc: 0.5957\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.4653 - accuracy: 0.8761 - tp: 2365.0000 - fp: 363.0000 - tn: 6009.0000 - fn: 821.0000 - precision: 0.8669 - recall: 0.7423 - auc: 0.9430 - prc: 0.9050\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.3792 - accuracy: 0.9085 - tp: 2594.0000 - fp: 283.0000 - tn: 6089.0000 - fn: 592.0000 - precision: 0.9016 - recall: 0.8142 - auc: 0.9626 - prc: 0.9332\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2500 - accuracy: 0.9421 - tp: 2832.0000 - fp: 199.0000 - tn: 6173.0000 - fn: 354.0000 - precision: 0.9343 - recall: 0.8889 - auc: 0.9828 - prc: 0.9683\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1768 - accuracy: 0.9610 - tp: 2962.0000 - fp: 149.0000 - tn: 6223.0000 - fn: 224.0000 - precision: 0.9521 - recall: 0.9297 - auc: 0.9908 - prc: 0.9833\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0956 - accuracy: 0.9807 - tp: 3056.0000 - fp: 54.0000 - tn: 6318.0000 - fn: 130.0000 - precision: 0.9826 - recall: 0.9592 - auc: 0.9976 - prc: 0.9957\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0382 - accuracy: 0.9920 - tp: 3125.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 61.0000 - precision: 0.9952 - recall: 0.9809 - auc: 0.9994 - prc: 0.9989\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0427 - accuracy: 0.9892 - tp: 3116.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 70.0000 - precision: 0.9895 - recall: 0.9780 - auc: 0.9995 - prc: 0.9991\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0415 - accuracy: 0.9905 - tp: 3130.0000 - fp: 35.0000 - tn: 6337.0000 - fn: 56.0000 - precision: 0.9889 - recall: 0.9824 - auc: 0.9996 - prc: 0.9992\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0990 - accuracy: 0.9768 - tp: 3066.0000 - fp: 102.0000 - tn: 6270.0000 - fn: 120.0000 - precision: 0.9678 - recall: 0.9623 - auc: 0.9957 - prc: 0.9929\n","Score for fold 1: loss of 0.700748860836029; accuracy of 88.07511925697327%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.1207 - accuracy: 0.9744 - tp: 3044.0000 - fp: 102.0000 - tn: 6272.0000 - fn: 143.0000 - precision: 0.9676 - recall: 0.9551 - auc: 0.9943 - prc: 0.9905\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0552 - accuracy: 0.9895 - tp: 3123.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 64.0000 - precision: 0.9886 - recall: 0.9799 - auc: 0.9987 - prc: 0.9977\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0349 - accuracy: 0.9921 - tp: 3135.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 52.0000 - precision: 0.9924 - recall: 0.9837 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0220 - accuracy: 0.9947 - tp: 3150.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 37.0000 - precision: 0.9956 - recall: 0.9884 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0180 - accuracy: 0.9956 - tp: 3155.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 32.0000 - precision: 0.9968 - recall: 0.9900 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0140 - accuracy: 0.9969 - tp: 3171.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 16.0000 - precision: 0.9956 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0167 - accuracy: 0.9963 - tp: 3167.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 20.0000 - precision: 0.9953 - recall: 0.9937 - auc: 0.9999 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0115 - accuracy: 0.9975 - tp: 3172.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 15.0000 - precision: 0.9972 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0470 - accuracy: 0.9894 - tp: 3134.0000 - fp: 48.0000 - tn: 6326.0000 - fn: 53.0000 - precision: 0.9849 - recall: 0.9834 - auc: 0.9987 - prc: 0.9974\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0184 - accuracy: 0.9970 - tp: 3172.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 0.9997 - prc: 0.9994\n","Score for fold 2: loss of 0.09688185900449753; accuracy of 98.11676144599915%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0260 - accuracy: 0.9939 - tp: 3152.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 35.0000 - precision: 0.9928 - recall: 0.9890 - auc: 0.9994 - prc: 0.9991\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0204 - accuracy: 0.9956 - tp: 3162.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 25.0000 - precision: 0.9947 - recall: 0.9922 - auc: 0.9997 - prc: 0.9993\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0248 - accuracy: 0.9948 - tp: 3158.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 29.0000 - precision: 0.9934 - recall: 0.9909 - auc: 0.9996 - prc: 0.9992\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0149 - accuracy: 0.9971 - tp: 3167.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 20.0000 - precision: 0.9975 - recall: 0.9937 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0172 - accuracy: 0.9964 - tp: 3167.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 20.0000 - precision: 0.9956 - recall: 0.9937 - auc: 0.9998 - prc: 0.9997\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0150 - accuracy: 0.9969 - tp: 3167.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 20.0000 - precision: 0.9969 - recall: 0.9937 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0064 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0047 - accuracy: 0.9990 - tp: 3180.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 7.0000 - precision: 0.9991 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0049 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.035865239799022675; accuracy of 99.1525411605835%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0099 - accuracy: 0.9981 - tp: 3175.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 12.0000 - precision: 0.9981 - recall: 0.9962 - auc: 0.9998 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0068 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0055 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0046 - accuracy: 0.9987 - tp: 3175.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 12.0000 - precision: 1.0000 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3175.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 12.0000 - precision: 0.9997 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0046 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3176.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 11.0000 - precision: 1.0000 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.01335320994257927; accuracy of 99.52918887138367%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0051 - accuracy: 0.9984 - tp: 3173.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 14.0000 - precision: 0.9997 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0057 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0054 - accuracy: 0.9984 - tp: 3174.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 13.0000 - precision: 0.9994 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0054 - accuracy: 0.9984 - tp: 3173.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 14.0000 - precision: 0.9997 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9982 - tp: 3172.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 15.0000 - precision: 0.9994 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9983 - tp: 3173.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 14.0000 - precision: 0.9994 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0057 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0051 - accuracy: 0.9985 - tp: 3174.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 13.0000 - precision: 0.9997 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9983 - tp: 3173.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 14.0000 - precision: 0.9994 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.00021883500448893756; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0067 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0052 - accuracy: 0.9986 - tp: 3174.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 13.0000 - precision: 1.0000 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3174.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 13.0000 - precision: 1.0000 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0047 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.004023849498480558; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0046 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.00899815745651722; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0053 - accuracy: 0.9985 - tp: 3174.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 13.0000 - precision: 0.9997 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0049 - accuracy: 0.9985 - tp: 3174.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 13.0000 - precision: 0.9997 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0047 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0048 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 8.016266656341031e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.012647939845919609; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0036 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.006484183948487043; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.700748860836029 - Accuracy: 88.07511925697327%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.09688185900449753 - Accuracy: 98.11676144599915%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.035865239799022675 - Accuracy: 99.1525411605835%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01335320994257927 - Accuracy: 99.52918887138367%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.00021883500448893756 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.004023849498480558 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.00899815745651722 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 8.016266656341031e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.012647939845919609 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.006484183948487043 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.41203093528748 (+- 3.487583094411595)\n","> Loss: 0.08793022980025852\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 4ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3529.0000 - fp: 1.0000 - tn: 7081.0000 - fn: 12.0000 - precision: 0.9997 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 1.0218 - accuracy: 0.9095 - tp: 2139.0000 - fp: 333.0000 - tn: 4625.0000 - fn: 340.0000 - precision: 0.8653 - recall: 0.8628 - auc: 0.9260 - prc: 0.8664\n","\n",">round 2  client 1 evaluation training metrics:\n","[0.0037921343464404345, 0.9987762570381165, 3529.0, 1.0, 7081.0, 12.0, 0.9997166991233826, 0.9966111183166504, 0.9999946355819702, 0.9999892711639404]\n","\n",">round 2  client 1 evaluation metrics:\n","[1.0217913389205933, 0.9095064997673035, 2139.0, 333.0, 4625.0, 340.0, 0.8652912378311157, 0.8628479242324829, 0.9260200262069702, 0.8663688898086548]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.7395 - accuracy: 0.8431 - tp: 3882.0000 - fp: 884.0000 - tn: 10446.0000 - fn: 1783.0000 - precision: 0.8145 - recall: 0.6853 - auc: 0.8941 - prc: 0.8178\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.5686 - accuracy: 0.8420 - tp: 2158.0000 - fp: 482.0000 - tn: 5890.0000 - fn: 1028.0000 - precision: 0.8174 - recall: 0.6773 - auc: 0.9132 - prc: 0.8571\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.4591 - accuracy: 0.8807 - tp: 2424.0000 - fp: 378.0000 - tn: 5994.0000 - fn: 762.0000 - precision: 0.8651 - recall: 0.7608 - auc: 0.9440 - prc: 0.9048\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.3385 - accuracy: 0.9136 - tp: 2695.0000 - fp: 335.0000 - tn: 6037.0000 - fn: 491.0000 - precision: 0.8894 - recall: 0.8459 - auc: 0.9695 - prc: 0.9462\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2021 - accuracy: 0.9503 - tp: 2927.0000 - fp: 216.0000 - tn: 6156.0000 - fn: 259.0000 - precision: 0.9313 - recall: 0.9187 - auc: 0.9891 - prc: 0.9794\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1779 - accuracy: 0.9528 - tp: 2937.0000 - fp: 202.0000 - tn: 6170.0000 - fn: 249.0000 - precision: 0.9356 - recall: 0.9218 - auc: 0.9913 - prc: 0.9843\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0987 - accuracy: 0.9784 - tp: 3071.0000 - fp: 91.0000 - tn: 6281.0000 - fn: 115.0000 - precision: 0.9712 - recall: 0.9639 - auc: 0.9976 - prc: 0.9956\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0496 - accuracy: 0.9880 - tp: 3118.0000 - fp: 47.0000 - tn: 6325.0000 - fn: 68.0000 - precision: 0.9852 - recall: 0.9787 - auc: 0.9995 - prc: 0.9990\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0347 - accuracy: 0.9908 - tp: 3126.0000 - fp: 28.0000 - tn: 6344.0000 - fn: 60.0000 - precision: 0.9911 - recall: 0.9812 - auc: 0.9997 - prc: 0.9995\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0478 - accuracy: 0.9872 - tp: 3115.0000 - fp: 51.0000 - tn: 6321.0000 - fn: 71.0000 - precision: 0.9839 - recall: 0.9777 - auc: 0.9994 - prc: 0.9988\n","Score for fold 1: loss of 0.8251177072525024; accuracy of 84.6009373664856%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1619 - accuracy: 0.9655 - tp: 3006.0000 - fp: 149.0000 - tn: 6225.0000 - fn: 181.0000 - precision: 0.9528 - recall: 0.9432 - auc: 0.9907 - prc: 0.9835\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0853 - accuracy: 0.9794 - tp: 3076.0000 - fp: 86.0000 - tn: 6288.0000 - fn: 111.0000 - precision: 0.9728 - recall: 0.9652 - auc: 0.9978 - prc: 0.9959\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0522 - accuracy: 0.9871 - tp: 3109.0000 - fp: 45.0000 - tn: 6329.0000 - fn: 78.0000 - precision: 0.9857 - recall: 0.9755 - auc: 0.9989 - prc: 0.9977\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0334 - accuracy: 0.9931 - tp: 3146.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 41.0000 - precision: 0.9921 - recall: 0.9871 - auc: 0.9995 - prc: 0.9990\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0214 - accuracy: 0.9937 - tp: 3147.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 40.0000 - precision: 0.9937 - recall: 0.9874 - auc: 0.9999 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0157 - accuracy: 0.9962 - tp: 3164.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 23.0000 - precision: 0.9959 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0166 - accuracy: 0.9958 - tp: 3160.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 27.0000 - precision: 0.9959 - recall: 0.9915 - auc: 0.9999 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0175 - accuracy: 0.9956 - tp: 3161.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 26.0000 - precision: 0.9950 - recall: 0.9918 - auc: 0.9999 - prc: 0.9998\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0153 - accuracy: 0.9961 - tp: 3165.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 22.0000 - precision: 0.9953 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0145 - accuracy: 0.9955 - tp: 3161.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 26.0000 - precision: 0.9947 - recall: 0.9918 - auc: 0.9999 - prc: 0.9999\n","Score for fold 2: loss of 0.0546572208404541; accuracy of 98.21092486381531%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0735 - accuracy: 0.9858 - tp: 3114.0000 - fp: 63.0000 - tn: 6311.0000 - fn: 73.0000 - precision: 0.9802 - recall: 0.9771 - auc: 0.9963 - prc: 0.9933\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0953 - accuracy: 0.9764 - tp: 3058.0000 - fp: 97.0000 - tn: 6277.0000 - fn: 129.0000 - precision: 0.9693 - recall: 0.9595 - auc: 0.9974 - prc: 0.9949\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0491 - accuracy: 0.9883 - tp: 3123.0000 - fp: 48.0000 - tn: 6326.0000 - fn: 64.0000 - precision: 0.9849 - recall: 0.9799 - auc: 0.9992 - prc: 0.9986\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0317 - accuracy: 0.9896 - tp: 3128.0000 - fp: 40.0000 - tn: 6334.0000 - fn: 59.0000 - precision: 0.9874 - recall: 0.9815 - auc: 0.9997 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0348 - accuracy: 0.9908 - tp: 3134.0000 - fp: 35.0000 - tn: 6339.0000 - fn: 53.0000 - precision: 0.9890 - recall: 0.9834 - auc: 0.9997 - prc: 0.9994\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0204 - accuracy: 0.9939 - tp: 3152.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 35.0000 - precision: 0.9928 - recall: 0.9890 - auc: 0.9999 - prc: 0.9998\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0168 - accuracy: 0.9952 - tp: 3158.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 29.0000 - precision: 0.9946 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0134 - accuracy: 0.9950 - tp: 3160.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 27.0000 - precision: 0.9934 - recall: 0.9915 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0137 - accuracy: 0.9956 - tp: 3163.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 24.0000 - precision: 0.9943 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0135 - accuracy: 0.9957 - tp: 3163.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 24.0000 - precision: 0.9947 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Score for fold 3: loss of 0.03235655650496483; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0191 - accuracy: 0.9932 - tp: 3151.0000 - fp: 29.0000 - tn: 6345.0000 - fn: 36.0000 - precision: 0.9909 - recall: 0.9887 - auc: 0.9999 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0166 - accuracy: 0.9955 - tp: 3163.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 24.0000 - precision: 0.9940 - recall: 0.9925 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0119 - accuracy: 0.9955 - tp: 3163.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 24.0000 - precision: 0.9940 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0106 - accuracy: 0.9958 - tp: 3165.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 22.0000 - precision: 0.9943 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0146 - accuracy: 0.9950 - tp: 3162.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 25.0000 - precision: 0.9928 - recall: 0.9922 - auc: 0.9997 - prc: 0.9994\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0119 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 0.9997 - prc: 0.9995\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0108 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0106 - accuracy: 0.9954 - tp: 3163.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 24.0000 - precision: 0.9937 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0114 - accuracy: 0.9961 - tp: 3166.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 21.0000 - precision: 0.9950 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.00890327338129282; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0091 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0428 - accuracy: 0.9874 - tp: 3111.0000 - fp: 44.0000 - tn: 6330.0000 - fn: 76.0000 - precision: 0.9861 - recall: 0.9762 - auc: 0.9995 - prc: 0.9991\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0309 - accuracy: 0.9912 - tp: 3137.0000 - fp: 34.0000 - tn: 6340.0000 - fn: 50.0000 - precision: 0.9893 - recall: 0.9843 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0395 - accuracy: 0.9892 - tp: 3130.0000 - fp: 46.0000 - tn: 6328.0000 - fn: 57.0000 - precision: 0.9855 - recall: 0.9821 - auc: 0.9995 - prc: 0.9991\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1482 - accuracy: 0.9676 - tp: 3024.0000 - fp: 147.0000 - tn: 6227.0000 - fn: 163.0000 - precision: 0.9536 - recall: 0.9489 - auc: 0.9918 - prc: 0.9841\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0401 - accuracy: 0.9903 - tp: 3139.0000 - fp: 45.0000 - tn: 6329.0000 - fn: 48.0000 - precision: 0.9859 - recall: 0.9849 - auc: 0.9994 - prc: 0.9989\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0227 - accuracy: 0.9938 - tp: 3149.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 38.0000 - precision: 0.9934 - recall: 0.9881 - auc: 0.9999 - prc: 0.9998\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0175 - accuracy: 0.9945 - tp: 3151.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 36.0000 - precision: 0.9946 - recall: 0.9887 - auc: 0.9999 - prc: 0.9998\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0147 - accuracy: 0.9950 - tp: 3156.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 31.0000 - precision: 0.9946 - recall: 0.9903 - auc: 0.9999 - prc: 0.9999\n","Score for fold 5: loss of 0.06250785291194916; accuracy of 97.83427715301514%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0195 - accuracy: 0.9950 - tp: 3160.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 27.0000 - precision: 0.9934 - recall: 0.9915 - auc: 0.9999 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0244 - accuracy: 0.9930 - tp: 3149.0000 - fp: 29.0000 - tn: 6345.0000 - fn: 38.0000 - precision: 0.9909 - recall: 0.9881 - auc: 0.9996 - prc: 0.9992\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0150 - accuracy: 0.9950 - tp: 3160.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 27.0000 - precision: 0.9934 - recall: 0.9915 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0199 - accuracy: 0.9927 - tp: 3149.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 38.0000 - precision: 0.9899 - recall: 0.9881 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9958 - tp: 3165.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 22.0000 - precision: 0.9943 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0137 - accuracy: 0.9958 - tp: 3165.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 22.0000 - precision: 0.9943 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0114 - accuracy: 0.9954 - tp: 3163.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 24.0000 - precision: 0.9937 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0105 - accuracy: 0.9963 - tp: 3167.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 20.0000 - precision: 0.9953 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0108 - accuracy: 0.9950 - tp: 3161.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 26.0000 - precision: 0.9931 - recall: 0.9918 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0100 - accuracy: 0.9954 - tp: 3163.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 24.0000 - precision: 0.9937 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.016011621803045273; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0121 - accuracy: 0.9949 - tp: 3160.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 27.0000 - precision: 0.9931 - recall: 0.9915 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0104 - accuracy: 0.9959 - tp: 3165.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 22.0000 - precision: 0.9947 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0106 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0102 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0097 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0098 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0095 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0107 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.01507498323917389; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0101 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0095 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9962 - tp: 3168.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 19.0000 - precision: 0.9947 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9956 - tp: 3165.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 22.0000 - precision: 0.9937 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.00865025445818901; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0095 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0098 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0092 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 9: loss of 0.007390936836600304; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0090 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0092 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0085 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0082 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 10: loss of 0.012217496521770954; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.8251177072525024 - Accuracy: 84.6009373664856%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0546572208404541 - Accuracy: 98.21092486381531%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.03235655650496483 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00890327338129282 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.06250785291194916 - Accuracy: 97.83427715301514%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.016011621803045273 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.01507498323917389 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.00865025445818901 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.007390936836600304 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.012217496521770954 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 97.68796563148499 (+- 4.408328328616502)\n","> Loss: 0.10428879037499428\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0085 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","78/78 [==============================] - 1s 9ms/step - loss: 0.9045 - accuracy: 0.9087 - tp: 2139.0000 - fp: 339.0000 - tn: 4619.0000 - fn: 340.0000 - precision: 0.8632 - recall: 0.8628 - auc: 0.9341 - prc: 0.8813\n","\n",">round 2  client 2 evaluation training metrics:\n","[0.008487033657729626, 0.9962345957756042, 3521.0, 20.0, 7062.0, 20.0, 0.994351863861084, 0.994351863861084, 0.9999703168869019, 0.9999408721923828]\n","\n",">round 2  client 2 evaluation metrics:\n","[0.9044817090034485, 0.9086997509002686, 2139.0, 339.0, 4619.0, 340.0, 0.8631961345672607, 0.8628479242324829, 0.9340631365776062, 0.8813015818595886]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 30ms/step - loss: 0.6369 - accuracy: 0.8638 - tp: 4188.0000 - fp: 838.0000 - tn: 10492.0000 - fn: 1477.0000 - precision: 0.8333 - recall: 0.7393 - auc: 0.9126 - prc: 0.8471\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.4262 - accuracy: 0.8920 - tp: 2536.0000 - fp: 382.0000 - tn: 5990.0000 - fn: 650.0000 - precision: 0.8691 - recall: 0.7960 - auc: 0.9512 - prc: 0.9135\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.3315 - accuracy: 0.9253 - tp: 2749.0000 - fp: 277.0000 - tn: 6095.0000 - fn: 437.0000 - precision: 0.9085 - recall: 0.8628 - auc: 0.9690 - prc: 0.9431\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2348 - accuracy: 0.9525 - tp: 2939.0000 - fp: 207.0000 - tn: 6165.0000 - fn: 247.0000 - precision: 0.9342 - recall: 0.9225 - auc: 0.9828 - prc: 0.9679\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1505 - accuracy: 0.9696 - tp: 3013.0000 - fp: 118.0000 - tn: 6254.0000 - fn: 173.0000 - precision: 0.9623 - recall: 0.9457 - auc: 0.9931 - prc: 0.9869\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0966 - accuracy: 0.9798 - tp: 3085.0000 - fp: 92.0000 - tn: 6280.0000 - fn: 101.0000 - precision: 0.9710 - recall: 0.9683 - auc: 0.9964 - prc: 0.9933\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0780 - accuracy: 0.9847 - tp: 3109.0000 - fp: 69.0000 - tn: 6303.0000 - fn: 77.0000 - precision: 0.9783 - recall: 0.9758 - auc: 0.9974 - prc: 0.9955\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1376 - accuracy: 0.9754 - tp: 3052.0000 - fp: 101.0000 - tn: 6271.0000 - fn: 134.0000 - precision: 0.9680 - recall: 0.9579 - auc: 0.9925 - prc: 0.9860\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1153 - accuracy: 0.9771 - tp: 3064.0000 - fp: 97.0000 - tn: 6275.0000 - fn: 122.0000 - precision: 0.9693 - recall: 0.9617 - auc: 0.9956 - prc: 0.9916\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0487 - accuracy: 0.9919 - tp: 3146.0000 - fp: 37.0000 - tn: 6335.0000 - fn: 40.0000 - precision: 0.9884 - recall: 0.9874 - auc: 0.9988 - prc: 0.9978\n","Score for fold 1: loss of 0.5741217732429504; accuracy of 89.67136144638062%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0999 - accuracy: 0.9827 - tp: 3100.0000 - fp: 78.0000 - tn: 6296.0000 - fn: 87.0000 - precision: 0.9755 - recall: 0.9727 - auc: 0.9949 - prc: 0.9905\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0414 - accuracy: 0.9927 - tp: 3149.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 38.0000 - precision: 0.9899 - recall: 0.9881 - auc: 0.9990 - prc: 0.9984\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0284 - accuracy: 0.9945 - tp: 3159.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 28.0000 - precision: 0.9921 - recall: 0.9912 - auc: 0.9991 - prc: 0.9981\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0227 - accuracy: 0.9963 - tp: 3166.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 21.0000 - precision: 0.9956 - recall: 0.9934 - auc: 0.9994 - prc: 0.9990\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0196 - accuracy: 0.9962 - tp: 3165.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 22.0000 - precision: 0.9956 - recall: 0.9931 - auc: 0.9995 - prc: 0.9992\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0193 - accuracy: 0.9967 - tp: 3167.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 20.0000 - precision: 0.9962 - recall: 0.9937 - auc: 0.9997 - prc: 0.9996\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0172 - accuracy: 0.9969 - tp: 3168.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 19.0000 - precision: 0.9965 - recall: 0.9940 - auc: 0.9995 - prc: 0.9992\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0163 - accuracy: 0.9967 - tp: 3167.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 20.0000 - precision: 0.9962 - recall: 0.9937 - auc: 0.9997 - prc: 0.9997\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0187 - accuracy: 0.9965 - tp: 3166.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 21.0000 - precision: 0.9962 - recall: 0.9934 - auc: 0.9997 - prc: 0.9993\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0130 - accuracy: 0.9974 - tp: 3172.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 15.0000 - precision: 0.9969 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.029666373506188393; accuracy of 99.34086799621582%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0240 - accuracy: 0.9935 - tp: 3153.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 34.0000 - precision: 0.9912 - recall: 0.9893 - auc: 0.9999 - prc: 0.9997\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0166 - accuracy: 0.9962 - tp: 3166.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 21.0000 - precision: 0.9953 - recall: 0.9934 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0119 - accuracy: 0.9976 - tp: 3172.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 15.0000 - precision: 0.9975 - recall: 0.9953 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0168 - accuracy: 0.9973 - tp: 3171.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 16.0000 - precision: 0.9969 - recall: 0.9950 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0155 - accuracy: 0.9971 - tp: 3172.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 15.0000 - precision: 0.9959 - recall: 0.9953 - auc: 0.9995 - prc: 0.9989\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0107 - accuracy: 0.9978 - tp: 3175.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 12.0000 - precision: 0.9972 - recall: 0.9962 - auc: 0.9998 - prc: 0.9997\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9982 - tp: 3178.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9978 - tp: 3176.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0060 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0068 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.007404860109090805; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9991 - tp: 3182.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3185.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.04647225886583328; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0692 - accuracy: 0.9856 - tp: 3118.0000 - fp: 69.0000 - tn: 6305.0000 - fn: 69.0000 - precision: 0.9783 - recall: 0.9783 - auc: 0.9965 - prc: 0.9934\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1488 - accuracy: 0.9669 - tp: 3018.0000 - fp: 147.0000 - tn: 6227.0000 - fn: 169.0000 - precision: 0.9536 - recall: 0.9470 - auc: 0.9925 - prc: 0.9864\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0450 - accuracy: 0.9923 - tp: 3147.0000 - fp: 34.0000 - tn: 6340.0000 - fn: 40.0000 - precision: 0.9893 - recall: 0.9874 - auc: 0.9993 - prc: 0.9987\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0143 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9974 - tp: 3174.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0069 - accuracy: 0.9977 - tp: 3175.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 12.0000 - precision: 0.9969 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.014210360124707222; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0058 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0051 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0055 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0039 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.0002379175421083346; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.01205740962177515; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.0289072934538126; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0054 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0276 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9996 - prc: 0.9992\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0406 - accuracy: 0.9906 - tp: 3142.0000 - fp: 45.0000 - tn: 6329.0000 - fn: 45.0000 - precision: 0.9859 - recall: 0.9859 - auc: 0.9991 - prc: 0.9985\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0221 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 0.9997 - prc: 0.9996\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0301 - accuracy: 0.9915 - tp: 3146.0000 - fp: 40.0000 - tn: 6334.0000 - fn: 41.0000 - precision: 0.9874 - recall: 0.9871 - auc: 0.9998 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0147 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9997 - prc: 0.9994\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0079 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0100 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 0.9998 - prc: 0.9998\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.5038195252418518; accuracy of 90.77212810516357%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0064 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0067 - accuracy: 0.9982 - tp: 3178.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0333 - accuracy: 0.9914 - tp: 3145.0000 - fp: 40.0000 - tn: 6334.0000 - fn: 42.0000 - precision: 0.9874 - recall: 0.9868 - auc: 0.9990 - prc: 0.9981\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0184 - accuracy: 0.9948 - tp: 3160.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 27.0000 - precision: 0.9928 - recall: 0.9915 - auc: 0.9999 - prc: 0.9998\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0126 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9995 - prc: 0.9990\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.008083926513791084; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5741217732429504 - Accuracy: 89.67136144638062%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.029666373506188393 - Accuracy: 99.34086799621582%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.007404860109090805 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.04647225886583328 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.014210360124707222 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.0002379175421083346 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.01205740962177515 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.0289072934538126 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.5038195252418518 - Accuracy: 90.77212810516357%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.008083926513791084 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 97.79011070728302 (+- 3.796604620471589)\n","> Loss: 0.12249816982221091\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 0.0035 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.8519 - accuracy: 0.9039 - tp: 2120.0000 - fp: 356.0000 - tn: 4602.0000 - fn: 359.0000 - precision: 0.8562 - recall: 0.8552 - auc: 0.9345 - prc: 0.8834\n","\n",">round 2  client 3 evaluation training metrics:\n","[0.0034695141948759556, 0.9988703727722168, 3535.0, 6.0, 7076.0, 6.0, 0.9983055591583252, 0.9983055591583252, 0.9999970197677612, 0.9999939203262329]\n","\n",">round 2  client 3 evaluation metrics:\n","[0.8519449234008789, 0.9038590788841248, 2120.0, 356.0, 4602.0, 359.0, 0.8562197089195251, 0.8551835417747498, 0.9344558119773865, 0.883358895778656]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.6016 - accuracy: 0.8662 - tp: 4220.0000 - fp: 829.0000 - tn: 10501.0000 - fn: 1445.0000 - precision: 0.8358 - recall: 0.7449 - auc: 0.9162 - prc: 0.8537\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.3762 - accuracy: 0.9030 - tp: 2576.0000 - fp: 317.0000 - tn: 6055.0000 - fn: 610.0000 - precision: 0.8904 - recall: 0.8085 - auc: 0.9629 - prc: 0.9372\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2881 - accuracy: 0.9336 - tp: 2806.0000 - fp: 255.0000 - tn: 6117.0000 - fn: 380.0000 - precision: 0.9167 - recall: 0.8807 - auc: 0.9777 - prc: 0.9602\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.2046 - accuracy: 0.9544 - tp: 2927.0000 - fp: 177.0000 - tn: 6195.0000 - fn: 259.0000 - precision: 0.9430 - recall: 0.9187 - auc: 0.9876 - prc: 0.9777\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1014 - accuracy: 0.9804 - tp: 3081.0000 - fp: 82.0000 - tn: 6290.0000 - fn: 105.0000 - precision: 0.9741 - recall: 0.9670 - auc: 0.9969 - prc: 0.9942\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0535 - accuracy: 0.9888 - tp: 3131.0000 - fp: 52.0000 - tn: 6320.0000 - fn: 55.0000 - precision: 0.9837 - recall: 0.9827 - auc: 0.9989 - prc: 0.9978\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0313 - accuracy: 0.9942 - tp: 3157.0000 - fp: 26.0000 - tn: 6346.0000 - fn: 29.0000 - precision: 0.9918 - recall: 0.9909 - auc: 0.9997 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0331 - accuracy: 0.9930 - tp: 3152.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 34.0000 - precision: 0.9896 - recall: 0.9893 - auc: 0.9994 - prc: 0.9989\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0335 - accuracy: 0.9939 - tp: 3157.0000 - fp: 29.0000 - tn: 6343.0000 - fn: 29.0000 - precision: 0.9909 - recall: 0.9909 - auc: 0.9991 - prc: 0.9986\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0612 - accuracy: 0.9871 - tp: 3122.0000 - fp: 59.0000 - tn: 6313.0000 - fn: 64.0000 - precision: 0.9815 - recall: 0.9799 - auc: 0.9983 - prc: 0.9971\n","Score for fold 1: loss of 0.5242490172386169; accuracy of 89.92466926574707%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1010 - accuracy: 0.9822 - tp: 3095.0000 - fp: 79.0000 - tn: 6293.0000 - fn: 91.0000 - precision: 0.9751 - recall: 0.9714 - auc: 0.9949 - prc: 0.9907\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0918 - accuracy: 0.9796 - tp: 3086.0000 - fp: 95.0000 - tn: 6277.0000 - fn: 100.0000 - precision: 0.9701 - recall: 0.9686 - auc: 0.9963 - prc: 0.9929\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0446 - accuracy: 0.9901 - tp: 3137.0000 - fp: 46.0000 - tn: 6326.0000 - fn: 49.0000 - precision: 0.9855 - recall: 0.9846 - auc: 0.9995 - prc: 0.9990\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0116 - accuracy: 0.9984 - tp: 3177.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 9.0000 - precision: 0.9981 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.050857558846473694; accuracy of 99.1525411605835%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0091 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9998 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0082 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0068 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0014999281847849488; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0006346494774334133; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.0001672541256994009; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.00034624739782884717; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 4.407039887155406e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4341e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.4177e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4041e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8058e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2735e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7016e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9916e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.3977e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2249e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.1180e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.010512983426451683; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7695e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3717e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7570e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6897e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2139e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9510e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3822e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9342e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8046e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.004055280704051256; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9235e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 5.3452349675353616e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5242490172386169 - Accuracy: 89.92466926574707%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.050857558846473694 - Accuracy: 99.1525411605835%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0014999281847849488 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0006346494774334133 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0001672541256994009 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.00034624739782884717 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 4.407039887155406e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.010512983426451683 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.004055280704051256 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 5.3452349675353616e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.87005567550659 (+- 2.9922177079647256)\n","> Loss: 0.05924204421498871\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 8.4284e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 13ms/step - loss: 1.0301 - accuracy: 0.9053 - tp: 2127.0000 - fp: 352.0000 - tn: 4606.0000 - fn: 352.0000 - precision: 0.8580 - recall: 0.8580 - auc: 0.9252 - prc: 0.8678\n","\n",">round 2  client 4 evaluation training metrics:\n","[0.0008428383152931929, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997019767761, 0.9999994039535522]\n","\n",">round 2  client 4 evaluation metrics:\n","[1.030079960823059, 0.9053381681442261, 2127.0, 352.0, 4606.0, 352.0, 0.8580072522163391, 0.8580072522163391, 0.9251630902290344, 0.8678070306777954]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.6052 - accuracy: 0.8660 - tp: 4192.0000 - fp: 804.0000 - tn: 10526.0000 - fn: 1473.0000 - precision: 0.8391 - recall: 0.7400 - auc: 0.9108 - prc: 0.8425\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.3798 - accuracy: 0.9033 - tp: 2592.0000 - fp: 330.0000 - tn: 6042.0000 - fn: 594.0000 - precision: 0.8871 - recall: 0.8136 - auc: 0.9621 - prc: 0.9341\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.2910 - accuracy: 0.9362 - tp: 2828.0000 - fp: 252.0000 - tn: 6120.0000 - fn: 358.0000 - precision: 0.9182 - recall: 0.8876 - auc: 0.9759 - prc: 0.9564\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2018 - accuracy: 0.9597 - tp: 2960.0000 - fp: 159.0000 - tn: 6213.0000 - fn: 226.0000 - precision: 0.9490 - recall: 0.9291 - auc: 0.9873 - prc: 0.9752\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1512 - accuracy: 0.9715 - tp: 3029.0000 - fp: 115.0000 - tn: 6257.0000 - fn: 157.0000 - precision: 0.9634 - recall: 0.9507 - auc: 0.9918 - prc: 0.9837\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0852 - accuracy: 0.9829 - tp: 3101.0000 - fp: 78.0000 - tn: 6294.0000 - fn: 85.0000 - precision: 0.9755 - recall: 0.9733 - auc: 0.9975 - prc: 0.9953\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0844 - accuracy: 0.9820 - tp: 3097.0000 - fp: 83.0000 - tn: 6289.0000 - fn: 89.0000 - precision: 0.9739 - recall: 0.9721 - auc: 0.9975 - prc: 0.9954\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0481 - accuracy: 0.9913 - tp: 3144.0000 - fp: 41.0000 - tn: 6331.0000 - fn: 42.0000 - precision: 0.9871 - recall: 0.9868 - auc: 0.9991 - prc: 0.9985\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0467 - accuracy: 0.9916 - tp: 3145.0000 - fp: 39.0000 - tn: 6333.0000 - fn: 41.0000 - precision: 0.9878 - recall: 0.9871 - auc: 0.9987 - prc: 0.9977\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0283 - accuracy: 0.9935 - tp: 3153.0000 - fp: 29.0000 - tn: 6343.0000 - fn: 33.0000 - precision: 0.9909 - recall: 0.9896 - auc: 0.9998 - prc: 0.9997\n","Score for fold 1: loss of 0.6303170323371887; accuracy of 89.5480215549469%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0820 - accuracy: 0.9860 - tp: 3115.0000 - fp: 63.0000 - tn: 6309.0000 - fn: 71.0000 - precision: 0.9802 - recall: 0.9777 - auc: 0.9954 - prc: 0.9923\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0421 - accuracy: 0.9929 - tp: 3147.0000 - fp: 29.0000 - tn: 6343.0000 - fn: 39.0000 - precision: 0.9909 - recall: 0.9878 - auc: 0.9986 - prc: 0.9976\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0313 - accuracy: 0.9942 - tp: 3156.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 30.0000 - precision: 0.9921 - recall: 0.9906 - auc: 0.9995 - prc: 0.9989\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0198 - accuracy: 0.9957 - tp: 3165.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0269 - accuracy: 0.9935 - tp: 3154.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 32.0000 - precision: 0.9906 - recall: 0.9900 - auc: 0.9998 - prc: 0.9996\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0484 - accuracy: 0.9892 - tp: 3131.0000 - fp: 48.0000 - tn: 6324.0000 - fn: 55.0000 - precision: 0.9849 - recall: 0.9827 - auc: 0.9989 - prc: 0.9985\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0146 - accuracy: 0.9976 - tp: 3172.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 14.0000 - precision: 0.9972 - recall: 0.9956 - auc: 0.9999 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0057 - accuracy: 0.9991 - tp: 3180.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9991 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0040 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.07474290579557419; accuracy of 98.49340915679932%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0708 - accuracy: 0.9862 - tp: 3118.0000 - fp: 64.0000 - tn: 6308.0000 - fn: 68.0000 - precision: 0.9799 - recall: 0.9787 - auc: 0.9975 - prc: 0.9959\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0617 - accuracy: 0.9888 - tp: 3127.0000 - fp: 48.0000 - tn: 6324.0000 - fn: 59.0000 - precision: 0.9849 - recall: 0.9815 - auc: 0.9988 - prc: 0.9978\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0171 - accuracy: 0.9968 - tp: 3170.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9992 - tp: 3181.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9991 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.044474560767412186; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0062 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0030 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0009622136130928993; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.00043690967140719295; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3019e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.0275e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.5479e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.3726e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1863e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2915e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8129e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.8445e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.4252e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.2498e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.004613526631146669; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.1308e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.9825e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1932e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.6745e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.6387e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1303e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1191e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3222e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6090e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.00011541238927748054; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.6767e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.5181e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.7692e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.9502e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.5089e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.8110e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7196e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.6642e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0375e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2998e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 6.830952042946592e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.0426e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2517e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.4615e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2683e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9337e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6441e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2095e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6608e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1069e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5816e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 2.2312065993901342e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.0828e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6405e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0490e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2704e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4927e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6544e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2217e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0050e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.5991e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.1402e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 1.9258739484939724e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.6303170323371887 - Accuracy: 89.5480215549469%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.07474290579557419 - Accuracy: 98.49340915679932%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.044474560767412186 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0009622136130928993 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.00043690967140719295 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.004613526631146669 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.00011541238927748054 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 6.830952042946592e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 2.2312065993901342e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 1.9258739484939724e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.67231607437134 (+- 3.0854247973402593)\n","> Loss: 0.07557724415310077\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 4.3939e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 11ms/step - loss: 1.1265 - accuracy: 0.8966 - tp: 2093.0000 - fp: 383.0000 - tn: 4575.0000 - fn: 386.0000 - precision: 0.8453 - recall: 0.8443 - auc: 0.9190 - prc: 0.8553\n","\n",">round 2  client 5 evaluation training metrics:\n","[0.0004393944691400975, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 2  client 5 evaluation metrics:\n","[1.1265326738357544, 0.8965981006622314, 2093.0, 383.0, 4575.0, 386.0, 0.8453150391578674, 0.8442920446395874, 0.9190319776535034, 0.8552515506744385]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 30ms/step - loss: 0.6164 - accuracy: 0.8604 - tp: 4139.0000 - fp: 847.0000 - tn: 10483.0000 - fn: 1526.0000 - precision: 0.8301 - recall: 0.7306 - auc: 0.9054 - prc: 0.8314\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.3942 - accuracy: 0.8981 - tp: 2576.0000 - fp: 364.0000 - tn: 6008.0000 - fn: 610.0000 - precision: 0.8762 - recall: 0.8085 - auc: 0.9585 - prc: 0.9269\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2970 - accuracy: 0.9331 - tp: 2808.0000 - fp: 261.0000 - tn: 6111.0000 - fn: 378.0000 - precision: 0.9150 - recall: 0.8814 - auc: 0.9749 - prc: 0.9540\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1996 - accuracy: 0.9642 - tp: 2993.0000 - fp: 149.0000 - tn: 6223.0000 - fn: 193.0000 - precision: 0.9526 - recall: 0.9394 - auc: 0.9862 - prc: 0.9736\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1372 - accuracy: 0.9745 - tp: 3054.0000 - fp: 112.0000 - tn: 6260.0000 - fn: 132.0000 - precision: 0.9646 - recall: 0.9586 - auc: 0.9924 - prc: 0.9843\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1165 - accuracy: 0.9779 - tp: 3063.0000 - fp: 88.0000 - tn: 6284.0000 - fn: 123.0000 - precision: 0.9721 - recall: 0.9614 - auc: 0.9944 - prc: 0.9888\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0783 - accuracy: 0.9862 - tp: 3116.0000 - fp: 62.0000 - tn: 6310.0000 - fn: 70.0000 - precision: 0.9805 - recall: 0.9780 - auc: 0.9975 - prc: 0.9952\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0771 - accuracy: 0.9837 - tp: 3106.0000 - fp: 76.0000 - tn: 6296.0000 - fn: 80.0000 - precision: 0.9761 - recall: 0.9749 - auc: 0.9982 - prc: 0.9969\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0550 - accuracy: 0.9881 - tp: 3129.0000 - fp: 57.0000 - tn: 6315.0000 - fn: 57.0000 - precision: 0.9821 - recall: 0.9821 - auc: 0.9987 - prc: 0.9975\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0263 - accuracy: 0.9942 - tp: 3158.0000 - fp: 27.0000 - tn: 6345.0000 - fn: 28.0000 - precision: 0.9915 - recall: 0.9912 - auc: 0.9999 - prc: 0.9997\n","Score for fold 1: loss of 0.6368659734725952; accuracy of 88.7005627155304%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0901 - accuracy: 0.9847 - tp: 3111.0000 - fp: 71.0000 - tn: 6301.0000 - fn: 75.0000 - precision: 0.9777 - recall: 0.9765 - auc: 0.9953 - prc: 0.9920\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0443 - accuracy: 0.9918 - tp: 3145.0000 - fp: 37.0000 - tn: 6335.0000 - fn: 41.0000 - precision: 0.9884 - recall: 0.9871 - auc: 0.9991 - prc: 0.9983\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0233 - accuracy: 0.9959 - tp: 3165.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 21.0000 - precision: 0.9943 - recall: 0.9934 - auc: 0.9998 - prc: 0.9997\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0149 - accuracy: 0.9978 - tp: 3172.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 14.0000 - precision: 0.9978 - recall: 0.9956 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0098 - accuracy: 0.9980 - tp: 3174.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 12.0000 - precision: 0.9978 - recall: 0.9962 - auc: 0.9997 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0072 - accuracy: 0.9984 - tp: 3176.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 10.0000 - precision: 0.9984 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9983 - tp: 3176.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 10.0000 - precision: 0.9981 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0133 - accuracy: 0.9974 - tp: 3170.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 16.0000 - precision: 0.9972 - recall: 0.9950 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0099 - accuracy: 0.9982 - tp: 3175.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 11.0000 - precision: 0.9981 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0042 - accuracy: 0.9992 - tp: 3180.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 6.0000 - precision: 0.9994 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.02592220902442932; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0204 - accuracy: 0.9952 - tp: 3161.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 25.0000 - precision: 0.9934 - recall: 0.9922 - auc: 0.9999 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0598 - accuracy: 0.9891 - tp: 3129.0000 - fp: 47.0000 - tn: 6325.0000 - fn: 57.0000 - precision: 0.9852 - recall: 0.9821 - auc: 0.9983 - prc: 0.9967\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0178 - accuracy: 0.9970 - tp: 3171.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0093 - accuracy: 0.9986 - tp: 3178.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 8.0000 - precision: 0.9984 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0187 - accuracy: 0.9961 - tp: 3166.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9947 - recall: 0.9937 - auc: 0.9999 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9993 - tp: 3181.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 5.0000 - precision: 0.9994 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0106 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9997 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0061 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0065 - accuracy: 0.9992 - tp: 3181.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9991 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.029635213315486908; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6504e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.2650e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.2978e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.5741e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.0570e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 3.4190e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 3.0839e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.7500e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.025041228160262108; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8689e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.9710e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.2775e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.6358e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.3328e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 2.0570e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.9009e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 1.7632e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 1.6598e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.01846529357135296; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.2648 - accuracy: 0.9628 - tp: 3003.0000 - fp: 173.0000 - tn: 6199.0000 - fn: 183.0000 - precision: 0.9455 - recall: 0.9426 - auc: 0.9827 - prc: 0.9684\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.1838 - accuracy: 0.9621 - tp: 2989.0000 - fp: 165.0000 - tn: 6207.0000 - fn: 197.0000 - precision: 0.9477 - recall: 0.9382 - auc: 0.9883 - prc: 0.9769\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0805 - accuracy: 0.9848 - tp: 3106.0000 - fp: 65.0000 - tn: 6307.0000 - fn: 80.0000 - precision: 0.9795 - recall: 0.9749 - auc: 0.9972 - prc: 0.9940\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0354 - accuracy: 0.9935 - tp: 3152.0000 - fp: 28.0000 - tn: 6344.0000 - fn: 34.0000 - precision: 0.9912 - recall: 0.9893 - auc: 0.9993 - prc: 0.9986\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0147 - accuracy: 0.9976 - tp: 3171.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 15.0000 - precision: 0.9975 - recall: 0.9953 - auc: 0.9997 - prc: 0.9994\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0074 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0063 - accuracy: 0.9990 - tp: 3180.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0049 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.09357551485300064; accuracy of 98.21092486381531%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0089 - accuracy: 0.9982 - tp: 3177.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 0.9992 - tp: 3181.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9991 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.003716291394084692; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0018 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0015 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000   \n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.0004957569763064384; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.4317e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.4167e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8159e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.1948e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.4808e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.8242e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4426e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.8828e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.4688e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.0028540485072880983; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.7168e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6844e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.7936e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.5660e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.0962e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0999e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.7326e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.1334e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0006e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.1864e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Score for fold 10: loss of 6.527253572130576e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.6368659734725952 - Accuracy: 88.7005627155304%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.02592220902442932 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.029635213315486908 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.025041228160262108 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.01846529357135296 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.09357551485300064 - Accuracy: 98.21092486381531%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.003716291394084692 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.0004957569763064384 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.0028540485072880983 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 6.527253572130576e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.45574259757996 (+- 3.2911458605023225)\n","> Loss: 0.08366368018105277\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 6.7238e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 1.0100 - accuracy: 0.9103 - tp: 2143.0000 - fp: 331.0000 - tn: 4627.0000 - fn: 336.0000 - precision: 0.8662 - recall: 0.8645 - auc: 0.9250 - prc: 0.8645\n","\n",">round 2  client 6 evaluation training metrics:\n","[0.0006723786354996264, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999998807907104, 0.9999997019767761]\n","\n",">round 2  client 6 evaluation metrics:\n","[1.0099608898162842, 0.9103133082389832, 2143.0, 331.0, 4627.0, 336.0, 0.866208553314209, 0.8644614815711975, 0.9249801635742188, 0.8644764423370361]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.5954 - accuracy: 0.8708 - tp: 4212.0000 - fp: 743.0000 - tn: 10587.0000 - fn: 1453.0000 - precision: 0.8501 - recall: 0.7435 - auc: 0.9136 - prc: 0.8443\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.3915 - accuracy: 0.8941 - tp: 2493.0000 - fp: 319.0000 - tn: 6053.0000 - fn: 693.0000 - precision: 0.8866 - recall: 0.7825 - auc: 0.9594 - prc: 0.9289\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3014 - accuracy: 0.9334 - tp: 2787.0000 - fp: 238.0000 - tn: 6134.0000 - fn: 399.0000 - precision: 0.9213 - recall: 0.8748 - auc: 0.9751 - prc: 0.9535\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.2031 - accuracy: 0.9582 - tp: 2961.0000 - fp: 175.0000 - tn: 6197.0000 - fn: 225.0000 - precision: 0.9442 - recall: 0.9294 - auc: 0.9870 - prc: 0.9754\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1417 - accuracy: 0.9751 - tp: 3057.0000 - fp: 109.0000 - tn: 6263.0000 - fn: 129.0000 - precision: 0.9656 - recall: 0.9595 - auc: 0.9921 - prc: 0.9848\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0928 - accuracy: 0.9823 - tp: 3092.0000 - fp: 75.0000 - tn: 6297.0000 - fn: 94.0000 - precision: 0.9763 - recall: 0.9705 - auc: 0.9956 - prc: 0.9914\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0750 - accuracy: 0.9852 - tp: 3105.0000 - fp: 60.0000 - tn: 6312.0000 - fn: 81.0000 - precision: 0.9810 - recall: 0.9746 - auc: 0.9981 - prc: 0.9965\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0460 - accuracy: 0.9910 - tp: 3137.0000 - fp: 37.0000 - tn: 6335.0000 - fn: 49.0000 - precision: 0.9883 - recall: 0.9846 - auc: 0.9990 - prc: 0.9982\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0350 - accuracy: 0.9938 - tp: 3151.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 35.0000 - precision: 0.9924 - recall: 0.9890 - auc: 0.9992 - prc: 0.9985\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0821 - accuracy: 0.9810 - tp: 3090.0000 - fp: 86.0000 - tn: 6286.0000 - fn: 96.0000 - precision: 0.9729 - recall: 0.9699 - auc: 0.9979 - prc: 0.9959\n","Score for fold 1: loss of 0.5206934809684753; accuracy of 90.48964381217957%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1419 - accuracy: 0.9678 - tp: 3023.0000 - fp: 145.0000 - tn: 6227.0000 - fn: 163.0000 - precision: 0.9542 - recall: 0.9488 - auc: 0.9933 - prc: 0.9877\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0614 - accuracy: 0.9893 - tp: 3128.0000 - fp: 44.0000 - tn: 6328.0000 - fn: 58.0000 - precision: 0.9861 - recall: 0.9818 - auc: 0.9983 - prc: 0.9969\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0335 - accuracy: 0.9942 - tp: 3152.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 34.0000 - precision: 0.9934 - recall: 0.9893 - auc: 0.9995 - prc: 0.9992\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0156 - accuracy: 0.9980 - tp: 3173.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 13.0000 - precision: 0.9981 - recall: 0.9959 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9981 - tp: 3175.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 11.0000 - precision: 0.9978 - recall: 0.9965 - auc: 0.9998 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0103 - accuracy: 0.9978 - tp: 3172.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 14.0000 - precision: 0.9978 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0072 - accuracy: 0.9984 - tp: 3175.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 11.0000 - precision: 0.9987 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0073 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0064 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0053 - accuracy: 0.9982 - tp: 3174.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 12.0000 - precision: 0.9984 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.04919253662228584; accuracy of 98.49340915679932%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0091 - accuracy: 0.9975 - tp: 3168.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 18.0000 - precision: 0.9981 - recall: 0.9944 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0344 - accuracy: 0.9916 - tp: 3140.0000 - fp: 34.0000 - tn: 6338.0000 - fn: 46.0000 - precision: 0.9893 - recall: 0.9856 - auc: 0.9990 - prc: 0.9980\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0420 - accuracy: 0.9896 - tp: 3131.0000 - fp: 44.0000 - tn: 6328.0000 - fn: 55.0000 - precision: 0.9861 - recall: 0.9827 - auc: 0.9995 - prc: 0.9991\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0178 - accuracy: 0.9956 - tp: 3161.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 25.0000 - precision: 0.9947 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0102 - accuracy: 0.9979 - tp: 3171.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 15.0000 - precision: 0.9984 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0096 - accuracy: 0.9980 - tp: 3174.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 12.0000 - precision: 0.9978 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0065 - accuracy: 0.9984 - tp: 3174.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0066 - accuracy: 0.9978 - tp: 3174.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 12.0000 - precision: 0.9972 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0362 - accuracy: 0.9918 - tp: 3141.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 45.0000 - precision: 0.9896 - recall: 0.9859 - auc: 0.9989 - prc: 0.9982\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0238 - accuracy: 0.9945 - tp: 3156.0000 - fp: 23.0000 - tn: 6349.0000 - fn: 30.0000 - precision: 0.9928 - recall: 0.9906 - auc: 0.9996 - prc: 0.9993\n","Score for fold 3: loss of 0.017232950776815414; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0082 - accuracy: 0.9982 - tp: 3174.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 12.0000 - precision: 0.9984 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9977 - tp: 3174.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9969 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0122 - accuracy: 0.9961 - tp: 3166.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9947 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0352 - accuracy: 0.9923 - tp: 3148.0000 - fp: 36.0000 - tn: 6336.0000 - fn: 38.0000 - precision: 0.9887 - recall: 0.9881 - auc: 0.9994 - prc: 0.9989\n","Epoch 5/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0340 - accuracy: 0.9916 - tp: 3144.0000 - fp: 38.0000 - tn: 6334.0000 - fn: 42.0000 - precision: 0.9881 - recall: 0.9868 - auc: 0.9992 - prc: 0.9985\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0107 - accuracy: 0.9978 - tp: 3175.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0026696259155869484; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.0002257594169350341; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.0001144433263107203; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.7596e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.6007e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3770e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6917e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.2791e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.7998e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.2005e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.0325e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.3096e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.0039946408942341805; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 7.6574448030442e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 7.235436351038516e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3863e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.0534e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.2504e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.3846e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.4593e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.5085e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.0604e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9975e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3450e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3730e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.013117823749780655; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5206934809684753 - Accuracy: 90.48964381217957%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.04919253662228584 - Accuracy: 98.49340915679932%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.017232950776815414 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0026696259155869484 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0002257594169350341 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.0001144433263107203 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0039946408942341805 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 7.6574448030442e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 7.235436351038516e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.013117823749780655 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.8229751586914 (+- 2.8120386467747016)\n","> Loss: 0.060739019048196494\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 1.1374 - accuracy: 0.9037 - tp: 2120.0000 - fp: 357.0000 - tn: 4601.0000 - fn: 359.0000 - precision: 0.8559 - recall: 0.8552 - auc: 0.9160 - prc: 0.8502\n","\n",">round 2  client 7 evaluation training metrics:\n","[0.001739773084409535, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999995231628418, 0.9999991655349731]\n","\n",">round 2  client 7 evaluation metrics:\n","[1.1373670101165771, 0.9037246108055115, 2120.0, 357.0, 4601.0, 359.0, 0.8558740615844727, 0.8551835417747498, 0.9159884452819824, 0.8502066731452942]\n","\n","=============================================================\n","\n","> round 2 average training auc= 0.24811680283489843\n","> round 2 average training loss= 0.08484845394211463\n","> round 2 average epoch count= 10.0\n","10/78 [==>...........................] - ETA: 0s"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["78/78 [==============================] - 0s 5ms/step\n","> round 2 test auc= 0.3728707692026302\n","111/111 [==============================] - 1s 7ms/step - loss: 4.3913 - accuracy: 0.5907 - tp: 1362.0000 - fp: 2169.0000 - tn: 4913.0000 - fn: 2179.0000 - precision: 0.3857 - recall: 0.3846 - auc: 0.5532 - prc: 0.3663\n","\n","> round 2 final model training loss_metric= [4.391294956207275]\n","> round 2 final model training TP_metric= [1362.0]\n","> round 2 final model training FP_metric= [2169.0]\n","> round 2 final model training TN_metric= [4913.0]\n","> round 2 final model training FN_metric= [2179.0]\n","> round 2 final model training accuracy_metric= [59.06994342803955]\n","> round 2 final model training precision_metric= [38.57264220714569]\n","> round 2 final model training recall_metric = [38.463711738586426]\n","> round 2 final model training auc_metric= [0.5532016158103943]\n","> round 2 final model training prc_metric= [0.3663180470466614]\n","\n","78/78 [==============================] - 1s 8ms/step - loss: 4.2423 - accuracy: 0.6013 - tp: 994.0000 - fp: 1480.0000 - tn: 3478.0000 - fn: 1485.0000 - precision: 0.4018 - recall: 0.4010 - auc: 0.5744 - prc: 0.3800\n","> round 2 final model loss_metric= [4.242292881011963]\n","> round 2 final model TP_metric= [994.0]\n","> round 2 final model FP_metric= [1480.0]\n","> round 2 final model TN_metric= [3478.0]\n","> round 2 final model FN_metric= [1485.0]\n","> round 2 final model accuracy_metric= [60.131776332855225]\n","> round 2 final model precision_metric= [40.17784893512726]\n","> round 2 final model recall_metric = [40.096813440322876]\n","> round 2 final model auc_metric= [0.5743519067764282]\n","> round 2 final model prc_metric= [0.37997058033943176]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 3 start, random seed= 3\n","\n","> client 1 started learning...........\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 28ms/step - loss: 0.4887 - accuracy: 0.7729 - tp: 3691.0000 - fp: 1886.0000 - tn: 9444.0000 - fn: 1974.0000 - precision: 0.6618 - recall: 0.6515 - auc: 0.7649 - prc: 0.5952\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.2103 - accuracy: 0.9548 - tp: 2926.0000 - fp: 172.0000 - tn: 6200.0000 - fn: 260.0000 - precision: 0.9445 - recall: 0.9184 - auc: 0.9885 - prc: 0.9796\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.1195 - accuracy: 0.9750 - tp: 3051.0000 - fp: 104.0000 - tn: 6268.0000 - fn: 135.0000 - precision: 0.9670 - recall: 0.9576 - auc: 0.9958 - prc: 0.9920\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0544 - accuracy: 0.9906 - tp: 3131.0000 - fp: 35.0000 - tn: 6337.0000 - fn: 55.0000 - precision: 0.9889 - recall: 0.9827 - auc: 0.9992 - prc: 0.9983\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0228 - accuracy: 0.9963 - tp: 3160.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 26.0000 - precision: 0.9972 - recall: 0.9918 - auc: 0.9997 - prc: 0.9993\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0138 - accuracy: 0.9980 - tp: 3172.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 14.0000 - precision: 0.9984 - recall: 0.9956 - auc: 0.9997 - prc: 0.9995\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0147 - accuracy: 0.9976 - tp: 3169.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 17.0000 - precision: 0.9981 - recall: 0.9947 - auc: 0.9997 - prc: 0.9994\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0167 - accuracy: 0.9969 - tp: 3167.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 19.0000 - precision: 0.9965 - recall: 0.9940 - auc: 0.9999 - prc: 0.9998\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0070 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0058 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.5673770308494568; accuracy of 92.20657348632812%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0683 - accuracy: 0.9874 - tp: 3121.0000 - fp: 54.0000 - tn: 6320.0000 - fn: 66.0000 - precision: 0.9830 - recall: 0.9793 - auc: 0.9970 - prc: 0.9945\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0527 - accuracy: 0.9877 - tp: 3123.0000 - fp: 54.0000 - tn: 6320.0000 - fn: 64.0000 - precision: 0.9830 - recall: 0.9799 - auc: 0.9990 - prc: 0.9980\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0712 - accuracy: 0.9827 - tp: 3096.0000 - fp: 74.0000 - tn: 6300.0000 - fn: 91.0000 - precision: 0.9767 - recall: 0.9714 - auc: 0.9984 - prc: 0.9969\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0421 - accuracy: 0.9903 - tp: 3132.0000 - fp: 38.0000 - tn: 6336.0000 - fn: 55.0000 - precision: 0.9880 - recall: 0.9827 - auc: 0.9991 - prc: 0.9985\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0249 - accuracy: 0.9942 - tp: 3156.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 31.0000 - precision: 0.9925 - recall: 0.9903 - auc: 0.9998 - prc: 0.9997\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0065 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0052 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0049 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0049 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0049 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.07096215337514877; accuracy of 97.83427715301514%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0129 - accuracy: 0.9963 - tp: 3166.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 21.0000 - precision: 0.9956 - recall: 0.9934 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0283 - accuracy: 0.9939 - tp: 3154.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 33.0000 - precision: 0.9921 - recall: 0.9896 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 0.9973 - tp: 3170.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 17.0000 - precision: 0.9972 - recall: 0.9947 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0138 - accuracy: 0.9965 - tp: 3164.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 23.0000 - precision: 0.9968 - recall: 0.9928 - auc: 0.9997 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0072 - accuracy: 0.9984 - tp: 3176.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9987 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0269 - accuracy: 0.9934 - tp: 3151.0000 - fp: 27.0000 - tn: 6347.0000 - fn: 36.0000 - precision: 0.9915 - recall: 0.9887 - auc: 0.9996 - prc: 0.9995\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0105 - accuracy: 0.9977 - tp: 3174.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 13.0000 - precision: 0.9972 - recall: 0.9959 - auc: 0.9997 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0065 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3179.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 8.0000 - precision: 0.9987 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.014857510104775429; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0054 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.00846897903829813; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0055 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3175.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 12.0000 - precision: 0.9997 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0045 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.0001423474313924089; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.006459834054112434; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9982 - tp: 3173.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 14.0000 - precision: 0.9991 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0063 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0059 - accuracy: 0.9984 - tp: 3173.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 14.0000 - precision: 0.9997 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9986 - tp: 3175.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 12.0000 - precision: 0.9997 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0049 - accuracy: 0.9982 - tp: 3173.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 14.0000 - precision: 0.9991 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0048 - accuracy: 0.9986 - tp: 3175.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 12.0000 - precision: 0.9997 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0052 - accuracy: 0.9982 - tp: 3173.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 14.0000 - precision: 0.9991 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9987 - tp: 3175.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 12.0000 - precision: 1.0000 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3175.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 12.0000 - precision: 0.9997 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.0001523399114375934; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0035 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.008418476209044456; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9984 - tp: 3174.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 13.0000 - precision: 0.9994 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9984 - tp: 3174.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 13.0000 - precision: 0.9994 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.0019192604813724756; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0033 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.01626143977046013; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5673770308494568 - Accuracy: 92.20657348632812%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.07096215337514877 - Accuracy: 97.83427715301514%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.014857510104775429 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00846897903829813 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0001423474313924089 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.006459834054112434 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0001523399114375934 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.008418476209044456 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.0019192604813724756 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.01626143977046013 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.88167381286621 (+- 2.307582707738891)\n","> Loss: 0.06950193712254986\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 4ms/step\n","111/111 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9988 - tp: 3529.0000 - fp: 1.0000 - tn: 7081.0000 - fn: 12.0000 - precision: 0.9997 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 8ms/step - loss: 0.8107 - accuracy: 0.9281 - tp: 2208.0000 - fp: 264.0000 - tn: 4694.0000 - fn: 271.0000 - precision: 0.8932 - recall: 0.8907 - auc: 0.9432 - prc: 0.8961\n","\n",">round 3  client 1 evaluation training metrics:\n","[0.004519749898463488, 0.9987762570381165, 3529.0, 1.0, 7081.0, 12.0, 0.9997166991233826, 0.9966111183166504, 0.9999945163726807, 0.9999889731407166]\n","\n",">round 3  client 1 evaluation metrics:\n","[0.8106610178947449, 0.928062379360199, 2208.0, 264.0, 4694.0, 271.0, 0.893203854560852, 0.8906817436218262, 0.9432123899459839, 0.8960852026939392]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.5429 - accuracy: 0.9014 - tp: 4767.0000 - fp: 777.0000 - tn: 10553.0000 - fn: 898.0000 - precision: 0.8598 - recall: 0.8415 - auc: 0.9414 - prc: 0.8925\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.2773 - accuracy: 0.9356 - tp: 2813.0000 - fp: 243.0000 - tn: 6129.0000 - fn: 373.0000 - precision: 0.9205 - recall: 0.8829 - auc: 0.9810 - prc: 0.9655\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1544 - accuracy: 0.9643 - tp: 2982.0000 - fp: 137.0000 - tn: 6235.0000 - fn: 204.0000 - precision: 0.9561 - recall: 0.9360 - auc: 0.9940 - prc: 0.9889\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0553 - accuracy: 0.9899 - tp: 3126.0000 - fp: 37.0000 - tn: 6335.0000 - fn: 60.0000 - precision: 0.9883 - recall: 0.9812 - auc: 0.9993 - prc: 0.9985\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0860 - accuracy: 0.9798 - tp: 3080.0000 - fp: 87.0000 - tn: 6285.0000 - fn: 106.0000 - precision: 0.9725 - recall: 0.9667 - auc: 0.9973 - prc: 0.9949\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0757 - accuracy: 0.9839 - tp: 3100.0000 - fp: 68.0000 - tn: 6304.0000 - fn: 86.0000 - precision: 0.9785 - recall: 0.9730 - auc: 0.9981 - prc: 0.9965\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0320 - accuracy: 0.9933 - tp: 3146.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 40.0000 - precision: 0.9924 - recall: 0.9874 - auc: 0.9998 - prc: 0.9996\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0192 - accuracy: 0.9944 - tp: 3152.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 34.0000 - precision: 0.9937 - recall: 0.9893 - auc: 0.9999 - prc: 0.9998\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0159 - accuracy: 0.9944 - tp: 3155.0000 - fp: 23.0000 - tn: 6349.0000 - fn: 31.0000 - precision: 0.9928 - recall: 0.9903 - auc: 0.9999 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0142 - accuracy: 0.9954 - tp: 3161.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 25.0000 - precision: 0.9940 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 0.4824962913990021; accuracy of 91.26760363578796%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1576 - accuracy: 0.9669 - tp: 3021.0000 - fp: 150.0000 - tn: 6224.0000 - fn: 166.0000 - precision: 0.9527 - recall: 0.9479 - auc: 0.9913 - prc: 0.9833\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0474 - accuracy: 0.9891 - tp: 3133.0000 - fp: 50.0000 - tn: 6324.0000 - fn: 54.0000 - precision: 0.9843 - recall: 0.9831 - auc: 0.9996 - prc: 0.9992\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0214 - accuracy: 0.9949 - tp: 3161.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 26.0000 - precision: 0.9928 - recall: 0.9918 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0185 - accuracy: 0.9944 - tp: 3160.0000 - fp: 27.0000 - tn: 6347.0000 - fn: 27.0000 - precision: 0.9915 - recall: 0.9915 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0156 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0177 - accuracy: 0.9946 - tp: 3161.0000 - fp: 26.0000 - tn: 6348.0000 - fn: 26.0000 - precision: 0.9918 - recall: 0.9918 - auc: 0.9999 - prc: 0.9998\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0137 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0145 - accuracy: 0.9939 - tp: 3158.0000 - fp: 29.0000 - tn: 6345.0000 - fn: 29.0000 - precision: 0.9909 - recall: 0.9909 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0115 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0115 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.014791558496654034; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0146 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 0.9997 - prc: 0.9994\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0794 - accuracy: 0.9813 - tp: 3094.0000 - fp: 86.0000 - tn: 6288.0000 - fn: 93.0000 - precision: 0.9730 - recall: 0.9708 - auc: 0.9974 - prc: 0.9955\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0319 - accuracy: 0.9923 - tp: 3150.0000 - fp: 37.0000 - tn: 6337.0000 - fn: 37.0000 - precision: 0.9884 - recall: 0.9884 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0201 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0163 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0114 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Score for fold 3: loss of 0.05118509754538536; accuracy of 98.96422028541565%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0343 - accuracy: 0.9911 - tp: 3143.0000 - fp: 41.0000 - tn: 6333.0000 - fn: 44.0000 - precision: 0.9871 - recall: 0.9862 - auc: 0.9990 - prc: 0.9981\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0195 - accuracy: 0.9946 - tp: 3160.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 27.0000 - precision: 0.9922 - recall: 0.9915 - auc: 0.9999 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0119 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0235 - accuracy: 0.9917 - tp: 3147.0000 - fp: 39.0000 - tn: 6335.0000 - fn: 40.0000 - precision: 0.9878 - recall: 0.9874 - auc: 0.9998 - prc: 0.9997\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0405 - accuracy: 0.9902 - tp: 3139.0000 - fp: 46.0000 - tn: 6328.0000 - fn: 48.0000 - precision: 0.9856 - recall: 0.9849 - auc: 0.9992 - prc: 0.9986\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0324 - accuracy: 0.9912 - tp: 3143.0000 - fp: 40.0000 - tn: 6334.0000 - fn: 44.0000 - precision: 0.9874 - recall: 0.9862 - auc: 0.9997 - prc: 0.9994\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0389 - accuracy: 0.9901 - tp: 3136.0000 - fp: 44.0000 - tn: 6330.0000 - fn: 51.0000 - precision: 0.9862 - recall: 0.9840 - auc: 0.9993 - prc: 0.9987\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0119 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0099 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0098 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.03915516287088394; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0192 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9999 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0125 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0117 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0090 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0092 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0139 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0092 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0089 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Score for fold 5: loss of 0.014060219749808311; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0098 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0096 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0092 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0092 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0093 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.004179874900728464; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0079 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0077 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0077 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0075 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0077 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.02863006293773651; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 0.9998 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0162 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0232 - accuracy: 0.9941 - tp: 3159.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 28.0000 - precision: 0.9912 - recall: 0.9912 - auc: 0.9996 - prc: 0.9993\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0305 - accuracy: 0.9918 - tp: 3146.0000 - fp: 37.0000 - tn: 6337.0000 - fn: 41.0000 - precision: 0.9884 - recall: 0.9871 - auc: 0.9997 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0273 - accuracy: 0.9924 - tp: 3150.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 37.0000 - precision: 0.9887 - recall: 0.9884 - auc: 0.9998 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0807 - accuracy: 0.9823 - tp: 3102.0000 - fp: 84.0000 - tn: 6290.0000 - fn: 85.0000 - precision: 0.9736 - recall: 0.9733 - auc: 0.9958 - prc: 0.9919\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0680 - accuracy: 0.9831 - tp: 3104.0000 - fp: 79.0000 - tn: 6295.0000 - fn: 83.0000 - precision: 0.9752 - recall: 0.9740 - auc: 0.9983 - prc: 0.9966\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0150 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0097 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0087 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.043071068823337555; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0127 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0107 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0130 - accuracy: 0.9941 - tp: 3159.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 28.0000 - precision: 0.9912 - recall: 0.9912 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0119 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 0.9957 - tp: 3166.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0090 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0090 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0085 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0083 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 9: loss of 0.008198832161724567; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0083 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9970 - tp: 3172.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.013666873797774315; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.4824962913990021 - Accuracy: 91.26760363578796%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.014791558496654034 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.05118509754538536 - Accuracy: 98.96422028541565%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.03915516287088394 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.014060219749808311 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.004179874900728464 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.02863006293773651 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.043071068823337555 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.008198832161724567 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.013666873797774315 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.59003603458405 (+- 2.4675454699231794)\n","> Loss: 0.06994350426830351\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","78/78 [==============================] - 1s 8ms/step - loss: 0.7828 - accuracy: 0.9227 - tp: 2189.0000 - fp: 285.0000 - tn: 4673.0000 - fn: 290.0000 - precision: 0.8848 - recall: 0.8830 - auc: 0.9444 - prc: 0.8968\n","\n",">round 3  client 2 evaluation training metrics:\n","[0.007940065115690231, 0.9966111183166504, 3523.0, 18.0, 7064.0, 18.0, 0.9949166774749756, 0.9949166774749756, 0.9999731183052063, 0.9999464154243469]\n","\n",">round 3  client 2 evaluation metrics:\n","[0.7828157544136047, 0.9226838946342468, 2189.0, 285.0, 4673.0, 290.0, 0.8848019242286682, 0.883017361164093, 0.9443500638008118, 0.8968037366867065]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 10s 28ms/step - loss: 0.4076 - accuracy: 0.9206 - tp: 4970.0000 - fp: 654.0000 - tn: 10676.0000 - fn: 695.0000 - precision: 0.8837 - recall: 0.8773 - auc: 0.9531 - prc: 0.9116\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1699 - accuracy: 0.9622 - tp: 2981.0000 - fp: 156.0000 - tn: 6216.0000 - fn: 205.0000 - precision: 0.9503 - recall: 0.9357 - auc: 0.9924 - prc: 0.9862\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0851 - accuracy: 0.9837 - tp: 3102.0000 - fp: 72.0000 - tn: 6300.0000 - fn: 84.0000 - precision: 0.9773 - recall: 0.9736 - auc: 0.9981 - prc: 0.9965\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0341 - accuracy: 0.9953 - tp: 3162.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 24.0000 - precision: 0.9934 - recall: 0.9925 - auc: 0.9994 - prc: 0.9989\n","Epoch 5/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0441 - accuracy: 0.9919 - tp: 3146.0000 - fp: 37.0000 - tn: 6335.0000 - fn: 40.0000 - precision: 0.9884 - recall: 0.9874 - auc: 0.9980 - prc: 0.9960\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0324 - accuracy: 0.9957 - tp: 3165.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 0.9993 - prc: 0.9988\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0170 - accuracy: 0.9971 - tp: 3170.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 16.0000 - precision: 0.9962 - recall: 0.9950 - auc: 0.9998 - prc: 0.9997\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0129 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9997 - prc: 0.9994\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0109 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9998 - prc: 0.9998\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.351717472076416; accuracy of 94.17840242385864%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0611 - accuracy: 0.9882 - tp: 3130.0000 - fp: 56.0000 - tn: 6318.0000 - fn: 57.0000 - precision: 0.9824 - recall: 0.9821 - auc: 0.9971 - prc: 0.9947\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0188 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0145 - accuracy: 0.9975 - tp: 3174.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 13.0000 - precision: 0.9965 - recall: 0.9959 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0217 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 0.9996 - prc: 0.9992\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0148 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0070 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0056 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0058 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.03703216090798378; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0106 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2392 - accuracy: 0.9480 - tp: 2926.0000 - fp: 236.0000 - tn: 6138.0000 - fn: 261.0000 - precision: 0.9254 - recall: 0.9181 - auc: 0.9841 - prc: 0.9729\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1432 - accuracy: 0.9689 - tp: 3016.0000 - fp: 126.0000 - tn: 6248.0000 - fn: 171.0000 - precision: 0.9599 - recall: 0.9463 - auc: 0.9938 - prc: 0.9884\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0287 - accuracy: 0.9953 - tp: 3163.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 24.0000 - precision: 0.9934 - recall: 0.9925 - auc: 0.9999 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0116 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0074 - accuracy: 0.9984 - tp: 3179.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0062 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0065 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.10374902933835983; accuracy of 97.74011373519897%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0205 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 0.9997 - prc: 0.9996\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9978 - tp: 3176.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0062 - accuracy: 0.9979 - tp: 3176.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 11.0000 - precision: 0.9972 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 0.9982 - tp: 3178.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 0.9998 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0070 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0054 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0054 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0057 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.010915900580585003; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0053 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0053 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3179.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 8.0000 - precision: 0.9981 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9990 - tp: 3181.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9987 - tp: 3180.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 7.0000 - precision: 0.9984 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3180.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 7.0000 - precision: 0.9984 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3179.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 8.0000 - precision: 0.9981 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9986 - tp: 3179.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 8.0000 - precision: 0.9984 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.017771853134036064; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0051 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9991 - tp: 3182.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0049 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9991 - tp: 3182.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9990 - tp: 3181.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.012873688712716103; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0050 - accuracy: 0.9985 - tp: 3179.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 8.0000 - precision: 0.9981 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3180.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 7.0000 - precision: 0.9984 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9991 - tp: 3182.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.011855494230985641; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.0012219081399962306; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.01132921315729618; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0034 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0033 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0030 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.0020964874420315027; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.351717472076416 - Accuracy: 94.17840242385864%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03703216090798378 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.10374902933835983 - Accuracy: 97.74011373519897%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.010915900580585003 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.017771853134036064 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.012873688712716103 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.011855494230985641 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.0012219081399962306 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.01132921315729618 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.0020964874420315027 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.97527754306793 (+- 1.7216651232791282)\n","> Loss: 0.05605632077204063\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 4ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.8391 - accuracy: 0.9118 - tp: 2148.0000 - fp: 325.0000 - tn: 4633.0000 - fn: 331.0000 - precision: 0.8686 - recall: 0.8665 - auc: 0.9354 - prc: 0.8841\n","\n",">round 3  client 3 evaluation training metrics:\n","[0.002514283172786236, 0.9988703727722168, 3535.0, 6.0, 7076.0, 6.0, 0.9983055591583252, 0.9983055591583252, 0.9999973177909851, 0.9999946355819702]\n","\n",">round 3  client 3 evaluation metrics:\n","[0.8391203880310059, 0.9117923974990845, 2148.0, 325.0, 4633.0, 331.0, 0.86858069896698, 0.866478443145752, 0.9354026317596436, 0.8841260075569153]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.3823 - accuracy: 0.9199 - tp: 4944.0000 - fp: 640.0000 - tn: 10690.0000 - fn: 721.0000 - precision: 0.8854 - recall: 0.8727 - auc: 0.9500 - prc: 0.9091\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1677 - accuracy: 0.9655 - tp: 2995.0000 - fp: 139.0000 - tn: 6233.0000 - fn: 191.0000 - precision: 0.9556 - recall: 0.9401 - auc: 0.9917 - prc: 0.9849\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0730 - accuracy: 0.9843 - tp: 3104.0000 - fp: 68.0000 - tn: 6304.0000 - fn: 82.0000 - precision: 0.9786 - recall: 0.9743 - auc: 0.9985 - prc: 0.9973\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0334 - accuracy: 0.9936 - tp: 3152.0000 - fp: 27.0000 - tn: 6345.0000 - fn: 34.0000 - precision: 0.9915 - recall: 0.9893 - auc: 0.9995 - prc: 0.9989\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0268 - accuracy: 0.9937 - tp: 3155.0000 - fp: 29.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9909 - recall: 0.9903 - auc: 0.9998 - prc: 0.9997\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0054 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0020 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.5144952535629272; accuracy of 93.5969889163971%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0759 - accuracy: 0.9874 - tp: 3125.0000 - fp: 59.0000 - tn: 6313.0000 - fn: 61.0000 - precision: 0.9815 - recall: 0.9809 - auc: 0.9959 - prc: 0.9922\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0442 - accuracy: 0.9913 - tp: 3143.0000 - fp: 40.0000 - tn: 6332.0000 - fn: 43.0000 - precision: 0.9874 - recall: 0.9865 - auc: 0.9986 - prc: 0.9974\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0121 - accuracy: 0.9984 - tp: 3178.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0022 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.028602348640561104; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0681 - accuracy: 0.9863 - tp: 3120.0000 - fp: 65.0000 - tn: 6307.0000 - fn: 66.0000 - precision: 0.9796 - recall: 0.9793 - auc: 0.9967 - prc: 0.9937\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0291 - accuracy: 0.9945 - tp: 3159.0000 - fp: 26.0000 - tn: 6346.0000 - fn: 27.0000 - precision: 0.9918 - recall: 0.9915 - auc: 0.9996 - prc: 0.9991\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0212602149695158; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0058 - accuracy: 0.9984 - tp: 3178.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0103 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0007616102229803801; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.1475e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.7160e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.5346e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.7674e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3293e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.0464e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.7560e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.0760e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.014683868736028671; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 8.537129178876057e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.0979e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 7.145584095269442e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.00014255514543037862; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5465e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 2.40732424572343e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0453e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6160e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4309e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.0028e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.8387e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7949e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6592e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5063e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4531e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.007524591870605946; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5144952535629272 - Accuracy: 93.5969889163971%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.028602348640561104 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0212602149695158 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0007616102229803801 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.014683868736028671 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 8.537129178876057e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 7.145584095269442e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.00014255514543037862 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 2.40732424572343e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.007524591870605946 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.19020652770996 (+- 1.8814483910930238)\n","> Loss: 0.05876513435232482\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.7918 - accuracy: 0.9223 - tp: 2190.0000 - fp: 289.0000 - tn: 4669.0000 - fn: 289.0000 - precision: 0.8834 - recall: 0.8834 - auc: 0.9448 - prc: 0.9028\n","\n",">round 3  client 4 evaluation training metrics:\n","[0.001225113868713379, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999996423721313, 0.9999992847442627]\n","\n",">round 3  client 4 evaluation metrics:\n","[0.791841447353363, 0.922280490398407, 2190.0, 289.0, 4669.0, 289.0, 0.8834207057952881, 0.8834207057952881, 0.9447885751724243, 0.9027552008628845]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.4548 - accuracy: 0.9236 - tp: 5001.0000 - fp: 634.0000 - tn: 10696.0000 - fn: 664.0000 - precision: 0.8875 - recall: 0.8828 - auc: 0.9538 - prc: 0.9166\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1917 - accuracy: 0.9618 - tp: 2982.0000 - fp: 161.0000 - tn: 6211.0000 - fn: 204.0000 - precision: 0.9488 - recall: 0.9360 - auc: 0.9885 - prc: 0.9787\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1143 - accuracy: 0.9773 - tp: 3067.0000 - fp: 98.0000 - tn: 6274.0000 - fn: 119.0000 - precision: 0.9690 - recall: 0.9626 - auc: 0.9957 - prc: 0.9918\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0571 - accuracy: 0.9894 - tp: 3131.0000 - fp: 46.0000 - tn: 6326.0000 - fn: 55.0000 - precision: 0.9855 - recall: 0.9827 - auc: 0.9990 - prc: 0.9979\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0500 - accuracy: 0.9885 - tp: 3127.0000 - fp: 51.0000 - tn: 6321.0000 - fn: 59.0000 - precision: 0.9840 - recall: 0.9815 - auc: 0.9991 - prc: 0.9983\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0407 - accuracy: 0.9914 - tp: 3143.0000 - fp: 39.0000 - tn: 6333.0000 - fn: 43.0000 - precision: 0.9877 - recall: 0.9865 - auc: 0.9992 - prc: 0.9985\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0159 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 0.9997 - prc: 0.9994\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0055 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0416 - accuracy: 0.9929 - tp: 3151.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 35.0000 - precision: 0.9896 - recall: 0.9890 - auc: 0.9985 - prc: 0.9974\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0286 - accuracy: 0.9944 - tp: 3158.0000 - fp: 26.0000 - tn: 6346.0000 - fn: 28.0000 - precision: 0.9918 - recall: 0.9912 - auc: 0.9995 - prc: 0.9991\n","Score for fold 1: loss of 0.5310347676277161; accuracy of 93.0320143699646%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0704 - accuracy: 0.9877 - tp: 3125.0000 - fp: 57.0000 - tn: 6315.0000 - fn: 61.0000 - precision: 0.9821 - recall: 0.9809 - auc: 0.9965 - prc: 0.9938\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0187 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9999 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5307e-04 - accuracy: 0.9999 - tp: 3185.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 1.0000 - precision: 1.0000 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.016518905758857727; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0026 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.8939e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.9389e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7793e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0004378494923003018; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.0620e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.5827e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.1907e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.9463e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.8046e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.6681e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 1.6013e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.5074e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.3571e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.2898e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.014658605679869652; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 0.9998 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.6818e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 8.4638e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 8.3005e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.0754e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.0511e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4516e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 6.16496690781787e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.5290e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.7990e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.5746e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0376e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.4122e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9678e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7763e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6608e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6926e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.6464e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 7.345832273131236e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.2554e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9634e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.4924e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3316e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8063e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0929e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.4966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9790e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7218e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3459e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 4.602997796609998e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.2996e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8328e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0603e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.7098e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.6077e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4321e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.1371e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8601e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4560e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 2.4812294213916175e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4840e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2039e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6788e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.2663e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0871e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8569e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0815e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7888e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0826e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.1525e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 1.3818110346619505e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.3888e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.1573e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2861e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.6827e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7330e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.6796e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.9025e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3040e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0559e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8639e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 1.4226834537112154e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5310347676277161 - Accuracy: 93.0320143699646%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.016518905758857727 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0004378494923003018 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.014658605679869652 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 6.16496690781787e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 7.345832273131236e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 4.602997796609998e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 2.4812294213916175e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.3818110346619505e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 1.4226834537112154e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.26553606987 (+- 2.0791677442620706)\n","> Loss: 0.0562884123767617\n","------------------------------------------------------------------------\n","111/111 [==============================] - 3s 7ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 4.6938e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 13ms/step - loss: 0.8722 - accuracy: 0.9168 - tp: 2169.0000 - fp: 309.0000 - tn: 4649.0000 - fn: 310.0000 - precision: 0.8753 - recall: 0.8749 - auc: 0.9378 - prc: 0.8873\n","\n",">round 3  client 5 evaluation training metrics:\n","[0.0004693795053754002, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 3  client 5 evaluation metrics:\n","[0.8722313046455383, 0.9167675375938416, 2169.0, 309.0, 4649.0, 310.0, 0.8753026723861694, 0.87494957447052, 0.9378346800804138, 0.8872584700584412]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.4218 - accuracy: 0.9239 - tp: 4999.0000 - fp: 627.0000 - tn: 10703.0000 - fn: 666.0000 - precision: 0.8886 - recall: 0.8824 - auc: 0.9493 - prc: 0.9057\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1701 - accuracy: 0.9619 - tp: 2986.0000 - fp: 164.0000 - tn: 6208.0000 - fn: 200.0000 - precision: 0.9479 - recall: 0.9372 - auc: 0.9920 - prc: 0.9854\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0717 - accuracy: 0.9863 - tp: 3113.0000 - fp: 58.0000 - tn: 6314.0000 - fn: 73.0000 - precision: 0.9817 - recall: 0.9771 - auc: 0.9985 - prc: 0.9974\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0270 - accuracy: 0.9953 - tp: 3162.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 24.0000 - precision: 0.9934 - recall: 0.9925 - auc: 0.9999 - prc: 0.9997\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0542 - accuracy: 0.9900 - tp: 3135.0000 - fp: 45.0000 - tn: 6327.0000 - fn: 51.0000 - precision: 0.9858 - recall: 0.9840 - auc: 0.9980 - prc: 0.9968\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0334 - accuracy: 0.9936 - tp: 3153.0000 - fp: 28.0000 - tn: 6344.0000 - fn: 33.0000 - precision: 0.9912 - recall: 0.9896 - auc: 0.9994 - prc: 0.9988\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0110 - accuracy: 0.9990 - tp: 3180.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 0.9997 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0042 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0027 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.4019041359424591; accuracy of 93.31449866294861%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0791 - accuracy: 0.9844 - tp: 3109.0000 - fp: 72.0000 - tn: 6300.0000 - fn: 77.0000 - precision: 0.9774 - recall: 0.9758 - auc: 0.9958 - prc: 0.9921\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0745 - accuracy: 0.9813 - tp: 3093.0000 - fp: 86.0000 - tn: 6286.0000 - fn: 93.0000 - precision: 0.9729 - recall: 0.9708 - auc: 0.9982 - prc: 0.9966\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0120 - accuracy: 0.9983 - tp: 3177.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9978 - recall: 0.9972 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0022 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.017643557861447334; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0035 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1666 - accuracy: 0.9741 - tp: 3055.0000 - fp: 117.0000 - tn: 6255.0000 - fn: 131.0000 - precision: 0.9631 - recall: 0.9589 - auc: 0.9892 - prc: 0.9804\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0390 - accuracy: 0.9920 - tp: 3144.0000 - fp: 34.0000 - tn: 6338.0000 - fn: 42.0000 - precision: 0.9893 - recall: 0.9868 - auc: 0.9996 - prc: 0.9992\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0117 - accuracy: 0.9975 - tp: 3173.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9965 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.043983202427625656; accuracy of 99.1525411605835%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0056 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.9104e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.4006e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.4551e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3381e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.2356e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0002725309459492564; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.6550e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8197e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9191e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1936e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.7568e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2219e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.9393e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9118e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1399e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0713e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.0001316084380960092; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 3.1035e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.0513e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.6959e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.5026e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.3686e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.2723e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 1.1847e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.0950e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.0491e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6350e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.010084372013807297; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9330e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.8050e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.3122e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5366e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.9848e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7946e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2150e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6962e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 3.6542587622534484e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 3.9830e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.8493e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1696e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.8014e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3297e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1929e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5650e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9307e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5815e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1817e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.009788190945982933; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000       \n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.1340e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5350e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8759e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1823e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2032e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3109e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.3124e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4722e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5589e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 2.401176607236266e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0389e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.1883e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7332e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0865e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.5554e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.2587e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 4.7670e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2031e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.1200e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.5888e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 3.6386521969689056e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.4019041359424591 - Accuracy: 93.31449866294861%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.017643557861447334 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.043983202427625656 - Accuracy: 99.1525411605835%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0002725309459492564 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0001316084380960092 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.010084372013807297 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 3.6542587622534484e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.009788190945982933 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 2.401176607236266e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.6386521969689056e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.17137384414673 (+- 1.9687737057028416)\n","> Loss: 0.04839045394510322\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 4.1536e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 12ms/step - loss: 0.8438 - accuracy: 0.9240 - tp: 2195.0000 - fp: 281.0000 - tn: 4677.0000 - fn: 284.0000 - precision: 0.8865 - recall: 0.8854 - auc: 0.9393 - prc: 0.8904\n","\n",">round 3  client 6 evaluation training metrics:\n","[0.00041536104981787503, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 3  client 6 evaluation metrics:\n","[0.8438372611999512, 0.9240285158157349, 2195.0, 281.0, 4677.0, 284.0, 0.8865104913711548, 0.8854376673698425, 0.9393435120582581, 0.8904412984848022]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.4505 - accuracy: 0.9230 - tp: 4991.0000 - fp: 634.0000 - tn: 10696.0000 - fn: 674.0000 - precision: 0.8873 - recall: 0.8810 - auc: 0.9481 - prc: 0.9040\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1912 - accuracy: 0.9563 - tp: 2953.0000 - fp: 185.0000 - tn: 6187.0000 - fn: 233.0000 - precision: 0.9410 - recall: 0.9269 - auc: 0.9897 - prc: 0.9810\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1000 - accuracy: 0.9805 - tp: 3082.0000 - fp: 82.0000 - tn: 6290.0000 - fn: 104.0000 - precision: 0.9741 - recall: 0.9674 - auc: 0.9969 - prc: 0.9944\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0305 - accuracy: 0.9961 - tp: 3162.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 24.0000 - precision: 0.9959 - recall: 0.9925 - auc: 0.9998 - prc: 0.9996\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0163 - accuracy: 0.9978 - tp: 3173.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 13.0000 - precision: 0.9975 - recall: 0.9959 - auc: 0.9997 - prc: 0.9994\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9986 - tp: 3177.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 9.0000 - precision: 0.9987 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9990 - tp: 3179.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 7.0000 - precision: 0.9991 - recall: 0.9978 - auc: 0.9997 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0058 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 0.9998 - prc: 0.9995\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Score for fold 1: loss of 0.26016363501548767; accuracy of 95.38606405258179%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0662 - accuracy: 0.9895 - tp: 3132.0000 - fp: 46.0000 - tn: 6326.0000 - fn: 54.0000 - precision: 0.9855 - recall: 0.9831 - auc: 0.9968 - prc: 0.9946\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0377 - accuracy: 0.9927 - tp: 3147.0000 - fp: 31.0000 - tn: 6341.0000 - fn: 39.0000 - precision: 0.9902 - recall: 0.9878 - auc: 0.9990 - prc: 0.9982\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0137 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0069 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9997 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0018 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.03617427125573158; accuracy of 99.1525411605835%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0111 - accuracy: 0.9978 - tp: 3175.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0323 - accuracy: 0.9926 - tp: 3150.0000 - fp: 35.0000 - tn: 6337.0000 - fn: 36.0000 - precision: 0.9890 - recall: 0.9887 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0773 - accuracy: 0.9845 - tp: 3110.0000 - fp: 72.0000 - tn: 6300.0000 - fn: 76.0000 - precision: 0.9774 - recall: 0.9761 - auc: 0.9971 - prc: 0.9946\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0335 - accuracy: 0.9930 - tp: 3152.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 34.0000 - precision: 0.9896 - recall: 0.9893 - auc: 0.9995 - prc: 0.9990\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0097 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0059 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0040 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.08408226072788239; accuracy of 98.49340915679932%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0145 - accuracy: 0.9975 - tp: 3173.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9965 - recall: 0.9959 - auc: 0.9996 - prc: 0.9993\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.00019892903219442815; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 7.753137469990179e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 5.7709818065632135e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 2.337148725928273e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.002064792439341545; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.0238e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9655e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4235e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1129e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0158e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.1917e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2357e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5997e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8232e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8249e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.012978509068489075; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.7206e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5324e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1731e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.5419e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2127e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.4567e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3616e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1953e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1379e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.009004231542348862; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.26016363501548767 - Accuracy: 95.38606405258179%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03617427125573158 - Accuracy: 99.1525411605835%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.08408226072788239 - Accuracy: 98.49340915679932%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00019892903219442815 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 7.753137469990179e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 5.7709818065632135e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 2.337148725928273e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.002064792439341545 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.012978509068489075 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.009004231542348862 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.24670338630676 (+- 1.367781067614265)\n","> Loss: 0.04048252417615004\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 12ms/step - loss: 0.9779 - accuracy: 0.9188 - tp: 2176.0000 - fp: 301.0000 - tn: 4657.0000 - fn: 303.0000 - precision: 0.8785 - recall: 0.8778 - auc: 0.9303 - prc: 0.8740\n","\n",">round 3  client 7 evaluation training metrics:\n","[0.0014675369020551443, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999995827674866, 0.9999991059303284]\n","\n",">round 3  client 7 evaluation metrics:\n","[0.9779255390167236, 0.9187844395637512, 2176.0, 301.0, 4657.0, 303.0, 0.8784820437431335, 0.8777732849121094, 0.9302946925163269, 0.8740493655204773]\n","\n","=============================================================\n","\n","> round 3 average training auc= 0.24867747317785782\n","> round 3 average training loss= 0.0570611838590334\n","> round 3 average epoch count= 10.0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["78/78 [==============================] - 0s 5ms/step\n","> round 3 test auc= 0.25976524275928925\n","111/111 [==============================] - 1s 8ms/step - loss: 2.5169 - accuracy: 0.7669 - tp: 2296.0000 - fp: 1231.0000 - tn: 5851.0000 - fn: 1245.0000 - precision: 0.6510 - recall: 0.6484 - auc: 0.7811 - prc: 0.6375\n","\n","> round 3 final model training loss_metric= [2.516897201538086]\n","> round 3 final model training TP_metric= [2296.0]\n","> round 3 final model training FP_metric= [1231.0]\n","> round 3 final model training TN_metric= [5851.0]\n","> round 3 final model training FN_metric= [1245.0]\n","> round 3 final model training accuracy_metric= [76.6920804977417]\n","> round 3 final model training precision_metric= [65.0978147983551]\n","> round 3 final model training recall_metric = [64.84044194221497]\n","> round 3 final model training auc_metric= [0.7811378240585327]\n","> round 3 final model training prc_metric= [0.6375198364257812]\n","\n","78/78 [==============================] - 1s 8ms/step - loss: 2.0983 - accuracy: 0.7962 - tp: 1716.0000 - fp: 753.0000 - tn: 4205.0000 - fn: 763.0000 - precision: 0.6950 - recall: 0.6922 - auc: 0.8163 - prc: 0.6881\n","> round 3 final model loss_metric= [2.0982680320739746]\n","> round 3 final model TP_metric= [1716.0]\n","> round 3 final model FP_metric= [753.0]\n","> round 3 final model TN_metric= [4205.0]\n","> round 3 final model FN_metric= [763.0]\n","> round 3 final model accuracy_metric= [79.61543798446655]\n","> round 3 final model precision_metric= [69.50182318687439]\n","> round 3 final model recall_metric = [69.22146081924438]\n","> round 3 final model auc_metric= [0.8163476586341858]\n","> round 3 final model prc_metric= [0.6881147623062134]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 4 start, random seed= 4\n","\n","> client 1 started learning...........\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 9s 29ms/step - loss: 0.3484 - accuracy: 0.8722 - tp: 4553.0000 - fp: 1060.0000 - tn: 10270.0000 - fn: 1112.0000 - precision: 0.8112 - recall: 0.8037 - auc: 0.8973 - prc: 0.8137\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1124 - accuracy: 0.9763 - tp: 3057.0000 - fp: 98.0000 - tn: 6274.0000 - fn: 129.0000 - precision: 0.9689 - recall: 0.9595 - auc: 0.9968 - prc: 0.9941\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0382 - accuracy: 0.9937 - tp: 3149.0000 - fp: 23.0000 - tn: 6349.0000 - fn: 37.0000 - precision: 0.9927 - recall: 0.9884 - auc: 0.9996 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0122 - accuracy: 0.9982 - tp: 3173.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 0.9998 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0065 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0055 - accuracy: 0.9987 - tp: 3176.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9983 - tp: 3174.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 12.0000 - precision: 0.9987 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9987 - tp: 3176.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.26993632316589355; accuracy of 95.96244096755981%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0522 - accuracy: 0.9890 - tp: 3129.0000 - fp: 47.0000 - tn: 6327.0000 - fn: 58.0000 - precision: 0.9852 - recall: 0.9818 - auc: 0.9984 - prc: 0.9972\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0888 - accuracy: 0.9785 - tp: 3076.0000 - fp: 95.0000 - tn: 6279.0000 - fn: 111.0000 - precision: 0.9700 - recall: 0.9652 - auc: 0.9972 - prc: 0.9945\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0237 - accuracy: 0.9947 - tp: 3156.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 31.0000 - precision: 0.9937 - recall: 0.9903 - auc: 0.9997 - prc: 0.9996\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9979 - tp: 3172.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 15.0000 - precision: 0.9984 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0058 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0049 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0058 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0048 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.05352070927619934; accuracy of 98.68173003196716%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0236 - accuracy: 0.9940 - tp: 3152.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 35.0000 - precision: 0.9931 - recall: 0.9890 - auc: 0.9994 - prc: 0.9988\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0227 - accuracy: 0.9956 - tp: 3161.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 26.0000 - precision: 0.9950 - recall: 0.9918 - auc: 0.9999 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3177.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 10.0000 - precision: 1.0000 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.05559324845671654; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0065 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0049 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0034865327179431915; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.010764060541987419; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.02176724001765251; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 4.602211993187666e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.005209299735724926; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9983 - tp: 3175.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 12.0000 - precision: 0.9987 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.003358392044901848; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.003395410254597664; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.26993632316589355 - Accuracy: 95.96244096755981%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.05352070927619934 - Accuracy: 98.68173003196716%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.05559324845671654 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0034865327179431915 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.010764060541987419 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.02176724001765251 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 4.602211993187666e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.005209299735724926 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.003358392044901848 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.003395410254597664 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.27609264850616 (+- 1.1781771656881237)\n","> Loss: 0.04270772383315489\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.6873 - accuracy: 0.9338 - tp: 2231.0000 - fp: 244.0000 - tn: 4714.0000 - fn: 248.0000 - precision: 0.9014 - recall: 0.9000 - auc: 0.9493 - prc: 0.9058\n","\n",">round 4  client 1 evaluation training metrics:\n","[0.0037579063791781664, 0.9987762570381165, 3530.0, 2.0, 7080.0, 11.0, 0.9994337558746338, 0.9968935251235962, 0.9999945759773254, 0.9999892711639404]\n","\n",">round 4  client 1 evaluation metrics:\n","[0.6873199343681335, 0.933844268321991, 2231.0, 244.0, 4714.0, 248.0, 0.901414155960083, 0.8999596834182739, 0.9493230581283569, 0.9057806134223938]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 28ms/step - loss: 0.4106 - accuracy: 0.9252 - tp: 5013.0000 - fp: 619.0000 - tn: 10711.0000 - fn: 652.0000 - precision: 0.8901 - recall: 0.8849 - auc: 0.9585 - prc: 0.9218\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1081 - accuracy: 0.9773 - tp: 3063.0000 - fp: 94.0000 - tn: 6278.0000 - fn: 123.0000 - precision: 0.9702 - recall: 0.9614 - auc: 0.9973 - prc: 0.9948\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0350 - accuracy: 0.9945 - tp: 3154.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 32.0000 - precision: 0.9934 - recall: 0.9900 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0195 - accuracy: 0.9949 - tp: 3156.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 30.0000 - precision: 0.9940 - recall: 0.9906 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0162 - accuracy: 0.9953 - tp: 3160.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 26.0000 - precision: 0.9940 - recall: 0.9918 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0133 - accuracy: 0.9967 - tp: 3167.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 19.0000 - precision: 0.9959 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0125 - accuracy: 0.9960 - tp: 3165.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9947 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0115 - accuracy: 0.9962 - tp: 3168.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0107 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0110 - accuracy: 0.9962 - tp: 3168.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 0.26940470933914185; accuracy of 94.74178552627563%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.2367 - accuracy: 0.9458 - tp: 2919.0000 - fp: 250.0000 - tn: 6124.0000 - fn: 268.0000 - precision: 0.9211 - recall: 0.9159 - auc: 0.9857 - prc: 0.9733\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0858 - accuracy: 0.9796 - tp: 3080.0000 - fp: 88.0000 - tn: 6286.0000 - fn: 107.0000 - precision: 0.9722 - recall: 0.9664 - auc: 0.9980 - prc: 0.9960\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0258 - accuracy: 0.9929 - tp: 3152.0000 - fp: 33.0000 - tn: 6341.0000 - fn: 35.0000 - precision: 0.9896 - recall: 0.9890 - auc: 0.9999 - prc: 0.9997\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0171 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0141 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0128 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0124 - accuracy: 0.9955 - tp: 3164.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 23.0000 - precision: 0.9937 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0116 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0116 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0113 - accuracy: 0.9951 - tp: 3163.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 24.0000 - precision: 0.9928 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.08454037457704544; accuracy of 98.30508232116699%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0221 - accuracy: 0.9927 - tp: 3152.0000 - fp: 35.0000 - tn: 6339.0000 - fn: 35.0000 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - prc: 0.9997\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0452 - accuracy: 0.9870 - tp: 3124.0000 - fp: 61.0000 - tn: 6313.0000 - fn: 63.0000 - precision: 0.9808 - recall: 0.9802 - auc: 0.9987 - prc: 0.9975\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0255 - accuracy: 0.9931 - tp: 3154.0000 - fp: 33.0000 - tn: 6341.0000 - fn: 33.0000 - precision: 0.9896 - recall: 0.9896 - auc: 0.9998 - prc: 0.9996\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0125 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 3: loss of 0.03820366412401199; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0146 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 0.9997 - prc: 0.9994\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0095 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0096 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.004984585102647543; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0092 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0094 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0086 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0091 - accuracy: 0.9946 - tp: 3161.0000 - fp: 26.0000 - tn: 6348.0000 - fn: 26.0000 - precision: 0.9918 - recall: 0.9918 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 5: loss of 0.005984137300401926; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0079 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0080 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9958 - tp: 3163.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 24.0000 - precision: 0.9950 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.018715709447860718; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0094 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 0.9961 - tp: 3166.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 21.0000 - precision: 0.9950 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.00894551444798708; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0817 - accuracy: 0.9801 - tp: 3091.0000 - fp: 94.0000 - tn: 6280.0000 - fn: 96.0000 - precision: 0.9705 - recall: 0.9699 - auc: 0.9966 - prc: 0.9934\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.3261 - accuracy: 0.9338 - tp: 2853.0000 - fp: 299.0000 - tn: 6075.0000 - fn: 334.0000 - precision: 0.9051 - recall: 0.8952 - auc: 0.9733 - prc: 0.9526\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0598 - accuracy: 0.9859 - tp: 3112.0000 - fp: 60.0000 - tn: 6314.0000 - fn: 75.0000 - precision: 0.9811 - recall: 0.9765 - auc: 0.9992 - prc: 0.9984\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0183 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0157 - accuracy: 0.9957 - tp: 3166.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0224 - accuracy: 0.9938 - tp: 3156.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 31.0000 - precision: 0.9912 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0133 - accuracy: 0.9953 - tp: 3163.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 24.0000 - precision: 0.9934 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0118 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0115 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.1620921492576599; accuracy of 95.76271176338196%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0209 - accuracy: 0.9925 - tp: 3151.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 36.0000 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - prc: 0.9997\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0509 - accuracy: 0.9862 - tp: 3120.0000 - fp: 65.0000 - tn: 6309.0000 - fn: 67.0000 - precision: 0.9796 - recall: 0.9790 - auc: 0.9990 - prc: 0.9980\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0222 - accuracy: 0.9937 - tp: 3156.0000 - fp: 29.0000 - tn: 6345.0000 - fn: 31.0000 - precision: 0.9909 - recall: 0.9903 - auc: 0.9997 - prc: 0.9996\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0140 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0110 - accuracy: 0.9960 - tp: 3166.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 21.0000 - precision: 0.9947 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0128 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0117 - accuracy: 0.9950 - tp: 3161.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 26.0000 - precision: 0.9931 - recall: 0.9918 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0113 - accuracy: 0.9964 - tp: 3169.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 18.0000 - precision: 0.9950 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0103 - accuracy: 0.9959 - tp: 3166.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 21.0000 - precision: 0.9943 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9964 - tp: 3169.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 18.0000 - precision: 0.9950 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 9: loss of 0.015996670350432396; accuracy of 99.34086799621582%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0096 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0090 - accuracy: 0.9968 - tp: 3171.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9970 - tp: 3172.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0087 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.01581578142940998; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.26940470933914185 - Accuracy: 94.74178552627563%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.08454037457704544 - Accuracy: 98.30508232116699%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.03820366412401199 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.004984585102647543 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.005984137300401926 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.018715709447860718 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.00894551444798708 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.1620921492576599 - Accuracy: 95.76271176338196%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.015996670350432396 - Accuracy: 99.34086799621582%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.01581578142940998 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.49489331245422 (+- 1.692140354232425)\n","> Loss: 0.062468329537659885\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","78/78 [==============================] - 1s 12ms/step - loss: 0.6107 - accuracy: 0.9290 - tp: 2212.0000 - fp: 261.0000 - tn: 4697.0000 - fn: 267.0000 - precision: 0.8945 - recall: 0.8923 - auc: 0.9548 - prc: 0.9177\n","\n",">round 4  client 2 evaluation training metrics:\n","[0.008649934083223343, 0.9962345957756042, 3521.0, 20.0, 7062.0, 20.0, 0.994351863861084, 0.994351863861084, 0.9999694228172302, 0.9999390840530396]\n","\n",">round 4  client 2 evaluation metrics:\n","[0.610685408115387, 0.9290036559104919, 2212.0, 261.0, 4697.0, 267.0, 0.894460141658783, 0.8922953009605408, 0.9547765254974365, 0.9176851511001587]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 9s 29ms/step - loss: 0.3222 - accuracy: 0.9363 - tp: 5115.0000 - fp: 532.0000 - tn: 10798.0000 - fn: 550.0000 - precision: 0.9058 - recall: 0.9029 - auc: 0.9658 - prc: 0.9359\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0883 - accuracy: 0.9829 - tp: 3097.0000 - fp: 74.0000 - tn: 6298.0000 - fn: 89.0000 - precision: 0.9767 - recall: 0.9721 - auc: 0.9979 - prc: 0.9958\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0252 - accuracy: 0.9973 - tp: 3172.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9962 - recall: 0.9956 - auc: 0.9997 - prc: 0.9997\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0143 - accuracy: 0.9979 - tp: 3175.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9972 - recall: 0.9965 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9990 - tp: 3180.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 0.9997 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0069 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0041 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Score for fold 1: loss of 0.16218477487564087; accuracy of 96.24413251876831%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0292 - accuracy: 0.9947 - tp: 3161.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 26.0000 - precision: 0.9922 - recall: 0.9918 - auc: 0.9989 - prc: 0.9977\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0229 - accuracy: 0.9964 - tp: 3169.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 18.0000 - precision: 0.9950 - recall: 0.9944 - auc: 0.9995 - prc: 0.9991\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0511 - accuracy: 0.9883 - tp: 3130.0000 - fp: 55.0000 - tn: 6319.0000 - fn: 57.0000 - precision: 0.9827 - recall: 0.9821 - auc: 0.9984 - prc: 0.9968\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0185 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 0.9996 - prc: 0.9993\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9997 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0056 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0052 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.03986566513776779; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0127 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0444 - accuracy: 0.9905 - tp: 3141.0000 - fp: 45.0000 - tn: 6329.0000 - fn: 46.0000 - precision: 0.9859 - recall: 0.9856 - auc: 0.9989 - prc: 0.9980\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0202 - accuracy: 0.9953 - tp: 3164.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0084 - accuracy: 0.9982 - tp: 3178.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.00708141690120101; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.015734484419226646; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0036 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.00012996629811823368; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2442 - accuracy: 0.9638 - tp: 3014.0000 - fp: 173.0000 - tn: 6201.0000 - fn: 173.0000 - precision: 0.9457 - recall: 0.9457 - auc: 0.9865 - prc: 0.9747\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1323 - accuracy: 0.9694 - tp: 3034.0000 - fp: 140.0000 - tn: 6234.0000 - fn: 153.0000 - precision: 0.9559 - recall: 0.9520 - auc: 0.9943 - prc: 0.9891\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0327 - accuracy: 0.9946 - tp: 3159.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 28.0000 - precision: 0.9925 - recall: 0.9912 - auc: 0.9998 - prc: 0.9996\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0117 - accuracy: 0.9978 - tp: 3176.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.23097755014896393; accuracy of 94.53860521316528%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0173 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 0.9999 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0129 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0116 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9976 - tp: 3175.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 12.0000 - precision: 0.9965 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0060 - accuracy: 0.9980 - tp: 3177.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0067 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0065 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0060 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0054 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0059 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.0034275169018656015; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0056 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0054 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0049 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9977 - tp: 3174.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 13.0000 - precision: 0.9972 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0142 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.001530034700408578; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0022 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.021938500925898552; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0042 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.0041748955845832825; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.16218477487564087 - Accuracy: 96.24413251876831%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03986566513776779 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.00708141690120101 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.015734484419226646 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.00012996629811823368 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.23097755014896393 - Accuracy: 94.53860521316528%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0034275169018656015 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.001530034700408578 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.021938500925898552 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.0041748955845832825 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.8711166381836 (+- 1.789003013823291)\n","> Loss: 0.04870448058936745\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 11ms/step - loss: 0.7711 - accuracy: 0.9131 - tp: 2156.0000 - fp: 323.0000 - tn: 4635.0000 - fn: 323.0000 - precision: 0.8697 - recall: 0.8697 - auc: 0.9408 - prc: 0.8950\n","\n",">round 4  client 3 evaluation training metrics:\n","[0.0024003256112337112, 0.9990586638450623, 3536.0, 5.0, 7077.0, 5.0, 0.998587965965271, 0.998587965965271, 0.9999977350234985, 0.9999955296516418]\n","\n",">round 4  client 3 evaluation metrics:\n","[0.7710798382759094, 0.9131370186805725, 2156.0, 323.0, 4635.0, 323.0, 0.8697054982185364, 0.8697054982185364, 0.940837025642395, 0.8950449824333191]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.3660 - accuracy: 0.9270 - tp: 5027.0000 - fp: 603.0000 - tn: 10727.0000 - fn: 638.0000 - precision: 0.8929 - recall: 0.8874 - auc: 0.9565 - prc: 0.9211\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0965 - accuracy: 0.9801 - tp: 3080.0000 - fp: 84.0000 - tn: 6288.0000 - fn: 106.0000 - precision: 0.9735 - recall: 0.9667 - auc: 0.9969 - prc: 0.9944\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0263 - accuracy: 0.9965 - tp: 3167.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 19.0000 - precision: 0.9956 - recall: 0.9940 - auc: 0.9998 - prc: 0.9996\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0072 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.17577266693115234; accuracy of 96.61017060279846%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0604 - accuracy: 0.9870 - tp: 3123.0000 - fp: 61.0000 - tn: 6311.0000 - fn: 63.0000 - precision: 0.9808 - recall: 0.9802 - auc: 0.9974 - prc: 0.9948\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0281 - accuracy: 0.9938 - tp: 3155.0000 - fp: 28.0000 - tn: 6344.0000 - fn: 31.0000 - precision: 0.9912 - recall: 0.9903 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0797 - accuracy: 0.9852 - tp: 3114.0000 - fp: 69.0000 - tn: 6303.0000 - fn: 72.0000 - precision: 0.9783 - recall: 0.9774 - auc: 0.9966 - prc: 0.9944\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0247 - accuracy: 0.9954 - tp: 3163.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9934 - recall: 0.9928 - auc: 0.9996 - prc: 0.9992\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9988 - tp: 3179.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9987 - recall: 0.9978 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.5218e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.05318966135382652; accuracy of 99.1525411605835%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0079 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0240 - accuracy: 0.9938 - tp: 3155.0000 - fp: 28.0000 - tn: 6344.0000 - fn: 31.0000 - precision: 0.9912 - recall: 0.9903 - auc: 0.9996 - prc: 0.9992\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0143 - accuracy: 0.9969 - tp: 3171.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0007017696625553071; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.6555e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.6966e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9068e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8156e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3165e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5195e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.2822e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9610e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1743e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1290e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.009062318131327629; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.9974e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8429e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3472e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1717e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8969e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.1218e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.1649e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.8949e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.01589135080575943; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.7840e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 7.887735409894958e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 3.769444811041467e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9615e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5047e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.8340e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 1.6803660400910303e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6685e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0776e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5821e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4711e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0211e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4600e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2753e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7881e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1714e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9352e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.010320479050278664; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0017 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3513e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.8666e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 1.273478483199142e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.17577266693115234 - Accuracy: 96.61017060279846%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.05318966135382652 - Accuracy: 99.1525411605835%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0007017696625553071 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.009062318131327629 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.01589135080575943 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 7.887735409894958e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 3.769444811041467e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 1.6803660400910303e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.010320479050278664 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 1.273478483199142e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.5197731256485 (+- 1.000467506179018)\n","> Loss: 0.026508435618234218\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 8.1020e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 11ms/step - loss: 0.6419 - accuracy: 0.9338 - tp: 2231.0000 - fp: 244.0000 - tn: 4714.0000 - fn: 248.0000 - precision: 0.9014 - recall: 0.9000 - auc: 0.9545 - prc: 0.9180\n","\n",">round 4  client 4 evaluation training metrics:\n","[0.000810197670944035, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999996423721313, 0.9999994039535522]\n","\n",">round 4  client 4 evaluation metrics:\n","[0.6418612599372864, 0.933844268321991, 2231.0, 244.0, 4714.0, 248.0, 0.901414155960083, 0.8999596834182739, 0.9545471668243408, 0.9179949760437012]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.3091 - accuracy: 0.9409 - tp: 5145.0000 - fp: 484.0000 - tn: 10846.0000 - fn: 520.0000 - precision: 0.9140 - recall: 0.9082 - auc: 0.9653 - prc: 0.9361\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0986 - accuracy: 0.9806 - tp: 3083.0000 - fp: 82.0000 - tn: 6290.0000 - fn: 103.0000 - precision: 0.9741 - recall: 0.9677 - auc: 0.9970 - prc: 0.9946\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0428 - accuracy: 0.9932 - tp: 3151.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 35.0000 - precision: 0.9906 - recall: 0.9890 - auc: 0.9992 - prc: 0.9985\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0148 - accuracy: 0.9978 - tp: 3175.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0126 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0070 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9997 - prc: 0.9995\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0086 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0049 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.3528096377849579; accuracy of 94.91525292396545%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1193 - accuracy: 0.9772 - tp: 3076.0000 - fp: 108.0000 - tn: 6264.0000 - fn: 110.0000 - precision: 0.9661 - recall: 0.9655 - auc: 0.9943 - prc: 0.9890\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0382 - accuracy: 0.9920 - tp: 3143.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 43.0000 - precision: 0.9896 - recall: 0.9865 - auc: 0.9992 - prc: 0.9987\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0111 - accuracy: 0.9981 - tp: 3176.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9975 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4665e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.03784946724772453; accuracy of 98.68173003196716%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0067 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.5591e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.3067e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1669e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.8847e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0001496901677455753; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.5587e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.3505e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7948e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.7143e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7214e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2558e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.1120e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5615e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8348e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 9.392997162649408e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1086e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.5532e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.3564e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.0143e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.9689e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9546e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.4892e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.4295e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9483e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8146e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 2.1836898667970672e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4978e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2855e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2499e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.5406e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0902e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.8271e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9920e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8650e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4852e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8104e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Score for fold 6: loss of 3.7801342841703445e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.9397e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6470e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3052e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.8544e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1571e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.1871e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6256e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1153e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1120e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4956e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.755521043378394e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 2.3064e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.5315e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.6242e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.8979e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.8148e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.1467e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.4066e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 3.0470e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.7661e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.6255e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.014559265226125717; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.2932e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7986e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0407 - accuracy: 0.9937 - tp: 3156.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 30.0000 - precision: 0.9906 - recall: 0.9906 - auc: 0.9976 - prc: 0.9953\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1752 - accuracy: 0.9584 - tp: 2983.0000 - fp: 195.0000 - tn: 6177.0000 - fn: 203.0000 - precision: 0.9386 - recall: 0.9363 - auc: 0.9914 - prc: 0.9852\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2011 - accuracy: 0.9628 - tp: 3000.0000 - fp: 170.0000 - tn: 6202.0000 - fn: 186.0000 - precision: 0.9464 - recall: 0.9416 - auc: 0.9873 - prc: 0.9787\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0957 - accuracy: 0.9784 - tp: 3076.0000 - fp: 96.0000 - tn: 6276.0000 - fn: 110.0000 - precision: 0.9697 - recall: 0.9655 - auc: 0.9969 - prc: 0.9943\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0402 - accuracy: 0.9934 - tp: 3151.0000 - fp: 28.0000 - tn: 6344.0000 - fn: 35.0000 - precision: 0.9912 - recall: 0.9890 - auc: 0.9989 - prc: 0.9979\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0171 - accuracy: 0.9979 - tp: 3175.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9972 - recall: 0.9965 - auc: 0.9997 - prc: 0.9994\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0095 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9997 - prc: 0.9995\n","Score for fold 9: loss of 0.4324517250061035; accuracy of 92.65536665916443%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0380 - accuracy: 0.9947 - tp: 3159.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 27.0000 - precision: 0.9925 - recall: 0.9915 - auc: 0.9982 - prc: 0.9965\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0117 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 0.9998 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.6645e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.4977e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8183e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.2134e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.015174107626080513; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.3528096377849579 - Accuracy: 94.91525292396545%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03784946724772453 - Accuracy: 98.68173003196716%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0001496901677455753 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 9.392997162649408e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.1836898667970672e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 3.7801342841703445e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.755521043378394e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.014559265226125717 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.4324517250061035 - Accuracy: 92.65536665916443%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.015174107626080513 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.58756959438324 (+- 2.4830921234240173)\n","> Loss: 0.08531650164823076\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 12ms/step - loss: 0.0020 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 12ms/step - loss: 0.6778 - accuracy: 0.9161 - tp: 2165.0000 - fp: 310.0000 - tn: 4648.0000 - fn: 314.0000 - precision: 0.8747 - recall: 0.8733 - auc: 0.9500 - prc: 0.9126\n","\n",">round 4  client 5 evaluation training metrics:\n","[0.002036765916272998, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999963641166687, 0.9999927282333374]\n","\n",">round 4  client 5 evaluation metrics:\n","[0.6777533292770386, 0.9160951972007751, 2165.0, 310.0, 4648.0, 314.0, 0.8747474551200867, 0.8733360171318054, 0.9500236511230469, 0.9126152992248535]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 31ms/step - loss: 0.2734 - accuracy: 0.9321 - tp: 5077.0000 - fp: 566.0000 - tn: 10764.0000 - fn: 588.0000 - precision: 0.8997 - recall: 0.8962 - auc: 0.9650 - prc: 0.9365\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0804 - accuracy: 0.9822 - tp: 3092.0000 - fp: 76.0000 - tn: 6296.0000 - fn: 94.0000 - precision: 0.9760 - recall: 0.9705 - auc: 0.9982 - prc: 0.9969\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0252 - accuracy: 0.9965 - tp: 3166.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 20.0000 - precision: 0.9959 - recall: 0.9937 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 0.9997 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0084 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 0.9997 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0043 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0029 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0016 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.22442477941513062; accuracy of 96.23352289199829%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1950 - accuracy: 0.9731 - tp: 3053.0000 - fp: 124.0000 - tn: 6248.0000 - fn: 133.0000 - precision: 0.9610 - recall: 0.9583 - auc: 0.9870 - prc: 0.9777\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0703 - accuracy: 0.9864 - tp: 3111.0000 - fp: 55.0000 - tn: 6317.0000 - fn: 75.0000 - precision: 0.9826 - recall: 0.9765 - auc: 0.9980 - prc: 0.9961\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0169 - accuracy: 0.9965 - tp: 3167.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 19.0000 - precision: 0.9956 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0153 - accuracy: 0.9962 - tp: 3166.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9950 - recall: 0.9937 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0110 - accuracy: 0.9975 - tp: 3173.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9965 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.06682699173688889; accuracy of 98.68173003196716%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0080 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.8166e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.3776e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9971e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.7437e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.015069058164954185; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.8191e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.6812e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.2934e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.8166e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 2.6320e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 2.3178e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 2.1053e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.9262e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.8194e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.008631096221506596; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9420e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0814e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9355e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7301e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0457e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.8165e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.7306e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2728e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2759e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 3.2231044315267354e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 2.2509e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.4354e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.0730e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.0590e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.7104e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7645e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.0147e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.6985e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0734e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.6740e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.011197981424629688; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1094 - accuracy: 0.9794 - tp: 3083.0000 - fp: 94.0000 - tn: 6278.0000 - fn: 103.0000 - precision: 0.9704 - recall: 0.9677 - auc: 0.9949 - prc: 0.9903\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0397 - accuracy: 0.9913 - tp: 3143.0000 - fp: 40.0000 - tn: 6332.0000 - fn: 43.0000 - precision: 0.9874 - recall: 0.9865 - auc: 0.9996 - prc: 0.9992\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0306 - accuracy: 0.9935 - tp: 3155.0000 - fp: 31.0000 - tn: 6341.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9993 - prc: 0.9986\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0112 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 0.9997 - prc: 0.9995\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.5971e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.06055442988872528; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0071 - accuracy: 0.9982 - tp: 3177.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0052 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0051 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0769e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5081e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.4154e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.3263e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1980e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7560e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.0009406927274540067; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1379e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.1233e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.8173e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3380e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5700e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3061e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0487e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.9498e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4114e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5127e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.00010333344107493758; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0712e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5473e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4970e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2314e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4080e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.4995e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.0319e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.4343e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 33ms/step - loss: 6.0050e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.6038e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 3.4459735616110265e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.22442477941513062 - Accuracy: 96.23352289199829%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.06682699173688889 - Accuracy: 98.68173003196716%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.015069058164954185 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.008631096221506596 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 3.2231044315267354e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.011197981424629688 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.06055442988872528 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.0009406927274540067 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.00010333344107493758 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.4459735616110265e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.3220329284668 (+- 1.1274291324248313)\n","> Loss: 0.03878150538002956\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 4.3250e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.7463 - accuracy: 0.9230 - tp: 2191.0000 - fp: 285.0000 - tn: 4673.0000 - fn: 288.0000 - precision: 0.8849 - recall: 0.8838 - auc: 0.9474 - prc: 0.9044\n","\n",">round 4  client 6 evaluation training metrics:\n","[0.0004325011104810983, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999998807907104, 0.9999998807907104]\n","\n",">round 4  client 6 evaluation metrics:\n","[0.7462555170059204, 0.9229528307914734, 2191.0, 285.0, 4673.0, 288.0, 0.8848949670791626, 0.8838241100311279, 0.9474067091941833, 0.9043792486190796]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 30ms/step - loss: 0.3082 - accuracy: 0.9350 - tp: 5102.0000 - fp: 541.0000 - tn: 10789.0000 - fn: 563.0000 - precision: 0.9041 - recall: 0.9006 - auc: 0.9635 - prc: 0.9330\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0746 - accuracy: 0.9872 - tp: 3120.0000 - fp: 56.0000 - tn: 6316.0000 - fn: 66.0000 - precision: 0.9824 - recall: 0.9793 - auc: 0.9985 - prc: 0.9972\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0202 - accuracy: 0.9976 - tp: 3174.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 12.0000 - precision: 0.9965 - recall: 0.9962 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9983 - tp: 3177.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9978 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0069 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0049 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0056 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.22428376972675323; accuracy of 95.85687518119812%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0601 - accuracy: 0.9892 - tp: 3133.0000 - fp: 50.0000 - tn: 6322.0000 - fn: 53.0000 - precision: 0.9843 - recall: 0.9834 - auc: 0.9975 - prc: 0.9953\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0457 - accuracy: 0.9909 - tp: 3140.0000 - fp: 41.0000 - tn: 6331.0000 - fn: 46.0000 - precision: 0.9871 - recall: 0.9856 - auc: 0.9989 - prc: 0.9978\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0123 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0090 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0044 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0027 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.027336888015270233; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0156 - accuracy: 0.9962 - tp: 3168.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 0.9995 - prc: 0.9990\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0136 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.003973391372710466; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0048 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1750 - accuracy: 0.9788 - tp: 3083.0000 - fp: 100.0000 - tn: 6272.0000 - fn: 103.0000 - precision: 0.9686 - recall: 0.9677 - auc: 0.9869 - prc: 0.9749\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0292 - accuracy: 0.9940 - tp: 3155.0000 - fp: 26.0000 - tn: 6346.0000 - fn: 31.0000 - precision: 0.9918 - recall: 0.9903 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9979 - tp: 3175.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9972 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.08699905127286911; accuracy of 98.77589344978333%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0112 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0078 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9951 - tp: 3162.0000 - fp: 23.0000 - tn: 6349.0000 - fn: 24.0000 - precision: 0.9928 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0105 - accuracy: 0.9976 - tp: 3174.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 12.0000 - precision: 0.9965 - recall: 0.9962 - auc: 0.9997 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0052 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0030 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0032 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.021212752908468246; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0134 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9995 - prc: 0.9990\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.6593e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3766e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7327e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.0515e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.0299e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.7646e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.013450291007757187; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.5296e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7296e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1859e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.8191e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3319e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.5333e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9944e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2831e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0278e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.010545361787080765; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 8.547989273210987e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 3.130744516965933e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 2.9690769224544056e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.22428376972675323 - Accuracy: 95.85687518119812%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.027336888015270233 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.003973391372710466 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.08699905127286911 - Accuracy: 98.77589344978333%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.021212752908468246 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.013450291007757187 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.010545361787080765 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 8.547989273210987e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 3.130744516965933e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 2.9690769224544056e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.2937844991684 (+- 1.2097148837088165)\n","> Loss: 0.03879479841980356\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 9.5958e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 12ms/step - loss: 0.7901 - accuracy: 0.9252 - tp: 2200.0000 - fp: 277.0000 - tn: 4681.0000 - fn: 279.0000 - precision: 0.8882 - recall: 0.8875 - auc: 0.9439 - prc: 0.8967\n","\n",">round 4  client 7 evaluation training metrics:\n","[0.0009595793089829385, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999996423721313, 0.9999992251396179]\n","\n",">round 4  client 7 evaluation metrics:\n","[0.7901078462600708, 0.9252386689186096, 2200.0, 277.0, 4681.0, 279.0, 0.8881711959838867, 0.887454628944397, 0.943850040435791, 0.8966565132141113]\n","\n","=============================================================\n","\n","> round 4 average training auc= 0.24940508828826907\n","> round 4 average training loss= 0.049040253575211475\n","Epoch 1/10\n","36/36 [==============================] - 1s 34ms/step - loss: 0.0089 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0094 - accuracy: 0.9964 - tp: 3522.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 19.0000 - precision: 0.9946 - recall: 0.9946 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","36/36 [==============================] - 1s 33ms/step - loss: 0.0088 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","36/36 [==============================] - 1s 29ms/step - loss: 0.0088 - accuracy: 0.9960 - tp: 3519.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 22.0000 - precision: 0.9943 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9954 - tp: 3516.0000 - fp: 24.0000 - tn: 7058.0000 - fn: 25.0000 - precision: 0.9932 - recall: 0.9929 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0088 - accuracy: 0.9959 - tp: 3519.0000 - fp: 22.0000 - tn: 7060.0000 - fn: 22.0000 - precision: 0.9938 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9960 - tp: 3520.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 21.0000 - precision: 0.9941 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 0.9960 - tp: 3520.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 21.0000 - precision: 0.9941 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9968 - tp: 3524.0000 - fp: 17.0000 - tn: 7065.0000 - fn: 17.0000 - precision: 0.9952 - recall: 0.9952 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0088 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","> model 2 retrained, original loss= 0.062468329537659885 , retrained loss= 0.008831595070660114 epoch count 20.0\n","Epoch 1/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0027 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","36/36 [==============================] - 1s 27ms/step - loss: 8.8851e-04 - accuracy: 0.9997 - tp: 3538.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","36/36 [==============================] - 1s 28ms/step - loss: 8.7613e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","36/36 [==============================] - 1s 29ms/step - loss: 8.9088e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","36/36 [==============================] - 1s 29ms/step - loss: 7.0683e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","36/36 [==============================] - 1s 30ms/step - loss: 8.2752e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","> model 5 retrained, original loss= 0.08531650164823076 , retrained loss= 0.0008275248692370951 epoch count 20.0\n","> round 4 average epoch count= 12.857142857142858\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["78/78 [==============================] - 1s 7ms/step\n","> round 4 test auc= 0.3322253925576376\n","111/111 [==============================] - 1s 8ms/step - loss: 4.2739 - accuracy: 0.6384 - tp: 1610.0000 - fp: 1910.0000 - tn: 5172.0000 - fn: 1931.0000 - precision: 0.4574 - recall: 0.4547 - auc: 0.6178 - prc: 0.4332\n","\n","> round 4 final model training loss_metric= [4.273864269256592]\n","> round 4 final model training TP_metric= [1610.0]\n","> round 4 final model training FP_metric= [1910.0]\n","> round 4 final model training TN_metric= [5172.0]\n","> round 4 final model training FN_metric= [1931.0]\n","> round 4 final model training accuracy_metric= [63.84260654449463]\n","> round 4 final model training precision_metric= [45.73863744735718]\n","> round 4 final model training recall_metric = [45.46738266944885]\n","> round 4 final model training auc_metric= [0.6177704930305481]\n","> round 4 final model training prc_metric= [0.4332350194454193]\n","\n","78/78 [==============================] - 1s 9ms/step - loss: 3.6039 - accuracy: 0.6746 - tp: 1261.0000 - fp: 1202.0000 - tn: 3756.0000 - fn: 1218.0000 - precision: 0.5120 - recall: 0.5087 - auc: 0.6656 - prc: 0.4853\n","> round 4 final model loss_metric= [3.60388445854187]\n","> round 4 final model TP_metric= [1261.0]\n","> round 4 final model FP_metric= [1202.0]\n","> round 4 final model TN_metric= [3756.0]\n","> round 4 final model FN_metric= [1218.0]\n","> round 4 final model accuracy_metric= [67.45999455451965]\n","> round 4 final model precision_metric= [51.19772553443909]\n","> round 4 final model recall_metric = [50.8672833442688]\n","> round 4 final model auc_metric= [0.6656484007835388]\n","> round 4 final model prc_metric= [0.48529958724975586]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 5 start, random seed= 5\n","\n","> client 1 started learning...........\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 30ms/step - loss: 0.2833 - accuracy: 0.8256 - tp: 4160.0000 - fp: 1459.0000 - tn: 9871.0000 - fn: 1505.0000 - precision: 0.7403 - recall: 0.7343 - auc: 0.8383 - prc: 0.7151\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0774 - accuracy: 0.9851 - tp: 3103.0000 - fp: 59.0000 - tn: 6313.0000 - fn: 83.0000 - precision: 0.9813 - recall: 0.9739 - auc: 0.9986 - prc: 0.9973\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0223 - accuracy: 0.9968 - tp: 3165.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 21.0000 - precision: 0.9969 - recall: 0.9934 - auc: 0.9997 - prc: 0.9993\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0105 - accuracy: 0.9982 - tp: 3173.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0066 - accuracy: 0.9987 - tp: 3176.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0055 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 0.9987 - tp: 3176.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 0.9984 - tp: 3175.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 11.0000 - precision: 0.9987 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0049 - accuracy: 0.9982 - tp: 3173.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 0.9998 - prc: 0.9995\n","Score for fold 1: loss of 0.11671067029237747; accuracy of 96.90141081809998%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0825 - accuracy: 0.9797 - tp: 3083.0000 - fp: 90.0000 - tn: 6284.0000 - fn: 104.0000 - precision: 0.9716 - recall: 0.9674 - auc: 0.9971 - prc: 0.9944\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0768 - accuracy: 0.9796 - tp: 3078.0000 - fp: 86.0000 - tn: 6288.0000 - fn: 109.0000 - precision: 0.9728 - recall: 0.9658 - auc: 0.9980 - prc: 0.9963\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0159 - accuracy: 0.9976 - tp: 3169.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 18.0000 - precision: 0.9984 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0063 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0049 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0046 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.01935635134577751; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9973 - tp: 3170.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 17.0000 - precision: 0.9972 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0054 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9981 - tp: 3174.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 13.0000 - precision: 0.9984 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0038548363372683525; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9984 - tp: 3176.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9987 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.008592301048338413; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.01356327161192894; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0045 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9984 - tp: 3176.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9987 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.007717754226177931; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.4812399058428127e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.013286517933011055; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 2.3228974896483123e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.013867707923054695; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.11671067029237747 - Accuracy: 96.90141081809998%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.01935635134577751 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0038548363372683525 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.008592301048338413 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.01356327161192894 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.007717754226177931 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.4812399058428127e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.013286517933011055 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 2.3228974896483123e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.013867707923054695 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.48298454284668 (+- 0.8759560890034979)\n","> Loss: 0.019698745209188927\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 8ms/step - loss: 0.5325 - accuracy: 0.9476 - tp: 2282.0000 - fp: 193.0000 - tn: 4765.0000 - fn: 197.0000 - precision: 0.9220 - recall: 0.9205 - auc: 0.9620 - prc: 0.9279\n","\n",">round 5  client 1 evaluation training metrics:\n","[0.00425704987719655, 0.9987762570381165, 3530.0, 2.0, 7080.0, 11.0, 0.9994337558746338, 0.9968935251235962, 0.9999945759773254, 0.9999892711639404]\n","\n",">round 5  client 1 evaluation metrics:\n","[0.5324878096580505, 0.9475594758987427, 2282.0, 193.0, 4765.0, 197.0, 0.9220201969146729, 0.9205324649810791, 0.9619790315628052, 0.9279347658157349]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 31ms/step - loss: 0.3397 - accuracy: 0.9385 - tp: 5124.0000 - fp: 505.0000 - tn: 10825.0000 - fn: 541.0000 - precision: 0.9103 - recall: 0.9045 - auc: 0.9678 - prc: 0.9388\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0713 - accuracy: 0.9851 - tp: 3104.0000 - fp: 60.0000 - tn: 6312.0000 - fn: 82.0000 - precision: 0.9810 - recall: 0.9743 - auc: 0.9989 - prc: 0.9978\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0277 - accuracy: 0.9942 - tp: 3155.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 31.0000 - precision: 0.9925 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0173 - accuracy: 0.9949 - tp: 3158.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 28.0000 - precision: 0.9934 - recall: 0.9912 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0158 - accuracy: 0.9948 - tp: 3158.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 28.0000 - precision: 0.9931 - recall: 0.9912 - auc: 0.9999 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0227 - accuracy: 0.9938 - tp: 3147.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 39.0000 - precision: 0.9937 - recall: 0.9878 - auc: 0.9999 - prc: 0.9997\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0144 - accuracy: 0.9959 - tp: 3163.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 23.0000 - precision: 0.9950 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9962 - tp: 3165.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 21.0000 - precision: 0.9953 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0101 - accuracy: 0.9952 - tp: 3161.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 25.0000 - precision: 0.9934 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9958 - tp: 3165.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 0.287252813577652; accuracy of 93.80281567573547%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0744 - accuracy: 0.9842 - tp: 3109.0000 - fp: 73.0000 - tn: 6301.0000 - fn: 78.0000 - precision: 0.9771 - recall: 0.9755 - auc: 0.9971 - prc: 0.9941\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0312 - accuracy: 0.9925 - tp: 3150.0000 - fp: 35.0000 - tn: 6339.0000 - fn: 37.0000 - precision: 0.9890 - recall: 0.9884 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0168 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0110 - accuracy: 0.9968 - tp: 3171.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0126 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0103 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0095 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0096 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.02671469934284687; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0105 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0113 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0985 - accuracy: 0.9782 - tp: 3083.0000 - fp: 104.0000 - tn: 6270.0000 - fn: 104.0000 - precision: 0.9674 - recall: 0.9674 - auc: 0.9955 - prc: 0.9911\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0500 - accuracy: 0.9874 - tp: 3124.0000 - fp: 57.0000 - tn: 6317.0000 - fn: 63.0000 - precision: 0.9821 - recall: 0.9802 - auc: 0.9993 - prc: 0.9986\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0217 - accuracy: 0.9950 - tp: 3162.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 25.0000 - precision: 0.9928 - recall: 0.9922 - auc: 0.9996 - prc: 0.9993\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0157 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0202 - accuracy: 0.9936 - tp: 3156.0000 - fp: 30.0000 - tn: 6344.0000 - fn: 31.0000 - precision: 0.9906 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0559 - accuracy: 0.9880 - tp: 3127.0000 - fp: 55.0000 - tn: 6319.0000 - fn: 60.0000 - precision: 0.9827 - recall: 0.9812 - auc: 0.9978 - prc: 0.9958\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0352 - accuracy: 0.9916 - tp: 3147.0000 - fp: 40.0000 - tn: 6334.0000 - fn: 40.0000 - precision: 0.9874 - recall: 0.9874 - auc: 0.9994 - prc: 0.9988\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0136 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 3: loss of 0.17467738687992096; accuracy of 95.76271176338196%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0235 - accuracy: 0.9929 - tp: 3152.0000 - fp: 33.0000 - tn: 6341.0000 - fn: 35.0000 - precision: 0.9896 - recall: 0.9890 - auc: 0.9998 - prc: 0.9997\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0151 - accuracy: 0.9953 - tp: 3164.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0107 - accuracy: 0.9960 - tp: 3167.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9943 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0096 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0108 - accuracy: 0.9949 - tp: 3162.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 25.0000 - precision: 0.9925 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0096 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.010341222397983074; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0097 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Score for fold 5: loss of 0.01986902393400669; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0094 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0091 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0075 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0097 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.02543356455862522; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0103 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0092 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0084 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0083 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0083 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.008302876725792885; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9953 - tp: 3164.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0091 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9959 - tp: 3166.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 21.0000 - precision: 0.9943 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.002207114128395915; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3167.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9943 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0866 - accuracy: 0.9809 - tp: 3095.0000 - fp: 91.0000 - tn: 6283.0000 - fn: 92.0000 - precision: 0.9714 - recall: 0.9711 - auc: 0.9970 - prc: 0.9945\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0761 - accuracy: 0.9816 - tp: 3094.0000 - fp: 83.0000 - tn: 6291.0000 - fn: 93.0000 - precision: 0.9739 - recall: 0.9708 - auc: 0.9975 - prc: 0.9957\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0675 - accuracy: 0.9839 - tp: 3102.0000 - fp: 69.0000 - tn: 6305.0000 - fn: 85.0000 - precision: 0.9782 - recall: 0.9733 - auc: 0.9986 - prc: 0.9973\n","Score for fold 9: loss of 0.6346534490585327; accuracy of 87.00565099716187%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0350 - accuracy: 0.9899 - tp: 3129.0000 - fp: 39.0000 - tn: 6335.0000 - fn: 58.0000 - precision: 0.9877 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0194 - accuracy: 0.9935 - tp: 3152.0000 - fp: 27.0000 - tn: 6347.0000 - fn: 35.0000 - precision: 0.9915 - recall: 0.9890 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0137 - accuracy: 0.9947 - tp: 3159.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 28.0000 - precision: 0.9928 - recall: 0.9912 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0123 - accuracy: 0.9945 - tp: 3158.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 29.0000 - precision: 0.9925 - recall: 0.9909 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9955 - tp: 3162.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 25.0000 - precision: 0.9943 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9952 - tp: 3161.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 26.0000 - precision: 0.9937 - recall: 0.9918 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0106 - accuracy: 0.9949 - tp: 3162.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 25.0000 - precision: 0.9925 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0103 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9953 - tp: 3162.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 25.0000 - precision: 0.9937 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0100 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Score for fold 10: loss of 0.0024909295607358217; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.287252813577652 - Accuracy: 93.80281567573547%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.02671469934284687 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.17467738687992096 - Accuracy: 95.76271176338196%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.010341222397983074 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.01986902393400669 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.02543356455862522 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.008302876725792885 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.002207114128395915 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.6346534490585327 - Accuracy: 87.00565099716187%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.0024909295607358217 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 97.28046894073486 (+- 3.925450356450802)\n","> Loss: 0.11919430801644922\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0092 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","78/78 [==============================] - 1s 10ms/step - loss: 0.5119 - accuracy: 0.9342 - tp: 2232.0000 - fp: 242.0000 - tn: 4716.0000 - fn: 247.0000 - precision: 0.9022 - recall: 0.9004 - auc: 0.9626 - prc: 0.9332\n","\n",">round 5  client 2 evaluation training metrics:\n","[0.009205920621752739, 0.9962345957756042, 3521.0, 20.0, 7062.0, 20.0, 0.994351863861084, 0.994351863861084, 0.9999688863754272, 0.9999379515647888]\n","\n",">round 5  client 2 evaluation metrics:\n","[0.5118794441223145, 0.9342476725578308, 2232.0, 242.0, 4716.0, 247.0, 0.9021826982498169, 0.900363028049469, 0.9626278877258301, 0.9331912994384766]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 10s 29ms/step - loss: 0.2200 - accuracy: 0.9469 - tp: 5205.0000 - fp: 442.0000 - tn: 10888.0000 - fn: 460.0000 - precision: 0.9217 - recall: 0.9188 - auc: 0.9747 - prc: 0.9530\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0429 - accuracy: 0.9935 - tp: 3154.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 32.0000 - precision: 0.9906 - recall: 0.9900 - auc: 0.9993 - prc: 0.9988\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0162 - accuracy: 0.9969 - tp: 3170.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9956 - recall: 0.9950 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0114 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0122 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9995 - prc: 0.9990\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0083 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9995 - prc: 0.9990\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0055 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0084 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9997 - prc: 0.9995\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0066 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.11567384004592896; accuracy of 96.43192291259766%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0253 - accuracy: 0.9935 - tp: 3154.0000 - fp: 29.0000 - tn: 6345.0000 - fn: 33.0000 - precision: 0.9909 - recall: 0.9896 - auc: 0.9996 - prc: 0.9992\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0265 - accuracy: 0.9925 - tp: 3151.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 36.0000 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - prc: 0.9996\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0150 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0064 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0054 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.026296868920326233; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0078 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0810 - accuracy: 0.9821 - tp: 3101.0000 - fp: 85.0000 - tn: 6289.0000 - fn: 86.0000 - precision: 0.9733 - recall: 0.9730 - auc: 0.9970 - prc: 0.9942\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0271 - accuracy: 0.9931 - tp: 3153.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 34.0000 - precision: 0.9900 - recall: 0.9893 - auc: 0.9993 - prc: 0.9987\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0113 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0153 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.028967345133423805; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0055 - accuracy: 0.9982 - tp: 3178.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0066 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 0.9998 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0087 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9997 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0250 - accuracy: 0.9940 - tp: 3158.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 29.0000 - precision: 0.9912 - recall: 0.9909 - auc: 0.9996 - prc: 0.9992\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0155 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - prc: 0.9998\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.001435768324881792; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.012628136202692986; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0031 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.02425115369260311; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0050 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.010779820382595062; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.024908915162086487; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 4.262895890860818e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.0038047709967941046; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.11567384004592896 - Accuracy: 96.43192291259766%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.026296868920326233 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.028967345133423805 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.001435768324881792 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.012628136202692986 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.02425115369260311 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.010779820382595062 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.024908915162086487 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 4.262895890860818e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.0038047709967941046 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.41720247268677 (+- 1.0092488417902148)\n","> Loss: 0.024878924782024116\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 13ms/step - loss: 0.6886 - accuracy: 0.9312 - tp: 2222.0000 - fp: 255.0000 - tn: 4703.0000 - fn: 257.0000 - precision: 0.8971 - recall: 0.8963 - auc: 0.9510 - prc: 0.9098\n","\n",">round 5  client 3 evaluation training metrics:\n","[0.0023728522937744856, 0.9988703727722168, 3535.0, 6.0, 7076.0, 6.0, 0.9983055591583252, 0.9983055591583252, 0.9999974370002747, 0.9999948143959045]\n","\n",">round 5  client 3 evaluation metrics:\n","[0.6885960102081299, 0.9311550259590149, 2222.0, 255.0, 4703.0, 257.0, 0.8970528841018677, 0.8963291645050049, 0.9509982466697693, 0.9097880125045776]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.2634 - accuracy: 0.9432 - tp: 5172.0000 - fp: 473.0000 - tn: 10857.0000 - fn: 493.0000 - precision: 0.9162 - recall: 0.9130 - auc: 0.9667 - prc: 0.9375\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0670 - accuracy: 0.9865 - tp: 3115.0000 - fp: 58.0000 - tn: 6314.0000 - fn: 71.0000 - precision: 0.9817 - recall: 0.9777 - auc: 0.9988 - prc: 0.9980\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0140 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0060 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.19862335920333862; accuracy of 96.23352289199829%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0429 - accuracy: 0.9910 - tp: 3142.0000 - fp: 42.0000 - tn: 6330.0000 - fn: 44.0000 - precision: 0.9868 - recall: 0.9862 - auc: 0.9992 - prc: 0.9986\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0162 - accuracy: 0.9972 - tp: 3172.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 14.0000 - precision: 0.9959 - recall: 0.9956 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.00737022003158927; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3181.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9991 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.8945e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4647e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9034e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0100e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.8184e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6019e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4726e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4997e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.01375674270093441; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0021 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 3.8448157283710316e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.5281e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.9715e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.3626e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.7211e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2929e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1254e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0647e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.6378e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.0164e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 3.6136e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.029059994965791702; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0031 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 9.912575478665531e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.5548e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.2112e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.9234e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.7533e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.7569e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8723e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7021e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2446e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4242e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7836e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.006567028351128101; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8284e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6434e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4737e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.5077e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.3928e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 2.9168899345677346e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.8259e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7688e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6565e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7279e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.9119e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4700e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5339e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 1.3479448170983233e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.8173e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.6758e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.2820e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 9.9679e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.5889e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 6.99267638992751e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.19862335920333862 - Accuracy: 96.23352289199829%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.00737022003158927 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.01375674270093441 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 3.8448157283710316e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.029059994965791702 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 9.912575478665531e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.006567028351128101 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 2.9168899345677346e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.3479448170983233e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 6.99267638992751e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.52918946743011 (+- 1.105350112788812)\n","> Loss: 0.025556456018875906\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 8.0466e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.4659 - accuracy: 0.9462 - tp: 2279.0000 - fp: 200.0000 - tn: 4758.0000 - fn: 200.0000 - precision: 0.9193 - recall: 0.9193 - auc: 0.9694 - prc: 0.9447\n","\n",">round 5  client 4 evaluation training metrics:\n","[0.0008046641014516354, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997019767761, 0.9999994039535522]\n","\n",">round 5  client 4 evaluation metrics:\n","[0.4658879339694977, 0.9462148547172546, 2279.0, 200.0, 4758.0, 200.0, 0.9193223118782043, 0.9193223118782043, 0.9694044589996338, 0.9447450637817383]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 30ms/step - loss: 0.2370 - accuracy: 0.9501 - tp: 5235.0000 - fp: 418.0000 - tn: 10912.0000 - fn: 430.0000 - precision: 0.9261 - recall: 0.9241 - auc: 0.9766 - prc: 0.9566\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0563 - accuracy: 0.9888 - tp: 3127.0000 - fp: 48.0000 - tn: 6324.0000 - fn: 59.0000 - precision: 0.9849 - recall: 0.9815 - auc: 0.9989 - prc: 0.9979\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0133 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0051 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0022 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0025 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.17435915768146515; accuracy of 97.0809817314148%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0657 - accuracy: 0.9884 - tp: 3129.0000 - fp: 54.0000 - tn: 6318.0000 - fn: 57.0000 - precision: 0.9830 - recall: 0.9821 - auc: 0.9982 - prc: 0.9966\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0242 - accuracy: 0.9967 - tp: 3169.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9953 - recall: 0.9947 - auc: 0.9994 - prc: 0.9988\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0070 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.1324e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8062e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.5957e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.3592e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.04062575101852417; accuracy of 99.34086799621582%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0052 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.3876e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.4057e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 8.0132e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.3615e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5123e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2810e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0001719190477160737; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.1754e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.0080e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2918e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2548e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5145e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9695e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4534e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.2778e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.7022e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8795e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.00028698932146653533; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.3118e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3448e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.9719e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3896e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0908e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0595e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1852e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8981e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5524e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1157e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 3.102883056271821e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1288e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2175e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.1903e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1384e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.8386e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.5216e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.9956e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2376e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3829e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1265e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.5254191566782538e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.8968e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.4541e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.2425e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9999e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9597e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1104e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.4921e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.7935e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.6200e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 3.0743e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.010292242281138897; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9124e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7596e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.8985e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.7932e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0307e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2660e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7924e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6750e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5743e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 1.0855027539946605e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 33ms/step - loss: 6.5342e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.5819e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.3852e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9501e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5786e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4443e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2851e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0690e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6963e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8759e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 8.136051292240154e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.9041e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.0794e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2995e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2495e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.5532e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 3.8794e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 3.1533e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 2.8209e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 2.3716e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 2.0775e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.014046426862478256; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.17435915768146515 - Accuracy: 97.0809817314148%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.04062575101852417 - Accuracy: 99.34086799621582%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0001719190477160737 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00028698932146653533 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 3.102883056271821e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.5254191566782538e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.010292242281138897 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 1.0855027539946605e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 8.136051292240154e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.014046426862478256 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.6045196056366 (+- 0.8638292204786172)\n","> Loss: 0.023984776031375075\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.5187 - accuracy: 0.9457 - tp: 2276.0000 - fp: 201.0000 - tn: 4757.0000 - fn: 203.0000 - precision: 0.9189 - recall: 0.9181 - auc: 0.9653 - prc: 0.9357\n","\n",">round 5  client 5 evaluation training metrics:\n","[0.0014228068757802248, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999998211860657, 0.9999995827674866]\n","\n",">round 5  client 5 evaluation metrics:\n","[0.5186606049537659, 0.9456770420074463, 2276.0, 201.0, 4757.0, 203.0, 0.9188534617424011, 0.9181121587753296, 0.9652628302574158, 0.935682475566864]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 9s 31ms/step - loss: 0.2244 - accuracy: 0.9521 - tp: 5250.0000 - fp: 399.0000 - tn: 10931.0000 - fn: 415.0000 - precision: 0.9294 - recall: 0.9267 - auc: 0.9751 - prc: 0.9526\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0417 - accuracy: 0.9923 - tp: 3147.0000 - fp: 35.0000 - tn: 6337.0000 - fn: 39.0000 - precision: 0.9890 - recall: 0.9878 - auc: 0.9996 - prc: 0.9993\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0084 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0031 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0258e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.8490e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 3.0830e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.17095309495925903; accuracy of 96.79849147796631%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0283 - accuracy: 0.9953 - tp: 3162.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 24.0000 - precision: 0.9934 - recall: 0.9925 - auc: 0.9987 - prc: 0.9977\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0264 - accuracy: 0.9951 - tp: 3162.0000 - fp: 23.0000 - tn: 6349.0000 - fn: 24.0000 - precision: 0.9928 - recall: 0.9925 - auc: 0.9993 - prc: 0.9986\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0094 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0024 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3925e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.2574e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1991e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.8906e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4657e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.015160111710429192; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0061 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0360 - accuracy: 0.9925 - tp: 3149.0000 - fp: 35.0000 - tn: 6337.0000 - fn: 37.0000 - precision: 0.9890 - recall: 0.9884 - auc: 0.9992 - prc: 0.9985\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0199 - accuracy: 0.9956 - tp: 3165.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 0.9997 - prc: 0.9993\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0055 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4608e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.5480e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.7493e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.0805e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.009524793364107609; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0017 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.4252e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5569e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2496e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3390e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4863e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6848e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1882e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4417e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 8.424399857176468e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6515e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2659e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4495e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6467e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.8116e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.7152e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.7762e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.0945e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.3776e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.0470e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 5.654709821101278e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7811e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.3665e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.7326e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9132e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7395e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1259e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9757e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8053e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.4181e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.7330e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.9396919014980085e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7115e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.7233e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.6543e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.6947e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.5407e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.0927e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.0223e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6934e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3561e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9340e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 2.1467039914568886e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9455e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9945e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7259e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6336e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6887e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8892e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.3966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.1616e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 1.2018887900921982e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 3.0553e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.6648e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.0666e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.8462e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4113e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4170e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8629e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.1466e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.9598e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.4331e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.008106011897325516; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.8092e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6800e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.2318e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0637 - accuracy: 0.9908 - tp: 3142.0000 - fp: 44.0000 - tn: 6328.0000 - fn: 44.0000 - precision: 0.9862 - recall: 0.9862 - auc: 0.9962 - prc: 0.9929\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1799 - accuracy: 0.9606 - tp: 2988.0000 - fp: 179.0000 - tn: 6193.0000 - fn: 198.0000 - precision: 0.9435 - recall: 0.9379 - auc: 0.9909 - prc: 0.9841\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0488 - accuracy: 0.9879 - tp: 3126.0000 - fp: 56.0000 - tn: 6316.0000 - fn: 60.0000 - precision: 0.9824 - recall: 0.9812 - auc: 0.9991 - prc: 0.9983\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9982 - tp: 3177.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.1675458401441574; accuracy of 97.55178689956665%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.17095309495925903 - Accuracy: 96.79849147796631%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.015160111710429192 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.009524793364107609 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 8.424399857176468e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 5.654709821101278e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.9396919014980085e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 2.1467039914568886e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 1.2018887900921982e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.008106011897325516 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.1675458401441574 - Accuracy: 97.55178689956665%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.34086561203003 (+- 1.1053513821796057)\n","> Loss: 0.0371483526018892\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0221 - accuracy: 0.9964 - tp: 3521.0000 - fp: 19.0000 - tn: 7061.0000 - fn: 19.0000 - precision: 0.9946 - recall: 0.9946 - auc: 0.9990 - prc: 0.9981\n","78/78 [==============================] - 1s 10ms/step - loss: 0.7009 - accuracy: 0.9186 - tp: 2175.0000 - fp: 301.0000 - tn: 4657.0000 - fn: 304.0000 - precision: 0.8784 - recall: 0.8774 - auc: 0.9494 - prc: 0.9092\n","\n",">round 5  client 6 evaluation training metrics:\n","[0.022069571539759636, 0.9964218735694885, 3521.0, 19.0, 7061.0, 19.0, 0.9946327805519104, 0.9946327805519104, 0.99903804063797, 0.9981130361557007]\n","\n",">round 5  client 6 evaluation metrics:\n","[0.7008823752403259, 0.9186499714851379, 2175.0, 301.0, 4657.0, 304.0, 0.8784329295158386, 0.8773698806762695, 0.9493954181671143, 0.9092029929161072]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.1990 - accuracy: 0.9423 - tp: 5167.0000 - fp: 483.0000 - tn: 10847.0000 - fn: 498.0000 - precision: 0.9145 - recall: 0.9121 - auc: 0.9701 - prc: 0.9454\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0358 - accuracy: 0.9930 - tp: 3150.0000 - fp: 31.0000 - tn: 6341.0000 - fn: 36.0000 - precision: 0.9903 - recall: 0.9887 - auc: 0.9998 - prc: 0.9996\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0046 - accuracy: 0.9992 - tp: 3181.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9991 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.1103314533829689; accuracy of 98.02259802818298%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0350 - accuracy: 0.9932 - tp: 3151.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 35.0000 - precision: 0.9906 - recall: 0.9890 - auc: 0.9982 - prc: 0.9967\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0292 - accuracy: 0.9946 - tp: 3159.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 27.0000 - precision: 0.9921 - recall: 0.9915 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0177 - accuracy: 0.9953 - tp: 3163.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0222 - accuracy: 0.9954 - tp: 3164.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9994 - prc: 0.9988\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3632e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.02996889501810074; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0142 - accuracy: 0.9965 - tp: 3169.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0113 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.013730010017752647; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0059 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0144 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0116 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9995 - prc: 0.9990\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9982 - tp: 3177.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.006590709090232849; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.6904e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.8959e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.4429e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1952e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.8552e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.7528e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9985e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2592e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.3314e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.01944163627922535; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.002024353016167879; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.5988573068170808e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 1.0712013136071619e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 1.0937177648884244e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 1.2072172467014752e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.1103314533829689 - Accuracy: 98.02259802818298%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.02996889501810074 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.013730010017752647 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.006590709090232849 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.01944163627922535 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.002024353016167879 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.5988573068170808e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 1.0712013136071619e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.0937177648884244e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 1.2072172467014752e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.65159952640533 (+- 0.5712924282153072)\n","> Loss: 0.01821367667407685\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 9.5329e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.6966 - accuracy: 0.9357 - tp: 2238.0000 - fp: 237.0000 - tn: 4721.0000 - fn: 241.0000 - precision: 0.9042 - recall: 0.9028 - auc: 0.9523 - prc: 0.9107\n","\n",">round 5  client 7 evaluation training metrics:\n","[0.0009532936383038759, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997019767761, 0.9999992251396179]\n","\n",">round 5  client 7 evaluation metrics:\n","[0.696577250957489, 0.9357267618179321, 2238.0, 237.0, 4721.0, 241.0, 0.9042423963546753, 0.9027833938598633, 0.9523081183433533, 0.9106583595275879]\n","\n","=============================================================\n","\n","> round 5 average training auc= 0.2490147395978353\n","> round 5 average training loss= 0.038382177047697044\n","Epoch 1/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9960 - tp: 3520.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 21.0000 - precision: 0.9941 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9961 - tp: 3520.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 21.0000 - precision: 0.9944 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9962 - tp: 3520.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 21.0000 - precision: 0.9946 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9955 - tp: 3517.0000 - fp: 24.0000 - tn: 7058.0000 - fn: 24.0000 - precision: 0.9932 - recall: 0.9932 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","36/36 [==============================] - 1s 29ms/step - loss: 0.0089 - accuracy: 0.9964 - tp: 3522.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 19.0000 - precision: 0.9946 - recall: 0.9946 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 0.9955 - tp: 3517.0000 - fp: 24.0000 - tn: 7058.0000 - fn: 24.0000 - precision: 0.9932 - recall: 0.9932 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9960 - tp: 3519.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 22.0000 - precision: 0.9941 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","> model 2 retrained, original loss= 0.11919430801644922 , retrained loss= 0.008965074084699154 epoch count 20.0\n","> round 5 average epoch count= 11.428571428571429\n"," 1/78 [..............................] - ETA: 2s"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["78/78 [==============================] - 0s 5ms/step\n","> round 5 test auc= 0.233145856767904\n","111/111 [==============================] - 1s 10ms/step - loss: 2.0871 - accuracy: 0.8149 - tp: 2557.0000 - fp: 982.0000 - tn: 6100.0000 - fn: 984.0000 - precision: 0.7225 - recall: 0.7221 - auc: 0.8295 - prc: 0.7046\n","\n","> round 5 final model training loss_metric= [2.087085247039795]\n","> round 5 final model training TP_metric= [2557.0]\n","> round 5 final model training FP_metric= [982.0]\n","> round 5 final model training TN_metric= [6100.0]\n","> round 5 final model training FN_metric= [984.0]\n","> round 5 final model training accuracy_metric= [81.49298429489136]\n","> round 5 final model training precision_metric= [72.25204706192017]\n","> round 5 final model training recall_metric = [72.21124172210693]\n","> round 5 final model training auc_metric= [0.8295177221298218]\n","> round 5 final model training prc_metric= [0.7046399712562561]\n","\n","78/78 [==============================] - 1s 8ms/step - loss: 1.5998 - accuracy: 0.8552 - tp: 1938.0000 - fp: 536.0000 - tn: 4422.0000 - fn: 541.0000 - precision: 0.7833 - recall: 0.7818 - auc: 0.8735 - prc: 0.7697\n","> round 5 final model loss_metric= [1.599827527999878]\n","> round 5 final model TP_metric= [1938.0]\n","> round 5 final model FP_metric= [536.0]\n","> round 5 final model TN_metric= [4422.0]\n","> round 5 final model FN_metric= [541.0]\n","> round 5 final model accuracy_metric= [85.51835417747498]\n","> round 5 final model precision_metric= [78.33468317985535]\n","> round 5 final model recall_metric = [78.17668318748474]\n","> round 5 final model auc_metric= [0.8735008239746094]\n","> round 5 final model prc_metric= [0.7697172164916992]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 6 start, random seed= 6\n","\n","> client 1 started learning...........\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.2520 - accuracy: 0.9100 - tp: 4887.0000 - fp: 751.0000 - tn: 10579.0000 - fn: 778.0000 - precision: 0.8668 - recall: 0.8627 - auc: 0.9347 - prc: 0.8770\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0502 - accuracy: 0.9899 - tp: 3131.0000 - fp: 42.0000 - tn: 6330.0000 - fn: 55.0000 - precision: 0.9868 - recall: 0.9827 - auc: 0.9992 - prc: 0.9984\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0157 - accuracy: 0.9978 - tp: 3171.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 15.0000 - precision: 0.9981 - recall: 0.9953 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9985 - tp: 3174.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 0.9998 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0055 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9984 - tp: 3174.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.2732517421245575; accuracy of 95.30516266822815%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0493 - accuracy: 0.9889 - tp: 3129.0000 - fp: 48.0000 - tn: 6326.0000 - fn: 58.0000 - precision: 0.9849 - recall: 0.9818 - auc: 0.9980 - prc: 0.9963\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0284 - accuracy: 0.9931 - tp: 3149.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 38.0000 - precision: 0.9912 - recall: 0.9881 - auc: 0.9998 - prc: 0.9996\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9979 - tp: 3173.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 14.0000 - precision: 0.9981 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9982 - tp: 3175.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9984 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0164 - accuracy: 0.9964 - tp: 3166.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 21.0000 - precision: 0.9959 - recall: 0.9934 - auc: 0.9999 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0055 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.011135227046906948; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0050 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9978 - tp: 3171.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 16.0000 - precision: 0.9984 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.00936892256140709; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0038 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.02446567639708519; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.0036721620708703995; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3175.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 12.0000 - precision: 0.9997 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.8783495761454105e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0188 - accuracy: 0.9969 - tp: 3170.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 17.0000 - precision: 0.9959 - recall: 0.9947 - auc: 0.9989 - prc: 0.9980\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1236 - accuracy: 0.9700 - tp: 3038.0000 - fp: 138.0000 - tn: 6236.0000 - fn: 149.0000 - precision: 0.9565 - recall: 0.9532 - auc: 0.9945 - prc: 0.9900\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0440 - accuracy: 0.9888 - tp: 3131.0000 - fp: 51.0000 - tn: 6323.0000 - fn: 56.0000 - precision: 0.9840 - recall: 0.9824 - auc: 0.9995 - prc: 0.9990\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0198 - accuracy: 0.9946 - tp: 3161.0000 - fp: 26.0000 - tn: 6348.0000 - fn: 26.0000 - precision: 0.9918 - recall: 0.9918 - auc: 0.9997 - prc: 0.9993\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0073 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.24128839373588562; accuracy of 94.16195750236511%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0197 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9994 - prc: 0.9989\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0125 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0055 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.008041691966354847; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0030 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.015654562041163445; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 4.340985105955042e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.2732517421245575 - Accuracy: 95.30516266822815%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.011135227046906948 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.00936892256140709 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.02446567639708519 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0036721620708703995 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.8783495761454105e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.24128839373588562 - Accuracy: 94.16195750236511%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.008041691966354847 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.015654562041163445 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 4.340985105955042e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.8148844242096 (+- 2.059518805700151)\n","> Loss: 0.05869405712910521\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 4ms/step\n","111/111 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.5143 - accuracy: 0.9438 - tp: 2268.0000 - fp: 207.0000 - tn: 4751.0000 - fn: 211.0000 - precision: 0.9164 - recall: 0.9149 - auc: 0.9652 - prc: 0.9362\n","\n",">round 6  client 1 evaluation training metrics:\n","[0.003786359215155244, 0.9987762570381165, 3530.0, 2.0, 7080.0, 11.0, 0.9994337558746338, 0.9968935251235962, 0.9999945759773254, 0.9999892711639404]\n","\n",">round 6  client 1 evaluation metrics:\n","[0.5142844915390015, 0.9437945485115051, 2268.0, 207.0, 4751.0, 211.0, 0.9163636565208435, 0.9148850440979004, 0.9651898145675659, 0.9361619353294373]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.1728 - accuracy: 0.9516 - tp: 5242.0000 - fp: 399.0000 - tn: 10931.0000 - fn: 423.0000 - precision: 0.9293 - recall: 0.9253 - auc: 0.9786 - prc: 0.9600\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0560 - accuracy: 0.9863 - tp: 3114.0000 - fp: 59.0000 - tn: 6313.0000 - fn: 72.0000 - precision: 0.9814 - recall: 0.9774 - auc: 0.9990 - prc: 0.9980\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0221 - accuracy: 0.9931 - tp: 3150.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 36.0000 - precision: 0.9906 - recall: 0.9887 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0145 - accuracy: 0.9951 - tp: 3160.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 26.0000 - precision: 0.9934 - recall: 0.9918 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0130 - accuracy: 0.9958 - tp: 3163.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 23.0000 - precision: 0.9947 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0127 - accuracy: 0.9962 - tp: 3165.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 21.0000 - precision: 0.9953 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9953 - tp: 3161.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 25.0000 - precision: 0.9937 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0124 - accuracy: 0.9955 - tp: 3162.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 24.0000 - precision: 0.9940 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9954 - tp: 3161.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 25.0000 - precision: 0.9940 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0111 - accuracy: 0.9951 - tp: 3159.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 27.0000 - precision: 0.9937 - recall: 0.9915 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 0.0554419569671154; accuracy of 98.40375781059265%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0173 - accuracy: 0.9945 - tp: 3158.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 29.0000 - precision: 0.9925 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0142 - accuracy: 0.9953 - tp: 3164.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0154 - accuracy: 0.9951 - tp: 3163.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 24.0000 - precision: 0.9928 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0142 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0160 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 0.9995 - prc: 0.9990\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0120 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0504 - accuracy: 0.9873 - tp: 3126.0000 - fp: 60.0000 - tn: 6314.0000 - fn: 61.0000 - precision: 0.9812 - recall: 0.9809 - auc: 0.9985 - prc: 0.9970\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0153 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0105 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.025760993361473083; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0117 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0087 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0086 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Score for fold 3: loss of 0.014479676261544228; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0084 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0085 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.011587999761104584; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0080 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.028224298730492592; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0094 - accuracy: 0.9962 - tp: 3168.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 19.0000 - precision: 0.9947 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0085 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0087 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.008127833716571331; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0083 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9960 - tp: 3167.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9943 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0084 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.010860441252589226; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1150 - accuracy: 0.9786 - tp: 3084.0000 - fp: 102.0000 - tn: 6272.0000 - fn: 103.0000 - precision: 0.9680 - recall: 0.9677 - auc: 0.9941 - prc: 0.9886\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1268 - accuracy: 0.9704 - tp: 3042.0000 - fp: 138.0000 - tn: 6236.0000 - fn: 145.0000 - precision: 0.9566 - recall: 0.9545 - auc: 0.9940 - prc: 0.9885\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0660 - accuracy: 0.9828 - tp: 3104.0000 - fp: 81.0000 - tn: 6293.0000 - fn: 83.0000 - precision: 0.9746 - recall: 0.9740 - auc: 0.9981 - prc: 0.9962\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0226 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9999 - prc: 0.9997\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0122 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0169 - accuracy: 0.9951 - tp: 3163.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 24.0000 - precision: 0.9928 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0132 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0093 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.08313193917274475; accuracy of 97.55178689956665%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0257 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9992 - prc: 0.9986\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0146 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0085 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Score for fold 9: loss of 0.03265518695116043; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0432 - accuracy: 0.9896 - tp: 3137.0000 - fp: 49.0000 - tn: 6325.0000 - fn: 50.0000 - precision: 0.9846 - recall: 0.9843 - auc: 0.9989 - prc: 0.9977\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0250 - accuracy: 0.9936 - tp: 3156.0000 - fp: 30.0000 - tn: 6344.0000 - fn: 31.0000 - precision: 0.9906 - recall: 0.9903 - auc: 0.9994 - prc: 0.9987\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0103 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0097 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0094 - accuracy: 0.9959 - tp: 3166.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 21.0000 - precision: 0.9943 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0090 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 10: loss of 0.007414216175675392; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.0554419569671154 - Accuracy: 98.40375781059265%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.025760993361473083 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.014479676261544228 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.011587999761104584 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.028224298730492592 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.008127833716571331 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.010860441252589226 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.08313193917274475 - Accuracy: 97.55178689956665%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.03265518695116043 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.007414216175675392 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.1247433423996 (+- 0.6573584266505823)\n","> Loss: 0.0277684542350471\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","78/78 [==============================] - 1s 9ms/step - loss: 0.4383 - accuracy: 0.9439 - tp: 2268.0000 - fp: 206.0000 - tn: 4752.0000 - fn: 211.0000 - precision: 0.9167 - recall: 0.9149 - auc: 0.9697 - prc: 0.9454\n","\n",">round 6  client 2 evaluation training metrics:\n","[0.008417606353759766, 0.9966111183166504, 3523.0, 18.0, 7064.0, 18.0, 0.9949166774749756, 0.9949166774749756, 0.9999718070030212, 0.9999439716339111]\n","\n",">round 6  client 2 evaluation metrics:\n","[0.438325971364975, 0.9439290165901184, 2268.0, 206.0, 4752.0, 211.0, 0.9167340397834778, 0.9148850440979004, 0.969741940498352, 0.945410966873169]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.1662 - accuracy: 0.9565 - tp: 5290.0000 - fp: 365.0000 - tn: 10965.0000 - fn: 375.0000 - precision: 0.9355 - recall: 0.9338 - auc: 0.9808 - prc: 0.9643\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0246 - accuracy: 0.9962 - tp: 3167.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9947 - recall: 0.9940 - auc: 0.9998 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0105 - accuracy: 0.9987 - tp: 3179.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9984 - recall: 0.9978 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0057 - accuracy: 0.9990 - tp: 3180.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9985 - tp: 3178.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9981 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0054 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9998 - prc: 0.9995\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0060 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9998 - prc: 0.9995\n","Score for fold 1: loss of 0.06423766165971756; accuracy of 98.8732397556305%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0128 - accuracy: 0.9980 - tp: 3177.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 0.9993 - prc: 0.9986\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0128 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0106 - accuracy: 0.9973 - tp: 3173.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 14.0000 - precision: 0.9962 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0147 - accuracy: 0.9964 - tp: 3169.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 18.0000 - precision: 0.9950 - recall: 0.9944 - auc: 0.9995 - prc: 0.9990\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0239 - accuracy: 0.9944 - tp: 3160.0000 - fp: 27.0000 - tn: 6347.0000 - fn: 27.0000 - precision: 0.9915 - recall: 0.9915 - auc: 0.9994 - prc: 0.9988\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0164 - accuracy: 0.9953 - tp: 3164.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9980 - tp: 3177.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.04542824253439903; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0166 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 0.9997 - prc: 0.9994\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0218 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9996 - prc: 0.9993\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0077 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0044 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0016045146621763706; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0032 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.00239075836725533; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.0001058033449226059; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3179.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 8.0000 - precision: 0.9981 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 2.7332336685503833e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0023 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.013214008882641792; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0038 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0100 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9994 - prc: 0.9992\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1094 - accuracy: 0.9812 - tp: 3097.0000 - fp: 90.0000 - tn: 6284.0000 - fn: 90.0000 - precision: 0.9718 - recall: 0.9718 - auc: 0.9939 - prc: 0.9883\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1677 - accuracy: 0.9573 - tp: 2973.0000 - fp: 194.0000 - tn: 6180.0000 - fn: 214.0000 - precision: 0.9387 - recall: 0.9329 - auc: 0.9918 - prc: 0.9849\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0317 - accuracy: 0.9953 - tp: 3163.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 24.0000 - precision: 0.9934 - recall: 0.9925 - auc: 0.9997 - prc: 0.9994\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0046 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0066 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.12279491126537323; accuracy of 97.45762944221497%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0105 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.014823470264673233; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0021 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0018 - accuracy: 0.9993 - tp: 3183.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.014121094718575478; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.06423766165971756 - Accuracy: 98.8732397556305%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.04542824253439903 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0016045146621763706 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00239075836725533 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0001058033449226059 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 2.7332336685503833e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.013214008882641792 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.12279491126537323 - Accuracy: 97.45762944221497%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.014823470264673233 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.014121094718575478 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.4635945558548 (+- 0.7531033911496213)\n","> Loss: 0.027874779803642013\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.5764 - accuracy: 0.9290 - tp: 2214.0000 - fp: 263.0000 - tn: 4695.0000 - fn: 265.0000 - precision: 0.8938 - recall: 0.8931 - auc: 0.9587 - prc: 0.9250\n","\n",">round 6  client 3 evaluation training metrics:\n","[0.0028808030765503645, 0.9990586638450623, 3536.0, 5.0, 7077.0, 5.0, 0.998587965965271, 0.998587965965271, 0.9999977350234985, 0.9999953508377075]\n","\n",">round 6  client 3 evaluation metrics:\n","[0.5763521194458008, 0.9290036559104919, 2214.0, 263.0, 4695.0, 265.0, 0.8938231468200684, 0.8931020498275757, 0.9587389826774597, 0.924950122833252]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 10s 30ms/step - loss: 0.1870 - accuracy: 0.9486 - tp: 5226.0000 - fp: 434.0000 - tn: 10896.0000 - fn: 439.0000 - precision: 0.9233 - recall: 0.9225 - auc: 0.9748 - prc: 0.9538\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0356 - accuracy: 0.9931 - tp: 3151.0000 - fp: 31.0000 - tn: 6341.0000 - fn: 35.0000 - precision: 0.9903 - recall: 0.9890 - auc: 0.9996 - prc: 0.9993\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.17587031424045563; accuracy of 96.98681831359863%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0248 - accuracy: 0.9956 - tp: 3165.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 0.9989 - prc: 0.9979\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0179 - accuracy: 0.9962 - tp: 3167.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9947 - recall: 0.9940 - auc: 0.9997 - prc: 0.9993\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0101 - accuracy: 0.9984 - tp: 3178.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.3456e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3838e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8069e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1339e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6580e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.011028070002794266; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 8.71233714860864e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9648e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7665e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 2.2467904273071326e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.3939e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2630e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8705e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3211e-04 - accuracy: 0.9998 - tp: 3184.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 2.0000 - precision: 1.0000 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4301e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.2169e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0104e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4427e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5220e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2256e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.008592100813984871; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.9991e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.9209e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.8114e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.2049e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.2327687727520242e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.9710e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4558e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4782e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8431e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 9.0679e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.537064599688165e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6899e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.5832e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5096e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.9078e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5370e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 4.4908092604600824e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.3620e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.7050e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.2051e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5619e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1952e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0821e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7065e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.6694e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9767e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.9213e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.02320709638297558; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0031 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9722e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 9.7526e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.8129e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.6038e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 1.3779220353171695e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.17587031424045563 - Accuracy: 96.98681831359863%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.011028070002794266 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 8.71233714860864e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 2.2467904273071326e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.008592100813984871 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.2327687727520242e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.537064599688165e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 4.4908092604600824e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.02320709638297558 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 1.3779220353171695e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.64218378067017 (+- 0.889119811845821)\n","> Loss: 0.021885314107930754\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 8.0279e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.3275 - accuracy: 0.9583 - tp: 2323.0000 - fp: 154.0000 - tn: 4804.0000 - fn: 156.0000 - precision: 0.9378 - recall: 0.9371 - auc: 0.9794 - prc: 0.9612\n","\n",">round 6  client 4 evaluation training metrics:\n","[0.0008027919102460146, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999996423721313, 0.9999994039535522]\n","\n",">round 6  client 4 evaluation metrics:\n","[0.327455997467041, 0.9583165049552917, 2323.0, 154.0, 4804.0, 156.0, 0.937828004360199, 0.9370713829994202, 0.9793639183044434, 0.9611697793006897]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.2623 - accuracy: 0.9566 - tp: 5292.0000 - fp: 365.0000 - tn: 10965.0000 - fn: 373.0000 - precision: 0.9355 - recall: 0.9342 - auc: 0.9813 - prc: 0.9646\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0480 - accuracy: 0.9900 - tp: 3135.0000 - fp: 45.0000 - tn: 6327.0000 - fn: 51.0000 - precision: 0.9858 - recall: 0.9840 - auc: 0.9992 - prc: 0.9984\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9985 - tp: 3178.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9981 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.1854933202266693; accuracy of 96.89265489578247%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0304 - accuracy: 0.9941 - tp: 3157.0000 - fp: 27.0000 - tn: 6345.0000 - fn: 29.0000 - precision: 0.9915 - recall: 0.9909 - auc: 0.9991 - prc: 0.9982\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9982 - tp: 3177.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 0.9998 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2809e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.3841e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.7219e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.4295e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.2651e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.015612689778208733; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.1516e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.6226e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.0370e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 32ms/step - loss: 6.0471e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.4769e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.0506e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.3810e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0655e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2526e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0002729768166318536; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4276e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9844e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8442e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7536e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1013e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1046e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4442e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.0176e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000       \n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.2127e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 2.557574953243602e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.0224e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.5991e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.2291e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0797e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9561e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.4456e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9220e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7633e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6922e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.4843e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 1.2379815416352358e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7348e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4077e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6619e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3638e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3573e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.4535e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2581e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2091e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.8636e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.9514e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.6828742445795797e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8194e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9555e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1290e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4539e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5119e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0256e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0488e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9941e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9225e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7515e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 7.83059931563912e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.4029e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3298e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1441e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1461e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3478e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3695e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2183e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.5748e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1414e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.6147e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 7.1631452556175645e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1499e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7091e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6326e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.8004e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4160e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.9675e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.9554e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.0286e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2738e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6621e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 4.646370143746026e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.8054e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1689e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1638e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.7756e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.5928e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.5522e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.9257e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 2.6929e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 2.3585e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.2316e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.011057263240218163; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.1854933202266693 - Accuracy: 96.89265489578247%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.015612689778208733 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0002729768166318536 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 2.557574953243602e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 1.2379815416352358e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.6828742445795797e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 7.83059931563912e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 7.1631452556175645e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 4.646370143746026e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.011057263240218163 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.65160012245178 (+- 0.9226430969766741)\n","> Loss: 0.021251067448383766\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 1s 6ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.4000 - accuracy: 0.9586 - tp: 2324.0000 - fp: 153.0000 - tn: 4805.0000 - fn: 155.0000 - precision: 0.9382 - recall: 0.9375 - auc: 0.9741 - prc: 0.9516\n","\n",">round 6  client 5 evaluation training metrics:\n","[0.0011250704992562532, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999998211860657, 0.9999996423721313]\n","\n",">round 6  client 5 evaluation metrics:\n","[0.40001824498176575, 0.9585854411125183, 2324.0, 153.0, 4805.0, 155.0, 0.9382317066192627, 0.93747478723526, 0.9740872979164124, 0.9516094923019409]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.1007 - accuracy: 0.9706 - tp: 5412.0000 - fp: 246.0000 - tn: 11084.0000 - fn: 253.0000 - precision: 0.9565 - recall: 0.9553 - auc: 0.9859 - prc: 0.9732\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0287 - accuracy: 0.9934 - tp: 3153.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 33.0000 - precision: 0.9906 - recall: 0.9896 - auc: 0.9998 - prc: 0.9996\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0091 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0035 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0015 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9024e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.08574047684669495; accuracy of 98.30508232116699%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0122 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0120 - accuracy: 0.9974 - tp: 3173.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0049 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 8.6363e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.6892e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.2839e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.0253312811255455; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.5613e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9617e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3616e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9872e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4668e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4438e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8083e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9185e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 7.042595825623721e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 3.1478e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 1.6831e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.2404e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.2194e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.1980e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1544e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1296e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.4588e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 3.7120e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.3085e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.011894836090505123; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.8228e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6981e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3577e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9921e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1791e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.5395e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.2061e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.1992e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.8544e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 3.1526375096291304e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 4.6396e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.3744e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.2816e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.8669e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.5518e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0409e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6779e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1266e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7513e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1616e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.5753468687762506e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8600e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6803e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0955e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7434e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.9078e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.7963e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1583e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.8009e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.3514e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2574e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.0891292731685098e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9611e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4972e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3466e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.6935e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3699e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.3594e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8027e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5544e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4963e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.5147e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 3.7620909552060766e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.9384e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.0472e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.9496e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.4898e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.9351e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 32ms/step - loss: 3.3954e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 2.7664e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 2.4616e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.1123e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.8404e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.008884016424417496; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000       \n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.5255e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2980e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6973e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3853e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6532e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8562e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8214e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.8627e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 3.3369287848472595e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.08574047684669495 - Accuracy: 98.30508232116699%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0253312811255455 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 7.042595825623721e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.011894836090505123 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 3.1526375096291304e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.5753468687762506e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.0891292731685098e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.7620909552060766e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.008884016424417496 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.3369287848472595e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.75517809391022 (+- 0.49861465813751454)\n","> Loss: 0.01319863066016751\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 3.9755e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.4677 - accuracy: 0.9523 - tp: 2301.0000 - fp: 177.0000 - tn: 4781.0000 - fn: 178.0000 - precision: 0.9286 - recall: 0.9282 - auc: 0.9674 - prc: 0.9394\n","\n",">round 6  client 6 evaluation training metrics:\n","[0.0003975524159613997, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 6  client 6 evaluation metrics:\n","[0.4677168130874634, 0.9522656798362732, 2301.0, 177.0, 4781.0, 178.0, 0.9285714030265808, 0.9281968474388123, 0.9673767685890198, 0.9393534064292908]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.1572 - accuracy: 0.9616 - tp: 5333.0000 - fp: 321.0000 - tn: 11009.0000 - fn: 332.0000 - precision: 0.9432 - recall: 0.9414 - auc: 0.9800 - prc: 0.9623\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0193 - accuracy: 0.9961 - tp: 3167.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 19.0000 - precision: 0.9943 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0057 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.027129318565130234; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0045 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0052 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.0033004479482769966; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 5.744252848671749e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 8.5732e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9261e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0037e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2344e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2816e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1514e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3147e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7809e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9250e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5100e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.01626063697040081; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0017 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 2.999129719682969e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 3.2607851608190686e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.736817830533255e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 9.606344974599779e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 8.2595e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.0445e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0316e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.2567e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.5549e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8995e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6627e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2342e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.009017186239361763; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.2388 - accuracy: 0.9588 - tp: 2982.0000 - fp: 190.0000 - tn: 6182.0000 - fn: 204.0000 - precision: 0.9401 - recall: 0.9360 - auc: 0.9840 - prc: 0.9690\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0679 - accuracy: 0.9861 - tp: 3115.0000 - fp: 62.0000 - tn: 6310.0000 - fn: 71.0000 - precision: 0.9805 - recall: 0.9777 - auc: 0.9984 - prc: 0.9969\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0119 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0030 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0016 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5906e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.8532e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.5570e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.21619954705238342; accuracy of 95.38606405258179%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.027129318565130234 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0033004479482769966 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 5.744252848671749e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01626063697040081 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.999129719682969e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 3.2607851608190686e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.736817830533255e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 9.606344974599779e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.009017186239361763 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.21619954705238342 - Accuracy: 95.38606405258179%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.38794612884521 (+- 1.3614462523836999)\n","> Loss: 0.02720541529761249\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0225 - accuracy: 0.9952 - tp: 3514.0000 - fp: 25.0000 - tn: 7055.0000 - fn: 26.0000 - precision: 0.9929 - recall: 0.9927 - auc: 0.9995 - prc: 0.9990\n","78/78 [==============================] - 1s 10ms/step - loss: 0.5600 - accuracy: 0.9286 - tp: 2212.0000 - fp: 264.0000 - tn: 4694.0000 - fn: 267.0000 - precision: 0.8934 - recall: 0.8923 - auc: 0.9585 - prc: 0.9247\n","\n",">round 6  client 7 evaluation training metrics:\n","[0.022505182772874832, 0.9951977133750916, 3514.0, 25.0, 7055.0, 26.0, 0.992935836315155, 0.9926553964614868, 0.999508261680603, 0.9990414977073669]\n","\n",">round 6  client 7 evaluation metrics:\n","[0.5599969029426575, 0.9286002516746521, 2212.0, 264.0, 4694.0, 267.0, 0.8933764100074768, 0.8922953009605408, 0.9585428833961487, 0.9246687889099121]\n","\n","=============================================================\n","\n","> round 6 average training auc= 0.2476576976499047\n","> round 6 average training loss= 0.02826824552598412\n","Epoch 1/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3529.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","> model 1 retrained, original loss= 0.05869405712910521 , retrained loss= 0.003835549345239997 epoch count 20.0\n","Epoch 1/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9959 - tp: 3519.0000 - fp: 22.0000 - tn: 7060.0000 - fn: 22.0000 - precision: 0.9938 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9953 - tp: 3516.0000 - fp: 25.0000 - tn: 7057.0000 - fn: 25.0000 - precision: 0.9929 - recall: 0.9929 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9964 - tp: 3522.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 19.0000 - precision: 0.9946 - recall: 0.9946 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9959 - tp: 3519.0000 - fp: 22.0000 - tn: 7060.0000 - fn: 22.0000 - precision: 0.9938 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9949 - tp: 3514.0000 - fp: 27.0000 - tn: 7055.0000 - fn: 27.0000 - precision: 0.9924 - recall: 0.9924 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9961 - tp: 3520.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 21.0000 - precision: 0.9944 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","36/36 [==============================] - 1s 29ms/step - loss: 0.0088 - accuracy: 0.9960 - tp: 3520.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 21.0000 - precision: 0.9941 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","> model 2 retrained, original loss= 0.0277684542350471 , retrained loss= 0.008803974837064743 epoch count 20.0\n","Epoch 1/10\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","36/36 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3533.0000 - fp: 8.0000 - tn: 7074.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0038 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9984 - tp: 3532.0000 - fp: 8.0000 - tn: 7074.0000 - fn: 9.0000 - precision: 0.9977 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3535.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 6.0000 - precision: 0.9986 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","> model 3 retrained, original loss= 0.027874779803642013 , retrained loss= 0.002998737385496497 epoch count 20.0\n","Epoch 1/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0231 - accuracy: 0.9942 - tp: 3509.0000 - fp: 31.0000 - tn: 7049.0000 - fn: 31.0000 - precision: 0.9912 - recall: 0.9912 - auc: 0.9994 - prc: 0.9989\n","Epoch 2/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9991 - tp: 3535.0000 - fp: 5.0000 - tn: 7075.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0016 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9991 - tp: 3535.0000 - fp: 5.0000 - tn: 7075.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","> model 7 retrained, original loss= 0.02720541529761249 , retrained loss= 0.0012364172143861651 epoch count 20.0\n","> round 6 average epoch count= 15.714285714285714\n"," 1/78 [..............................] - ETA: 2s"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["78/78 [==============================] - 0s 5ms/step\n","> round 6 test auc= 0.24231071725790373\n","111/111 [==============================] - 1s 8ms/step - loss: 1.9647 - accuracy: 0.8057 - tp: 2507.0000 - fp: 1030.0000 - tn: 6052.0000 - fn: 1034.0000 - precision: 0.7088 - recall: 0.7080 - auc: 0.8339 - prc: 0.7069\n","\n","> round 6 final model training loss_metric= [1.9646553993225098]\n","> round 6 final model training TP_metric= [2507.0]\n","> round 6 final model training FP_metric= [1030.0]\n","> round 6 final model training TN_metric= [6052.0]\n","> round 6 final model training FN_metric= [1034.0]\n","> round 6 final model training accuracy_metric= [80.57045936584473]\n","> round 6 final model training precision_metric= [70.87927460670471]\n","> round 6 final model training recall_metric = [70.79920768737793]\n","> round 6 final model training auc_metric= [0.8338630199432373]\n","> round 6 final model training prc_metric= [0.7069113254547119]\n","\n","78/78 [==============================] - 1s 8ms/step - loss: 1.5032 - accuracy: 0.8511 - tp: 1924.0000 - fp: 552.0000 - tn: 4406.0000 - fn: 555.0000 - precision: 0.7771 - recall: 0.7761 - auc: 0.8752 - prc: 0.7720\n","> round 6 final model loss_metric= [1.5032280683517456]\n","> round 6 final model TP_metric= [1924.0]\n","> round 6 final model FP_metric= [552.0]\n","> round 6 final model TN_metric= [4406.0]\n","> round 6 final model FN_metric= [555.0]\n","> round 6 final model accuracy_metric= [85.11496782302856]\n","> round 6 final model precision_metric= [77.705979347229]\n","> round 6 final model recall_metric = [77.61194109916687]\n","> round 6 final model auc_metric= [0.8752000331878662]\n","> round 6 final model prc_metric= [0.7719994783401489]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 7 start, random seed= 7\n","\n","> client 1 started learning...........\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 31ms/step - loss: 0.1496 - accuracy: 0.9170 - tp: 4951.0000 - fp: 696.0000 - tn: 10634.0000 - fn: 714.0000 - precision: 0.8767 - recall: 0.8740 - auc: 0.9416 - prc: 0.8890\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0280 - accuracy: 0.9952 - tp: 3158.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 28.0000 - precision: 0.9943 - recall: 0.9912 - auc: 0.9996 - prc: 0.9992\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0087 - accuracy: 0.9980 - tp: 3172.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 14.0000 - precision: 0.9984 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0050 - accuracy: 0.9984 - tp: 3174.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0046 - accuracy: 0.9984 - tp: 3174.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3174.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.10063761472702026; accuracy of 98.21596145629883%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0309 - accuracy: 0.9946 - tp: 3157.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 30.0000 - precision: 0.9931 - recall: 0.9906 - auc: 0.9989 - prc: 0.9980\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0369 - accuracy: 0.9913 - tp: 3142.0000 - fp: 38.0000 - tn: 6336.0000 - fn: 45.0000 - precision: 0.9881 - recall: 0.9859 - auc: 0.9996 - prc: 0.9992\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0171 - accuracy: 0.9955 - tp: 3162.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 25.0000 - precision: 0.9943 - recall: 0.9922 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0058 - accuracy: 0.9985 - tp: 3177.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 10.0000 - precision: 0.9987 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.013193408958613873; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 4.7568562877131626e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9982 - tp: 3174.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.002036821795627475; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0043 - accuracy: 0.9983 - tp: 3174.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 1.1966933016083203e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0030 - accuracy: 0.9991 - tp: 3179.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 8.0000 - precision: 0.9997 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.014249762520194054; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 0.9980 - tp: 3173.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 14.0000 - precision: 0.9984 - recall: 0.9956 - auc: 0.9998 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0778 - accuracy: 0.9826 - tp: 3097.0000 - fp: 76.0000 - tn: 6298.0000 - fn: 90.0000 - precision: 0.9760 - recall: 0.9718 - auc: 0.9966 - prc: 0.9937\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1203 - accuracy: 0.9736 - tp: 3046.0000 - fp: 111.0000 - tn: 6263.0000 - fn: 141.0000 - precision: 0.9648 - recall: 0.9558 - auc: 0.9951 - prc: 0.9907\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0263 - accuracy: 0.9947 - tp: 3156.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 31.0000 - precision: 0.9937 - recall: 0.9903 - auc: 0.9996 - prc: 0.9992\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0093 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0047 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.10792211443185806; accuracy of 97.17513918876648%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0248 - accuracy: 0.9946 - tp: 3157.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 30.0000 - precision: 0.9931 - recall: 0.9906 - auc: 0.9998 - prc: 0.9997\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9992 - tp: 3179.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 8.0000 - precision: 1.0000 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3179.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 8.0000 - precision: 1.0000 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9992 - tp: 3179.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 8.0000 - precision: 1.0000 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9992 - tp: 3179.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 8.0000 - precision: 1.0000 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9992 - tp: 3179.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 8.0000 - precision: 1.0000 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0030 - accuracy: 0.9992 - tp: 3179.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 8.0000 - precision: 1.0000 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3179.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 8.0000 - precision: 1.0000 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3179.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 8.0000 - precision: 1.0000 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.021410642191767693; accuracy of 99.52918887138367%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0051 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.011122273281216621; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3174.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 13.0000 - precision: 0.9994 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 4.6387489419430494e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.10063761472702026 - Accuracy: 98.21596145629883%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.013193408958613873 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 4.7568562877131626e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.002036821795627475 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 1.1966933016083203e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.014249762520194054 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.10792211443185806 - Accuracy: 97.17513918876648%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.021410642191767693 - Accuracy: 99.52918887138367%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.011122273281216621 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 4.6387489419430494e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.38845098018646 (+- 0.8918911486053375)\n","> Loss: 0.02706785608916107\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.4742 - accuracy: 0.9418 - tp: 2259.0000 - fp: 213.0000 - tn: 4745.0000 - fn: 220.0000 - precision: 0.9138 - recall: 0.9113 - auc: 0.9685 - prc: 0.9405\n","\n",">round 7  client 1 evaluation training metrics:\n","[0.0037932314444333315, 0.9987762570381165, 3530.0, 2.0, 7080.0, 11.0, 0.9994337558746338, 0.9968935251235962, 0.9999946355819702, 0.9999892711639404]\n","\n",">round 7  client 1 evaluation metrics:\n","[0.47416555881500244, 0.9417775869369507, 2259.0, 213.0, 4745.0, 220.0, 0.9138349294662476, 0.9112545251846313, 0.9685191512107849, 0.9404525756835938]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 28ms/step - loss: 0.1025 - accuracy: 0.9599 - tp: 5315.0000 - fp: 332.0000 - tn: 10998.0000 - fn: 350.0000 - precision: 0.9412 - recall: 0.9382 - auc: 0.9833 - prc: 0.9679\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0233 - accuracy: 0.9936 - tp: 3152.0000 - fp: 27.0000 - tn: 6345.0000 - fn: 34.0000 - precision: 0.9915 - recall: 0.9893 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0137 - accuracy: 0.9953 - tp: 3160.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 26.0000 - precision: 0.9940 - recall: 0.9918 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9951 - tp: 3160.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 26.0000 - precision: 0.9934 - recall: 0.9918 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0117 - accuracy: 0.9950 - tp: 3160.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 26.0000 - precision: 0.9931 - recall: 0.9918 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 0.9959 - tp: 3166.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0100 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0103 - accuracy: 0.9954 - tp: 3164.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0097 - accuracy: 0.9952 - tp: 3162.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9931 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 0.042185377329587936; accuracy of 98.8732397556305%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0330 - accuracy: 0.9925 - tp: 3148.0000 - fp: 33.0000 - tn: 6341.0000 - fn: 39.0000 - precision: 0.9896 - recall: 0.9878 - auc: 0.9991 - prc: 0.9982\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0631 - accuracy: 0.9828 - tp: 3103.0000 - fp: 80.0000 - tn: 6294.0000 - fn: 84.0000 - precision: 0.9749 - recall: 0.9736 - auc: 0.9982 - prc: 0.9966\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0340 - accuracy: 0.9924 - tp: 3146.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 41.0000 - precision: 0.9899 - recall: 0.9871 - auc: 0.9994 - prc: 0.9988\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0152 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0103 - accuracy: 0.9956 - tp: 3165.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 22.0000 - precision: 0.9937 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0100 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0097 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0097 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.026737412437796593; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0182 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9997 - prc: 0.9994\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0239 - accuracy: 0.9905 - tp: 3141.0000 - fp: 45.0000 - tn: 6329.0000 - fn: 46.0000 - precision: 0.9859 - recall: 0.9856 - auc: 0.9998 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0154 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0131 - accuracy: 0.9952 - tp: 3163.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 24.0000 - precision: 0.9931 - recall: 0.9925 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0353 - accuracy: 0.9905 - tp: 3141.0000 - fp: 45.0000 - tn: 6329.0000 - fn: 46.0000 - precision: 0.9859 - recall: 0.9856 - auc: 0.9995 - prc: 0.9992\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0261 - accuracy: 0.9924 - tp: 3150.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 37.0000 - precision: 0.9887 - recall: 0.9884 - auc: 0.9998 - prc: 0.9996\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0140 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0091 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 3: loss of 0.03694339841604233; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0294 - accuracy: 0.9926 - tp: 3151.0000 - fp: 35.0000 - tn: 6339.0000 - fn: 36.0000 - precision: 0.9890 - recall: 0.9887 - auc: 0.9993 - prc: 0.9987\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0171 - accuracy: 0.9939 - tp: 3158.0000 - fp: 29.0000 - tn: 6345.0000 - fn: 29.0000 - precision: 0.9909 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0116 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0133 - accuracy: 0.9953 - tp: 3164.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0104 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0092 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0088 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.008808606304228306; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0072 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0069 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0072 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0070 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0066 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.03133954480290413; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0102 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0089 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0089 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0096 - accuracy: 0.9949 - tp: 3162.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 25.0000 - precision: 0.9925 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0089 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0090 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.001976007129997015; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0096 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0087 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0088 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.003811726812273264; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0075 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0075 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0073 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0076 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0075 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0074 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.018331145867705345; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0088 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Score for fold 9: loss of 0.010331072844564915; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0084 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0079 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9965 - tp: 3168.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 19.0000 - precision: 0.9956 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0080 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 10: loss of 0.010528362356126308; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.042185377329587936 - Accuracy: 98.8732397556305%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.026737412437796593 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.03694339841604233 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.008808606304228306 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.03133954480290413 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.001976007129997015 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.003811726812273264 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.018331145867705345 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.010331072844564915 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.010528362356126308 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.36001598834991 (+- 0.39643097838121577)\n","> Loss: 0.019099265430122615\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 0s 6ms/step\n","111/111 [==============================] - 1s 12ms/step - loss: 0.0079 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","78/78 [==============================] - 1s 14ms/step - loss: 0.4435 - accuracy: 0.9478 - tp: 2285.0000 - fp: 194.0000 - tn: 4764.0000 - fn: 194.0000 - precision: 0.9217 - recall: 0.9217 - auc: 0.9714 - prc: 0.9466\n","\n",">round 7  client 2 evaluation training metrics:\n","[0.007918410934507847, 0.9966111183166504, 3523.0, 18.0, 7064.0, 18.0, 0.9949166774749756, 0.9949166774749756, 0.9999727606773376, 0.9999456405639648]\n","\n",">round 7  client 2 evaluation metrics:\n","[0.44354963302612305, 0.9478284120559692, 2285.0, 194.0, 4764.0, 194.0, 0.9217426180839539, 0.9217426180839539, 0.9714401364326477, 0.9466215968132019]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.0963 - accuracy: 0.9658 - tp: 5371.0000 - fp: 288.0000 - tn: 11042.0000 - fn: 294.0000 - precision: 0.9491 - recall: 0.9481 - auc: 0.9848 - prc: 0.9710\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0208 - accuracy: 0.9949 - tp: 3161.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 25.0000 - precision: 0.9925 - recall: 0.9922 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9984 - tp: 3178.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0072 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0049 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0050 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0041 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.03164979815483093; accuracy of 99.43661689758301%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0134 - accuracy: 0.9968 - tp: 3171.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 0.9997 - prc: 0.9994\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0139 - accuracy: 0.9974 - tp: 3174.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0084 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0115 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0153 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0199 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9997 - prc: 0.9993\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0106 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9997 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0060 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.028609253466129303; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0213 - accuracy: 0.9940 - tp: 3158.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 29.0000 - precision: 0.9912 - recall: 0.9909 - auc: 0.9996 - prc: 0.9993\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0044 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0065 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9998 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9998 - prc: 0.9995\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9991 - tp: 3182.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.021882886067032814; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3180.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 7.0000 - precision: 0.9984 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.013137107715010643; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0032 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 3.351204577484168e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.018801512196660042; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.009904210455715656; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0033 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 2.14252904697787e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 1.465675450162962e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0026 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.0022200134117156267; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.03164979815483093 - Accuracy: 99.43661689758301%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.028609253466129303 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.021882886067032814 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.013137107715010643 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 3.351204577484168e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.018801512196660042 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.009904210455715656 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 2.14252904697787e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.465675450162962e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.0022200134117156267 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.69883918762207 (+- 0.2940298239140133)\n","> Loss: 0.012627437555784127\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 1s 7ms/step\n","111/111 [==============================] - 1s 12ms/step - loss: 0.0024 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 11ms/step - loss: 0.4654 - accuracy: 0.9474 - tp: 2283.0000 - fp: 195.0000 - tn: 4763.0000 - fn: 196.0000 - precision: 0.9213 - recall: 0.9209 - auc: 0.9665 - prc: 0.9403\n","\n",">round 7  client 3 evaluation training metrics:\n","[0.00240191537886858, 0.9988703727722168, 3535.0, 6.0, 7076.0, 6.0, 0.9983055591583252, 0.9983055591583252, 0.9999972581863403, 0.9999945163726807]\n","\n",">round 7  client 3 evaluation metrics:\n","[0.46538421511650085, 0.9474250078201294, 2283.0, 195.0, 4763.0, 196.0, 0.9213075041770935, 0.920935869216919, 0.9664669632911682, 0.9403257369995117]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.1648 - accuracy: 0.9575 - tp: 5298.0000 - fp: 355.0000 - tn: 10975.0000 - fn: 367.0000 - precision: 0.9372 - recall: 0.9352 - auc: 0.9800 - prc: 0.9637\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0280 - accuracy: 0.9954 - tp: 3162.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 24.0000 - precision: 0.9937 - recall: 0.9925 - auc: 0.9996 - prc: 0.9992\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0064 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0036 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.07493084669113159; accuracy of 98.30508232116699%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0253 - accuracy: 0.9935 - tp: 3154.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 32.0000 - precision: 0.9906 - recall: 0.9900 - auc: 0.9994 - prc: 0.9991\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0092 - accuracy: 0.9990 - tp: 3180.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.021946657449007034; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0135 - accuracy: 0.9974 - tp: 3172.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 14.0000 - precision: 0.9965 - recall: 0.9956 - auc: 0.9995 - prc: 0.9990\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0241 - accuracy: 0.9937 - tp: 3155.0000 - fp: 29.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9909 - recall: 0.9903 - auc: 0.9997 - prc: 0.9995\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0407 - accuracy: 0.9909 - tp: 3139.0000 - fp: 40.0000 - tn: 6332.0000 - fn: 47.0000 - precision: 0.9874 - recall: 0.9852 - auc: 0.9994 - prc: 0.9990\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0165 - accuracy: 0.9963 - tp: 3168.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.049968745559453964; accuracy of 98.49340915679932%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0097 - accuracy: 0.9977 - tp: 3174.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9969 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.4347e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1717e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7820e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5126e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6625e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6853e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1555e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.009144450537860394; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1849e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.1604e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1390e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2144e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6124e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3293e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9273e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.1392e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.9469e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.021614424884319305; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9902e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9490e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9557e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3220e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.0227e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.8218517652712762e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.7132e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.3900e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.4022e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.6926e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0361e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9268e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5119e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6976e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5954e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1080e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.009215951897203922; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.4331e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.4488e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 32ms/step - loss: 9.0360e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9422e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 1.3078557458356954e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.3462e-04 - accuracy: 0.9995 - tp: 3182.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 4.0000 - precision: 0.9997 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7702e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3954e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7067e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.3198e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.9470e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.9851e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8834e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.5384e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 1.2307778888498433e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.6425e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.8093e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.8718e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.5402e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5429e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1936e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8390e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9065e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9635e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.3299e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.015726150944828987; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.07493084669113159 - Accuracy: 98.30508232116699%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.021946657449007034 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.049968745559453964 - Accuracy: 98.49340915679932%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.009144450537860394 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.021614424884319305 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.8218517652712762e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.009215951897203922 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 1.3078557458356954e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.2307778888498433e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.015726150944828987 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.56685364246368 (+- 0.5958301538605767)\n","> Loss: 0.020259083281780478\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9999 - prc: 0.9999\n","78/78 [==============================] - 1s 13ms/step - loss: 0.4615 - accuracy: 0.9496 - tp: 2290.0000 - fp: 186.0000 - tn: 4772.0000 - fn: 189.0000 - precision: 0.9249 - recall: 0.9238 - auc: 0.9717 - prc: 0.9479\n","\n",">round 7  client 4 evaluation training metrics:\n","[0.001975616440176964, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9998584985733032, 0.9998722672462463]\n","\n",">round 7  client 4 evaluation metrics:\n","[0.46152088046073914, 0.9495764374732971, 2290.0, 186.0, 4772.0, 189.0, 0.9248788356781006, 0.9237595796585083, 0.9717419147491455, 0.9478908777236938]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 31ms/step - loss: 0.1762 - accuracy: 0.9596 - tp: 5315.0000 - fp: 336.0000 - tn: 10994.0000 - fn: 350.0000 - precision: 0.9405 - recall: 0.9382 - auc: 0.9812 - prc: 0.9651\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0339 - accuracy: 0.9940 - tp: 3155.0000 - fp: 26.0000 - tn: 6346.0000 - fn: 31.0000 - precision: 0.9918 - recall: 0.9903 - auc: 0.9996 - prc: 0.9994\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 0.9998 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0023 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0020 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0017 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.14200636744499207; accuracy of 97.26930260658264%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0287 - accuracy: 0.9957 - tp: 3165.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 0.9984 - prc: 0.9969\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0219 - accuracy: 0.9953 - tp: 3163.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 0.9997 - prc: 0.9993\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0058 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0168 - accuracy: 0.9969 - tp: 3171.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 0.9995 - prc: 0.9990\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0422e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.3459e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2372e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7084e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.014356797561049461; accuracy of 99.52918887138367%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0026 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0955e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.2908e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1047e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7717e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5871e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 9.937319555319846e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.2412e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 32ms/step - loss: 6.5896e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.5303e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.4812e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.9809e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6533e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8190e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5096e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3144e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5974e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 1.6650898032821715e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3409e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7276e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6069e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.7055e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3372e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8931e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8127e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.9822e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.7113e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.0535e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 2.661840699147433e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.0792e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.2686e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.5079e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.1679e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9417e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.4965e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.3015e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.9190e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.4047e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.2365e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.012014742940664291; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.6156e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.0525e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.3101e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 32ms/step - loss: 5.0217e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.2397e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7138e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2763e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6601e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.6489e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.0635808393999469e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.4577e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.1012e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.1860e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6013e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7357e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.7662e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.3150e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 2.9205e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 2.5662e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 2.5030e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.010094333440065384; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4860e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5191e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4659e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6910e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1104e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6305e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2916e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2040e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5895e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 5.9898716244788375e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.5910e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0850e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8869e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6889e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8785e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9018e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.3474e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.9959e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7661e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8279e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 6.951119303266751e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.14200636744499207 - Accuracy: 97.26930260658264%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.014356797561049461 - Accuracy: 99.52918887138367%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 9.937319555319846e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 1.6650898032821715e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.661840699147433e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.012014742940664291 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.0635808393999469e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.010094333440065384 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 5.9898716244788375e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 6.951119303266751e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.64218378067017 (+- 0.804299751282378)\n","> Loss: 0.017863846068667043\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 4.1023e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 13ms/step - loss: 0.3090 - accuracy: 0.9613 - tp: 2335.0000 - fp: 144.0000 - tn: 4814.0000 - fn: 144.0000 - precision: 0.9419 - recall: 0.9419 - auc: 0.9798 - prc: 0.9626\n","\n",">round 7  client 5 evaluation training metrics:\n","[0.0004102328384760767, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 7  client 5 evaluation metrics:\n","[0.3090282380580902, 0.9612746834754944, 2335.0, 144.0, 4814.0, 144.0, 0.941912055015564, 0.941912055015564, 0.9797735810279846, 0.962603747844696]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.1041 - accuracy: 0.9711 - tp: 5417.0000 - fp: 243.0000 - tn: 11087.0000 - fn: 248.0000 - precision: 0.9571 - recall: 0.9562 - auc: 0.9883 - prc: 0.9778\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0187 - accuracy: 0.9975 - tp: 3173.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9965 - recall: 0.9959 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3650e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.1520e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.8581e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.04835665598511696; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0156 - accuracy: 0.9967 - tp: 3170.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0131 - accuracy: 0.9971 - tp: 3172.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 0.9997 - prc: 0.9994\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0069 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0045 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.2293e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.4627e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.9281e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.5096e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.017504923045635223; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0037 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0111 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0060 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.3892e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6466e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7071e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6297e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0031e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6398e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0004149604355916381; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.2469e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.4079e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.1829e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.8587e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2098e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.4161e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 33ms/step - loss: 5.9400e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.9899e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 7.1670e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.6668e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 4.0681541577214375e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0835e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3987e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5268e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7747e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8959e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0584e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7279e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6026e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8128e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2780e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 2.5842260583885945e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 5.6213e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.0841e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0646e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6736e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3615e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2749e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5604e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4844e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7635e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9688e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.1490020369819831e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.5064e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.5659e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.4683e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.3014e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.7619e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 3.7961e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.8844e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.3901e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 2.0592e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.9531e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.010978312231600285; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9591e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1158e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5508e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.2745e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2407e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.5555e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 32ms/step - loss: 6.0312e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 32ms/step - loss: 5.3381e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.7755e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 4.86519866171875e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6510e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2628e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3160e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2571e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7931e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8595e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8113e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3827e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2133e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7509e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 4.990145043848315e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.7440e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.5578e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 32ms/step - loss: 6.8486e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.4063e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.4649e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 3.8700e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.3428e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 3.1715e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.6962e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.4372e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.008564521558582783; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.04835665598511696 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.017504923045635223 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0004149604355916381 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 4.0681541577214375e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.5842260583885945e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.1490020369819831e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.010978312231600285 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 4.86519866171875e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 4.990145043848315e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.008564521558582783 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.83050763607025 (+- 0.2849865528583017)\n","> Loss: 0.008590724242276337\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 8.7708e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.3845 - accuracy: 0.9587 - tp: 2325.0000 - fp: 153.0000 - tn: 4805.0000 - fn: 154.0000 - precision: 0.9383 - recall: 0.9379 - auc: 0.9741 - prc: 0.9524\n","\n",">round 7  client 6 evaluation training metrics:\n","[0.0008770828135311604, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 7  client 6 evaluation metrics:\n","[0.3845359683036804, 0.9587199091911316, 2325.0, 153.0, 4805.0, 154.0, 0.9382566809654236, 0.9378781914710999, 0.9740614295005798, 0.9523507356643677]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.1061 - accuracy: 0.9696 - tp: 5406.0000 - fp: 257.0000 - tn: 11073.0000 - fn: 259.0000 - precision: 0.9546 - recall: 0.9543 - auc: 0.9858 - prc: 0.9736\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0190 - accuracy: 0.9958 - tp: 3165.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.04662416875362396; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 35ms/step - loss: 0.0294 - accuracy: 0.9934 - tp: 3154.0000 - fp: 31.0000 - tn: 6341.0000 - fn: 32.0000 - precision: 0.9903 - recall: 0.9900 - auc: 0.9996 - prc: 0.9991\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0209 - accuracy: 0.9954 - tp: 3164.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9997 - prc: 0.9993\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0146 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0124 - accuracy: 0.9971 - tp: 3172.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0064 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.048057835549116135; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0021808508317917585; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0816e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7677e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2972e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.4074e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1101e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1687e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0164e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.7352e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.0455e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.012119419872760773; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.5446e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3480e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2021e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.1796e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.8201e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2938e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0825e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.9071e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.8849e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.008914057165384293; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.6792209862614982e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2525e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.4454e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9819e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8136e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9506e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2948e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.5428e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.1299e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.8946e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.010132490657269955; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.1172e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.0017203378956764936; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 9.047866114997305e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 8.000693014764693e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.04662416875362396 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.048057835549116135 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0021808508317917585 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.012119419872760773 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.008914057165384293 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.6792209862614982e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.010132490657269955 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.0017203378956764936 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 9.047866114997305e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 8.000693014764693e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.774010181427 (+- 0.3240051662537598)\n","> Loss: 0.012978300149461575\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 9.6132e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.4261 - accuracy: 0.9540 - tp: 2308.0000 - fp: 171.0000 - tn: 4787.0000 - fn: 171.0000 - precision: 0.9310 - recall: 0.9310 - auc: 0.9704 - prc: 0.9452\n","\n",">round 7  client 7 evaluation training metrics:\n","[0.0009613201837055385, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997019767761, 0.9999992251396179]\n","\n",">round 7  client 7 evaluation metrics:\n","[0.42606621980667114, 0.9540137052536011, 2308.0, 171.0, 4787.0, 171.0, 0.9310205578804016, 0.9310205578804016, 0.9704372882843018, 0.9452207088470459]\n","\n","=============================================================\n","\n","> round 7 average training auc= 0.24949388698483574\n","> round 7 average training loss= 0.016926644688179036\n","> round 7 average epoch count= 10.0\n","10/78 [==>...........................] - ETA: 0s"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["78/78 [==============================] - 0s 5ms/step\n","> round 7 test auc= 0.2370545145271475\n","111/111 [==============================] - 1s 9ms/step - loss: 1.5095 - accuracy: 0.8603 - tp: 2798.0000 - fp: 741.0000 - tn: 6341.0000 - fn: 743.0000 - precision: 0.7906 - recall: 0.7902 - auc: 0.8814 - prc: 0.7834\n","\n","> round 7 final model training loss_metric= [1.5094525814056396]\n","> round 7 final model training TP_metric= [2798.0]\n","> round 7 final model training FP_metric= [741.0]\n","> round 7 final model training TN_metric= [6341.0]\n","> round 7 final model training FN_metric= [743.0]\n","> round 7 final model training accuracy_metric= [86.03031039237976]\n","> round 7 final model training precision_metric= [79.06188368797302]\n","> round 7 final model training recall_metric = [79.0172278881073]\n","> round 7 final model training auc_metric= [0.8814428448677063]\n","> round 7 final model training prc_metric= [0.7833713293075562]\n","\n","78/78 [==============================] - 1s 9ms/step - loss: 1.1129 - accuracy: 0.8942 - tp: 2084.0000 - fp: 392.0000 - tn: 4566.0000 - fn: 395.0000 - precision: 0.8417 - recall: 0.8407 - auc: 0.9142 - prc: 0.8396\n","> round 7 final model loss_metric= [1.1129233837127686]\n","> round 7 final model TP_metric= [2084.0]\n","> round 7 final model FP_metric= [392.0]\n","> round 7 final model TN_metric= [4566.0]\n","> round 7 final model FN_metric= [395.0]\n","> round 7 final model accuracy_metric= [89.41777348518372]\n","> round 7 final model precision_metric= [84.1680109500885]\n","> round 7 final model recall_metric = [84.06615853309631]\n","> round 7 final model auc_metric= [0.9141608476638794]\n","> round 7 final model prc_metric= [0.8395564556121826]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 8 start, random seed= 8\n","\n","> client 1 started learning...........\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 10s 31ms/step - loss: 0.0720 - accuracy: 0.9456 - tp: 5196.0000 - fp: 456.0000 - tn: 10874.0000 - fn: 469.0000 - precision: 0.9193 - recall: 0.9172 - auc: 0.9619 - prc: 0.9269\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0157 - accuracy: 0.9970 - tp: 3167.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 19.0000 - precision: 0.9969 - recall: 0.9940 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9988 - tp: 3176.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9984 - tp: 3174.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.04329731687903404; accuracy of 99.06103014945984%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0540 - accuracy: 0.9878 - tp: 3122.0000 - fp: 52.0000 - tn: 6322.0000 - fn: 65.0000 - precision: 0.9836 - recall: 0.9796 - auc: 0.9980 - prc: 0.9967\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0474 - accuracy: 0.9876 - tp: 3121.0000 - fp: 53.0000 - tn: 6321.0000 - fn: 66.0000 - precision: 0.9833 - recall: 0.9793 - auc: 0.9994 - prc: 0.9988\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0162 - accuracy: 0.9961 - tp: 3164.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 23.0000 - precision: 0.9956 - recall: 0.9928 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0072 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0049 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.008867166936397552; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0048 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0037 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9991 - tp: 3178.0000 - fp: 0.0000e+00 - tn: 6374.0000 - fn: 9.0000 - precision: 1.0000 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.030104082077741623; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0053 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.003628486068919301; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0036 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.006635789759457111; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.0034139365889132023; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.3177578694012482e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.009321731515228748; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.0051393997855484486; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.00379921798594296; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.04329731687903404 - Accuracy: 99.06103014945984%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.008867166936397552 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.030104082077741623 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.003628486068919301 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.006635789759457111 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.0034139365889132023 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.3177578694012482e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.009321731515228748 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.0051393997855484486 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.00379921798594296 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.76485908031464 (+- 0.2562837731910008)\n","> Loss: 0.0114220305175877\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.2604 - accuracy: 0.9677 - tp: 2357.0000 - fp: 118.0000 - tn: 4840.0000 - fn: 122.0000 - precision: 0.9523 - recall: 0.9508 - auc: 0.9836 - prc: 0.9692\n","\n",">round 8  client 1 evaluation training metrics:\n","[0.003768532071262598, 0.9987762570381165, 3530.0, 2.0, 7080.0, 11.0, 0.9994337558746338, 0.9968935251235962, 0.9999945759773254, 0.9999892711639404]\n","\n",">round 8  client 1 evaluation metrics:\n","[0.260385662317276, 0.9677289128303528, 2357.0, 118.0, 4840.0, 122.0, 0.9523232579231262, 0.9507865905761719, 0.9835714101791382, 0.9692056775093079]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 30ms/step - loss: 0.0632 - accuracy: 0.9761 - tp: 5455.0000 - fp: 197.0000 - tn: 11133.0000 - fn: 210.0000 - precision: 0.9651 - recall: 0.9629 - auc: 0.9915 - prc: 0.9838\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0187 - accuracy: 0.9945 - tp: 3158.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 28.0000 - precision: 0.9921 - recall: 0.9912 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9958 - tp: 3166.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0098 - accuracy: 0.9959 - tp: 3166.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0126 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0098 - accuracy: 0.9967 - tp: 3170.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 0.9969 - tp: 3171.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 0.021564055234193802; accuracy of 99.24882650375366%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0190 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0378 - accuracy: 0.9898 - tp: 3137.0000 - fp: 48.0000 - tn: 6326.0000 - fn: 50.0000 - precision: 0.9849 - recall: 0.9843 - auc: 0.9994 - prc: 0.9988\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0414 - accuracy: 0.9893 - tp: 3135.0000 - fp: 50.0000 - tn: 6324.0000 - fn: 52.0000 - precision: 0.9843 - recall: 0.9837 - auc: 0.9993 - prc: 0.9989\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0189 - accuracy: 0.9951 - tp: 3163.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 24.0000 - precision: 0.9928 - recall: 0.9925 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0141 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0144 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 0.9997 - prc: 0.9994\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0151 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0105 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.024390606209635735; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0141 - accuracy: 0.9941 - tp: 3159.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 28.0000 - precision: 0.9912 - recall: 0.9912 - auc: 0.9999 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0111 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0091 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0106 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 0.9998 - prc: 0.9998\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0085 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 3: loss of 0.01600806973874569; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0093 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0077 - accuracy: 0.9972 - tp: 3173.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 14.0000 - precision: 0.9959 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0076 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0075 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.028845487162470818; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0095 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9951 - tp: 3162.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 25.0000 - precision: 0.9931 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 5: loss of 0.0022071285638958216; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0087 - accuracy: 0.9956 - tp: 3165.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 22.0000 - precision: 0.9937 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0085 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9957 - tp: 3166.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0084 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.0037099644541740417; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9950 - tp: 3163.0000 - fp: 24.0000 - tn: 6350.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0080 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0080 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0078 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.009775076061487198; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 0.9969 - tp: 3171.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 16.0000 - precision: 0.9956 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0086 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0084 - accuracy: 0.9956 - tp: 3165.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 22.0000 - precision: 0.9937 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.0052962834015488625; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9956 - tp: 3165.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 22.0000 - precision: 0.9937 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9961 - tp: 3167.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 20.0000 - precision: 0.9947 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Score for fold 9: loss of 0.009873123839497566; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0069 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0068 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0066 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0067 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0100 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.1064 - accuracy: 0.9794 - tp: 3085.0000 - fp: 95.0000 - tn: 6279.0000 - fn: 102.0000 - precision: 0.9701 - recall: 0.9680 - auc: 0.9949 - prc: 0.9902\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1243 - accuracy: 0.9683 - tp: 3028.0000 - fp: 144.0000 - tn: 6230.0000 - fn: 159.0000 - precision: 0.9546 - recall: 0.9501 - auc: 0.9942 - prc: 0.9894\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0379 - accuracy: 0.9889 - tp: 3132.0000 - fp: 51.0000 - tn: 6323.0000 - fn: 55.0000 - precision: 0.9840 - recall: 0.9827 - auc: 0.9996 - prc: 0.9992\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0144 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 0.9999 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0107 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Score for fold 10: loss of 0.4311602711677551; accuracy of 93.5969889163971%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.021564055234193802 - Accuracy: 99.24882650375366%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.024390606209635735 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.01600806973874569 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.028845487162470818 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0022071285638958216 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.0037099644541740417 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.009775076061487198 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.0052962834015488625 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.009873123839497566 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.4311602711677551 - Accuracy: 93.5969889163971%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 98.86085212230682 (+- 1.778908939013906)\n","> Loss: 0.05528300658334047\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.1145 - accuracy: 0.9797 - tp: 3433.0000 - fp: 108.0000 - tn: 6974.0000 - fn: 108.0000 - precision: 0.9695 - recall: 0.9695 - auc: 0.9921 - prc: 0.9850\n","78/78 [==============================] - 1s 9ms/step - loss: 0.5747 - accuracy: 0.9330 - tp: 2230.0000 - fp: 249.0000 - tn: 4709.0000 - fn: 249.0000 - precision: 0.8996 - recall: 0.8996 - auc: 0.9586 - prc: 0.9226\n","\n",">round 8  client 2 evaluation training metrics:\n","[0.11446236073970795, 0.9796667695045471, 3433.0, 108.0, 6974.0, 108.0, 0.9695001244544983, 0.9695001244544983, 0.9921293258666992, 0.9849836230278015]\n","\n",">round 8  client 2 evaluation metrics:\n","[0.5747363567352295, 0.933037519454956, 2230.0, 249.0, 4709.0, 249.0, 0.8995562791824341, 0.8995562791824341, 0.9585551023483276, 0.9225916862487793]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 30ms/step - loss: 0.0655 - accuracy: 0.9636 - tp: 5354.0000 - fp: 308.0000 - tn: 11022.0000 - fn: 311.0000 - precision: 0.9456 - recall: 0.9451 - auc: 0.9807 - prc: 0.9635\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0143 - accuracy: 0.9969 - tp: 3170.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9956 - recall: 0.9950 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0068 - accuracy: 0.9981 - tp: 3176.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9975 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0051 - accuracy: 0.9983 - tp: 3177.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9978 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3178.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0046 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.01979568414390087; accuracy of 99.24882650375366%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0082 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0178 - accuracy: 0.9952 - tp: 3163.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 24.0000 - precision: 0.9931 - recall: 0.9925 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0148 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0222 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 0.9997 - prc: 0.9993\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0123 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 0.9996 - prc: 0.9993\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0065 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9984 - tp: 3179.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.0049212113954126835; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.039868198335170746; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0071 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9995 - prc: 0.9991\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0053 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0470 - accuracy: 0.9891 - tp: 3135.0000 - fp: 52.0000 - tn: 6322.0000 - fn: 52.0000 - precision: 0.9837 - recall: 0.9837 - auc: 0.9989 - prc: 0.9979\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0355 - accuracy: 0.9923 - tp: 3149.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 38.0000 - precision: 0.9887 - recall: 0.9881 - auc: 0.9995 - prc: 0.9989\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0100 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0062 - accuracy: 0.9980 - tp: 3177.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0061 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0031 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0433100201189518; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0070 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0074 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0125 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9995 - prc: 0.9990\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.015595515258610249; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0040 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0090 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0061 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9984 - tp: 3179.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.017296504229307175; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0110 - accuracy: 0.9972 - tp: 3173.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 14.0000 - precision: 0.9959 - recall: 0.9956 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0114 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0089 - accuracy: 0.9978 - tp: 3176.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 11.0000 - precision: 0.9969 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0033 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.0012014094972983003; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0018 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0018 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.01879321038722992; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0020 - accuracy: 0.9993 - tp: 3183.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.013295025564730167; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0031 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 4.9775415391195565e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.01979568414390087 - Accuracy: 99.24882650375366%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0049212113954126835 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.039868198335170746 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0433100201189518 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.015595515258610249 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.017296504229307175 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0012014094972983003 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.01879321038722992 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.013295025564730167 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 4.9775415391195565e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.67064499855042 (+- 0.24965872663163527)\n","> Loss: 0.01741265543460031\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 11ms/step - loss: 0.5136 - accuracy: 0.9447 - tp: 2273.0000 - fp: 205.0000 - tn: 4753.0000 - fn: 206.0000 - precision: 0.9173 - recall: 0.9169 - auc: 0.9641 - prc: 0.9339\n","\n",">round 8  client 3 evaluation training metrics:\n","[0.0023030999582260847, 0.9990586638450623, 3536.0, 5.0, 7077.0, 5.0, 0.998587965965271, 0.998587965965271, 0.9999978542327881, 0.9999957084655762]\n","\n",">round 8  client 3 evaluation metrics:\n","[0.5135512351989746, 0.9447357654571533, 2273.0, 205.0, 4753.0, 206.0, 0.9172719717025757, 0.9169020056724548, 0.964063286781311, 0.9338584542274475]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 9s 31ms/step - loss: 0.1020 - accuracy: 0.9638 - tp: 5355.0000 - fp: 306.0000 - tn: 11024.0000 - fn: 310.0000 - precision: 0.9459 - recall: 0.9453 - auc: 0.9814 - prc: 0.9656\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0160 - accuracy: 0.9973 - tp: 3172.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9962 - recall: 0.9956 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000   \n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.11610285192728043; accuracy of 97.92843461036682%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0292 - accuracy: 0.9957 - tp: 3165.0000 - fp: 20.0000 - tn: 6352.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 0.9983 - prc: 0.9968\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0100 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0065 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.5033e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.01044128742069006; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0034 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5292e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 8.136614633258432e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.4935e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.2076e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.7290e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 32ms/step - loss: 5.3178e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.0052e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.8891e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9870e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1610e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1657e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9885e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.011344742961227894; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.4673e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.8245e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5684e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2535e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8346e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.8902e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.4726e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9119e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.9593e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.015723897144198418; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5415e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8855e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.3738e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.2621e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4401e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.8483e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.3041798410995398e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.1967e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9649e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4211e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8245e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0853e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5724e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7996e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7008e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.5950e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.4528e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.02078777179121971; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4417e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.2758e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.9696e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.6535e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.5609e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.1014e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1279e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.8600e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1210e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.007977516390383244; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4519e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4859e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.3929e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 32ms/step - loss: 8.9803e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.5200e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 4.547300704871304e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.5381e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.6174e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9038e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.1094e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7230e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7142e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3129e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4766e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6933e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.4520e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 3.510863052724744e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.11610285192728043 - Accuracy: 97.92843461036682%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.01044128742069006 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 8.136614633258432e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.011344742961227894 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.015723897144198418 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.3041798410995398e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.02078777179121971 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.007977516390383244 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 4.547300704871304e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.510863052724744e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.69868004322052 (+- 0.5967227987170097)\n","> Loss: 0.018248053374350093\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 7.9263e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2266 - accuracy: 0.9711 - tp: 2370.0000 - fp: 106.0000 - tn: 4852.0000 - fn: 109.0000 - precision: 0.9572 - recall: 0.9560 - auc: 0.9864 - prc: 0.9742\n","\n",">round 8  client 4 evaluation training metrics:\n","[0.0007926341495476663, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999996423721313, 0.9999994039535522]\n","\n",">round 8  client 4 evaluation metrics:\n","[0.22659356892108917, 0.9710904955863953, 2370.0, 106.0, 4852.0, 109.0, 0.9571890234947205, 0.9560306668281555, 0.9863758087158203, 0.9742456674575806]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 34ms/step - loss: 0.1322 - accuracy: 0.9731 - tp: 5433.0000 - fp: 225.0000 - tn: 11105.0000 - fn: 232.0000 - precision: 0.9602 - recall: 0.9590 - auc: 0.9900 - prc: 0.9811\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0227 - accuracy: 0.9955 - tp: 3162.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 24.0000 - precision: 0.9940 - recall: 0.9925 - auc: 0.9999 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0049 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0022 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0916e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.9357e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.4496e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7314e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.06755366921424866; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0101 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0264 - accuracy: 0.9935 - tp: 3154.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 32.0000 - precision: 0.9906 - recall: 0.9900 - auc: 0.9996 - prc: 0.9991\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0232 - accuracy: 0.9953 - tp: 3163.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 0.9996 - prc: 0.9992\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0050 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.5495e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.5281e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.4980e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.0515e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.9714e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.014773941598832607; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0151 - accuracy: 0.9962 - tp: 3168.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0070 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9998 - prc: 0.9995\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 0.9998 - prc: 0.9995\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0196 - accuracy: 0.9950 - tp: 3162.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 24.0000 - precision: 0.9925 - recall: 0.9925 - auc: 0.9997 - prc: 0.9994\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9997 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0079 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.013701410964131355; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 32ms/step - loss: 9.1792e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.3387e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1805e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.3124e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6103e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.4495e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6001e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3345e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 5.503975989995524e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1963e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1698e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1327e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7923e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7542e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9132e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7819e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.7446e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.1650e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.4258e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 1.9843821064569056e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 2.5760e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.5669e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 1.1540e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.0505e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1868e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3988e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8257e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1742e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9267e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6450e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.008553086780011654; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.2016e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.2065e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 32ms/step - loss: 6.6861e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.2568e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2293e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6244e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6978e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2245e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7358e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.7559887055540457e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4138e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0206e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8225e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0444e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7980e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.7437e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.4175e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.7219e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.7430e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 1.5139825336518697e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.5895e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2789e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2407e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1225e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4201e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0720e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.3846e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3282e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2346e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.5531e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 7.371356332441792e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 33ms/step - loss: 2.2361e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.5927e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.0336e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0430e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6745e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7906e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.3039e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.9209e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.5759e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.3732e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.008836032822728157; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.06755366921424866 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.014773941598832607 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.013701410964131355 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 5.503975989995524e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 1.9843821064569056e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.008553086780011654 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.7559887055540457e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 1.5139825336518697e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 7.371356332441792e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.008836032822728157 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.77401077747345 (+- 0.3347717409845286)\n","> Loss: 0.011353309602964146\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 9.1251e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 12ms/step - loss: 0.3238 - accuracy: 0.9613 - tp: 2335.0000 - fp: 144.0000 - tn: 4814.0000 - fn: 144.0000 - precision: 0.9419 - recall: 0.9419 - auc: 0.9797 - prc: 0.9609\n","\n",">round 8  client 5 evaluation training metrics:\n","[0.0009125114302150905, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 8  client 5 evaluation metrics:\n","[0.3237841725349426, 0.9612746834754944, 2335.0, 144.0, 4814.0, 144.0, 0.941912055015564, 0.941912055015564, 0.9796807169914246, 0.9608574509620667]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.0681 - accuracy: 0.9748 - tp: 5450.0000 - fp: 213.0000 - tn: 11117.0000 - fn: 215.0000 - precision: 0.9624 - recall: 0.9620 - auc: 0.9895 - prc: 0.9796\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0104 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 8.9313e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.7416e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.7068e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.5677e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.0000e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.028815994039177895; accuracy of 98.96422028541565%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0254 - accuracy: 0.9930 - tp: 3151.0000 - fp: 32.0000 - tn: 6340.0000 - fn: 35.0000 - precision: 0.9899 - recall: 0.9890 - auc: 0.9998 - prc: 0.9997\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0216 - accuracy: 0.9955 - tp: 3164.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 0.9998 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0184 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.2425e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.5915e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.2903e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1260e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.0065e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.03198123723268509; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0050 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.8385e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.4643e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9044e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1679e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8138e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.4366e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8350e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.00025723539874888957; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.1559e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2808e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.6835e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.0803e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.9330e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6836e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6105e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6654e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2267e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1518e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 4.633683420252055e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9762e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7047e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3480e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0699e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1616e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7049e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4944e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8518e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.5561e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.7306e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 2.4260687496280298e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.3056e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6019e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5784e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.5669e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4713e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.0167e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5025e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2502e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6586e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0069e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 8.794264431344345e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7808e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.8458e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.0761e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1268e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4491e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2049e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.1081e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8753e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2003e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.6190e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 9.781247172213625e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9644e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.8666e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1210e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2057e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0532e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4594e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.6767e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.7538e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.8661e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2594e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 6.326130460365675e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2156e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1397e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0544e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.8519e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8733e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7133e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7529e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.5976e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.1117e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 9.10351809579879e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9171e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.2140e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.5969e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.8987e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.1153e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 4.4222e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7442e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5846e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.2267e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.4126e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 3.6250214634492295e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.028815994039177895 - Accuracy: 98.96422028541565%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03198123723268509 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.00025723539874888957 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 4.633683420252055e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.4260687496280298e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 8.794264431344345e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 9.781247172213625e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 6.326130460365675e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 9.10351809579879e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.6250214634492295e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.82109248638153 (+- 0.3633475780925267)\n","> Loss: 0.006116269437393384\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 3.9706e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2801 - accuracy: 0.9642 - tp: 2343.0000 - fp: 130.0000 - tn: 4828.0000 - fn: 136.0000 - precision: 0.9474 - recall: 0.9451 - auc: 0.9816 - prc: 0.9661\n","\n",">round 8  client 6 evaluation training metrics:\n","[0.000397062161937356, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 8  client 6 evaluation metrics:\n","[0.28008708357810974, 0.964232861995697, 2343.0, 130.0, 4828.0, 136.0, 0.947432279586792, 0.9451391696929932, 0.9816098809242249, 0.9661165475845337]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0515 - accuracy: 0.9783 - tp: 5477.0000 - fp: 181.0000 - tn: 11149.0000 - fn: 188.0000 - precision: 0.9680 - recall: 0.9668 - auc: 0.9908 - prc: 0.9828\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0052 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0096 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0118 - accuracy: 0.9971 - tp: 3172.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 3.9191e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.0710e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 1.6132e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 1.2805e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.1631e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.11232306063175201; accuracy of 98.49340915679932%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0165 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9995 - prc: 0.9990\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0145 - accuracy: 0.9967 - tp: 3170.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0055 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.0012429597554728389; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 8.476737275486812e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 1.4786597603233531e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 1.851298839028459e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 7.607989118696423e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.2372e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9759e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.8182e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.002149091102182865; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7862e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5252e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.8290e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.0359e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1368e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.2171e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.0838e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.0827e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.7566e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1705e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.010290736332535744; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 5.323609912011307e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 5.295359187584836e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.11232306063175201 - Accuracy: 98.49340915679932%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0012429597554728389 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 8.476737275486812e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 1.4786597603233531e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 1.851298839028459e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 7.607989118696423e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.002149091102182865 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.010290736332535744 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 5.323609912011307e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 5.295359187584836e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.79284346103668 (+- 0.4492224557536983)\n","> Loss: 0.012614214173891015\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 9.5159e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 11ms/step - loss: 0.2865 - accuracy: 0.9667 - tp: 2355.0000 - fp: 124.0000 - tn: 4834.0000 - fn: 124.0000 - precision: 0.9500 - recall: 0.9500 - auc: 0.9808 - prc: 0.9638\n","\n",">round 8  client 7 evaluation training metrics:\n","[0.0009515907731838524, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997019767761, 0.9999992251396179]\n","\n",">round 8  client 7 evaluation metrics:\n","[0.2865140736103058, 0.9666532278060913, 2355.0, 124.0, 4834.0, 124.0, 0.949979841709137, 0.949979841709137, 0.9808242917060852, 0.9638149738311768]\n","\n","=============================================================\n","\n","> round 8 average training auc= 0.2483660854698127\n","> round 8 average training loss= 0.01892136273201816\n","Epoch 1/10\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0266 - accuracy: 0.9925 - tp: 3501.0000 - fp: 40.0000 - tn: 7042.0000 - fn: 40.0000 - precision: 0.9887 - recall: 0.9887 - auc: 0.9994 - prc: 0.9989\n","Epoch 2/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0534 - accuracy: 0.9880 - tp: 3476.0000 - fp: 62.0000 - tn: 7020.0000 - fn: 65.0000 - precision: 0.9825 - recall: 0.9816 - auc: 0.9984 - prc: 0.9978\n","Epoch 3/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0360 - accuracy: 0.9906 - tp: 3483.0000 - fp: 42.0000 - tn: 7040.0000 - fn: 58.0000 - precision: 0.9881 - recall: 0.9836 - auc: 0.9996 - prc: 0.9993\n","Epoch 4/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0178 - accuracy: 0.9952 - tp: 3512.0000 - fp: 22.0000 - tn: 7060.0000 - fn: 29.0000 - precision: 0.9938 - recall: 0.9918 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0116 - accuracy: 0.9960 - tp: 3516.0000 - fp: 17.0000 - tn: 7065.0000 - fn: 25.0000 - precision: 0.9952 - recall: 0.9929 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0108 - accuracy: 0.9958 - tp: 3514.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 27.0000 - precision: 0.9949 - recall: 0.9924 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0106 - accuracy: 0.9967 - tp: 3521.0000 - fp: 15.0000 - tn: 7067.0000 - fn: 20.0000 - precision: 0.9958 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9962 - tp: 3515.0000 - fp: 14.0000 - tn: 7068.0000 - fn: 26.0000 - precision: 0.9960 - recall: 0.9927 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0097 - accuracy: 0.9958 - tp: 3516.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 25.0000 - precision: 0.9943 - recall: 0.9929 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9955 - tp: 3514.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 27.0000 - precision: 0.9941 - recall: 0.9924 - auc: 1.0000 - prc: 0.9999\n","> model 2 retrained, original loss= 0.05528300658334047 , retrained loss= 0.009949577040970325 epoch count 20.0\n","Epoch 1/10\n","36/36 [==============================] - 1s 27ms/step - loss: 8.4543e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","36/36 [==============================] - 1s 25ms/step - loss: 8.6924e-04 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","36/36 [==============================] - 1s 27ms/step - loss: 8.6792e-04 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","36/36 [==============================] - 1s 28ms/step - loss: 8.8242e-04 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","36/36 [==============================] - 1s 30ms/step - loss: 8.6533e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","36/36 [==============================] - 1s 30ms/step - loss: 8.6778e-04 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","36/36 [==============================] - 1s 28ms/step - loss: 8.7243e-04 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","36/36 [==============================] - 1s 26ms/step - loss: 8.5890e-04 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","36/36 [==============================] - 1s 25ms/step - loss: 8.9195e-04 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 9.0854e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","> model 4 retrained, original loss= 0.018248053374350093 , retrained loss= 0.0009085397468879819 epoch count 20.0\n","> round 8 average epoch count= 12.857142857142858\n"," 1/78 [..............................] - ETA: 2s"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["78/78 [==============================] - 0s 5ms/step\n","> round 8 test auc= 0.25533942403541016\n","111/111 [==============================] - 1s 8ms/step - loss: 1.3457 - accuracy: 0.8665 - tp: 2829.0000 - fp: 706.0000 - tn: 6376.0000 - fn: 712.0000 - precision: 0.8003 - recall: 0.7989 - auc: 0.8919 - prc: 0.8072\n","\n","> round 8 final model training loss_metric= [1.3457342386245728]\n","> round 8 final model training TP_metric= [2829.0]\n","> round 8 final model training FP_metric= [706.0]\n","> round 8 final model training TN_metric= [6376.0]\n","> round 8 final model training FN_metric= [712.0]\n","> round 8 final model training accuracy_metric= [86.65160536766052]\n","> round 8 final model training precision_metric= [80.0282895565033]\n","> round 8 final model training recall_metric = [79.8926830291748]\n","> round 8 final model training auc_metric= [0.8918861150741577]\n","> round 8 final model training prc_metric= [0.807220458984375]\n","\n","78/78 [==============================] - 1s 9ms/step - loss: 1.0552 - accuracy: 0.8977 - tp: 2097.0000 - fp: 379.0000 - tn: 4579.0000 - fn: 382.0000 - precision: 0.8469 - recall: 0.8459 - auc: 0.9202 - prc: 0.8514\n","> round 8 final model loss_metric= [1.055188536643982]\n","> round 8 final model TP_metric= [2097.0]\n","> round 8 final model FP_metric= [379.0]\n","> round 8 final model TN_metric= [4579.0]\n","> round 8 final model FN_metric= [382.0]\n","> round 8 final model accuracy_metric= [89.76737856864929]\n","> round 8 final model precision_metric= [84.69305038452148]\n","> round 8 final model recall_metric = [84.5905601978302]\n","> round 8 final model auc_metric= [0.9201986789703369]\n","> round 8 final model prc_metric= [0.8514086604118347]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 9 start, random seed= 9\n","\n","> client 1 started learning...........\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0906 - accuracy: 0.9435 - tp: 5181.0000 - fp: 476.0000 - tn: 10854.0000 - fn: 484.0000 - precision: 0.9159 - recall: 0.9146 - auc: 0.9636 - prc: 0.9306\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0222 - accuracy: 0.9948 - tp: 3160.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 26.0000 - precision: 0.9925 - recall: 0.9918 - auc: 0.9999 - prc: 0.9997\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0062 - accuracy: 0.9978 - tp: 3172.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 14.0000 - precision: 0.9978 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0048 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3175.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3176.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.026642611250281334; accuracy of 98.96713495254517%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0121 - accuracy: 0.9969 - tp: 3168.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 19.0000 - precision: 0.9965 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0284 - accuracy: 0.9933 - tp: 3150.0000 - fp: 27.0000 - tn: 6347.0000 - fn: 37.0000 - precision: 0.9915 - recall: 0.9884 - auc: 0.9993 - prc: 0.9987\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0137 - accuracy: 0.9968 - tp: 3167.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 20.0000 - precision: 0.9965 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0054 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.012466831132769585; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0049 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0032148577738553286; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.004023959394544363; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3175.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 2.6831214199773967e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.015158945694565773; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.011680775322020054; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 8.272613740700763e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.00861230306327343; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.0035958748776465654; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.026642611250281334 - Accuracy: 98.96713495254517%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.012466831132769585 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0032148577738553286 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.004023959394544363 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.6831214199773967e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.015158945694565773 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.011680775322020054 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 8.272613740700763e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.00861230306327343 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.0035958748776465654 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.76488649845123 (+- 0.2855671536224762)\n","> Loss: 0.00854312623368969\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.1764 - accuracy: 0.9745 - tp: 2382.0000 - fp: 93.0000 - tn: 4865.0000 - fn: 97.0000 - precision: 0.9624 - recall: 0.9609 - auc: 0.9904 - prc: 0.9815\n","\n",">round 9  client 1 evaluation training metrics:\n","[0.0037558558396995068, 0.9987762570381165, 3530.0, 2.0, 7080.0, 11.0, 0.9994337558746338, 0.9968935251235962, 0.9999945759773254, 0.9999892711639404]\n","\n",">round 9  client 1 evaluation metrics:\n","[0.1763976663351059, 0.9744520783424377, 2382.0, 93.0, 4865.0, 97.0, 0.9624242186546326, 0.9608713388442993, 0.9903725385665894, 0.9814804196357727]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 30ms/step - loss: 0.0339 - accuracy: 0.9835 - tp: 5523.0000 - fp: 138.0000 - tn: 11192.0000 - fn: 142.0000 - precision: 0.9756 - recall: 0.9749 - auc: 0.9954 - prc: 0.9911\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0153 - accuracy: 0.9951 - tp: 3161.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 25.0000 - precision: 0.9931 - recall: 0.9922 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0110 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0087 - accuracy: 0.9971 - tp: 3172.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0147 - accuracy: 0.9948 - tp: 3160.0000 - fp: 24.0000 - tn: 6348.0000 - fn: 26.0000 - precision: 0.9925 - recall: 0.9918 - auc: 0.9999 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0175 - accuracy: 0.9940 - tp: 3157.0000 - fp: 28.0000 - tn: 6344.0000 - fn: 29.0000 - precision: 0.9912 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0116 - accuracy: 0.9959 - tp: 3165.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 21.0000 - precision: 0.9943 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9954 - tp: 3164.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9956 - tp: 3165.0000 - fp: 21.0000 - tn: 6351.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9961 - tp: 3167.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 19.0000 - precision: 0.9943 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Score for fold 1: loss of 0.06974061578512192; accuracy of 97.93426990509033%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0294 - accuracy: 0.9909 - tp: 3143.0000 - fp: 43.0000 - tn: 6331.0000 - fn: 44.0000 - precision: 0.9865 - recall: 0.9862 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0346 - accuracy: 0.9909 - tp: 3143.0000 - fp: 43.0000 - tn: 6331.0000 - fn: 44.0000 - precision: 0.9865 - recall: 0.9862 - auc: 0.9992 - prc: 0.9985\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0231 - accuracy: 0.9932 - tp: 3154.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 33.0000 - precision: 0.9900 - recall: 0.9896 - auc: 0.9996 - prc: 0.9993\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0147 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0099 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0104 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0115 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 0.9997 - prc: 0.9995\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0092 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.018241019919514656; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0156 - accuracy: 0.9952 - tp: 3163.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 24.0000 - precision: 0.9931 - recall: 0.9925 - auc: 0.9997 - prc: 0.9994\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0147 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0100 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0082 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9955 - tp: 3162.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 25.0000 - precision: 0.9943 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0078 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0078 - accuracy: 0.9968 - tp: 3171.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Score for fold 3: loss of 0.01959952712059021; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0098 - accuracy: 0.9954 - tp: 3164.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 23.0000 - precision: 0.9934 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9956 - tp: 3160.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 27.0000 - precision: 0.9953 - recall: 0.9915 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0090 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0090 - accuracy: 0.9953 - tp: 3164.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 23.0000 - precision: 0.9931 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9948 - tp: 3162.0000 - fp: 25.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0091 - accuracy: 0.9944 - tp: 3160.0000 - fp: 27.0000 - tn: 6347.0000 - fn: 27.0000 - precision: 0.9915 - recall: 0.9915 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.0019504798110574484; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0082 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9960 - tp: 3167.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9943 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9958 - tp: 3166.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 21.0000 - precision: 0.9940 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Score for fold 5: loss of 0.01354808360338211; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0083 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0085 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0082 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0080 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0080 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0081 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0081 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0080 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.009368034079670906; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9955 - tp: 3161.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 26.0000 - precision: 0.9947 - recall: 0.9918 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3168.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 19.0000 - precision: 0.9953 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9955 - tp: 3165.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9934 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.002409956883639097; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0077 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0077 - accuracy: 0.9970 - tp: 3172.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0075 - accuracy: 0.9971 - tp: 3172.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 15.0000 - precision: 0.9959 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0074 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0074 - accuracy: 0.9971 - tp: 3171.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 16.0000 - precision: 0.9962 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0074 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0076 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.016984861344099045; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0073 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0074 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0073 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0071 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0071 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0072 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0070 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0071 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9968 - tp: 3170.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 17.0000 - precision: 0.9956 - recall: 0.9947 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.018515480682253838; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9957 - tp: 3165.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 22.0000 - precision: 0.9940 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0085 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 10: loss of 0.004292783327400684; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.06974061578512192 - Accuracy: 97.93426990509033%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.018241019919514656 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.01959952712059021 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0019504798110574484 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.01354808360338211 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.009368034079670906 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.002409956883639097 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.016984861344099045 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.018515480682253838 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.004292783327400684 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.37911331653595 (+- 0.5314065091683404)\n","> Loss: 0.017465084255672992\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0078 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2698 - accuracy: 0.9650 - tp: 2349.0000 - fp: 130.0000 - tn: 4828.0000 - fn: 130.0000 - precision: 0.9476 - recall: 0.9476 - auc: 0.9853 - prc: 0.9725\n","\n",">round 9  client 2 evaluation training metrics:\n","[0.007752928417176008, 0.9966111183166504, 3523.0, 18.0, 7064.0, 18.0, 0.9949166774749756, 0.9949166774749756, 0.999973475933075, 0.9999471306800842]\n","\n",">round 9  client 2 evaluation metrics:\n","[0.26976484060287476, 0.9650396704673767, 2349.0, 130.0, 4828.0, 130.0, 0.9475594758987427, 0.9475594758987427, 0.9852973818778992, 0.9725072383880615]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0539 - accuracy: 0.9781 - tp: 5478.0000 - fp: 186.0000 - tn: 11144.0000 - fn: 187.0000 - precision: 0.9672 - recall: 0.9670 - auc: 0.9923 - prc: 0.9854\n","Epoch 2/10\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0128 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0060 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3181.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9991 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9992 - tp: 3181.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9991 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0025 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.0571134053170681; accuracy of 99.06103014945984%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0173 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 0.9997 - prc: 0.9993\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0163 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0164 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0231 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9995 - prc: 0.9991\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0134 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0061 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.024027101695537567; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0057 - accuracy: 0.9979 - tp: 3177.0000 - fp: 10.0000 - tn: 6364.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0030 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0027 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.010621370747685432; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.013647355139255524; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0051 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.001351518789306283; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9984 - tp: 3179.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 8.0000 - precision: 0.9978 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.010421939194202423; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0023 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0025 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.018312396481633186; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 0.018312396481633186; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 3.8237893022596836e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 3.8237893022596836e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 1.4832310625934042e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 1.4832310625934042e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0023 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0023 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0025 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0025 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.011241781525313854; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.0571134053170681 - Accuracy: 99.06103014945984%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.024027101695537567 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.010621370747685432 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.013647355139255524 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.001351518789306283 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.010421939194202423 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.018312396481633186 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.8237893022596836e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.4832310625934042e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.011241781525313854 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.717777967453 (+- 0.28186802744374984)\n","> Loss: 0.01467899390936509\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 0.011241781525313854; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.0571134053170681 - Accuracy: 99.06103014945984%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.024027101695537567 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.010621370747685432 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.013647355139255524 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.001351518789306283 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.010421939194202423 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.018312396481633186 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.8237893022596836e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.4832310625934042e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.011241781525313854 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.717777967453 (+- 0.28186802744374984)\n","> Loss: 0.01467899390936509\n","------------------------------------------------------------------------\n","111/111 [==============================] - 1s 6ms/step\n","111/111 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2905 - accuracy: 0.9626 - tp: 2339.0000 - fp: 138.0000 - tn: 4820.0000 - fn: 140.0000 - precision: 0.9443 - recall: 0.9435 - auc: 0.9824 - prc: 0.9669\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2905 - accuracy: 0.9626 - tp: 2339.0000 - fp: 138.0000 - tn: 4820.0000 - fn: 140.0000 - precision: 0.9443 - recall: 0.9435 - auc: 0.9824 - prc: 0.9669\n","\n",">round 9  client 3 evaluation training metrics:\n","[0.0030111661180853844, 0.9990586638450623, 3536.0, 5.0, 7077.0, 5.0, 0.998587965965271, 0.998587965965271, 0.9999976754188538, 0.9999953508377075]\n","\n",">round 9  client 3 evaluation metrics:\n","[0.29050391912460327, 0.9626193642616272, 2339.0, 138.0, 4820.0, 140.0, 0.9442874193191528, 0.9435256123542786, 0.9823732972145081, 0.9668770432472229]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","\n",">round 9  client 3 evaluation training metrics:\n","[0.0030111661180853844, 0.9990586638450623, 3536.0, 5.0, 7077.0, 5.0, 0.998587965965271, 0.998587965965271, 0.9999976754188538, 0.9999953508377075]\n","\n",">round 9  client 3 evaluation metrics:\n","[0.29050391912460327, 0.9626193642616272, 2339.0, 138.0, 4820.0, 140.0, 0.9442874193191528, 0.9435256123542786, 0.9823732972145081, 0.9668770432472229]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 10s 29ms/step - loss: 0.0828 - accuracy: 0.9735 - tp: 5438.0000 - fp: 223.0000 - tn: 11107.0000 - fn: 227.0000 - precision: 0.9606 - recall: 0.9599 - auc: 0.9902 - prc: 0.9816\n","32/32 [==============================] - 10s 29ms/step - loss: 0.0828 - accuracy: 0.9735 - tp: 5438.0000 - fp: 223.0000 - tn: 11107.0000 - fn: 227.0000 - precision: 0.9606 - recall: 0.9599 - auc: 0.9902 - prc: 0.9816\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0114 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0114 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000   \n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.07473830133676529; accuracy of 98.11676144599915%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.07473830133676529; accuracy of 98.11676144599915%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0168 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 0.9995 - prc: 0.9990\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0168 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 0.9995 - prc: 0.9990\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0484 - accuracy: 0.9880 - tp: 3128.0000 - fp: 57.0000 - tn: 6315.0000 - fn: 58.0000 - precision: 0.9821 - recall: 0.9818 - auc: 0.9987 - prc: 0.9975\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0484 - accuracy: 0.9880 - tp: 3128.0000 - fp: 57.0000 - tn: 6315.0000 - fn: 58.0000 - precision: 0.9821 - recall: 0.9818 - auc: 0.9987 - prc: 0.9975\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0165 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9999 - prc: 0.9998\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0165 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.9440e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.9440e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4869e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4869e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1784e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1784e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2169e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2169e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.06663002073764801; accuracy of 98.68173003196716%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Score for fold 2: loss of 0.06663002073764801; accuracy of 98.68173003196716%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9995 - prc: 0.9990\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9995 - prc: 0.9990\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 32ms/step - loss: 9.1512e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 9.1512e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.9263e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 6.9263e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.4578e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.4578e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2909e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2909e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.0051e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 6.0051e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7785e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7785e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5559e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5559e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5666e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5666e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.007513531018048525; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 0.007513531018048525; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.3047e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.3047e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2873e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2873e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7102e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7102e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3425e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3425e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.1583e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.1583e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.0900e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.0900e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.9598e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 4.9598e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 33ms/step - loss: 4.7443e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 33ms/step - loss: 4.7443e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 32ms/step - loss: 5.0154e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 5.0154e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.012396818958222866; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Score for fold 4: loss of 0.012396818958222866; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6974e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6974e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9170e-04 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9170e-04 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7850e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7850e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.9684e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 9.9684e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 2.0218842109898105e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Score for fold 5: loss of 2.0218842109898105e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.5375e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 9.5375e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.8096e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 9.8096e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 9.4449e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 9.4449e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.0808e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.0808e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.0446e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.0446e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3182.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9994 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.9066e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 9.9066e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.0145136002392974e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 1.0145136002392974e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.3487e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 8.3487e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6093e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6093e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6358e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6358e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6245e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6245e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8190e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8190e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8414e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8414e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.9859e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 4.9859e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.1440e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.1440e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.7982e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 4.7982e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 32ms/step - loss: 4.4588e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 4.4588e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.012274992652237415; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 0.012274992652237415; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.4096e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 9.4096e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.9087e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 8.9087e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.5319e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.5319e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4485e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4485e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.8960e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 8.8960e-04 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 9.607736501493491e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 9.607736501493491e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.0784e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 9.0784e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.8047e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 9.8047e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 9.4731e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 9.4731e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 32ms/step - loss: 9.1349e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 9.1349e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.3385e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 9.3385e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.2752e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.2752e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.1156e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 9.1156e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.6175e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.6175e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 6.3959064391383436e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 6.3959064391383436e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.1091e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.1091e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9665e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9665e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.3859e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 9.3859e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.9904e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 9.9904e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.9551e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 9.9551e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 32ms/step - loss: 9.9618e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 9.9618e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.5618e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 9.5618e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 6.199332347023301e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.07473830133676529 - Accuracy: 98.11676144599915%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.06663002073764801 - Accuracy: 98.68173003196716%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.007513531018048525 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.012396818958222866 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.0218842109898105e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.0145136002392974e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.012274992652237415 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 9.607736501493491e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 6.3959064391383436e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 6.199332347023301e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.62335109710693 (+- 0.6302523455287472)\n","> Loss: 0.017360623165632205\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 6.199332347023301e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.07473830133676529 - Accuracy: 98.11676144599915%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.06663002073764801 - Accuracy: 98.68173003196716%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.007513531018048525 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.012396818958222866 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.0218842109898105e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.0145136002392974e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.012274992652237415 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 9.607736501493491e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 6.3959064391383436e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 6.199332347023301e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.62335109710693 (+- 0.6302523455287472)\n","> Loss: 0.017360623165632205\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 7.9839e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 10ms/step - loss: 7.9839e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2076 - accuracy: 0.9732 - tp: 2375.0000 - fp: 95.0000 - tn: 4863.0000 - fn: 104.0000 - precision: 0.9615 - recall: 0.9580 - auc: 0.9887 - prc: 0.9786\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2076 - accuracy: 0.9732 - tp: 2375.0000 - fp: 95.0000 - tn: 4863.0000 - fn: 104.0000 - precision: 0.9615 - recall: 0.9580 - auc: 0.9887 - prc: 0.9786\n","\n",">round 9  client 4 evaluation training metrics:\n","[0.0007983944960869849, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999996423721313, 0.9999994039535522]\n","\n",">round 9  client 4 evaluation metrics:\n","[0.20763015747070312, 0.973241925239563, 2375.0, 95.0, 4863.0, 104.0, 0.9615384340286255, 0.95804762840271, 0.9886736869812012, 0.9786272644996643]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","\n",">round 9  client 4 evaluation training metrics:\n","[0.0007983944960869849, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999996423721313, 0.9999994039535522]\n","\n",">round 9  client 4 evaluation metrics:\n","[0.20763015747070312, 0.973241925239563, 2375.0, 95.0, 4863.0, 104.0, 0.9615384340286255, 0.95804762840271, 0.9886736869812012, 0.9786272644996643]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.0913 - accuracy: 0.9781 - tp: 5473.0000 - fp: 180.0000 - tn: 11150.0000 - fn: 192.0000 - precision: 0.9682 - recall: 0.9661 - auc: 0.9923 - prc: 0.9854\n","32/32 [==============================] - 8s 31ms/step - loss: 0.0913 - accuracy: 0.9781 - tp: 5473.0000 - fp: 180.0000 - tn: 11150.0000 - fn: 192.0000 - precision: 0.9682 - recall: 0.9661 - auc: 0.9923 - prc: 0.9854\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0169 - accuracy: 0.9961 - tp: 3167.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 19.0000 - precision: 0.9943 - recall: 0.9940 - auc: 0.9999 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0169 - accuracy: 0.9961 - tp: 3167.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 19.0000 - precision: 0.9943 - recall: 0.9940 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9990 - tp: 3180.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9990 - tp: 3180.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9987 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5075e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.5075e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3554e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3554e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4174e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4174e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3029e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3029e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.04367497190833092; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.04367497190833092; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0147 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9992 - prc: 0.9990\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0147 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9992 - prc: 0.9990\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0111 - accuracy: 0.9974 - tp: 3173.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0111 - accuracy: 0.9974 - tp: 3173.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9995 - prc: 0.9991\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 0.9995 - prc: 0.9991\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0047 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0047 - accuracy: 0.9988 - tp: 3180.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0019 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0019 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0033 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 0.9998 - prc: 0.9995\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0033 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 0.9998 - prc: 0.9995\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 2.7332e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 2.7332e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.7118e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 1.7118e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.4426e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 1.4426e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.2260e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 1.2260e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.011438590474426746; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.011438590474426746; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7582e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 26ms/step - loss: 7.7582e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7317e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7317e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0203e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0203e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000       \n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000       \n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6299e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6299e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0776e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0776e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6788e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6788e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6761e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6761e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.1223e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.1223e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 3.472678145044483e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 3.472678145044483e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 2.6273e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 2.6273e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.5216e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 1.5216e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.0633e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 1.0633e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6709e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6709e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.4493e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 6.4493e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3502e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3502e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7756e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7756e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.0299e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 4.0299e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.7356e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 3.7356e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.2512e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 3.2512e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.012334753759205341; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Score for fold 4: loss of 0.012334753759205341; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 0.9998 - prc: 0.9995\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 0.9998 - prc: 0.9995\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.5417e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 6.5417e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.8534e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.8534e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1037e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1037e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0707e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0707e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5578e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5578e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.9973e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 4.9973e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.8186e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 31ms/step - loss: 6.8186e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Score for fold 5: loss of 2.1704436221625656e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Score for fold 5: loss of 2.1704436221625656e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 8.0390e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 8.0390e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5643e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5643e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1135e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1135e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7209e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7209e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.4669e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.4669e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3160e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3160e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.0468e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.0468e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.9440e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.9440e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.3924e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.3924e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.5096e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.5096e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.00011131409701192752; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 0.00011131409701192752; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.6198e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 7.6198e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9852e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9852e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8001e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8001e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.1308e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.1308e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2587e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2587e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6379e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6379e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6328e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6328e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8346e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8346e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9433e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9433e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4451e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4451e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 4.17692990595242e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 4.17692990595242e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.9795e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.9795e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.6104e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.6104e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5056e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5056e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9288e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9288e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0845e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0845e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1752e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1752e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5501e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5501e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7433e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7433e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6828e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6828e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7950e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7950e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 3.808786004810827e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 3.808786004810827e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7320e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7320e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.5295e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.5295e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2065e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2065e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.6157e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 4.6157e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.3514e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.3514e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.8988e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 4.8988e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8406e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8406e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1023e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1023e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.5799e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.5799e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 4.432077275851043e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 4.432077275851043e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1192e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1192e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6561e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6561e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2796e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2796e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1064e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1064e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2408e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2408e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8115e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8115e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7898e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7898e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.5838e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.5838e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2055e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2055e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.6372e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 4.6372e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 2.4571772883064114e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.04367497190833092 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.011438590474426746 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 3.472678145044483e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.012334753759205341 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.1704436221625656e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.00011131409701192752 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 4.17692990595242e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.808786004810827e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 4.432077275851043e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 2.4571772883064114e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.8870050907135 (+- 0.2259888251653086)\n","> Loss: 0.006763093642712192\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 2.4571772883064114e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.04367497190833092 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.011438590474426746 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 3.472678145044483e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.012334753759205341 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 2.1704436221625656e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.00011131409701192752 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 4.17692990595242e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.808786004810827e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 4.432077275851043e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 2.4571772883064114e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.8870050907135 (+- 0.2259888251653086)\n","> Loss: 0.006763093642712192\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 4.0006e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 9ms/step - loss: 4.0006e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9734 - tp: 2379.0000 - fp: 98.0000 - tn: 4860.0000 - fn: 100.0000 - precision: 0.9604 - recall: 0.9597 - auc: 0.9882 - prc: 0.9777\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9734 - tp: 2379.0000 - fp: 98.0000 - tn: 4860.0000 - fn: 100.0000 - precision: 0.9604 - recall: 0.9597 - auc: 0.9882 - prc: 0.9777\n","\n",">round 9  client 5 evaluation training metrics:\n","[0.00040005563641898334, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 9  client 5 evaluation metrics:\n","[0.2129736989736557, 0.9733763337135315, 2379.0, 98.0, 4860.0, 100.0, 0.9604359865188599, 0.9596611261367798, 0.9881799221038818, 0.9777307510375977]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","\n",">round 9  client 5 evaluation training metrics:\n","[0.00040005563641898334, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 9  client 5 evaluation metrics:\n","[0.2129736989736557, 0.9733763337135315, 2379.0, 98.0, 4860.0, 100.0, 0.9604359865188599, 0.9596611261367798, 0.9881799221038818, 0.9777307510375977]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 30ms/step - loss: 0.0709 - accuracy: 0.9797 - tp: 5490.0000 - fp: 170.0000 - tn: 11160.0000 - fn: 175.0000 - precision: 0.9700 - recall: 0.9691 - auc: 0.9932 - prc: 0.9869\n","32/32 [==============================] - 8s 30ms/step - loss: 0.0709 - accuracy: 0.9797 - tp: 5490.0000 - fp: 170.0000 - tn: 11160.0000 - fn: 175.0000 - precision: 0.9700 - recall: 0.9691 - auc: 0.9932 - prc: 0.9869\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0102 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0102 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.9559e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 9.9559e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.5882e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.5882e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9873e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9873e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0223e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0223e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6361e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6361e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.04503178596496582; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.04503178596496582; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0069 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9998 - prc: 0.9998\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0069 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9998 - prc: 0.9998\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0133 - accuracy: 0.9970 - tp: 3171.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 0.9997 - prc: 0.9994\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0133 - accuracy: 0.9970 - tp: 3171.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0289 - accuracy: 0.9930 - tp: 3152.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 34.0000 - precision: 0.9896 - recall: 0.9893 - auc: 0.9992 - prc: 0.9986\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0289 - accuracy: 0.9930 - tp: 3152.0000 - fp: 33.0000 - tn: 6339.0000 - fn: 34.0000 - precision: 0.9896 - recall: 0.9893 - auc: 0.9992 - prc: 0.9986\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2327e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2327e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7486e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.7486e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9091e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9091e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7911e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7911e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5133e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5133e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.004300692118704319; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.004300692118704319; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 0.9998 - prc: 0.9995\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0188 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9997 - prc: 0.9994\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0188 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9997 - prc: 0.9994\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0051 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0051 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0045 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.9144e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 7.9144e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.2491e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.2491e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8913e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8913e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2458e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2458e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.007684545125812292; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 0.007684545125812292; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.8900e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 1.8900e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.3603e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 1.3603e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1035e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1035e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 8.7955e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 8.7955e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 7.6814e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 7.6814e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.9077e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 6.9077e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0176e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0176e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.01115486491471529; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Score for fold 4: loss of 0.01115486491471529; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.6428e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 6.6428e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.0140e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 7.0140e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1663e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1663e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8763e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8763e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2398e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2398e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6549e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6549e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5475e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5475e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3887e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3887e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.5368e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.5368e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 5.2210707508493215e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Score for fold 5: loss of 5.2210707508493215e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7480e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7480e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.6713e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 6.6713e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.1867e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.1867e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.8958e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.8958e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.0460e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 6.0460e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.1854e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.1854e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.8697e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.8697e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.9874e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.9874e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.8417e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.8417e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5095e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5095e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 3.27179477608297e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 3.27179477608297e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4573e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4573e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.8893e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 4.8893e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4230e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4230e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.7537e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.7537e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4149e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4149e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3622e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3622e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1087e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1087e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.4322e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.4322e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.9179e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.9179e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.5231e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.5231e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.3650885193783324e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 1.3650885193783324e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 2.0396e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 2.0396e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1360e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1360e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6677e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6677e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0800e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0800e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9703e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9703e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.3420e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.3420e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.7742e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 3.7742e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.3472e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 3.3472e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.0369e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 3.0369e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.8064e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 2.8064e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 0.008551414124667645; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 0.008551414124667645; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 9.8710e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 9.8710e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7015e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7015e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3486e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3486e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9193e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9193e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8372e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8372e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7915e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7915e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8697e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8697e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7932e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7932e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.7399e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.7399e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7396e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7396e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 7.512842330470448e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Score for fold 9: loss of 7.512842330470448e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7368e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7368e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1709e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1709e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.8397e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 6.8397e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.9906e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.9906e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 4.6040e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 4.6040e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2170e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2170e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6707e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6707e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 32ms/step - loss: 6.0340e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 6.0340e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8489e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8489e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 5.13176337335608e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.04503178596496582 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.004300692118704319 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.007684545125812292 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01115486491471529 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 5.2210707508493215e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 3.27179477608297e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.3650885193783324e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.008551414124667645 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 7.512842330470448e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 5.13176337335608e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.84933972358704 (+- 0.21962167274494288)\n","> Loss: 0.00768345263950323\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 5.13176337335608e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.04503178596496582 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.004300692118704319 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.007684545125812292 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01115486491471529 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 5.2210707508493215e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 3.27179477608297e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.3650885193783324e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.008551414124667645 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 7.512842330470448e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 5.13176337335608e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.84933972358704 (+- 0.21962167274494288)\n","> Loss: 0.00768345263950323\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 3.9997e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 9ms/step - loss: 3.9997e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 11ms/step - loss: 0.2958 - accuracy: 0.9614 - tp: 2335.0000 - fp: 143.0000 - tn: 4815.0000 - fn: 144.0000 - precision: 0.9423 - recall: 0.9419 - auc: 0.9818 - prc: 0.9656\n","78/78 [==============================] - 1s 11ms/step - loss: 0.2958 - accuracy: 0.9614 - tp: 2335.0000 - fp: 143.0000 - tn: 4815.0000 - fn: 144.0000 - precision: 0.9423 - recall: 0.9419 - auc: 0.9818 - prc: 0.9656\n","\n",">round 9  client 6 evaluation training metrics:\n","[0.00039997402927838266, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 9  client 6 evaluation metrics:\n","[0.29583701491355896, 0.9614091515541077, 2335.0, 143.0, 4815.0, 144.0, 0.9422921538352966, 0.941912055015564, 0.9818130731582642, 0.965595006942749]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","\n",">round 9  client 6 evaluation training metrics:\n","[0.00039997402927838266, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 9  client 6 evaluation metrics:\n","[0.29583701491355896, 0.9614091515541077, 2335.0, 143.0, 4815.0, 144.0, 0.9422921538352966, 0.941912055015564, 0.9818130731582642, 0.965595006942749]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0581 - accuracy: 0.9763 - tp: 5462.0000 - fp: 200.0000 - tn: 11130.0000 - fn: 203.0000 - precision: 0.9647 - recall: 0.9642 - auc: 0.9908 - prc: 0.9824\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0581 - accuracy: 0.9763 - tp: 5462.0000 - fp: 200.0000 - tn: 11130.0000 - fn: 203.0000 - precision: 0.9647 - recall: 0.9642 - auc: 0.9908 - prc: 0.9824\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0064 - accuracy: 0.9985 - tp: 3178.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9981 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0064 - accuracy: 0.9985 - tp: 3178.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9981 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.027776336297392845; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.027776336297392845; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 0.9997 - prc: 0.9995\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 0.9979 - tp: 3176.0000 - fp: 10.0000 - tn: 6362.0000 - fn: 10.0000 - precision: 0.9969 - recall: 0.9969 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0176 - accuracy: 0.9962 - tp: 3168.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 0.9997 - prc: 0.9994\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0176 - accuracy: 0.9962 - tp: 3168.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0057 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0057 - accuracy: 0.9980 - tp: 3176.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0170 - accuracy: 0.9957 - tp: 3164.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9940 - recall: 0.9931 - auc: 0.9995 - prc: 0.9990\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0170 - accuracy: 0.9957 - tp: 3164.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 22.0000 - precision: 0.9940 - recall: 0.9931 - auc: 0.9995 - prc: 0.9990\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0046 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0046 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.03590864688158035; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.03590864688158035; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0241 - accuracy: 0.9937 - tp: 3156.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 30.0000 - precision: 0.9906 - recall: 0.9906 - auc: 0.9996 - prc: 0.9993\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0241 - accuracy: 0.9937 - tp: 3156.0000 - fp: 30.0000 - tn: 6342.0000 - fn: 30.0000 - precision: 0.9906 - recall: 0.9906 - auc: 0.9996 - prc: 0.9993\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0145 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 0.9997 - prc: 0.9994\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0145 - accuracy: 0.9960 - tp: 3167.0000 - fp: 19.0000 - tn: 6353.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0012047589989379048; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 0.0012047589989379048; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6460e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.6460e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0354e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.0354e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.9033e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.9033e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1026e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 6.1026e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.7363e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 7.7363e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.7544e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 6.7544e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.9427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.9427e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.3119e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.3119e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.4168e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.4168e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.010822132229804993; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Score for fold 4: loss of 0.010822132229804993; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 3.045952871616464e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Score for fold 5: loss of 3.045952871616464e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0015 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0015 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.6576401321799494e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 1.6576401321799494e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9012e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9012e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9725e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.9725e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 9.2626e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 9.2626e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.001779409241862595; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 0.001779409241862595; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 7.357430149568245e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 7.357430149568245e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.6459e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 8.6459e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 8.6327e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 8.6327e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.9398e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 7.9398e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.7430e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 8.7430e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.5198e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 26ms/step - loss: 8.5198e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.5112e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.5112e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.0520e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 7.0520e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1232e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1232e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.3877e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.3877e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.009093067608773708; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 0.009093067608773708; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.5653e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 7.5653e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4889e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4889e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1124e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1124e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7099e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7099e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.4508e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.4508e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.3195e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.3195e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.8441e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 29ms/step - loss: 4.8441e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.7569e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.7569e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2295e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.2295e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.010095687583088875; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.027776336297392845 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03590864688158035 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0012047589989379048 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.010822132229804993 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 3.045952871616464e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.6576401321799494e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.001779409241862595 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 7.357430149568245e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.009093067608773708 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.010095687583088875 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.86817240715027 (+- 0.147085976488014)\n","> Loss: 0.009673443220162881\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 0.010095687583088875; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.027776336297392845 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03590864688158035 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0012047589989379048 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.010822132229804993 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 3.045952871616464e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.6576401321799494e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.001779409241862595 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 7.357430149568245e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.009093067608773708 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.010095687583088875 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.86817240715027 (+- 0.147085976488014)\n","> Loss: 0.009673443220162881\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2978 - accuracy: 0.9632 - tp: 2340.0000 - fp: 135.0000 - tn: 4823.0000 - fn: 139.0000 - precision: 0.9455 - recall: 0.9439 - auc: 0.9798 - prc: 0.9627\n","78/78 [==============================] - 1s 10ms/step - loss: 0.2978 - accuracy: 0.9632 - tp: 2340.0000 - fp: 135.0000 - tn: 4823.0000 - fn: 139.0000 - precision: 0.9455 - recall: 0.9439 - auc: 0.9798 - prc: 0.9627\n","\n",">round 9  client 7 evaluation training metrics:\n","[0.0014281374169513583, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997019767761, 0.9999992251396179]\n","\n",">round 9  client 7 evaluation metrics:\n","[0.29781100153923035, 0.9631571769714355, 2340.0, 135.0, 4823.0, 139.0, 0.9454545378684998, 0.9439290165901184, 0.9798272848129272, 0.9626730680465698]\n","\n","=============================================================\n","\n","> round 9 average training auc= 0.24860325394267196\n","> round 9 average training loss= 0.01173825958096261\n","\n",">round 9  client 7 evaluation training metrics:\n","[0.0014281374169513583, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9999997019767761, 0.9999992251396179]\n","\n",">round 9  client 7 evaluation metrics:\n","[0.29781100153923035, 0.9631571769714355, 2340.0, 135.0, 4823.0, 139.0, 0.9454545378684998, 0.9439290165901184, 0.9798272848129272, 0.9626730680465698]\n","\n","=============================================================\n","\n","> round 9 average training auc= 0.24860325394267196\n","> round 9 average training loss= 0.01173825958096261\n","Epoch 1/10\n","Epoch 1/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9955 - tp: 3517.0000 - fp: 24.0000 - tn: 7058.0000 - fn: 24.0000 - precision: 0.9932 - recall: 0.9932 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9955 - tp: 3517.0000 - fp: 24.0000 - tn: 7058.0000 - fn: 24.0000 - precision: 0.9932 - recall: 0.9932 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0081 - accuracy: 0.9960 - tp: 3519.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 22.0000 - precision: 0.9941 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0081 - accuracy: 0.9960 - tp: 3519.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 22.0000 - precision: 0.9941 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9960 - tp: 3520.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 21.0000 - precision: 0.9941 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0081 - accuracy: 0.9960 - tp: 3520.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 21.0000 - precision: 0.9941 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0084 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0080 - accuracy: 0.9962 - tp: 3519.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 22.0000 - precision: 0.9949 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0080 - accuracy: 0.9962 - tp: 3519.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 22.0000 - precision: 0.9949 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","36/36 [==============================] - 1s 29ms/step - loss: 0.0081 - accuracy: 0.9962 - tp: 3520.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 21.0000 - precision: 0.9946 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 29ms/step - loss: 0.0081 - accuracy: 0.9962 - tp: 3520.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 21.0000 - precision: 0.9946 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3522.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 19.0000 - precision: 0.9946 - recall: 0.9946 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0083 - accuracy: 0.9964 - tp: 3522.0000 - fp: 19.0000 - tn: 7063.0000 - fn: 19.0000 - precision: 0.9946 - recall: 0.9946 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0081 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0081 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9960 - tp: 3519.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 22.0000 - precision: 0.9941 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9960 - tp: 3519.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 22.0000 - precision: 0.9941 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9958 - tp: 3518.0000 - fp: 22.0000 - tn: 7060.0000 - fn: 23.0000 - precision: 0.9938 - recall: 0.9935 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9958 - tp: 3518.0000 - fp: 22.0000 - tn: 7060.0000 - fn: 23.0000 - precision: 0.9938 - recall: 0.9935 - auc: 1.0000 - prc: 0.9999\n","> model 2 retrained, original loss= 0.017465084255672992 , retrained loss= 0.008289181627333164 epoch count 20.0\n","Epoch 1/10\n","> model 2 retrained, original loss= 0.017465084255672992 , retrained loss= 0.008289181627333164 epoch count 20.0\n","Epoch 1/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0935 - accuracy: 0.9814 - tp: 3441.0000 - fp: 98.0000 - tn: 6984.0000 - fn: 100.0000 - precision: 0.9723 - recall: 0.9718 - auc: 0.9964 - prc: 0.9935\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0935 - accuracy: 0.9814 - tp: 3441.0000 - fp: 98.0000 - tn: 6984.0000 - fn: 100.0000 - precision: 0.9723 - recall: 0.9718 - auc: 0.9964 - prc: 0.9935\n","Epoch 3/10\n","Epoch 3/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0851 - accuracy: 0.9804 - tp: 3433.0000 - fp: 100.0000 - tn: 6982.0000 - fn: 108.0000 - precision: 0.9717 - recall: 0.9695 - auc: 0.9979 - prc: 0.9960\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0851 - accuracy: 0.9804 - tp: 3433.0000 - fp: 100.0000 - tn: 6982.0000 - fn: 108.0000 - precision: 0.9717 - recall: 0.9695 - auc: 0.9979 - prc: 0.9960\n","Epoch 4/10\n","Epoch 4/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0489 - accuracy: 0.9894 - tp: 3483.0000 - fp: 55.0000 - tn: 7027.0000 - fn: 58.0000 - precision: 0.9845 - recall: 0.9836 - auc: 0.9989 - prc: 0.9978\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0489 - accuracy: 0.9894 - tp: 3483.0000 - fp: 55.0000 - tn: 7027.0000 - fn: 58.0000 - precision: 0.9845 - recall: 0.9836 - auc: 0.9989 - prc: 0.9978\n","Epoch 5/10\n","Epoch 5/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0059 - accuracy: 0.9986 - tp: 3533.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 8.0000 - precision: 0.9980 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0059 - accuracy: 0.9986 - tp: 3533.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 8.0000 - precision: 0.9980 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9983 - tp: 3532.0000 - fp: 9.0000 - tn: 7073.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9983 - tp: 3532.0000 - fp: 9.0000 - tn: 7073.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","> model 3 retrained, original loss= 0.01467899390936509 , retrained loss= 0.0031778982374817133 epoch count 20.0\n","> model 3 retrained, original loss= 0.01467899390936509 , retrained loss= 0.0031778982374817133 epoch count 20.0\n","Epoch 1/10\n","Epoch 1/10\n","36/36 [==============================] - 1s 29ms/step - loss: 8.6500e-04 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 29ms/step - loss: 8.6500e-04 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","36/36 [==============================] - 1s 30ms/step - loss: 8.7034e-04 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 30ms/step - loss: 8.7034e-04 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","36/36 [==============================] - 1s 30ms/step - loss: 8.5869e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 30ms/step - loss: 8.5869e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","36/36 [==============================] - 1s 29ms/step - loss: 9.0004e-04 - accuracy: 0.9993 - tp: 3536.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 4.0000 - precision: 0.9992 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 29ms/step - loss: 9.0004e-04 - accuracy: 0.9993 - tp: 3536.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 4.0000 - precision: 0.9992 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3537.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9995 - tp: 3537.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","36/36 [==============================] - 1s 26ms/step - loss: 9.0361e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 9.0361e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","36/36 [==============================] - 1s 26ms/step - loss: 9.0899e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 9.0899e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","36/36 [==============================] - 1s 26ms/step - loss: 9.3767e-04 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 9.3767e-04 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","36/36 [==============================] - 1s 25ms/step - loss: 8.4386e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 8.4386e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 8.7888e-04 - accuracy: 0.9993 - tp: 3536.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 4.0000 - precision: 0.9992 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 8.7888e-04 - accuracy: 0.9993 - tp: 3536.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 4.0000 - precision: 0.9992 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","> model 4 retrained, original loss= 0.017360623165632205 , retrained loss= 0.0008788753184489906 epoch count 20.0\n","> round 9 average epoch count= 14.285714285714286\n","> model 4 retrained, original loss= 0.017360623165632205 , retrained loss= 0.0008788753184489906 epoch count 20.0\n","> round 9 average epoch count= 14.285714285714286\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n","/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"output_type":"stream","name":"stdout","text":["78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","> round 9 test auc= 0.2626688432238653> round 9 test auc= 0.2626688432238653\n","\n","111/111 [==============================] - 1s 9ms/step - loss: 1.1861 - accuracy: 0.8784 - tp: 2894.0000 - fp: 645.0000 - tn: 6437.0000 - fn: 647.0000 - precision: 0.8177 - recall: 0.8173 - auc: 0.9074 - prc: 0.8284\n","111/111 [==============================] - 1s 9ms/step - loss: 1.1861 - accuracy: 0.8784 - tp: 2894.0000 - fp: 645.0000 - tn: 6437.0000 - fn: 647.0000 - precision: 0.8177 - recall: 0.8173 - auc: 0.9074 - prc: 0.8284\n","\n","> round 9 final model training loss_metric= [1.186104416847229]\n","> round 9 final model training TP_metric= [2894.0]\n","> round 9 final model training FP_metric= [645.0]\n","> round 9 final model training TN_metric= [6437.0]\n","> round 9 final model training FN_metric= [647.0]\n","> round 9 final model training accuracy_metric= [87.83770799636841]\n","> round 9 final model training precision_metric= [81.77451491355896]\n","> round 9 final model training recall_metric = [81.72832727432251]\n","> round 9 final model training auc_metric= [0.9073945879936218]\n","> round 9 final model training prc_metric= [0.8284363746643066]\n","\n","\n","> round 9 final model training loss_metric= [1.186104416847229]\n","> round 9 final model training TP_metric= [2894.0]\n","> round 9 final model training FP_metric= [645.0]\n","> round 9 final model training TN_metric= [6437.0]\n","> round 9 final model training FN_metric= [647.0]\n","> round 9 final model training accuracy_metric= [87.83770799636841]\n","> round 9 final model training precision_metric= [81.77451491355896]\n","> round 9 final model training recall_metric = [81.72832727432251]\n","> round 9 final model training auc_metric= [0.9073945879936218]\n","> round 9 final model training prc_metric= [0.8284363746643066]\n","\n","78/78 [==============================] - 1s 9ms/step - loss: 0.8594 - accuracy: 0.9122 - tp: 2152.0000 - fp: 326.0000 - tn: 4632.0000 - fn: 327.0000 - precision: 0.8684 - recall: 0.8681 - auc: 0.9359 - prc: 0.8785\n","78/78 [==============================] - 1s 9ms/step - loss: 0.8594 - accuracy: 0.9122 - tp: 2152.0000 - fp: 326.0000 - tn: 4632.0000 - fn: 327.0000 - precision: 0.8684 - recall: 0.8681 - auc: 0.9359 - prc: 0.8785\n","> round 9 final model loss_metric= [0.8594245314598083]\n","> round 9 final model TP_metric= [2152.0]\n","> round 9 final model FP_metric= [326.0]\n","> round 9 final model TN_metric= [4632.0]\n","> round 9 final model FN_metric= [327.0]\n","> round 9 final model accuracy_metric= [91.21958017349243]\n","> round 9 final model precision_metric= [86.84422969818115]\n","> round 9 final model recall_metric = [86.80920004844666]\n","> round 9 final model auc_metric= [0.935916006565094]\n","> round 9 final model prc_metric= [0.8785238265991211]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 10 start, random seed= 10\n","\n","> client 1 started learning...........\n","\n","> round 9 final model loss_metric= [0.8594245314598083]\n","> round 9 final model TP_metric= [2152.0]\n","> round 9 final model FP_metric= [326.0]\n","> round 9 final model TN_metric= [4632.0]\n","> round 9 final model FN_metric= [327.0]\n","> round 9 final model accuracy_metric= [91.21958017349243]\n","> round 9 final model precision_metric= [86.84422969818115]\n","> round 9 final model recall_metric = [86.80920004844666]\n","> round 9 final model auc_metric= [0.935916006565094]\n","> round 9 final model prc_metric= [0.8785238265991211]\n","(17,)\n","\n","##############################################################################################################\n","\n","> round 10 start, random seed= 10\n","\n","> client 1 started learning...........\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n","/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 30ms/step - loss: 0.0572 - accuracy: 0.9545 - tp: 5272.0000 - fp: 381.0000 - tn: 10949.0000 - fn: 393.0000 - precision: 0.9326 - recall: 0.9306 - auc: 0.9717 - prc: 0.9453\n","32/32 [==============================] - 8s 30ms/step - loss: 0.0572 - accuracy: 0.9545 - tp: 5272.0000 - fp: 381.0000 - tn: 10949.0000 - fn: 393.0000 - precision: 0.9326 - recall: 0.9306 - auc: 0.9717 - prc: 0.9453\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0116 - accuracy: 0.9972 - tp: 3168.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 18.0000 - precision: 0.9972 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0116 - accuracy: 0.9972 - tp: 3168.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 18.0000 - precision: 0.9972 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0082 - accuracy: 0.9979 - tp: 3168.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 18.0000 - precision: 0.9994 - recall: 0.9944 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0082 - accuracy: 0.9979 - tp: 3168.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 18.0000 - precision: 0.9994 - recall: 0.9944 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9986 - tp: 3175.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3174.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9984 - tp: 3174.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9985 - tp: 3177.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 9.0000 - precision: 0.9984 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9985 - tp: 3177.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 9.0000 - precision: 0.9984 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0052 - accuracy: 0.9983 - tp: 3173.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0052 - accuracy: 0.9983 - tp: 3173.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0046 - accuracy: 0.9983 - tp: 3173.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0046 - accuracy: 0.9983 - tp: 3173.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 13.0000 - precision: 0.9991 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0041 - accuracy: 0.9982 - tp: 3173.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0041 - accuracy: 0.9982 - tp: 3173.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 13.0000 - precision: 0.9987 - recall: 0.9959 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3174.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9985 - tp: 3174.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 12.0000 - precision: 0.9994 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.01997137814760208; accuracy of 99.34272170066833%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.01997137814760208; accuracy of 99.34272170066833%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0094 - accuracy: 0.9978 - tp: 3172.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 15.0000 - precision: 0.9981 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0094 - accuracy: 0.9978 - tp: 3172.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 15.0000 - precision: 0.9981 - recall: 0.9953 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0335 - accuracy: 0.9908 - tp: 3138.0000 - fp: 39.0000 - tn: 6335.0000 - fn: 49.0000 - precision: 0.9877 - recall: 0.9846 - auc: 0.9995 - prc: 0.9990\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0335 - accuracy: 0.9908 - tp: 3138.0000 - fp: 39.0000 - tn: 6335.0000 - fn: 49.0000 - precision: 0.9877 - recall: 0.9846 - auc: 0.9995 - prc: 0.9990\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0381 - accuracy: 0.9912 - tp: 3141.0000 - fp: 38.0000 - tn: 6336.0000 - fn: 46.0000 - precision: 0.9880 - recall: 0.9856 - auc: 0.9989 - prc: 0.9979\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0381 - accuracy: 0.9912 - tp: 3141.0000 - fp: 38.0000 - tn: 6336.0000 - fn: 46.0000 - precision: 0.9880 - recall: 0.9856 - auc: 0.9989 - prc: 0.9979\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0135 - accuracy: 0.9969 - tp: 3168.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 19.0000 - precision: 0.9965 - recall: 0.9940 - auc: 0.9999 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0135 - accuracy: 0.9969 - tp: 3168.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 19.0000 - precision: 0.9965 - recall: 0.9940 - auc: 0.9999 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9988 - tp: 3178.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 9.0000 - precision: 0.9994 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9986 - tp: 3177.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 10.0000 - precision: 0.9991 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9990 - tp: 3178.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 9.0000 - precision: 0.9997 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.03141825273633003; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.03141825273633003; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.9978 - tp: 3172.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 15.0000 - precision: 0.9981 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.9978 - tp: 3172.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 15.0000 - precision: 0.9981 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0070 - accuracy: 0.9980 - tp: 3173.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 14.0000 - precision: 0.9984 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0070 - accuracy: 0.9980 - tp: 3173.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 14.0000 - precision: 0.9984 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0058 - accuracy: 0.9983 - tp: 3175.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 12.0000 - precision: 0.9987 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0058 - accuracy: 0.9983 - tp: 3175.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 12.0000 - precision: 0.9987 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9983 - tp: 3175.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 12.0000 - precision: 0.9987 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9983 - tp: 3175.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 12.0000 - precision: 0.9987 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.0038835874292999506; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 0.0038835874292999506; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 3s 32ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 3s 32ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.01611255295574665; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Score for fold 4: loss of 0.01611255295574665; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0051 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 0.9998 - prc: 0.9995\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0051 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.003704522270709276; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Score for fold 5: loss of 0.003704522270709276; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9987 - tp: 3176.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 11.0000 - precision: 0.9997 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9984 - tp: 3175.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 12.0000 - precision: 0.9991 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.485552274971269e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 1.485552274971269e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0040 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3177.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 10.0000 - precision: 0.9997 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.0076560163870453835; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Score for fold 7: loss of 0.0076560163870453835; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0042 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0043 - accuracy: 0.9986 - tp: 3176.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 8.171430636139121e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 8.171430636139121e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9985 - tp: 3176.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 11.0000 - precision: 0.9991 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - tp: 3177.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 10.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.0035423317458480597; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 0.0035423317458480597; accuracy of 99.90583658218384%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3179.0000 - fp: 2.0000 - tn: 6372.0000 - fn: 8.0000 - precision: 0.9994 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3178.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 9.0000 - precision: 0.9991 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3180.0000 - fp: 1.0000 - tn: 6373.0000 - fn: 7.0000 - precision: 0.9997 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3180.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 7.0000 - precision: 0.9991 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3180.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 7.0000 - precision: 0.9991 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.01706639491021633; accuracy of 99.52918887138367%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.01997137814760208 - Accuracy: 99.34272170066833%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03141825273633003 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0038835874292999506 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01611255295574665 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.003704522270709276 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.485552274971269e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0076560163870453835 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 8.171430636139121e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.0035423317458480597 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.01706639491021633 - Accuracy: 99.52918887138367%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.76477921009064 (+- 0.22740276195884276)\n","> Loss: 0.010337806353618362\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 0.01706639491021633; accuracy of 99.52918887138367%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.01997137814760208 - Accuracy: 99.34272170066833%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.03141825273633003 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.0038835874292999506 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01611255295574665 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.003704522270709276 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.485552274971269e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0076560163870453835 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 8.171430636139121e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.0035423317458480597 - Accuracy: 99.90583658218384%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.01706639491021633 - Accuracy: 99.52918887138367%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.76477921009064 (+- 0.22740276195884276)\n","> Loss: 0.010337806353618362\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 10ms/step - loss: 0.1942 - accuracy: 0.9750 - tp: 2383.0000 - fp: 90.0000 - tn: 4868.0000 - fn: 96.0000 - precision: 0.9636 - recall: 0.9613 - auc: 0.9878 - prc: 0.9769\n","78/78 [==============================] - 1s 10ms/step - loss: 0.1942 - accuracy: 0.9750 - tp: 2383.0000 - fp: 90.0000 - tn: 4868.0000 - fn: 96.0000 - precision: 0.9636 - recall: 0.9613 - auc: 0.9878 - prc: 0.9769\n","\n",">round 10  client 1 evaluation training metrics:\n","[0.00405979435890913, 0.9987762570381165, 3530.0, 2.0, 7080.0, 11.0, 0.9994337558746338, 0.9968935251235962, 0.9999942183494568, 0.9999883770942688]\n","\n",">round 10  client 1 evaluation metrics:\n","[0.19418922066688538, 0.9749898910522461, 2383.0, 90.0, 4868.0, 96.0, 0.9636069536209106, 0.9612746834754944, 0.987765908241272, 0.9769186973571777]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","\n",">round 10  client 1 evaluation training metrics:\n","[0.00405979435890913, 0.9987762570381165, 3530.0, 2.0, 7080.0, 11.0, 0.9994337558746338, 0.9968935251235962, 0.9999942183494568, 0.9999883770942688]\n","\n",">round 10  client 1 evaluation metrics:\n","[0.19418922066688538, 0.9749898910522461, 2383.0, 90.0, 4868.0, 96.0, 0.9636069536209106, 0.9612746834754944, 0.987765908241272, 0.9769186973571777]\n","\n","=============================================================\n","\n","> client 2 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0418 - accuracy: 0.9824 - tp: 5510.0000 - fp: 144.0000 - tn: 11186.0000 - fn: 155.0000 - precision: 0.9745 - recall: 0.9726 - auc: 0.9943 - prc: 0.9891\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0418 - accuracy: 0.9824 - tp: 5510.0000 - fp: 144.0000 - tn: 11186.0000 - fn: 155.0000 - precision: 0.9745 - recall: 0.9726 - auc: 0.9943 - prc: 0.9891\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0180 - accuracy: 0.9945 - tp: 3155.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 31.0000 - precision: 0.9931 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0180 - accuracy: 0.9945 - tp: 3155.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 31.0000 - precision: 0.9931 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0185 - accuracy: 0.9944 - tp: 3157.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 29.0000 - precision: 0.9921 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0185 - accuracy: 0.9944 - tp: 3157.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 29.0000 - precision: 0.9921 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0113 - accuracy: 0.9964 - tp: 3168.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9950 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0113 - accuracy: 0.9964 - tp: 3168.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9950 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9970 - tp: 3170.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9959 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9970 - tp: 3170.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9959 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9968 - tp: 3169.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9956 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9968 - tp: 3169.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9956 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9970 - tp: 3170.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9959 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9970 - tp: 3170.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9959 - recall: 0.9950 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0085 - accuracy: 0.9967 - tp: 3170.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0085 - accuracy: 0.9967 - tp: 3170.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0075 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0075 - accuracy: 0.9975 - tp: 3174.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0075 - accuracy: 0.9971 - tp: 3172.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0075 - accuracy: 0.9971 - tp: 3172.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.027505449950695038; accuracy of 99.24882650375366%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.027505449950695038; accuracy of 99.24882650375366%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0112 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0112 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 0.9954 - tp: 3165.0000 - fp: 22.0000 - tn: 6352.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0189 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0189 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9999 - prc: 0.9998\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0315 - accuracy: 0.9908 - tp: 3143.0000 - fp: 44.0000 - tn: 6330.0000 - fn: 44.0000 - precision: 0.9862 - recall: 0.9862 - auc: 0.9995 - prc: 0.9991\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0315 - accuracy: 0.9908 - tp: 3143.0000 - fp: 44.0000 - tn: 6330.0000 - fn: 44.0000 - precision: 0.9862 - recall: 0.9862 - auc: 0.9995 - prc: 0.9991\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0271 - accuracy: 0.9927 - tp: 3151.0000 - fp: 34.0000 - tn: 6340.0000 - fn: 36.0000 - precision: 0.9893 - recall: 0.9887 - auc: 0.9994 - prc: 0.9991\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0271 - accuracy: 0.9927 - tp: 3151.0000 - fp: 34.0000 - tn: 6340.0000 - fn: 36.0000 - precision: 0.9893 - recall: 0.9887 - auc: 0.9994 - prc: 0.9991\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0244 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9994 - prc: 0.9988\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0244 - accuracy: 0.9935 - tp: 3156.0000 - fp: 31.0000 - tn: 6343.0000 - fn: 31.0000 - precision: 0.9903 - recall: 0.9903 - auc: 0.9994 - prc: 0.9988\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0159 - accuracy: 0.9940 - tp: 3158.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 29.0000 - precision: 0.9912 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0159 - accuracy: 0.9940 - tp: 3158.0000 - fp: 28.0000 - tn: 6346.0000 - fn: 29.0000 - precision: 0.9912 - recall: 0.9909 - auc: 0.9999 - prc: 0.9998\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0116 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0116 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 2: loss of 0.017479801550507545; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Score for fold 2: loss of 0.017479801550507545; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0108 - accuracy: 0.9956 - tp: 3165.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 22.0000 - precision: 0.9937 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0108 - accuracy: 0.9956 - tp: 3165.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 22.0000 - precision: 0.9937 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9959 - tp: 3167.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 20.0000 - precision: 0.9940 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 0.9957 - tp: 3166.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 0.9957 - tp: 3166.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 21.0000 - precision: 0.9937 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0087 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0087 - accuracy: 0.9956 - tp: 3166.0000 - fp: 21.0000 - tn: 6353.0000 - fn: 21.0000 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0086 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0086 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0086 - accuracy: 0.9959 - tp: 3166.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 21.0000 - precision: 0.9943 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0086 - accuracy: 0.9959 - tp: 3166.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 21.0000 - precision: 0.9943 - recall: 0.9934 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0085 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0085 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0085 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0085 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Score for fold 3: loss of 0.004829348996281624; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 0.004829348996281624; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9968 - tp: 3171.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9968 - tp: 3171.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9962 - tp: 3168.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 19.0000 - precision: 0.9947 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9962 - tp: 3168.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 19.0000 - precision: 0.9947 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9973 - tp: 3174.0000 - fp: 13.0000 - tn: 6361.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0080 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0080 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Score for fold 4: loss of 0.019256820902228355; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Score for fold 4: loss of 0.019256820902228355; accuracy of 99.4350254535675%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0090 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 5: loss of 0.01826341822743416; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Score for fold 5: loss of 0.01826341822743416; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0092 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 0.9997 - prc: 0.9995\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0092 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 0.9997 - prc: 0.9995\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0079 - accuracy: 0.9961 - tp: 3167.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 20.0000 - precision: 0.9947 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0079 - accuracy: 0.9961 - tp: 3167.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 20.0000 - precision: 0.9947 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0079 - accuracy: 0.9960 - tp: 3167.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9943 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0079 - accuracy: 0.9960 - tp: 3167.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9943 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9957 - tp: 3165.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 22.0000 - precision: 0.9940 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9957 - tp: 3165.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 22.0000 - precision: 0.9940 - recall: 0.9931 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0078 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9960 - tp: 3167.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9943 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9960 - tp: 3167.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 20.0000 - precision: 0.9943 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 6: loss of 0.009802027605473995; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 0.009802027605473995; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0078 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0078 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0078 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0078 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 34ms/step - loss: 0.0077 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 34ms/step - loss: 0.0077 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0079 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0079 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Score for fold 7: loss of 0.0101004121825099; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 0.0101004121825099; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0088 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0088 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0091 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0091 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0088 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0088 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9960 - tp: 3168.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 19.0000 - precision: 0.9940 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0089 - accuracy: 0.9952 - tp: 3164.0000 - fp: 23.0000 - tn: 6351.0000 - fn: 23.0000 - precision: 0.9928 - recall: 0.9928 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9964 - tp: 3170.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Score for fold 8: loss of 0.002346731722354889; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 0.002346731722354889; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0080 - accuracy: 0.9961 - tp: 3168.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 19.0000 - precision: 0.9944 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0078 - accuracy: 0.9965 - tp: 3170.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9963 - tp: 3169.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 18.0000 - precision: 0.9947 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0079 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0079 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0079 - accuracy: 0.9962 - tp: 3168.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 19.0000 - precision: 0.9947 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0079 - accuracy: 0.9962 - tp: 3168.0000 - fp: 17.0000 - tn: 6357.0000 - fn: 19.0000 - precision: 0.9947 - recall: 0.9940 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0081 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0081 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0077 - accuracy: 0.9964 - tp: 3169.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 18.0000 - precision: 0.9950 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0077 - accuracy: 0.9964 - tp: 3169.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 18.0000 - precision: 0.9950 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9962 - tp: 3169.0000 - fp: 18.0000 - tn: 6356.0000 - fn: 18.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0079 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0079 - accuracy: 0.9958 - tp: 3167.0000 - fp: 20.0000 - tn: 6354.0000 - fn: 20.0000 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - prc: 0.9999\n","Score for fold 9: loss of 0.017192546278238297; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 0.017192546278238297; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0092 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0092 - accuracy: 0.9967 - tp: 3171.0000 - fp: 16.0000 - tn: 6358.0000 - fn: 16.0000 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0562 - accuracy: 0.9874 - tp: 3127.0000 - fp: 60.0000 - tn: 6314.0000 - fn: 60.0000 - precision: 0.9812 - recall: 0.9812 - auc: 0.9978 - prc: 0.9961\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0562 - accuracy: 0.9874 - tp: 3127.0000 - fp: 60.0000 - tn: 6314.0000 - fn: 60.0000 - precision: 0.9812 - recall: 0.9812 - auc: 0.9978 - prc: 0.9961\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1417 - accuracy: 0.9674 - tp: 3026.0000 - fp: 151.0000 - tn: 6223.0000 - fn: 161.0000 - precision: 0.9525 - recall: 0.9495 - auc: 0.9936 - prc: 0.9877\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1417 - accuracy: 0.9674 - tp: 3026.0000 - fp: 151.0000 - tn: 6223.0000 - fn: 161.0000 - precision: 0.9525 - recall: 0.9495 - auc: 0.9936 - prc: 0.9877\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0534 - accuracy: 0.9886 - tp: 3132.0000 - fp: 54.0000 - tn: 6320.0000 - fn: 55.0000 - precision: 0.9831 - recall: 0.9827 - auc: 0.9986 - prc: 0.9972\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0534 - accuracy: 0.9886 - tp: 3132.0000 - fp: 54.0000 - tn: 6320.0000 - fn: 55.0000 - precision: 0.9831 - recall: 0.9827 - auc: 0.9986 - prc: 0.9972\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0376 - accuracy: 0.9925 - tp: 3151.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 36.0000 - precision: 0.9887 - recall: 0.9887 - auc: 0.9992 - prc: 0.9983\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0376 - accuracy: 0.9925 - tp: 3151.0000 - fp: 36.0000 - tn: 6338.0000 - fn: 36.0000 - precision: 0.9887 - recall: 0.9887 - auc: 0.9992 - prc: 0.9983\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0430 - accuracy: 0.9926 - tp: 3150.0000 - fp: 34.0000 - tn: 6340.0000 - fn: 37.0000 - precision: 0.9893 - recall: 0.9884 - auc: 0.9978 - prc: 0.9968\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0430 - accuracy: 0.9926 - tp: 3150.0000 - fp: 34.0000 - tn: 6340.0000 - fn: 37.0000 - precision: 0.9893 - recall: 0.9884 - auc: 0.9978 - prc: 0.9968\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0136 - accuracy: 0.9955 - tp: 3163.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 24.0000 - precision: 0.9940 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0136 - accuracy: 0.9955 - tp: 3163.0000 - fp: 19.0000 - tn: 6355.0000 - fn: 24.0000 - precision: 0.9940 - recall: 0.9925 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.09401248395442963; accuracy of 96.61017060279846%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.027505449950695038 - Accuracy: 99.24882650375366%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.017479801550507545 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.004829348996281624 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.019256820902228355 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.01826341822743416 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.009802027605473995 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0101004121825099 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.002346731722354889 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.017192546278238297 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.09401248395442963 - Accuracy: 96.61017060279846%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.3222451210022 (+- 0.9194965701360676)\n","> Loss: 0.022078904137015343\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 0.09401248395442963; accuracy of 96.61017060279846%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.027505449950695038 - Accuracy: 99.24882650375366%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.017479801550507545 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.004829348996281624 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.019256820902228355 - Accuracy: 99.4350254535675%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.01826341822743416 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.009802027605473995 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0101004121825099 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.002346731722354889 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.017192546278238297 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.09401248395442963 - Accuracy: 96.61017060279846%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.3222451210022 (+- 0.9194965701360676)\n","> Loss: 0.022078904137015343\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0162 - accuracy: 0.9945 - tp: 3511.0000 - fp: 28.0000 - tn: 7054.0000 - fn: 30.0000 - precision: 0.9921 - recall: 0.9915 - auc: 0.9998 - prc: 0.9997\n","111/111 [==============================] - 1s 9ms/step - loss: 0.0162 - accuracy: 0.9945 - tp: 3511.0000 - fp: 28.0000 - tn: 7054.0000 - fn: 30.0000 - precision: 0.9921 - recall: 0.9915 - auc: 0.9998 - prc: 0.9997\n","78/78 [==============================] - 1s 10ms/step - loss: 0.3492 - accuracy: 0.9515 - tp: 2295.0000 - fp: 177.0000 - tn: 4781.0000 - fn: 184.0000 - precision: 0.9284 - recall: 0.9258 - auc: 0.9772 - prc: 0.9572\n","78/78 [==============================] - 1s 10ms/step - loss: 0.3492 - accuracy: 0.9515 - tp: 2295.0000 - fp: 177.0000 - tn: 4781.0000 - fn: 184.0000 - precision: 0.9284 - recall: 0.9258 - auc: 0.9772 - prc: 0.9572\n","\n",">round 10  client 2 evaluation training metrics:\n","[0.016238350421190262, 0.9945401549339294, 3511.0, 28.0, 7054.0, 30.0, 0.9920881390571594, 0.991527795791626, 0.9997868537902832, 0.9997339248657227]\n","\n",">round 10  client 2 evaluation metrics:\n","[0.34923022985458374, 0.9514589309692383, 2295.0, 177.0, 4781.0, 184.0, 0.928398072719574, 0.9257765412330627, 0.9772431254386902, 0.9571551084518433]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","\n",">round 10  client 2 evaluation training metrics:\n","[0.016238350421190262, 0.9945401549339294, 3511.0, 28.0, 7054.0, 30.0, 0.9920881390571594, 0.991527795791626, 0.9997868537902832, 0.9997339248657227]\n","\n",">round 10  client 2 evaluation metrics:\n","[0.34923022985458374, 0.9514589309692383, 2295.0, 177.0, 4781.0, 184.0, 0.928398072719574, 0.9257765412330627, 0.9772431254386902, 0.9571551084518433]\n","\n","=============================================================\n","\n","> client 3 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 32ms/step - loss: 0.0264 - accuracy: 0.9746 - tp: 5445.0000 - fp: 211.0000 - tn: 11119.0000 - fn: 220.0000 - precision: 0.9627 - recall: 0.9612 - auc: 0.9904 - prc: 0.9819\n","32/32 [==============================] - 7s 32ms/step - loss: 0.0264 - accuracy: 0.9746 - tp: 5445.0000 - fp: 211.0000 - tn: 11119.0000 - fn: 220.0000 - precision: 0.9627 - recall: 0.9612 - auc: 0.9904 - prc: 0.9819\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0087 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0087 - accuracy: 0.9977 - tp: 3175.0000 - fp: 11.0000 - tn: 6361.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0035 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0035 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3181.0000 - fp: 5.0000 - tn: 6367.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.02625572867691517; accuracy of 99.24882650375366%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.02625572867691517; accuracy of 99.24882650375366%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0087 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9996 - prc: 0.9994\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0087 - accuracy: 0.9977 - tp: 3176.0000 - fp: 11.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9965 - recall: 0.9965 - auc: 0.9996 - prc: 0.9994\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9975 - tp: 3175.0000 - fp: 12.0000 - tn: 6362.0000 - fn: 12.0000 - precision: 0.9962 - recall: 0.9962 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0120 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 0.9997 - prc: 0.9995\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0120 - accuracy: 0.9969 - tp: 3172.0000 - fp: 15.0000 - tn: 6359.0000 - fn: 15.0000 - precision: 0.9953 - recall: 0.9953 - auc: 0.9997 - prc: 0.9995\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0298 - accuracy: 0.9933 - tp: 3155.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 32.0000 - precision: 0.9900 - recall: 0.9900 - auc: 0.9987 - prc: 0.9975\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0298 - accuracy: 0.9933 - tp: 3155.0000 - fp: 32.0000 - tn: 6342.0000 - fn: 32.0000 - precision: 0.9900 - recall: 0.9900 - auc: 0.9987 - prc: 0.9975\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0448 - accuracy: 0.9900 - tp: 3138.0000 - fp: 47.0000 - tn: 6327.0000 - fn: 49.0000 - precision: 0.9852 - recall: 0.9846 - auc: 0.9986 - prc: 0.9972\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0448 - accuracy: 0.9900 - tp: 3138.0000 - fp: 47.0000 - tn: 6327.0000 - fn: 49.0000 - precision: 0.9852 - recall: 0.9846 - auc: 0.9986 - prc: 0.9972\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0149 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 0.9997 - prc: 0.9995\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0149 - accuracy: 0.9971 - tp: 3173.0000 - fp: 14.0000 - tn: 6360.0000 - fn: 14.0000 - precision: 0.9956 - recall: 0.9956 - auc: 0.9997 - prc: 0.9995\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0026 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.05763303488492966; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.05763303488492966; accuracy of 98.87005686759949%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.015380819328129292; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 0.015380819328129292; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9998 - prc: 0.9995\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.00228505558334291; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Score for fold 4: loss of 0.00228505558334291; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 3.752356133190915e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Score for fold 5: loss of 3.752356133190915e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9986 - tp: 3180.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.02215316705405712; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 0.02215316705405712; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0048 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0048 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3184.0000 - fp: 3.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 0.9988 - tp: 3181.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 6.0000 - precision: 0.9984 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.029266012832522392; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 0.029266012832522392; accuracy of 99.62335228919983%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0049 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0049 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 0.9998 - prc: 0.9995\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0028 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 2.4593622583779506e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Score for fold 8: loss of 2.4593622583779506e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9983 - tp: 3179.0000 - fp: 8.0000 - tn: 6366.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 0.9981 - tp: 3178.0000 - fp: 9.0000 - tn: 6365.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 0.9985 - tp: 3180.0000 - fp: 7.0000 - tn: 6367.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 1.8942420865641907e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 1.8942420865641907e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - tp: 3181.0000 - fp: 6.0000 - tn: 6368.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9992 - tp: 3183.0000 - fp: 4.0000 - tn: 6370.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9990 - tp: 3182.0000 - fp: 5.0000 - tn: 6369.0000 - fn: 5.0000 - precision: 0.9984 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.005017123185098171; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.02625572867691517 - Accuracy: 99.24882650375366%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.05763303488492966 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.015380819328129292 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00228505558334291 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 3.752356133190915e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.02215316705405712 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.029266012832522392 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 2.4593622583779506e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.8942420865641907e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.005017123185098171 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.68006074428558 (+- 0.3474981751910294)\n","> Loss: 0.015807200114977604\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 0.005017123185098171; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.02625572867691517 - Accuracy: 99.24882650375366%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.05763303488492966 - Accuracy: 98.87005686759949%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.015380819328129292 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.00228505558334291 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 3.752356133190915e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.02215316705405712 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.029266012832522392 - Accuracy: 99.62335228919983%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 2.4593622583779506e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 1.8942420865641907e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.005017123185098171 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.68006074428558 (+- 0.3474981751910294)\n","> Loss: 0.015807200114977604\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 1s 6ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - tp: 3536.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 5.0000 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 11ms/step - loss: 0.3725 - accuracy: 0.9570 - tp: 2317.0000 - fp: 158.0000 - tn: 4800.0000 - fn: 162.0000 - precision: 0.9362 - recall: 0.9347 - auc: 0.9745 - prc: 0.9525\n","78/78 [==============================] - 1s 11ms/step - loss: 0.3725 - accuracy: 0.9570 - tp: 2317.0000 - fp: 158.0000 - tn: 4800.0000 - fn: 162.0000 - precision: 0.9362 - recall: 0.9347 - auc: 0.9745 - prc: 0.9525\n","\n",">round 10  client 3 evaluation training metrics:\n","[0.0024426737800240517, 0.9990586638450623, 3536.0, 5.0, 7077.0, 5.0, 0.998587965965271, 0.998587965965271, 0.9999976754188538, 0.9999953508377075]\n","\n",">round 10  client 3 evaluation metrics:\n","[0.37254467606544495, 0.9569718837738037, 2317.0, 158.0, 4800.0, 162.0, 0.9361616373062134, 0.9346510767936707, 0.9745094180107117, 0.9524945616722107]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","\n",">round 10  client 3 evaluation training metrics:\n","[0.0024426737800240517, 0.9990586638450623, 3536.0, 5.0, 7077.0, 5.0, 0.998587965965271, 0.998587965965271, 0.9999976754188538, 0.9999953508377075]\n","\n",">round 10  client 3 evaluation metrics:\n","[0.37254467606544495, 0.9569718837738037, 2317.0, 158.0, 4800.0, 162.0, 0.9361616373062134, 0.9346510767936707, 0.9745094180107117, 0.9524945616722107]\n","\n","=============================================================\n","\n","> client 4 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0705 - accuracy: 0.9724 - tp: 5427.0000 - fp: 231.0000 - tn: 11099.0000 - fn: 238.0000 - precision: 0.9592 - recall: 0.9580 - auc: 0.9873 - prc: 0.9761\n","32/32 [==============================] - 8s 29ms/step - loss: 0.0705 - accuracy: 0.9724 - tp: 5427.0000 - fp: 231.0000 - tn: 11099.0000 - fn: 238.0000 - precision: 0.9592 - recall: 0.9580 - auc: 0.9873 - prc: 0.9761\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0112 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0112 - accuracy: 0.9983 - tp: 3178.0000 - fp: 8.0000 - tn: 6364.0000 - fn: 8.0000 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0022 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0019 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3183.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 3.0000 - precision: 0.9997 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.0059103877283632755; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.0059103877283632755; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.9991 - tp: 3181.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 5.0000 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3432e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.3432e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7320e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7320e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2824e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.2824e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9068e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9068e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0994e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0994e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4313e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4313e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6178e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6178e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.0053404089994728565; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.0053404089994728565; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4893e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4893e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8581e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8581e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.0644e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.0644e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8558e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.8558e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 1.1848303984152153e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Score for fold 3: loss of 1.1848303984152153e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 7.0719e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 7.0719e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0614e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0614e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5412e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5412e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5140e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5140e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2670e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2670e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1505e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1505e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.0956e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.0956e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8203e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8203e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 4.9235e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 4.9235e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.7331e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 4.7331e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.01442680787295103; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Score for fold 4: loss of 0.01442680787295103; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0317 - accuracy: 0.9939 - tp: 3157.0000 - fp: 29.0000 - tn: 6343.0000 - fn: 29.0000 - precision: 0.9909 - recall: 0.9909 - auc: 0.9985 - prc: 0.9971\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0317 - accuracy: 0.9939 - tp: 3157.0000 - fp: 29.0000 - tn: 6343.0000 - fn: 29.0000 - precision: 0.9909 - recall: 0.9909 - auc: 0.9985 - prc: 0.9971\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1796 - accuracy: 0.9615 - tp: 2995.0000 - fp: 177.0000 - tn: 6195.0000 - fn: 191.0000 - precision: 0.9442 - recall: 0.9401 - auc: 0.9901 - prc: 0.9810\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1796 - accuracy: 0.9615 - tp: 2995.0000 - fp: 177.0000 - tn: 6195.0000 - fn: 191.0000 - precision: 0.9442 - recall: 0.9401 - auc: 0.9901 - prc: 0.9810\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0907 - accuracy: 0.9805 - tp: 3087.0000 - fp: 87.0000 - tn: 6285.0000 - fn: 99.0000 - precision: 0.9726 - recall: 0.9689 - auc: 0.9967 - prc: 0.9939\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0907 - accuracy: 0.9805 - tp: 3087.0000 - fp: 87.0000 - tn: 6285.0000 - fn: 99.0000 - precision: 0.9726 - recall: 0.9689 - auc: 0.9967 - prc: 0.9939\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9979 - tp: 3175.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9972 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9979 - tp: 3175.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 11.0000 - precision: 0.9972 - recall: 0.9965 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9995\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3117e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.3117e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 8.0244e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 8.0244e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.0985383689403534; accuracy of 97.74011373519897%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Score for fold 5: loss of 0.0985383689403534; accuracy of 97.74011373519897%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0107 - accuracy: 0.9974 - tp: 3173.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0107 - accuracy: 0.9974 - tp: 3173.0000 - fp: 12.0000 - tn: 6360.0000 - fn: 13.0000 - precision: 0.9962 - recall: 0.9959 - auc: 1.0000 - prc: 0.9999\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0016 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0013 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 0.0005787322879768908; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 0.0005787322879768908; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9068e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9068e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9695e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9695e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.8286e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 9.8286e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 6.212510197656229e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 6.212510197656229e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.6367e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.6367e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.4746e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 9.4746e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4917e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 9.4917e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9101e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9101e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 3.4361426514806226e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 3.4361426514806226e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 9.8290e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 9.8290e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 9.7337e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 9.7337e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 9.7880e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 9.7880e-04 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 9.7789e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 9.7789e-04 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9350e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9350e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6126e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.6126e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9112e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9112e-04 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.5959e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 9.5959e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 2.602441054477822e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 2.602441054477822e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8037e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8037e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.1905e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.1905e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.8725e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 27ms/step - loss: 6.8725e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6903e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.6903e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7591e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7591e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5289e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5289e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1714e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1714e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5263e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5263e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.0985e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.0985e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2900e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2900e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.016529735177755356; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.0059103877283632755 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0053404089994728565 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 1.1848303984152153e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01442680787295103 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0985383689403534 - Accuracy: 97.74011373519897%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.0005787322879768908 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 6.212510197656229e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.4361426514806226e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 2.602441054477822e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.016529735177755356 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.7175133228302 (+- 0.6644922642973232)\n","> Loss: 0.01414588002498931\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 0.016529735177755356; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.0059103877283632755 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0053404089994728565 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 1.1848303984152153e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.01442680787295103 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.0985383689403534 - Accuracy: 97.74011373519897%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.0005787322879768908 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 6.212510197656229e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.4361426514806226e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 2.602441054477822e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.016529735177755356 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.7175133228302 (+- 0.6644922642973232)\n","> Loss: 0.01414588002498931\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9999 - prc: 0.9999\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9999 - prc: 0.9999\n","78/78 [==============================] - 1s 11ms/step - loss: 0.4055 - accuracy: 0.9516 - tp: 2299.0000 - fp: 180.0000 - tn: 4778.0000 - fn: 180.0000 - precision: 0.9274 - recall: 0.9274 - auc: 0.9728 - prc: 0.9496\n","78/78 [==============================] - 1s 11ms/step - loss: 0.4055 - accuracy: 0.9516 - tp: 2299.0000 - fp: 180.0000 - tn: 4778.0000 - fn: 180.0000 - precision: 0.9274 - recall: 0.9274 - auc: 0.9728 - prc: 0.9496\n","\n",">round 10  client 4 evaluation training metrics:\n","[0.0020644834730774164, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9998584985733032, 0.9998722672462463]\n","\n",">round 10  client 4 evaluation metrics:\n","[0.4054718613624573, 0.9515933990478516, 2299.0, 180.0, 4778.0, 180.0, 0.9273900985717773, 0.9273900985717773, 0.9727617502212524, 0.9496058225631714]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","\n",">round 10  client 4 evaluation training metrics:\n","[0.0020644834730774164, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9998584985733032, 0.9998722672462463]\n","\n",">round 10  client 4 evaluation metrics:\n","[0.4054718613624573, 0.9515933990478516, 2299.0, 180.0, 4778.0, 180.0, 0.9273900985717773, 0.9273900985717773, 0.9727617502212524, 0.9496058225631714]\n","\n","=============================================================\n","\n","> client 5 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.0825 - accuracy: 0.9699 - tp: 5408.0000 - fp: 254.0000 - tn: 11076.0000 - fn: 257.0000 - precision: 0.9551 - recall: 0.9546 - auc: 0.9857 - prc: 0.9733\n","32/32 [==============================] - 8s 31ms/step - loss: 0.0825 - accuracy: 0.9699 - tp: 5408.0000 - fp: 254.0000 - tn: 11076.0000 - fn: 257.0000 - precision: 0.9551 - recall: 0.9546 - auc: 0.9857 - prc: 0.9733\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0079 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0079 - accuracy: 0.9986 - tp: 3179.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 7.0000 - precision: 0.9981 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.4005e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.4005e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.8575e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.8575e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.5624e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.5624e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9203e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9203e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6294e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.6294e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.032703593373298645; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.032703593373298645; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0361 - accuracy: 0.9925 - tp: 3149.0000 - fp: 35.0000 - tn: 6337.0000 - fn: 37.0000 - precision: 0.9890 - recall: 0.9884 - auc: 0.9987 - prc: 0.9976\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0361 - accuracy: 0.9925 - tp: 3149.0000 - fp: 35.0000 - tn: 6337.0000 - fn: 37.0000 - precision: 0.9890 - recall: 0.9884 - auc: 0.9987 - prc: 0.9976\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0225 - accuracy: 0.9954 - tp: 3164.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9996 - prc: 0.9993\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0225 - accuracy: 0.9954 - tp: 3164.0000 - fp: 22.0000 - tn: 6350.0000 - fn: 22.0000 - precision: 0.9931 - recall: 0.9931 - auc: 0.9996 - prc: 0.9993\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0120 - accuracy: 0.9965 - tp: 3169.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0120 - accuracy: 0.9965 - tp: 3169.0000 - fp: 16.0000 - tn: 6356.0000 - fn: 17.0000 - precision: 0.9950 - recall: 0.9947 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0030 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0030 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.2758e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 8.2758e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.2572e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 4.2572e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 1.7699e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 1.7699e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 1.4001e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 1.4001e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 1.2828e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 1.2828e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1845e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 1.1845e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.0269923135638237; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.0269923135638237; accuracy of 99.24670457839966%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0974e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0974e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7094e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.7094e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7939e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7939e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1801e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1801e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.7343e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 6.7343e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1358e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1358e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.5216e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 6.5216e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.0391e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 7.0391e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.7337e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 4.7337e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.00032572486088611186; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 0.00032572486088611186; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 2.0480e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 2.0480e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 1.2963e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 1.2963e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9763e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.9763e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.8065e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.8065e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.6215e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 7.6215e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4186e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4186e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7800e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.7800e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9155e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9155e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.6005e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.6005e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.2776e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.2776e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 0.0103178471326828; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Score for fold 4: loss of 0.0103178471326828; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 6.5243e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 6.5243e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3759e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3759e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7800e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7800e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.3592e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.3592e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.5458e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 6.5458e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 4.9925e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 4.9925e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.3074e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.3074e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5263e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5263e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3463e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3463e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 1.3075700735498685e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Score for fold 5: loss of 1.3075700735498685e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6249e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.6249e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4164e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4164e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2307e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.2307e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5353e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5353e-04 - accuracy: 0.9997 - tp: 3184.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 2.0000 - precision: 0.9997 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5670e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5670e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5543e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.5543e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9003e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9003e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4183e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.4183e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 32ms/step - loss: 5.6858e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 5.6858e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 32ms/step - loss: 4.9783e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 4.9783e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.4067745723878033e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 1.4067745723878033e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.3344e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.3344e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.1292e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.1292e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 6.3737e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 6.3737e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 33ms/step - loss: 5.3963e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 33ms/step - loss: 5.3963e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 30ms/step - loss: 4.7366e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 4.7366e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8478e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8478e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.7542e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 4.7542e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8677e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8677e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0619e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0619e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8539e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8539e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 1.0497538823983632e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 1.0497538823983632e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.0667e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.0667e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.0154e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.0154e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8028e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8028e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 32ms/step - loss: 5.1116e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 5.1116e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 31ms/step - loss: 4.8452e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 31ms/step - loss: 4.8452e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0584e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0584e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0007e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0007e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2952e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2952e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0848e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0848e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0581e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0581e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 2.5312920115538873e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Score for fold 8: loss of 2.5312920115538873e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8735e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8735e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9157e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9157e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.5617e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.5617e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7708e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7708e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.9425e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 4.9425e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7757e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7757e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.4054e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.4054e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.6828e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.6828e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.4614e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.4614e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6517e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.6517e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 4.314255875215167e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 4.314255875215167e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8113e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8113e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2451e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.2451e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9921e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9921e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6988e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.6988e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7582e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7582e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6098e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6098e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7469e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.7469e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3932e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3932e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0044e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0044e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9309e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.9309e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 3.435443204580224e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.032703593373298645 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0269923135638237 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.00032572486088611186 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0103178471326828 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 1.3075700735498685e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.4067745723878033e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.0497538823983632e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 2.5312920115538873e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 4.314255875215167e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.435443204580224e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.8305082321167 (+- 0.29717005024485404)\n","> Loss: 0.007038740090706597\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 3.435443204580224e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.032703593373298645 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0269923135638237 - Accuracy: 99.24670457839966%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.00032572486088611186 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.0103178471326828 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 1.3075700735498685e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.4067745723878033e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 1.0497538823983632e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 2.5312920115538873e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 4.314255875215167e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.435443204580224e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.8305082321167 (+- 0.29717005024485404)\n","> Loss: 0.007038740090706597\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 6ms/step\n","111/111 [==============================] - 2s 6ms/step\n","78/78 [==============================] - 1s 6ms/step\n","78/78 [==============================] - 1s 6ms/step\n","111/111 [==============================] - 1s 11ms/step - loss: 4.0271e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 11ms/step - loss: 4.0271e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 13ms/step - loss: 0.2086 - accuracy: 0.9755 - tp: 2388.0000 - fp: 91.0000 - tn: 4867.0000 - fn: 91.0000 - precision: 0.9633 - recall: 0.9633 - auc: 0.9872 - prc: 0.9763\n","78/78 [==============================] - 1s 13ms/step - loss: 0.2086 - accuracy: 0.9755 - tp: 2388.0000 - fp: 91.0000 - tn: 4867.0000 - fn: 91.0000 - precision: 0.9633 - recall: 0.9633 - auc: 0.9872 - prc: 0.9763\n","\n",">round 10  client 5 evaluation training metrics:\n","[0.00040270763565786183, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 10  client 5 evaluation metrics:\n","[0.20860280096530914, 0.9755277633666992, 2388.0, 91.0, 4867.0, 91.0, 0.9632916450500488, 0.9632916450500488, 0.9872007966041565, 0.9762563705444336]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","\n",">round 10  client 5 evaluation training metrics:\n","[0.00040270763565786183, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 10  client 5 evaluation metrics:\n","[0.20860280096530914, 0.9755277633666992, 2388.0, 91.0, 4867.0, 91.0, 0.9632916450500488, 0.9632916450500488, 0.9872007966041565, 0.9762563705444336]\n","\n","=============================================================\n","\n","> client 6 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 7s 29ms/step - loss: 0.0525 - accuracy: 0.9839 - tp: 5527.0000 - fp: 135.0000 - tn: 11195.0000 - fn: 138.0000 - precision: 0.9762 - recall: 0.9756 - auc: 0.9932 - prc: 0.9872\n","32/32 [==============================] - 7s 29ms/step - loss: 0.0525 - accuracy: 0.9839 - tp: 5527.0000 - fp: 135.0000 - tn: 11195.0000 - fn: 138.0000 - precision: 0.9762 - recall: 0.9756 - auc: 0.9932 - prc: 0.9872\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0126 - accuracy: 0.9972 - tp: 3172.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 14.0000 - precision: 0.9959 - recall: 0.9956 - auc: 0.9999 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0126 - accuracy: 0.9972 - tp: 3172.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 14.0000 - precision: 0.9959 - recall: 0.9956 - auc: 0.9999 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.8452e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 2.8452e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 1.6947e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 1.6947e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 33ms/step - loss: 1.3575e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 33ms/step - loss: 1.3575e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0425e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0425e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 8.3417e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 8.3417e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9454e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.9454e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.019968777894973755; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.019968777894973755; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0027 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0027 - accuracy: 0.9995 - tp: 3183.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 3.0000 - precision: 0.9994 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0171 - accuracy: 0.9970 - tp: 3171.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 0.9997 - prc: 0.9994\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0171 - accuracy: 0.9970 - tp: 3171.0000 - fp: 14.0000 - tn: 6358.0000 - fn: 15.0000 - precision: 0.9956 - recall: 0.9953 - auc: 0.9997 - prc: 0.9994\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0154 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9999 - prc: 0.9999\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0154 - accuracy: 0.9964 - tp: 3169.0000 - fp: 17.0000 - tn: 6355.0000 - fn: 17.0000 - precision: 0.9947 - recall: 0.9947 - auc: 0.9999 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0021 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5268e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.5268e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5359e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5359e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4712e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4712e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9359e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.9359e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.0013148626312613487; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.0013148626312613487; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 7.2186e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 7.2186e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8838e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8838e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.7155e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.7155e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.2745e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.2745e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2801e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2801e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8835e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8835e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0650e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.0650e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3500e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3500e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9780e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9780e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8489e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.8489e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 3.15023135044612e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 3.15023135044612e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1259e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.1259e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7708e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7708e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7948e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.7948e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0527e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0527e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6764e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6764e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8616e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8616e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3492e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.3492e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2512e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.2512e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.8209e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 4.8209e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.1400e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 6.1400e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 2.4979071895359084e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Score for fold 4: loss of 2.4979071895359084e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 29ms/step - loss: 2.7159e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 2.7159e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 1.5349e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 1.5349e-04 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 9.2182e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 9.2182e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 6.7558e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 6.7558e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 25ms/step - loss: 5.6097e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 5.6097e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.4898e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 4.4898e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.9310e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 3.9310e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 3.4072e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 3.4072e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 3.0582e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 3.0582e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 2.6941e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 2.6941e-05 - accuracy: 1.0000 - tp: 3186.0000 - fp: 0.0000e+00 - tn: 6372.0000 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.009126915596425533; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","Score for fold 5: loss of 0.009126915596425533; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2210e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.2210e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9590e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.9590e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.9201e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 4.9201e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4044e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4044e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8664e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.8664e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 6.5136e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 6.5136e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.1702e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.1702e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1409e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.1409e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1181e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1181e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.2651989891310222e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 1.2651989891310222e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4702e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4702e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7744e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.7744e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9951e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.9951e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.4655e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.4655e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2548e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.2548e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8138e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.8138e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 4.5979e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 4.5979e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5022e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5022e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8888e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8888e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3285e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.3285e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 5.8880041251541115e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 5.8880041251541115e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8822e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 30ms/step - loss: 5.8822e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8949e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8949e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0058e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0058e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5599e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5599e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3051e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3051e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4551e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.4551e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3850e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.3850e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5704e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.5704e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1673e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.1673e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6302e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6302e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 3.5461778224998852e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 3.5461778224998852e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 34ms/step - loss: 6.4460e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 34ms/step - loss: 6.4460e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.6839e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.6839e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 30ms/step - loss: 4.7124e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 4.7124e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 5.0902e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 5.0902e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4630e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.4630e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9122e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.9122e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7473e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.7473e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 25ms/step - loss: 4.9840e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 4.9840e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0000e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0000e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8079e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.8079e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 5.541855443880195e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 5.541855443880195e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 4.4418e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 4.4418e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6146e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","32/32 [==============================] - 1s 26ms/step - loss: 5.6146e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000   \n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0550e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.0550e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4248e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 5.4248e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 29ms/step - loss: 4.8220e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 4.8220e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 32ms/step - loss: 4.5651e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 4.5651e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 32ms/step - loss: 4.6942e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 4.6942e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 4.5476e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 4.5476e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 31ms/step - loss: 5.9607e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 5.9607e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2790e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2790e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 3.184261686328682e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.019968777894973755 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0013148626312613487 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 3.15023135044612e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 2.4979071895359084e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.009126915596425533 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.2651989891310222e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 5.8880041251541115e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.5461778224998852e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 5.541855443880195e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.184261686328682e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.95291888713837 (+- 0.09648733643285073)\n","> Loss: 0.003049784979702963\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 3.184261686328682e-06; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.019968777894973755 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.0013148626312613487 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 3.15023135044612e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 2.4979071895359084e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.009126915596425533 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.2651989891310222e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 5.8880041251541115e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 3.5461778224998852e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 5.541855443880195e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 3.184261686328682e-06 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.95291888713837 (+- 0.09648733643285073)\n","> Loss: 0.003049784979702963\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 4.2263e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","111/111 [==============================] - 1s 10ms/step - loss: 4.2263e-04 - accuracy: 0.9998 - tp: 3539.0000 - fp: 1.0000 - tn: 7079.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","78/78 [==============================] - 1s 9ms/step - loss: 0.1431 - accuracy: 0.9781 - tp: 2397.0000 - fp: 81.0000 - tn: 4877.0000 - fn: 82.0000 - precision: 0.9673 - recall: 0.9669 - auc: 0.9908 - prc: 0.9829\n","78/78 [==============================] - 1s 9ms/step - loss: 0.1431 - accuracy: 0.9781 - tp: 2397.0000 - fp: 81.0000 - tn: 4877.0000 - fn: 82.0000 - precision: 0.9673 - recall: 0.9669 - auc: 0.9908 - prc: 0.9829\n","\n",">round 10  client 6 evaluation training metrics:\n","[0.00042263470822945237, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 10  client 6 evaluation metrics:\n","[0.14310258626937866, 0.978082537651062, 2397.0, 81.0, 4877.0, 82.0, 0.9673123359680176, 0.9669221639633179, 0.9908452033996582, 0.9828596711158752]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","\n",">round 10  client 6 evaluation training metrics:\n","[0.00042263470822945237, 0.9998116493225098, 3539.0, 1.0, 7079.0, 1.0, 0.9997175335884094, 0.9997175335884094, 0.9999999403953552, 0.9999998211860657]\n","\n",">round 10  client 6 evaluation metrics:\n","[0.14310258626937866, 0.978082537651062, 2397.0, 81.0, 4877.0, 82.0, 0.9673123359680176, 0.9669221639633179, 0.9908452033996582, 0.9828596711158752]\n","\n","=============================================================\n","\n","> client 7 started learning...........\n","\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/10\n","32/32 [==============================] - 8s 31ms/step - loss: 0.0442 - accuracy: 0.9845 - tp: 5533.0000 - fp: 131.0000 - tn: 11199.0000 - fn: 132.0000 - precision: 0.9769 - recall: 0.9767 - auc: 0.9951 - prc: 0.9906\n","32/32 [==============================] - 8s 31ms/step - loss: 0.0442 - accuracy: 0.9845 - tp: 5533.0000 - fp: 131.0000 - tn: 11199.0000 - fn: 132.0000 - precision: 0.9769 - recall: 0.9767 - auc: 0.9951 - prc: 0.9906\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9968 - tp: 3170.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9968 - tp: 3170.0000 - fp: 15.0000 - tn: 6357.0000 - fn: 16.0000 - precision: 0.9953 - recall: 0.9950 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0018 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0016 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 1: loss of 0.007840699516236782; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","Score for fold 1: loss of 0.007840699516236782; accuracy of 99.71751570701599%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0040 - accuracy: 0.9987 - tp: 3180.0000 - fp: 6.0000 - tn: 6366.0000 - fn: 6.0000 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0043 - accuracy: 0.9985 - tp: 3179.0000 - fp: 7.0000 - tn: 6365.0000 - fn: 7.0000 - precision: 0.9978 - recall: 0.9978 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0194 - accuracy: 0.9948 - tp: 3161.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9999 - prc: 0.9998\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0194 - accuracy: 0.9948 - tp: 3161.0000 - fp: 25.0000 - tn: 6347.0000 - fn: 25.0000 - precision: 0.9922 - recall: 0.9922 - auc: 0.9999 - prc: 0.9998\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0213 - accuracy: 0.9950 - tp: 3161.0000 - fp: 23.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9928 - recall: 0.9922 - auc: 0.9996 - prc: 0.9993\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0213 - accuracy: 0.9950 - tp: 3161.0000 - fp: 23.0000 - tn: 6349.0000 - fn: 25.0000 - precision: 0.9928 - recall: 0.9922 - auc: 0.9996 - prc: 0.9993\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0182 - accuracy: 0.9961 - tp: 3167.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 19.0000 - precision: 0.9943 - recall: 0.9940 - auc: 0.9995 - prc: 0.9993\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0182 - accuracy: 0.9961 - tp: 3167.0000 - fp: 18.0000 - tn: 6354.0000 - fn: 19.0000 - precision: 0.9943 - recall: 0.9940 - auc: 0.9995 - prc: 0.9993\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0119 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9997 - prc: 0.9995\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0119 - accuracy: 0.9973 - tp: 3173.0000 - fp: 13.0000 - tn: 6359.0000 - fn: 13.0000 - precision: 0.9959 - recall: 0.9959 - auc: 0.9997 - prc: 0.9995\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0016 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0016 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Score for fold 2: loss of 0.04298052191734314; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","Score for fold 2: loss of 0.04298052191734314; accuracy of 99.05837774276733%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9981 - tp: 3177.0000 - fp: 9.0000 - tn: 6363.0000 - fn: 9.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0023 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0023 - accuracy: 0.9993 - tp: 3182.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 4.0000 - precision: 0.9991 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 3: loss of 0.002913055708631873; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","Score for fold 3: loss of 0.002913055708631873; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 4: loss of 3.476937490631826e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","Score for fold 4: loss of 3.476937490631826e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 32ms/step - loss: 8.4605e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 8.4605e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 31ms/step - loss: 6.8942e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 6.8942e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 32ms/step - loss: 5.4618e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 5.4618e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 29ms/step - loss: 5.9975e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 5.9975e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.5966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6810e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.6810e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3630e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.3630e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8903e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.8903e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0359e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.0359e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0460e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 5.0460e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 5: loss of 0.010681109502911568; accuracy of 99.81167316436768%Score for fold 5: loss of 0.010681109502911568; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 6: loss of 1.0361013664805796e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","Score for fold 6: loss of 1.0361013664805796e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4757e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.4757e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7107e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 9.7107e-04 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0011 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0010 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Score for fold 7: loss of 0.0020069368183612823; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","Score for fold 7: loss of 0.0020069368183612823; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0012 - accuracy: 0.9992 - tp: 3182.0000 - fp: 4.0000 - tn: 6368.0000 - fn: 4.0000 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0014 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3183.0000 - fp: 3.0000 - tn: 6369.0000 - fn: 3.0000 - precision: 0.9991 - recall: 0.9991 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Score for fold 8: loss of 1.1051940418838058e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","Score for fold 8: loss of 1.1051940418838058e-05; accuracy of 100.0%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0861e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.0861e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.2324e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.2324e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2769e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.2769e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.5211e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.5211e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 32ms/step - loss: 7.2393e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 7.2393e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 30ms/step - loss: 8.4478e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 8.4478e-04 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 32ms/step - loss: 7.2973e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 32ms/step - loss: 7.2973e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 30ms/step - loss: 7.1411e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 30ms/step - loss: 7.1411e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0733e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0733e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 9: loss of 0.008807457983493805; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","Score for fold 9: loss of 0.008807457983493805; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Epoch 1/10\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3184.0000 - fp: 2.0000 - tn: 6370.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1908e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 8.1908e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","32/32 [==============================] - 1s 25ms/step - loss: 7.8301e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 25ms/step - loss: 7.8301e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4023e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.4023e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7717e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 6.7717e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0593e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 27ms/step - loss: 7.0593e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 7.1966e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9464e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9464e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9881e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","32/32 [==============================] - 1s 26ms/step - loss: 6.9881e-04 - accuracy: 0.9998 - tp: 3185.0000 - fp: 1.0000 - tn: 6371.0000 - fn: 1.0000 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - prc: 1.0000\n","Score for fold 10: loss of 0.022092901170253754; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.007840699516236782 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.04298052191734314 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.002913055708631873 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 3.476937490631826e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.010681109502911568 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.0361013664805796e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0020069368183612823 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 1.1051940418838058e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.008807457983493805 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.022092901170253754 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.78342592716217 (+- 0.2597578768660122)\n","> Loss: 0.009737886494622216\n","------------------------------------------------------------------------\n","Score for fold 10: loss of 0.022092901170253754; accuracy of 99.81167316436768%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.007840699516236782 - Accuracy: 99.71751570701599%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.04298052191734314 - Accuracy: 99.05837774276733%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.002913055708631873 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 3.476937490631826e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.010681109502911568 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 1.0361013664805796e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.0020069368183612823 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 1.1051940418838058e-05 - Accuracy: 100.0%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.008807457983493805 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.022092901170253754 - Accuracy: 99.81167316436768%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 99.78342592716217 (+- 0.2597578768660122)\n","> Loss: 0.009737886494622216\n","------------------------------------------------------------------------\n","111/111 [==============================] - 2s 5ms/step\n","111/111 [==============================] - 2s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","78/78 [==============================] - 0s 5ms/step\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9996\n","111/111 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 0.9998 - prc: 0.9996\n","78/78 [==============================] - 1s 10ms/step - loss: 0.3242 - accuracy: 0.9613 - tp: 2333.0000 - fp: 142.0000 - tn: 4816.0000 - fn: 146.0000 - precision: 0.9426 - recall: 0.9411 - auc: 0.9800 - prc: 0.9627\n","78/78 [==============================] - 1s 10ms/step - loss: 0.3242 - accuracy: 0.9613 - tp: 2333.0000 - fp: 142.0000 - tn: 4816.0000 - fn: 146.0000 - precision: 0.9426 - recall: 0.9411 - auc: 0.9800 - prc: 0.9627\n","\n",">round 10  client 7 evaluation training metrics:\n","[0.002756301313638687, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9997878074645996, 0.999589741230011]\n","\n",">round 10  client 7 evaluation metrics:\n","[0.3241795003414154, 0.9612746834754944, 2333.0, 142.0, 4816.0, 146.0, 0.9426262378692627, 0.941105306148529, 0.9800313711166382, 0.9626948237419128]\n","\n","=============================================================\n","\n","> round 10 average training auc= 0.24888904482247748\n","> round 10 average training loss= 0.011742314599376054\n","\n",">round 10  client 7 evaluation training metrics:\n","[0.002756301313638687, 0.9996233582496643, 3538.0, 2.0, 7078.0, 2.0, 0.9994350075721741, 0.9994350075721741, 0.9997878074645996, 0.999589741230011]\n","\n",">round 10  client 7 evaluation metrics:\n","[0.3241795003414154, 0.9612746834754944, 2333.0, 142.0, 4816.0, 146.0, 0.9426262378692627, 0.941105306148529, 0.9800313711166382, 0.9626948237419128]\n","\n","=============================================================\n","\n","> round 10 average training auc= 0.24888904482247748\n","> round 10 average training loss= 0.011742314599376054\n","Epoch 1/10\n","Epoch 1/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0038 - accuracy: 0.9988 - tp: 3530.0000 - fp: 2.0000 - tn: 7080.0000 - fn: 11.0000 - precision: 0.9994 - recall: 0.9969 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0038 - accuracy: 0.9986 - tp: 3529.0000 - fp: 3.0000 - tn: 7079.0000 - fn: 12.0000 - precision: 0.9992 - recall: 0.9966 - auc: 1.0000 - prc: 1.0000\n","> model 1 retrained, original loss= 0.010337806353618362 , retrained loss= 0.003821873338893056 epoch count 20.0\n","> model 1 retrained, original loss= 0.010337806353618362 , retrained loss= 0.003821873338893056 epoch count 20.0\n","Epoch 1/10\n","Epoch 1/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0218 - accuracy: 0.9935 - tp: 3505.0000 - fp: 33.0000 - tn: 7049.0000 - fn: 36.0000 - precision: 0.9907 - recall: 0.9898 - auc: 0.9995 - prc: 0.9989\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0218 - accuracy: 0.9935 - tp: 3505.0000 - fp: 33.0000 - tn: 7049.0000 - fn: 36.0000 - precision: 0.9907 - recall: 0.9898 - auc: 0.9995 - prc: 0.9989\n","Epoch 2/10\n","Epoch 2/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0129 - accuracy: 0.9957 - tp: 3518.0000 - fp: 23.0000 - tn: 7059.0000 - fn: 23.0000 - precision: 0.9935 - recall: 0.9935 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0129 - accuracy: 0.9957 - tp: 3518.0000 - fp: 23.0000 - tn: 7059.0000 - fn: 23.0000 - precision: 0.9935 - recall: 0.9935 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9960 - tp: 3520.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 21.0000 - precision: 0.9941 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9960 - tp: 3520.0000 - fp: 21.0000 - tn: 7061.0000 - fn: 21.0000 - precision: 0.9941 - recall: 0.9941 - auc: 1.0000 - prc: 0.9999\n","Epoch 4/10\n","Epoch 4/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9957 - tp: 3518.0000 - fp: 23.0000 - tn: 7059.0000 - fn: 23.0000 - precision: 0.9935 - recall: 0.9935 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9957 - tp: 3518.0000 - fp: 23.0000 - tn: 7059.0000 - fn: 23.0000 - precision: 0.9935 - recall: 0.9935 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9957 - tp: 3518.0000 - fp: 23.0000 - tn: 7059.0000 - fn: 23.0000 - precision: 0.9935 - recall: 0.9935 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9957 - tp: 3518.0000 - fp: 23.0000 - tn: 7059.0000 - fn: 23.0000 - precision: 0.9935 - recall: 0.9935 - auc: 1.0000 - prc: 0.9999\n","Epoch 6/10\n","Epoch 6/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9966 - tp: 3523.0000 - fp: 18.0000 - tn: 7064.0000 - fn: 18.0000 - precision: 0.9949 - recall: 0.9949 - auc: 1.0000 - prc: 0.9999\n","Epoch 7/10\n","Epoch 7/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9962 - tp: 3521.0000 - fp: 20.0000 - tn: 7062.0000 - fn: 20.0000 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - prc: 0.9999\n","Epoch 8/10\n","Epoch 8/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9968 - tp: 3524.0000 - fp: 17.0000 - tn: 7065.0000 - fn: 17.0000 - precision: 0.9952 - recall: 0.9952 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9968 - tp: 3524.0000 - fp: 17.0000 - tn: 7065.0000 - fn: 17.0000 - precision: 0.9952 - recall: 0.9952 - auc: 1.0000 - prc: 0.9999\n","Epoch 9/10\n","Epoch 9/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9959 - tp: 3519.0000 - fp: 22.0000 - tn: 7060.0000 - fn: 22.0000 - precision: 0.9938 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9959 - tp: 3519.0000 - fp: 22.0000 - tn: 7060.0000 - fn: 22.0000 - precision: 0.9938 - recall: 0.9938 - auc: 1.0000 - prc: 0.9999\n","Epoch 10/10\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9953 - tp: 3516.0000 - fp: 25.0000 - tn: 7057.0000 - fn: 25.0000 - precision: 0.9929 - recall: 0.9929 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9953 - tp: 3516.0000 - fp: 25.0000 - tn: 7057.0000 - fn: 25.0000 - precision: 0.9929 - recall: 0.9929 - auc: 1.0000 - prc: 0.9999\n","> model 2 retrained, original loss= 0.022078904137015343 , retrained loss= 0.008474254980683327 epoch count 20.0\n","> model 2 retrained, original loss= 0.022078904137015343 , retrained loss= 0.008474254980683327 epoch count 20.0\n","Epoch 1/10\n","Epoch 1/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3535.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 6.0000 - precision: 0.9986 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - tp: 3535.0000 - fp: 5.0000 - tn: 7077.0000 - fn: 6.0000 - precision: 0.9986 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","Epoch 2/10\n","Epoch 2/10\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","Epoch 3/10\n","Epoch 3/10\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0027 - accuracy: 0.9985 - tp: 3533.0000 - fp: 8.0000 - tn: 7074.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0027 - accuracy: 0.9985 - tp: 3533.0000 - fp: 8.0000 - tn: 7074.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0031 - accuracy: 0.9987 - tp: 3534.0000 - fp: 7.0000 - tn: 7075.0000 - fn: 7.0000 - precision: 0.9980 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3533.0000 - fp: 8.0000 - tn: 7074.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 0.9985 - tp: 3533.0000 - fp: 8.0000 - tn: 7074.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9988 - tp: 3534.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 7.0000 - precision: 0.9983 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9988 - tp: 3534.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 7.0000 - precision: 0.9983 - recall: 0.9980 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3533.0000 - fp: 8.0000 - tn: 7074.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9985 - tp: 3533.0000 - fp: 8.0000 - tn: 7074.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9989 - tp: 3535.0000 - fp: 6.0000 - tn: 7076.0000 - fn: 6.0000 - precision: 0.9983 - recall: 0.9983 - auc: 1.0000 - prc: 1.0000\n","> model 3 retrained, original loss= 0.015807200114977604 , retrained loss= 0.0026875759940594435 epoch count 20.0\n","> model 3 retrained, original loss= 0.015807200114977604 , retrained loss= 0.0026875759940594435 epoch count 20.0\n","Epoch 1/10\n","Epoch 1/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9985 - tp: 3532.0000 - fp: 8.0000 - tn: 7072.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 0.9996 - prc: 0.9992\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9985 - tp: 3532.0000 - fp: 8.0000 - tn: 7072.0000 - fn: 8.0000 - precision: 0.9977 - recall: 0.9977 - auc: 0.9996 - prc: 0.9992\n","Epoch 2/10\n","Epoch 2/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0109 - accuracy: 0.9982 - tp: 3530.0000 - fp: 9.0000 - tn: 7071.0000 - fn: 10.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0109 - accuracy: 0.9982 - tp: 3530.0000 - fp: 9.0000 - tn: 7071.0000 - fn: 10.0000 - precision: 0.9975 - recall: 0.9972 - auc: 1.0000 - prc: 0.9999\n","Epoch 3/10\n","Epoch 3/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9976 - tp: 3527.0000 - fp: 13.0000 - tn: 7067.0000 - fn: 13.0000 - precision: 0.9963 - recall: 0.9963 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9976 - tp: 3527.0000 - fp: 13.0000 - tn: 7067.0000 - fn: 13.0000 - precision: 0.9963 - recall: 0.9963 - auc: 1.0000 - prc: 1.0000\n","Epoch 4/10\n","Epoch 4/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9981 - tp: 3530.0000 - fp: 10.0000 - tn: 7070.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9981 - tp: 3530.0000 - fp: 10.0000 - tn: 7070.0000 - fn: 10.0000 - precision: 0.9972 - recall: 0.9972 - auc: 1.0000 - prc: 1.0000\n","Epoch 5/10\n","Epoch 5/10\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9983 - tp: 3531.0000 - fp: 9.0000 - tn: 7071.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9998 - prc: 0.9995\n","36/36 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9983 - tp: 3531.0000 - fp: 9.0000 - tn: 7071.0000 - fn: 9.0000 - precision: 0.9975 - recall: 0.9975 - auc: 0.9998 - prc: 0.9995\n","Epoch 6/10\n","Epoch 6/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","36/36 [==============================] - 1s 31ms/step - loss: 9.4107e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 31ms/step - loss: 9.4107e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","36/36 [==============================] - 1s 30ms/step - loss: 9.2307e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 30ms/step - loss: 9.2307e-04 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","36/36 [==============================] - 1s 30ms/step - loss: 9.5472e-04 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 30ms/step - loss: 9.5472e-04 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","> model 4 retrained, original loss= 0.01414588002498931 , retrained loss= 0.0009547227527946234 epoch count 20.0\n","> model 4 retrained, original loss= 0.01414588002498931 , retrained loss= 0.0009547227527946234 epoch count 20.0\n","Epoch 1/10\n","Epoch 1/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0826 - accuracy: 0.9837 - tp: 3452.0000 - fp: 85.0000 - tn: 6995.0000 - fn: 88.0000 - precision: 0.9760 - recall: 0.9751 - auc: 0.9963 - prc: 0.9927\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0826 - accuracy: 0.9837 - tp: 3452.0000 - fp: 85.0000 - tn: 6995.0000 - fn: 88.0000 - precision: 0.9760 - recall: 0.9751 - auc: 0.9963 - prc: 0.9927\n","Epoch 2/10\n","Epoch 2/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.1030 - accuracy: 0.9765 - tp: 3411.0000 - fp: 121.0000 - tn: 6959.0000 - fn: 129.0000 - precision: 0.9657 - recall: 0.9636 - auc: 0.9960 - prc: 0.9925\n","36/36 [==============================] - 1s 26ms/step - loss: 0.1030 - accuracy: 0.9765 - tp: 3411.0000 - fp: 121.0000 - tn: 6959.0000 - fn: 129.0000 - precision: 0.9657 - recall: 0.9636 - auc: 0.9960 - prc: 0.9925\n","Epoch 3/10\n","Epoch 3/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0256 - accuracy: 0.9942 - tp: 3509.0000 - fp: 31.0000 - tn: 7049.0000 - fn: 31.0000 - precision: 0.9912 - recall: 0.9912 - auc: 0.9996 - prc: 0.9995\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0256 - accuracy: 0.9942 - tp: 3509.0000 - fp: 31.0000 - tn: 7049.0000 - fn: 31.0000 - precision: 0.9912 - recall: 0.9912 - auc: 0.9996 - prc: 0.9995\n","Epoch 4/10\n","Epoch 4/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0103 - accuracy: 0.9972 - tp: 3525.0000 - fp: 15.0000 - tn: 7065.0000 - fn: 15.0000 - precision: 0.9958 - recall: 0.9958 - auc: 1.0000 - prc: 0.9999\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0103 - accuracy: 0.9972 - tp: 3525.0000 - fp: 15.0000 - tn: 7065.0000 - fn: 15.0000 - precision: 0.9958 - recall: 0.9958 - auc: 1.0000 - prc: 0.9999\n","Epoch 5/10\n","Epoch 5/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9992 - tp: 3536.0000 - fp: 4.0000 - tn: 7076.0000 - fn: 4.0000 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - prc: 1.0000\n","Epoch 6/10\n","Epoch 6/10\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 7/10\n","Epoch 7/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 8/10\n","Epoch 8/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9996 - tp: 3538.0000 - fp: 2.0000 - tn: 7078.0000 - fn: 2.0000 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - prc: 1.0000\n","Epoch 9/10\n","Epoch 9/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","Epoch 10/10\n","Epoch 10/10\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","36/36 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - tp: 3537.0000 - fp: 3.0000 - tn: 7077.0000 - fn: 3.0000 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - prc: 1.0000\n","> model 7 retrained, original loss= 0.009737886494622216 , retrained loss= 0.0013164947740733624 epoch count 20.0\n","> round 10 average epoch count= 17.142857142857142\n","> model 7 retrained, original loss= 0.009737886494622216 , retrained loss= 0.0013164947740733624 epoch count 20.0\n","> round 10 average epoch count= 17.142857142857142\n"," 1/78 [..............................] - ETA: 2s"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n","/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  a = np.asanyarray(a)\n"]},{"output_type":"stream","name":"stdout","text":["78/78 [==============================] - 0s 6ms/step\n","78/78 [==============================] - 0s 6ms/step\n","> round 10 test auc= 0.2740564441639917\n","> round 10 test auc= 0.2740564441639917\n","111/111 [==============================] - 1s 10ms/step - loss: 2.1291 - accuracy: 0.8138 - tp: 2548.0000 - fp: 985.0000 - tn: 6097.0000 - fn: 993.0000 - precision: 0.7212 - recall: 0.7196 - auc: 0.8323 - prc: 0.7063\n","111/111 [==============================] - 1s 10ms/step - loss: 2.1291 - accuracy: 0.8138 - tp: 2548.0000 - fp: 985.0000 - tn: 6097.0000 - fn: 993.0000 - precision: 0.7212 - recall: 0.7196 - auc: 0.8323 - prc: 0.7063\n","\n","> round 10 final model training loss_metric= [2.129120111465454]\n","> round 10 final model training TP_metric= [2548.0]\n","> round 10 final model training FP_metric= [985.0]\n","> round 10 final model training TN_metric= [6097.0]\n","> round 10 final model training FN_metric= [993.0]\n","> round 10 final model training accuracy_metric= [81.38002157211304]\n","> round 10 final model training precision_metric= [72.12001085281372]\n","> round 10 final model training recall_metric = [71.95707559585571]\n","> round 10 final model training auc_metric= [0.8323444128036499]\n","> round 10 final model training prc_metric= [0.70634925365448]\n","\n","\n","> round 10 final model training loss_metric= [2.129120111465454]\n","> round 10 final model training TP_metric= [2548.0]\n","> round 10 final model training FP_metric= [985.0]\n","> round 10 final model training TN_metric= [6097.0]\n","> round 10 final model training FN_metric= [993.0]\n","> round 10 final model training accuracy_metric= [81.38002157211304]\n","> round 10 final model training precision_metric= [72.12001085281372]\n","> round 10 final model training recall_metric = [71.95707559585571]\n","> round 10 final model training auc_metric= [0.8323444128036499]\n","> round 10 final model training prc_metric= [0.70634925365448]\n","\n","78/78 [==============================] - 1s 9ms/step - loss: 1.6059 - accuracy: 0.8546 - tp: 1936.0000 - fp: 538.0000 - tn: 4420.0000 - fn: 543.0000 - precision: 0.7825 - recall: 0.7810 - auc: 0.8755 - prc: 0.7740\n","78/78 [==============================] - 1s 9ms/step - loss: 1.6059 - accuracy: 0.8546 - tp: 1936.0000 - fp: 538.0000 - tn: 4420.0000 - fn: 543.0000 - precision: 0.7825 - recall: 0.7810 - auc: 0.8755 - prc: 0.7740\n","> round 10 final model loss_metric= [1.6058977842330933]\n","> round 10 final model TP_metric= [1936.0]\n","> round 10 final model FP_metric= [538.0]\n","> round 10 final model TN_metric= [4420.0]\n","> round 10 final model FN_metric= [543.0]\n","> round 10 final model accuracy_metric= [85.46456694602966]\n","> round 10 final model precision_metric= [78.25384140014648]\n","> round 10 final model recall_metric = [78.09600830078125]\n","> round 10 final model auc_metric= [0.8754945993423462]\n","> round 10 final model prc_metric= [0.7740361094474792]\n","(17,)\n","Model: \"model_63\"\n","> round 10 final model loss_metric= [1.6058977842330933]\n","> round 10 final model TP_metric= [1936.0]\n","> round 10 final model FP_metric= [538.0]\n","> round 10 final model TN_metric= [4420.0]\n","> round 10 final model FN_metric= [543.0]\n","> round 10 final model accuracy_metric= [85.46456694602966]\n","> round 10 final model precision_metric= [78.25384140014648]\n","> round 10 final model recall_metric = [78.09600830078125]\n","> round 10 final model auc_metric= [0.8754945993423462]\n","> round 10 final model prc_metric= [0.7740361094474792]\n","(17,)\n","Model: \"model_63\"\n","_________________________________________________________________\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n","=================================================================\n"," input_64 (InputLayer)       [(None, 100)]             0         \n"," input_64 (InputLayer)       [(None, 100)]             0         \n","                                                                 \n","                                                                 \n"," embedding_63 (Embedding)    (None, 100, 300)          6855900   \n"," embedding_63 (Embedding)    (None, 100, 300)          6855900   \n","                                                                 \n","                                                                 \n"," conv1d_63 (Conv1D)          (None, 97, 512)           614912    \n"," conv1d_63 (Conv1D)          (None, 97, 512)           614912    \n","                                                                 \n","                                                                 \n"," batch_normalization_63 (Bat  (None, 97, 512)          2048      \n"," batch_normalization_63 (Bat  (None, 97, 512)          2048      \n"," chNormalization)                                                \n"," chNormalization)                                                \n","                                                                 \n","                                                                 \n"," max_pooling1d_63 (MaxPoolin  (None, 24, 512)          0         \n"," max_pooling1d_63 (MaxPoolin  (None, 24, 512)          0         \n"," g1D)                                                            \n"," g1D)                                                            \n","                                                                 \n","                                                                 \n"," attention_63 (attention)    (None, 24, 512)           536       \n"," attention_63 (attention)    (None, 24, 512)           536       \n","                                                                 \n","                                                                 \n"," bidirectional_63 (Bidirecti  (None, 24, 200)          490400    \n"," bidirectional_63 (Bidirecti  (None, 24, 200)          490400    \n"," onal)                                                           \n"," onal)                                                           \n","                                                                 \n","                                                                 \n"," global_max_pooling1d_63 (Gl  (None, 200)              0         \n"," global_max_pooling1d_63 (Gl  (None, 200)              0         \n"," obalMaxPooling1D)                                               \n"," obalMaxPooling1D)                                               \n","                                                                 \n","                                                                 \n"," dense_63 (Dense)            (None, 3)                 603       \n"," dense_63 (Dense)            (None, 3)                 603       \n","                                                                 \n","                                                                 \n","=================================================================\n","=================================================================\n","Total params: 7,964,399\n","Total params: 7,964,399\n","Trainable params: 1,107,475\n","Trainable params: 1,107,475\n","Non-trainable params: 6,856,924\n","Non-trainable params: 6,856,924\n","_________________________________________________________________\n","_________________________________________________________________\n","> average epoch count= 12.428571428571429\n","> 10 ROUNDS 7 CLIENTS ENDED..........\n","\n","Federated Model Took: 8149.079129934311\n","\n","\n","> average epoch count= 12.428571428571429\n","> 10 ROUNDS 7 CLIENTS ENDED..........\n","\n","Federated Model Took: 8149.079129934311\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n","/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = asarray(a).shape\n"]}],"source":["start_time = time.time()\n","federated_learning_evaluation(clients_number)\n","print(\"\")\n","print(\"Federated Model Took: {}\\n\\n\".format(time.time() - start_time))"]}],"metadata":{"colab":{"collapsed_sections":["S2h9vDxwy3mD"],"provenance":[{"file_id":"1CtQM2LuZRc8Nz8bpmwbixf_jFpXtPcI9","timestamp":1678101101677}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}